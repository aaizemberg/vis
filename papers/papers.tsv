Conference	Year	Paper Title	Paper DOI	Link	First page	Last page	Paper type: C=conference paper, J = journal paper, M=miscellaneous (capstone, keynote, VAST challenge, panel, poster, ...)	Abstract	Author Names	Author Affiliation	References	Author Keywords	Experimental: OCRd Author Affiliations
Vis	1990	Interdisciplinary visualization: lessons learned at NCSA	10.0000/00000002	http://dl.acm.org/citation.cfm?id=949606&CFID=522724143&CFTOKEN=98665846	457	457	M		Donna J. Cox	National Center for Supercomputing Applications			National Center for Supercomputing Applications
Vis	1990	Surface representations of two- and three-dimensional fluid flow topology	10.1109/VISUAL.1990.146359	http://dx.doi.org/10.1109/VISUAL.1990.146359	6	13, 460	C		James Helman;Lambertus Hesselink	Stanford Univ., CA, USA|c|;			Stanford University Stanford##Stanford University Stanford
Vis	1990	FAST: a multi-processed environment for visualization of computational fluid dynamics	10.1109/VISUAL.1990.146360	http://dx.doi.org/10.1109/VISUAL.1990.146360	14	27, 461-2	C		Gordon V. Bancroft;Fergus Merritt;Todd Plessel;Paul G. Kelaita;R. Kevin McCabe;Al Globus	Sterling Federal Syst. Inc., Palo Alto, CA, USA|c|;;;;;			Sterling Federal Systems Inc##Sterling Federal Systems Inc##Sterling Federal Systems Inc##Sterling Federal Systems Inc##Sterling Federal Systems Inc##Sterling Federal Systems Inc
Vis	1990	The VIS-5D system for easy interactive visualization	10.1109/VISUAL.1990.146361	http://dx.doi.org/10.1109/VISUAL.1990.146361	28	35, 462	C		William L. Hibbard;David A. Santek	Space Sci. & Eng. Center, Wisconsin Univ., Madison, WI, USA|c|;			University of Wisconsin -Madison##University of Wisconsin -Madison
Vis	1990	A procedural interface for volume rendering	10.1109/VISUAL.1990.146362	http://dx.doi.org/10.1109/VISUAL.1990.146362	36	44, 462	C		James L. Montine	Alliant Comput. Syst., Littleton, MA, USA|c|			Alliant Comput. Syst., Littleton, MA, USA|c|
Vis	1990	Techniques for the interactive visualization of volumetric data	10.1109/VISUAL.1990.146363	http://dx.doi.org/10.1109/VISUAL.1990.146363	45	50, 462-3	C		Gregory M. Nielson;Bernd Hamann	Dept. of Comput. Sci., Arizona State Univ., Tempe, AZ, USA|c|;	10.1109/VISUAL.1990.146388		Arizona State University Tempe##Arizona State University Tempe
Vis	1990	Displaying voxel-based objects according to their qualitative shape synthesis	10.1109/VISUAL.1990.146364	http://dx.doi.org/10.1109/VISUAL.1990.146364	51	58, 463-4	C		Yaser Yacoob	Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA|c|			University of Maryland College Park
Vis	1990	Interpreting a 3D object from a rough 2D line drawing	10.1109/VISUAL.1990.146365	http://dx.doi.org/10.1109/VISUAL.1990.146365	59	66	C		Del Lamb;Amit Bandopadhay	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;			State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook
Vis	1990	Animation techniques for chain-coded objects	10.1109/VISUAL.1990.146366	http://dx.doi.org/10.1109/VISUAL.1990.146366	67	73	C		Anthony J. Maeder	Dept. of Comput. Sci., Monash Univ., Clayton, Vic., Australia|c|			Monash University
Vis	1990	Extracting geometric models through constraint minimization	10.1109/VISUAL.1990.146367	http://dx.doi.org/10.1109/VISUAL.1990.146367	74	82, 464-5	C		James V. Miller;David E. Breen;Michael J. Wozny	Rensselaer Design. Res. Center, Rensselaer Polytech Inst., Troy, NY, USA|c|;;			Rensselaer Design Research Center Rensselaer Polytechnic Institute Troy##Rensselaer Design Research Center Rensselaer Polytechnic Institute Troy##Rensselaer Design Research Center Rensselaer Polytechnic Institute Troy
Vis	1990	Wide-band relativistic Doppler effect visualization	10.1109/VISUAL.1990.146368	http://dx.doi.org/10.1109/VISUAL.1990.146368	83	92, 465-7	C		Ping-Kang Hsiung;Robert H. Thibadeau;Christopher B. Cox;Robert H. P. Dunn;Michael Wu;Paul Andrew Olbrich	Carnegie Mellon Univ., Pittsburgh, PA, USA|c|;;;;;			Carnegie Mellon University Pittsburgh##lon University
Vis	1990	Dynamic graphics for network visualization	10.1109/VISUAL.1990.146369	http://dx.doi.org/10.1109/VISUAL.1990.146369	93	96, 467	C		Richard A. Becker;Stephen G. Eick;Eileen O. Miller;Allan R. Wilks	AT&T Bell Lab., Murray Hill, NJ, USA|c|;;;			AT&T Bell Laboratories Murray Hill##AT&T Bell Laboratories Murray Hill##AT&T Bell Laboratories Murray Hill##AT&T Bell Laboratories Murray Hill
Vis	1990	Techniques for visualizing Fermat's last theorem: a case study	10.1109/VISUAL.1990.146370	http://dx.doi.org/10.1109/VISUAL.1990.146370	97	106, 467-8	C		Andrew J. Hanson;Pheng-Ann Heng;B. C. Kaplan	Indiana Univ., Bloomington, IN, USA|c|;;			Applications Indiana University##Applications Indiana University##Applications Indiana University
Vis	1990	Visualizing computer memory architectures	10.1109/VISUAL.1990.146371	http://dx.doi.org/10.1109/VISUAL.1990.146371	107	113	C		Bowen Alpern;Larry Carter;Ted Selker	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;			IBM Thomas J. Watson Research Center##IBM Thomas J. Watson Research Center##IBM Thomas J. Watson Research Center
Vis	1990	A methodology for scientific data visualisation: choosing representations based on a natural scene paradigm	10.1109/VISUAL.1990.146372	http://dx.doi.org/10.1109/VISUAL.1990.146372	114	123	C		Philip K. Robertson	CSIRO, Canberra, ACT, Australia|c|			CSIRO, Canberra, ACT, Australia|c|
Vis	1990	Moving iconic objects in scientific visualization	10.1109/VISUAL.1990.146373	http://dx.doi.org/10.1109/VISUAL.1990.146373	124	130, 468	C		G. David Kerlick	Tektronix Labs., Beaverton, OR, USA|c|			Tektronix Labs., Beaverton, OR, USA|c|
Vis	1990	Classifying visual knowledge representations: a foundation for visualization research	10.1109/VISUAL.1990.146374	http://dx.doi.org/10.1109/VISUAL.1990.146374	131	138	C		Gerald L. Lohse;Henry H. Rueter;Kevin Biolsi;Neff Walker	Cognitive Sci. & Machine Intelligence Lab., Michigan Univ., Ann Arbor, MI, USA|c|;;;			Cognitive Sci. & Machine Intelligence Lab., Michigan Univ., Ann Arbor, MI, USA|c|;;;
Vis	1990	A problem-oriented classification of visualization techniques	10.1109/VISUAL.1990.146375	http://dx.doi.org/10.1109/VISUAL.1990.146375	139	143, 469	C		Stephen Wehrend;Clayton Lewis	Colorado Univ., Boulder, CO, USA|c|;			University of Colorado##University of Colorado
Vis	1990	Visualization and three-dimensional image processing of positron emission tomography (PET) brain images	10.1109/VISUAL.1990.146376	http://dx.doi.org/10.1109/VISUAL.1990.146376	144	149, 469	C		Nahum D. Gershon	MITRE Corp., McLean, VA, USA|c|			The MITRE Corporation
Vis	1990	Applying space subdivision techniques to volume rendering	10.1109/VISUAL.1990.146377	http://dx.doi.org/10.1109/VISUAL.1990.146377	150	159, 470	C		Kalpathi R. Subramanian;Donald S. Fussell	;			The University of Texas at Austin Austin##The University of Texas at Austin Austin##The University of Texas at Austin
Vis	1990	Volume visualization in cell biology	10.1109/VISUAL.1990.146378	http://dx.doi.org/10.1109/VISUAL.1990.146378	160	168, 471-2	C		Arie E. Kaufman;Roni Yagel;Reuven Bakalash;I. Spector	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;;			Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;;
Vis	1990	Hierarchical triangulation using terrain features	10.1109/VISUAL.1990.146379	http://dx.doi.org/10.1109/VISUAL.1990.146379	168	175	C		Lori L. Scarlatos;Theodosios Pavlidis	Grumman Data Syst., Woodbury, NY, USA|c|;			Woodbury Rd. Woodbury
Vis	1990	Rendering and managing spherical data with sphere quadtrees	10.1109/VISUAL.1990.146380	http://dx.doi.org/10.1109/VISUAL.1990.146380	176	186	C		Gyorgy Fekete	NASA, Goddard Space Flight Center, Greenbelt, MD|c|			SAR at National SDace Science Data Center NASA/Goddarh Space Flight Center Greenbelt
Vis	1990	Methods for surface interrogation	10.1109/VISUAL.1990.146381	http://dx.doi.org/10.1109/VISUAL.1990.146381	187	193, 472	C		Hans Hagen;Thomas Schreiber;Ernst Gschwind	Kaiserslautern Univ., Germany|c|;;			Universitat Kaiserslautern FB-Informatik##Universitat Kaiserslautern FB-Informatik##Universitat Kaiserslautern FB-Informatik
Vis	1990	A three-dimensional/stereoscopic display and model control system for Great Lakes forecasts	10.1109/VISUAL.1990.146382	http://dx.doi.org/10.1109/VISUAL.1990.146382	194	201, 473-4	C		Chieh-Cheng Yen;Keith W. Bedford;Jill Kempf;Robert E. Marshall	Dept. of Civil Eng., Ohio State Univ., OH, USA|c|;;;			The Ohio State University##The Ohio State University
Vis	1990	Spline-based color sequences for univariate, bivariate and trivariate mapping	10.1109/VISUAL.1990.146383	http://dx.doi.org/10.1109/VISUAL.1990.146383	202	208, 474-5	C		Binh Pham	Dept. of Comput. Sci., Monash Univ., Melbourne, Vic., Australia|c|			Monash University
Vis	1990	Interactive visualization of quaternion Julia sets	10.1109/VISUAL.1990.146384	http://dx.doi.org/10.1109/VISUAL.1990.146384	209	218, 475-6	C		John C. Hart;Louis H. Kauffman;Dan Sandin	Electron. Visualization Lab., Illinois Univ., Chicago, IL, USA|c|;;			Electron. Visualization Lab., Illinois Univ., Chicago, IL, USA|c|;;
Vis	1990	A journey into the fourth dimension	10.1109/VISUAL.1990.146385	http://dx.doi.org/10.1109/VISUAL.1990.146385	219	229, 476-477	C		Yan Ke;E. S. Panduranga	Dept. of Comput. Sci., Saskatchewan Univ., Saskatoon, Sask., Canada|c|;			University of Saskatchewan Saskatoon##Johns Hopkins University Baltimore
Vis	1990	Exploring N-dimensional databases	10.1109/VISUAL.1990.146386	http://dx.doi.org/10.1109/VISUAL.1990.146386	230	237	C		Jeffrey LeBlanc;Matthew O. Ward;Norman Wittels	Worcester Polytech. Inst., MA, USA|c|;;			Worcester Polytech. Inst., MA, USA|c|;;
Vis	1990	Shape coding of multidimensional data on a microcomputer display	10.1109/VISUAL.1990.146387	http://dx.doi.org/10.1109/VISUAL.1990.146387	238	246, 478	C		Jeff Beddow	Microsimulations Res., Minneapolis, MN|c|			Microsimulations Research
Vis	1990	Visualization of irregular multivariate data	10.1109/VISUAL.1990.146388	http://dx.doi.org/10.1109/VISUAL.1990.146388	247	254, 478-9	C		Thomas A. Foley;David A. Lane	Dept. of Comput. Sci., Arizona State Univ., Tempe, AZ, USA|c|;			Arizona State University Tempe##Arizona State University Tempe
Vis	1990	Visualizing a scalar field on an N-dimensional lattice	10.1109/VISUAL.1990.146389	http://dx.doi.org/10.1109/VISUAL.1990.146389	255	262, 479-480	C		Ted Mihalisin;E. Grawlinksi;John Timlin;John Schwegler	Dept. of Phys., Temple Univ., Philadelphia, PA, USA|c|;;;			Temple University##Temple University##Temple University##Temple University
Vis	1990	Ray traced scalar fields with shaded polygonal output	10.1109/VISUAL.1990.146390	http://dx.doi.org/10.1109/VISUAL.1990.146390	263	272, 480-481	C		Ray J. Meyers;Michael B. Stephenson	Sandia Nat. Lab., Albuquerque, NM, USA|c|;			Sandia Nat. Lab., Albuquerque, NM, USA|c|;
Vis	1990	The application of transport theory to visualization of 3D scalar data fields	10.1109/VISUAL.1990.146391	http://dx.doi.org/10.1109/VISUAL.1990.146391	273	280, 481-2	C		Wolfgang Krüger	ART+COM e.V., Berlin, Germany|c|			ART+COM e.V., Berlin, Germany|c|
Vis	1990	Visualization of scalar data defined on a structured grid-applications to petroleum research	10.1109/VISUAL.1990.146392	http://dx.doi.org/10.1109/VISUAL.1990.146392	281	288, 482-3	C		J. L. Pajon;V. Bui Tran	Inst. Francais due Petrole, Rueil Malmaison, France|c|;			Institut Franqais du Pktrole 1##
Vis	1990	A numerical method for rendering spherical reflections	10.1109/VISUAL.1990.146393	http://dx.doi.org/10.1109/VISUAL.1990.146393	289	297, 483-4	C		David P. Dobkin;E. S. Panduranga;M. Zhu	Dept. of Comput. Sci., Princeton Univ., NJ, USA|c|;;			Princeton University Princeton##Princeton University Princeton##Princeton University Princeton
Vis	1990	Superposing images with shadow casting	10.1109/VISUAL.1990.146394	http://dx.doi.org/10.1109/VISUAL.1990.146394	298	306, 484-5	C		Philip C. Hsu;John Staudhammer	Dept. of Electr. Eng., Florida Univ., Gainesville, FL, USA|c|;			University of Florida Gainesville##University of Florida Gainesville
Vis	1990	Automatic illustration of 3D geometric models: surfaces	10.1109/VISUAL.1990.146395	http://dx.doi.org/10.1109/VISUAL.1990.146395	307	314, 485-6	C		Debra Dooley;Michael F. Cohen	Dept. of Comput. Sci., Utah Univ., Salt Lake City, UT, USA|c|;			University of Utah Salt Lake City##University of Utah Salt Lake City
Vis	1990	Scattered data interpolation tools in a microcomputer visualization environment	10.1109/VISUAL.1990.146396	http://dx.doi.org/10.1109/VISUAL.1990.146396	315	322	C		Keith Voegele	Dept. of Comput. Sci., Arizona State Univ., Tempe, AZ, USA|c|			Arizona State University Tempe
Vis	1990	Design of an end-user data visualization system	10.1109/VISUAL.1990.146397	http://dx.doi.org/10.1109/VISUAL.1990.146397	323	328, 487	C		Donald L. Brittain;Josh Aller;Michael Wilson;Sue-Ling C. Wang	Wavefront Technol. Inc., Santa Barbara, CA, USA|c|;;;			Wavefront Technologies##Wavefront Technologies##Wavefront Technologies##Wavefront Technologies
Vis	1990	A system for three-dimensional acoustic 'visualization' in a virtual environment workstation	10.1109/VISUAL.1990.146398	http://dx.doi.org/10.1109/VISUAL.1990.146398	329	337	C		Elizabeth M. Wenzel;Scott S. Fisher;Philip K. Stone;Scott H. Foster	NASA Ames Res. Center, Moffett Field, CA, USA|c|;;;			NASA-Ames Research Center##NASA-Ames Research Center
Vis	1990	An interpersonal multimedia visualization system	10.1109/VISUAL.1990.146399	http://dx.doi.org/10.1109/VISUAL.1990.146399	338	341	C		Richard L. Phillips	Los Alamos Nat. Lab., NM, USA|c|			Los Alamos Nat. Lab., NM, USA|c|
Vis	1990	Techniques for visualizing 3-dimensional manifolds	10.1109/VISUAL.1990.146400	http://dx.doi.org/10.1109/VISUAL.1990.146400	342	352, 487-8	C		Michael J. Laszlo	Dept. of Electr. Eng. & Comput. Sci., Illinois Univ., Chicago, IL, USA|c|			University of Illinois at Chicago
Vis	1990	Accurate display of tensor product isosurfaces	10.1109/VISUAL.1990.146401	http://dx.doi.org/10.1109/VISUAL.1990.146401	353	360, 489	C		Alyn P. Rockwood	Silicon Graphics Comput. Syst., Mountain View, CA, USA|c|			Silicon Graphics Comput. Syst., Mountain View, CA, USA|c|
Vis	1990	Parallel coordinates: a tool for visualizing multi-dimensional geometry	10.1109/VISUAL.1990.146402	http://dx.doi.org/10.1109/VISUAL.1990.146402	361	378	C		Alfred Inselberg;Bernard Dimsdale	IBM Sci. Center, Los Angeles, CA, USA|c|;			IBM Scientific Center &####IBM Scientific Center &##Wilshire Boulevard University of Southern California Los Angeles
Vis	1990	Visualization of free form volumes	10.1109/VISUAL.1990.146403	http://dx.doi.org/10.1109/VISUAL.1990.146403	379	386	C		Dieter Lasser	Fachbereich Inf., Kaiserslautern Univ., Germany|c|			Universitat Kaiserslaut-ern
Vis	1990	Visualization for nonlinear engineering FEM analysis in manufacturing	10.1109/VISUAL.1990.146412	http://dx.doi.org/10.1109/VISUAL.1990.146412	422	423, 490	C		Gerald W. Edgar	Boeing Comput. Services, Seattle, WA, USA|c|			Boeing Computer Services Seattle
Vis	1990	Volume microscopy of biological specimens based on non-confocal imaging techniques	10.1109/VISUAL.1990.146413	http://dx.doi.org/10.1109/VISUAL.1990.146413	424	428	C		Stephen L. Senft;Vincent J. Argio;William L. van Zandt	Washington Univ. Sch. of Med., St. Louis, MO, USA|c|;;			Washington University School of Medicine
Vis	1990	Visualization for the information age	10.1109/VISUAL.1990.146414	http://dx.doi.org/10.1109/VISUAL.1990.146414	429		C		Laurin Herr	Pacific Interface, New York, NY, USA|c|			Pacific Interface, New York, NY, USA|c|
Vis	1990	Case study in scientific visualization: factors inducing periodic breathing in humans with blunted hypoxic sensitivity	10.1109/VISUAL.1990.146415	http://dx.doi.org/10.1109/VISUAL.1990.146415	430	434	C		Wayne E. Fordyce;Jeffrey Ventrella	Res. Comput. Services, Syracuse Univ., NY, USA|c|;			Research Computing Services 120 Hinds Hall Syracuse University Syracuse##Research Computing Services 120 Hinds Hall Syracuse University Syracuse##Research Computing Services 120 Hinds Hall Syracuse University Syracuse
Vis	1990	Interactive investigation of fluid mechanics data sets	10.1109/VISUAL.1990.146416	http://dx.doi.org/10.1109/VISUAL.1990.146416	435	439, 490	C		Steve M. Legensky				
Vis	1990	Real-world applications of visualization solutions	10.1109/VISUAL.1990.146417	http://dx.doi.org/10.1109/VISUAL.1990.146417	440	442	C		David A. Prawel	Precision Visuals Inc., Boulder, CO, USA|c|			Precision Visuals, Inc
Vis	1990	Personal visualization system: applications in research and engineering	10.1109/VISUAL.1990.146418	http://dx.doi.org/10.1109/VISUAL.1990.146418	443	448, 490-1	C		Quentin E. Dolecek;K. Moorjani;B. F. Kim;D. G. Tilley;Thomas S. Denney Jr.	Appl. Phys. Lab., Johns Hopkins Univ., Laurel, MD, USA|c|;;;;			Johns Hopkins University##Johns Hopkins University##Johns Hopkins University##Johns Hopkins University##Johns Hopkins University
Vis	1990	A graphical interface for robotic remediation of underground storage tanks	10.1109/VISUAL.1990.146419	http://dx.doi.org/10.1109/VISUAL.1990.146419	449	456	C		Brian K. Christensen;Lisa M. Desjarlais	Sandia Nat. Lab., Albuquerque, NM, USA|c|;			University of New##University of New
Vis	1991	Scientific visualization from inside the metacomputer	10.1109/VISUAL.1991.175767	http://dx.doi.org/10.1109/VISUAL.1991.175767	2		M		Larry L. Smarr	Nato Centre for Supercomput. Appls., Champaign, IL, USA|c|			Nato Centre for Supercomput. Appls., Champaign, IL, USA|c|
Vis	1991	Visualizing causal effects in 4D space-time vector fields	10.1109/VISUAL.1991.175770	http://dx.doi.org/10.1109/VISUAL.1991.175770	12	16, 406	C		Deborah Silver;M. Gao;Norman J. Zabusky	Rutgers Univ., Piscataway, NJ, USA|c|;;			Rutgers University Piscataway##Rutgers University Piscataway
Vis	1991	The virtual windtunnel: An environment for the exploration of three-dimensional unsteady flows	10.1109/VISUAL.1991.175771	http://dx.doi.org/10.1109/VISUAL.1991.175771	17	24, 407	C		Steve Bryson;Creon Levit	NASA Ames Res. Center, Moffett Field, CA, USA|c|;			NASA Ames Res. Center, Moffett Field, CA, USA|c|;
Vis	1991	Volume rendering of flow-visualization point data	10.1109/VISUAL.1991.175772	http://dx.doi.org/10.1109/VISUAL.1991.175772	25	32	C		Paul Gene Swann;Sudhanshu Kumar Semwal	Dept. of Comput. Sci., Colorado Univ., Colorado Springs, CO, USA|c|;			University of Colorado Colorado Springs##University of Colorado Colorado Springs
Vis	1991	A tool for visualizing the topology of three-dimensional vector fields	10.1109/VISUAL.1991.175773	http://dx.doi.org/10.1109/VISUAL.1991.175773	33	40, 408	C		Al Globus;Creon Levit;T. Lasinski	;;	10.1109/VISUAL.1990.146360;10.1109/VISUAL.1990.146359		Computer Sciences Corporation1 C. Levit
Vis	1991	Two widely-different architectural approaches to computer image generation	10.1109/VISUAL.1991.175776	http://dx.doi.org/10.1109/VISUAL.1991.175776	42	49	C		H. W. Park;K. S. Eo;D. L. Kim;B. K. Choi;Yongmin Kim 0001;T. Alexander	Dept. of Electr. Eng., Washington Univ., Seattle, WA, USA|c|;;;;;			Samsung Advanced Institute of Technology####Samsung Advanced Institute of Technology######University of Washington Seattle
Vis	1991	Fast rotation of volume data on parallel architectures	10.1109/VISUAL.1991.175777	http://dx.doi.org/10.1109/VISUAL.1991.175777	50	57, 409	C		Peter Schröder;James B. Salem	Thinking Machines Corp., Cambridge, MA, USA|c|;			Thinking Machines Corporation##Thinking Machines Corporation
Vis	1991	Achieving direct volume visualization with interactive semantic region selection	10.1109/VISUAL.1991.175778	http://dx.doi.org/10.1109/VISUAL.1991.175778	58	65, 410	C		Terry S. Yoo;Ulrich Neumann;Henry Fuchs;Stephen M. Pizer;Tim J. Cullip;John Rhoades;Ross T. Whitaker	North Carolina Univ., Chapel Hill, NC, USA|c|;;;;;;			University of North Carolina Chapel Hill##University of North Carolina Chapel Hill##University of North Carolina Chapel Hill##University of North Carolina Chapel Hill##University of North Carolina Chapel Hill##University of North Carolina Chapel Hill##University of North Carolina Chapel Hill
Vis	1991	Span filtering: an optimization scheme for volume visualization of large finite element models	10.1109/VISUAL.1991.175780	http://dx.doi.org/10.1109/VISUAL.1991.175780	68	75, 411	C		Richard S. Gallagher	Swanson Analysis Systems Inc., Houston, PA, USA|c|	10.1109/VISUAL.1990.146390		Swanson Analysis Systems, Inc. Houston
Vis	1991	Visualization of equations in an interactive environment	10.1109/VISUAL.1991.175781	http://dx.doi.org/10.1109/VISUAL.1991.175781	76	82, 412	C		David Watson;Jakub Wejchert;David W. Williams;Bri M. Collins	IBM European Visualization Centre, Winchester, UK|c|;;;	10.1109/VISUAL.1990.146401		IBM European Visualization Centre IBM UIi Scientific Centre Winchester##IBM European Visualization Centre IBM UIi Scientific Centre Winchester##IBM European Visualization Centre IBM UIi Scientific Centre Winchester##IBM European Visualization Centre IBM UIi Scientific Centre Winchester
Vis	1991	The asymptotic decider: resolving the ambiguity in marching cubes	10.1109/VISUAL.1991.175782	http://dx.doi.org/10.1109/VISUAL.1991.175782	83	91, 413	C		Gregory M. Nielson;Bernd Hamann	Dept. of Comput. Sci., Arizona State Univ., Tempe, AZ, USA|c|;	10.1109/VISUAL.1990.146363		Arizona State University Tempe##Arizona State University Tempe
Vis	1991	Acoustic imaging: the reconstruction of underwater objects	10.1109/VISUAL.1991.175784	http://dx.doi.org/10.1109/VISUAL.1991.175784	94	101, 414	C		Lawrence J. Rosenblum;Behzad Kamgar-Parsi;Edward O. Belcher;Ola Engelsen	US Naval Res. Lab., Washington, DC, USA|c|;;;			University of Washington######
Vis	1991	Computer assisted sphere packing in higher dimensions	10.1109/VISUAL.1991.175785	http://dx.doi.org/10.1109/VISUAL.1991.175785	102	108	C		Nelson L. Max	California Univ., Davis, CA, USA|c|			University of California
Vis	1991	The electronic structure of oxygen in silicon as revealed by volume visualization of Ab initio calculations	10.1109/VISUAL.1991.175786	http://dx.doi.org/10.1109/VISUAL.1991.175786	109	115, 415	C		Robert H. Wolfe;Mark Needels;John D. Joannopoulos	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;			T. J. Watson Res. Ctr. MIT Yorktown Heights##T. J. Watson Res. Ctr. MIT Yorktown Heights##T. J. Watson Res. Ctr. MIT Yorktown Heights##T. J. Watson Res. Ctr. MIT Yorktown Heights##T. J. Watson Res. Ctr. MIT Yorktown Heights##T. J. Watson Res. Ctr. MIT Yorktown Heights
Vis	1991	Golf green visualization	10.1109/VISUAL.1991.175787	http://dx.doi.org/10.1109/VISUAL.1991.175787	116	123, 416	C		William E. Lorensen;Boris Yamron	General Electric Co., Schenectady, NY, USA|c|;			General Electric Company Corporate Research and Development Schenectady##General Electric Company Corporate Research and Development Schenectady
Vis	1991	The stream polygon: A technique for 3D vector field visualization	10.1109/VISUAL.1991.175789	http://dx.doi.org/10.1109/VISUAL.1991.175789	126	132, 417	C		William J. Schroeder;Christopher R. Volpe;William E. Lorensen	General Electric Corp. Res. & Dev., Schenectady, NY, USA|c|;;			General Electric Corp. Res. & Dev., Schenectady, NY, USA|c|;;
Vis	1991	The hyperbox	10.1109/VISUAL.1991.175790	http://dx.doi.org/10.1109/VISUAL.1991.175790	133	139, 418	C		Bowen Alpern;Larry Carter	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;	10.1109/VISUAL.1990.146386;10.1109/VISUAL.1990.146402;10.1109/VISUAL.1990.146387;10.1109/VISUAL.1990.146389		IBM Watson Research Ceder##IBM Watson Research Ceder
Vis	1991	Gray scale diagrams as business charts	10.1109/VISUAL.1991.175791	http://dx.doi.org/10.1109/VISUAL.1991.175791	140	147	C		W. R. Feeney	Dept. of Inf. & Decisions Syst., San Diego State Univ., San Diego, CA, USA|c|			San Diego State University
Vis	1991	Shadowed hedgehogs: a technique for visualizing 2D slices of 3D vector fields	10.1109/VISUAL.1991.175792	http://dx.doi.org/10.1109/VISUAL.1991.175792	148	153	C		R. Victor Klassen;Steven J. Harrington	Xerox Webster Res. Center, Webster, NY, USA|c|;			SOO Phillips Rd##SOO Phillips Rd
Vis	1991	Interactive data visualization using focusing and linking	10.1109/VISUAL.1991.175794	http://dx.doi.org/10.1109/VISUAL.1991.175794	156	163, 419	C		Andreas Buja;John Alan McDonald;J. Michalak;Werner Stuetzle	Bellcore, Morristown, NJ, USA|c|;;;			U. of Washington Morristown##U. of Washington Morristown##U. of Washington Morristown##U. of Washington Morristown
Vis	1991	Color icons: merging color and texture perception for integrated visualization of multiple parameters	10.1109/VISUAL.1991.175795	http://dx.doi.org/10.1109/VISUAL.1991.175795	164	170, 420	C		Haim Levkowitz	Dept. of Comput. Sci., Lowell Univ., MA|c|			University of Lowell Lowell
Vis	1991	Visualization and analysis of multi-variate data: a technique for all fields	10.1109/VISUAL.1991.175796	http://dx.doi.org/10.1109/VISUAL.1991.175796	171	178, 421	C		Ted Mihalisin;John Timlin;John Schwegler	Mihalisin Associates, Ambler, PA, USA|c|;;			Mihalisin Associates, Ambler, PA, USA|c|;;
Vis	1991	The visual comparison of three sequences	10.1109/VISUAL.1991.175797	http://dx.doi.org/10.1109/VISUAL.1991.175797	179	186	C		Kenneth P. Hinkley;Matthew O. Ward	Dept. of Comput. Sci., Worchester Polytech. Inst., MA, USA|c|;			Worcester Polytechnic Inst. Worcester
Vis	1991	Enhanced visualization of multi-dimensional structures. Applications in positron emission tomography and climate data	10.1109/VISUAL.1991.175799	http://dx.doi.org/10.1109/VISUAL.1991.175799	188	193, 422	C		Nahum D. Gershon	Mitre Corp., McLean, VA, USA|c|			The MITRE Corporation McLean
Vis	1991	Topographical mapping of brain electrical activity	10.1109/VISUAL.1991.175800	http://dx.doi.org/10.1109/VISUAL.1991.175800	194	201	C		S. K. Law;P. L. Nunez;A. F. Westdorp;A. V. Nelson;K. L. Pilgreen	Dept. of Biomed. Eng., Tulane Univ., New Orleans, LA, USA|c|;;;;			Tulane University##LCS
Vis	1991	In vivo blood flow visualization with magnetic resonance imaging	10.1109/VISUAL.1991.175801	http://dx.doi.org/10.1109/VISUAL.1991.175801	202	209, 423	C		Guang-Zhong Yang;Peter Burger;Philip J. Kilner;Raad Mohiaddin	Dept. of Comput., Imperial Coll., London Univ., UK|c|;;;			London University##London University##London University##London University##London University##London University
Vis	1991	Visualizing 4-D medical ultrasound data	10.1109/VISUAL.1991.175802	http://dx.doi.org/10.1109/VISUAL.1991.175802	210	215	C		Nils Thune;Bjørn Olstad	Dept. of Sci. & Technol., Christian Michelsen Inst., Fantoft, Norway|c|;			Dept. of Sci. & Technol., Christian Michelsen Inst., Fantoft, Norway|c|;
Vis	1991	Multi-valued volumetric visualization	10.1109/VISUAL.1991.175804	http://dx.doi.org/10.1109/VISUAL.1991.175804	218	225, 424	C		Thomas A. Foley;David A. Lane	Dept. of Comput. Sci., Arizona State Univ., Tempe, AZ, USA|c|;	10.1109/VISUAL.1990.146388;10.1109/VISUAL.1990.146373;10.1109/VISUAL.1990.146362;10.1109/VISUAL.1991.175782;10.1109/VISUAL.1990.146363		Arizona State University Tempe
Vis	1991	Realistic volume imaging	10.1109/VISUAL.1991.175805	http://dx.doi.org/10.1109/VISUAL.1991.175805	226	231, 425	C		Roni Yagel;Arie E. Kaufman;Qiang Zhang	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;			State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook
Vis	1991	A fast ray tracing casting algorithm using adaptive isotriangular subdivision	10.1109/VISUAL.1991.175806	http://dx.doi.org/10.1109/VISUAL.1991.175806	232	238, 426	C		Renben Shu;Alan Liu	Inst. of Syst. Sci., Nat. Univ. of Singapore, Kent Ridge, Singapore|c|;			National University of Singapore Kent Ridge##National University of Singapore Kent Ridge
Vis	1991	NetV: an experimental network-based volume visualization system	10.1109/VISUAL.1991.175807	http://dx.doi.org/10.1109/VISUAL.1991.175807	239	245	C		T. Todd Elvins;David R. Nadeau	San Diego Supercomput. Center, Adv. Sci. Visualization Lab., CA, USA|c|;	10.1109/VISUAL.1990.146362;10.1109/VISUAL.1990.146397;10.1109/VISUAL.1990.146382;10.1109/VISUAL.1991.175814		San Diego Supercomput. Center, Adv. Sci. Visualization Lab., CA, USA|c|;
Vis	1991	Interactive data exploration with a supercomputer	10.1109/VISUAL.1991.175809	http://dx.doi.org/10.1109/VISUAL.1991.175809	248	254	C		Stuart Smith;Georges G. Grinstein;R. Daniel Bergeron	Dept. of Comput. Sci., Lowell Univ., MA, USA|c|;;			University of Lowell Lowell##University of Lowell Lowell##University of Lowell Lowell
Vis	1991	Run-time visualization of program data	10.1109/VISUAL.1991.175810	http://dx.doi.org/10.1109/VISUAL.1991.175810	255	261	C		Allan Tuchman;David Jablonowski;George Cybenko	Center for Supercomput. Res. & Dev., Illinois Univ., Urbana, IL, USA|c|;;			University of Illinois at Urbana-Champaign Urbana##University of Illinois at Urbana-Champaign Urbana##University of Illinois at Urbana-Champaign Urbana
Vis	1991	A scientific visualization synthesizer	10.1109/VISUAL.1991.175811	http://dx.doi.org/10.1109/VISUAL.1991.175811	262	267	C		Roger Crawfis;M. J. Allison	Lawrence Livermore Nat. Lab., CA, USA|c|;			Lawrence Livermore National Laboratory Livermore##Lawrence Livermore National Laboratory Livermore
Vis	1991	Integration of visualization and scientific calculation in a software system	10.1109/VISUAL.1991.175812	http://dx.doi.org/10.1109/VISUAL.1991.175812	268	274, 428	C		Ulrich Lang;Ruth E. Lang;Roland Rühle	Stuttgart Univ. Comput. Center, Germany|c|;;			University of Stuttgart Computer Center##University of Stuttgart Computer Center##University of Stuttgart Computer Center
Vis	1991	Image handling in a multi-vendor environment	10.1109/VISUAL.1991.175814	http://dx.doi.org/10.1109/VISUAL.1991.175814	276	283	C		David R. Nadeau;T. Todd Elvins;Michael J. Bailey	San Diego Supercomput. Center, CA, USA|c|;;	10.1109/VISUAL.1991.175807		San Diego Supercomput. Center, CA, USA|c|;;
Vis	1991	Tree-maps: a space-filling approach to the visualization of hierarchical information structures	10.1109/VISUAL.1991.175815	http://dx.doi.org/10.1109/VISUAL.1991.175815	284	291	C		Brian Johnson;Ben Shneiderman	Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA|c|;			Laboratory University of Maryland##Laboratory University of Maryland##Laboratory University of Maryland
Vis	1991	How shall we connect our software tools?	10.1109/VISUAL.1991.175816	http://dx.doi.org/10.1109/VISUAL.1991.175816	292	296	C		Eric Grosse	AT&T Bell Lab., Murray Hill, NJ, USA|c|			AT&T Bell Laboratories Murray Hill
Vis	1991	A data model for scientific visualization with provisions for regular and irregular grids	10.1109/VISUAL.1991.175818	http://dx.doi.org/10.1109/VISUAL.1991.175818	298	305	C		Robert B. Haber;Bruce Lucas;Nancy S. Collins	Dept. of Theor. & Appl. Mech., Illinois Univ., Urbana, IL, USA|c|;;			Dept. of Theor. & Appl. Mech., Illinois Univ., Urbana, IL, USA|c|;;
Vis	1991	Cooperative, computer-aided design of scientific visualizations	10.1109/VISUAL.1991.175819	http://dx.doi.org/10.1109/VISUAL.1991.175819	306	313, 430	C		Sandeep Kochhar;Mark Friedell;Mark Vincent LaPolla	Harvard Univ., Cambridge, MA, USA|c|;;		Grammar-directed design, cooperative design and modeling, design automation, human-computer interaction, automated design of graphical displays	Harvard University##Harvard University##Harvard University
Vis	1991	Deixis and the future of visualization excellence	10.1109/VISUAL.1991.175820	http://dx.doi.org/10.1109/VISUAL.1991.175820	314	320, 431	C		William C. Hill;James D. Hollan	;			
Vis	1991	Visualizing the fourth dimension using geometry and light	10.1109/VISUAL.1991.175821	http://dx.doi.org/10.1109/VISUAL.1991.175821	321	328, 432	C		Andrew J. Hanson;Pheng-Ann Heng	Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA|c|;	10.1109/VISUAL.1990.146370		Indiana University Bloomington##Indiana University Bloomington
Vis	1991	Applying 3D visualization techniques to finite element analysis	10.1109/VISUAL.1991.175823	http://dx.doi.org/10.1109/VISUAL.1991.175823	330	335	M		Richard S. Gallagher;Robert B. Haber;Gordon Ferguson;David Parker;Douglas W. Stillman;James Winget	;;;;;			
Vis	1991	Color vs. black-and-white in visualization	10.1109/VISUAL.1991.175824	http://dx.doi.org/10.1109/VISUAL.1991.175824	336	339	M		Haim Levkowitz;Richard A. Holub;Gary W. Meyer;Philip K. Robertson	Inst. for Visualization & Perception Res., Lowell Univ., MA, USA|c|;;;			Inst. for Visualization & Perception Res., Lowell Univ., MA, USA|c|;;;
Vis	1991	Remote visualization: challenges and opportunities	10.1109/VISUAL.1991.175825	http://dx.doi.org/10.1109/VISUAL.1991.175825	340	344	M		Guru M. Parulkar;Jack Bowie;Hans-Werner Braun;Roch Guerin;Daniel Stevenson	Washington Univ., St. Louis, WA|c|;;;;			Washington Univ., St. Louis, WA|c|;;;;
Vis	1991	How visualization applications drive tool selection: one product can't do it all	10.1109/VISUAL.1991.175826	http://dx.doi.org/10.1109/VISUAL.1991.175826	345	347	M		D. Prawel;M. Brown;C. Harris;R. Kriz;M. Vigil	;;;;			
Vis	1991	Multimedia environments for scientists	10.1109/VISUAL.1991.175827	http://dx.doi.org/10.1109/VISUAL.1991.175827	348	353	M		Meera M. Blattner;Georges Grinstein;Ephraim P. Glinert;William Hill;Creon Levit;Stuart Smith	;;;;;			
Vis	1991	Volume visualization comes of age: the state of the art in technology and application	10.1109/VISUAL.1991.175828	http://dx.doi.org/10.1109/VISUAL.1991.175828	354	357	M		Vincent Argiro;Mary Whitton;Alan Evans;Wulf Massell;Stephen Paddock;Elliot Fishman	;;;;;			
Vis	1991	Visualisation tools for semiconductor modelling software	10.1109/VISUAL.1991.175830	http://dx.doi.org/10.1109/VISUAL.1991.175830	360	363, 433	C		Duncan Stevenson	CSIRO, Canberra, ACT, Australia|c|			CSIRO Division of Information Technology GPO
Vis	1991	Visualizing chemical kinetics in fractal domains	10.1109/VISUAL.1991.175831	http://dx.doi.org/10.1109/VISUAL.1991.175831	364	367, 434	C		Neal E. Hurlburt;Lola W. Anacker;Raoul Kopelman	Lockheed Palo Alto Res. Lab., CA, USA|c|;;			NASA Ames Chemistry##NASA Ames Chemistry##NASA Ames Chemistry
Vis	1991	Multidimensional real time visualization on personal computers	10.1109/VISUAL.1991.175832	http://dx.doi.org/10.1109/VISUAL.1991.175832	368	371	C		Quentin E. Dolecek	Johns Hopkins Univ., Laurel, MD, USA|c|			Johns Hopkins University Laurel
Vis	1991	Advanced visualization on desktop workstations	10.1109/VISUAL.1991.175833	http://dx.doi.org/10.1109/VISUAL.1991.175833	372	378, 435	C		Steve M. Legensky	Intelligent Light, Fair Lawn, NJ, USA|c|			Intelligent Light
Vis	1991	Distributed visualization using workstations, supercomputers, and high speed networks	10.1109/VISUAL.1991.175834	http://dx.doi.org/10.1109/VISUAL.1991.175834	379	382	C		David W. Robertson;V. L. Jacobson;William E. Johnston;S. C. Loken;E. H. Theil;B. L. Tieney	Lawrence Berkeley Lab., California Univ., Berkeley, CA, USA|c|;;;;;			University of California##University of California##University of California##University of California##University of California##University of California
Vis	1991	Designing a distributed scientific visualization tool	10.1109/VISUAL.1991.175835	http://dx.doi.org/10.1109/VISUAL.1991.175835	383	386	C		L. van der Sluis				Technology Applications, Inc
Vis	1991	Experiments with interdisciplinary projects and scientific visualization applications at the undergraduate level	10.1109/VISUAL.1991.175836	http://dx.doi.org/10.1109/VISUAL.1991.175836	387	391	C		Nan C. Schaller	Dept. of Comput. Sci., Rochester Inst. of Technol., NY, USA|c|			Dept. of Comput. Sci., Rochester Inst. of Technol., NY, USA|c|
Vis	1991	Visualization in computational fluid dynamics: a case study	10.1109/VISUAL.1991.175837	http://dx.doi.org/10.1109/VISUAL.1991.175837	392	397, 436	C		Robert Haimes;David L. Darmofal	Dept. of Aeronaut. & Astronaut, MIT, Cambridge, MA, USA|c|;			Massachusetts Institute of Technology##Massachusetts Institute of Technology
Vis	1991	Visualizing environmental data for program decision support	10.1109/VISUAL.1991.175838	http://dx.doi.org/10.1109/VISUAL.1991.175838	398	404	C		J. Burnetti;R. Manley;W. Mitchell;D. Varnadore	Mitre Corp., McLean, VA, USA|c|;;;			Mitre Corp., McLean, VA, USA|c|;;;
Vis	1992	Visualizing a three dimensional hydrodynamic model	10.1109/VISUAL.1992.235173	http://dx.doi.org/10.1109/VISUAL.1992.235173	441	445	C		C. S. Jones;J. A. Baca	USACE Waterways Exp. Station, Vicksburg, MS, USA|c|;			USACE Waterways Exp. Station, Vicksburg, MS, USA|c|;
Vis	1992	Case study: visualizing classical problems in CFD	10.1109/VISUAL.1992.235174	http://dx.doi.org/10.1109/VISUAL.1992.235174	436	440	C		Norman J. Zabusky;Deborah Silver	Rutgers Univ., Piscataway, NJ, USA|c|;	10.1109/VISUAL.1991.175770;10.1109/VISUAL.1991.175773		CAIP Rutgers University Rut gers University Piscataway##CAIP Rutgers University Rut gers University Piscataway
Vis	1992	Visualization requirements in the atmospheric and environmental sciences (five case study reports)	10.1109/VISUAL.1992.235175	http://dx.doi.org/10.1109/VISUAL.1992.235175	428	435	C		Theresa-Marie Rhyne;Mark Bolstad;Penny Rheingans;Lynne Petterson;Walter Shackelford;Mike E. Botts;E. Pepke;K. W. Johnson;William L. Hibbard;Charles R. Dyer;Brian E. Paul;Lloyd Treinish	;;;;;;;;;;;	10.1109/VISUAL.1992.235215		U.S. EPA Scientific Visualization Center NASA Marshall Space Flight Center Florida State University University of Wisconsin at Madison IBM T J. Watson Research Center
Vis	1992	Visualizing seafloor structures with satellite gravity measurements	10.1109/VISUAL.1992.235176	http://dx.doi.org/10.1109/VISUAL.1992.235176	424	427	C		J. McLeod;C. Small	San Diego Supercomput. Center, CA, USA|c|;			San Diego Supercomput. Center, CA, USA|c|;
Vis	1992	The microscopist's workstation	10.1109/VISUAL.1992.235177	http://dx.doi.org/10.1109/VISUAL.1992.235177	419	423	C		Philip J. Mercurio;T. Todd Elvins;Stephen J. Young	San Diego Supercomput. Center, CA, USA|c|;;	10.1109/VISUAL.1991.175807		San Diego Supercomput. Center, CA, USA|c|;;
Vis	1992	Visualization of cardiac bioelectricity-a case study	10.1109/VISUAL.1992.235178	http://dx.doi.org/10.1109/VISUAL.1992.235178	411	418	C		Robert S. MacLeod;N. E. Harrison;Christopher R. Johnson 0001;Michael A. Matheson	Utah Univ., Salt Lake City, UT, USA|c|;;			University of Utah##University of Utah##University of Utah##University of Utah##University of Utah##University of Utah##University of Utah
Vis	1992	Visualization in anthropology: reconstruction of human fossils from multiple pieces	10.1109/VISUAL.1992.235179	http://dx.doi.org/10.1109/VISUAL.1992.235179	404	410	C		Alan D. Kalvin;David Dean;Jean-Jaques Hublin;M. Braun	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;;			The City University of New York######IBM T.J. Watson Research Center
Vis	1992	Visualization of neutron scattering data using AVS	10.1109/VISUAL.1992.235180	http://dx.doi.org/10.1109/VISUAL.1992.235180	398	403	C		R. Popovic	Rutherford Appleton Lab., Didcot, UK|c|	10.1109/VISUAL.1991.175830		Rutherford Appleton Laboratory Chilton
Vis	1992	Visualizing the Universe	10.1109/VISUAL.1992.235181	http://dx.doi.org/10.1109/VISUAL.1992.235181	390	397	C		M. J. Geller;E. E. Flaco;D. G. Fabricant;B. Estus	Harvard-Smithsonian Center for Astrophys., Cambridge, MA, USA|c|;;;			Har var d-Smi t hsonian Cent er for Astrophysics Cambridge##Har var d-Smi t hsonian Cent er for Astrophysics Cambridge##Har var d-Smi t hsonian Cent er for Astrophysics Cambridge##Har var d-Smi t hsonian Cent er for Astrophysics Cambridge
Vis	1992	Object-oriented, dataflow visualization system-a paradigm shift?	10.1109/VISUAL.1992.235182	http://dx.doi.org/10.1109/VISUAL.1992.235182	384	388	M		William Ribarsky;Bob Brown;Terry Myerson;Richard Feldmann;Stuart Smith;Lloyd Treinish	;;;;;			
Vis	1992	Visualization in the neurosciences: utility in research, teaching, and clinical practice	10.1109/VISUAL.1992.235183	http://dx.doi.org/10.1109/VISUAL.1992.235183	380	383	M		Stuart A. Tobet;Joan C. King;Steven L. Wertheim;Frank H. Duffy	E.K. Shriver Center, Harvard Program in Neurosci., Boston, MA, USA|c|;;;			E.K. Shriver Center, Harvard Program in Neurosci., Boston, MA, USA|c|;;;
Vis	1992	Real virtual environment applications-now	10.1109/VISUAL.1992.235184	http://dx.doi.org/10.1109/VISUAL.1992.235184	375	379	M		Paul T. Breen;Georges G. Grinstein;David W. Mizell;Richard M. Satava;Bradford Smith;Michael M. Stephens;David Zeltzer				
Vis	1992	Improving visualization: theoretical and empirical foundations	10.1109/VISUAL.1992.235185	http://dx.doi.org/10.1109/VISUAL.1992.235185	372	374	M		Stephen M. Kosslyn;Nahum D. Gershon;Haim Levkowitz;Justin D. Pearlman	Dept. of Psychol., Harvard Univ., Cambridge, MA, USA|c|;;;			Dept. of Psychol., Harvard Univ., Cambridge, MA, USA|c|;;;
Vis	1992	Grand challenge problems in visualization software	10.1109/VISUAL.1992.235186	http://dx.doi.org/10.1109/VISUAL.1992.235186	366	371	M		Lloyd A. Treinish;David M. Butler;Hikmet Senay;Georges G. Grinstein;Steve T. Bryson	IBM Thomas. J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;;;			IBM Thomas. J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;;;
Vis	1992	Techniques for managing very large scientific databases	10.1109/VISUAL.1992.235187	http://dx.doi.org/10.1109/VISUAL.1992.235187	362	365	M		William J. Campbell;George Fekete;Robert F. Cromp;Ray Wall;Michael Goldberg	;;;;			
Vis	1992	Visualizing n-dimensional implications of two-dimensional design decisions	10.1109/VISUAL.1992.235188	http://dx.doi.org/10.1109/VISUAL.1992.235188	356	360	C		Stephen M. Ervin	Dept. of Landscape Archit., Harvard Univ., Graduate Sch. of Design, Cambridge, MA, USA|c|			Harvard University
Vis	1992	Interactive terrain rendering and volume visualization on the Princeton Engine	10.1109/VISUAL.1992.235189	http://dx.doi.org/10.1109/VISUAL.1992.235189	349	355	C		James T. Kaba;J. Matey;Gordon Stoll;Herb Taylor;Pat Hanrahan	David Sarnoff Res. Center, Princeton, NJ, USA|c|;;;;	10.1109/VISUAL.1991.175778;10.1109/VISUAL.1991.175777;10.1109/VISUAL.1991.175805		Princeton University##Princeton University##Princeton University##Princeton University##Princeton University
Vis	1992	A voxel-based, forward projection algorithm for rendering surface and volumetric data	10.1109/VISUAL.1992.235190	http://dx.doi.org/10.1109/VISUAL.1992.235190	340	348	C		John R. Wright;Julia C. Hsieh	Hughes Training Inc., West Covina, CA, USA|c|;			Hughes Training, Inc. West Covina##Hughes Training, Inc. West Covina
Vis	1992	Optimizing triangulations by curvature equalization	10.1109/VISUAL.1992.235191	http://dx.doi.org/10.1109/VISUAL.1992.235191	333	339	C		Lori L. Scarlatos;Theodosios Pavlidis	Grumman Data Systems, Woodbury, NY, USA|c|;			Grumman Data Systems, Woodbury, NY, USA|c|;
Vis	1992	Visualization of high resolution, three-dimensional, nonlinear finite element analyses	10.1109/VISUAL.1992.235192	http://dx.doi.org/10.1109/VISUAL.1992.235192	324	331	C		Mark A. Christon;T. Spelce	Lawrence Livermore Nat. Lab., CA, USA|c|;			Lawrence Livermore National Laboratory##Lawrence Livermore National Laboratory
Vis	1992	Visualization of second order tensor fields and matrix data	10.1109/VISUAL.1992.235193	http://dx.doi.org/10.1109/VISUAL.1992.235193	316	323	C		Thierry Delmarcelle;Lambertus Hesselink	Stanford Univ., CA, USA|c|;	10.1109/VISUAL.1990.146373;10.1109/VISUAL.1990.146359;10.1109/VISUAL.1991.175789;10.1109/VISUAL.1991.175773		Stanford University Stanford
Vis	1992	Volume warping	10.1109/VISUAL.1992.235194	http://dx.doi.org/10.1109/VISUAL.1992.235194	308	315	C		T. J. True;J. F. Hughes	Digital Equipment Corp., Maynard, MA, USA|c|;			Digital Equipment Corporation Maynard
Vis	1992	Network video device control	10.1109/VISUAL.1992.235195	http://dx.doi.org/10.1109/VISUAL.1992.235195	299	306	C		David R. Nadeau;Michael J. Bailey	Adv. Sci. Visualization Lab., San Diego, CA, USA|c|;	10.1109/VISUAL.1991.175814		Adv. Sci. Visualization Lab., San Diego, CA, USA|c|;
Vis	1992	Virtual spacetime: an environment for the visualization of curved spacetimes via geodesic flows	10.1109/VISUAL.1992.235196	http://dx.doi.org/10.1109/VISUAL.1992.235196	291	298	C		Steve Bryson	NASA Ames Res. Center, Moffett Field, CA, USA|c|	10.1109/VISUAL.1991.175771		NASA Ames Res. Center, Moffett Field, CA, USA|c|
Vis	1992	Automated design of virtual worlds for visualizing multivariate relations	10.1109/VISUAL.1992.235197	http://dx.doi.org/10.1109/VISUAL.1992.235197	283	290	C		Clifford Beshers;Steven K. Feiner	Dept. of Comput. Sci., Columbia Univ., New York, NY, USA|c|;	10.1109/VISUAL.1991.175819		Columbia University New York##Columbia University New York
Vis	1992	Visualization for the document space	10.1109/VISUAL.1992.235198	http://dx.doi.org/10.1109/VISUAL.1992.235198	274	281	C		X. Lin	Center for Comput. Legal Res., Pace Univ., White Plains, NY, USA|c|			Center for Computerized Legal Research Pace University White Plains
Vis	1992	Visualization of fuzzy data using generalized animation	10.1109/VISUAL.1992.235199	http://dx.doi.org/10.1109/VISUAL.1992.235199	268	273	C		Nahum D. Gershon	Mitre Corp., McLean, VA, USA|c|			The MITRE Corporation
Vis	1992	Surface curvature analysis using color	10.1109/VISUAL.1992.235200	http://dx.doi.org/10.1109/VISUAL.1992.235200	260	267	C		L. R. Seidenberg;Robert B. Jerard;J. Megewick	Dept. of Mech. Eng., New Hampshire Univ., Durham, NH, USA|c|;;			University of New Hampshire##University of New Hampshire##University of New Hampshire##University of New Hampshire
Vis	1992	Color, change, and control of quantitative data display	10.1109/VISUAL.1992.235201	http://dx.doi.org/10.1109/VISUAL.1992.235201	252	259	C		Penny Rheingans	Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|	10.1109/VISUAL.1990.146383		University of North Carolina Chapel Hill
Vis	1992	SuperGlue: a programming environment for scientific visualization	10.1109/VISUAL.1992.235202	http://dx.doi.org/10.1109/VISUAL.1992.235202	243	250	C		Jeff P. Hultquist;E. L. Raible	NASA Ames Res. Center, Moffett Field, CA, USA|c|;	10.1109/VISUAL.1991.175771;10.1109/VISUAL.1990.146360;10.1109/VISUAL.1992.235211		NASA Ames Res. Center, Moffett Field, CA, USA|c|;
Vis	1992	A characterization of the scientific data analysis process	10.1109/VISUAL.1992.235203	http://dx.doi.org/10.1109/VISUAL.1992.235203	235	242	C		R. R. Springmeyer;Meera Blattner;Nelson L. Max	Lawrence Livermore Nat. Lab., CA, USA|c|;;	10.1109/VISUAL.1990.146399		Lawrence Livermore National Laboratory##Lawrence Livermore National Laboratory##Lawrence Livermore National Laboratory
Vis	1992	A scientific visualization renderer	10.1109/VISUAL.1992.235204	http://dx.doi.org/10.1109/VISUAL.1992.235204	227	234	C		Bruce Lucas	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|	10.1109/VISUAL.1992.235219;10.1109/VISUAL.1991.175818		IBM T . J . Watson Research Center
Vis	1992	VISAGE: an object-oriented scientific visualization system	10.1109/VISUAL.1992.235205	http://dx.doi.org/10.1109/VISUAL.1992.235205	219	226	C		William J. Schroeder;William E. Lorensen;G. D. Montanaro;Christopher R. Volpe	GE Corp. Res. & Dev., Schenectady, NY, USA|c|;;;	10.1109/VISUAL.1991.175787;10.1109/VISUAL.1991.175789;10.1109/VISUAL.1990.146360		GE Corp. Res. & Dev., Schenectady, NY, USA|c|;;;
Vis	1992	Visualizing code profiling line oriented statistics	10.1109/VISUAL.1992.235206	http://dx.doi.org/10.1109/VISUAL.1992.235206	210	217	C		Stephen G. Eick;Joseph L. Steffen	AT&T Bell Lab., Murray Hill, NJ, USA|c|;			AT&T Bell Lab., Murray Hill, NJ, USA|c|;
Vis	1992	The state of the art of visual languages for visualization	10.1109/VISUAL.1992.235207	http://dx.doi.org/10.1109/VISUAL.1992.235207	202	209	C		Carla S. Williams;John Rasure;C. Hansen	Dept. of Electr. & Comput. Eng., New Mexico Univ., Albuquerque, NM, USA|c|;;	10.1109/VISUAL.1992.235219		University of New Mexico Albuquerque##University of New Mexico Albuquerque
Vis	1992	Visual query specification in a multimedia database system	10.1109/VISUAL.1992.235208	http://dx.doi.org/10.1109/VISUAL.1992.235208	194	201	C		Daniel A. Keim;Vincent Y. Lum	Inst. fuer Inf., Munchen Univ., Germany|c|;		Visual Query Specijication, Graphical User Interface, Multimedia Database System, Natural-Language Interface, Information Retrieval, Image Data Management	Universitiit Munchen Leopoldstr
Vis	1992	Logical time in visualizations produced by parallel programs	10.1109/VISUAL.1992.235209	http://dx.doi.org/10.1109/VISUAL.1992.235209	186	193	C		Janice E. Cuny;Alfred Hough;Joydip Kunda	Dept. of Comput. Sci., Massachusetts Univ., Amherst, MA, USA|c|;;			University of Massachusetts##University of Massachusetts##University of Massachusetts
Vis	1992	Visualizing wind velocities by advecting cloud textures	10.1109/VISUAL.1992.235210	http://dx.doi.org/10.1109/VISUAL.1992.235210	179	184	C		Nelson L. Max;Roger Crawfis;Dean Williams	Lawrence Livermore Nat. Lab., CA, USA|c|;;	10.1109/VISUAL.1991.175773	advection, 3-D texture, volume visualization, vectorfield, wind, clouds, climate modeling	Lawrence Livennore National Laboratory Livermore##Lawrence Livennore National Laboratory Livermore##Lawrence Livennore National Laboratory Livermore
Vis	1992	Constructing stream surfaces in steady 3D vector fields	10.1109/VISUAL.1992.235211	http://dx.doi.org/10.1109/VISUAL.1992.235211	171	178	C		Jeff P. Hultquist	NASA Ames Res. Center, Moffett Field, CA, USA|c|	10.1109/VISUAL.1990.146359;10.1109/VISUAL.1991.175837;10.1109/VISUAL.1990.146373;10.1109/VISUAL.1992.235202;10.1109/VISUAL.1991.175789		NASA Ames Res. Center, Moffett Field, CA, USA|c|
Vis	1992	Flow visualization as a basic tool to investigate the dynamics and topology of jets	10.1109/VISUAL.1992.235212	http://dx.doi.org/10.1109/VISUAL.1992.235212	164	170	C		Fernando Grinstein;Upul Obeysekare;Gopal Patnaik	US Naval Res. Lab., Washington, DC, USA|c|;;			Naval Research Laboratory####
Vis	1992	Visualization of simulated airflow in a clean room	10.1109/VISUAL.1992.235213	http://dx.doi.org/10.1109/VISUAL.1992.235213	156	163	C		K. Koyamada	Tokyo Res. Lab., Japan|c|	10.1109/VISUAL.1991.175771		IBM Japan Ltd
Vis	1992	Representing medical images with partitioning trees	10.1109/VISUAL.1992.235214	http://dx.doi.org/10.1109/VISUAL.1992.235214	147	154	C		Kalpathi R. Subramanian;Bruce F. Naylor	AT&T Bell Lab., Murray Hill, NJ, USA|c|;	10.1109/VISUAL.1990.146377		AT&T Bell Laboratories Murray Hill##AT&T Bell Laboratories Murray Hill
Vis	1992	Display of scientific data structures for algorithm visualization	10.1109/VISUAL.1992.235215	http://dx.doi.org/10.1109/VISUAL.1992.235215	139	146	C		William L. Hibbard;Charles R. Dyer;Brian E. Paul	Wisconsin Univ., Madison, WI, USA|c|;;			University of Wisconsin-Madison##University of Wisconsin-Madison##University of Wisconsin-Madison
Vis	1992	An efficient range search algorithm for visualizing extrema of volume data	10.1109/VISUAL.1992.235216	http://dx.doi.org/10.1109/VISUAL.1992.235216	132	138	C		Xiaolin Wu;Yonggang Fang	Dept. of Comput. Sci., Western Ontario Univ., London, Ont., Canada|c|;		Visualization of volume data, multidimensional range search, computational geometry, algorithms, data structures, expected time complexity, nearest common ancestor	University of Western Ontario London
Vis	1992	Improving the visualization of hierarchies with treemaps: design issues and experimentation	10.1109/VISUAL.1992.235217	http://dx.doi.org/10.1109/VISUAL.1992.235217	124	131	C		David Turo;B. Johnson	Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA|c|;	10.1109/VISUAL.1991.175796;10.1109/VISUAL.1991.175791;10.1109/VISUAL.1991.175815;10.1109/VISUAL.1991.175794		Laboratory University of Maryland##Laboratory University of Maryland
Vis	1992	Anatomical atlases based on volume visualization	10.1109/VISUAL.1992.235218	http://dx.doi.org/10.1109/VISUAL.1992.235218	115	122	C		Karl Heinz Höhne;Andreas Pommert;Martin Riemer;Thomas Schiemann;Rainer Schubert;Ulf Tiede;Werner Lierse	;;;;;;			University Hospital Eppendorf##University Hospital Eppendorf##University Hospital Eppendorf##University Hospital Eppendorf##University Hospital Eppendorf##University Hospital Eppendorf##University Hospital Eppendorf
Vis	1992	An architecture for a scientific visualization system	10.1109/VISUAL.1992.235219	http://dx.doi.org/10.1109/VISUAL.1992.235219	107	114	C		Bruce Lucas;G. D. Abrams;Nancy S. Collins;D. A. Epstien;Donna L. Gresh;Kevin P. McAuliffe	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;;;;	10.1109/VISUAL.1990.146397;10.1109/VISUAL.1992.235204;10.1109/VISUAL.1991.175818;10.1109/VISUAL.1991.175833		IBM T. J. Watson Research Center##IBM T. J. Watson Research Center##IBM T. J. Watson Research Center##IBM T. J. Watson Research Center##IBM T. J. Watson Research Center##IBM T. J. Watson Research Center
Vis	1992	Direct volumetric visualization	10.1109/VISUAL.1992.235220	http://dx.doi.org/10.1109/VISUAL.1992.235220	99	106	C		R. D. Williams;Fred L. Wefer;T. E. Clifton	;;			
Vis	1992	Volume rendering on a distributed memory parallel computer	10.1109/VISUAL.1992.235221	http://dx.doi.org/10.1109/VISUAL.1992.235221	93	98	C		T. Todd Elvins	Adv. Sci. Visualization Lab., San Diego, CA, USA|c|	10.1109/VISUAL.1991.175807;10.1109/VISUAL.1991.175814		Adv. Sci. Visualization Lab., San Diego, CA, USA|c|
Vis	1992	Four-dimensional views of 3D scalar fields	10.1109/VISUAL.1992.235222	http://dx.doi.org/10.1109/VISUAL.1992.235222	84	91	C		Andrew J. Hanson;Pheng-Ann Heng	CERN, Geneva, Switzerland|c|;	10.1109/VISUAL.1990.146363;10.1109/VISUAL.1991.175821;10.1109/VISUAL.1990.146391		CERN CH-1211
Vis	1992	Massively parallel isosurface extraction	10.1109/VISUAL.1992.235223	http://dx.doi.org/10.1109/VISUAL.1992.235223	77	83	C		Charles D. Hansen;Paul A. Hinker	Los Alamos Nat. Lab., NM, USA|c|;	10.1109/VISUAL.1991.175782		Los Alamos Nat. Lab., NM, USA|c|;
Vis	1992	Generalized focal surfaces: a new method for surface interrogation	10.1109/VISUAL.1992.235224	http://dx.doi.org/10.1109/VISUAL.1992.235224	70	76	C		Hans Hagen;Stefanie Hahmann	Kaiserslautern Univ., Germany|c|;			Kaiserslautern Univ., Germany|c|;
Vis	1992	A 3-D streamline tracking algorithm using dual stream functions	10.1109/VISUAL.1992.235225	http://dx.doi.org/10.1109/VISUAL.1992.235225	62	68	C		David N. Kenwright;Gordon D. Mallison	Dept. of Mech. Eng., Auckland Univ., New Zealand|c|;			University of Auckland Private Bag##University of Auckland Private Bag
Vis	1992	Rendering surface-particles	10.1109/VISUAL.1992.235226	http://dx.doi.org/10.1109/VISUAL.1992.235226	54	61	C		Jarke J. van Wijk	Netherlands Energy Res. Found. ECN, Petten, Netherlands|c|	10.1109/VISUAL.1990.146359		Netherlands Energy Res. Found. ECN, Petten, Netherlands|c|
Vis	1992	Virtual Smoke: an interactive 3D flow visualization technique	10.1109/VISUAL.1992.235227	http://dx.doi.org/10.1109/VISUAL.1992.235227	46	53	C		Kwan-Liu Ma;Philip J. Smith	Utah Univ., Salt Lake City, UT, USA|c|;	10.1109/VISUAL.1991.175772;10.1109/VISUAL.1991.175778;10.1109/VISUAL.1991.175770;10.1109/VISUAL.1990.146360;10.1109/VISUAL.1991.175789;10.1109/VISUAL.1991.175777		University of Utah Salt Lake City
Vis	1992	Interactive splatting of nonrectilinear volumes	10.1109/VISUAL.1992.235228	http://dx.doi.org/10.1109/VISUAL.1992.235228	37	44	C		Peter L. Williams	Nat. Center for Supercomput. Applications, Illinois Univ., Urbana, IL, USA|c|	10.1109/VISUAL.1991.175818		University of Illinois at Urbana
Vis	1992	Interactive visualization of large scalar voxel fields	10.1109/VISUAL.1992.235229	http://dx.doi.org/10.1109/VISUAL.1992.235229	29	36	C		Georgios Sakas;J. Hartig	Tech. Hochschule, Darmstadt, Germany|c|;			Technische Hochschule Darmstadt##Technische Hochschule Darmstadt
Vis	1992	Approximation and rendering of volume data using wavelet transforms	10.1109/VISUAL.1992.235230	http://dx.doi.org/10.1109/VISUAL.1992.235230	21	28	C		Shigeru Muraki	Image Understanding Section, Electrotech. Lab., Tsukuba, Japan|c|			Image Understanding Section, Electrotech. Lab., Tsukuba, Japan|c|
Vis	1992	Towards a comprehensive volume visualization system	10.1109/VISUAL.1992.235231	http://dx.doi.org/10.1109/VISUAL.1992.235231	13	20	C		Ricardo S. Avila;Lisa M. Sobierajski;Arie E. Kaufman	State Univ. of New York, Stony Brook, NY, USA|c|;;	10.1109/VISUAL.1990.146362;10.1109/VISUAL.1990.146413;10.1109/VISUAL.1991.175805		State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook
Vis	1993	Fast volume rendering of compressed data	10.1109/VISUAL.1993.398845	http://dx.doi.org/10.1109/VISUAL.1993.398845	11	18	C		Paul Ning;Lambertus Hesselink	Dept. of Electr. Eng., Stanford Univ., CA, USA|c|;	10.1109/VISUAL.1991.175778		Stanford University Stanford##Stanford University Stanford
Vis	1993	Flow volumes for interactive vector field visualization	10.1109/VISUAL.1993.398846	http://dx.doi.org/10.1109/VISUAL.1993.398846	19	24	C		Nelson L. Max;Barry G. Becker;Roger Crawfis	Lawrence Livermore Nat. Lab., Livermore, CA, USA|c|;;	10.1109/VISUAL.1992.235210;10.1109/VISUAL.1992.235211		Lawrence Livermore National Laboratory Livermore##Lawrence Livermore National Laboratory Livermore##Lawrence Livermore National Laboratory Livermore
Vis	1993	The vision camera: An interactive tool for volume data exploration and navigation	10.1109/VISUAL.1993.398847	http://dx.doi.org/10.1109/VISUAL.1993.398847	25	30	C		Hans-Heino Ehricke;G. Daiber;Wolfgang Straßer	Wilhelm-Schickard-Inst. fuer Inf., Tubingen Univ., Germany|c|;;			Wilhelm-Schickard-Inst. fuer Inf., Tubingen Univ., Germany|c|;;
Vis	1993	Visualization of time-dependent flow fields	10.1109/VISUAL.1993.398848	http://dx.doi.org/10.1109/VISUAL.1993.398848	32	38	C		David A. Lane	NASA Ames Res. Center, Moffett Field, CA, USA|c|	10.1109/VISUAL.1992.235211;10.1109/VISUAL.1990.146360;10.1109/VISUAL.1992.235212;10.1109/VISUAL.1991.175773;10.1109/VISUAL.1991.175789		NASA Ames Res. Center, Moffett Field, CA, USA|c|
Vis	1993	A probe for local flow field visualization	10.1109/VISUAL.1993.398849	http://dx.doi.org/10.1109/VISUAL.1993.398849	39	45	C		Wim C. de Leeuw;Jarke J. van Wijk	Fac. of Tech. Math. & Inf., Delft Univ. of Technol., Netherlands|c|;	10.1109/VISUAL.1992.235193;10.1109/VISUAL.1991.175789;10.1109/VISUAL.1992.235210		University of Technology##University of Technology
Vis	1993	Visualization of turbulent flow with particles	10.1109/VISUAL.1993.398850	http://dx.doi.org/10.1109/VISUAL.1993.398850	46	52	C		Andrea J. S. Hin;Frits H. Post	Fac. of Tech. Math. & Inf., Delft Univ. of Technol., Netherlands|c|;			Delft University of Technology##Delft University of Technology
Vis	1993	Optimal filter design for volume reconstruction and visualization	10.1109/VISUAL.1993.398851	http://dx.doi.org/10.1109/VISUAL.1993.398851	54	61	C		Ingrid Carlbom	Digital Equipment Corp., Cambridge, MA, USA|c|			Digital Equipment Corporation
Vis	1993	Accelerating volume animation by space-leaping	10.1109/VISUAL.1993.398852	http://dx.doi.org/10.1109/VISUAL.1993.398852	62	69	C		Roni Yagel;Z. Shi	Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbbus, OH, USA|c|;	10.1109/VISUAL.1992.235231		The Ohio State University##The Ohio State University
Vis	1993	Rapid exploration of curvilinear grids using direct volume rendering (Extended Abstract)	10.1109/VISUAL.1993.398853	http://dx.doi.org/10.1109/VISUAL.1993.398853	70	77	C		Allen Van Gelder;Jane Wilhelms	Comput. & Inf. Sci., California Univ., Santa Cruz, CA, USA|c|;	10.1109/VISUAL.1992.235204;10.1109/VISUAL.1992.235228		University of California##University of California
Vis	1993	Volume sampled voxelization of geometric primitives	10.1109/VISUAL.1993.398854	http://dx.doi.org/10.1109/VISUAL.1993.398854	78	84	C		Sidney W. Wang;Arie E. Kaufman	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;	10.1109/VISUAL.1992.235190	voxelization, volume sampling, discrete ray tracing, filtering	State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook
Vis	1993	Tioga: A database-oriented visualization tool	10.1109/VISUAL.1993.398855	http://dx.doi.org/10.1109/VISUAL.1993.398855	86	93	C		Michael Stonebraker;Jolly Chen;Nobuko Nathan;Caroline Paxson;Alan Su;Jiang Wu	EECS Dept., California Univ., Berkeley, CA, USA|c|;;;;;			University of California Berkeley##University of California Berkeley##University of California Berkeley##University of California Berkeley##University of California Berkeley##University of California Berkeley
Vis	1993	Bridging the gap between visualization and data management: A simple visualization management system	10.1109/VISUAL.1993.398856	http://dx.doi.org/10.1109/VISUAL.1993.398856	94	101	C		Peter Kochevar;Zahid Ahmed;J. Shade;Colin Sharp	Digital Equipment Corp., San Diego, CA, USA|c|;;;	10.1109/VISUAL.1992.235219;10.1109/VISUAL.1992.235197		Digital Equipment Corp., San Diego, CA, USA|c|;;;
Vis	1993	GRASPARC-A problem solving environment integrating computation and visualization	10.1109/VISUAL.1993.398857	http://dx.doi.org/10.1109/VISUAL.1993.398857	102	109	C		Ken Brodlie;A. Poon;Helen Wright;L. Brankin;G. Banecki;A. Gay	Sch. of Comput. Studies, Leeds Univ., UK|c|;;;;;	10.1109/VISUAL.1992.235219;10.1109/VISUAL.1991.175818		School of Computer S t u d i e s University of Leeds Leeds
Vis	1993	An environment for telecollaborative data exploration	10.1109/VISUAL.1993.398858	http://dx.doi.org/10.1109/VISUAL.1993.398858	110	117	C		Gudrun Klinker	Digital Equipment Corp., Cambridge, MA, USA|c|	10.1109/VISUAL.1992.235215		Digital Equipment Corporation
Vis	1993	HyperSlice - Visualization of Scalar Functions of Many Variables	10.1109/VISUAL.1993.398859	http://dx.doi.org/10.1109/VISUAL.1993.398859	119	125	C		Jarke J. van Wijk;Robert van Liere	Netherlands Energy Res. Foundation, Petten, Netherlands|c|;	10.1109/VISUAL.1990.146387;10.1109/VISUAL.1991.175809		Netherlands Energy Res. Foundation, Petten, Netherlands|c|;
Vis	1993	Fine-grain visualization algorithms in dataflow environments	10.1109/VISUAL.1993.398860	http://dx.doi.org/10.1109/VISUAL.1993.398860	126	133	C		D. Song;Eric J. Golin	Dept. of Comput. Sci., Illinois Univ., Urbana, IL, USA|c|;	10.1109/VISUAL.1992.235219		University of Illinois at Urbana-Champaign##University of Illinois at Urbana-Champaign
Vis	1993	Developing modular application builders to exploit MIMD parallel	10.1109/VISUAL.1993.398861	http://dx.doi.org/10.1109/VISUAL.1993.398861	134	141	C		C. Thornborrow;A. J. S. Wilson;Chris Faigle	Edinburgh Parallel Comput. Centre, Edinburgh Univ., UK|c|;;			Edinburgh Parallel Computing Centre University of Edinburgh Edinburgh##Edinburgh Parallel Computing Centre University of Edinburgh Edinburgh##Edinburgh Parallel Computing Centre University of Edinburgh Edinburgh
Vis	1993	Virtual input devices for 3D systems	10.1109/VISUAL.1993.398862	http://dx.doi.org/10.1109/VISUAL.1993.398862	142	148	C		Taosong He;Arie E. Kaufman	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;	10.1109/VISUAL.1992.235231	device unified interface, 3d input device, virtual input device, device information-base	State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook
Vis	1993	InfoCrystal: A visual tool for information retrieval	10.1109/VISUAL.1993.398863	http://dx.doi.org/10.1109/VISUAL.1993.398863	150	157	C		Anselm Spoerri	Center for Educational Comput. Initiatives, MIT, Cambridge, MA, USA|c|		information visualization, visual query language, information retrieval, graphical user interface, human factors	Center for Educational Comput. Initiatives, MIT, Cambridge, MA, USA|c|
Vis	1993	Visual feedback in querying large databases	10.1109/VISUAL.1993.398864	http://dx.doi.org/10.1109/VISUAL.1993.398864	158	165	C		Daniel A. Keim;Hans-Peter Kriegel;Thomas Seidl 0001	Inst. for Comput. Sci., Munich Univ., Germany|c|;;	10.1109/VISUAL.1990.146387;10.1109/VISUAL.1990.146386;10.1109/VISUAL.1990.146389;10.1109/VISUAL.1990.146402		University of Munich Leopoldstr##University of Munich Leopoldstr##University of Munich Leopoldstr
Vis	1993	DIVIDE: Distributed visual display of the execution of asynchronous, distributed algorithms on loosely-coupled parallel processors	10.1109/VISUAL.1993.398865	http://dx.doi.org/10.1109/VISUAL.1993.398865	166	173	C		Tom M. Morrow;Sumit Ghosh	Oracle Corp., Redwood Shores, CA, USA|c|;			Oracle Corporation
Vis	1993	Performance visualization of parallel programs	10.1109/VISUAL.1993.398866	http://dx.doi.org/10.1109/VISUAL.1993.398866	174	181	C		Abdul Waheed;Diane T. Rover	Dept. of Electr. Eng., Michigan State Univ., E. Lansing, MI, USA|c|;			Michigan State University##Michigan State University
Vis	1993	Orientation maps: Techniques for visualizing rotations (A  Consumer's Guide)	10.1109/VISUAL.1993.398867	http://dx.doi.org/10.1109/VISUAL.1993.398867	183	188	C		Bowen Alpern;Larry Carter;M. Grayson;C. Pelkie	IBM T. J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;;			IBM T. J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;;
Vis	1993	Geometric optimization	10.1109/VISUAL.1993.398868	http://dx.doi.org/10.1109/VISUAL.1993.398868	189	195	C		Paul A. Hinker;Charles D. Hansen	Los Alamos Nat. Lab., NM, USA|c|;	10.1109/VISUAL.1992.235223		Los Alamos Nat. Lab., NM, USA|c|;
Vis	1993	Interactive visualization methods for four dimensions	10.1109/VISUAL.1993.398869	http://dx.doi.org/10.1109/VISUAL.1993.398869	196	203	C		Andrew J. Hanson;Robert A. Cross	Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA|c|;	10.1109/VISUAL.1991.175821;10.1109/VISUAL.1992.235222		Indiana University Bloomington##Indiana University Bloomington
Vis	1993	Navigating large networks with hierarchies	10.1109/VISUAL.1993.398870	http://dx.doi.org/10.1109/VISUAL.1993.398870	204	210	C		Stephen G. Eick;Graham J. Wills	AT&T Bell Lab., USA|c|;	10.1109/VISUAL.1990.146369;10.1109/VISUAL.1991.175815		AT&T Bell Lab., USA|c|;
Vis	1993	Dichromatic color representations for complex display systems	10.1109/VISUAL.1993.398871	http://dx.doi.org/10.1109/VISUAL.1993.398871	212	219	C		Mark S. Peercy;Lambertus Hesselink	Stanford Univ., CA, USA|c|;			Stanford University Stanford
Vis	1993	Towards a texture naming system: Identifying relevant dimensions of texture	10.1109/VISUAL.1993.398872	http://dx.doi.org/10.1109/VISUAL.1993.398872	220	227	C		A. Ravishankar Rao;Gerald L. Lohse	IBM T.J. Watson Res. Center, Yorktown Heights, NY, USA|c|;	10.1109/VISUAL.1990.146374		T. J . Watson Research Ctr
Vis	1993	Applying observations of work activity in designing prototype data analysis tools	10.1109/VISUAL.1993.398873	http://dx.doi.org/10.1109/VISUAL.1993.398873	228	235	C		R. R. Springmeyer	Lawrence Livermore Nat. Lab., Livermore, CA, USA|c|	10.1109/VISUAL.1992.235203;10.1109/VISUAL.1990.146360		Lawrence Livermore National Laboratory Livermore
Vis	1993	An architecture for rule-based visualization	10.1109/VISUAL.1993.398874	http://dx.doi.org/10.1109/VISUAL.1993.398874	236	243	C		Bernice E. Rogowitz;Lloyd Treinish	IBM T.J. Watson Res. Center, Yorktown Heights, NY, USA|c|;	10.1109/VISUAL.1992.235199;10.1109/VISUAL.1992.235219;10.1109/VISUAL.1991.175818		IBM T.J. Watson Res. Center, Yorktown Heights, NY, USA|c|;
Vis	1993	Implicit stream surfaces	10.1109/VISUAL.1993.398875	http://dx.doi.org/10.1109/VISUAL.1993.398875	245	252	C		Jarke J. van Wijk	Netherlands Energy Res. Foundation, Petten, Netherlands|c|	10.1109/VISUAL.1992.235211;10.1109/VISUAL.1992.235225;10.1109/VISUAL.1990.146359		Netherlands Energy Res. Foundation, Petten, Netherlands|c|
Vis	1993	Cloud tracing in convection-diffusion systems	10.1109/VISUAL.1993.398876	http://dx.doi.org/10.1109/VISUAL.1993.398876	253	260	C		Kwan-Liu Ma;Philip J. Smith	NASA Langley Res. Center, Hampton, VA, USA|c|;	10.1109/VISUAL.1992.235210;10.1109/VISUAL.1991.175770;10.1109/VISUAL.1991.175773;10.1109/VISUAL.1992.235211;10.1109/VISUAL.1992.235227;10.1109/VISUAL.1992.235174;10.1109/VISUAL.1991.175789		University of Utah Salt Lake City##NASA Langley Research Center Hampton
Vis	1993	Texture splats for 3D scalar and vector field visualization	10.1109/VISUAL.1993.398877	http://dx.doi.org/10.1109/VISUAL.1993.398877	261	266	C		Roger Crawfis;Nelson L. Max	Lawrence Livermore Nat. Lab., Livermore, CA, USA|c|;			Lawrence Livemore National Laboratory Livermore##
Vis	1993	Geometric clipping using Boolean textures	10.1109/VISUAL.1993.398878	http://dx.doi.org/10.1109/VISUAL.1993.398878	268	274	C		W. E. Lorenson	General Electric Corp., Schenectady, NY, USA|c|	10.1109/VISUAL.1992.235205;10.1109/VISUAL.1992.235204		General Electric Company Corporate Research and Development Schenectady
Vis	1993	Data shaders	10.1109/VISUAL.1993.398879	http://dx.doi.org/10.1109/VISUAL.1993.398879	275	282	C		Brian Corrie;Paul Mackerras	Dept. of Comput. Sci., Australian Nat. Univ., Canberra, ACT, Australia|c|;	10.1109/VISUAL.1991.175804		Australian National University Canberra##Australian National University Canberra
Vis	1993	Spray rendering: Visualization using smart particles	10.1109/VISUAL.1993.398880	http://dx.doi.org/10.1109/VISUAL.1993.398880	283	290	C		Alex T. Pang;Kyle Smith	Board of Studies in Comput. & Inf. Sci., California Univ., Santa Cruz, CA, USA|c|;	10.1109/VISUAL.1992.235226		University of California##University of California##University of California##University of California
Vis	1993	Interactive shading for surface and volume visualization on graphics workstations	10.1109/VISUAL.1993.398881	http://dx.doi.org/10.1109/VISUAL.1993.398881	291	298	C		Peter A. Fletcher;Philip K. Robertson	CSIRO, Canberra, ACT, Australia|c|;			CSIRO Division of Information Technology GPO##CSIRO Division of Information Technology GPO
Vis	1993	Fast analytical computation of Richard's smooth molecular surface	10.1109/VISUAL.1993.398882	http://dx.doi.org/10.1109/VISUAL.1993.398882	300	307	C		Amitabh Varshney;Frederick P. Brooks Jr.	Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;			University of North Carolina at Chapel Hill Chapel Hill##University of North Carolina at Chapel Hill Chapel Hill
Vis	1993	Computer visualization of long genomic sequences	10.1109/VISUAL.1993.398883	http://dx.doi.org/10.1109/VISUAL.1993.398883	308	315	C		Dachywan Wu;James Roberge;Douglas J. Cork;Bao Gia Nguyen;Thom Grace	Illinois Inst. of Technol., Chicago, IL, USA|c|;;;;			Illinois Institute of Technology Chicago
Vis	1993	Visualization of acoustic lens data	10.1109/VISUAL.1993.398884	http://dx.doi.org/10.1109/VISUAL.1993.398884	316	323	C		A. J. Bladek	Appl. Phys. Lab., Washington Univ., Seattle, WA, USA|c|	10.1109/VISUAL.1991.175784		University of Washington
Vis	1993	MRIVIEW: An interactive computational tool for investigation of brain structure and function	10.1109/VISUAL.1993.398885	http://dx.doi.org/10.1109/VISUAL.1993.398885	324	331	C		Douglas M. Ranken;John S. George	Los Alamos Nat. Lab., NM, USA|c|;			Los Alamos Nat. Lab., NM, USA|c|;
Vis	1993	Visualization and modeling of geophysical data	10.1109/VISUAL.1993.398892	http://dx.doi.org/10.1109/VISUAL.1993.398892	362	365	C		G. Celniker;I. Chakravarty;J. Moorman	Schlumberger Lab. for Comput. Sci., Austin, TX, USA|c|;;			Schlumberger Lab. for Comput. Sci., Austin, TX, USA|c|;;
Vis	1993	Visualization of oil reservoirs over a large range of scales as a catalyst for multi-disciplinary integration	10.1109/VISUAL.1993.398893	http://dx.doi.org/10.1109/VISUAL.1993.398893	366	369	C		S. Tyson;B. Williams	Santos Ltd., Australia|c|;			GeoVisual Systems Ltd##GeoVisual Systems Ltd##GeoVisual Systems Ltd##GeoVisual Systems Ltd
Vis	1993	Unsteady phenomena, hypersonic flows and co-operative flow visualization in aerospace research	10.1109/VISUAL.1993.398894	http://dx.doi.org/10.1109/VISUAL.1993.398894	370	373	C		Hans-Georg Pagendarm	German Aerosp. Res. Establishment, Gottingen, Germany|c|			German Aerospace Research Establishment##German Aerospace Research Establishment
Vis	1993	Towards interactive steering, visualization and animation of unsteady finite element simulations	10.1109/VISUAL.1993.398895	http://dx.doi.org/10.1109/VISUAL.1993.398895	374	377	C		G. David Kerlick;E. Kirby	Boeing Computer Services Res. & Technology, Bellevue, WA, USA|c|;			Boeing Computer Services Research and Technology##Boeing Computer Services Research and Technology
Vis	1993	Visualizing results of transient flow simulations	10.1109/VISUAL.1993.398896	http://dx.doi.org/10.1109/VISUAL.1993.398896	406	409	C		H. F. Mayer;B. Tabatabai	Joanneum Res., Graz, Austria|c|;	10.1109/VISUAL.1991.175771		JOANNEUM RESEARCH Institute for Information Systems##JOANNEUM RESEARCH Institute for Information Systems
Vis	1993	Fanal: A relational analysis and visualization package for high energy physics	10.1109/VISUAL.1993.398897	http://dx.doi.org/10.1109/VISUAL.1993.398897	382	385	C		H. Videau;P. Mora de Freitas	Ecole Polytech., CNRS, France|c|;			Ecole Polytech., CNRS, France|c|;
Vis	1993	Non conventional methods for the visualization of events from high energy physics	10.1109/VISUAL.1993.398898	http://dx.doi.org/10.1109/VISUAL.1993.398898	386	390	C		Hans Drevermann;D. Kuhm;B. Nilsson	CERN, Geneva, Switzerland|c|;;			CERN Inst .f. Experiment alphysik d. Univ. Niels Bohr Institute##CERN Inst .f. Experiment alphysik d. Univ. Niels Bohr Institute##CERN Inst .f. Experiment alphysik d. Univ. Niels Bohr Institute
Vis	1993	Visualization of stratospheric ozone depletion and the polar vortex	10.1109/VISUAL.1993.398899	http://dx.doi.org/10.1109/VISUAL.1993.398899	391	396	C		Lloyd Treinish	IBM T.J. Watson Res. Center, Yorktown Heights, NY, USA|c|	10.1109/VISUAL.1992.235219		IBM Thomas J. Watson Research Center
Vis	1993	A climate simulation case study	10.1109/VISUAL.1993.398900	http://dx.doi.org/10.1109/VISUAL.1993.398900	397	401	C		P. C. Chen	Fujitsu America, Inc., San Jose, CA, USA|c|			Fujitsu America, Inc
Vis	1993	Feature extraction for oceanographic data using a 3D edge operator	10.1109/VISUAL.1993.398901	http://dx.doi.org/10.1109/VISUAL.1993.398901	402	405	C		R. J. Moorehead;Z. Zhu	NSF Eng. Res. Center for Computational Field Simulation, Mississippi State Univ., MS, USA|c|;			NSF Engineering Research Center for Computational Field Simulation Mississippi State University Mississippi State##NSF Engineering Research Center for Computational Field Simulation Mississippi State University Mississippi State##NSF Engineering Research Center for Computational Field Simulation Mississippi State University Mississippi State
Vis	1993	Enhancing reality in the operating room	10.1109/VISUAL.1993.398902	http://dx.doi.org/10.1109/VISUAL.1993.398902	410	415	C		William E. Lorensen;Harvey E. Cline;C. Nafis;D. Altobelli;L. Gleason	General Electric Co., Schenectady, NY, USA|c|;;;;;			General Electric Company Corporate Research and Development Schenectady##General Electric Company Corporate Research and Development Schenectady##General Electric Company Corporate Research and Development Schenectady
Vis	1993	3D simulation of delivery	10.1109/VISUAL.1993.398903	http://dx.doi.org/10.1109/VISUAL.1993.398903	416	419	C		Jean-Daniel Boissonnat;Bernhard Geiger	I.N.R.I.A., Sophia-Antipolis, France|c|;			I.N.R.I.A., Sophia-Antipolis, France|c|;
Vis	1993	The virtual restoration of the Visir tomb	10.1109/VISUAL.1993.398904	http://dx.doi.org/10.1109/VISUAL.1993.398904	420	423	C		Patrizia Palamidese;M. Betro;G. Muccioli	CNUCE CNR, Pisa, Italy|c|;;			CNUCE CNR##CNUCE CNR##CNUCE CNR
Vis	1993	The quantum Coulomb three-body problem - Visualization of simulation results and numerical methods	10.1109/VISUAL.1993.398911	http://dx.doi.org/10.1109/VISUAL.1993.398911	378	381	C		D. I. Abramov;V. V. Gusev;Stanislav V. Klimenko;L. I. Ponomarev;W. Krueger;W. Renz	Dept. of Theoretical Phys., St. Petersburg State Univ., Russia|c|;;;;;	10.1109/VISUAL.1990.146391;10.1109/VISUAL.1991.175812		S.-Petersburg State University##Russian Scientific Center "Kurchatov Institute"
Vis	1994	Visualization and geographic information system integration: what are the needs and the requirements, if any?	10.1109/VISUAL.1994.346284	http://dx.doi.org/10.1109/VISUAL.1994.346284	400	403	M		Theresa-Marie Rhyne;William Ivey;Loey Knapp;Peter Kochevar;Tom Mace	Martin Marietta/US EPA Visualization Center, USA|c|;;;;			Martin Marietta/US EPA Visualization Center, USA|c|;;;;
Vis	1994	Validation, verification and evaluation	10.1109/VISUAL.1994.346285	http://dx.doi.org/10.1109/VISUAL.1994.346285	414	418	M		Samuel P. Uselton;Geoff Dorn;Charbel Farhat;Michael W. Vannier;Kim Esbensen;Al Globus	NASA Ames Res. Center, Moffett Field, CA, USA|c|;;;;;			NASA Ames Res. Center, Moffett Field, CA, USA|c|;;;;;
Vis	1994	Visualizing data: is virtual reality the key?	10.1109/VISUAL.1994.346286	http://dx.doi.org/10.1109/VISUAL.1994.346286	410	413	M		Linda M. Stone;Thomas Erickson;Benjamin B. Bederson;Peter Rothman;Raymond Muzzy	LORAL Space & Range Syst., Sunnyvale, CA, USA|c|;;;;			LORAL Space & Range Syst., Sunnyvale, CA, USA|c|;;;;
Vis	1994	Visualizing multidimensional (multivariate) data and relations	10.1109/VISUAL.1994.346287	http://dx.doi.org/10.1109/VISUAL.1994.346287	404	409	M		Alfred Inselberg;Georges G. Grinstein;Ted Mihalisin;Hans Hinterberger	Dept. of Comput. Sci., California Univ., Los Angeles, CA, USA|c|;;;			Dept. of Comput. Sci., California Univ., Los Angeles, CA, USA|c|;;;
Vis	1994	Visualization in medicine: VIRTUAL reality or ACTUAL reality ?	10.1109/VISUAL.1994.346288	http://dx.doi.org/10.1109/VISUAL.1994.346288	396	399	M		Christian Roux;Jean-Louis Coatrieux;Jean-Louis Dillenseger;Elliot K. Fishman;Murray H. Loew;Hans-Peter Meinzer;Justin D. Pearlman	Dept. Image et Traitement de l''Inf., Ecole Nat. Superieure des Telecommun. de Bretagne, Brest, France|c|;;;;;;			Dept. Image et Traitement de l''Inf., Ecole Nat. Superieure des Telecommun. de Bretagne, Brest, France|c|;;;;;;
Vis	1994	Challenges and opportunities in visualization for NASA's EOS Mission to Planet Earth	10.1109/VISUAL.1994.346289	http://dx.doi.org/10.1109/VISUAL.1994.346289	392	395	M		Mike E. Botts;Jon D. Dykstra;Lee S. Elson;Steven J. Goodman;Meemong Lee	Alabama Univ., Huntsville, AL, USA|c|;;;;			Alabama Univ., Huntsville, AL, USA|c|;;;;
Vis	1994	Visualization of volcanic ash clouds	10.1109/VISUAL.1994.346290	http://dx.doi.org/10.1109/VISUAL.1994.346290	386	390, C46	C		Mitchell Roth;Rick Guritz	Arctic Region Supercomput. Center, Alaska Univ., Fairbanks, AK, USA|c|;			Arctic Region Supercomput. Center, Alaska Univ., Fairbanks, AK, USA|c|;
Vis	1994	Volume rendering of pool fire data	10.1109/VISUAL.1994.346291	http://dx.doi.org/10.1109/VISUAL.1994.346291	382	385, C45	C		Holly E. Rushmeier;Anthony Hamins;Mun-Young Choi	Nat. Inst. of Stand. & Technol., Gaithersburg, MD, USA|c|;;			NIST Gaithersburg##NIST Gaithersburg##NIST Gaithersburg##NIST Gaithersburg
Vis	1994	Visualization of an electric power transmission system	10.1109/VISUAL.1994.346292	http://dx.doi.org/10.1109/VISUAL.1994.346292	379	381, C44	C		Pramod M. Mahadev;Richard D. Christie	Dept. of Electr. Eng., Washington Univ., Seattle, WA, USA|c|;			University of Washington Seattle##University of Washington Seattle
Vis	1994	New techniques in the design of healthcare facilities	10.1109/VISUAL.1994.346293	http://dx.doi.org/10.1109/VISUAL.1994.346293	374	377, C43	C		Tarek K. Alameldin;Mardelle Shepley	Visualization Lab., Texas A&M Univ., College Station, TX, USA|c|;			Visualization Lab., Texas A&M Univ., College Station, TX, USA|c|;
Vis	1994	Visualization of 3D ultrasonic data	10.1109/VISUAL.1994.346294	http://dx.doi.org/10.1109/VISUAL.1994.346294	369	373, C42	C		Georgios Sakas;Lars-Arne Schreyer;Marcus Grimm	Fraunhofer-Inst. for Comput. Graphics, Darmstadt, Germany|c|;;	10.1109/VISUAL.1992.235228		Fraunhofer-Inst. for Comput. Graphics, Darmstadt, Germany|c|;;
Vis	1994	Observing a volume rendered fetus within a pregnant patient	10.1109/VISUAL.1994.346295	http://dx.doi.org/10.1109/VISUAL.1994.346295	364	368, C41	C		Andrei State;David T. Chen;Chris Tector;Andrew Brandt;Hong Chen;Ryutarou Ohbuchi;Michael Bajura;Henry Fuchs	North Carolina Univ., Chapel Hill, NC, USA|c|;;;;;;;			University of North Carolina##University of North Carolina##University of North Carolina##University of North Carolina##University of North Carolina##University of North Carolina##University of North Carolina##University of North Carolina
Vis	1994	Integrating spatial data display with virtual reconstruction	10.1109/VISUAL.1994.346296	http://dx.doi.org/10.1109/VISUAL.1994.346296	359	362, C40	C		Philip Peterson;Brian Hayden;F. David Fracchia	Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada|c|;;	10.1109/VISUAL.1993.398904;10.1109/VISUAL.1992.235188;10.1109/VISUAL.1991.175771		Simon Fraser University##Simon Fraser University##Simon Fraser University
Vis	1994	Visualization of mesoscale flow features in ocean basins	10.1109/VISUAL.1994.346297	http://dx.doi.org/10.1109/VISUAL.1994.346297	355	358, C39	C		Andreas Johannsen;Robert J. Moorhead II	NSF Eng. Res. Center for Comput. Field Simulation, Mississippi State Univ., MS, USA|c|;	10.1109/VISUAL.1994.346332;10.1109/VISUAL.1993.398901;10.1109/VISUAL.1994.346332		NSF Engineering Research Center for Computational Field Simulation##NSF Engineering Research Center for Computational Field Simulation##NSF Engineering Research Center for Computational Field Simulation
Vis	1994	Severe rainfall events in Northwestern Peru (visualization of scattered meteorological data)	10.1109/VISUAL.1994.346298	http://dx.doi.org/10.1109/VISUAL.1994.346298	350	354, C38	C		Lloyd Treinish	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|	10.1109/VISUAL.1992.235219		IBM Thomas J. Watson Research Center
Vis	1994	A case study on visualization for boundary value problems	10.1109/VISUAL.1994.346299	http://dx.doi.org/10.1109/VISUAL.1994.346299	345	348	C		Gábor Domokos;Randy C. Paffenroth	Dept. of Strength of Mater., Tech. Univ. Budapest, Hungary|c|;			Technical University of Budapest
Vis	1994	Visualization and data analysis in space and atmospheric science	10.1109/VISUAL.1994.346300	http://dx.doi.org/10.1109/VISUAL.1994.346300	341	344, C37	C		A. Mankofsky;E. P. Szuszczewicz;P. Blanchard;C. Goodrich;D. McNabb;R. Kulkarni;D. Kamins	Sci. Applications Int. Corp., McLean, VA, USA|c|;;;;;;			Science Applications International Corporation Mckan##Science Applications International Corporation Mckan##Science Applications International Corporation Mckan##Science Applications International Corporation Mckan##Science Applications International Corporation Mckan##Science Applications International Corporation Mckan##Science Applications International Corporation Mckan
Vis	1994	Tokamak plasma turbulence visualization	10.1109/VISUAL.1994.346301	http://dx.doi.org/10.1109/VISUAL.1994.346301	337	340, C36	C		Scott E. Parker;Ravi Samtaney	Plasma Phys. Lab., Princeton Univ., NJ, USA|c|;		Computational geometry, object modeling, geometric modeling, volume modeling, implicit modeling, sweeping	Plasma Phys. Lab., Princeton Univ., NJ, USA|c|;
Vis	1994	XmdvTool: integrating multiple methods for visualizing multivariate data	10.1109/VISUAL.1994.346302	http://dx.doi.org/10.1109/VISUAL.1994.346302	326	333	C		Matthew O. Ward	Dept. of Comput. Sci., Worcester Polytech. Inst., MA, USA|c|	10.1109/VISUAL.1990.146386;10.1109/VISUAL.1990.146387;10.1109/VISUAL.1990.146402		Dept. of Comput. Sci., Worcester Polytech. Inst., MA, USA|c|
Vis	1994	An object oriented design for the visualization of multi-variable data objects	10.1109/VISUAL.1994.346303	http://dx.doi.org/10.1109/VISUAL.1994.346303	318	325, C35	C		Jean-Marie Favre;James K. Hahn	Dept. of Electr. Eng. & Comput. Sci., George Washington Univ., Washington, DC, USA|c|;	10.1109/VISUAL.1991.175804;10.1109/VISUAL.1992.235219;10.1109/VISUAL.1990.146373;10.1109/VISUAL.1992.235205		The George Washington University Washington##The George Washington University Washington
Vis	1994	A lattice model for data display	10.1109/VISUAL.1994.346304	http://dx.doi.org/10.1109/VISUAL.1994.346304	310	317	C		William L. Hibbard;Charles R. Dyer;Brian E. Paul	Space Sci. & Eng. Center, Wisconsin Univ., Madison, WI, USA|c|;;	10.1109/VISUAL.1992.235205;10.1109/VISUAL.1992.235202;10.1109/VISUAL.1991.175818;10.1109/VISUAL.1992.235215		University of Wisconsin -Madison##University of Wisconsin -Madison##University of Wisconsin -Madison
Vis	1994	Mix&amp;Match: a construction kit for visualization	10.1109/VISUAL.1994.346305	http://dx.doi.org/10.1109/VISUAL.1994.346305	302	309, C34	C		Alex T. Pang;Naim Alper	Baskin Center for Comput. Eng. & Inf. Sci., California Univ., Santa Cruz, CA, USA|c|;	10.1109/VISUAL.1993.398860;10.1109/VISUAL.1990.146373;10.1109/VISUAL.1991.175804;10.1109/VISUAL.1992.235207;10.1109/VISUAL.1992.235219;10.1109/VISUAL.1993.398880;10.1109/VISUAL.1993.398879		University of California##University of California
Vis	1994	Nonpolygonal isosurface rendering for large volume datasets	10.1109/VISUAL.1994.346306	http://dx.doi.org/10.1109/VISUAL.1994.346306	293	300, C33	C		James W. Durkin;John F. Hughes	Program of Comput. Graphics, Cornell Univ., Ithaca, NY, USA|c|;			Program of Comput. Graphics, Cornell Univ., Ithaca, NY, USA|c|;
Vis	1994	Approximation of isosurface in the Marching Cube: ambiguity problem	10.1109/VISUAL.1994.346307	http://dx.doi.org/10.1109/VISUAL.1994.346307	288	292	C		Sergey V. Matveyev	Dept. of Comput. Sci., Inst. for High Energy Phys., Moscow, Russia|c|	10.1109/VISUAL.1991.175782		Dept. of Comput. Sci., Inst. for High Energy Phys., Moscow, Russia|c|
Vis	1994	Discretized Marching Cubes	10.1109/VISUAL.1994.346308	http://dx.doi.org/10.1109/VISUAL.1994.346308	281	287, C32	C		Claudio Montani;Riccardo Scateni;Roberto Scopigno	CNR, Pisa, Italy|c|;;	10.1109/VISUAL.1992.235223		I.E.I. -Consiglio Nazionale delle Ricerche##Studi Superiori Sardegna (CRSI)##CNUCE -Consiglio Nazionale delle Ricerche
Vis	1994	An annotation system for 3D fluid flow visualization	10.1109/VISUAL.1994.346309	http://dx.doi.org/10.1109/VISUAL.1994.346309	273	279, C31	C		Maria M. Loughlin;John F. Hughes	Res. Lab., Digital Equipment Corp., Cambridge, MA, USA|c|;	10.1109/VISUAL.1990.146360;10.1109/VISUAL.1991.175837;10.1109/VISUAL.1992.235203		Cambridge Research Lab Digital Equipment Corporation One Kendall Sq
Vis	1994	The design and implementation of the Cortex visualization system	10.1109/VISUAL.1994.346310	http://dx.doi.org/10.1109/VISUAL.1994.346310	265	272, C30	C		Deb Banerjee;Chris Morley;Wayne Smith	Fluent Inc., Lebanon, NH, USA|c|;;	10.1109/VISUAL.1992.235223;10.1109/VISUAL.1991.175833;10.1109/VISUAL.1990.146360	interactive, extensible, spray rendering, smart particles, visualization environment	Fluent Inc. Centerra Resource Park Lebanon##Fluent Inc. Centerra Resource Park Lebanon##Fluent Inc. Centerra Resource Park Lebanon
Vis	1994	UFAT-a particle tracer for time-dependent flow fields	10.1109/VISUAL.1994.346311	http://dx.doi.org/10.1109/VISUAL.1994.346311	257	264, C29	C		David A. Lane	NASA Ames Res. Center, Moffett Field, CA, USA|c|	10.1109/VISUAL.1990.146360;10.1109/VISUAL.1993.398848;10.1109/VISUAL.1993.398850;10.1109/VISUAL.1993.398849;10.1109/VISUAL.1993.398846		Computer Sciences Corporation
Vis	1994	Visualizing 3D velocity fields near contour surfaces	10.1109/VISUAL.1994.346312	http://dx.doi.org/10.1109/VISUAL.1994.346312	248	255, C28	C		Nelson L. Max;Roger Crawfis;Charles Grant	Lawrence Livermore Nat. Lab., CA, USA|c|;;	10.1109/VISUAL.1993.398877;10.1109/VISUAL.1994.346313		Lawrence Livermore National Laboratory Livermore##Lawrence Livermore National Laboratory Livermore##Lawrence Livermore National Laboratory Livermore
Vis	1994	Visualizing flow over curvilinear grid surfaces using line integral convolution	10.1109/VISUAL.1994.346313	http://dx.doi.org/10.1109/VISUAL.1994.346313	240	247, C27	C		Lisa K. Forssell	Comput. Sci. Corp., NASA Ames Res. Center, Moffett Field, CA, USA|c|	10.1109/VISUAL.1992.235227;10.1109/VISUAL.1990.146360;10.1109/VISUAL.1991.175771;10.1109/VISUAL.1992.235210;10.1109/VISUAL.1990.146359;10.1109/VISUAL.1993.398846;10.1109/VISUAL.1993.398850;10.1109/VISUAL.1991.175773;10.1109/VISUAL.1992.235226		Computer Sciences Corporation
Vis	1994	Volume rendering methods for computational fluid dynamics visualization	10.1109/VISUAL.1994.346314	http://dx.doi.org/10.1109/VISUAL.1994.346314	232	239, C26	C		David S. Ebert;Roni Yagel;James N. Scott;Yair Kurzion	Dept. of Comput. Sci., Maryland Univ., Baltimore, MD, USA|c|;;;			University of Maryland Baltimore County##The Ohio State University##The Ohio State University
Vis	1994	Streamball techniques for flow visualization	10.1109/VISUAL.1994.346315	http://dx.doi.org/10.1109/VISUAL.1994.346315	225	231, C25	C		Manfred Brill;Hans Hagen;Hans-Christian Rodrian;Wladimir Djatschin;Stanislav V. Klimenko	Dept. of Comput. Sci., Kaiserslautern Univ., Germany|c|;;;;	10.1109/VISUAL.1992.235193;10.1109/VISUAL.1991.175789;10.1109/VISUAL.1992.235226;10.1109/VISUAL.1992.235211;10.1109/VISUAL.1993.398875		Dept. of Comput. Sci., Kaiserslautern Univ., Germany|c|;;;;
Vis	1994	User modeling for adaptive visualization systems	10.1109/VISUAL.1994.346316	http://dx.doi.org/10.1109/VISUAL.1994.346316	217	223, C24	C		Gitta Domik;Bernd Gutkauf	Paderborn Univ., Germany|c|;	10.1109/VISUAL.1990.146387;10.1109/VISUAL.1991.175795;10.1109/VISUAL.1990.146375		University of Paderborn
Vis	1994	Restorer: a visualization technique for handling missing data	10.1109/VISUAL.1994.346317	http://dx.doi.org/10.1109/VISUAL.1994.346317	212	216, C23	C		Ray Twiddy;John Cavallo;Shahram M. Shiri	Hughes STX Corp., NASA Goddard Space Flight Center, Greenbelt, MD, USA|c|;;			Hughes STX Corporation##Hughes STX Corporation##Hughes STX Corporation
Vis	1994	Spiders: a new user interface for rotation and visualization of n-dimensional point sets	10.1109/VISUAL.1994.346318	http://dx.doi.org/10.1109/VISUAL.1994.346318	205	211, C22	C		Kirk L. Duffin;William A. Barrett	Brigham Young Univ., Provo, UT, USA|c|;	10.1109/VISUAL.1991.175794		Brigham Young University##Brigham Young University
Vis	1994	Parallel performance measures for volume ray casting	10.1109/VISUAL.1994.346319	http://dx.doi.org/10.1109/VISUAL.1994.346319	196	203	C		Cláudio T. Silva;Arie E. Kaufman	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;	10.1109/VISUAL.1992.235231;10.1109/VISUAL.1991.175777;10.1109/VISUAL.1994.346340		State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook
Vis	1994	Fast surface rendering from raster data by voxel traversal using chessboard distance	10.1109/VISUAL.1994.346320	http://dx.doi.org/10.1109/VISUAL.1994.346320	188	195, C21	C		Milos Srámek	Slovak Tech. Univ., Bratislava, Slovakia|c|	10.1109/VISUAL.1993.398852		Slovak Academy of Sciences
Vis	1994	Differential volume rendering: a fast volume visualization technique for flow animation	10.1109/VISUAL.1994.346321	http://dx.doi.org/10.1109/VISUAL.1994.346321	180	187, C20	C		Han-Wei Shen;Christopher R. Johnson 0001	Dept. of Comput. Sci., Utah Univ., Salt Lake City, UT, USA|c|;	10.1109/VISUAL.1993.398877;10.1109/VISUAL.1992.235227;10.1109/VISUAL.1992.235210;10.1109/VISUAL.1991.175772;10.1109/VISUAL.1993.398852;10.1109/VISUAL.1991.175773;10.1109/VISUAL.1993.398846		University of Utah Salt Lake City##University of Utah Salt Lake City
Vis	1994	Strata-various: multi-layer visualization of dynamics in software system behavior	10.1109/VISUAL.1994.346322	http://dx.doi.org/10.1109/VISUAL.1994.346322	172	178, C19	C		Doug Kimelman;Bryan S. Rosenburg;Tova Roth	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;			IBM Thomas J. Watson Research Center Yorktown Heights##IBM Thomas J. Watson Research Center Yorktown Heights##IBM Thomas J. Watson Research Center Yorktown Heights
Vis	1994	A library for visualizing combinatorial structures	10.1109/VISUAL.1994.346323	http://dx.doi.org/10.1109/VISUAL.1994.346323	164	171, C18	C		Marc Najork;Marc H. Brown	DEC Syst. Res. Center, Palo Alto, CA, USA|c|;			DEC Syst. Res. Center, Palo Alto, CA, USA|c|;
Vis	1994	Virtual reality performance for virtual geometry	10.1109/VISUAL.1994.346324	http://dx.doi.org/10.1109/VISUAL.1994.346324	156	163, C17	C		Robert A. Cross;Andrew J. Hanson	Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA|c|;	10.1109/VISUAL.1994.346330;10.1109/VISUAL.1993.398869;10.1109/VISUAL.1991.175821;10.1109/VISUAL.1992.235222		Indiana University Bloomington##Indiana University Bloomington
Vis	1994	GASP-a system for visualizing geometric algorithms	10.1109/VISUAL.1994.346325	http://dx.doi.org/10.1109/VISUAL.1994.346325	149	155, C16	C		Ayellet Tal;David P. Dobkin	Dept. of Comput. Sci., Princeton Univ., NJ, USA|c|;			Princeton University##Princeton University
Vis	1994	The topology of symmetric, second-order tensor fields	10.1109/VISUAL.1994.346326	http://dx.doi.org/10.1109/VISUAL.1994.346326	140	147, C15	C		Thierry Delmarcelle;Lambertus Hesselink	Dept. of Appl. Phys., Stanford Univ., CA, USA|c|;	10.1109/VISUAL.1991.175773		Dept. of Appl. Phys., Stanford Univ., CA, USA|c|;
Vis	1994	Vortex tubes in turbulent flows: identification, representation, reconstruction	10.1109/VISUAL.1994.346327	http://dx.doi.org/10.1109/VISUAL.1994.346327	132	139, C14	C		David C. Banks;Bart A. Singer	Inst. for Comput. Applications in Sci. & Eng., NASA Langley Res. Center, Hampton, VA, USA|c|;	10.1109/VISUAL.1991.175773		Inst. for Comput. Applications in Sci. & Eng., NASA Langley Res. Center, Hampton, VA, USA|c|;
Vis	1994	3D visualization of unsteady 2D airplane wake vortices	10.1109/VISUAL.1994.346328	http://dx.doi.org/10.1109/VISUAL.1994.346328	124	131, C13	C		Kwan-Liu Ma;Z. C. Zheng	Inst. for Comput. Applications in Sci. & Eng., NASA Langley Res. Center, Hampton, VA, USA|c|;			Inst. for Comput. Applications in Sci. & Eng., NASA Langley Res. Center, Hampton, VA, USA|c|;
Vis	1994	Feature detection from vector quantities in a numerically simulated hypersonic flow field in combination with experimental flow visualization	10.1109/VISUAL.1994.346329	http://dx.doi.org/10.1109/VISUAL.1994.346329	117	123, C12	C		Hans-Georg Pagendarm;Birgit Walter	DLR, German Aerosp. Res. Establ., Gottingen, Germany|c|;	10.1109/VISUAL.1992.235225		DLR, German Aerosp. Res. Establ., Gottingen, Germany|c|;
Vis	1994	Visualizing flow with quaternion frames	10.1109/VISUAL.1994.346330	http://dx.doi.org/10.1109/VISUAL.1994.346330	108	115, C11	C		Andrew J. Hanson;Hui Ma	Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA|c|;	10.1109/VISUAL.1993.398869;10.1109/VISUAL.1994.346324;10.1109/VISUAL.1992.235211		Indiana University Bloomington##Indiana University Bloomington
Vis	1994	An evaluation of reconstruction filters for volume rendering	10.1109/VISUAL.1994.346331	http://dx.doi.org/10.1109/VISUAL.1994.346331	100	107, C10	C		Steve Marschner;Richard Lobb	Program of Comput. Graphics, Cornell Univ., Ithaca, NY, USA|c|;	10.1109/VISUAL.1993.398851		Come11 University##Come11 University
Vis	1994	Progressive transmission of scientific data using biorthogonal wavelet transform	10.1109/VISUAL.1994.346332	http://dx.doi.org/10.1109/VISUAL.1994.346332	93	99, C9	C		Hai Tao;Robert J. Moorhead II	NSF Eng. Res. Center for Comput. Field Simulation, Mississippi Univ., MS, USA|c|;	10.1109/VISUAL.1993.398845		NSF Engineering Research Center for Computational Field Simulation##NSF Engineering Research Center for Computational Field Simulation
Vis	1994	Wavelet-based volume morphing	10.1109/VISUAL.1994.346333	http://dx.doi.org/10.1109/VISUAL.1994.346333	85	92, C8	C		Taosong He;Sidney W. Wang;Arie E. Kaufman	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;	10.1109/VISUAL.1993.398854		State University of New York at Stony Brook Stony Brook##
Vis	1994	Isosurface generation by using extrema graphs	10.1109/VISUAL.1994.346334	http://dx.doi.org/10.1109/VISUAL.1994.346334	77	83, C7	C		Takayuki Itoh;Koji Koyamada	Res. Lab., IBM Japan Ltd., Tokyo, Japan|c|;	10.1109/VISUAL.1992.235213;10.1109/VISUAL.1991.175780		Res. Lab., IBM Japan Ltd., Tokyo, Japan|c|;
Vis	1994	Triangulation and display of rational parametric surfaces	10.1109/VISUAL.1994.346335	http://dx.doi.org/10.1109/VISUAL.1994.346335	69	76, C6	C		Chandrajit L. Bajaj;Andrew V. Royappa	Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN, USA|c|;			Purdue University West Lafayette##Purdue University West Lafayette
Vis	1994	Piecewise-linear surface approximation from noisy scattered samples	10.1109/VISUAL.1994.346336	http://dx.doi.org/10.1109/VISUAL.1994.346336	61	68	C		Michael Margaliot;Craig Gotsman	Dept. of Electr. Eng., Technion-Israel Inst. of Technol., Haifa, Israel|c|;			Dept. of Electrical Engineering Technion -Israel Institute of Technology Haifa 32000
Vis	1994	Introducing alpha shapes for the analysis of path integral Monte Carlo results	10.1109/VISUAL.1994.346337	http://dx.doi.org/10.1109/VISUAL.1994.346337	52	59	C		Patrick J. Moran;Marcus Wagner	Dept. of Comput. Sci., Illinois Univ., Urbana, IL, USA|c|;			Dept. of Comput. Sci., Illinois Univ., Urbana, IL, USA|c|;
Vis	1994	Visualizing polycrystalline orientation microstructures with spherical color maps	10.1109/VISUAL.1994.346338	http://dx.doi.org/10.1109/VISUAL.1994.346338	46	51, C5	C		Boris Yamrom;John A. Sutliff;Andrew P. Woodfield	Gen. Electr. Corp. Res. & Dev. Center, Schenectady, NY, USA|c|;;	10.1109/VISUAL.1993.398867;10.1109/VISUAL.1990.146380		Gen. Electr. Corp. Res. & Dev. Center, Schenectady, NY, USA|c|;;
Vis	1994	Implicit modeling of swept surfaces and volumes	10.1109/VISUAL.1994.346339	http://dx.doi.org/10.1109/VISUAL.1994.346339	40	45, C4	C		William J. Schroeder;William E. Lorensen;Steve Linthicum	Gen. Electr. Corp. Res. & Dev. Center, Schenectady, NY, USA|c|;;			Gen. Electr. Corp. Res. & Dev. Center, Schenectady, NY, USA|c|;;
Vis	1994	VolVis: a diversified volume visualization system	10.1109/VISUAL.1994.346340	http://dx.doi.org/10.1109/VISUAL.1994.346340	31	38, C3	C		Ricardo S. Avila;Taosong He;Lichan Hong;Arie E. Kaufman;Hanspeter Pfister;Cláudio T. Silva;Lisa M. Sobierajski;Sidney W. Wang	Howard Hughes Med. Inst., State Univ. of New York, Stony Brook, NY, USA|c|;;;;;;;	10.1109/VISUAL.1992.235231;10.1109/VISUAL.1993.398862;10.1109/VISUAL.1993.398854;10.1109/VISUAL.1990.146391		Howard Hughes Medical Institute Stony Brook##University of New York at Stony Brook State University of New York at Stony Brook
Vis	1994	A distributed, parallel, interactive volume rendering package	10.1109/VISUAL.1994.346341	http://dx.doi.org/10.1109/VISUAL.1994.346341	21	30, C2	C		John S. Rowlan;G. Edward Lent;Nihar Gokhale;Shannon Bradshaw	Div. of Math. & Comput. Sci., Argonne Nat. Lab., IL, USA|c|;;;			Div. of Math. & Comput. Sci., Argonne Nat. Lab., IL, USA|c|;;;
Vis	1994	Integrated control of distributed volume visualization through the World-Wide-Web	10.1109/VISUAL.1994.346342	http://dx.doi.org/10.1109/VISUAL.1994.346342	13	20	C		Cheong S. Ang;David C. Martin;Michael D. Doyle	Libr. & Center for Knowledge Manage., California Univ., San Francisco, CA, USA|c|;;	10.1109/VISUAL.1992.235231		University of California##University of California##University of California##University of California##University of California
InfoVis	1995	Visualisation for functional design	10.1109/INFVIS.1995.528680	http://dx.doi.org/10.1109/INFVIS.1995.528680	4	10	C		Robert Spence;Lisa Tweedie;Huw Dawkes;Hua Su	Dept. of Electr. Eng., Imperial Coll. of Sci., Technol. & Med., London, UK|c|;;;			Imperial College of Science, Technology and Medicine London##Imperial College of Science, Technology and Medicine London##Imperial College of Science, Technology and Medicine London##Imperial College of Science, Technology and Medicine London
InfoVis	1995	Towards a generative theory of diagram design	10.1109/INFVIS.1995.528681	http://dx.doi.org/10.1109/INFVIS.1995.528681	11	18	C		Klaus Reichenberger;Thomas Kamps;Gene Golovchinsky	GMD-Inst. for Integrated Publication & Inf. Sci., Darmstadt, Germany|c|;;	10.1109/VISUAL.1995.480815		University of Toronto##University of Toronto##University of Toronto
InfoVis	1995	Research report: information animation applications in the capital markets	10.1109/INFVIS.1995.528682	http://dx.doi.org/10.1109/INFVIS.1995.528682	19	25	C		W. Wright	Visible Decisions Inc., Toronto, Ont., Canada|c|			Visible Decisions Inc. Toronto
InfoVis	1995	Research report: improving browsing in information by the automatic display layout	10.1109/INFVIS.1995.528683	http://dx.doi.org/10.1109/INFVIS.1995.528683	26	33	C		Peter Lüders;Rolf Ernst	Tech. Univ. Braunschweig, Germany|c|;			Technische Universitst Braunschweig##Technische Universitst Braunschweig
InfoVis	1995	SDM: malleable information graphics	10.1109/INFVIS.1995.528684	http://dx.doi.org/10.1109/INFVIS.1995.528684	36	42	C		Mei C. Chuah;Steven F. Roth;Joe Mattis;John Kolojejchick	Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA|c|;;;		Interactive techniques, visualization, direct manipulation	Carnegie Mellon University Pittsburgh##Carnegie Mellon University Pittsburgh##Carnegie Mellon University Pittsburgh##Carnegie Mellon University Pittsburgh
InfoVis	1995	The information mural: a technique for displaying and navigating large information spaces	10.1109/INFVIS.1995.528685	http://dx.doi.org/10.1109/INFVIS.1995.528685	43	50	C		Dean F. Jerding;John T. Stasko	Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;	10.1109/VISUAL.1994.346322		Usability Center College of Computing Georgia Institute of Technology##Usability Center College of Computing Georgia Institute of Technology
InfoVis	1995	Visualizing the non-visual: spatial analysis and interaction with information from text documents	10.1109/INFVIS.1995.528686	http://dx.doi.org/10.1109/INFVIS.1995.528686	51	58	C		James A. Wise;James J. Thomas;Kelly Pennock;D. Lantrip;M. Pottier;Anne Schur;V. Crow	Pacific Northwest Lab., Richland, WA, USA|c|;;;;;;	10.1109/VISUAL.1993.398863		Pacific Northwest Lab., Richland, WA, USA|c|;;;;;;
InfoVis	1995	VRMosaic: WEB access from within a virtual environment	10.1109/INFVIS.1995.528687	http://dx.doi.org/10.1109/INFVIS.1995.528687	59	64	C		Ian G. Angus;Henry Sowizral	Inf. & Support Services, Boeing Co., Seattle, WA, USA|c|;		Virtual Reality, Mosaic, User Interface Components	Boeing Information and Support Services##Boeing Information and Support Services
InfoVis	1995	IVEE: an Information Visualization and Exploration Environment	10.1109/INFVIS.1995.528688	http://dx.doi.org/10.1109/INFVIS.1995.528688	66	73	C		Christopher Ahlberg;Erik Wistrand	Dept. of Comput. Sci., Chalmers Univ. of Technol., Goteborg, Sweden|c|;	10.1109/VISUAL.1991.175815;10.1109/VISUAL.1993.398863		SSKKII Chalmers University of Technology##SSKKII Chalmers University of Technology
InfoVis	1995	Research report. Interacting with huge hierarchies: beyond cone trees	10.1109/INFVIS.1995.528689	http://dx.doi.org/10.1109/INFVIS.1995.528689	74	81	C		S. Jeromy Carrière;Rick Kazman	Dept. of Comput. Sci., Waterloo Univ., Ont., Canada|c|;			University of Waterloo##University of Waterloo
InfoVis	1995	Research report. DataSpace: 3-D visualizations of large databases	10.1109/INFVIS.1995.528690	http://dx.doi.org/10.1109/INFVIS.1995.528690	82	88	C		Vinod Anupam;Shaul Dar;Ted Leibfried;Eric Petajan	AT&T Bell Labs., Murray Hill, NJ, USA|c|;;;	10.1109/VISUAL.1994.346304		AT&T Bell Laboratories##University of Houston
InfoVis	1995	Case study. Narcissus: visualising information	10.1109/INFVIS.1995.528691	http://dx.doi.org/10.1109/INFVIS.1995.528691	90	96	C		Robert J. Hendley;Nick S. Drew;Andrew Wood;Russell Beale	Sch. of Comput. Sci., Birmingham Univ., UK|c|;;;			University of Birmingham##{R.J.Hendley
InfoVis	1995	Case study. Visualising cyberspace: information visualisation in the Harmony Internet browser	10.1109/INFVIS.1995.528692	http://dx.doi.org/10.1109/INFVIS.1995.528692	97	104	C		K. Andrews	Inst. for Inf. Process. & Comput. Supported New Media, Graz Univ. of Technol., Austria|c|	10.1109/VISUAL.1991.175815;10.1109/VISUAL.1992.235198		Graz University of Technology
InfoVis	1995	Case study: fishing for information on the Internet	10.1109/INFVIS.1995.528693	http://dx.doi.org/10.1109/INFVIS.1995.528693	105	111	C		R. Mitchell;David S. Day;Lynette Hirschman	Mitre Corp., Bedford, MA, USA|c|;;	10.1109/VISUAL.1991.175815		The MITRE Corporation Bedford##The MITRE Corporation Bedford##The MITRE Corporation Bedford
InfoVis	1995	Case study. A WWW viewpoint on scientific visualization: an EPA case study for technology transfer	10.1109/INFVIS.1995.528694	http://dx.doi.org/10.1109/INFVIS.1995.528694	112	114	C		Theresa-Marie Rhyne	Lockheed Martin, Research Triangle Park, NC, USA|c|	10.1109/VISUAL.1993.398874		U.S. EPA Scientific Visualization Center##U.S. EPA Scientific Visualization Center
InfoVis	1995	Case study: an empirical investigation of thumbnail image recognition	10.1109/INFVIS.1995.528695	http://dx.doi.org/10.1109/INFVIS.1995.528695	115	121	C		C. A. Burton;L. J. Johnston;E. A. Sonenberg	Melbourne Univ., Parkville, Vic., Australia|c|;;			The University of Melbourne##The University of Melbourne##The University of Melbourne
InfoVis	1995	Case study: visualizing Internet resources	10.1109/INFVIS.1995.528696	http://dx.doi.org/10.1109/INFVIS.1995.528696	122	128	C		Nahum D. Gershon;Joshua LeVasseur;Joel Winstead;J. Croall;A. Pernicks;William Ruh	Mitre Corp., McLean, VA, USA|c|;;;;;			The MITREC Corporation##The MITREC Corporation##The MITREC Corporation##The MITREC Corporation##The MITREC Corporation##The MITREC Corporation
InfoVis	1995	Case study: 3D displays of Internet traffic	10.1109/INFVIS.1995.528697	http://dx.doi.org/10.1109/INFVIS.1995.528697	129	131	C		Kenneth C. Cox;Stephen G. Eick	AT&T Bell Labs., Naperville, IL, USA|c|;	10.1109/VISUAL.1993.398870		AT&T Bell Labs., Naperville, IL, USA|c|;
Vis	1995	Interval set: a volume rendering technique generalizing isosurface extraction	10.1109/VISUAL.1995.480789	http://dx.doi.org/10.1109/VISUAL.1995.480789	3	10, 342	C		Baining Guo	Dept. of Comput. Sci., Toronto Univ., Ont., Canada|c|			University of Toronto Toronto
Vis	1995	Interactive maximum projection volume rendering	10.1109/VISUAL.1995.480790	http://dx.doi.org/10.1109/VISUAL.1995.480790	11	18, 433	C		Michael D. McCool;Wolfgang Heidrich;John Stevens	Comput. Graphics Lab., Waterloo Univ., Ont., Canada|c|;;			Toronto Western Hospital##Toronto Western Hospital##Toronto Western Hospital
Vis	1995	Interactive realism for visualization using ray tracing	10.1109/VISUAL.1995.480791	http://dx.doi.org/10.1109/VISUAL.1995.480791	19	26, 434	C		Robert A. Cross	Naval Res. Lab., Washington, DC, USA|c|			Naval Res. Lab., Washington, DC, USA|c|
Vis	1995	A hardware acceleration method for volumetric ray tracing	10.1109/VISUAL.1995.480792	http://dx.doi.org/10.1109/VISUAL.1995.480792	27	34, 435	C		Lisa M. Sobierajski;Ricardo S. Avila	Corp. Res. & Dev., Gen. Electr. Co., Schenectady, NY, USA|c|;	10.1109/VISUAL.1994.346320;10.1109/VISUAL.1995.485154;10.1109/VISUAL.1990.146391;10.1109/VISUAL.1993.398854;10.1109/VISUAL.1994.346340;10.1109/VISUAL.1992.235231		Corp. Res. & Dev., Gen. Electr. Co., Schenectady, NY, USA|c|;
Vis	1995	Defining, computing, and visualizing molecular interfaces	10.1109/VISUAL.1995.480793	http://dx.doi.org/10.1109/VISUAL.1995.480793	36	43, 436	C		Amitabh Varshney;Frederick P. Brooks Jr.;David C. Richardson;William V. Wright;Dinesh Manocha	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;;;	10.1109/VISUAL.1993.398878		State University of New York at Stony Brook University of North Carolina at Chapel Hill Stony Brook##########
Vis	1995	Visualization of biological sequence similarity search results	10.1109/VISUAL.1995.480794	http://dx.doi.org/10.1109/VISUAL.1995.480794	44	51, 437	C		Ed Huai-hsin Chi;Phillip Barry;Elizabeth Shoop;John V. Carlis;Ernest F. Retzel;John Riedl	Dept. of Comput. Sci., Minnesota Univ., Minneapolis, MN, USA|c|;;;;;	10.1109/VISUAL.1993.398883		University of Minnesota##University of Minnesota##University of Minnesota##University of Minnesota##University of Minnesota##University of Minnesota
Vis	1995	Enhancing transparent skin surfaces with ridge and valley lines	10.1109/VISUAL.1995.480795	http://dx.doi.org/10.1109/VISUAL.1995.480795	52	59, 438	C		Victoria Interrante;Henry Fuchs;Stephen M. Pizer	Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;			University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill
Vis	1995	Splatting of curvilinear volumes	10.1109/VISUAL.1995.480796	http://dx.doi.org/10.1109/VISUAL.1995.480796	61	68, 439	C		Xiaoyang Mao;Lichan Hong;Arie E. Kaufman	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;	10.1109/VISUAL.1992.235228;10.1109/VISUAL.1993.398853;10.1109/VISUAL.1994.346340		State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook
Vis	1995	On enhancing the speed of splatting with indexing	10.1109/VISUAL.1995.480797	http://dx.doi.org/10.1109/VISUAL.1995.480797	69	76, 441	C		Insung Ihm;Rae Kyoung Lee	Dept. of Comput. Sci., Sogang Univ., Seoul, South Korea|c|;	10.1109/VISUAL.1990.146377		Sogang University Seoul##Sogang University Seoul
Vis	1995	IFS fractal interpolation for 2D and 3D visualization	10.1109/VISUAL.1995.480798	http://dx.doi.org/10.1109/VISUAL.1995.480798	77	84, 441	C		Craig M. Wittenbrink	Baskin Center for Comput. Eng. & Inf. Sci., California Univ., Santa Cruz, CA, USA|c|			University of California
Vis	1995	Automated generation of visual simulation databases using remote sensing and GIS	10.1109/VISUAL.1995.480799	http://dx.doi.org/10.1109/VISUAL.1995.480799	86	93, 442	C		Martin Suter;Daniel Nüesch	Dept. of Geogr., Zurich Univ., Switzerland|c|;		remote sensing, geographic information systems,geographic databases,satellite images,classification, visual simulation, level of detail	University of Zurich##University of Zurich
Vis	1995	Virtual GIS: a real-time 3D geographic information system	10.1109/VISUAL.1995.480800	http://dx.doi.org/10.1109/VISUAL.1995.480800	94	100, 443	C		David Koller;Peter Lindstrom;William Ribarsky;Larry F. Hodges;Nickolas Faust;Gregory A. Turner	Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;;;;;			Usability Center##Tech Research Institute
Vis	1995	An architecture for retaining and analyzing visual explorations of databases	10.1109/VISUAL.1995.480801	http://dx.doi.org/10.1109/VISUAL.1995.480801	101	108	C		John Peter Lee;Georges G. Grinstein	Inst. for Visualization & Perception Res., Massachusetts Univ., Lowell, MA, USA|c|;	10.1109/VISUAL.1994.346304;10.1109/VISUAL.1994.346303;10.1109/VISUAL.1990.146375;10.1109/VISUAL.1992.235203;10.1109/VISUAL.1993.398874;10.1109/VISUAL.1993.398857	visual database exploration, database visualization, metadata, user modeling, interaction	The MITRB Corporation Bedford##University of Massachusetts Lowell Lowell
Vis	1995	An illustrated analysis of sonification for scientific visualisation	10.1109/VISUAL.1995.480802	http://dx.doi.org/10.1109/VISUAL.1995.480802	110	117	C		Rosane Minghim;A. Robin Forrest	Sch. of Inf. Syst., East Anglia Univ., Norwich, UK|c|;			University of East Anglia School of Information Systems Norwich##University of East Anglia School of Information Systems Norwich
Vis	1995	A rule-based tool for assisting colormap selection	10.1109/VISUAL.1995.480803	http://dx.doi.org/10.1109/VISUAL.1995.480803	118	125, 444	C		Lawrence D. Bergman;Bernice E. Rogowitz;Lloyd Treinish	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;	10.1109/VISUAL.1995.480821;10.1109/VISUAL.1993.398874		IBM Thomas J. Watson Research Center Yorktown Heights##IBM Thomas J. Watson Research Center Yorktown Heights##IBM Thomas J. Watson Research Center Yorktown Heights
Vis	1995	Space walking	10.1109/VISUAL.1995.480804	http://dx.doi.org/10.1109/VISUAL.1995.480804	126	133, 445	C		Andrew J. Hanson;Hui Ma	Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA|c|;	10.1109/VISUAL.1994.346324;10.1109/VISUAL.1992.235222		Indiana University##Indiana University
Vis	1995	Fast multiresolution surface meshing	10.1109/VISUAL.1995.480805	http://dx.doi.org/10.1109/VISUAL.1995.480805	135	142, 446	C		Markus H. Gross;Roger Gatti;Oliver G. Staadt	Dept. of Comput. Sci., Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;;	10.1109/VISUAL.1994.346333		ETH-Ziirich##ETH-Ziirich##ETH-Ziirich
Vis	1995	Sweeping simplices: a fast iso-surface extraction algorithm for unstructured grids	10.1109/VISUAL.1995.480806	http://dx.doi.org/10.1109/VISUAL.1995.480806	143	150, 447	C		Han-Wei Shen;Christopher R. Johnson 0001	Dept. of Comput. Sci., Utah Univ., Salt Lake City, UT, USA|c|;	10.1109/VISUAL.1991.175780		University of Utah Salt Lake City##University of Utah Salt Lake City
Vis	1995	Interval volume: a solid fitting technique for volumetric data display and analysis	10.1109/VISUAL.1995.480807	http://dx.doi.org/10.1109/VISUAL.1995.480807	151	158, 448	C		Issei Fujishiro;Yuji Maeda;Hiroshi Sato	Dept. of Inf. Sci., Ochanomizu Univ., Tokyo, Japan|c|;;	10.1109/VISUAL.1991.175782;10.1109/VISUAL.1992.235223	Volume visualization, surface fitting, isosurface, Marching cubes, atomic collision	Ochanomizu University University of Tsukuba Tokyo 112##
Vis	1995	Fast normal estimation using surface characteristics	10.1109/VISUAL.1995.480808	http://dx.doi.org/10.1109/VISUAL.1995.480808	159	166, 449	C		Byeong-Seok Shin;Yeong-Gil Shin	Dept. of Comput. Eng., Seoul Nat. Univ., South Korea|c|;	10.1109/VISUAL.1990.146378;10.1109/VISUAL.1993.398848		Seoul National University
Vis	1995	Compression domain rendering of time-resolved volume data	10.1109/VISUAL.1995.480809	http://dx.doi.org/10.1109/VISUAL.1995.480809	168	175, 450	C		Rüdiger Westermann	German Nat. Res. Center for Comput. Sci., St. Augustin, Germany|c|	10.1109/VISUAL.1990.146391;10.1109/VISUAL.1992.235230	volume rendering, wavelet transforms, singularities, Lipschitz exponents	Visualization and Media Systems Design German National Research Center for Computer Science Sankt Augustin
Vis	1995	High-speed volume rendering using redundant block compression	10.1109/VISUAL.1995.480810	http://dx.doi.org/10.1109/VISUAL.1995.480810	176	183, 451	C		Günter Knittel	Wilhelm-Schickard-Inst. fur Inf., Tubingen Univ., Germany|c|	10.1109/VISUAL.1993.398845;10.1109/VISUAL.1993.398852;10.1109/VISUAL.1992.235231		WSI I GRIS t University of Tiibingen
Vis	1995	Authenticity analysis of wavelet approximations in visualization	10.1109/VISUAL.1995.480811	http://dx.doi.org/10.1109/VISUAL.1995.480811	184	191, 452	C		Pak Chung Wong;R. Daniel Bergeron	Dept. of Comput. Sci., New Hampshire Univ., Durham, NH, USA|c|;	10.1109/VISUAL.1994.346333;10.1109/VISUAL.1994.346332		University of New Hampshire Durham##University of New Hampshire Durham
Vis	1995	Direct rendering of Laplacian pyramid compressed volume data	10.1109/VISUAL.1995.480812	http://dx.doi.org/10.1109/VISUAL.1995.480812	192	199	C		Mohammad H. Ghavamnia;Xue D. Yang	Dept. of Comput. Sci., Regina Univ., Sask., Canada|c|;	10.1109/VISUAL.1993.398845		University of Regina Regina
Vis	1995	Automatic generation of triangular irregular networks using greedy cuts	10.1109/VISUAL.1995.480813	http://dx.doi.org/10.1109/VISUAL.1995.480813	201	208, 453	C		Cláudio T. Silva;Joseph S. B. Mitchell;Arie E. Kaufman	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;	10.1109/VISUAL.1992.235191;10.1109/VISUAL.1990.146379		Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;
Vis	1995	Legibility enhancement for information visualisation	10.1109/VISUAL.1995.480814	http://dx.doi.org/10.1109/VISUAL.1995.480814	209	216, 454	C		Rob Ingram;Steve Benford	Dept. of Comput. Sci., Nottingham Univ., UK|c|;			The University of Nottingham Nottingham##The University of Nottingham Nottingham
Vis	1995	Subverting structure: data-driven diagram generation	10.1109/VISUAL.1995.480815	http://dx.doi.org/10.1109/VISUAL.1995.480815	217	223, 455	C		Gene Golovchinsky;Klaus Reichenberger;Thomas Kamps	Dept. of Ind. Eng., Toronto Univ., Ont., Canada|c|;;	10.1109/INFVIS.1995.528681		University of Toronto
Vis	1995	A model and a system for data-parallel program visualization	10.1109/VISUAL.1995.480816	http://dx.doi.org/10.1109/VISUAL.1995.480816	224	231, 456	C		Thomas A. Wagner;R. Daniel Bergeron	Massachusetts Univ., Amherst, MA, USA|c|;	10.1109/VISUAL.1991.175809		University of Massachusetts at Amherst##University of Massachusetts at Amherst
Vis	1995	Enhanced spot noise for vector field visualization	10.1109/VISUAL.1995.480817	http://dx.doi.org/10.1109/VISUAL.1995.480817	233	239, 457	C		Wim C. de Leeuw;Jarke J. van Wijk	Fac. of Tech. Math. & Inf., Delft Univ. of Technol., Netherlands|c|;	10.1109/VISUAL.1994.346312;10.1109/VISUAL.1994.346313;10.1109/VISUAL.1993.398877		Delft University of Technology##Delft University of Technology
Vis	1995	Interactive visualization of mixed scalar and vector fields	10.1109/VISUAL.1995.480818	http://dx.doi.org/10.1109/VISUAL.1995.480818	240	247, 458	C		Lichan Hong;Xiaoyang Mao;Arie E. Kaufman	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;	10.1109/VISUAL.1993.398849;10.1109/VISUAL.1994.346340;10.1109/VISUAL.1993.398877;10.1109/VISUAL.1992.235227;10.1109/VISUAL.1992.235210;10.1109/VISUAL.1994.346321;10.1109/VISUAL.1991.175789		State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook
Vis	1995	Vector plots for irregular grids	10.1109/VISUAL.1995.480819	http://dx.doi.org/10.1109/VISUAL.1995.480819	248	253, 459	C		Don Dovey	Lawrence Livermore Nat. Lab., CA, USA|c|	10.1109/VISUAL.1993.398877;10.1109/VISUAL.1994.346313;10.1109/VISUAL.1994.346312		Lawrence Livermore Nat. Lab., CA, USA|c|
Vis	1995	Tensor product surfaces guided by minimal surface area triangulations	10.1109/VISUAL.1995.480820	http://dx.doi.org/10.1109/VISUAL.1995.480820	254	261, 460	C		John K. Johnstone;Kenneth R. Sloan	Dept. of Comput. & Inf. Sci., Alabama Univ., Birmingham, AL, USA|c|;		surface reconstruction, contour data, minimum area triangulation, Bezier surface, biomedical visualization	University of Alabama at Birmingham 115A Campbell Hall##University of Alabama at Birmingham 115A Campbell Hall
Vis	1995	An extended data-flow architecture for data analysis and visualization	10.1109/VISUAL.1995.480821	http://dx.doi.org/10.1109/VISUAL.1995.480821	263	270, 461	C		Greg Abram;Lloyd Treinish	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;	10.1109/VISUAL.1994.346305;10.1109/VISUAL.1993.398860;10.1109/VISUAL.1991.175818;10.1109/VISUAL.1992.235219		IBM Thomas J. Watson Research Center Post Office##IBM Thomas J. Watson Research Center Post Office
Vis	1995	High Dimensional Brushing for Interactive Exploration of Multivariate Data	10.1109/VISUAL.1995.485139	http://dx.doi.org/10.1109/VISUAL.1995.485139	271		C		Allen R. Martin;Matthew O. Ward	;	10.1109/VISUAL.1990.146386;10.1109/VISUAL.1990.146402;10.1109/VISUAL.1994.346302		
Vis	1995	Recursive pattern: a technique for visualizing very large amounts of data	10.1109/VISUAL.1995.485140	http://dx.doi.org/10.1109/VISUAL.1995.485140	279	286, 463	C		Daniel A. Keim;Mihael Ankerst;Hans-Peter Kriegel	Inst. for Comput. Sci., Munchen Univ., Germany|c|;;	10.1109/VISUAL.1990.146402;10.1109/INFVIS.1995.528688;10.1109/VISUAL.1991.175809;10.1109/VISUAL.1990.146386;10.1109/VISUAL.1990.146387;10.1109/VISUAL.1990.146389	Visualizing Large Data Sets, Visualizing Multidimensional and Multivariate Data, Visualizing Large Sequential Data Sets, Recursive Visualization Techniques, Interfaces to Databases	University of Munich Leopoldstr. llB##University of Munich Leopoldstr. llB##University of Munich Leopoldstr. llB
Vis	1995	Iconic techniques for feature visualization	10.1109/VISUAL.1995.485141	http://dx.doi.org/10.1109/VISUAL.1995.485141	288	295, 464	C		Frank J. Post;Theo van Walsum;Frits H. Post;Deborah Silver	Fac. of Tech. Math. & Inf., Delft Univ. of Technol., Netherlands|c|;;;	10.1109/VISUAL.1993.398849;10.1109/VISUAL.1991.175809;10.1109/VISUAL.1992.235174	scientific visualization, feature extraction, iconic visualization, attribute calculation	Delft University of Technology##Delft University of Technology##Delft University of Technology##Delft University of Technology##Delft University of Technology
Vis	1995	Voxel based object simplification	10.1109/VISUAL.1995.485142	http://dx.doi.org/10.1109/VISUAL.1995.485142	296	303, 465	C		Taosong He;Lichan Hong;Arie E. Kaufman;Amitabh Varshney;Sidney W. Wang	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;;;	10.1109/VISUAL.1992.235229		State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook
Vis	1995	3D computational steering with parametrized geometric objects	10.1109/VISUAL.1995.485143	http://dx.doi.org/10.1109/VISUAL.1995.485143	304	311, 466	C		Jurriaan D. Mulder;Jarke J. van Wijk	Centre for Math. & Comput. Sci., CWI, Amsterdam, Netherlands|c|;	10.1109/VISUAL.1991.175812;10.1109/VISUAL.1993.398895;10.1109/VISUAL.1990.146382		Centre for Math. & Comput. Sci., CWI, Amsterdam, Netherlands|c|;
Vis	1995	Fast Algorithms for Visualizing Fluid Motion in Steady Flow on Unstructured Grids	10.1109/VISUAL.1995.485144	http://dx.doi.org/10.1109/VISUAL.1995.485144	313		C		Shyh-Kuang Ueng;Kris Sikorski;Kwan-Liu Ma	;;	10.1109/VISUAL.1992.235211;10.1109/VISUAL.1994.346329;10.1109/VISUAL.1991.175789;10.1109/VISUAL.1993.398876		University of Utah Salt Lake City##University of Utah Salt Lake City
Vis	1995	Optimization of time-dependent particle tracing using tetrahedral decomposition	10.1109/VISUAL.1995.485145	http://dx.doi.org/10.1109/VISUAL.1995.485145	321	328, 468	C		David N. Kenwright;David A. Lane	Comput. Sci. Corp., NASA Ames Res. Center, Moffett Field, CA, USA|c|;	10.1109/VISUAL.1993.398848;10.1109/VISUAL.1991.175771		Computer Sciences Corporation##Computer Sciences Corporation
Vis	1995	Unsteady flow volumes	10.1109/VISUAL.1995.485146	http://dx.doi.org/10.1109/VISUAL.1995.485146	329	335, 469	C		Barry G. Becker;Nelson L. Max;David A. Lane	Lawrence Livermore Nat. Lab., CA, USA|c|;;	10.1109/VISUAL.1992.235226;10.1109/VISUAL.1992.235227;10.1109/VISUAL.1994.346311;10.1109/VISUAL.1993.398876;10.1109/VISUAL.1993.398875;10.1109/VISUAL.1993.398846;10.1109/VISUAL.1992.235211;10.1109/VISUAL.1993.398877		NASA Ames Research Center
Vis	1995	Propositional n-traces: visualizing a problem in philosophical logic	10.1109/VISUAL.1995.485147	http://dx.doi.org/10.1109/VISUAL.1995.485147	338	341, 470	C		Nathalie Prevost;Ray E. Jennings;Loki Jörgenson;F. David Fracchia	Dept. of Philos., Simon Fraser Univ., Burnaby, BC, Canada|c|;;;	10.1109/VISUAL.1993.398863		Simon Fraser University##Simon Fraser University##Simon Fraser University##Simon Fraser University
Vis	1995	Qualitative analysis of invariant tori in a dynamical system	10.1109/VISUAL.1995.485148	http://dx.doi.org/10.1109/VISUAL.1995.485148	342	345, 471	C		Daryl H. Hepting;Gianne Derks;Kossi D. Edoh;Robert D. Russell	Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada|c|;;;			Simon Fraser University Burnaby
Vis	1995	Pictorial statistics-visualization of high-dimensional statistical distributions	10.1109/VISUAL.1995.485149	http://dx.doi.org/10.1109/VISUAL.1995.485149	346	349	C		Andreas A. Müller	IWSP, Gottingen Univ., Germany|c|			IWSP
Vis	1995	Visualization for aerodynamic design of helicopter rotor blades	10.1109/VISUAL.1995.485150	http://dx.doi.org/10.1109/VISUAL.1995.485150	351	354, 472	C		G. David Kerlick	Boeing Inf. & Support Services Res. & Technol., Bellevue, WA, USA|c|			Boeing Information and Support Services, Research and Technology
Vis	1995	Visualization of high speed aerodynamic configuration design	10.1109/VISUAL.1995.485151	http://dx.doi.org/10.1109/VISUAL.1995.485151	355	358, 473	C		Monika Hannemann;Helmut Sobieczky	German Aerosp. Res. Establ., Gottingen, Germany|c|;	10.1109/VISUAL.1993.398894		German Aerosp. Res. Establ., Gottingen, Germany|c|;
Vis	1995	Volume-based reasoning and visualization of diecastability	10.1109/VISUAL.1995.485152	http://dx.doi.org/10.1109/VISUAL.1995.485152	359	362, 474	C		Roni Yagel;Shao-Chiung Lu;Alec B. Rebello;R. A. Miller	Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA|c|;;;			The Ohio State University##The Ohio State University##The Ohio State University##The Ohio State University
Vis	1995	A visualization tool for studying the development of the moss Physcomitrella patens	10.1109/VISUAL.1995.485153	http://dx.doi.org/10.1109/VISUAL.1995.485153	364	367, 475	C		F. David Fracchia;Neil W. Ashton	Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada|c|;			Simon Fraser University Burnaby
Vis	1995	Marching through the Visible Man	10.1109/VISUAL.1995.485154	http://dx.doi.org/10.1109/VISUAL.1995.485154	368	373, 476	C		William E. Lorensen	Corp. Res. & Dev., Gen. Electr. Co., Schenectady, NY, USA|c|	10.1109/VISUAL.1992.235205		Corp. Res. & Dev., Gen. Electr. Co., Schenectady, NY, USA|c|
Vis	1995	Astronomers and their shady algorithms	10.1109/VISUAL.1995.485155	http://dx.doi.org/10.1109/VISUAL.1995.485155	374	377, 477	C		Richard Gooch	CSIRO Australia Telescope Nat. Facility, Sydney, NSW, Australia|c|			Macquarie University Sydney##Macquarie University Sydney
Vis	1995	Flow visualization in a hypersonic fin/ramp flow	10.1109/VISUAL.1995.485156	http://dx.doi.org/10.1109/VISUAL.1995.485156	379	382, 478	C		Hans-Georg Pagendarm;Thomas Gerhold	German Aerosp. Res. Establ., Gottingen, Germany|c|;	10.1109/VISUAL.1994.346329;10.1109/VISUAL.1993.398875		German Aerosp. Res. Establ., Gottingen, Germany|c|;
Vis	1995	Case study: an integrated approach for steering, visualization, and analysis of atmospheric simulations	10.1109/VISUAL.1995.485157	http://dx.doi.org/10.1109/VISUAL.1995.485157	383	387, 479	C		Yves Jean;Thomas Kindler;William Ribarsky;Weiming Gu;Greg Eisenhauer;Karsten Schwan;Fred Alyea	Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;;;;;;			Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;;;;;;
Vis	1995	Turbulent flow visualization in computational and experimental hydraulics	10.1109/VISUAL.1995.485158	http://dx.doi.org/10.1109/VISUAL.1995.485158	388	391, 480	C		A. E. Mynett;I. Ari Sadarjoen;A. J. S. Hin	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;;;			Delft University of Technology University of Groningen##Delft University of Technology University of Groningen##Delft University of Technology University of Groningen
Vis	1995	Interactive 3D visualization of actual anatomy and simulated chemical time-course data for fish	10.1109/VISUAL.1995.485169	http://dx.doi.org/10.1109/VISUAL.1995.485169	393	396, 481	C		Penny Rheingans;John Nichols	Sci. Visualization Lab., US Environ. Protection Agency, Research Triangle Park, NC, USA|c|;;			EPA Scientific Visualization Laboratory Research Triangle Park##EPA Scientific Visualization Laboratory Research Triangle Park
Vis	1995	Visualizing the tracking and diving behavior of marine mammals: a case study	10.1109/VISUAL.1995.485170	http://dx.doi.org/10.1109/VISUAL.1995.485170	397	399, 482	C		Guy W. Oliver	Long Marine Lab., California Univ., Santa Cruz, CA, USA|c|			University Iof California
Vis	1995	Case study: using spatial access methods to support the visualization of environmental data	10.1109/VISUAL.1995.485171	http://dx.doi.org/10.1109/VISUAL.1995.485171	400	403, 483	C		Charles Falkenberg;Ravi Kulkarni	Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA|c|;			Visualization Laboratory University of Maryland College Park
InfoVis	1996	Visage: a user interface environment for exploring information	10.1109/INFVIS.1996.559210	http://dx.doi.org/10.1109/INFVIS.1996.559210	3	12, 116	C		Steven F. Roth;Peter Lucas 0002;Jeffrey Senn;Cristina C. Gomberg;Michael B. Burks;Philip J. Stroffolino;John A. Kolojechick;Carolyn Dunmire	Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA|c|;;;;;;;	10.1109/VISUAL.1993.398870;10.1109/VISUAL.1991.175815	Visualization, exploratory data analysis, graphics, user interface environment, human-computer interaction	MAYA Design Group, Inc##Carnegie Mellon University
InfoVis	1996	Data characterization for automatically visualizing heterogeneous information	10.1109/INFVIS.1996.559211	http://dx.doi.org/10.1109/INFVIS.1996.559211	13	20, 117	C		Michelle X. Zhou;Steven K. Feiner	Dept. of Comput. Sci., Columbia Univ., New York, NY, USA|c|;	10.1109/VISUAL.1990.146375		Columbia University##Columbia University
InfoVis	1996	Rapid prototyping of information visualizations using VANISH	10.1109/INFVIS.1996.559212	http://dx.doi.org/10.1109/INFVIS.1996.559212	21	28, 118	C		Rick Kazman;S. Jeromy Carrière	Dept. of Comput. Sci., Waterloo Univ., Ont., Canada|c|;	10.1109/INFVIS.1995.528688;10.1109/INFVIS.1995.528689;10.1109/VISUAL.1991.175815	information visualization, software tools, visual programming languages	University of Waterloo Waterloo##University of Waterloo Waterloo
InfoVis	1996	On the semantics of interactive visualizations	10.1109/INFVIS.1996.559213	http://dx.doi.org/10.1109/INFVIS.1996.559213	29	36	C		Mei C. Chuah;Steven F. Roth	Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA|c|;	10.1109/INFVIS.1995.528684;10.1109/INFVIS.1996.559210	information visualization, interactive techniques, user interfaces, automatic presentation systems, graphics	Carnegie Mellon University Pittsburgh##Carnegie Mellon University Pittsburgh
InfoVis	1996	Techniques for non-linear magnification transformations	10.1109/INFVIS.1996.559214	http://dx.doi.org/10.1109/INFVIS.1996.559214	38	45	C		Alan Keahey;Edward L. Robertson	Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA|c|;			Indiana University##Indiana University
InfoVis	1996	Distortion viewing techniques for 3-dimensional data	10.1109/INFVIS.1996.559215	http://dx.doi.org/10.1109/INFVIS.1996.559215	46	53, 119	C		M. Sheelagh T. Carpendale;David J. Cowperthwaite;F. David Fracchia	Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada|c|;;		distortion viewing, screen layout, 3D interaction, information visualization, interface metaphors, interface design issues	Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada|c|;;
InfoVis	1996	Selection: 524,288 ways to say "this is interesting"	10.1109/INFVIS.1996.559216	http://dx.doi.org/10.1109/INFVIS.1996.559216	54	60, 120	C		Graham J. Wills	AT&T Bell Labs., Naperville, IL, USA|c|			AT&T Bell Labs., Naperville, IL, USA|c|
InfoVis	1996	Towards rich information landscapes for visualising structured Web spaces	10.1109/INFVIS.1996.559218	http://dx.doi.org/10.1109/INFVIS.1996.559218	62	63, 121	M		Keith Andrews;Michael Pichler;Peter Wolf	Inst. for Inf. & Comput. Supported New Media, Graz Univ. of Technol., Austria|c|;;			Inst. for Inf. & Comput. Supported New Media, Graz Univ. of Technol., Austria|c|;;
InfoVis	1996	Visualizing the results of multimedia Web search engines	10.1109/INFVIS.1996.559219	http://dx.doi.org/10.1109/INFVIS.1996.559219	64	65, 122	M		Sougata Mukherjea;Kyoji Hirata;Yoshinori Hara	C&C Res. Lab., NEC USA Inc., USA|c|;;			NEC USA Inc##NEC USA Inc##NEC USA Inc
InfoVis	1996	Minimally-immersive interactive volumetric information visualization	10.1109/INFVIS.1996.559220	http://dx.doi.org/10.1109/INFVIS.1996.559220	66	67, 123	M		David S. Ebert;Chris Shaw 0002;Amen Zwa;Ethan L. Miller;D. Aaron Roberts	Maryland Univ., Baltimore, MD, USA|c|;;;;			U. of Maryland Baltimore County##U. of Maryland Baltimore County##U. of Maryland Baltimore County##U. of Maryland Baltimore County##U. of Maryland Baltimore County
InfoVis	1996	Interactive visualization of multiway tables	10.1109/INFVIS.1996.559221	http://dx.doi.org/10.1109/INFVIS.1996.559221	68	69, 124	M		Kenneth C. Cox;Dianne Hackborn	Lucent Technol., Bell Labs., Naperville, IL, USA|c|;			Lucent Technologies##Oregon State University Corvallis
InfoVis	1996	FINESSE: a financial information spreadsheet	10.1109/INFVIS.1996.559222	http://dx.doi.org/10.1109/INFVIS.1996.559222	70	71, 125	M		Amitabh Varshney;Arie E. Kaufman	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;			State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook
InfoVis	1996	Animating multidimensional scaling to visualize N-dimensional data sets	10.1109/INFVIS.1996.559223	http://dx.doi.org/10.1109/INFVIS.1996.559223	72	73, 126	M		Chris Bentley;Matthew O. Ward	Dept. of Comput. Sci., Worcester Polytech. Inst., MA, USA|c|;			Dept. of Comput. Sci., Worcester Polytech. Inst., MA, USA|c|;
InfoVis	1996	Dual multiresolution HyperSlice for multivariate data visualization	10.1109/INFVIS.1996.559224	http://dx.doi.org/10.1109/INFVIS.1996.559224	74	75, 127	M		Pak Chung Wong;Andrew H. Crabb;R. Daniel Bergeron	Dept. of Comput. Sci., New Hampshire Univ., Durham, NH, USA|c|;;			University of N e w Hampshire##University of N e w Hampshire##University of N e w Hampshire
InfoVis	1996	Geospatial metadata querying and visualization on the WWW using Java<sup>TM</sup> applets	10.1109/INFVIS.1996.559225	http://dx.doi.org/10.1109/INFVIS.1996.559225	77	84, 128	C		Naim Alper;Chuck Stein	Mar Inc., USA|c|;	10.1109/INFVIS.1995.528686;10.1109/INFVIS.1995.528682		Mar Inc., USA|c|;
InfoVis	1996	Visualizing the global topology of the MBone	10.1109/INFVIS.1996.559226	http://dx.doi.org/10.1109/INFVIS.1996.559226	85	92, 129	C		Tamara Munzner;Eric Hoffman;Kimberly C. Claffy;Bill Fenner	Stanford Univ., CA, USA|c|;;;	10.1109/INFVIS.1995.528697		Stanford University * Ipsilon + NLANR Xerox PARC##Stanford University * Ipsilon + NLANR Xerox PARC##Stanford University * Ipsilon + NLANR Xerox PARC##Stanford University * Ipsilon + NLANR Xerox PARC
InfoVis	1996	Visualizing usability log data	10.1109/INFVIS.1996.559227	http://dx.doi.org/10.1109/INFVIS.1996.559227	93	98, 130	C		Mark Gray;Albert N. Badre;Mark Guzdial	Coll. of Comput., Georgia Univ., Athens, GA, USA|c|;;			Coll. of Comput., Georgia Univ., Athens, GA, USA|c|;;
InfoVis	1996	DEPICT: Documents Evaluated as Pictures. Visualizing information using context vectors and self-organizing maps	10.1109/INFVIS.1996.559228	http://dx.doi.org/10.1109/INFVIS.1996.559228	100	107, 131	C		David A. Rushall;Marc R. Ilgen	HNC Software Inc., San Diego, CA, USA|c|;			HNC Software, Inc##HNC Software, Inc
InfoVis	1996	Visualizing a tennis match	10.1109/INFVIS.1996.559229	http://dx.doi.org/10.1109/INFVIS.1996.559229	108	114, 132	C		Liqun Jin;David C. Banks	Dept. of Comput. Sci., Mississippi State Univ., MS, USA|c|;	10.1109/VISUAL.1991.175815		Mississippi State University Mississippi State##Mississippi State University Mississippi State
Vis	1996	Anatomy-based facial tissue modeling using the finite element method	10.1109/VISUAL.1996.567595	http://dx.doi.org/10.1109/VISUAL.1996.567595	21	28	C		Erwin Keeve;Sabine Girod;Paula Pfeifle;Bernd Girod	Telecommun. Inst., Erlangen-Nurnberg Univ., Germany|c|;;;		human facial modeling, finite element method, computer-aided surgery, surgery planning and simulation	University of Erlangen##University of Erlangen-Nuremberg##University of Erlangen##University of Erlangen
Vis	1996	A fast Gibbs sampler for synthesizing constrained fractals	10.1109/VISUAL.1996.567598	http://dx.doi.org/10.1109/VISUAL.1996.567598	29	35	C		Baba C. Vemuri;Chhandomay Mandal	Dept. of Comput. & Inf. Sci., Florida Univ., Gainesville, FL, USA|c|;			University of Florida##University of Florida
Vis	1996	Temporal continuity of levels of detail in Delaunay triangulated terrain	10.1109/VISUAL.1996.567600	http://dx.doi.org/10.1109/VISUAL.1996.567600	37	42	C		Daniel Cohen-Or;Yishay Levanoni	Sch. of Math. Sci., Tel Aviv Univ., Israel|c|;			Tel-Aviv University##Tel-Aviv University
Vis	1996	BLaC-wavelets: a multiresolution analysis with non-nested spaces	10.1109/VISUAL.1996.567602	http://dx.doi.org/10.1109/VISUAL.1996.567602	43	48	C		Georges-Pierre Bonneau;Stefanie Hahmann;Gregory M. Nielson	Lab. LMC, CNRS, Grenoble, France|c|;;			CNRS##CNRS##CNRS
Vis	1996	Fast stereo volume rendering	10.1109/VISUAL.1996.567603	http://dx.doi.org/10.1109/VISUAL.1996.567603	49	56	C		Taosong He;Arie E. Kaufman	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;	10.1109/VISUAL.1994.346340		State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook
Vis	1996	Hierarchical and parallelizable direct volume rendering for irregular and multiple grids	10.1109/VISUAL.1996.567606	http://dx.doi.org/10.1109/VISUAL.1996.567606	57	63	C		Jane Wilhelms;Allen Van Gelder;Paul Tarantino;Jonathan Gibbs	California Univ., Santa Cruz, CA, USA|c|;;;	10.1109/VISUAL.1992.235204;10.1109/VISUAL.1993.398853;10.1109/VISUAL.1995.480796;10.1109/VISUAL.1992.235228	Computer Graphics, Scientific Visualization, Scanline, Direct Volume Rendering, Curvilinear Grid, Irregular Grid, k-D Tree	University of California##University of California##University of California##University of California
Vis	1996	Fast Perspective Volume Rendering with Splatting by Utilizing a Ray-Driven Approach	10.1109/VISUAL.1996.567608	http://doi.ieeecomputersociety.org/10.1109/VISUAL.1996.567608	65	72	C		Klaus Mueller;Roni Yagel	The Ohio State University, Columbus, OH, USA	10.1109/VISUAL.1995.480792;10.1109/VISUAL.1993.398877;10.1109/VISUAL.1993.398852		The Ohio State University, Columbus, OH, USA
Vis	1996	Deformable volume rendering by 3D texture mapping and octree encoding	10.1109/VISUAL.1996.567609	http://dx.doi.org/10.1109/VISUAL.1996.567609	73	80	C		Shiaofen Fang;Rajagopalan Srinivasan;Su Huang;Raghu Raghavan	Nat. Univ. of Singapore, Singapore|c|;;;	10.1109/VISUAL.1994.346333	Volume Rendering, 3D Texture Mapping, Morphing, Volume Deformation, Octree, Scientific Visualization	National University of Singapore##National University of Singapore##National University of Singapore##National University of Singapore
Vis	1996	Visualization over the World Wide Web and its application to environmental data	10.1109/VISUAL.1996.567610	http://dx.doi.org/10.1109/VISUAL.1996.567610	81	86	C		Jason D. Wood;Ken Brodlie;Helen Wright	Leeds Univ., UK|c|;;	10.1109/VISUAL.1994.346342		University of Leeds##University of Leeds##University of Leeds
Vis	1996	Cheops: a compact explorer for complex hierarchies	10.1109/VISUAL.1996.567745	http://dx.doi.org/10.1109/VISUAL.1996.567745	87	92	C		Luc Beaudoin;Marc-Antoine Parent;Louis C. Vroomen	Centre de Recherche Inf. de Montreal, Que.,, Canada|c|;;	10.1109/INFVIS.1995.528689	Hierarchical representation, information visualization and exploration, focus+context techniques, graphical browser	McGill College##McGill College##McGill College
Vis	1996	The Design and Implementation of an Object-Oriented Toolkit for 3D Graphics and Visualization	10.1109/VISUAL.1996.567752	http://doi.ieeecomputersociety.org/10.1109/VISUAL.1996.567752	93	100	C		William J. Schroeder;Ken Martin;William E. Lorensen		10.1109/VISUAL.1993.398878;10.1109/VISUAL.1994.346303;10.1109/VISUAL.1992.235205;10.1109/VISUAL.1995.480821		
Vis	1996	Visualization of Complex Models Using Dynamic Texture-based Simplification	10.1109/VISUAL.1996.567774	http://doi.ieeecomputersociety.org/10.1109/VISUAL.1996.567774	101	106	C		Daniel G. Aliaga	University of North Carolina at Chapel Hill			University of North Carolina at Chapel Hill
Vis	1996	Interactive visualization of 3D-vector fields using illuminated stream lines	10.1109/VISUAL.1996.567777	http://dx.doi.org/10.1109/VISUAL.1996.567777	107	113	C		Malte Zöckler;Detlev Stalling;Hans-Christian Hege	Konrad-Zuse-Zentrum fur Informationstech., Berlin, Germany|c|;;	10.1109/VISUAL.1993.398850;10.1109/VISUAL.1993.398849;10.1109/VISUAL.1994.346312;10.1109/VISUAL.1992.235226;10.1109/VISUAL.1995.485141;10.1109/VISUAL.1992.235227;10.1109/VISUAL.1994.346313;10.1109/VISUAL.1995.480817;10.1109/VISUAL.1993.398877		Konrad-Zuse-Zentrum fur Informationstech., Berlin, Germany|c|;;
Vis	1996	Raycasting vector fields	10.1109/VISUAL.1996.567780	http://dx.doi.org/10.1109/VISUAL.1996.567780	115	120	C		Thomas Frühauf	Fraunhofer Inst. for Comput. Graphics, Darmstadt, Germany|c|	10.1109/VISUAL.1993.398875;10.1109/VISUAL.1993.398853;10.1109/VISUAL.1993.398877;10.1109/VISUAL.1992.235228;10.1109/VISUAL.1995.480818		Fraunhofer Inst. for Comput. Graphics, Darmstadt, Germany|c|
Vis	1996	Multi-frequency noise for LIC	10.1109/VISUAL.1996.567784	http://dx.doi.org/10.1109/VISUAL.1996.567784	121	126	C		Ming-Hoe Kiu;David C. Banks	Dept. of Electr. Eng., Mississippi State Univ., MS, USA|c|;	10.1109/VISUAL.1994.346313		Dept. of Electr. Eng., Mississippi State Univ., MS, USA|c|;
Vis	1996	A linear iteration time layout algorithm for visualising high-dimensional data	10.1109/VISUAL.1996.567787	http://dx.doi.org/10.1109/VISUAL.1996.567787	127	131	C		Matthew Chalmers	Union Bank of Switzerland, Switzerland|c|	10.1109/INFVIS.1995.528686;10.1109/VISUAL.1995.480814	layout algorithms, visualization, high-dimensional data, spring models, stochastic algorithms, force-directed placement	Union Bank of Switzerland, Switzerland|c|
Vis	1996	Flexible information visualization of multivariate data from biological sequence similarity searches	10.1109/VISUAL.1996.567796	http://dx.doi.org/10.1109/VISUAL.1996.567796	133	140	C		Ed Huai-hsin Chi;John Riedl;Elizabeth Shoop;John V. Carlis;Ernest F. Retzel;Phillip Barry	Dept. of Comput. Sci., Minnesota Univ. Med. Sch., Minneapolis, MN, USA|c|;;;;;	10.1109/VISUAL.1993.398883;10.1109/VISUAL.1990.146402;10.1109/VISUAL.1995.480794	Information Visualization, Biomedical Visualization, Multimodal and Multidimensional Visualization, Applications of Visualization	University of Minnesota Computational Biology Centers##University of Minnesota Computational Biology Centers##University of Minnesota Computational Biology Centers##University of Minnesota Computational Biology Centers##University of Minnesota Computational Biology Centers##University of Minnesota Computational Biology Centers
Vis	1996	Multiresolution multidimensional wavelet brushing	10.1109/VISUAL.1996.567800	http://dx.doi.org/10.1109/VISUAL.1996.567800	141	148	C		Pak Chung Wong;R. Daniel Bergeron	Dept. of Comput. Sci., New Hampshire Univ., Durham, NH, USA|c|;	10.1109/VISUAL.1990.146386;10.1109/VISUAL.1993.398864;10.1109/VISUAL.1995.480811;10.1109/VISUAL.1994.346302;10.1109/VISUAL.1995.485139;10.1109/VISUAL.1990.146402		University of New Hampshire
Vis	1996	History consideration in reconstructing polyhedral surfaces from parallel slices	10.1109/VISUAL.1996.567804	http://dx.doi.org/10.1109/VISUAL.1996.567804	149	156	C		Gill Barequet;Daniel Shapiro;Ayellet Tal	Tel Aviv Univ., Israel|c|;;		reconstruction, interpolation, triangulation	Tel Aviv Univ., Israel|c|;;
Vis	1996	Volume tracking	10.1109/VISUAL.1996.567807	http://dx.doi.org/10.1109/VISUAL.1996.567807	157	164	C		Deborah Silver;Xin Wang	Dept. of Electr. & Comput. Eng., Rutgers Univ., Piscataway, NJ, USA|c|;	10.1109/VISUAL.1995.485141;10.1109/VISUAL.1995.480789	Scientific Visualization, Multi-dimensional Visualization, Feature Tracking, Computer Vision, CFD	Rutgers University##Rutgers University
Vis	1996	Contour blending using warp-guided distance field interpolation	10.1109/VISUAL.1996.567812	http://dx.doi.org/10.1109/VISUAL.1996.567812	165	172	C		Daniel Cohen-Or;David Levin;Amira Solomovici	Sch. of Math. Sci., Tel Aviv Univ., Israel|c|;;	10.1109/VISUAL.1994.346333	Shape-plending, Interpolation, Shape Reconstruction, Radial Basis functions	Tel-Aviv University##Tel-Aviv University##Tel-Aviv University
Vis	1996	Complex-valued contour meshing	10.1109/VISUAL.1996.568103	http://dx.doi.org/10.1109/VISUAL.1996.568103	173	180	C		Chris Weigle;David C. Banks	Dept. of Comput. Sci., Mississippi State Univ., MS, USA|c|;	10.1109/VISUAL.1993.398869;10.1109/VISUAL.1991.175782		Mississippi State University##Mississippi State University
Vis	1996	Perceptualisation using a tactile mouse	10.1109/VISUAL.1996.568104	http://dx.doi.org/10.1109/VISUAL.1996.568104	181	188	C		Robert G. Hughes;A. Robin Forrest	Sch. of Inf. Syst., Univ. of East Anglia, Norwich, UK|c|;	10.1109/VISUAL.1995.480802		University of East Anglia##University of East Anglia
Vis	1996	LISTEN: sounding uncertainty visualization	10.1109/VISUAL.1996.568105	http://dx.doi.org/10.1109/VISUAL.1996.568105	189	195	C		Suresh K. Lodha;Catherine M. Wilson;Robert E. Sheehan	Dept. of Comput. & Inf. Sci., California Univ., Santa Cruz, CA, USA|c|;;	10.1109/VISUAL.1992.235199;10.1109/VISUAL.1995.480802;10.1109/VISUAL.1996.568116;10.1109/VISUAL.1994.346315;10.1109/VISUAL.1993.398849;10.1109/VISUAL.1995.485141	flow, geometry, interactive, interpolation, MIDI, modular, portable, sonification, uncertainty, visualization	University of California##University of California##University of California
Vis	1996	A haptic interaction method for volume visualization	10.1109/VISUAL.1996.568108	http://dx.doi.org/10.1109/VISUAL.1996.568108	197	204	C		Ricardo S. Avila;Lisa M. Sobierajski	Gen. Electr. Corp. Res. & Dev. Center, Schenectady, NY, USA|c|;	10.1109/VISUAL.1995.480792		Gen. Electr. Corp. Res. & Dev. Center, Schenectady, NY, USA|c|;
Vis	1996	Two-handed interactive stereoscopic visualization	10.1109/VISUAL.1996.568109	http://dx.doi.org/10.1109/VISUAL.1996.568109	205	210	C		David S. Ebert;Chris Shaw 0002;Amen Zwa;Cindy Starr	Maryland Univ., Baltimore, MD, USA|c|;;;	10.1109/VISUAL.1995.485141		U. of Maryland Baltimore County##NASA GSFC x
Vis	1996	Illustrating transparent surfaces with curvature-directed strokes	10.1109/VISUAL.1996.568110	http://dx.doi.org/10.1109/VISUAL.1996.568110	211	218	C		Victoria Interrante;Henry Fuchs;Stephen M. Pizer	ICASE, NASA Langley Res. Center, USA|c|;;	10.1109/VISUAL.1995.480795;10.1109/VISUAL.1990.146395;10.1109/VISUAL.1996.568111		ICASE##ICASE##ICASE
Vis	1996	Opacity-modulating triangular textures for irregular surfaces	10.1109/VISUAL.1996.568111	http://dx.doi.org/10.1109/VISUAL.1996.568111	219	225	C		Penny Rheingans	Dept. of Comput. Sci., Mississippi Univ., MS, USA|c|	10.1109/VISUAL.1990.146395;10.1109/VISUAL.1995.480795		University of Mississippi
Vis	1996	Generation of Transfer Functions with Stochastic Search Technique	10.1109/VISUAL.1996.568113	http://dx.doi.org/10.1109/VISUAL.1996.568113	227	234	C		Taosong He;Lichan Hong;Arie E. Kaufman;Hanspeter Pfister	Department of Computer Science, State University of New York at Stony Brook, Stony Brook, NY			State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook
Vis	1996	Real-time incremental visualization of dynamic ultrasound volumes using parallel BSP trees	10.1109/VISUAL.1996.568114	http://dx.doi.org/10.1109/VISUAL.1996.568114	235	240	C		William F. Garrett;Henry Fuchs;Mary C. Whitton;Andrei State	Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;	10.1109/VISUAL.1991.175802;10.1109/VISUAL.1994.346295	Augmented reality, ultrasound echography, 3D medical imaging, BSP tree	University of North Carolina at Chapel Hill
Vis	1996	FEL: The Field Encapsulation Library	10.1109/VISUAL.1996.568115	http://doi.ieeecomputersociety.org/10.1109/VISUAL.1996.568115	241	247	C		Steve Bryson;David N. Kenwright;Michael J. Gerald-Yamasaki	MRJ, Inc./ NASA Ames Research Center	10.1109/VISUAL.1995.485145;10.1109/VISUAL.1991.175771;10.1109/VISUAL.1992.235202		MRJ, Inc./ NASA Ames Research Center##MRJ, Inc./ NASA Ames Research Center##MRJ, Inc./ NASA Ames Research Center
Vis	1996	UFLOW: visualizing uncertainty in fluid flow	10.1109/VISUAL.1996.568116	http://dx.doi.org/10.1109/VISUAL.1996.568116	249	254	C		Suresh K. Lodha;Alex T. Pang;Robert E. Sheehan;Craig M. Wittenbrink	Dept. of Comput. Sci., California Univ., Santa Cruz, CA, USA|c|;;;	10.1109/VISUAL.1992.235199;10.1109/VISUAL.1996.568105;10.1109/VISUAL.1995.485141;10.1109/VISUAL.1994.346315	flow visualization, uncertainty glyphs, streamlines, rakes, flow envelopes, animation	University of California##University of California##University of California##University of California
Vis	1996	Time management, simultaneity and time-critical computation in interactive unsteady visualization environments	10.1109/VISUAL.1996.568117	http://dx.doi.org/10.1109/VISUAL.1996.568117	255	261	C		Steve Bryson;Sandy Johan	NASA Ames Res. Center, Moffett Field, CA, USA|c|;	10.1109/VISUAL.1995.485145		MRJ, Inc./NASA Ames Research Center##MRJ, Inc./NASA Ames Research Center
Vis	1996	Choosing effective colours for data visualization	10.1109/VISUAL.1996.568118	http://dx.doi.org/10.1109/VISUAL.1996.568118	263	270	C		Christopher G. Healey	Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC, Canada|c|	10.1109/VISUAL.1995.480803;10.1109/VISUAL.1993.398874		University of British Columbia
Vis	1996	Real-time slicing of data space	10.1109/VISUAL.1996.568119	http://dx.doi.org/10.1109/VISUAL.1996.568119	271	277	C		Roger Crawfis	Lawrence Livermore Nat. Lab., CA, USA|c|	10.1109/VISUAL.1993.398852;10.1109/VISUAL.1995.480796;10.1109/VISUAL.1995.480806;10.1109/VISUAL.1993.398846;10.1109/VISUAL.1993.398877;10.1109/VISUAL.1991.175782;10.1109/VISUAL.1995.480807;10.1109/VISUAL.1995.480797;10.1109/VISUAL.1995.480789	Isocontour, iso-surface, contour surface, volume rendering, splatting, animation, data partitioning, interactive, real-time, scientific visualization, compression	Lawrence Livermore National Laboratory
Vis	1996	Untangling Knots by Stochastic Energy Optimization	10.1109/VISUAL.1996.568120	http://doi.ieeecomputersociety.org/10.1109/VISUAL.1996.568120	279	286	C		Milana Huang;Robert P. Grzeszczuk;Louis H. Kauffman	Electronic Visualization Laboratory, Departments of EECS, University of Illinois at Chicago			University of Chicago####
Vis	1996	Isosurfacing in span space with utmost efficiency (ISSUE)	10.1109/VISUAL.1996.568121	http://dx.doi.org/10.1109/VISUAL.1996.568121	287	294	C		Han-Wei Shen;Charles D. Hansen;Yarden Livnat;Christopher R. Johnson 0001	Dept. of Comput. Sci., Utah Univ., Salt Lake City, UT, USA|c|;;;	10.1109/VISUAL.1991.175780;10.1109/VISUAL.1995.480806;10.1109/VISUAL.1994.346334		UT Los Alamos####
Vis	1996	Triangular NURBS surface modeling of scattered data	10.1109/VISUAL.1996.568122	http://doi.ieeecomputersociety.org/10.1109/VISUAL.1996.568122	295	302	C		Song Han;Gérard G. Medioni	Institute for Robotics and Intelligent Systems, University of Southern California, Los Angeles, CA			University of Southern California Los Angeles##University of Southern California Los Angeles
Vis	1996	Volume Thinning for Automatic Isosurface Propagation	10.1109/VISUAL.1996.568123	http://doi.ieeecomputersociety.org/10.1109/VISUAL.1996.568123	303	310	C		Takayuki Itoh;Yasushi Yamaguchi;Koji Koyamada	Tokyo Research Laboratory, IBM Japan, IBM Japan	10.1109/VISUAL.1991.175780		IBM Japan Graduate##IBM Japan Graduate##IBM Japan Graduate
Vis	1996	Mesh reduction with error control	10.1109/VISUAL.1996.568124	http://dx.doi.org/10.1109/VISUAL.1996.568124	311	318	C		Reinhard Klein;Gunther Liebich;Wolfgang Straßer	Wilhelm-Schickard-Inst. fur Inf., Tubingen Univ., Germany|c|;;	10.1109/VISUAL.1994.346308	hierarchical approximation, model simplification, levels-of-detail generation, shape approximation	UniversitÃ¤t TÃ¼bingen##UniversitÃ¤t TÃ¼bingen##UniversitÃ¤t TÃ¼bingen
Vis	1996	Optimizing triangle strips for fast rendering	10.1109/VISUAL.1996.568125	http://dx.doi.org/10.1109/VISUAL.1996.568125	319	326	C		Francine Evans;Steven Skiena;Amitabh Varshney	State Univ. of New York, Stony Brook, NY, USA|c|;;			State University of New York at Stony Brook##State University of New York at Stony Brook##State University of New York at Stony Brook
Vis	1996	Dynamic view-dependent simplification for polygonal models	10.1109/VISUAL.1996.568126	http://dx.doi.org/10.1109/VISUAL.1996.568126	327	334	C		Julie C. Xia;Amitabh Varshney	State Univ. of New York, Stony Brook, NY, USA|c|;	10.1109/VISUAL.1993.398868;10.1109/VISUAL.1995.480805		State University of New York at Stony Brook##State University of New York at Stony Brook
Vis	1996	Octree-based decimation of marching cubes surfaces	10.1109/VISUAL.1996.568127	http://dx.doi.org/10.1109/VISUAL.1996.568127	335	342	C		Raj Shekhar;Elias Fayyad;Roni Yagel;J. Fredrick Cornhill	Biomed. Eng. Center, Ohio State Univ., Columbus, OH, USA|c|;;;	10.1109/VISUAL.1994.346308		The Cleveland Clinic Foundation##The Ohio State University##The Ohio State University##The Cleveland Clinic Foundation
Vis	1996	Virtual Workbench-a non-immersive virtual environment for visualizing and interacting with 3D objects for scientific visualization	10.1109/VISUAL.1996.568128	http://dx.doi.org/10.1109/VISUAL.1996.568128	345	349	C		Upul Obeysekare;Chas Williams;Jim Durbin;Lawrence J. Rosenblum;Robert Rosenberg;Fernando Grinstein;Ravi Ramamurthi;Alexandra Landsberg;William Sandberg	Naval Res. Lab., Washington, DC, USA|c|;;;;;;;;	10.1109/VISUAL.1991.175771		Naval Research Labora-tory##Naval Research Labora-tory######Naval Research Labora-tory##########Naval Research Laboratory
Vis	1996	A system for the complementary visualization of 3D volume images using 2D and 3D binaurally processed sonification representations	10.1109/VISUAL.1996.568129	http://dx.doi.org/10.1109/VISUAL.1996.568129	351	354	C		David Rossiter;Wai-Yin Ng	Dept. of Inf. Eng., Chinese Univ. of Hong Kong, Shatin, Hong Kong|c|;	10.1109/VISUAL.1990.146398;10.1109/VISUAL.1995.480802		The Chinese University of Hong Kong##The Chinese University of Hong Kong
Vis	1996	Results in mathematics and music: Visualization of roughness in musical consonance	10.1109/VISUAL.1996.568130	http://dx.doi.org/10.1109/VISUAL.1996.568130	355	357	C		Florian Sobieczky				
Vis	1996	Using visualization in the archaeological excavations of a pre-Inca temple in Peru	10.1109/VISUAL.1996.568132	http://dx.doi.org/10.1109/VISUAL.1996.568132	359	362	C		Alan D. Kalvin;Alfredo Remy;Orlando Ardito;Kim Morla;Eduardo Nolasco;Jorge Prado;Regulo Franco;Antonio Murga;Guillermo Wiese	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;;;;;;;			IBM T.J. Watson Research Center##IBM##Pontificia Universidad Catolica##Pontificia Universidad Catolica##Pontificia Universidad Catolica##Pontificia Universidad Catolica######
Vis	1996	Three Dimensional Visualization of Proteins in Cellular Interactions	10.1109/VISUAL.1996.568133	http://doi.ieeecomputersociety.org/10.1109/VISUAL.1996.568133	363	366	C		Colin R. F. Monks;Patricia Crossno;George S. Davidson;Constantine J. Pavlakos;Abraham Kupfer;Cláudio T. Silva;Brian N. Wylie		10.1109/VISUAL.1994.346340		
Vis	1996	Clinical evaluation of interactive volume visualization	10.1109/VISUAL.1996.568134	http://dx.doi.org/10.1109/VISUAL.1996.568134	367	370	C		Karel J. Zuiderveld;Peter M. A. van Ooijen;John W. C. Chin-A-Woeng;Pieter C. Buijs;Marco Olree;Frits H. Post	Inst. of Med. Image Sci., Univ. Hospital Utrecht, Netherlands|c|;;;;;		Volume Rendering, Texture Mapping, MR Angiography, Visualization, Clinical Evaluation	University Hospital Utrecht##University Hospital Utrecht##University Hospital Utrecht##University Hospital Utrecht##University Hospital Utrecht##University Hospital Utrecht##University Hospital Utrecht
Vis	1996	Electrical energy absorption in the human head from a cellular telephone	10.1109/VISUAL.1996.568135	http://dx.doi.org/10.1109/VISUAL.1996.568135	371	374	C		Vishram Pandit;Robert McDermott;Gianluca Lazzi;Cynthia Furse;Om Gandhi	Dept. of Electr. Eng., Utah Univ., Salt Lake City, UT, USA|c|;;;;			University of Utah######
Vis	1996	Case study: Visualization of laser confocal microscopy datasets	10.1109/VISUAL.1996.568136	http://dx.doi.org/10.1109/VISUAL.1996.568136	375	379	C		Georgios Sakas;Michael G. Vicker;Peter Jörg Plath	Fraunhofer-Inst. for Comput. Graphics, Darmstadt, Germany|c|;;	10.1109/VISUAL.1992.235229		Fraunhofer IGD University of Bremen University of Bremen##Fraunhofer IGD University of Bremen University of Bremen##Fraunhofer IGD University of Bremen University of Bremen
Vis	1996	Flow visualization for turbomachinery design	10.1109/VISUAL.1996.568137	http://dx.doi.org/10.1109/VISUAL.1996.568137	381	384	C		Martin Roth;Ronald Peikert	Swiss Center for Sci. Comput., Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;	10.1109/VISUAL.1991.175773		ETH ZÃ¼rich##ETH ZÃ¼rich
Vis	1996	Wavelets applied to lossless compression and progressive transmission of floating point data in 3-D curvilinear grids	10.1109/VISUAL.1996.568138	http://dx.doi.org/10.1109/VISUAL.1996.568138	385	388	C		Aaron Trott;Robert J. Moorhead II;John McGinley	NSF Eng. Res. Center for CFS, Mississippi State Univ., MS, USA|c|;;	10.1109/VISUAL.1994.346332		NSF Engineering Research Center for CFS Mississippi State University##NSF Engineering Research Center for CFS Mississippi State University##NSF Engineering Research Center for CFS Mississippi State University
Vis	1996	Directional flow visualization of vector fields	10.1109/VISUAL.1996.568139	http://dx.doi.org/10.1109/VISUAL.1996.568139	389	392	C		Ed Boring;Alex T. Pang	Dept. of Comput. Sci., California Univ., Santa Cruz, CA, USA|c|;	10.1109/VISUAL.1995.480819	glyphs, streamlines, lighting, hue, value, region selection, clutter reduction, flow reversal	University of California##University of California
Vis	1996	Data level comparative visualization in aircraft design	10.1109/VISUAL.1996.568140	http://dx.doi.org/10.1109/VISUAL.1996.568140	393	396	C		Jens C. Trapp;Hans-Georg Pagendarm	DLR, German Aerosp. Res. Establ., Gottingen, Germany|c|;	10.1109/VISUAL.1995.485151;10.1109/VISUAL.1995.485156		DLR, German Aerosp. Res. Establ., Gottingen, Germany|c|;
Vis	1996	A system for measuring surface facet orientation from atomic force microscope data	10.1109/VISUAL.1996.568141	http://dx.doi.org/10.1109/VISUAL.1996.568141	397	400	C		John G. Hagedorn;Holly E. Rushmeier;John Blendell;Mark Vaudin	Comput. & Appl. Math. Lab., Nat. Inst. of Stand. & Technol., Gaithersburg, MD, USA|c|;;;			Comput. & Appl. Math. Lab., Nat. Inst. of Stand. & Technol., Gaithersburg, MD, USA|c|;;;
Vis	1996	A visualization tool for mechanical design	10.1109/VISUAL.1996.568142	http://dx.doi.org/10.1109/VISUAL.1996.568142	401	403	C		Shao-Chiung Lu;Alec B. Rebello;D. H. Cui;Roni Yagel;R. A. Miller;G. L. Kinzel	Center for Die Casting, Ohio State Univ., Columbus, OH, USA|c|;;;;;			The Ohio State University##The Ohio State University##The Ohio State University##The Ohio State University##The Ohio State University##The Ohio State University
Vis	1996	A 3D Contextual Shading Method for Visualization of Diecasting Defects	10.1109/VISUAL.1996.568143	http://doi.ieeecomputersociety.org/10.1109/VISUAL.1996.568143	405	407	C		Shao-Chiung Lu;Alec B. Rebello;D. H. Cui;Roni Yagel;R. A. Miller;G. L. Kinzel	Center for Die Casting, Ohio State Univ., Columbus, OH, USA|c|;;;;;			The Ohio State University##The Ohio State University##The Ohio State University##The Ohio State University##The Ohio State University##The Ohio State University
Vis	1996	Case Study: Mantle convection visualization on the Cray T3D	10.1109/VISUAL.1996.568144	http://dx.doi.org/10.1109/VISUAL.1996.568144	409	412	C		James S. Painter;Hans-Peter Bunge;Yarden Livnat	Adv. Comput. Lab., Los Alamos Nat. Lab., NM, USA|c|;;			University of Utah##University of Utah##University of Utah
Vis	1996	The challenges of visualizing and modeling environmental data	10.1109/VISUAL.1996.568145	http://dx.doi.org/10.1109/VISUAL.1996.568145	413	416	C		Yingcai Xiao;John P. Ziebarth;Chuck Woodbury;Eric Bayer;Bruce Rundell;Jeroen van der Zijp	Dept. of Math., Akron Univ., OH, USA|c|;;;;;			University of Akron##Intergraph Corporation Huntsville##CFD Research Corporation
Vis	1996	Visualization of water quality data for the Chesapeake Bay	10.1109/VISUAL.1996.568146	http://dx.doi.org/10.1109/VISUAL.1996.568146	417	420	C		Adam B. Forgang;Bernd Hamann;Carl F. Cerco	Dept. of Comput. Eng., California Univ., Davis, CA, USA|c|;;	10.1109/VISUAL.1995.485141		University of California##University of California##
Vis	1996	Data reduction and interpolation for visualizing 3D soil-quality data	10.1109/VISUAL.1996.568147	http://dx.doi.org/10.1109/VISUAL.1996.568147	421	424	C		David C. Banks;Bernd Hamann;Po-Yu Tsai;Robert J. Moorhead II;Jonathan Barlow	NSF Eng. Res. Center, Mississippi State Univ., MS, USA|c|;;;;			NSF Eng. Res. Center, Mississippi State Univ., MS, USA|c|;;;;
Vis	1996	Case Study: Visual access for landscape event based temporal data	10.1109/VISUAL.1996.568148	http://dx.doi.org/10.1109/VISUAL.1996.568148	425	428	C		M. Sheelagh T. Carpendale;Andrew Fall;David J. Cowperthwaite;Joseph Fall;F. David Fracchia	Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada|c|;;;;		distortion viewing, 3D interaction, information visualization, temporal data	Simon Fraser University##Simon Fraser University##Simon Fraser University##Simon Fraser University##Simon Fraser University##Simon Fraser University
Vis	1996	Interactive visualization of ocean circulation models	10.1109/VISUAL.1996.568149	http://dx.doi.org/10.1109/VISUAL.1996.568149	429	432	C		Scott Nations;Robert J. Moorhead II;Kelly P. Gaither;Steve Aukstakalnis;Rhonda Vickery;Warren Carl Couvillion Jr.;Daniel N. Fox;Peter Flynn;Alan J. Wallcraft;Patrick Hogan;Ole Martin Smedstad	Mississippi State Univ., MS, USA|c|;;;;;;;;;;			Mississippi State University##Mississippi State University##Mississippi State University##Mississippi State University##Mississippi State University##Mississippi State University##Mississippi State University##Mississippi State University##Mississippi State University##Mississippi State University##Mississippi State University
Vis	1996	Interactive Exploration and Modeling of Large Data Sets: A Case Study with Venus Light Scattering Data	10.1109/VISUAL.1996.568150	http://doi.ieeecomputersociety.org/10.1109/VISUAL.1996.568150	433	438	C		Jarke J. van Wijk;Hans J. W. Spoelder;Willem-Jan Knibbe;Kamran Eftekhari Shahroudi	The Netherlands and Centre for Mathematics and Computer Science CWI, Amsterdam, The Netherlands	10.1109/VISUAL.1995.485143		Netherlands Energy Vrije Universiteit##Netherlands Energy Vrije Universiteit##Netherlands Energy Vrije Universiteit##Netherlands Energy Vrije Universiteit
Vis	1996	Surface Rendering Versus Volume Rendering In Medical Imaging: Techniques And Applications	10.1109/VISUAL.1996.568151	http://dx.doi.org/10.1109/VISUAL.1996.568151	439	440	M		Ramin Shahidi;William E. Lorensen;Ron Kikinis;John Flynn;Arie E. Kaufman;Sandy Napel	Stanford University Medical Center|c|;;;;;			Stanford University Medical Center|c|;;;;;
Vis	1996	Real-time Accelerators for Volume Rendering	10.1109/VISUAL.1996.568160	http://dx.doi.org/10.1109/VISUAL.1996.568160	445	447	M		Arie E. Kaufman;Hanspeter Pfister;Günter Knittel;Jürgen Hesser;John C. Goble	SUNY at Stony Brook|c|;;;;			SUNY at Stony Brook|c|;;;;
Vis	1996	Information Exploration Shootout or "Benchmarks for Information Exploration"	10.1109/VISUAL.1996.568163	http://dx.doi.org/10.1109/VISUAL.1996.568163	449	450	M		Georges G. Grinstein;Gregory Piatetsky-Shapiro;Graham J. Wills	University of Massachusetts at Lowell and The MITRE Corporation|c|;;			University of Massachusetts at Lowell and The MITRE Corporation|c|;;
Vis	1996	Mathematical Vkualization: Standing at the Crossroads	10.1109/VISUAL.1996.568165	http://dx.doi.org/10.1109/VISUAL.1996.568165	451	453	M		Tamara Munzner;David Banks;George Francis;Andrew J. Hanson;Loki Jörgenson	Stanford University (co-organizer)|c|;;;;			Stanford University (co-organizer)|c|;;;;
Vis	1996	Breaking the Myth: One Picture is Not (always) Worth a Thousand Words	10.1109/VISUAL.1996.569203	http://dx.doi.org/10.1109/VISUAL.1996.569203	441	443	M		Nahum D. Gershon;Robert Braham;F. David Fracchia;Andrew S. Glassner;Barbara Mones-Hattal;Russ Rose	The MITRE Corporation|c|;;;;;;			The MITRE Corporation|c|;;;;;;
InfoVis	1997	H3: laying out large directed graphs in 3D hyperbolic space	10.1109/INFVIS.1997.636718	http://dx.doi.org/10.1109/INFVIS.1997.636718	2	10	C		Tamara Munzner	Stanford Univ., CA, USA|c|	10.1109/INFVIS.1995.528691;10.1109/INFVIS.1995.528689		Stanford University
InfoVis	1997	Visualizing information on a sphere	10.1109/INFVIS.1997.636759	http://dx.doi.org/10.1109/INFVIS.1997.636759	11	16	C		Markus H. Gross;Thomas C. Sprenger;J. Finger	Dept. of Comput. Sci., Zurich Univ., Switzerland|c|;;	10.1109/INFVIS.1995.528689;10.1109/INFVIS.1995.528691;10.1109/INFVIS.1995.528686;10.1109/VISUAL.1996.567787	information visualization, physically-based systems, multidimensional information space, hierarchies, blobby clustering	University of Freiburg##Federal Institute of Technology
InfoVis	1997	A spreadsheet approach to information visualization	10.1109/INFVIS.1997.636761	http://dx.doi.org/10.1109/INFVIS.1997.636761	17	24	C		Ed Huai-hsin Chi;Phillip Barry;John Riedl;Joseph A. Konstan	Dept. of Comput. Sci., Minnesota Univ., Minneapolis, MN, USA|c|;;;	10.1109/VISUAL.1996.567796;10.1109/VISUAL.1996.567752;10.1109/INFVIS.1995.528690;10.1109/VISUAL.1995.480794;10.1109/VISUAL.1993.398859		University of Minnesota##University of Minnesota##University of Minnesota##University of Minnesota
InfoVis	1997	Adaptive information visualization based on the user's multiple viewpoints - interactive 3D visualization of the WWW	10.1109/INFVIS.1997.636778	http://dx.doi.org/10.1109/INFVIS.1997.636778	25	28	C		Teruhiko Teraoka;Minoru Maruyama	Adv. Technol. R&D Center, Mitsubishi Electr. Corp., Amagasaki, Japan|c|;			Mitsubishi Electric Corporation Tsukaguchi-Honmachi##Shinshu University
InfoVis	1997	Managing software with new visual representations	10.1109/INFVIS.1997.636782	http://dx.doi.org/10.1109/INFVIS.1997.636782	30	37	C		Mei C. Chuah;Stephen G. Eick	Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA|c|;	10.1109/VISUAL.1993.398874		Carnegie Mellon University Pittsburgh##Carnegie Mellon University Pittsburgh
InfoVis	1997	On integrating visualization techniques for effective software exploration	10.1109/INFVIS.1997.636784	http://dx.doi.org/10.1109/INFVIS.1997.636784	38	45	C		Margaret-Anne D. Storey;Kenny Wong;F. David Fracchia;Hausi A. Müller	Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada|c|;;;	10.1109/VISUAL.1991.175815	Nested graphs, pan and zoom, fisheye views, hypertext, mental map, software visualization, program understanding	Simon Fraser University University of Victoria Burnaby####Simon Fraser University University of Victoria Burnaby
InfoVis	1997	Cacti: a front end for program visualization	10.1109/INFVIS.1997.636785	http://dx.doi.org/10.1109/INFVIS.1997.636785	46	49	C		Steven P. Reiss	Dept. of Comput. Sci., Brown Univ., Providence, RI, USA|c|	10.1109/INFVIS.1996.559210		Brown University Providence
InfoVis	1997	Nonlinear magnification fields	10.1109/INFVIS.1997.636786	http://dx.doi.org/10.1109/INFVIS.1997.636786	51	58	C		Alan Keahey;Edward L. Robertson	Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA|c|;	10.1109/INFVIS.1996.559214	information visualization, nonlinear magnification, data-driven magnification, fisheye views, magnification brushing, data-mining	Indiana University
InfoVis	1997	Managing multiple focal levels in Table Lens	10.1109/INFVIS.1997.636787	http://dx.doi.org/10.1109/INFVIS.1997.636787	59	63	C		Tichomir Tenev;Ramana Rao	Xerox Palo Alto Res. Center, CA, USA|c|;		Focus+Context, Fisheye, Information visualization, Table Lens	Xerox Palo Alto Research Center##Xerox Palo Alto Research Center
InfoVis	1997	Coordinating declarative queries with a direct manipulation data exploration environment	10.1109/INFVIS.1997.636788	http://dx.doi.org/10.1109/INFVIS.1997.636788	65	72	C		Mark Derthick;Steven F. Roth;John Kolojejchick	Robotics Inst., Carnegie Mellon Univ., Pittsburgh, PA, USA|c|;;	10.1109/INFVIS.1995.528688;10.1109/INFVIS.1996.559210		Carnegie Mellon University Robotics Institute##Carnegie Mellon University Robotics Institute##Carnegie Mellon University Robotics Institute
InfoVis	1997	Domesticating Bead: adapting an information visualization system to a financial institution	10.1109/INFVIS.1997.636789	http://dx.doi.org/10.1109/INFVIS.1997.636789	73	80	C		Dominique Brodbeck;Matthew Chalmers;Aran Lunzer;Pamela Cotture	Ubilab, UBS, Zurich, Switzerland|c|;;;	10.1109/VISUAL.1990.146402;10.1109/INFVIS.1995.528686;10.1109/VISUAL.1996.568118;10.1109/INFVIS.1995.528688;10.1109/VISUAL.1994.346302;10.1109/VISUAL.1991.175794;10.1109/VISUAL.1996.567787		Ubilab Union Bank of Switzerland##Ubilab Union Bank of Switzerland##Ubilab Union Bank of Switzerland##Ubilab Union Bank of Switzerland
InfoVis	1997	Design and evaluation of incremental data structures and algorithms for dynamic query interfaces	10.1109/INFVIS.1997.636790	http://dx.doi.org/10.1109/INFVIS.1997.636790	81	86	C		Egemen Tanin;Richard Beigel;Ben Shneiderman	Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA|c|;;	10.1109/INFVIS.1995.528688;10.1109/INFVIS.1995.528688	Data Structure, Algorithm, Database, User Interface, Information Visualization, Direct Manipulation, Dynamic Query	University of Maryland
InfoVis	1997	Volume rendering for relational data	10.1109/INFVIS.1997.636791	http://dx.doi.org/10.1109/INFVIS.1997.636791	87	90	C		Barry G. Becker	Silicon Graphics Comput. Syst., Mountain View, CA, USA|c|	10.1109/INFVIS.1995.528686;10.1109/INFVIS.1995.528688;10.1109/VISUAL.1995.485139;10.1109/VISUAL.1993.398877	volume rendering, relational data, scatterplot, multivariate data, information visualization	Silicon Graphics Inc
InfoVis	1997	The structure of the information visualization design space	10.1109/INFVIS.1997.636792	http://dx.doi.org/10.1109/INFVIS.1997.636792	92	99	C		Stuart K. Card;Jock D. Mackinlay	Xerox Palo Alto Res. Center, CA, USA|c|;	10.1109/INFVIS.1996.559213;10.1109/VISUAL.1991.175815;10.1109/INFVIS.1995.528686;10.1109/INFVIS.1995.528684;10.1109/INFVIS.1995.528697	information visualization, taxonomy, design space, morphological analysis	Xerox PARC##Xerox PARC
InfoVis	1997	Multidimensional detective	10.1109/INFVIS.1997.636793	http://dx.doi.org/10.1109/INFVIS.1997.636793	100	107	C		Alfred Inselberg	Dept. of Comput. Sci., Tel Aviv Univ., Israel|c|	10.1109/VISUAL.1990.146402;10.1109/VISUAL.1994.346302		Multidimensional Graphs Ltd y & Computer Science Department Tel Aviv University
InfoVis	1997	Metrics for effective information visualization	10.1109/INFVIS.1997.636794	http://dx.doi.org/10.1109/INFVIS.1997.636794	108	111	C		Richard Brath	Visible Decision Inc., Toronto, Ont., Canada|c|	10.1109/INFVIS.1996.559213;10.1109/INFVIS.1995.528682;10.1109/INFVIS.1996.559211		Visible Decision Inc., Toronto, Ont., Canada|c|
Vis	1997	A comparison of normal estimation schemes	10.1109/VISUAL.1997.663848	http://dx.doi.org/10.1109/VISUAL.1997.663848	19	26	C		Torsten Möller;Raghu Machiraju;Klaus Mueller;Roni Yagel	Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA|c|;;;	10.1109/VISUAL.1994.346331	interpolation filters, derivative filters, filter design, normal estimation, Taylor series expansion, efficient volume rendering	NSF Engineering Research Center for Computational Field Simulation####
Vis	1997	Collision detection for volumetric objects	10.1109/VISUAL.1997.663851	http://dx.doi.org/10.1109/VISUAL.1997.663851	27	34	C		Taosong He;Arie E. Kaufman	AT&T Bell Labs., Naperville, IL, USA|c|;	10.1109/VISUAL.1996.568108;10.1109/VISUAL.1994.346340	volume visualization, volume rendering, virtual reality, volume graphics, volumetric collision, collision probability, surface crossing probability, distance map, octree, sphere tree	Road State University of New York at Stony Brook Naperville##Road State University of New York at Stony Brook Naperville
Vis	1997	The VSBUFFER: visibility ordering of unstructured volume primitives by polygon drawing	10.1109/VISUAL.1997.663853	http://dx.doi.org/10.1109/VISUAL.1997.663853	35	42	C		Rüdiger Westermann;Thomas Ertl	Comput. Graphics Group, Erlangen-Nurnberg Univ., Germany|c|;	10.1109/VISUAL.1996.567606;10.1109/VISUAL.1993.398853;10.1109/VISUAL.1990.146391		UniversitÃ¤t Erlangen-NÃ¼rnberg##UniversitÃ¤t Erlangen-NÃ¼rnberg
Vis	1997	Volume rendering of abdominal aortic aneurysms	10.1109/VISUAL.1997.663855	http://dx.doi.org/10.1109/VISUAL.1997.663855	43	50	C		Roger C. Tam;Christopher G. Healey;Borys Flak;Peter Cahoon	Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC, Canada|c|;;;	10.1109/VISUAL.1996.568118;10.1109/VISUAL.1993.398874	aneurysm, colourization, computed tomography, CT, image processing, medical imaging, scientific visualization, segmentation, volume rendering	University of British Columbia EECS Department##University of British Columbia EECS Department##University of British Columbia EECS Department##University of British Columbia EECS Department
Vis	1997	Auralization of streamline vorticity in computational fluid dynamics data	10.1109/VISUAL.1997.663856	http://dx.doi.org/10.1109/VISUAL.1997.663856	51	57	C		Christopher R. Volpe;Ephraim P. Glinert	GE Corp. Res. & Dev., Schenectady, NY, USA|c|;	10.1109/VISUAL.1991.175789;10.1109/VISUAL.1990.146398;10.1109/VISUAL.1992.235205;10.1109/VISUAL.1995.480802		GE Corp. Res. & Dev., Schenectady, NY, USA|c|;
Vis	1997	Singularities in nonuniform tensor fields	10.1109/VISUAL.1997.663857	http://dx.doi.org/10.1109/VISUAL.1997.663857	59	66	C		Yingmei Lavin;Yuval Levy;Lambertus Hesselink	Dept. of Phys., Stanford Univ., CA, USA|c|;;	10.1109/VISUAL.1992.235193		Stanford University Technion, I.I.T. Stanford##Stanford University Technion, I.I.T. Stanford##Stanford University Stanford
Vis	1997	Visualization of higher order singularities in vector fields	10.1109/VISUAL.1997.663858	http://dx.doi.org/10.1109/VISUAL.1997.663858	67	74	C		Gerik Scheuermann;Hans Hagen;Heinz Krüger;Martin Menzel;Alyn P. Rockwood	Dept. of Comput. Sci., Kaiserslautern Univ., Germany|c|;;;;			Dept. of Comput. Sci., Kaiserslautern Univ., Germany|c|;;;;
Vis	1997	Principal stream surfaces	10.1109/VISUAL.1997.663859	http://dx.doi.org/10.1109/VISUAL.1997.663859	75	80	C		Wenli Cai;Pheng-Ann Heng	Fraunhofer Inst. for Comput. Graphics, Germany|c|;	10.1109/VISUAL.1993.398875;10.1109/VISUAL.1996.567780;10.1109/VISUAL.1992.235211;10.1109/VISUAL.1992.235225	flow field, visualization, volume rendering, filtering	The Chinese University of Hong Kong##The Chinese University of Hong Kong
Vis	1997	ROAMing terrain: Real-time Optimally Adapting Meshes	10.1109/VISUAL.1997.663860	http://dx.doi.org/10.1109/VISUAL.1997.663860	81	88	C		Mark A. Duchaineau;Murray Wolinsky;David E. Sigeti;Mark C. Miller;Charles Aldrich;Mark B. Mineev-Weinstein	Los Alamos Nat. Lab., NM, USA|c|;;;;;	10.1109/VISUAL.1996.567600;10.1109/VISUAL.1996.568126;10.1109/VISUAL.1996.568125;10.1109/VISUAL.1995.480813;10.1109/VISUAL.1995.480805	triangle bintree, view-dependent mesh, frame-to-frame coherence, greedy algorithms	Los Alamos Nat. Lab., NM, USA|c|;;;;;
Vis	1997	Visualization of height field data with physical models and texture photomapping	10.1109/VISUAL.1997.663862	http://dx.doi.org/10.1109/VISUAL.1997.663862	89	94	C		Dru Clark;Michael J. Bailey	California Univ., San Diego, La Jolla, CA, USA|c|;	10.1109/VISUAL.1991.175814	Computer graphics, object modeling, scientific visualization	UCSD / SDSC##University of California at San Diego and San Diego Supercomputer Center
Vis	1997	Visualization of large terrains in resource-limited computing environments	10.1109/VISUAL.1997.663863	http://dx.doi.org/10.1109/VISUAL.1997.663863	95	102	C		Boris Rabinovich;Craig Gotsman	Dept. of Comput. Sci., Technion-Israel Inst. of Technol., Haifa, Israel|c|;	10.1109/VISUAL.1996.567600	Terrain rendering, level-of-detail, interactive graphics	Technion -Israel Institute of Technology Haifa 32000##Technion -Israel Institute of Technology Haifa 32000
Vis	1997	Building and traversing a surface at variable resolution	10.1109/VISUAL.1997.663865	http://dx.doi.org/10.1109/VISUAL.1997.663865	103	110	C		Leila De Floriani;Paola Magillo;Enrico Puppo	Dipt. di Inf. e Sci. dell''Inf., Genoa Univ., Italy|c|;;			UniversitÃ di Genova Enrico Puppo Istituto per la Matematica Applicata â€“ Consiglio Nazionale delle Ricerche y##UniversitÃ di Genova Enrico Puppo Istituto per la Matematica Applicata â€“ Consiglio Nazionale delle Ricerche y
Vis	1997	Multivariate visualization using metric scaling	10.1109/VISUAL.1997.663866	http://dx.doi.org/10.1109/VISUAL.1997.663866	111	118	C		Pak Chung Wong;R. Daniel Bergeron	Dept. of Comput. Sci., New Hampshire Univ., Durham, NH, USA|c|;	10.1109/VISUAL.1995.480811;10.1109/VISUAL.1995.485139;10.1109/VISUAL.1994.346302;10.1109/VISUAL.1996.567800;10.1109/VISUAL.1993.398864;10.1109/VISUAL.1990.146387		University of New Hampshire
Vis	1997	Visualizing the behaviour of higher dimensional dynamical systems	10.1109/VISUAL.1997.663867	http://dx.doi.org/10.1109/VISUAL.1997.663867	119	125	C		Rainer Wegenkittl;Helwig Löffelmann;Eduard Gröller	Inst. of Comput. Graphics, Wien Univ. of Technol., Austria|c|;;	10.1109/VISUAL.1990.146373;10.1109/VISUAL.1991.175796;10.1109/VISUAL.1993.398869;10.1109/VISUAL.1991.175795;10.1109/VISUAL.1990.146386;10.1109/VISUAL.1990.146402;10.1109/VISUAL.1993.398849		Vienna University of Technology##Vienna University of Technology##Vienna University of Technology
Vis	1997	Displaying data in multidimensional relevance space with 2D visualization maps	10.1109/VISUAL.1997.663868	http://dx.doi.org/10.1109/VISUAL.1997.663868	127	134	C		Jackie Assa;Daniel Cohen-Or;Tova Milo	Dept. of Comput. Sci., Tel Aviv Univ., Israel|c|;;	10.1109/INFVIS.1995.528691;10.1109/VISUAL.1990.146402;10.1109/INFVIS.1995.528686;10.1109/VISUAL.1993.398863;10.1109/INFVIS.1995.528692		Tel-Aviv University##Tel-Aviv University##Tel-Aviv University
Vis	1997	Multiresolution tetrahedral framework for visualizing regular volume data	10.1109/VISUAL.1997.663869	http://dx.doi.org/10.1109/VISUAL.1997.663869	135	142	C		Yong Zhou;Baoquan Chen;Arie E. Kaufman	Center for Visual Comput., State Univ. of New York, Stony Brook, NY, USA|c|;;	10.1109/VISUAL.1996.568127	volume visualization, multiresolution volume, level of detail, isosurface extraction, volume subdivision, polygon simplification	State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook
Vis	1997	Haar wavelets over triangular domains with applications to multiresolution models for flow over a sphere	10.1109/VISUAL.1997.663871	http://dx.doi.org/10.1109/VISUAL.1997.663871	143	149	C		Gregory M. Nielson;Il-Hong Jung;Junwon Sung	Dept. of Comput. Sci. & Eng., Arizona State Univ., Tempe, AZ, USA|c|;;			Arizona State University Tempe##Arizona State University Tempe##Arizona State University Tempe
Vis	1997	Wavelet-based multiresolutional representation of computational field simulation datasets	10.1109/VISUAL.1997.663872	http://dx.doi.org/10.1109/VISUAL.1997.663872	151	158	C		Zhifan Zhu;Raghu Machiraju;Bryan Fry;Robert J. Moorhead II	NSF Eng. Res. Center for Comput. Field Simulation, Mississippi State Univ., MS, USA|c|;;;	10.1109/VISUAL.1994.346332;10.1109/VISUAL.1995.480810;10.1109/VISUAL.1996.568138;10.1109/VISUAL.1995.480812	wavelet transform, structure detection, human visual system, progressive transmission	Mississippi State University####Mississippi State University##Mississippi State University
Vis	1997	Dynamic color mapping of bivariate qualitative data	10.1109/VISUAL.1997.663874	http://dx.doi.org/10.1109/VISUAL.1997.663874	159	166	C		Penny Rheingans	Comp. and Inf. Science Department, Univ. of Mississippi, MS, USA	10.1109/VISUAL.1992.235201;10.1109/VISUAL.1995.480803;10.1109/VISUAL.1991.175795;10.1109/VISUAL.1992.235219		University of Mississippi
Vis	1997	The contour spectrum	10.1109/VISUAL.1997.663875	http://dx.doi.org/10.1109/VISUAL.1997.663875	167	173	C		Chandrajit L. Bajaj;Valerio Pascucci;Daniel Schikore	Shastra Lab., Purdue Univ., West Lafayette, IN, USA|c|;;	10.1109/VISUAL.1996.568123;10.1109/VISUAL.1995.480803;10.1109/VISUAL.1996.568113	Visualization, Scalar Data, User Interfaces, Real-time Quantitative Query	Purdue University West Lafayette##Purdue University West Lafayette##Purdue University West Lafayette
Vis	1997	Constrained 3D navigation with 2D controllers	10.1109/VISUAL.1997.663876	http://dx.doi.org/10.1109/VISUAL.1997.663876	175	182	C		Andrew J. Hanson;Eric A. Wernert	Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA|c|;	10.1109/VISUAL.1995.480804	Navigation, Constrained Navigation, Viewing Control, Camera Control	Indiana University Bloomington##Indiana University Bloomington
Vis	1997	Two-phase perspective ray casting for interactive volume navigation	10.1109/VISUAL.1997.663878	http://dx.doi.org/10.1109/VISUAL.1997.663878	183	189	C		Martin L. Brady;Kenneth K. Jung;H. T. Nguyen;Thinh P. Q. Nguyen	Microcomput. Res. Labs., Intel Corp., USA|c|;;;	10.1109/VISUAL.1994.346340;10.1109/VISUAL.1995.485154;10.1109/VISUAL.1996.567603	Volume navigation, volume rendering, 3D medical imaging, scientific visualization, texture mapping	Intel Corporation##Intel Corporation##Intel Corporation##Intel Corporation
Vis	1997	Accelerated volume rendering using homogeneous region encoding	10.1109/VISUAL.1997.663880	http://dx.doi.org/10.1109/VISUAL.1997.663880	191	196	C		Jason Freund;Kenneth R. Sloan	Silicon Graphics Inc., USA|c|;	10.1109/VISUAL.1990.146377	Volume Rendering, Ray-casting	University of Alabama at Birmingham##University of Alabama at Birmingham
Vis	1997	An anti-aliasing technique for splatting	10.1109/VISUAL.1997.663882	http://dx.doi.org/10.1109/VISUAL.1997.663882	197	204	C		J. Edward Swan II;Klaus Mueller;Torsten Möller;Naeem Shareef;Roger Crawfis;Roni Yagel	Adv. Comput. Center for the Arts & Design, Ohio State Univ., Columbus, OH, USA|c|;;;;;	10.1109/VISUAL.1996.567608;10.1109/VISUAL.1993.398877;10.1109/VISUAL.1994.346331;10.1109/VISUAL.1995.480792;10.1109/VISUAL.1993.398852	volume rendering, splatting, direct volume rendering, resampling, reconstruction, anti-aliasing, perspective projection	The Ohio State University####The Ohio State University##The Ohio State University##The Ohio State University##The Ohio State University##The Ohio State University
Vis	1997	A topology modifying progressive decimation algorithm	10.1109/VISUAL.1997.663883	http://dx.doi.org/10.1109/VISUAL.1997.663883	205	212	C		William J. Schroeder		10.1109/VISUAL.1995.485142;10.1109/VISUAL.1993.398868;10.1109/VISUAL.1996.568124		
Vis	1997	Efficient subdivision of finite-element datasets into consistent tetrahedra	10.1109/VISUAL.1997.663885	http://dx.doi.org/10.1109/VISUAL.1997.663885	213	219	C		Guy Albertelli;Roger Crawfis	Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA|c|;	10.1109/VISUAL.1992.235210;10.1109/VISUAL.1993.398846	tetrahedralization, mesh subdivision, volume rendering, flow visualization, isosurfaces, metrics, irregular grids	The Ohio State University##The Ohio State University
Vis	1997	Interval volume tetrahedrization	10.1109/VISUAL.1997.663886	http://dx.doi.org/10.1109/VISUAL.1997.663886	221	228	C		Gregory M. Nielson;Junwon Sung	Dept. of Comput. Sci., Arizona State Univ., Tempe, AZ, USA|c|;	10.1109/VISUAL.1991.175782;10.1109/VISUAL.1995.480789		Arizona State University Tempe##Arizona State University Tempe
Vis	1997	Computing the separating surface for segmented data	10.1109/VISUAL.1997.663887	http://dx.doi.org/10.1109/VISUAL.1997.663887	229	233	C		Gregory M. Nielson;Richard Franke	Dept. of Comput. Sci. & Eng., Arizona State Univ., Tempe, AZ, USA|c|;	10.1109/VISUAL.1991.175782		Arizona State University Tempe##Arizona State University Tempe
Vis	1997	Application-controlled demand paging for out-of-core visualization	10.1109/VISUAL.1997.663888	http://dx.doi.org/10.1109/VISUAL.1997.663888	235	244	C		Michael Cox;David Ellsworth	NASA Ames Res. Center, Moffett Field, CA, USA|c|;	10.1109/VISUAL.1994.346311;10.1109/VISUAL.1990.146360;10.1109/VISUAL.1993.398860	computational fluid dynamics, visualization, out-of-core visualization	MRJ/NASA Ames Research Center MRJ/NASA Ames Research Center Microcomputer Research Labs##MRJ/NASA Ames Research Center MRJ/NASA Ames Research Center Microcomputer Research Labs
Vis	1997	GADGET: goal-oriented application design guidance for modular visualization environments	10.1109/VISUAL.1997.663889	http://dx.doi.org/10.1109/VISUAL.1997.663889	245	252	C		Issei Fujishiro;Yuriko Takeshima;Yoshihiko Ichikawa;Kyoko Nakamura	Dept. of Inf. Sci., Ochanomizu Univ., Tokyo, Japan|c|;;;	10.1109/VISUAL.1990.146375;10.1109/VISUAL.1993.398857;10.1109/INFVIS.1996.559210	visualization systems, Modular Visualization Environments (MVEs), dataflow paradigm, visineers' heuristics and expertise, taxonomy of visualization techniques, knowledge base, object-oriented design	Ochanomizu University##Ochanomizu University##Sony Corporation
Vis	1997	Collaborative visualization	10.1109/VISUAL.1997.663890	http://dx.doi.org/10.1109/VISUAL.1997.663890	253	259	C		Jason D. Wood;Helen Wright;Ken Brodlie	Sch. of Comput. Studies, Leeds Univ., UK|c|;;	10.1109/VISUAL.1995.480821		University of Leeds##University of Leeds##University of Leeds
Vis	1997	VizWiz: a Java applet for interactive 3D scientific visualization on the Web	10.1109/VISUAL.1997.663891	http://dx.doi.org/10.1109/VISUAL.1997.663891	261	267	C		Cherilyn Michaels;Michael J. Bailey	Dept. of Comput. Sci. & Eng., California Univ., San Diego, La Jolla, CA, USA|c|;	10.1109/VISUAL.1990.146361		University of California San Diego##University of California
Vis	1997	Image synthesis from a sparse set of views	10.1109/VISUAL.1997.663892	http://dx.doi.org/10.1109/VISUAL.1997.663892	269	275	C		Qian Chen;Gérard G. Medioni	Univ. of Southern California, Los Angeles, CA, USA|c|;		image-based rendering, epipolar geometry, projective invariant, homography, Constrained Delaunay Triangulation	University of Southern California##University of Southern California##University of Southern California
Vis	1997	Virtualized reality: constructing time-varying virtual worlds from real world events	10.1109/VISUAL.1997.663893	http://dx.doi.org/10.1109/VISUAL.1997.663893	277	283	C		Peter Rander;P. J. Narayanan;Takeo Kanade	Robotics Inst., Carnegie Mellon Univ., Pittsburgh, PA, USA|c|;;		view synthesis, dynamic scene analysis, modeling from image sequences, computer vision and scene understanding, virtual worlds	Mellon University##Carnegie Mellon University
Vis	1997	Extracting feature lines from 3D unstructured grids	10.1109/VISUAL.1997.663894	http://dx.doi.org/10.1109/VISUAL.1997.663894	285	292	C		Kwan-Liu Ma;Victoria Interrante	Inst. for Comput. Applications in Sci. & Eng., NASA Langley Res. Center, Hampton, VA, USA|c|;	10.1109/VISUAL.1995.480795		Institute for Computer Applications in Science and Engineering (ICASE) NASA Langley Research Center##Institute for Computer Applications in Science and Engineering (ICASE) NASA Langley Research Center
Vis	1997	I/O optimal isosurface extraction	10.1109/VISUAL.1997.663895	http://dx.doi.org/10.1109/VISUAL.1997.663895	293	300	C		Yi-Jen Chiang;Cláudio T. Silva	;	10.1109/VISUAL.1995.480806;10.1109/VISUAL.1996.568121		State University of New York at Stony Brook##State University of New York at Stony Brook
Vis	1997	CAVEvis: distributed real-time visualization of time-varying scalar and vector fields using the CAVE virtual reality theater	10.1109/VISUAL.1997.663896	http://dx.doi.org/10.1109/VISUAL.1997.663896	301	308	C		Vijendra Jaswal	Nat. Center for Supercomput. Applications, Champaign, IL, USA|c|	10.1109/VISUAL.1996.568117;10.1109/VISUAL.1991.175771		Nat. Center for Supercomput. Applications, Champaign, IL, USA|c|
Vis	1997	Fast oriented line integral convolution for vector field visualization via the Internet	10.1109/VISUAL.1997.663897	http://dx.doi.org/10.1109/VISUAL.1997.663897	309	316	C		Rainer Wegenkittl;Eduard Gröller	Inst. of Comput. Graphics, Wien Univ. of Technol., Austria|c|;	10.1109/VISUAL.1995.480817;10.1109/VISUAL.1994.346313;10.1109/VISUAL.1993.398850;10.1109/VISUAL.1996.567784;10.1109/VISUAL.1993.398877;10.1109/VISUAL.1994.346312		Vienna University of Technology##Vienna University of Technology
Vis	1997	UFLIC: a line integral convolution algorithm for visualizing unsteady flows	10.1109/VISUAL.1997.663898	http://dx.doi.org/10.1109/VISUAL.1997.663898	317	322	C		Han-Wei Shen;David L. Kao	NASA Ames Res. Center, Moffett Field, CA, USA|c|;	10.1109/VISUAL.1995.480817;10.1109/VISUAL.1993.398848;10.1109/VISUAL.1996.567784	view synthesis, dynamic scene analysis, modeling from image sequences, computer vision and scene understanding, virtual worlds	MRJ Technology Solutions NASA Ames Research Center NASA Ames Research Center##MRJ Technology Solutions NASA Ames Research Center NASA Ames Research Center
Vis	1997	The motion map: efficient computation of steady flow animations	10.1109/VISUAL.1997.663899	http://dx.doi.org/10.1109/VISUAL.1997.663899	323	328	C		Bruno Jobard;Wilfrid Lefer	Lab., Calais, France|c|;	10.1109/VISUAL.1994.346313		Lab., Calais, France|c|;
Vis	1997	Integrated volume compression and visualization	10.1109/VISUAL.1997.663900	http://dx.doi.org/10.1109/VISUAL.1997.663900	329	336	C		Tzi-cker Chiueh;Chuan-Kai Yang;Taosong He;Hanspeter Pfister;Arie E. Kaufman	Center for Visual Comput., State Univ. of New York, Stony Brook, NY, USA|c|;;;;	10.1109/VISUAL.1993.398845	Volume Compression, Fourier Projection Theorem, Discrete Hartley Transform, Image Compositing	Center for Visual Comput., State Univ. of New York, Stony Brook, NY, USA|c|;;;;
Vis	1997	Multiresolution compression and reconstruction	10.1109/VISUAL.1997.663901	http://dx.doi.org/10.1109/VISUAL.1997.663901	337	346	C		Oliver G. Staadt;Markus H. Gross;Roger Weber	Dept. of Comput. Sci., Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;;		wavelets, isosurfaces, volumes, triangulation, tetrahedralization, meshing, oracles	Dept. of Comput. Sci., Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;;
Vis	1997	Optimized geometry compression for real-time rendering	10.1109/VISUAL.1997.663902	http://dx.doi.org/10.1109/VISUAL.1997.663902	347	354	C		Mike M. Chow	MIT, Cambridge, MA, USA|c|	10.1109/VISUAL.1996.568125		Massachusetts Institute of Technology
Vis	1997	Architectural walkthroughs using portal textures	10.1109/VISUAL.1997.663903	http://dx.doi.org/10.1109/VISUAL.1997.663903	355	362	C		Daniel G. Aliaga;Anselmo Lastra	Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;	10.1109/VISUAL.1996.567774	visibility culling, cells, portals, textures, sample points, morphing	University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill
Vis	1997	Repairing CAD models	10.1109/VISUAL.1997.663904	http://dx.doi.org/10.1109/VISUAL.1997.663904	363	370	C		Gill Barequet;Subodh Kumar	Dept. of Comput. Sci., Johns Hopkins Univ., Baltimore, MD, USA|c|;			Johns Hopkins University##Johns Hopkins University
Vis	1997	Dynamic smooth subdivision surfaces for data visualization	10.1109/VISUAL.1997.663905	http://dx.doi.org/10.1109/VISUAL.1997.663905	371	377	C		Chhandomay Mandal;Hong Qin;Baba C. Vemuri	Dept. of Comput. & Inf. Sci. & Eng., Florida Univ., Gainesville, FL, USA|c|;;		Visualization, Subdivision Surfaces, Dynamics, Finite Elements, Interactive Techniques	University of Florida Gainesville##University of Florida Gainesville##University of Florida Gainesville
Vis	1997	Smooth hierarchical surface triangulations	10.1109/VISUAL.1997.663906	http://dx.doi.org/10.1109/VISUAL.1997.663906	379	386	C		Tran S. Gieng;Bernd Hamann;Kenneth I. Joy;Gregory L. Schussman;Issac J. Trotts	Center for Image Process. & Integrated Comput., California Univ., Davis, CA, USA|c|;;;;	10.1109/VISUAL.1996.568126;10.1109/VISUAL.1996.568124	mesh simplification, triangle meshes,level-of-detail representation, shape approximation	University of California##University of California##University of California##University of California##University of California
Vis	1997	The multilevel finite element method for adaptive mesh optimization and visualization of volume data	10.1109/VISUAL.1997.663907	http://dx.doi.org/10.1109/VISUAL.1997.663907	387	394	C		Roberto Grosso;Christoph Lürig;Thomas Ertl	Comput. Graphics Group, Erlangen-Nurnberg Univ., Germany|c|;;	10.1109/VISUAL.1996.568127;10.1109/VISUAL.1996.568124;10.1109/VISUAL.1995.480805;10.1109/VISUAL.1996.568121;10.1109/VISUAL.1993.398852;10.1109/VISUAL.1995.480806;10.1109/VISUAL.1996.567606		UniversitÃ¤t Erlangen-NÃ¼rnberg##UniversitÃ¤t Erlangen-NÃ¼rnberg##UniversitÃ¤t Erlangen-NÃ¼rnberg
Vis	1997	Simplifying polygonal models using successive mappings	10.1109/VISUAL.1997.663908	http://dx.doi.org/10.1109/VISUAL.1997.663908	395	402	C		Jonathan D. Cohen;Dinesh Manocha;Marc Olano	North Carolina Univ., Chapel Hill, NC, USA|c|;;		model simplification,levels-of-detail, surface approximation, projection, linear programming	University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill
Vis	1997	Controlled simplification of genus for polygonal models 	10.1109/VISUAL.1997.663909	http://dx.doi.org/10.1109/VISUAL.1997.663909	403	410	C		Jihad El-Sana;Amitabh Varshney	State Univ. of New York, Stony Brook, NY, USA|c|;			State University of New York at Stony Brook##State University of New York at Stony Brook
Vis	1997	Vortex identification-applications in aerodynamics: a case study	10.1109/VISUAL.1997.663910	http://dx.doi.org/10.1109/VISUAL.1997.663910	413	416	C		David N. Kenwright;Robert Haimes	NASA Ames Res. Center, Moffett Field, CA, USA|c|;	10.1109/VISUAL.1996.568137;10.1109/VISUAL.1994.346327;10.1109/VISUAL.1991.175773		MRJ Technology Solutions Inc. Massachusetts Institute of Technology##MRJ Technology Solutions Inc. Massachusetts Institute of Technology
Vis	1997	exVis: developing a wind tunnel data visualization tool	10.1109/VISUAL.1997.663911	http://dx.doi.org/10.1109/VISUAL.1997.663911	417	420	C		Samuel P. Uselton	MRJ Technol. Solutions, NASA Ames Res. Center, Moffett Field, CA, USA|c|			MRJ Technology Solutions y
Vis	1997	Strategies for effectively visualizing 3D flow with volume LIC	10.1109/VISUAL.1997.663912	http://dx.doi.org/10.1109/VISUAL.1997.663912	421	424	C		Victoria Interrante;Chester Grosch	;	10.1109/VISUAL.1993.398877;10.1109/VISUAL.1996.567784;10.1109/VISUAL.1994.346313;10.1109/VISUAL.1996.567777;10.1109/VISUAL.1994.346312		Old Dominion University##Old Dominion University
Vis	1997	Towards efficient visualization support for single-block and multi-block datasets	10.1109/VISUAL.1997.663913	http://dx.doi.org/10.1109/VISUAL.1997.663913	425	428	C		Jean-Marie Favre	Swiss Center for Sci. Comput., Switzerland|c|			ABB Corp. Research Ltd
Vis	1997	Brushing techniques for exploring volume datasets	10.1109/VISUAL.1997.663914	http://dx.doi.org/10.1109/VISUAL.1997.663914	429	432	C		Pak Chung Wong;R. Daniel Bergeron	Dept. of Comput. Sci., New Hampshire Univ., Durham, NH, USA|c|;	10.1109/VISUAL.1995.480811;10.1109/VISUAL.1996.567800		University of New Hampshire
Vis	1997	Interactive volume rendering for virtual colonoscopy	10.1109/VISUAL.1997.663915	http://dx.doi.org/10.1109/VISUAL.1997.663915	433	436	C		Suya You;Lichan Hong;Ming Wan;Kittiboon Junyaprasert;Arie E. Kaufman;Shigeru Muraki;Yong Zhou;Mark Wax;Zhengrong Liang	Center for Visual Comput., State Univ. of New York, Stony Brook, NY, USA|c|;;;;;;;;		Virtual Colonoscopy,Endoscopy,Visibility,Interactive Navigation,Volume Rendering,Surface Rendering, Parallel Processing, Virtual Environment	Radiology State University of New York at Stony Brook Stony Brook##Radiology State University of New York at Stony Brook Stony Brook##Radiology State University of New York at Stony Brook Stony Brook##Radiology State University of New York at Stony Brook Stony Brook##Radiology State University of New York at Stony Brook Stony Brook##Radiology State University of New York at Stony Brook Stony Brook##Radiology State University of New York at Stony Brook Stony Brook##Radiology State University of New York at Stony Brook Stony Brook##Radiology State University of New York at Stony Brook Stony Brook
Vis	1997	DNA visual and analytic data mining	10.1109/VISUAL.1997.663916	http://dx.doi.org/10.1109/VISUAL.1997.663916	437	441	C		Patrick Hoffman;Georges G. Grinstein;Kenneth A. Marx;Ivo Grosse;Eugene Stanley	Inst. for Visualization & Perception Res., Massachusetts Univ., Lowell, MA, USA|c|;;;;	10.1109/VISUAL.1995.485139		University of Massachusetts Lowell Lowell##University of Massachusetts Lowell Lowell##University of Massachusetts Lowell Lowell##Boston University Boston##Boston University Boston
Vis	1997	An interactive cerebral blood vessel exploration system	10.1109/VISUAL.1997.663917	http://dx.doi.org/10.1109/VISUAL.1997.663917	443	446	C		Anna Puig;Dani Tost;Isabel Navazo	Polytech. Univ. of Catalonia, Spain|c|;;	10.1109/VISUAL.1995.480790	Volume Modelling and Rendering, Medical Applications, Cerebral Blood Vessel	Polytechnical University of Catalonia##Polytechnical University of Catalonia##Polytechnical University of Catalonia
Vis	1997	Instructional software for visualizing optical phenomena	10.1109/VISUAL.1997.663918	http://dx.doi.org/10.1109/VISUAL.1997.663918	447	450	C		David C. Banks;John T. Foley;Kiril Vidimce;Ming-Hoe Kiu	NSF Eng. Res. Center, Mississippi State Univ., MS, USA|c|;;;			NSF Eng. Res. Center, Mississippi State Univ., MS, USA|c|;;;
Vis	1997	Case study: wildfire visualization	10.1109/VISUAL.1997.663919	http://dx.doi.org/10.1109/VISUAL.1997.663919	451	454	C		James P. Ahrens;Patrick S. McCormick;James Bossert;Jon Reisner;Judith Winterkamp	Adv. Comput. Lab., Los Alamos Nat. Lab., NM, USA|c|;;;;	10.1109/VISUAL.1994.346291		Adv. Comput. Lab., Los Alamos Nat. Lab., NM, USA|c|;;;;
Vis	1997	Visualization of geometric algorithms in an electronic classroom	10.1109/VISUAL.1997.663920	http://dx.doi.org/10.1109/VISUAL.1997.663920	455	458	C		Maria Shneerson;Ayellet Tal	Dept. of Appl. Math., Weizmann Inst. of Sci., Rehovot, Israel|c|;		Algorithm animation, Visualization in Education, Geometric algorithms 	The Weizmann Institute of Science Technion â€“ Israel Institute of Technology Rehovot
Vis	1997	Collaborative augmented reality: exploring dynamical systems	10.1109/VISUAL.1997.663921	http://dx.doi.org/10.1109/VISUAL.1997.663921	459	462	C		Anton L. Fuhrmann;Helwig Löffelmann;Dieter Schmalstieg	Wien Univ. of Technol., Austria|c|;;	10.1109/VISUAL.1996.568128	virtual environments, scientific visualization, dynamical systems, augmented reality	Vienna University of Technology##Vienna University of Technology##Vienna University of Technology
Vis	1997	Case study: visualizing customer segmentations produced by self organizing maps	10.1109/VISUAL.1997.663922	http://dx.doi.org/10.1109/VISUAL.1997.663922	463	466	C		Holly E. Rushmeier;Richard D. Lawrence;George Almási	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;			IBM Thomas J. Watson Research Center##IBM Thomas J. Watson Research Center##IBM Thomas J. Watson Research Center
Vis	1997	Pearls found on the way to the ideal interface for scanned probe microscopes	10.1109/VISUAL.1997.663923	http://dx.doi.org/10.1109/VISUAL.1997.663923	467	470	C		Russell M. Taylor II;Jun Chen;Shoji Okimoto;Noel Llopis-Artime;Vernon L. Chi;Frederick P. Brooks Jr.;Michael R. Falvo;Scott Paulson;Pichet Thiansathaporn;David Glick;Sean Washburn;Richard Superfine	Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;;;;;;;;;		scientific visualization, interactive graphics, virtual environment, scanning tunneling microscopy, atomic force microscopy, user interface, telepresence, teleoperation, haptic, force	University of North Carolina##University of North Carolina##University of North Carolina##University of North Carolina##University of North Carolina##University of North Carolina##University of North Carolina##University of North Carolina##University of North Carolina##University of North Carolina##University of North Carolina##University of North Carolina##University of North Carolina
Vis	1997	Viewing IGES files through VRML	10.1109/VISUAL.1997.663924	http://dx.doi.org/10.1109/VISUAL.1997.663924	471	474	C		Jed Marti	Defense Group Inc., Salt Lake City, UT, USA|c|		Computer-aided Design, Applications of Visualization	Defense Group Inc., Salt Lake City, UT, USA|c|
Vis	1997	Visualization of plant growth	10.1109/VISUAL.1997.663925	http://dx.doi.org/10.1109/VISUAL.1997.663925	475	478	C		Jeremy J. Loomis;Xiuwen Liu;Zhaohua Ding;Kikuo Fujimura;Michael L. Evans;Hideo Ishikawa	Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA|c|;;;;;		Shape representation, image sequence analysis, non-rigid motion, plant biology	The Ohio State University##The Ohio State University
Vis	1997	Determination of unknown particle charges in a thunder cloud based upon detected electric field vectors	10.1109/VISUAL.1997.663926	http://dx.doi.org/10.1109/VISUAL.1997.663926	479	482	C		Dan Drake;Thomas Simpson;Larry Smithmier;Penny Rheingans	Dept. of Comput. Sci., Mississippi Univ., MS, USA|c|;;;	10.1109/VISUAL.1996.567777;10.1109/VISUAL.1994.346313;10.1109/VISUAL.1993.398850;10.1109/VISUAL.1996.568139;10.1109/VISUAL.1996.567752		University of Mississippi##University of Mississippi##University of Mississippi##University of Mississippi
Vis	1997	Interactive visualization of aircraft and power generation engines	10.1109/VISUAL.1997.663927	http://dx.doi.org/10.1109/VISUAL.1997.663927	483	486	C		Lisa Sobierajski Avila;William J. Schroeder	GE Corp. Res. & Dev., Miskayuna, NY, USA|c|;	10.1109/VISUAL.1996.567752;10.1109/VISUAL.1997.663883		GE Corporate Research & Development Niskayuna##GE Corporate Research & Development Niskayuna
Vis	1997	Case study: efficient visualization of physical and structural properties in crash-worthiness simulations	10.1109/VISUAL.1997.663928	http://dx.doi.org/10.1109/VISUAL.1997.663928	487	490	C		Sven Kuschfeldt;Thomas Ertl;Michael Holzner	Comput. Graphics Group, Erlangen-Nurnberg Univ., Germany|c|;;	10.1109/VISUAL.1996.568111;10.1109/VISUAL.1992.235200;10.1109/VISUAL.1993.398895;10.1109/VISUAL.1993.398878		Comput. Graphics Group, Erlangen-Nurnberg Univ., Germany|c|;;
Vis	1997	Visualization of rotation fields	10.1109/VISUAL.1997.663929	http://dx.doi.org/10.1109/VISUAL.1997.663929	491	494	C		Mark A. Livingston	Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|	10.1109/VISUAL.1992.235211;10.1109/VISUAL.1994.346330;10.1109/VISUAL.1992.235193;10.1109/VISUAL.1992.235227;10.1109/VISUAL.1994.346315;10.1109/VISUAL.1991.175789;10.1109/VISUAL.1993.398867;10.1109/VISUAL.1994.346338;10.1109/VISUAL.1993.398846	Scientific visualization, tufts, streamlines, stream surfaces	University of North Carolina at Chapel Hill
Vis	1997	Isosurface extraction using particle systems	10.1109/VISUAL.1997.663930	http://dx.doi.org/10.1109/VISUAL.1997.663930	495	498	C		Patricia Crossno;Edward Angel	Dept. of Comput. Sci., New Mexico Univ., Albuquerque, NM, USA|c|;	10.1109/VISUAL.1993.398880		University of New##University of New
Vis	1997	A visualization of music	10.1109/VISUAL.1997.663931	http://dx.doi.org/10.1109/VISUAL.1997.663931	499	503	C		Sean M. Smith;Glen N. Williams	Dept. of Comput. Sci., Texas A&M Univ., College Station, TX, USA|c|;			Texas A&M University##Texas A&M University
Vis	1997	Terascale Visualization: Approaches, Pitfalls And Issues	10.1109/VISUAL.1997.663932	http://dx.doi.org/10.1109/VISUAL.1997.663932	507	509	M		Carol L. Hunter;Roger Crawfis;Michael Cox;Bernd Hamann;Charles D. Hansen;Mark C. Miller	NASA Ames Research Center|c|;;;;			NASA Ames Research Center|c|;;;;
Vis	1997	Information Exploration Shootout Project And Benchmark Data Sets: Evaluating How Visualization Does In Analyzing Real-World Data Analysis Problems	10.1109/VISUAL.1997.663933	http://dx.doi.org/10.1109/VISUAL.1997.663933	511	513	M		Georges G. Grinstein;Sharon J. Laskowski;Graham J. Wills;Bernice E. Rogowitz	National Institute for Standards and Technology|c|;;			National Institute for Standards and Technology|c|;;
Vis	1997	Perceptual Measures For Effective Visualizations	10.1109/VISUAL.1997.663934	http://dx.doi.org/10.1109/VISUAL.1997.663934	515	517	M		Holly E. Rushmeier;Harrison H. Barrett;Penny Rheingans;Samuel P. Uselton;Andrew Watson	University of Arizona|c|;;;			University of Arizona|c|;;;
InfoVis	1998	WEBPATH-a three dimensional Web history	10.1109/INFVIS.1998.729553	http://dx.doi.org/10.1109/INFVIS.1998.729553	3	10, 148	C		Emmanuel Frécon;Gareth Smith	Swedish Inst. of Comput. Sci., Sweden|c|;		Virtual Environments, World-Wide-Web,Visualisation, Web Browsing	Lancaster University * Box##Lancaster University * Box
InfoVis	1998	Traversal-based visualization of data structures	10.1109/INFVIS.1998.729554	http://dx.doi.org/10.1109/INFVIS.1998.729554	11	18	C		Jeffrey L. Korn;Andrew W. Appel	Dept. of Comput. Sci., Princeton Univ., NJ, USA|c|;			Princeton University##Princeton University
InfoVis	1998	Reconfigurable disc trees for visualizing large hierarchical information space	10.1109/INFVIS.1998.729555	http://dx.doi.org/10.1109/INFVIS.1998.729555	19	25, 149	C		Chang-Sung Jeong;Alex T. Pang	Dept. of Electron. Eng., Korea Univ., Seoul, South Korea|c|;	10.1109/INFVIS.1995.528689;10.1109/INFVIS.1997.636792;10.1109/VISUAL.1991.175815;10.1109/VISUAL.1996.567745	Information visualization, disc tree,compact disc tree, plane disc tree, hierarchy	Korea University University of California Seoul##Korea University University of California Seoul
InfoVis	1998	An interactive view for hierarchical clustering	10.1109/INFVIS.1998.729556	http://dx.doi.org/10.1109/INFVIS.1998.729556	26	31, 150	C		Graham J. Wills	Lucent Technol., AT&T Bell Labs., Naperville, IL, USA|c|	10.1109/INFVIS.1996.559216		Lucent Technologies (Bell Laboratories)
InfoVis	1998	Dynamic aggregation with circular visual designs	10.1109/INFVIS.1998.729557	http://dx.doi.org/10.1109/INFVIS.1998.729557	35	43, 151	C		Mei C. Chuah	Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA|c|	10.1109/INFVIS.1997.636787;10.1109/VISUAL.1992.235206		Carnegie Mellon University Pittsburgh
InfoVis	1998	The generalized detail in-context problem	10.1109/INFVIS.1998.729558	http://dx.doi.org/10.1109/INFVIS.1998.729558	44	51, 152	C		Alan Keahey	Los Alamos Nat. Lab., NM, USA|c|	10.1109/INFVIS.1997.636786;10.1109/INFVIS.1997.636718;10.1109/INFVIS.1996.559214		Los Alamos National Laboratory
InfoVis	1998	Similarity clustering of dimensions for an enhanced visualization of multidimensional data	10.1109/INFVIS.1998.729559	http://dx.doi.org/10.1109/INFVIS.1998.729559	52	60, 153	C		Mihael Ankerst;Stefan Berchtold;Daniel A. Keim	Munich Univ., Germany|c|;;	10.1109/VISUAL.1990.146402;10.1109/VISUAL.1994.346302;10.1109/VISUAL.1995.485140		University of Munich####Martin-Luther-University Halle-Wittenberg
InfoVis	1998	An operator interaction framework for visualization systems	10.1109/INFVIS.1998.729560	http://dx.doi.org/10.1109/INFVIS.1998.729560	63	70	C		Ed Huai-hsin Chi;John Riedl	Dept. of Comput. Sci. & Eng., Minnesota Univ., MN, USA|c|;	10.1109/VISUAL.1996.567796;10.1109/INFVIS.1996.559213;10.1109/INFVIS.1995.528686;10.1109/INFVIS.1997.636793;10.1109/INFVIS.1997.636792;10.1109/VISUAL.1991.175815;10.1109/VISUAL.1995.480801;10.1109/INFVIS.1997.636761	information visualization, operators, user interactions, view/value, framework, spreadsheet, design, extensibility, visualization systems	University of Minnesota##University of Minnesota
InfoVis	1998	Algorithm visualization for distributed environments	10.1109/INFVIS.1998.729561	http://dx.doi.org/10.1109/INFVIS.1998.729561	71	78, 154	C		Yoram Moses;Zvi Polunsky;Ayellet Tal;Leonid Ulitsky	Dept. of Electr. Eng., Technion-Israel Inst. of Technol., Haifa, Israel|c|;;;	10.1109/VISUAL.1997.663920		The Weizmann Inst. of Science The Weizmann Inst. of Science Technion â€“ Israel Institute of Technology##The Weizmann Inst. of Science The Weizmann Inst. of Science Technion â€“ Israel Institute of Technology##The Weizmann Inst. of Science The Weizmann Inst. of Science Technion â€“ Israel Institute of Technology##The Weizmann Inst. of Science The Weizmann Inst. of Science Technion â€“ Israel Institute of Technology
InfoVis	1998	IVORY-an object-oriented framework for physics-based information visualization in Java	10.1109/INFVIS.1998.729562	http://dx.doi.org/10.1109/INFVIS.1998.729562	79	86, 155	C		Thomas C. Sprenger;Markus H. Gross;Daniel Bielser;T. Strasser	Dept. of Comput. Sci., Fed. Inst. of Technol., Zurich, Switzerland|c|;;;	10.1109/INFVIS.1995.528691;10.1109/VISUAL.1996.567752;10.1109/INFVIS.1997.636759;10.1109/INFVIS.1995.528688;10.1109/INFVIS.1996.559226	three-dimensional information visualization,physics-based graph layout, object-oriented visualization toolkit,multidimensional information modeling, time varying data	Swiss Federal Institute of Technology (ETH)##Swiss Federal Institute of Technology (ETH)##Swiss Federal Institute of Technology (ETH)##Swiss Federal Institute of Technology (ETH)
InfoVis	1998	Geographic visualization: designing manipulable maps for exploring temporally varying georeferenced statistics	10.1109/INFVIS.1998.729563	http://dx.doi.org/10.1109/INFVIS.1998.729563	87	94, 156	C		Alan M. MacEachren;Francis P. Boscoe;Daniel Haug;Linda Pickle	Dept. of Geogr., Pennsylvania State Univ., University Park, PA, USA|c|;;;	10.1109/VISUAL.1991.175794;10.1109/VISUAL.1997.663874;10.1109/VISUAL.1992.235201		Penn State University##
InfoVis	1998	Saying it in graphics: from intentions to visualizations	10.1109/INFVIS.1998.729564	http://dx.doi.org/10.1109/INFVIS.1998.729564	97	101	C		Stephan M. Kerpedjiev;Giuseppe Carenini;Nancy L. Green;Johanna D. Moore;Steven F. Roth	Carnegie Mellon Univ., Pittsburgh, PA, USA|c|;;;;			Carnegie Mellon University Pittsburgh######Carnegie Mellon University Pittsburgh########Carnegie Mellon University Pittsburgh
InfoVis	1998	Visualizing decision table classifiers	10.1109/INFVIS.1998.729565	http://dx.doi.org/10.1109/INFVIS.1998.729565	102	105, 157	C		Barry G. Becker	Silicon Graphics Inc., Mountain View, CA, USA|c|	10.1109/VISUAL.1990.146386		Silicon Graphics Inc
InfoVis	1998	Comparative visualization of protein structure-sequence alignments	10.1109/INFVIS.1998.729566	http://dx.doi.org/10.1109/INFVIS.1998.729566	106	110, 158	C		Marc D. Hansen;Doanna Meads;Alex T. Pang	Dept. of Comput. Sci., California Univ., CA, USA|c|;;	10.1109/VISUAL.1996.567796;10.1109/VISUAL.1996.568116;10.1109/VISUAL.1995.480794	proteins, structure, alignment, fold recognition, threading, similarity, glyphs, streamlines, ribbons,amino acids	UCSC##UCSC##UCSC
InfoVis	1998	LensBar-visualization for browsing and filtering large lists of data	10.1109/INFVIS.1998.729567	http://dx.doi.org/10.1109/INFVIS.1998.729567	113	120, 159	C		Toshiyuki Masui	Sony Comput. Sci. Labs. Inc., Tokyo, Japan|c|			Sony Computer Science Laboratories Inc
InfoVis	1998	The shape of Shakespeare: visualizing text using implicit surfaces	10.1109/INFVIS.1998.729568	http://dx.doi.org/10.1109/INFVIS.1998.729568	121	129, 160	C		Randall M. Rohrer;John L. Sibert;David S. Ebert	Dept. of Electr. Eng. & Comput. Sci., George Washington Univ., Washington, DC, USA|c|;;	10.1109/INFVIS.1997.636761;10.1109/INFVIS.1997.636759;10.1109/INFVIS.1995.528686;10.1109/VISUAL.1996.568110;10.1109/INFVIS.1996.559228	information visualization, text visualization, procedural visualization, implicit surface modeling, blobby models, document clustering, information retrieval, graphics, user interfaces	The George Washington University##University of Maryland Baltimore County##The George Washington University
InfoVis	1998	BiblioMapper: a cluster-based information visualization technique	10.1109/INFVIS.1998.729569	http://dx.doi.org/10.1109/INFVIS.1998.729569	130	136	C		Min Song	Sch. of Libr. & Inf. Sci., Indiana Univ., Bloomington, IN, USA|c|	10.1109/INFVIS.1996.559228;10.1109/INFVIS.1995.528686	Visualization, Information Retrieval,Clustering Algorithms, Textual Information	Indiana University
InfoVis	1998	Multi-faceted insight through interoperable visual information analysis paradigms	10.1109/INFVIS.1998.729570	http://dx.doi.org/10.1109/INFVIS.1998.729570	137	144, 161	C		Elizabeth G. Hetzler;Paul Whitney;Lou Martucci;James J. Thomas	Pacific Northwest Lab., Richland, WA, USA|c|;;;	10.1109/INFVIS.1997.636789;10.1109/INFVIS.1997.636793;10.1109/INFVIS.1995.528686;10.1109/INFVIS.1996.559228;10.1109/INFVIS.1997.636761	information visualization, user scenario,information analysis, document analysis	Pacific Northwest Lab., Richland, WA, USA|c|;;;
Vis	1998	Large scale terrain visualization using the restricted quadtree triangulation	10.1109/VISUAL.1998.745280	http://dx.doi.org/10.1109/VISUAL.1998.745280	19	26	C		Renato Pajarola	Inst. of Theor. Comput. Sci., Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|	10.1109/VISUAL.1997.663860;10.1109/VISUAL.1995.480800;10.1109/VISUAL.1995.480799	algorithms, computer graphics, virtual reality, triangulated surfaces, terrain visualization, terascale visualization	Inst. of Theor. Comput. Sci., Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|
Vis	1998	Contour interpolation and surface reconstruction of smooth terrain models	10.1109/VISUAL.1998.745281	http://dx.doi.org/10.1109/VISUAL.1998.745281	27	33	C		Jianyun Chai;Takaharu Miyoshi;Eihachiro Nakamae	Sanei Co., Japan|c|;;		PDE surfaces, terrain modeling, shape reconstruction, contour interpolation	Hiroshima Institute of Technology##Hiroshima Institute of Technology##Hiroshima Institute of Technology##Hiroshima Institute of Technology
Vis	1998	Smooth view-dependent level-of-detail control and its application to terrain rendering	10.1109/VISUAL.1998.745282	http://dx.doi.org/10.1109/VISUAL.1998.745282	35	42	C		Hugues Hoppe	Microsoft Res., USA|c|	10.1109/VISUAL.1997.663865;10.1109/VISUAL.1996.567600;10.1109/VISUAL.1996.568126;10.1109/VISUAL.1997.663860;10.1109/VISUAL.1997.663908		Microsoft Research
Vis	1998	Efficient implementation of multi-triangulations	10.1109/VISUAL.1998.745283	http://dx.doi.org/10.1109/VISUAL.1998.745283	43	50	C		Leila De Floriani;Paola Magillo;Enrico Puppo	Genoa Univ., Italy|c|;;	10.1109/VISUAL.1997.663865;10.1109/VISUAL.1997.663860		UniversitÃ di Genova Enrico Puppo Istituto per la Matematica Applicata â€“ Consiglio Nazionale delle Ricerche y##UniversitÃ di Genova Enrico Puppo Istituto per la Matematica Applicata â€“ Consiglio Nazionale delle Ricerche y
Vis	1998	Visualization of scalar topology for structural enhancement	10.1109/VISUAL.1998.745284	http://dx.doi.org/10.1109/VISUAL.1998.745284	51	58	C		Chandrajit L. Bajaj;Valerio Pascucci;Daniel Schikore	Dept. of Comput. Sci., Texas Univ., Austin, TX, USA|c|;;	10.1109/VISUAL.1992.235199;10.1109/VISUAL.1995.480803;10.1109/VISUAL.1991.175782;10.1109/VISUAL.1995.485154;10.1109/VISUAL.1991.175773;10.1109/VISUAL.1997.663875;10.1109/VISUAL.1994.346334;10.1109/VISUAL.1995.480795	Scientific Visualization, Scalar Fields, Curves and Surfaces, Vector Topology	TICAM University of Texas##TICAM University of Texas##TICAM University of Texas
Vis	1998	A general method for preserving attribute values on simplified meshes	10.1109/VISUAL.1998.745285	http://dx.doi.org/10.1109/VISUAL.1998.745285	59	66	C		Paolo Cignoni;Claudio Montani;Roberto Scopigno;Claudio Rocchini	Ist. di Elaborazione dell''Inf., Italy|c|;;;	10.1109/VISUAL.1993.398868	surface simplification, detail preservation,texture mapping	Istituto di Elaborazione dell'Informazione â€“ Consiglio Nazionale delle Ricerche##Istituto di Elaborazione dell'Informazione â€“ Consiglio Nazionale delle Ricerche##Istituto di Elaborazione dell'Informazione â€“ Consiglio Nazionale delle Ricerche##Istituto di Elaborazione dell'Informazione â€“ Consiglio Nazionale delle Ricerche
Vis	1998	Surface reconstruction with anisotropic density-scaled alpha shapes	10.1109/VISUAL.1998.745286	http://dx.doi.org/10.1109/VISUAL.1998.745286	67	72	C		Marek Teichmann;Michael V. Capps	Lab. for Comput. Sci., MIT, Cambridge, MA, USA|c|;			Massachusetts Institute of Technology##Massachusetts Institute of Technology
Vis	1998	Level of detail visualization of scalar data sets on irregular surface meshes	10.1109/VISUAL.1998.745287	http://dx.doi.org/10.1109/VISUAL.1998.745287	73	77	C		Georges-Pierre Bonneau;Alexandre Gerussi	CNRS, Grenoble, France|c|;	10.1109/VISUAL.1996.567602	wavelets, non-regular triangulations,compression, visualization	LMC -CNRS##LMC -CNRS
Vis	1998	Tracking scalar features in unstructured datasets	10.1109/VISUAL.1998.745288	http://dx.doi.org/10.1109/VISUAL.1998.745288	79	86	C		Deborah Silver;Xin Wang	Dept. of Electr. & Comput. Eng., Rutgers Univ., Piscataway, NJ, USA|c|;	10.1109/VISUAL.1996.567807;10.1109/VISUAL.1995.480809;10.1109/VISUAL.1995.480789;10.1109/VISUAL.1997.663886	Scientific Visualization, Time-varying Visualization,Feature Tracking, Computer Vision, CFD	Rutgers University##Rutgers University
Vis	1998	Feature detection in linked derived spaces	10.1109/VISUAL.1998.745289	http://dx.doi.org/10.1109/VISUAL.1998.745289	87	94	C		Chris Henze	NASA Ames Res. Center, Moffett Field, CA, USA|c|	10.1109/VISUAL.1996.568115;10.1109/VISUAL.1996.568121;10.1109/VISUAL.1994.346327;10.1109/VISUAL.1995.485139;10.1109/VISUAL.1991.175794;10.1109/VISUAL.1994.346302	computational fluid dynamics, feature detection, flow visualization, multivariate visualization, brushing	MRJ Technology Solutions Inc
Vis	1998	Extremal feature extraction from 3-D vector and noisy scalar fields	10.1109/VISUAL.1998.745290	http://dx.doi.org/10.1109/VISUAL.1998.745290	95	102	C		Chi-Keung Tang;Gérard G. Medioni	Univ. of Southern California, Los Angeles, CA, USA|c|;	10.1109/VISUAL.1991.175782;10.1109/VISUAL.1994.346327;10.1109/VISUAL.1994.346329;10.1109/VISUAL.1994.346328	Surface and curve extremality, surface fitting, scalar and vector field visualization, Marching Cubes	University of Southern California##University of Southern California
Vis	1998	Feature comparisons of vector fields using Earth mover's distance	10.1109/VISUAL.1998.745291	http://dx.doi.org/10.1109/VISUAL.1998.745291	103	109	C		Yingmei Lavin;Rajesh Batra;Lambertus Hesselink	Dept. of Phys., Stanford Univ., CA, USA|c|;;	10.1109/VISUAL.1997.663858;10.1109/VISUAL.1997.663857		Stanford University##Stanford University##Stanford University Stanford
Vis	1998	Building perceptual textures to visualize multidimensional datasets	10.1109/VISUAL.1998.745292	http://dx.doi.org/10.1109/VISUAL.1998.745292	111	118	C		Christopher G. Healey;James T. Enns	North Carolina State Univ., Raleigh, NC, USA|c|;	10.1109/VISUAL.1996.568118;10.1109/VISUAL.1993.398872	computer graphics, experimental design, human vision, multidimensional dataset, oceanography, perception, preattentive processing, scientific visualization, texture, typhoon	North Carolina State University##North Carolina State University
Vis	1998	Efficient co-triangulation of large data sets	10.1109/VISUAL.1998.745293	http://dx.doi.org/10.1109/VISUAL.1998.745293	119	126	C		Henrik Weimer;Joe D. Warren;Jane Troutner;Wendell Wiggins;John Shrout	Rice Univ., Houston, TX, USA|c|;;;;	10.1109/VISUAL.1994.346336;10.1109/VISUAL.1996.568124;10.1109/VISUAL.1996.568122	Delaunay triangulation, scattered data, multidimensional approximation, higher-dimensional approximation, computational geometry, data-structures	Rice University##Rice University##Rice University##Rice University##Rice University##Rice University
Vis	1998	Visualizing diffusion tensor images of the mouse spinal cord	10.1109/VISUAL.1998.745294	http://dx.doi.org/10.1109/VISUAL.1998.745294	127	134	C		David H. Laidlaw;Eric T. Ahrens;David Kremers;Matthew J. Avalos;Russell E. Jacobs;Carol Readhead	California Inst. of Technol., Pasadena, CA, USA|c|;;;;;	10.1109/VISUAL.1992.235201	multi-valued visualization, tensor field visualization,oil painting	California Institute of Technology##Brown University
Vis	1998	Image-guided streamline placement on curvilinear grid surfaces	10.1109/VISUAL.1998.745295	http://dx.doi.org/10.1109/VISUAL.1998.745295	135	142	C		Xiaoyang Mao;Yuji Hatanaka;Hidenori Higashida;Atsumi Imamiya	Dept. of Comput. & Media Eng., Yamanashi Univ., Kofu, Japan|c|;;;	10.1109/VISUAL.1994.346312;10.1109/VISUAL.1995.480819	vector field visualization, flow visualization, streamline, curvilinear grid	Yamanashi University##Yamanashi University##Yamanashi University##Yamanashi University
Vis	1998	A higher-order method for finding vortex core lines	10.1109/VISUAL.1998.745296	http://dx.doi.org/10.1109/VISUAL.1998.745296	143	150	C		Martin Roth;Ronald Peikert	Center for Sci. Comput., Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;	10.1109/VISUAL.1996.568137;10.1109/VISUAL.1997.663912;10.1109/VISUAL.1995.480817;10.1109/VISUAL.1991.175773;10.1109/VISUAL.1997.663910;10.1109/VISUAL.1994.346327;10.1109/VISUAL.1996.567807;10.1109/VISUAL.1997.663857;10.1109/VISUAL.1993.398877;10.1109/VISUAL.1997.663858		ETH ZÃ¼rich##ETH ZÃ¼rich
Vis	1998	Automatic detection of open and closed separation and attachment lines	10.1109/VISUAL.1998.745297	http://dx.doi.org/10.1109/VISUAL.1998.745297	151	158	C		David N. Kenwright	MRJ Technol Solutions, NASA Ames Res. Center, Moffett Field, CA, USA|c|	10.1109/VISUAL.1994.346329;10.1109/VISUAL.1991.175773;10.1109/VISUAL.1990.146359;10.1109/VISUAL.1995.480817		MRJ Technology Solutions
Vis	1998	Isosurface extraction in time-varying fields using a temporal hierarchical index tree	10.1109/VISUAL.1998.745298	http://dx.doi.org/10.1109/VISUAL.1998.745298	159	166	C		Han-Wei Shen	MRJ Technol. Solutions, NASA Ames Res. Center, Moffett Field, CA, USA|c|	10.1109/VISUAL.1996.568123;10.1109/VISUAL.1997.663895;10.1109/VISUAL.1996.568121;10.1109/VISUAL.1998.745299;10.1109/VISUAL.1991.175780;10.1109/VISUAL.1995.480806	scalar field visualization, volume visualization, isosurface extraction, time-varying fields, marching cubes, span space	MRJ Technology Solutions / NASA Ames Research Center
Vis	1998	Interactive out-of-core isosurface extraction	10.1109/VISUAL.1998.745299	http://dx.doi.org/10.1109/VISUAL.1998.745299	167	174	C		Yi-Jen Chiang;Cláudio T. Silva;William J. Schroeder	;;	10.1109/VISUAL.1997.663888;10.1109/VISUAL.1997.663895;10.1109/VISUAL.1996.568121	Isosurface Extraction, Marching Cubes, Out-Of-Core Computation, Interval Tree, Scientific Visualization	Polytechnic University IBM T. J. Watson Research Center Kitware##Polytechnic University IBM T. J. Watson Research Center Kitware##Polytechnic University IBM T. J. Watson Research Center Kitware
Vis	1998	View dependent isosurface extraction	10.1109/VISUAL.1998.745300	http://dx.doi.org/10.1109/VISUAL.1998.745300	175	180	C		Yarden Livnat;Charles D. Hansen	Utah Univ., Salt Lake City, UT, USA|c|;	10.1109/VISUAL.1995.480806;10.1109/VISUAL.1996.568121;10.1109/VISUAL.1996.568144;10.1109/VISUAL.1998.745713;10.1109/VISUAL.1994.346308;10.1109/VISUAL.1996.568123;10.1109/VISUAL.1996.568127;10.1109/VISUAL.1994.346307;10.1109/VISUAL.1991.175780;10.1109/VISUAL.1994.346334		University of Utah##University of Utah
Vis	1998	The Gridfit algorithm: an efficient and effective approach to visualizing large amounts of spatial data	10.1109/VISUAL.1998.745301	http://dx.doi.org/10.1109/VISUAL.1998.745301	181	188	C		Daniel A. Keim;Annemarie Herrmann	Inst. of Comput. Sci., Halle-Wittenberg Univ., Halle, Germany|c|;	10.1109/VISUAL.1995.485139;10.1109/INFVIS.1995.528688;10.1109/VISUAL.1991.175794;10.1109/VISUAL.1990.146387;10.1109/VISUAL.1990.146402;10.1109/VISUAL.1993.398870;10.1109/VISUAL.1995.485140;10.1109/VISUAL.1994.346302;10.1109/INFVIS.1995.528690;10.1109/VISUAL.1990.146386	visualizing large data sets, visualizing spatially referenced data, visualizing geographical data, interfaces to databases	University of Halle-Wittenberg##University of Halle-Wittenberg
Vis	1998	TOPIC ISLANDS TM - a wavelet-based text visualization system	10.1109/VISUAL.1998.745302	http://dx.doi.org/10.1109/VISUAL.1998.745302	189	196	C		Nancy E. Miller;Pak Chung Wong;Mary Brewster;Harlan Foote	Pacific Northwest Lab., Richland, WA, USA|c|;;;	10.1109/VISUAL.1997.663872;10.1109/INFVIS.1995.528686;10.1109/VISUAL.1996.567800;10.1109/VISUAL.1997.663871;10.1109/VISUAL.1995.480811;10.1109/VISUAL.1994.346333;10.1109/VISUAL.1994.346332;10.1109/VISUAL.1992.235206	text visualization, information visualization,wavelet transform, information retrieval	Pacific Northwest National Laboratory â€ ##Pacific Northwest National Laboratory â€ ##Pacific Northwest National Laboratory â€ ##Pacific Northwest National Laboratory â€ ##Pacific Northwest National Laboratory â€
Vis	1998	Continuous cartogram construction	10.1109/VISUAL.1998.745303	http://dx.doi.org/10.1109/VISUAL.1998.745303	197	204	C		Donald H. House;Christopher J. Kocmoud	;		cartogram, value-by-area map, map transformation,anamorphosis, thematic cartography, constrained optimization	
Vis	1998	A concept for virtual reality tools for design reviews	10.1109/VISUAL.1998.745304	http://dx.doi.org/10.1109/VISUAL.1998.745304	205	210	C		Klaus Kremer	Heinz Nixdorf Inst., Paderborn Univ., Germany|c|		virtual reality, virtual environments, visualization, design reviews, product configuration, product structures, product attributes, CAD, PDM, EDM	Heinz Nixdorf Institute
Vis	1998	Efficient warping for architectural walkthroughs using layered depth images	10.1109/VISUAL.1998.745305	http://dx.doi.org/10.1109/VISUAL.1998.745305	211	215	C		Voicu Popescu;Anselmo Lastra;Daniel G. Aliaga;Manuel Menezes de Oliveira Neto	North Carolina Univ., Chapel Hill, NC, USA|c|;;;	10.1109/VISUAL.1997.663903	image-based rendering, parallel warping, occlusion compatible ordering for discrete images, portal, cell, exposure error, layered depth image, clipping, architectural walkthrough	University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill
Vis	1998	Visualizing differences in movies of cortical activity	10.1109/VISUAL.1998.745306	http://dx.doi.org/10.1109/VISUAL.1998.745306	217	224	C		Kay A. Robbins;David M. Senseman	Div. of Comput. Sci., Texas Univ., San Antonio, TX, USA|c|;	10.1109/VISUAL.1997.663899	scientific visualization, animation, video analysis	University of Texas at San Antonio##University of Texas at San Antonio
Vis	1998	A distributed blackboard architecture for interactive data visualization	10.1109/VISUAL.1998.745307	http://dx.doi.org/10.1109/VISUAL.1998.745307	225	231	C		Robert van Liere;Jan Harkes;Wim C. de Leeuw	Center for Math. & Comput. Sci., CWI, Amsterdam, Netherlands|c|;;	10.1109/VISUAL.1992.235202;10.1109/VISUAL.1991.175818;10.1109/VISUAL.1997.663896;10.1109/VISUAL.1996.567752;10.1109/VISUAL.1995.485143;10.1109/VISUAL.1992.235207;10.1109/VISUAL.1994.346304		Center for Math. & Comput. Sci., CWI, Amsterdam, Netherlands|c|;;
Vis	1998	Eliminating popping artifacts in sheet buffer-based splatting	10.1109/VISUAL.1998.745309	http://dx.doi.org/10.1109/VISUAL.1998.745309	239	245	C		Klaus Mueller;Roger Crawfis	Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA|c|;	10.1109/VISUAL.1996.567608;10.1109/VISUAL.1996.568119;10.1109/VISUAL.1995.480792;10.1109/VISUAL.1997.663882;10.1109/VISUAL.1993.398877;10.1109/VISUAL.1993.398852		The Ohio State University##The Ohio State University
Vis	1998	Accelerated ray-casting for curvilinear volumes	10.1109/VISUAL.1998.745310	http://dx.doi.org/10.1109/VISUAL.1998.745310	247	253	C		Lichan Hong;Arie E. Kaufman	Lucent Technol., AT&T Bell Labs., Naperville, IL, USA|c|;	10.1109/VISUAL.1993.398853;10.1109/VISUAL.1992.235228;10.1109/VISUAL.1996.567606	volume visualization, volume rendering, irregular grid, curvilinear grid, ray-casting, parallel rendering, dynamic simulation	Lucent Technologies Room##
Vis	1998	High quality rendering of attributed volume data	10.1109/VISUAL.1998.745311	http://dx.doi.org/10.1109/VISUAL.1998.745311	255	262	C		Ulf Tiede;Thomas Schiemann;Karl Heinz Höhne	Inst. of Math. & Comput. Sci. in Med., Eppendorf Univ. Hosp., Hamburg, Germany|c|;;		partial-volume-effect, ray-casting, tomographic data,Visible-Human-Project	Medicine University Hospital Eppendorf##Medicine University Hospital Eppendorf##Medicine University Hospital Eppendorf
Vis	1998	Simplifying surfaces with color and texture using quadric error metrics	10.1109/VISUAL.1998.745312	http://dx.doi.org/10.1109/VISUAL.1998.745312	263	269	C		Michael Garland;Paul S. Heckbert	Carnegie Mellon Univ., Pittsburgh, PA, USA|c|;	10.1109/VISUAL.1997.663908	surface simplification, multiresolution modeling, level of detail, quadric error metric, edge contraction, surface properties, discontinuity preservation	Carnegie Mellon University##Carnegie Mellon University
Vis	1998	A unified approach for simplifying polygonal and spline models	10.1109/VISUAL.1998.745313	http://dx.doi.org/10.1109/VISUAL.1998.745313	271	278	C		Meenakshisundaram Gopi;Dinesh Manocha	Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;	10.1109/VISUAL.1997.663909;10.1109/VISUAL.1997.663908;10.1109/VISUAL.1997.663883	model simplification, levels-of-detail, surface approximation, spline patches, surface fitting, dynamic tessellation	University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill
Vis	1998	Fast and memory efficient polygonal simplification	10.1109/VISUAL.1998.745314	http://dx.doi.org/10.1109/VISUAL.1998.745314	279	286	C		Peter Lindstrom;Greg Turk	Georgia Inst. of Technol., Atlanta, GA, USA|c|;	10.1109/VISUAL.1995.485142;10.1109/VISUAL.1997.663883;10.1109/VISUAL.1997.663908;10.1109/VISUAL.1997.663906		Georgia Institute of Technology##Georgia Institute of Technology
Vis	1998	Simplification of tetrahedral meshes	10.1109/VISUAL.1998.745315	http://dx.doi.org/10.1109/VISUAL.1998.745315	287	295	C		Issac J. Trotts;Bernd Hamann;Kenneth I. Joy;David F. Wiley	Center for Image Process. & Integrated Comput., California Univ., Davis, CA, USA|c|;;;	10.1109/VISUAL.1996.568126;10.1109/VISUAL.1996.568124;10.1109/VISUAL.1997.663906	approximation, hierarchical representation, mesh generation, multiresolution method, scattered data, spline, triangulation, visualization	University of California##University of California##University of California##University of California
Vis	1998	Interactive deformations from tensor fields	10.1109/VISUAL.1998.745316	http://dx.doi.org/10.1109/VISUAL.1998.745316	297	304	C		Ed Boring;Alex T. Pang	Dept. of Comput. Sci., California Univ., Santa Cruz, CA, USA|c|;	10.1109/VISUAL.1997.663929;10.1109/VISUAL.1996.567752;10.1109/VISUAL.1993.398849;10.1109/VISUAL.1991.175773;10.1109/VISUAL.1992.235193;10.1109/VISUAL.1995.485141;10.1109/VISUAL.1994.346330;10.1109/VISUAL.1991.175789;10.1109/VISUAL.1994.346326;10.1109/VISUAL.1997.663857;10.1109/VISUAL.1992.235224;10.1109/VISUAL.1996.568139;10.1109/VISUAL.1994.346315	tensor,stress, strain, shear, normal,directional flow, symmetric, antisymmetric, deviator, isotropic	University of California##University of California
Vis	1998	Real-time techniques for 3D flow visualization	10.1109/VISUAL.1998.745317	http://dx.doi.org/10.1109/VISUAL.1998.745317	305	312	C		Anton L. Fuhrmann;Eduard Gröller	Inst. of Comput. Graphics, Wien Univ., Austria|c|;	10.1109/VISUAL.1994.346312;10.1109/VISUAL.1997.663897;10.1109/VISUAL.1997.663921;10.1109/VISUAL.1991.175771;10.1109/VISUAL.1997.663912;10.1109/VISUAL.1993.398877	virtual environments, flow visualization, texturing, interaction, magic lens, focussing	Vienna University of Technology##Vienna University of Technology
Vis	1998	Wavelets over curvilinear grids	10.1109/VISUAL.1998.745318	http://dx.doi.org/10.1109/VISUAL.1998.745318	313	317	C		Gregory M. Nielson;Il-Hong Jung;Junwon Sung	Dept. of Comput. Sci. & Eng., Arizona State Univ., Tempe, AZ, USA|c|;;	10.1109/VISUAL.1997.663883;10.1109/VISUAL.1997.663872;10.1109/VISUAL.1997.663871		Arizona State University Tempe##Arizona State University Tempe##Arizona State University Tempe
Vis	1998	Image-based transfer function design for data exploration in volume visualization	10.1109/VISUAL.1998.745319	http://dx.doi.org/10.1109/VISUAL.1998.745319	319	326	C		Shiaofen Fang;Tom Biddlecome;Mihran Tuceryan	Dept. of Comput. & Inf. Sci., Indiana Univ., Indianapolis, IN, USA|c|;;	10.1109/VISUAL.1996.567609;10.1109/VISUAL.1996.568113	volume visualization, 3D image processing, transfer function, volume rendering, data exploration	Indiana University Purdue University Indianapolis##Indiana University Purdue University Indianapolis##Indiana University Purdue University Indianapolis
Vis	1998	Image-based rendering with occlusions via cubist images	10.1109/VISUAL.1998.745320	http://dx.doi.org/10.1109/VISUAL.1998.745320	327	334	C		Andrew J. Hanson;Eric A. Wernert	Indiana Univ., Bloomington, IN, USA|c|;	10.1109/VISUAL.1997.663876	Image Based Rendering, Occlusions	Indiana University Bloomington##Indiana University Bloomington
Vis	1998	Hierarchical volume analysis and visualization based on morphological operators	10.1109/VISUAL.1998.745321	http://dx.doi.org/10.1109/VISUAL.1998.745321	335	341	C		Christoph Lürig;Thomas Ertl	Comput. Graphics Group, Erlangen-Nurnberg Univ., Germany|c|;			UniversitÃ¤t Erlangen-NÃ¼rnberg##UniversitÃ¤t Erlangen-NÃ¼rnberg
Vis	1998	Interactive display of very large textures	10.1109/VISUAL.1998.745322	http://dx.doi.org/10.1109/VISUAL.1998.745322	343	350	C		David Cline;Parris K. Egbert	Dept. of Comput. Sci., Brigham Young Univ., Provo, UT, USA|c|;		texture caching, bandwidth-limited resource, texture mapping, real-time display, interactivity	Brigham Young University##Brigham Young University
Vis	1998	Pixel masks for screen-door transparency	10.1109/VISUAL.1998.745323	http://dx.doi.org/10.1109/VISUAL.1998.745323	351	358	C		Jurriaan D. Mulder;Frans C. A. Groen;Jarke J. van Wijk	Center for Math. & Comput. Sci., CWI, Amsterdam, Netherlands|c|;;	10.1109/VISUAL.1990.146361	Screen-Door Transparency	Center for Math. & Comput. Sci., CWI, Amsterdam, Netherlands|c|;;
Vis	1998	Comparing LIC and spot noise	10.1109/VISUAL.1998.745324	http://dx.doi.org/10.1109/VISUAL.1998.745324	359	365	C		Wim C. de Leeuw;Robert van Liere	Center for Math. & Comput. Sci., CWI, Amsterdam, Netherlands|c|;	10.1109/VISUAL.1997.663898;10.1109/VISUAL.1997.663912;10.1109/VISUAL.1995.480817	flow visualization, texture synthesis	Center for Math. & Comput. Sci., CWI, Amsterdam, Netherlands|c|;
Vis	1998	Size preserving pattern mapping	10.1109/VISUAL.1998.745325	http://dx.doi.org/10.1109/VISUAL.1998.745325	367	373	C		Yair Kurzion;Torsten Möller;Roni Yagel	Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA|c|;;			The Ohio State University##
Vis	1998	Constrained optimal framings of curves and surfaces using quaternion Gauss maps	10.1109/VISUAL.1998.745326	http://dx.doi.org/10.1109/VISUAL.1998.745326	375	382	C		Andrew J. Hanson	Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA|c|	10.1109/VISUAL.1994.346330;10.1109/VISUAL.1997.663876	Quaternions, Frames, Tubing, Curves, Surfaces	Indiana University Bloomington
Vis	1998	Converting sets of polygons to manifold surfaces by cutting and stitching	10.1109/VISUAL.1998.745327	http://dx.doi.org/10.1109/VISUAL.1998.745327	383	390	C		André Guéziec;Gabriel Taubin;Francis Lazarus;William Horn	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;;	10.1109/VISUAL.1997.663904;10.1109/VISUAL.1995.480821	Polygonal Surface, Manifold, Cutting, Stitching	IBM T. J. Watson Research Center##IBM T. J. Watson Research Center##IBM T. J. Watson Research Center##IBM T. J. Watson Research Center
Vis	1998	Interpolation of triangle hierarchies	10.1109/VISUAL.1998.745328	http://dx.doi.org/10.1109/VISUAL.1998.745328	391	396	C		Axel Friedrich;Konrad Polthier;Markus Schmies	Tech. Univ. Berlin, Germany|c|;;		animation, shape interpolation, adaptive refinement,level-of-detail, multiresolutional representation	Technical University Berlin##Technical University Berlin##Technical University Berlin
Vis	1998	Progressive tetrahedralizations	10.1109/VISUAL.1998.745329	http://dx.doi.org/10.1109/VISUAL.1998.745329	397	402	C		Oliver G. Staadt;Markus H. Gross	Comput. Graphics Res. Group, Fed.. Inst. of Technol., Zurich, Switzerland|c|;	10.1109/VISUAL.1997.663907;10.1109/VISUAL.1997.663901;10.1109/VISUAL.1997.663883	mesh simplification, multiresolution, level-of-detail, unstructured meshes, mesh generation	Comput. Graphics Res. Group, Fed.. Inst. of Technol., Zurich, Switzerland|c|;
Vis	1998	Task-specific visualization design: a case study in operational weather forecasting	10.1109/VISUAL.1998.745330	http://dx.doi.org/10.1109/VISUAL.1998.745330	405	409	C		Lloyd Treinish	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|	10.1109/VISUAL.1995.480821;10.1109/VISUAL.1997.663922;10.1109/VISUAL.1994.346316;10.1109/INFVIS.1996.559211		IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|
Vis	1998	Development of a multi-source visualization prototype	10.1109/VISUAL.1998.745331	http://dx.doi.org/10.1109/VISUAL.1998.745331	411	414	C		Leslie Keely;Samuel P. Uselton	NASA Ames Res. Center, Moffett Field, CA, USA|c|;	10.1109/VISUAL.1997.663911;10.1109/VISUAL.1996.568115;10.1109/VISUAL.1998.745332		MRJ Technology Solutions NASA Ames Research Center##MRJ Technology Solutions NASA Ames Research Center
Vis	1998	Data level comparison of wind tunnel and computational fluid dynamics data	10.1109/VISUAL.1998.745332	http://dx.doi.org/10.1109/VISUAL.1998.745332	415	418	C		Qin Shen;Alex T. Pang;Samuel P. Uselton	Dept. of Comput. Sci., California Univ., CA, USA|c|;;	10.1109/VISUAL.1997.663910;10.1109/VISUAL.1996.568115;10.1109/VISUAL.1996.568116;10.1109/VISUAL.1997.663911		UCSC Sam Uselton MRJ Technology Solutions##UCSC Sam Uselton MRJ Technology Solutions
Vis	1998	Selective visualization of vortices in hydrodynamic flows	10.1109/VISUAL.1998.745333	http://dx.doi.org/10.1109/VISUAL.1998.745333	419	422	C		I. Ari Sadarjoen;Frits H. Post;Bing Ma;David C. Banks;Hans-Georg Pagendarm	Dept. of Comput. Sci., Delft Univ. of Technol., Netherlands|c|;;;;	10.1109/VISUAL.1995.485158;10.1109/VISUAL.1997.663910;10.1109/VISUAL.1994.346327;10.1109/VISUAL.1996.568137		Dept. of Comput. Sci., Delft Univ. of Technol., Netherlands|c|;;;;
Vis	1998	Visual presentation of magnetic resonance images	10.1109/VISUAL.1998.745334	http://dx.doi.org/10.1109/VISUAL.1998.745334	423	426	C		Johanna E. van der Heyden;M. Sheelagh T. Carpendale;Kevin B. Inkpen;M. Stella Atkins	Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada|c|;;;	10.1109/INFVIS.1996.559214		Simon Fraser University##Simon Fraser University##Simon Fraser University##Simon Fraser University
Vis	1998	Visualization in corneal topography	10.1109/VISUAL.1998.745335	http://dx.doi.org/10.1109/VISUAL.1998.745335	427	430	C		Frans Vos;Hans J. W. Spoelder	Delft Univ. of Technol., Netherlands|c|;			Delft Univ. of Technol., Netherlands|c|;
Vis	1998	A case study using the virtual environment for reconstructive surgery	10.1109/VISUAL.1998.745336	http://dx.doi.org/10.1109/VISUAL.1998.745336	431	434	C		Kevin Montgomery;Michael Stephanides;Stephen Schendel;Muriel Ross	Nat. Biocomput. Center, Stanford Univ., CA, USA|c|;;;			Stanford University##Stanford University##Stanford University##NASA Ames Research Center
Vis	1998	Interactive virtual angioscopy	10.1109/VISUAL.1998.745337	http://dx.doi.org/10.1109/VISUAL.1998.745337	435	438	C		Enrico Gobbetti;Piero Pili;Antonio Zorcolo;Massimiliano Tuveri	Center for Adv. Studies, Cagliari, Italy|c|;;;	10.1109/VISUAL.1997.663915		Center for Adv. Studies, Cagliari, Italy|c|;;;
Vis	1998	Volumetric modeling of acoustic fields in CNMAT's sound spatialization theatre	10.1109/VISUAL.1998.745338	http://dx.doi.org/10.1109/VISUAL.1998.745338	439	442	C		Sami Khoury;Adrian Freed;David Wessel	CNMAT, Berkeley, CA, USA|c|;;	10.1109/VISUAL.1996.567752		CNMAT, Berkeley, CA, USA|c|;;
Vis	1998	Supporting detail-in-context for the DNA representation, H-curves	10.1109/VISUAL.1998.745339	http://dx.doi.org/10.1109/VISUAL.1998.745339	443	446	C		M. L. Lantin;M. Sheelagh T. Carpendale	Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada|c|;			Simon Fraser University##Simon Fraser University
Vis	1998	Visualizing Hilbert curves	10.1109/VISUAL.1998.745340	http://dx.doi.org/10.1109/VISUAL.1998.745340	447	450	C		Nelson L. Max	Lawrence Livermore Nat. Lab., CA, USA|c|			Lawrence Livermore Nat. Lab., CA, USA|c|
Vis	1998	Rear-projecting virtual data onto physical terrain: an exercise in two senses being better than one	10.1109/VISUAL.1998.745341	http://dx.doi.org/10.1109/VISUAL.1998.745341	451	454	C		Dru Clark;Richard Marciano;Rosemarie McKeon;Michael J. Bailey	Supercomput. Center, California Univ., San Diego, La Jolla, CA, USA|c|;;;	10.1109/VISUAL.1997.663862		University of California at San Diego##University of California at San Diego##University of California at San Diego##University of California at San Diego
Vis	1998	Intent, perception, and out-of-core visualization applied to terrain	10.1109/VISUAL.1998.745342	http://dx.doi.org/10.1109/VISUAL.1998.745342	455	458	C		Douglass Davis;William Ribarsky;Nickolas Faust;Tian-Yue Jiang	Graphics, Visualization & Usability Center, Georgia Inst. of Technol., Atlanta, GA, USA|c|;;;	10.1109/VISUAL.1994.346311;10.1109/VISUAL.1997.663888		Usability Center Georgia Institute of Technology##Usability Center Georgia Institute of Technology##Usability Center Georgia Institute of Technology##Usability Center Georgia Institute of Technology
Vis	1998	Production visualization for the ASCI One TeraFLOPS machine	10.1109/VISUAL.1998.745343	http://dx.doi.org/10.1109/VISUAL.1998.745343	459	462	C		Philip D. Heermann	Sandia Nat. Labs., Albuquerque, NM, USA|c|			Sandia Nat. Labs., Albuquerque, NM, USA|c|
Vis	1998	Battlefield visualization on the responsive workbench	10.1109/VISUAL.1998.745344	http://dx.doi.org/10.1109/VISUAL.1998.745344	463	466	C		Jim Durbin;J. Edward Swan II;Brad Colbert;John Crowe;Rob King;Tony King;Christopher Scannell;Zachary Wartell;Terry Welsh	Naval Res. Lab., Washington, DC, USA|c|;;;;;;;;	10.1109/VISUAL.1996.568128		Naval Res. Lab., Washington, DC, USA|c|;;;;;;;;
Vis	1998	Scientific visualization and data modeling of scattered sediment contaminant data in New York/New Jersey estuaries	10.1109/VISUAL.1998.745345	http://dx.doi.org/10.1109/VISUAL.1998.745345	467	470	C		Hong Ma;Keith W. Jones;Eric A. Stern	Brookhaven Nat. Lab., Upton, NY, USA|c|;;			Brookhaven National Laboratory##Brookhaven National Laboratory##Brookhaven National Laboratory
Vis	1998	POPTEX: Interactive ocean model visualization using texture mapping hardware	10.1109/VISUAL.1998.745346	http://dx.doi.org/10.1109/VISUAL.1998.745346	471	474	C		Allen McPherson;Mathew Maltrud	Adv. Comput. Lab., Los Alamos Nat. Lab., NM, USA|c|;	10.1109/VISUAL.1990.146361;10.1109/VISUAL.1996.568149		Adv. Comput. Lab., Los Alamos Nat. Lab., NM, USA|c|;
Vis	1998	Acoustic imaging and visualization of plumes discharging from black smoker vents on the deep seafloor	10.1109/VISUAL.1998.745347	http://dx.doi.org/10.1109/VISUAL.1998.745347	475	478	C		Peter A. Rona;Karen G. Bemis;Deepak R. Kenchammana-Hosekote;Deborah Silver	Inst. of Marine & Coastal Sci., Rutgers Univ., New Brunswick, NJ, USA|c|;;;	10.1109/VISUAL.1995.485141		Inst. of Marine & Coastal Sci., Rutgers Univ., New Brunswick, NJ, USA|c|;;;
Vis	1998	Seabed visualization	10.1109/VISUAL.1998.745348	http://dx.doi.org/10.1109/VISUAL.1998.745348	479	481	C		Paul Chapman;Peter Stevens;Derek Wills;Graham R. Brookes	Dept. of Comput. Sci., Hull Univ., UK|c|;;;			Sonar Research & Development Ltd##Sonar Research & Development Ltd##Sonar Research & Development Ltd##Sonar Research & Development Ltd
Vis	1998	Configuration space visualization for mechanical design	10.1109/VISUAL.1998.745349	http://dx.doi.org/10.1109/VISUAL.1998.745349	483	486	C		Elisha Sacks;Leo Joskowicz	Purdue Univ., West Lafayette, IN, USA|c|;			The Hebrew University##The Hebrew University##The Hebrew University
Vis	1998	Three-dimensional visualization of microstructures	10.1109/VISUAL.1998.745350	http://dx.doi.org/10.1109/VISUAL.1998.745350	487	490	C		Marco Lanzagorta;Milo V. Kral;J. Edward Swan II;George Spanos;Robert Rosenberg;Eddy Kuo	Naval Res. Lab., Washington, DC, USA|c|;;;;;			Naval Res. Lab., Washington, DC, USA|c|;;;;;
Vis	1998	Visualization for multiparameter aircraft designs	10.1109/VISUAL.1998.745351	http://dx.doi.org/10.1109/VISUAL.1998.745351	491	494	C		Clifford A. Shaffer;Duane L. Knill;Layne T. Watson	Dept. of Comput. Sci., Virginia Polytech. Inst. & State Univ., Blacksburg, VA, USA|c|;;	10.1109/VISUAL.1997.663866;10.1109/VISUAL.1997.663868;10.1109/VISUAL.1990.146402		Virginia Tech Blacksburg##Virginia Tech Blacksburg##Virginia Tech Blacksburg##Virginia Tech Blacksburg
Vis	1998	Why is Real-Time Volume Rendering No Longer a Year Away?	10.1109/VISUAL.1998.745352	http://dx.doi.org/10.1109/VISUAL.1998.745352	497	499	M		Arie E. Kaufman;Marty Brady;William E. Lorensen;Frederick L. Kitson;Hanspeter Pfister	General Electric Corporation|c|;;;;			General Electric Corporation|c|;;;;
Vis	1998	Multi-Source Data Analysis Challenges	10.1109/VISUAL.1998.745353	http://dx.doi.org/10.1109/VISUAL.1998.745353	501	504	M		Samuel P. Uselton;Lloyd Treinish;James P. Ahrens;E. Wes Bethel;Andrei State	University of North Carolina at Chapel Hill|c|;;;;			University of North Carolina at Chapel Hill|c|;;;;
Vis	1998	Key Problems and Thorny Issues in Multidimensional Visualization	10.1109/VISUAL.1998.745354	http://dx.doi.org/10.1109/VISUAL.1998.745354	505	506	M		Georges G. Grinstein;Sharon J. Laskowski;Alfred Inselberg	University of Massachusetts Lowell|c|;;			University of Massachusetts Lowell|c|;;
Vis	1998	Art and Visualization: Oil and Water?	10.1109/VISUAL.1998.745355	http://dx.doi.org/10.1109/VISUAL.1998.745355	507	509	M		David H. Laidlaw;David Kremers;Felica Frankel;Victoria Interrante;Thomas F. Banchoff	University of Minnesota Computer Scientist|c|;;;;			University of Minnesota Computer Scientist|c|;;;;
Vis	1998	Interactive ray tracing for isosurface rendering	10.1109/VISUAL.1998.745713	http://dx.doi.org/10.1109/VISUAL.1998.745713	233	238	C		Steven G. Parker;Peter Shirley;Yarden Livnat;Charles D. Hansen;Peter-Pike J. Sloan	Dept. of Comput. Sci., Utah Univ., Salt Lake City, UT, USA|c|;;;;	10.1109/VISUAL.1997.663888;10.1109/VISUAL.1994.346331;10.1109/VISUAL.1994.346320;10.1109/VISUAL.1995.485154;10.1109/VISUAL.1998.745300		University of Utah##University of Utah##University of Utah##University of Utah##University of Utah
InfoVis	1999	Cluster and calendar based visualization of time series data	10.1109/INFVIS.1999.801851	http://dx.doi.org/10.1109/INFVIS.1999.801851	4	9, 140	C		Jarke J. van Wijk;Edward R. van Selow	Dept. of Math. & Comput. Sci., Eindhoven Univ. of Technol., Netherlands|c|;			Eindhoven University of Technology Netherlands Energy Research Foundation ECN##Eindhoven University of Technology Netherlands Energy Research Foundation ECN
InfoVis	1999	Visualizing application behavior on superscalar processors	10.1109/INFVIS.1999.801852	http://dx.doi.org/10.1109/INFVIS.1999.801852	10	17, 141	C		Chris Stolte;Robert Bosch;Pat Hanrahan;Mendel Rosenblum	Dept. of Comput. Sci., Stanford Univ., CA, USA|c|;;;		Computer systems visualization, visualization systems, superscalar processors	Stanford University##Stanford University##Stanford University##Stanford University
InfoVis	1999	Sensemaking of evolving Web sites using visualization spreadsheets	10.1109/INFVIS.1999.801853	http://dx.doi.org/10.1109/INFVIS.1999.801853	18	25, 142	C		Ed Huai-hsin Chi;Stuart K. Card	Xerox Palo Alto Res. Center, CA, USA|c|;	10.1109/INFVIS.1995.528691;10.1109/INFVIS.1995.528689;10.1109/INFVIS.1995.528686;10.1109/INFVIS.1998.729560;10.1109/VISUAL.1993.398870;10.1109/INFVIS.1995.528692	Information visualization, Spreadsheet, Sensemaking, World Wide Web, Information ecologies, Log file analysis	Xerox Palo Alto Research Center##Xerox Palo Alto Research Center
InfoVis	1999	Does animation help users build mental maps of spatial information?	10.1109/INFVIS.1999.801854	http://dx.doi.org/10.1109/INFVIS.1999.801854	28	35	C		Benjamin B. Bederson;Angela Boltman	Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA|c|;		Evaluation, animation, real-time computer graphics, Zoomable User Interfaces (ZUIs), multiscale interfaces, Pad++	Lab University of Maryland College Park##Lab University of Maryland College Park
InfoVis	1999	Evaluating a visualisation of image similarity as a tool for image browsing	10.1109/INFVIS.1999.801855	http://dx.doi.org/10.1109/INFVIS.1999.801855	36	43, 143	C		Kerry Rodden;Wojciech Basalaj;David Sinclair;Kenneth R. Wood	Comput. Lab., Cambridge Univ., UK|c|;;;			University of Cambridge Computer##University of Cambridge Computer##University of Cambridge Computer##University of Cambridge Computer
InfoVis	1999	Domain analysis: a technique to design a user-centered visualization framework	10.1109/INFVIS.1999.801856	http://dx.doi.org/10.1109/INFVIS.1999.801856	44	52, 144	C		Octavio Juarez Espinosa;Chris Hendrickson;James H. Garrett Jr.	Dept. of Civil & Environ. Eng., Carnegie Mellon Univ., Pittsburgh, PA, USA|c|;;	10.1109/INFVIS.1996.559210;10.1109/VISUAL.1991.175815	Visualization framework, Life-Cycle Assessment, user tasks, computer-human interaction, domain analysis, economic input-output	Carnegie Mellon University##Carnegie Mellon University##Carnegie Mellon University
InfoVis	1999	A framework for focus+context visualization	10.1109/INFVIS.1999.801857	http://dx.doi.org/10.1109/INFVIS.1999.801857	53	56, 145	C		Staffan Björk;Lars Erik Holmquist;Johan Redström	Viktoria Inst., Sweden|c|;;	10.1109/INFVIS.1997.636786;10.1109/INFVIS.1998.729558	Focus+context visualization, information visualization, fisheye views, formal methods, theory	Viktoria Inst., Sweden|c|;;
InfoVis	1999	Navigating hierarchies with structure-based brushes	10.1109/INFVIS.1999.801858	http://dx.doi.org/10.1109/INFVIS.1999.801858	58	64, 146	C		Ying-Huey Fua;Matthew O. Ward;Elke A. Rundensteiner	Dept. of Comput. Sci., Worcester Polytech. Inst., MA, USA|c|;;	10.1109/VISUAL.1990.146402;10.1109/INFVIS.1996.559216;10.1109/VISUAL.1995.485139;10.1109/VISUAL.1994.346302;10.1109/VISUAL.1999.809866;10.1109/VISUAL.1996.567800;10.1109/VISUAL.1991.175815;10.1109/INFVIS.1998.729555	Brushing, hierarchical representation, interactive selection, exploratory data analysis	Dept. of Comput. Sci., Worcester Polytech. Inst., MA, USA|c|;;
InfoVis	1999	Dynamic hierarchy specification and visualization	10.1109/INFVIS.1999.801859	http://dx.doi.org/10.1109/INFVIS.1999.801859	65	72	C		Richard M. Wilson 0002;R. Daniel Bergeron	Dept. of Comput. Sci., New Hampshire Univ., Durham, NH, USA|c|;	10.1109/INFVIS.1995.528689;10.1109/INFVIS.1998.729555;10.1109/VISUAL.1991.175815		University of New Hampshire Durham##University of New Hampshire Durham##University of New Hampshire Durham
InfoVis	1999	Cushion treemaps: visualization of hierarchical information	10.1109/INFVIS.1999.801860	http://dx.doi.org/10.1109/INFVIS.1999.801860	73	78, 147	C		Jarke J. van Wijk;Huub van de Wetering	Dept. of Math. & Comput. Sci., Eindhoven Univ. of Technol., Netherlands|c|;	10.1109/VISUAL.1991.175815	Information Visualization, Tree Visualization, Treemaps	Eindhoven University of Technology##Eindhoven University of Technology
InfoVis	1999	3D interactive visualization for inter-cell dependencies of spreadsheets	10.1109/INFVIS.1999.801861	http://dx.doi.org/10.1109/INFVIS.1999.801861	79	82, 148	C		Hidekazu Shiozawa;Ken-ichi Okada;Yutaka Matsushita	Dept. of Inf. & Comput. Sci., Keio Univ., Yokohama, Japan|c|;;	10.1109/INFVIS.1997.636761	information visualization, 3D user interfaces, spreadsheets, inter-cell dependencies, lifting-up operation, Natto View	Keio University##Keio University##Keio University
InfoVis	1999	Efficient multi-object dynamic query histograms	10.1109/INFVIS.1999.801862	http://dx.doi.org/10.1109/INFVIS.1999.801862	84	91	C		Mark Derthick;James Harrison;Andrew Moore;Steven F. Roth	Carnegie Mellon Univ., Pittsburgh, PA, USA|c|;;;	10.1109/INFVIS.1997.636790	Dynamic Query, Database, Probabilistic Algorithms	Carnegie Mellon University Robotics Institute##Carnegie Mellon University Robotics Institute##Carnegie Mellon University Robotics Institute##Carnegie Mellon University Robotics Institute
InfoVis	1999	Aggregate Towers: scale sensitive visualization and decluttering of geospatial data	10.1109/INFVIS.1999.801863	http://dx.doi.org/10.1109/INFVIS.1999.801863	92	99, 149	C		James K. Rayson	Mitre Corp., Bedford, MA, USA|c|	10.1109/VISUAL.1998.745301;10.1109/INFVIS.1995.528684	data visualization, information visualization, aggregation, zoom, cartography	The MITRE Corporation
InfoVis	1999	VisageWeb: visualizing WWW data in Visage	10.1109/INFVIS.1999.801864	http://dx.doi.org/10.1109/INFVIS.1999.801864	100	107, 150	C		Michael Higgins;Peter Lucas 0002;Jeffrey Senn	MAYA Design Group Inc., Pittsburgh, PA, USA|c|;;		World Wide Web, Information Visualization, User Interface	MAYA Design Group, Inc##MAYA Design Group, Inc
InfoVis	1999	The automated multidimensional detective	10.1109/INFVIS.1999.801865	http://dx.doi.org/10.1109/INFVIS.1999.801865	112	119, 151	C		Alfred Inselberg;Tova Avidan	Dept. of Comput. Sci., Tel Aviv Univ., Israel|c|;	10.1109/INFVIS.1997.636793		Dept. of Comput. Sci., Tel Aviv Univ., Israel|c|;
InfoVis	1999	Visualizing association rules for text mining	10.1109/INFVIS.1999.801866	http://dx.doi.org/10.1109/INFVIS.1999.801866	120	123, 152	C		Pak Chung Wong;Paul Whitney;James J. Thomas	Pacific Northwest Lab., Richland, WA, USA|c|;;	10.1109/INFVIS.1998.729565;10.1109/VISUAL.1998.745302;10.1109/INFVIS.1998.729570;10.1109/INFVIS.1995.528686;10.1109/INFVIS.1997.636791		Pacific Northwest Lab., Richland, WA, USA|c|;;
InfoVis	1999	A Java-based visual mining infrastructure and applications	10.1109/INFVIS.1999.801867	http://dx.doi.org/10.1109/INFVIS.1999.801867	124	127, 153	C		Ming C. Hao;Umeshwar Dayal;Meichun Hsu;Jim Baker;Bob Deletto	Hewlett Packard Res. Labs., USA|c|;;;;	10.1109/VISUAL.1998.745301;10.1109/VISUAL.1993.398870		Hewlett Packard Res. Labs., USA|c|;;;;
InfoVis	1999	The sunflower visual metaphor, a new paradigm for dimensional compression	10.1109/INFVIS.1999.801868	http://dx.doi.org/10.1109/INFVIS.1999.801868	128	131	C		Stuart J. Rose	Dept. of Manage. Inf. Syst., Arizona Univ., Tucson, AZ, USA|c|	10.1109/INFVIS.1998.729569;10.1109/INFVIS.1996.559228;10.1109/INFVIS.1998.729570;10.1109/INFVIS.1998.729559	information visualization, text visualization, visualization, knowledge management, information retrieval	The University of Arizona
InfoVis	1999	Constellation: a visualization tool for linguistic queries from MindNet	10.1109/INFVIS.1999.801869	http://dx.doi.org/10.1109/INFVIS.1999.801869	132	135, 154	C		Tamara Munzner;François Guimbretière;George G. Robertson	Stanford Univ., CA, USA|c|;;			Stanford University##Stanford University##Stanford University
Vis	1999	Progressive Compression of Arbitrary Triangular Meshes	10.1109/VIS.1999.10000	http://doi.ieeecomputersociety.org/10.1109/VIS.1999.10000	67	72	C		Daniel Cohen-Or;David Levin;Offir Remez		10.1109/VISUAL.1996.568125	compression, streaming, progressive meshes, simplification	Tel Aviv University Tel Aviv##Tel Aviv University Tel Aviv##Tel Aviv University Tel Aviv
Vis	1999	Construction of vector field hierarchies	10.1109/VISUAL.1999.809863	http://dx.doi.org/10.1109/VISUAL.1999.809863	19	25, 505	C		Bjørn Heckel;Gunther H. Weber;Bernd Hamann;Kenneth I. Joy	Dept. of Comput. Sci., California Univ., Davis, CA, USA|c|;;;	10.1109/VISUAL.1997.663871;10.1109/VISUAL.1998.745318	vector field visualization, Hardy's multiquadric method, binary-space partitioning, data simplification	University of California##UniversitÃ¤t Kaiserslautern##University of California##University of California
Vis	1999	Large field visualization with demand-driven calculation	10.1109/VISUAL.1999.809864	http://dx.doi.org/10.1109/VISUAL.1999.809864	27	506	C		Patrick J. Moran;Chris Henze	MRI Technol. Solutions, NASA Ames Res. Center, Moffett Field, CA, USA|c|;	10.1109/VISUAL.1992.235219;10.1109/VISUAL.1997.663888;10.1109/VISUAL.1996.568115;10.1109/VISUAL.1994.346311;10.1109/VISUAL.1993.398860;10.1109/VISUAL.1990.146360;10.1109/VISUAL.1997.663898;10.1109/VISUAL.1995.480821	large scale visualization, scientific visualization, interactive visualization, demand-driven evaluation, lazy evaluation, interpreted systems, Python	MRJ Technology Solutions MRJ Technology Solutions NASA Ames Research Center NASA Ames Research Center##MRJ Technology Solutions MRJ Technology Solutions NASA Ames Research Center NASA Ames Research Center
Vis	1999	Simplified representation of vector fields	10.1109/VISUAL.1999.809865	http://dx.doi.org/10.1109/VISUAL.1999.809865	35	507	C		Alexandru Telea;Jarke J. van Wijk	Eindhoven Univ. of Technol., Netherlands|c|;	10.1109/VISUAL.1995.480817;10.1109/VISUAL.1994.346327;10.1109/VISUAL.1991.175789	Flow Visualization, Simplification, Clustering	Eindhoven University of Technology##Eindhoven University of Technology
Vis	1999	Hierarchical parallel coordinates for exploration of large datasets	10.1109/VISUAL.1999.809866	http://dx.doi.org/10.1109/VISUAL.1999.809866	43	508	C		Ying-Huey Fua;Matthew O. Ward;Elke A. Rundensteiner	Dept. of Comput. Sci., Worcester Polytech. Inst., MA, USA|c|;;	10.1109/VISUAL.1994.346302;10.1109/INFVIS.1999.801858;10.1109/VISUAL.1996.567800;10.1109/VISUAL.1995.485140;10.1109/VISUAL.1990.146386;10.1109/VISUAL.1990.146402;10.1109/INFVIS.1998.729556;10.1109/VISUAL.1995.485139	Large-scale multivariate data visualization, hierarchical data exploration, parallel coordinates	Dept. of Comput. Sci., Worcester Polytech. Inst., MA, USA|c|;;
Vis	1999	Tetrahedral Mesh Compression with the Cut-Border Machine	10.1109/VISUAL.1999.809868	http://doi.ieeecomputersociety.org/10.1109/VISUAL.1999.809868	51	58	C		Stefan Gumhold;Stefan Guthe;Wolfgang Straßer	WSI/GRIS University of Tübingen	10.1109/VISUAL.1998.745329;10.1109/VISUAL.1997.663869		WSI/GRIS University of TÃ¼bingen##WSI/GRIS University of TÃ¼bingen##WSI/GRIS University of TÃ¼bingen
Vis	1999	New quadric metric for simplifying meshes with appearance attributes	10.1109/VISUAL.1999.809869	http://dx.doi.org/10.1109/VISUAL.1999.809869	59	510	C		Hugues Hoppe		10.1109/VISUAL.1998.745312;10.1109/VISUAL.1998.745285;10.1109/VISUAL.1998.745314;10.1109/VISUAL.1997.663908	level of detail, mesh decimation, multiresolution	Microsoft Research
Vis	1999	Efficient compression of non-manifold polygonal meshes	10.1109/VISUAL.1999.809870	http://dx.doi.org/10.1109/VISUAL.1999.809870	73	512	C		André Guéziec;Frank Bossen;Gabriel Taubin;Cláudio T. Silva	Multigen Paradigm, San Jose, CA, USA|c|;;;	10.1109/VISUAL.1997.663902;10.1109/VISUAL.1998.745327	Polygonal Mesh, Geometry Compression, Non-Manifold, Stitching	Multigen Paradigm, San Jose, CA, USA|c|;;;
Vis	1999	Image graphs-a novel approach to visual data exploration	10.1109/VISUAL.1999.809871	http://dx.doi.org/10.1109/VISUAL.1999.809871	81	88	C		Kwan-Liu Ma	California Univ., Davis, CA, USA|c|	10.1109/VISUAL.1995.480821;10.1109/VISUAL.1996.568113	knowledge representations, scientific visualization, visualization systems, volume rendering	University of California
Vis	1999	Forward image mapping	10.1109/VISUAL.1999.809872	http://dx.doi.org/10.1109/VISUAL.1999.809872	89	514	C		Baoquan Chen;Frank Dachille;Arie E. Kaufman	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;		image warping, forward mapping, texture mapping, antialiasing, anisotropic filtering, Gouraud shading, hardware	State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook
Vis	1999	Structured spatial domain image and data comparison metrics	10.1109/VISUAL.1999.809873	http://dx.doi.org/10.1109/VISUAL.1999.809873	97	515	C		Nivedita Sahasrabudhe;John E. West;Raghu Machiraju;Mark Janus	NSF Eng. Res. Center, Mississippi State Univ., MS, USA|c|;;;	10.1109/VISUAL.1997.663848;10.1109/VISUAL.1990.146360	metrics, steering, rendering, correlation measure	NSF Engineering Research Center##Information Technology Laboratory##NSF Engineering Research Center##NSF Engineering Research Center
Vis	1999	Feature Comparisons Of 3-D Vector Fields Using Earth Mover's Distance	10.1109/VISUAL.1999.809874	http://dx.doi.org/10.1109/VISUAL.1998.745291	105		C		Rajesh Batra;Lambertus Hesselink		10.1109/VISUAL.1998.745291;10.1109/VISUAL.1998.745332		Stanford University Stanford University Stanford##Stanford University Stanford University Stanford
Vis	1999	Rendering on a budget: a framework for time-critical rendering	10.1109/VISUAL.1999.809875	http://dx.doi.org/10.1109/VISUAL.1999.809875	115	516	C		James T. Klosowski;Cláudio T. Silva	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;		Polygon rendering, visibility ordering, occlusion culling	IBM T. J. Watson Research Center##IBM T. J. Watson Research Center
Vis	1999	Time-critical Multiresolution Scene Rendering	10.1109/VISUAL.1999.809876	http://doi.ieeecomputersociety.org/10.1109/VISUAL.1999.809876	123	130	C		Enrico Gobbetti;Eric Bouvier	CRS4, Center for Advanced Studies, Research and Development in Sardinia	10.1109/VISUAL.1996.568126;10.1109/VISUAL.1998.745282	multiresolution modeling,level of detail,adaptive rendering, time-critical graphics	CRS4, Center for Advanced Studies, Research and Development in Sardinia
Vis	1999	Skip Strips: maintaining triangle strips for view-dependent rendering	10.1109/VISUAL.1999.809877	http://dx.doi.org/10.1109/VISUAL.1999.809877	131	518	C		Jihad El-Sana;Elvir Azanli;Amitabh Varshney	Dept. of Math. & Comput. Sci., Ben-Gurion Univ. of the Negev, Beer-Sheva, Israel|c|;;	10.1109/VISUAL.1996.568125;10.1109/VISUAL.1998.745314;10.1109/VISUAL.1997.663902;10.1109/VISUAL.1998.745283;10.1109/VISUAL.1995.480805		Ben-Gurion University##Ben-Gurion University##Ben-Gurion University
Vis	1999	Isosurface extraction techniques for Web-based volume visualization	10.1109/VISUAL.1999.809878	http://dx.doi.org/10.1109/VISUAL.1999.809878	139	519	C		Klaus Engel;Rüdiger Westermann;Thomas Ertl	Stuttgart Univ., Germany|c|;;	10.1109/VISUAL.1997.663891;10.1109/VISUAL.1996.568121;10.1109/VISUAL.1995.480806;10.1109/VISUAL.1991.175782;10.1109/VISUAL.1998.745300;10.1109/VISUAL.1996.568127	Volume visualization, Isosurface reconstruction, Distributed Systems, Web-based Applications	University of Stuttgart##University of Stuttgart##University of Stuttgart
Vis	1999	Isosurface extraction in time-varying fields using a Temporal Branch-on-Need Tree (T-BON)	10.1109/VISUAL.1999.809879	http://dx.doi.org/10.1109/VISUAL.1999.809879	147	520	C		Philip M. Sutton;Charles D. Hansen	Dept. of Comput. Sci., Utah Univ., Salt Lake City, UT, USA|c|;	10.1109/VISUAL.1998.745343;10.1109/VISUAL.1996.568121;10.1109/VISUAL.1998.745299;10.1109/VISUAL.1998.745298;10.1109/VISUAL.1997.663895;10.1109/VISUAL.1997.663888;10.1109/VISUAL.1996.568133;10.1109/VISUAL.1996.568123;10.1109/VISUAL.1998.745350;10.1109/VISUAL.1998.745311;10.1109/VISUAL.1995.485154;10.1109/VISUAL.1997.663913	isosurface, time-dependent scalar field visualization, multiresolution methods, octree	University of Utah Salt Lake City##University of Utah Salt Lake City
Vis	1999	Interactive lens visualization techniques	10.1109/VISUAL.1999.809882	http://dx.doi.org/10.1109/VISUAL.1999.809882	155	521	C		Chris Shaw 0002;James A. Hall;David S. Ebert;D. Aaron Roberts	Regina Univ., Sask., Canada|c|;;;	10.1109/VISUAL.1995.485141;10.1109/VISUAL.1996.568109	Volumetric Data, Glyphs, Two-Handed Interfaces, Interactive Volume Rendering, Contour Diagrams, Stereoscopic Field Analyzer SFA, Seed Fill, Over Blending	Regina Univ., Sask., Canada|c|;;;
Vis	1999	Multi-projector displays using camera-based registration	10.1109/VISUAL.1999.809883	http://dx.doi.org/10.1109/VISUAL.1999.809883	161	522	C		Ramesh Raskar;Michael S. Brown;Ruigang Yang;Wei-Chao Chen;Greg Welch;Herman Towles;W. Brent Seales;Henry Fuchs	Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;;;;;		display, projection, spatially immersive display, panoramic image display, virtual environments, intensity blending, image-based modeling, depth, calibration, auto-calibration, structured light, camera-based registration	University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill
Vis	1999	Exploring geo-scientific data in virtual environments	10.1109/VISUAL.1999.809884	http://dx.doi.org/10.1109/VISUAL.1999.809884	169	173	C		Bernd Fröhlich 0001;Stephen Barrass;Björn Zehner;John Plate;Martin Göbel	GMD German Nat. Res. Center for Inf. Technol., Germany|c|;;;;	10.1109/VISUAL.1998.745317;10.1109/VISUAL.1991.175771		GMD German National Research Center for Information Technology##GMD German National Research Center for Information Technology##GMD German National Research Center for Information Technology##GMD German National Research Center for Information Technology##GMD German National Research Center for Information Technology
Vis	1999	Animating wrinkles on clothes	10.1109/VISUAL.1999.809885	http://dx.doi.org/10.1109/VISUAL.1999.809885	175	523	C		Sunil Hadap;Endre Bangerter;Pascal Volino;Nadia Magnenat-Thalmann	Geneva Univ., Switzerland|c|;;;		clothmodeling,wrinklemodeling,deformablemodels	University of Geneva##University of Geneva##University of Geneva##University of Geneva##University of Geneva##University of Geneva
Vis	1999	Hue-balls and lit-tensors for direct volume rendering of diffusion tensor fields	10.1109/VISUAL.1999.809886	http://dx.doi.org/10.1109/VISUAL.1999.809886	183	524	C		Gordon L. Kindlmann;David M. Weinstein	Dept. of Comput. Sci., Utah Univ., Salt Lake City, UT, USA|c|;	10.1109/VISUAL.1990.146373;10.1109/VISUAL.1992.235193;10.1109/VISUAL.1996.567777;10.1109/VISUAL.1998.745294		University of Utah##University of Utah
Vis	1999	Mixing translucent polygons with volumes	10.1109/VISUAL.1999.809887	http://dx.doi.org/10.1109/VISUAL.1999.809887	191	525	C		Kevin Kreeger;Arie E. Kaufman	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;	10.1109/VISUAL.1997.663853	Mixing polygons and volumes, Translucent Polygon Rendering, Volume rendering, Ray casting, Voxelization	State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook
Vis	1999	Multi-resolution multi-field ray tracing: a mathematical overview	10.1109/VISUAL.1999.809888	http://dx.doi.org/10.1109/VISUAL.1999.809888	199	206	C		Charidimos E. Gasparakis	Mitsubishi Electr. Inf. Technol. Center, USA|c|			Real Time Visualization
Vis	1999	Enabling Classification and Shading for 3D Texture Mapping based Volume Rendering using OpenGL and Extensions	10.1109/VISUAL.1999.809889	http://dx.doi.org/10.1109/VISUAL.1999.809889	207	526	C		Michael Meißner;Ulrich Hoffmann;Wolfgang Straßer	Comput. Graphics Lab., Tubingen Univ., Germany|c|;;		Volume Rendering, 3D Texture Mapping, Rectilinear Grid, Shading, Classification, OpenGL	Comput. Graphics Lab., Tubingen Univ., Germany|c|;;
Vis	1999	A distributed graphics system for large tiled displays	10.1109/VISUAL.1999.809890	http://dx.doi.org/10.1109/VISUAL.1999.809890	215	527	C		Greg Humphreys;Pat Hanrahan	Dept. of Comput. Sci., Stanford Univ., CA, USA|c|;			Stanford University##Stanford University
Vis	1999	A multi-threaded streaming pipeline architecture for large structured data sets	10.1109/VISUAL.1999.809891	http://dx.doi.org/10.1109/VISUAL.1999.809891	225	232	C		C. Charles Law;Ken Martin;William J. Schroeder;Joshua Temkin	Kitware Inc., USA|c|;;;	10.1109/VISUAL.1997.663895;10.1109/VISUAL.1997.663888;10.1109/VISUAL.1998.745299;10.1109/VISUAL.1998.745297;10.1109/VISUAL.1997.663910		Kitware, Inc.)
Vis	1999	Interactive exploration of volume line integral convolution based on 3D-texture mapping	10.1109/VISUAL.1999.809892	http://dx.doi.org/10.1109/VISUAL.1999.809892	233	528	C		Christof Rezk-Salama;Peter Hastreiter;Christian Teitzel;Thomas Ertl	Comput. Graphics Group, Erlangen-Nurnberg Univ., Germany|c|;;;	10.1109/VISUAL.1993.398877;10.1109/VISUAL.1993.398846;10.1109/VISUAL.1995.485141;10.1109/VISUAL.1994.346313;10.1109/VISUAL.1994.346314;10.1109/VISUAL.1990.146391;10.1109/VISUAL.1997.663898;10.1109/VISUAL.1997.663897;10.1109/VISUAL.1997.663899	Flow Visualization, Animated LIC, Direct Volume Rendering, 3D-Textures Mapping, Interactive Volume Exploration	University of Erlangenâ€“Nuremberg##University of Erlangenâ€“Nuremberg##University of Erlangenâ€“Nuremberg##University of Erlangenâ€“Nuremberg##University of Erlangenâ€“Nuremberg
Vis	1999	A framework for assisted exploration with collaboration	10.1109/VISUAL.1999.809893	http://dx.doi.org/10.1109/VISUAL.1999.809893	241	529	C		Eric A. Wernert;Andrew J. Hanson	Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA|c|;	10.1109/VISUAL.1998.745326;10.1109/VISUAL.1997.663876	wayfinding, locomotion, navigation, exploration, collaboration, virtual reality, VRML	Indiana University Bloomington##Indiana University Bloomington
Vis	1999	Tensorlines: Advection-Diffusion based Propagation through Diffusion Tensor Fields	10.1109/VISUAL.1999.809894	http://dx.doi.org/10.1109/VISUAL.1999.809894	249	253	C		David M. Weinstein;Gordon L. Kindlmann;Eric C. Lundberg	Center for Scientific Computing and Imaging, Department of Computer Science, University of Utah	10.1109/VISUAL.1993.398849;10.1109/VISUAL.1991.175789;10.1109/VISUAL.1992.235193;10.1109/VISUAL.1995.485141;10.1109/VISUAL.1998.745294;10.1109/VISUAL.1999.809886		University of Utah##University of Utah##University of Utah
Vis	1999	Visualizing Planar Vector Fields with Normal Component Using Line Integral Convolution	10.1109/VISUAL.1999.809895	http://doi.ieeecomputersociety.org/10.1109/VISUAL.1999.809895	255	261	C		Gerik Scheuermann;Holger Burbach;Hans Hagen	Department of Computer Science, University of Kaiserslautern, Germany	10.1109/VISUAL.1994.346312;10.1109/VISUAL.1994.346313;10.1109/VISUAL.1990.146360;10.1109/VISUAL.1998.745324	LIC, vector field visualization, deformation	University of Kaiserslautern##University of Kaiserslautern##University of Kaiserslautern
Vis	1999	The "Parallel Vectors" operator-a vector field visualization primitive	10.1109/VISUAL.1999.809896	http://dx.doi.org/10.1109/VISUAL.1999.809896	263	532	C		Ronald Peikert;Martin Roth	Dept. of Comput. Sci., ETH Zurich, Switzerland|c|;	10.1109/VISUAL.1998.745290;10.1109/VISUAL.1996.568137;10.1109/VISUAL.1998.745296;10.1109/VISUAL.1995.480795;10.1109/VISUAL.1994.346327;10.1109/VISUAL.1997.663894;10.1109/VISUAL.1998.745297;10.1109/VISUAL.1996.567807		ETH ZÃ¼rich##ETH ZÃ¼rich
Vis	1999	C1-interpolation for vector field topology visualization	10.1109/VISUAL.1999.809897	http://dx.doi.org/10.1109/VISUAL.1999.809897	271	533	C		Gerik Scheuermann;Xavier Tricoche;Hans Hagen	Dept. of Comput. Sci., Kaiserslautern Univ., Germany|c|;;	10.1109/VISUAL.1991.175773;10.1109/VISUAL.1998.745284;10.1109/VISUAL.1998.745296	vector field visualization, topology, critical point the- ory, C1-interpolation	University of Kaiserslautern##University of Kaiserslautern##University of Kaiserslautern
Vis	1999	Optimal triangular Haar bases for spherical data	10.1109/VISUAL.1999.809898	http://dx.doi.org/10.1109/VISUAL.1999.809898	279	534	C		Georges-Pierre Bonneau	CNRS, France|c|	10.1109/VISUAL.1997.663871	visualization, multiresolution, wavelets, orthogonality	LMC -CNRS
Vis	1999	Cracking the cracking problem with Coons patches	10.1109/VISUAL.1999.809899	http://dx.doi.org/10.1109/VISUAL.1999.809899	285	535	C		Gregory M. Nielson;Dave J. Holliday;Tom Roxborough	Dept. of Comput. Sci. & Eng., Arizona State Univ., Tempe, AZ, USA|c|;;	10.1109/VISUAL.1998.745328;10.1109/VISUAL.1997.663860		Arizona State University Tempe##Arizona State University Tempe##Arizona State University Tempe
Vis	1999	LOD-sprite technique for accelerated terrain rendering	10.1109/VISUAL.1999.809900	http://dx.doi.org/10.1109/VISUAL.1999.809900	291	536	C		Baoquan Chen;J. Edward Swan II;Eddy Kuo;Arie E. Kaufman	State Univ. of New York, Stony Brook, NY, USA|c|;;;	10.1109/VISUAL.1998.745344;10.1109/VISUAL.1996.567774;10.1109/VISUAL.1998.745282	Image-Based Modeling and Rendering,Texture Mapping, Acceleration Techniques, Multi-Resolution, Level of Detail, Terrain Rendering, Virtual Reality, Virtual Environments	State Univ. of New York, Stony Brook, NY, USA|c|;;;
Vis	1999	Implant sprays: compression of progressive tetrahedral mesh connectivity	10.1109/VISUAL.1999.809901	http://dx.doi.org/10.1109/VISUAL.1999.809901	299	305	C		Renato Pajarola;Jarek Rossignac;Andrzej Szymczak	Graphics, Visualization & Usability Center, Georgia Inst. of Technol., Atlanta, GA, USA|c|;;	10.1109/VISUAL.1998.745315;10.1109/VISUAL.1998.745329	tetrahedral meshes, compression, multiresolution models, progressive incremental reconstruction	Graphics, Visualization & Usability Center, Georgia Inst. of Technol., Atlanta, GA, USA|c|;;
Vis	1999	Progressive compression and transmission of arbitrary triangular meshes	10.1109/VISUAL.1999.809902	http://dx.doi.org/10.1109/VISUAL.1999.809902	307	537	C		Chandrajit L. Bajaj;Valerio Pascucci;Guozhong Zhuang	Dept. of Comput. Sci., Texas Univ., Austin, TX, USA|c|;;	10.1109/VISUAL.1998.745283;10.1109/VISUAL.1997.663883		University of Texas at Austin##University of Texas at Austin##University of Texas at Austin
Vis	1999	Spiraling Edge: fast surface reconstruction from partially organized sample points	10.1109/VISUAL.1999.809903	http://dx.doi.org/10.1109/VISUAL.1999.809903	317	538	C		Patricia Crossno;Edward Angel	Sandia Nat. Labs., CA, USA|c|;	10.1109/VISUAL.1997.663930;10.1109/VISUAL.1998.745286	Surface reconstruction, advancing front, triangulation	Laboratories University of New##Laboratories University of New
Vis	1999	Anisotropic nonlinear diffusion in flow visualization	10.1109/VISUAL.1999.809904	http://dx.doi.org/10.1109/VISUAL.1999.809904	325	539	C		Tobias Preußer;Martin Rumpf	Inst. fur Angewandte Math., Bonn Univ., Germany|c|;	10.1109/VISUAL.1993.398875;10.1109/VISUAL.1995.480817;10.1109/VISUAL.1994.346312;10.1109/VISUAL.1997.663912;10.1109/VISUAL.1996.567784;10.1109/VISUAL.1997.663898	flow visualization, multiscale, nonlinear diffusion, segmentation	Inst. fur Angewandte Math., Bonn Univ., Germany|c|;
Vis	1999	Visualizing Multivalued Data from 2D Incompressible Flows Using Concepts from Painting	10.1109/VISUAL.1999.809905	http://dx.doi.org/10.1109/VISUAL.1999.809905	333	540	C		Robert Michael Kirby;H. Marmanis;David H. Laidlaw	Div. of Appl. Math., Brown Univ., Providence, RI, USA|c|;;	10.1109/VISUAL.1998.745294		Brown University##Brown University##Brown University
Vis	1999	PLIC: bridging the gap between streamlines and LIC	10.1109/VISUAL.1999.809906	http://dx.doi.org/10.1109/VISUAL.1999.809906	341	541	C		Vivek Verma;David T. Kao;Alex T. Pang	Dept. of Comput. Sci., California Univ., Santa Cruz, CA, USA|c|;;	10.1109/VISUAL.1996.567784;10.1109/VISUAL.1997.663899;10.1109/VISUAL.1997.663898;10.1109/VISUAL.1994.346313;10.1109/VISUAL.1998.745332;10.1109/VISUAL.1998.745324;10.1109/VISUAL.1996.568116	unsteady flow, variable speed animation, jitter, texture mapping, comparative visualization	NASA Ames Research Center##
Vis	1999	Collapsing Flow Topology Using Area Metrics	10.1109/VISUAL.1999.809907	http://doi.ieeecomputersociety.org/10.1109/VISUAL.1999.809907	349	354	C		Wim C. de Leeuw;Robert van Liere	Center for Mathematics and Computer Science, Amsterdam, Netherlands	10.1109/VISUAL.1991.175773	multi-level visualization techniques, flow visualization, flow topology	Center for Mathematics and Computer Science, Amsterdam, Netherlands
Vis	1999	Multiresolution Techniques for Interactive Texture-based Volume Visualization	10.1109/VISUAL.1999.809908	http://doi.ieeecomputersociety.org/10.1109/VISUAL.1999.809908	355		C		Eric LaMar;Bernd Hamann;Kenneth I. Joy			multiresolution rendering, volume visualization, hardware texture	University of California##University of California##University of California
Vis	1999	Splatting without the blur	10.1109/VISUAL.1999.809909	http://dx.doi.org/10.1109/VISUAL.1999.809909	363	544	C		Klaus Mueller;Torsten Möller;Roger Crawfis	Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA|c|;;	10.1109/VISUAL.1998.745713;10.1109/VISUAL.1998.745311;10.1109/VISUAL.1996.567608;10.1109/VISUAL.1997.663848;10.1109/VISUAL.1998.745309;10.1109/VISUAL.1993.398877;10.1109/VISUAL.1994.346340		The Ohio State University##The Ohio State University##The Ohio State University
Vis	1999	A fast volume rendering algorithm for time-varying fields using a time-space partitioning (TSP) tree	10.1109/VISUAL.1999.809910	http://dx.doi.org/10.1109/VISUAL.1999.809910	371	545	C		Han-Wei Shen;Ling-Jan Chiang;Kwan-Liu Ma	MRJ Technol. Solutions, NASA Ames Res. Center, Moffett Field, CA, USA|c|;;	10.1109/VISUAL.1998.745713;10.1109/VISUAL.1997.663888;10.1109/VISUAL.1996.567609;10.1109/VISUAL.1998.745298;10.1109/VISUAL.1995.480809	scalar field visualization, volume visualization, volume rendering, time-varying fields	MRJ Technology Solutions / NASA Ames Research Center Ling-Jen Chiang y MRJ Technology Solutions / NASA Ames Research Center##MRJ Technology Solutions / NASA Ames Research Center Ling-Jen Chiang y MRJ Technology Solutions / NASA Ames Research Center
Vis	1999	High performance presence-accelerated ray casting	10.1109/VISUAL.1999.809911	http://dx.doi.org/10.1109/VISUAL.1999.809911	379	546	C		Ming Wan;Arie E. Kaufman;Steve Bryson	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;	10.1109/VISUAL.1994.346319;10.1109/VISUAL.1990.146377;10.1109/VISUAL.1999.809914;10.1109/VISUAL.1992.235231;10.1109/VISUAL.1998.745713	Volume rendering, presence acceleration, run-length encoding, projection template, multiresolution volumes, interactive classification, parallel processing	NASA Ames Research Center Moffett Field##State University of New York at Stony Brook
Vis	1999	Interactive exploration of extra- and interacranial blood vessels	10.1109/VISUAL.1999.809912	http://dx.doi.org/10.1109/VISUAL.1999.809912	389	547	C		Dirk Bartz;Wolfgang Straßer;Martin Skalej;Dorothea Welte	Wilhelm-Schickard-Inst. fur Inf., Tubingen Univ., Germany|c|;;;	10.1109/VISUAL.1998.745337;10.1109/VISUAL.1997.663915		University of TÃ¼bingen Auf der Morgenstelle##University of TÃ¼bingen Auf der Morgenstelle##University Hospital TÃ¼bingen##University Hospital TÃ¼bingen
Vis	1999	Digital design of a surgical simulator for interventional MR imaging	10.1109/VISUAL.1999.809913	http://dx.doi.org/10.1109/VISUAL.1999.809913	393	548	C		Terry S. Yoo;Penny Rheingans	Nat. Libr. of Med., Bethesda, MD, USA|c|;	10.1109/VISUAL.1998.745337;10.1109/VISUAL.1998.745336		National Library of Medicine National Institutes of Health##National Library of Medicine National Institutes of Health
Vis	1999	Volume rendering based interactive navigation within the human colon	10.1109/VISUAL.1999.809914	http://dx.doi.org/10.1109/VISUAL.1999.809914	397	549	C		Ming Wan;Qingyu Tang;Arie E. Kaufman;Zhengrong Liang;Mark Wax	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;;;	10.1109/VISUAL.1999.809911;10.1109/VISUAL.1997.663915;10.1109/VISUAL.1998.745713;10.1109/VISUAL.1993.398852		Radiology State University of New York at Stony Brook Stony Brook##Radiology State University of New York at Stony Brook Stony Brook##Radiology State University of New York at Stony Brook Stony Brook##Radiology State University of New York at Stony Brook Stony Brook##Radiology State University of New York at Stony Brook Stony Brook
Vis	1999	A computer animation representing the molecular events of G protein-coupled receptor activation	10.1109/VISUAL.1999.809915	http://dx.doi.org/10.1109/VISUAL.1999.809915	401	550	C		Zoya Maslak;Douglas J. Steel;Robert J. McDermott	Dept. of Art, Utah Univ., Salt Lake City, UT, USA|c|;;			University of Utah
Vis	1999	Visualizing gridded datasets with large number of missing values	10.1109/VISUAL.1999.809916	http://dx.doi.org/10.1109/VISUAL.1999.809916	405	551	C		Suzana Djurcilov;Alex T. Pang	Dept. of Comput. Sci., California Univ., Santa Cruz, CA, USA|c|;	10.1109/VISUAL.1996.568145		UCSC##UCSC
Vis	1999	Detecting vortical phenomena in vector data by medium-scale correlation	10.1109/VISUAL.1999.809917	http://dx.doi.org/10.1109/VISUAL.1999.809917	409	552	C		Hans-Georg Pagendarm;B. Henne;M. Rutten	DLR, Gottingen, Germany|c|;;	10.1109/VISUAL.1993.398849;10.1109/VISUAL.1997.663910;10.1109/VISUAL.1994.346327;10.1109/VISUAL.1996.568137		DLR, Gottingen, Germany|c|;;
Vis	1999	Interactive visualization of fluid dynamics simulations in locally refined cartesian grids	10.1109/VISUAL.1999.809918	http://dx.doi.org/10.1109/VISUAL.1999.809918	413	553	C		Martin Schulz 0005;Frank Reck;Wolf Bartelheimer;Thomas Ertl	;;;	10.1109/VISUAL.1997.663911		BMW AG y University of Erlangen####BMW AG y University of Erlangen####University of Stuttgart
Vis	1999	Visual debugging of visualization software: a case study for particle systems	10.1109/VISUAL.1999.809919	http://dx.doi.org/10.1109/VISUAL.1999.809919	417	554	C		Patricia Crossno;Edward Angel	Sandia Nat. Labs., CA, USA|c|;	10.1109/VISUAL.1996.568120;10.1109/VISUAL.1997.663930		Laboratories University of New##Laboratories University of New
Vis	1999	DELTA's Virtual Physics Laboratory: a comprehensive learning platform on physics and astronomy	10.1109/VISUAL.1999.809920	http://dx.doi.org/10.1109/VISUAL.1999.809920	421	423	C		Sepideh Chakaveh;Udo Zlender;Detlef Skaley;Konstantinos Fostiropoulos;Dieter Breitschwerdt	IMK-DELTA, Nat. Res. Center for Inf. Technol., St. Augustin, Germany|c|;;;;			IMK-DELTA##University of Heidelberg##Max Planck Institut FÅ¸r Exterterrestrische Physik Munich
Vis	1999	VizCraft: a multidimensional visualization tool for aircraft configuration design	10.1109/VISUAL.1999.809921	http://dx.doi.org/10.1109/VISUAL.1999.809921	425	555	C		Amit Goel;Chuck Baker;Clifford A. Shaffer;Bernard Grossman;Raphael T. Haftka;William H. Mason;Layne T. Watson	Dept. of Comput. Sci., Virginia Polytech. Inst. & State Univ., Blacksburg, VA, USA|c|;;;;;;	10.1109/VISUAL.1995.485139;10.1109/VISUAL.1998.745351;10.1109/INFVIS.1997.636793;10.1109/INFVIS.1998.729559;10.1109/VISUAL.1996.567800		Dept. of Comput. Sci., Virginia Polytech. Inst. & State Univ., Blacksburg, VA, USA|c|;;;;;;
Vis	1999	Design and implementation of an immersive geoscience toolkit	10.1109/VISUAL.1999.809922	http://dx.doi.org/10.1109/VISUAL.1999.809922	429	556	C		Christophe Winkler;Fabien Bosquet;Xavier Cavin;Jean-Claude Paul	Inst. Nat. de Recherche en Inf. et Autom., Nancy, France|c|;;;			Inst. Nat. de Recherche en Inf. et Autom., Nancy, France|c|;;;
Vis	1999	Visualization of conflicts and resolutions in a "Free Flight" scenario	10.1109/VISUAL.1999.809923	http://dx.doi.org/10.1109/VISUAL.1999.809923	433	557	C		Ronald Azuma;Howard Neely;Michael J. Daily;Mario Correa	HRL Labs., USA|c|;;;	10.1109/INFVIS.1997.636786		HRL Labs., USA|c|;;;
Vis	1999	Real-time visualization of scalably large collections of heterogeneous objects	10.1109/VISUAL.1999.809924	http://dx.doi.org/10.1109/VISUAL.1999.809924	437	558	C		Douglass Davis;William Ribarsky;Tian-Yue Jiang;Nickolas Faust;Sean Ho	GVU Center, Georgia Inst. of Technol., Atlanta, GA, USA|c|;;;;	10.1109/VISUAL.1998.745342;10.1109/VISUAL.1997.663888;10.1109/VISUAL.1998.745299		GVU Center Georgia Institute of Technology##GVU Center Georgia Institute of Technology##GVU Center Georgia Institute of Technology##GVU Center Georgia Institute of Technology##GVU Center Georgia Institute of Technology
Vis	1999	Geo-spatial visualization for situational awareness	10.1109/VISUAL.1999.809925	http://dx.doi.org/10.1109/VISUAL.1999.809925	441	559	C		Eliot Feibush;Nikhil Gagvani;Daniel Williams	Sarnoff Corp., Princeton, NJ, USA|c|;;			Sarnoff Corp., Princeton, NJ, USA|c|;;
Vis	1999	Whole field modelling. Effective real-time and post-survey visualization of underwater pipelines	10.1109/VISUAL.1999.809926	http://dx.doi.org/10.1109/VISUAL.1999.809926	445	560	C		Paul Chapman;Derek Wills;Peter Stevens;Graham R. Brookes	Dept. of Comput. Sci., Hull Univ., UK|c|;;;	10.1109/VISUAL.1998.745348		Sonar Research & Development Ltd##Sonar Research & Development Ltd##Sonar Research & Development Ltd##Sonar Research & Development Ltd
Vis	1999	Visualizing the evolution of a subject domain: a case study	10.1109/VISUAL.1999.809927	http://dx.doi.org/10.1109/VISUAL.1999.809927	449	561	C		Chaomei Chen;Les Carr	Dept. of Inf. Syst. & Comput., Brunel Univ., Uxbridge, UK|c|;	10.1109/VISUAL.1993.398870		Brunel University##Brunel University
Vis	1999	An interactive framework for visualizing foreign currency exchange options	10.1109/VISUAL.1999.809929	http://dx.doi.org/10.1109/VISUAL.1999.809929	453	562	C		Donna L. Gresh;Bernice E. Rogowitz;M. S. Tignor;E. J. Mayland	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;;	10.1109/VISUAL.1995.480821		IBM T.J. Watson Research Center##IBM T.J. Watson Research Center##IBM T.J. Watson Research Center##IBM T.J. Watson Research Center
Vis	1999	Visualizing large-scale telecommunication networks and services	10.1109/VISUAL.1999.809930	http://dx.doi.org/10.1109/VISUAL.1999.809930	457	461	C		Eleftherios Koutsofios;Stephen C. North;Russell Truscott;Daniel A. Keim	Inf. Visualization Res., AT&T Labs., Florham Park, NJ, USA|c|;;;	10.1109/VISUAL.1998.745301;10.1109/INFVIS.1995.528688;10.1109/VISUAL.1991.175794		AT&T Laboratories##AT&T Laboratories##AT&T Laboratories##AT&T Laboratories
Vis	1999	Detecting null alleles with vasarely charts	10.1109/VISUAL.1999.809931	http://dx.doi.org/10.1109/VISUAL.1999.809931	463	466	C		Carl Manaster;Elizabeth Nanthakumar;Phillip A. Morin	;;			
Vis	1999	Automating transfer function design for comprehensible volume rendering based on 3D field topology analysis	10.1109/VISUAL.1999.809932	http://dx.doi.org/10.1109/VISUAL.1999.809932	467	563	C		Issei Fujishiro;Taeko Azuma;Yuriko Takeshima	Dept. of Inf. Sci., Ochanomizu Univ., Tokyo, Japan|c|;;	10.1109/VISUAL.1996.568113		Ochanomizu University##Ochanomizu University##Ochanomizu University
Vis	1999	Accelerating 3D convolution using graphics hardware	10.1109/VISUAL.1999.809934	http://dx.doi.org/10.1109/VISUAL.1999.809934	471	564	C		Matthias Hopf;Thomas Ertl	Visualization & Interactive Syst. Group, Stuttgart Univ., Germany|c|;	10.1109/VISUAL.1998.745321;10.1109/VISUAL.1993.398877		IfI##IfI
Vis	1999	Visualizing Simulated Room Fires	10.1109/VISUAL.1999.809936	http://doi.ieeecomputersociety.org/10.1109/VISUAL.1999.809936	475	478	C		Jayesh Govindarajan;Matthew O. Ward;Jonathan Barnett	Computer Science Dept., Worcester Polytechnic Institute, Worcester, MA	10.1109/VISUAL.1994.346291;10.1109/VISUAL.1990.146392;10.1109/VISUAL.1993.398899;10.1109/VISUAL.1996.568110;10.1109/VISUAL.1995.480818		Computer Science Dept., Worcester Polytechnic Institute, Worcester, MA
Vis	1999	Why the PC will be the most pervasive visualization platform in 2001	10.1109/VISUAL.1999.809938	http://dx.doi.org/10.1109/VISUAL.1999.809938	481	483	M		Hanspeter Pfister;Michel Cox;Peter N. Glaskowsky;William E. Lorensen;Richard Greco	MERL|c|			MERL|c|
Vis	1999	Visualization needs more visual design!	10.1109/VISUAL.1999.809939	http://dx.doi.org/10.1109/VISUAL.1999.809939	485	490	M		J. Edward Swan II;Theresa-Marie Rhyne;David H. Laidlaw;Tamara Munzner;Victoria Interrante	Naval Research Laboratory|c|			Naval Research Laboratory|c|
Vis	1999	Automation or interaction: what's best for big data?	10.1109/VISUAL.1999.809940	http://dx.doi.org/10.1109/VISUAL.1999.809940	491	495	M		David N. Kenwright;David C. Banks;Steve Bryson;Robert Haimes;Robert van Liere;Samuel P. Uselton	NASA Ames Research Center|c|			NASA Ames Research Center|c|
InfoVis	2000	Using Visualization to Detect Plagiarism in Computer Science Classes	10.0000/00000001	http://dl.acm.org/citation.cfm?id=857699	173		C		Randy L. Ribler;Marc Abrams	Lynchburg College, Lynchbury, VA, USA;	10.1109/VISUAL.1993.398883;10.1109/VISUAL.1995.480794		Lynchburg College Lynchburg##Lynchburg College Lynchburg
InfoVis	2000	Polaris: a system for query, analysis and visualization of multi-dimensional relational databases	10.1109/INFVIS.2000.885086	http://dx.doi.org/10.1109/INFVIS.2000.885086	5	14	C		Chris Stolte;Pat Hanrahan	Dept. of Comput. Sci., Stanford Univ., CA, USA|c|;	10.1109/INFVIS.1996.559210		Stanford University##Stanford University
InfoVis	2000	Getting portals to behave	10.1109/INFVIS.2000.885087	http://dx.doi.org/10.1109/INFVIS.2000.885087	15	25	C		Christopher Olston;Allison Woodruff	Stanford Univ., CA, USA|c|;	10.1109/INFVIS.1995.528688	Portals, Multiple Views, Data Visualization	Stanford University##Stanford University
InfoVis	2000	A scalable framework for information visualization	10.1109/INFVIS.2000.885088	http://dx.doi.org/10.1109/INFVIS.2000.885088	27	36	C		Matthias Kreuseler;Norma López;Heidrun Schumann	Dept. of Comput. Sci., Rostock Univ., Germany|c|;;	10.1109/VISUAL.1990.146402;10.1109/INFVIS.1997.636759;10.1109/VISUAL.1996.567745;10.1109/VISUAL.1997.663916;10.1109/INFVIS.1995.528686;10.1109/INFVIS.1995.528691;10.1109/INFVIS.1998.729555;10.1109/VISUAL.1991.175815		University of Rostock##University of Rostock##University of Rostock
InfoVis	2000	Visualizing massive multi-digraphs	10.1109/INFVIS.2000.885089	http://dx.doi.org/10.1109/INFVIS.2000.885089	39	47	C		James Abello;Jeffrey L. Korn	;	10.1109/INFVIS.1998.729557;10.1109/VISUAL.1995.480803;10.1109/VISUAL.1993.398870	visualization, massive data sets, graphs, hierarchies, out-of-core algorithms	AT&T Labs-Research##AT&T Labs-Research
InfoVis	2000	Density functions for visual attributes and effective partitioning in graph visualization	10.1109/INFVIS.2000.885090	http://dx.doi.org/10.1109/INFVIS.2000.885090	49	56	C		Ivan Herman;M. Scott Marshall;Guy Melançon	Centre for Math. & Comput. Sci., Amsterdam, Netherlands|c|;;	10.1109/INFVIS.1999.801859;10.1109/VISUAL.1991.175773;10.1109/INFVIS.1999.801858;10.1109/VISUAL.1990.146360	graph visualization, graph navigation, metrics, clustering	Centre for Math. & Comput. Sci., Amsterdam, Netherlands|c|;;
InfoVis	2000	Focus+context display and navigation techniques for enhancing radial, space-filling hierarchy visualizations	10.1109/INFVIS.2000.885091	http://dx.doi.org/10.1109/INFVIS.2000.885091	57	65	C		John T. Stasko;Eugene Zhang	GVU Center, Georgia Inst. of Technol., Atlanta, GA, USA|c|;	10.1109/INFVIS.1999.801860;10.1109/VISUAL.1992.235217;10.1109/INFVIS.1998.729557;10.1109/VISUAL.1991.175815		GVU Center and College of Computing Georgia Institute of Technology Atlanta##GVU Center and College of Computing Georgia Institute of Technology Atlanta
InfoVis	2000	A taxonomy of visualization techniques using the data state reference model	10.1109/INFVIS.2000.885092	http://dx.doi.org/10.1109/INFVIS.2000.885092	69	75	C		Ed Huai-hsin Chi	Xerox Palo Alto Res. Center, CA, USA|c|	10.1109/INFVIS.1997.636761;10.1109/INFVIS.1997.636792;10.1109/INFVIS.1998.729560	Information Visualization, Data State Model,Reference Model, Taxonomy, Techniques, Operators	Xerox Palo Alto Research Center
InfoVis	2000	GADGET/IV: a taxonomic approach to semi-automatic design of information visualization applications using modular visualization environment	10.1109/INFVIS.2000.885093	http://dx.doi.org/10.1109/INFVIS.2000.885093	77	83	C		Issei Fujishiro;Rika Furuhata;Yoshihiko Ichikawa;Yuriko Takeshima	Dept. of Inf. Sci., Ochanomizu Univ., Tokyo, Japan|c|;;;	10.1109/INFVIS.1997.636788;10.1109/VISUAL.1997.663889;10.1109/INFVIS.1997.636792;10.1109/VISUAL.1990.146375		Ochanomizu University##Ochanomizu University##Ochanomizu University##Ochanomizu University
InfoVis	2000	Redefining the focus and context of focus+context visualization	10.1109/INFVIS.2000.885094	http://dx.doi.org/10.1109/INFVIS.2000.885094	85	89	C		Staffan Björk;Johan Redström	Interactive Inst., Gothenburg, Sweden|c|;	10.1109/INFVIS.1997.636786;10.1109/INFVIS.1999.801857		Interactive Inst., Gothenburg, Sweden|c|;
InfoVis	2000	From metaphor to method: cartographic perspectives on information visualization	10.1109/INFVIS.2000.885095	http://dx.doi.org/10.1109/INFVIS.2000.885095	91	97	C		André Skupin	Dept. of Geogr., New Orleans Univ., LA, USA|c|	10.1109/INFVIS.1995.528686;10.1109/VISUAL.1992.235198		University of New Orleans
InfoVis	2000	Information content measures of visual displays	10.1109/INFVIS.2000.885096	http://dx.doi.org/10.1109/INFVIS.2000.885096	99	103	C		Julie Yang-Peláez;Woodie Flowers	Dept. of Mech. Eng., MIT, Cambridge, MA, USA|c|;	10.1109/INFVIS.1997.636792;10.1109/INFVIS.1995.528691		Dept. of Mech. Eng., MIT, Cambridge, MA, USA|c|;
InfoVis	2000	Visualizing sequential patterns for text mining	10.1109/INFVIS.2000.885097	http://dx.doi.org/10.1109/INFVIS.2000.885097	105	111	C		Pak Chung Wong;Wendy Cowley;Harlan Foote;Elizabeth Jurrus;James J. Thomas	Pacific Northwest Lab., Richland, WA, USA|c|;;;;	10.1109/INFVIS.1998.729565;10.1109/INFVIS.1998.729570;10.1109/VISUAL.1998.745302;10.1109/INFVIS.1995.528686;10.1109/INFVIS.1999.801866;10.1109/INFVIS.1997.636791		Pacific Northwest National Laboratory##Pacific Northwest National Laboratory##Pacific Northwest National Laboratory##Pacific Northwest National Laboratory##Pacific Northwest National Laboratory##Pacific Northwest National Laboratory
InfoVis	2000	ThemeRiver: visualizing theme changes over time	10.1109/INFVIS.2000.885098	http://dx.doi.org/10.1109/INFVIS.2000.885098	115	123	C		Susan L. Havre;Elizabeth G. Hetzler;Lucy T. Nowell	Battelle Pacific Northwest Lab., Richland, WA, USA|c|;;	10.1109/INFVIS.1995.528686;10.1109/INFVIS.1997.636789;10.1109/INFVIS.1998.729570		Battelle Pacific Northwest Division Richland##Battelle Pacific Northwest Division Richland##Battelle Pacific Northwest Division Richland
InfoVis	2000	Lighthouse: showing the way to relevant information	10.1109/INFVIS.2000.885099	http://dx.doi.org/10.1109/INFVIS.2000.885099	125	129	C		Anton Leuski;James Allan	Center for Intelligent Inf. Retrieval, Massachusetts Univ., Amherst, MA, USA|c|;			University of Massachusetts Amherst##University of Massachusetts Amherst
InfoVis	2000	New methods for the visualization of electric power system information	10.1109/INFVIS.2000.885101	http://dx.doi.org/10.1109/INFVIS.2000.885101	131	16c	C		Thomas J. Overbye;Jamie D. Weber	Illinois Univ., Urbana, IL, USA|c|;			University of Illinois at Urbana-Champaign##University of Illinois at Urbana-Champaign
InfoVis	2000	Collaborative geographic visualization: enabling shared understanding of environmental processes	10.1109/INFVIS.2000.885102	http://dx.doi.org/10.1109/INFVIS.2000.885102	137	141	C		Isaac Brewer;Alan M. MacEachren;Hadi Abdo;Jack Gundrum;George Otto	Dept. of Geogr., Penn State Univ., PA, USA|c|;;;;			Penn State University##Penn State University##Penn State University##Penn State University##Penn State University
InfoVis	2000	Interactive problem solving via algorithm visualization	10.1109/INFVIS.2000.885103	http://dx.doi.org/10.1109/INFVIS.2000.885103	145	153	C		Pearl Pu;Denis Lalanne	Dept. of Comput. Sci., Swiss Federal Inst. of Technol., Lausanne, Switzerland|c|;	10.1109/INFVIS.1998.729557		
InfoVis	2000	Metaphor-aware 3D navigation	10.1109/INFVIS.2000.885104	http://dx.doi.org/10.1109/INFVIS.2000.885104	155	165	C		Cristina Russo Dos Santos;Pascal Gros;Pierre Abel;Didier Loisel;N. Trichaud;J. P. Paris	Eurecom Inst., Sophia Antipolis, France|c|;;;;;	10.1109/VISUAL.1997.663876		EurÃ©com Institute##EurÃ©com Institute##EurÃ©com Institute##EurÃ©com Institute##EurÃ©com Institute##EurÃ©com Institute##EurÃ©com Institute##EurÃ©com Institute##EurÃ©com Institute
InfoVis	2000	Creativity, complexity, and precision: information visualization for (landscape) architecture	10.1109/INFVIS.2000.885105	http://dx.doi.org/10.1109/INFVIS.2000.885105	167	171	C		Monika Büscher;Dan Shapiro;Michael Christensen;Preben Holst Mogensen;Peter Ørbæk	Dept. of Sociology, Lancaster Univ., UK|c|;;;;		Information visualization, architecture, work materials, context,  spatio-temporal order, electronic workspace 	Dept. of Sociology, Lancaster Univ., UK|c|;;;;
Vis	2000	Extracting regions of interest applying a local watershed transformation	10.1109/VISUAL.2000.885672	http://dx.doi.org/10.1109/VISUAL.2000.885672	21	28	C		Stanislav L. Stoev;Wolfgang Straßer	WSI/GRIS, Tubingen Univ., Germany|c|;	10.1109/VISUAL.1998.745311	computer vision, image processing, data visualization, volume visualization, feature extraction, morphological segmentation, Biomedical image segmentation, watershed transformation	University of TÃ¼bingen##University of TÃ¼bingen
Vis	2000	A visibility determination algorithm for interactive virtual endoscopy	10.1109/VISUAL.2000.885673	http://dx.doi.org/10.1109/VISUAL.2000.885673	29	36	C		Rami Hietala;Jarkko Oikarinen	Dept. of Diagnostic Radiol., Oulu Univ., Finland|c|;	10.1109/VISUAL.1997.663915;10.1109/VISUAL.1998.745337;10.1109/VISUAL.1998.745713;10.1109/VISUAL.1999.809912;10.1109/VISUAL.1999.809914	volume visualization, template, visiblity, isosurface extraction, surface rendering	Oulu University Hospital##Oulu University Hospital
Vis	2000	3D digital cleansing using segmentation rays	10.1109/VISUAL.2000.885674	http://dx.doi.org/10.1109/VISUAL.2000.885674	37	44	C		Sarang Lakare;Ming Wan;Mie Sato;Arie E. Kaufman	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;;	10.1109/VISUAL.1999.809914	Volume Segmentation, Segmentation Rays, Partial Volume Voxels, Volume Rendering, Virtual Endoscopy, Virtual Colonoscopy 	State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook##State University of New York at Stony Brook Stony Brook
Vis	2000	CEASAR: a smooth, accurate and robust centerline extraction algorithm	10.1109/VISUAL.2000.885675	http://dx.doi.org/10.1109/VISUAL.2000.885675	45	52	C		Ingmar Bitter;Mie Sato;Michael A. Bender;Kevin T. McDonnell;Arie E. Kaufman;Ming Wan	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;;;;	10.1109/VISUAL.2000.885674		SUNY at Stony Brook##
Vis	2000	Creating reusable visualizations with the relational visualization notation	10.1109/VISUAL.2000.885676	http://doi.ieeecomputersociety.org/10.1109/VISUAL.2000.885676	53	60	C		Matthew C. Humphrey	Iviz, Stafford VA, USA		information visualization, graphic design, visual design	Iviz, Stafford VA, USA
Vis	2000	H-BLOB: a hierarchical visual clustering method using implicit surfaces	10.1109/VISUAL.2000.885677	http://dx.doi.org/10.1109/VISUAL.2000.885677	61	68	C		Thomas C. Sprenger;R. Brunella;Markus H. Gross	Dept. of Comput. Sci., Swiss Fed. Inst. of Technol., Zurich, Switzerland|c|;;	10.1109/INFVIS.1997.636759;10.1109/INFVIS.1995.528691;10.1109/INFVIS.1998.729562	clustering, categorization, partitioning, information visualization, non-linear dimensionality reduction, physics-based graph layout, cluster visualization, multidimensional information visualization	Swiss Federal Institute of Technology (ETH) Zurich##Swiss Federal Institute of Technology (ETH) Zurich##Swiss Federal Institute of Technology (ETH) Zurich
Vis	2000	A spreadsheet interface for visualization exploration	10.1109/VISUAL.2000.885678	http://dx.doi.org/10.1109/VISUAL.2000.885678	69	76	C		T. J. Jankun-Kelly;Kwan-Liu Ma	Dept. of Comput. Sci., California Univ., Davis, CA, USA|c|;	10.1109/VISUAL.1999.809871;10.1109/VISUAL.1995.480821	speadsheets, user interfaces, knowledge representation, scientific visualization, visualization systems, volume rendering	University of California##University of California
Vis	2000	Procedural annotation of uncertain information	10.1109/VISUAL.2000.885679	http://dx.doi.org/10.1109/VISUAL.2000.885679	77	84	C		Andrej Cedilnik;Penny Rheingans	Maryland Univ., Baltimore, MD, USA|c|;	10.1109/VISUAL.1994.346317;10.1109/VISUAL.1996.568111;10.1109/VISUAL.1996.568109	procedure generation, uncertainty, visualization, annotation, glyphs	University of Maryland Baltimore County##University of Maryland Baltimore County
Vis	2000	Simplification of tetrahedral meshes with accurate error evaluation	10.1109/VISUAL.2000.885680	http://dx.doi.org/10.1109/VISUAL.2000.885680	85	92	C		Paolo Cignoni;D. Constanza;Claudio Montani;Claudio Rocchini;Roberto Scopigno	Ist. Sci. e Tecnol. dell''Inf., CNR, Pisa, Italy|c|;;;;	10.1109/VISUAL.1998.745315;10.1109/VISUAL.1997.663907;10.1109/VISUAL.1998.745329;10.1109/VISUAL.1998.745312	Simplicial Complexes, Mesh Simplification, Volume Visualization, Unstructured Grids	Istituto Scienza e Tecnologia dell'Informazione â€“ Consiglio Nazionale delle Ricerche##Istituto Scienza e Tecnologia dell'Informazione â€“ Consiglio Nazionale delle Ricerche##Istituto Scienza e Tecnologia dell'Informazione â€“ Consiglio Nazionale delle Ricerche##Istituto Scienza e Tecnologia dell'Informazione â€“ Consiglio Nazionale delle Ricerche##Istituto Scienza e Tecnologia dell'Informazione â€“ Consiglio Nazionale delle Ricerche
Vis	2000	Tetrahedron based, least squares, progressive volume models with application to freehand ultrasound data	10.1109/VISUAL.2000.885681	http://dx.doi.org/10.1109/VISUAL.2000.885681	93	100	C		Tom Roxborough;Gregory M. Nielson	Arizona State Univ., Tempe, AZ, USA|c|;	10.1109/VISUAL.1997.663907		Arizona State University##Arizona State University
Vis	2000	On-the-fly rendering of losslessly compressed irregular volume data	10.1109/VISUAL.2000.885682	http://dx.doi.org/10.1109/VISUAL.2000.885682	101	108	C		Chuan-Kai Yang;Tulika Mitra;Tzi-cker Chiueh	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;	10.1109/VISUAL.1999.809868	irregular grids, tetrahedral compression, volume rendering	State University of New York at Stony Brook *##State University of New York at Stony Brook *##State University of New York at Stony Brook *
Vis	2000	Hardware-accelerated volume and isosurface rendering based on cell-projection	10.1109/VISUAL.2000.885683	http://dx.doi.org/10.1109/VISUAL.2000.885683	109	116	C		Stefan Röttger;Martin Kraus;Thomas Ertl	Visualization & Interactive Syst. Group, Stuttgart Univ., Germany|c|;;	10.1109/VISUAL.1993.398846;10.1109/VISUAL.1994.346320;10.1109/VISUAL.1999.809887;10.1109/VISUAL.1994.346308;10.1109/VISUAL.2000.885688;10.1109/VISUAL.1994.346306;10.1109/VISUAL.1997.663853;10.1109/VISUAL.1999.809878;10.1109/VISUAL.1996.568127;10.1109/VISUAL.1995.480806;10.1109/VISUAL.1998.745300;10.1109/VISUAL.1996.568121;10.1109/VISUAL.1998.745713	Volume Rendering, Isosurfaces, Unstructured Meshes, Cell Projection, Graphics Hardware, Texture Mapping, Compositing	UniversitÃ¤t Stuttgart##UniversitÃ¤t Stuttgart##UniversitÃ¤t Stuttgart
Vis	2000	Achieving color uniformity across multi-projector displays	10.1109/VISUAL.2000.885684	http://dx.doi.org/10.1109/VISUAL.2000.885684	117	124	C		Aditi Majumder;Zhu He;Herman Towles;Greg Welch	Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;	10.1109/VISUAL.1999.809890	large area display, tiled displays, projector graphics, color calibration	University of North Carolina at Chapel Hill. majumder##University of North Carolina at Chapel Hill. majumder##University of North Carolina at Chapel Hill. majumder##University of North Carolina at Chapel Hill. majumder
Vis	2000	Automatic alignment of high-resolution multi-projector displays using an uncalibrated camera	10.1109/VISUAL.2000.885685	http://dx.doi.org/10.1109/VISUAL.2000.885685	125	130	C		Yuqun Chen;Douglas W. Clark;Adam Finkelstein;Timothy C. Housel;Kai Li	Dept. of Comput. Sci., Princeton Univ., NJ, USA|c|;;;;	10.1109/VISUAL.1999.809883	seamless tiling, automatic alignment, projective mapping, simulated annealing 	Princeton University##Princeton University##Princeton University##Princeton University##Princeton University
Vis	2000	Shock and vortex visualization using a combined visual/haptic interface	10.1109/VISUAL.2000.885686	http://dx.doi.org/10.1109/VISUAL.2000.885686	131	137	C		Dale A. Lawrence;Christopher D. Lee;Lucy Y. Pao;Roman Y. Novoselov	Dept. of Aerosp. Eng. Sci., Colorado Univ., Boulder, CO, USA|c|;;;	10.1109/VISUAL.1998.745296;10.1109/VISUAL.1998.745333;10.1109/VISUAL.1996.568108	haptic, interface, vortex, shock, visualization, fluid dynamics, virtual environment	University of Colorado Boulder##University of Colorado Boulder##University of Colorado Boulder##University of Colorado Boulder
Vis	2000	Six degree-of-freedom haptic display of polygonal models	10.1109/VISUAL.2000.885687	http://dx.doi.org/10.1109/VISUAL.2000.885687	139	146	C		Arthur D. Gregory;Ajith Mascarenhas;Stephen A. Ehmann;Ming C. Lin;Dinesh Manocha	Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;;	10.1109/VISUAL.1996.568108	haptics, virtual reality, forcefeedback devices, interactive computer graphics	University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill
Vis	2000	A level-set method for flow visualization	10.1109/VISUAL.2000.885688	http://dx.doi.org/10.1109/VISUAL.2000.885688	147	154	C		Rüdiger Westermann;Christopher R. Johnson 0001;Thomas Ertl	Sci. Comput. & Visualization Group, Univ. of Technol., Aachen, Germany|c|;;	10.1109/VISUAL.1999.809865;10.1109/VISUAL.1999.809892;10.1109/VISUAL.1993.398877;10.1109/VISUAL.1992.235211;10.1109/VISUAL.1997.663912;10.1109/VISUAL.1999.809863;10.1109/VISUAL.1993.398875;10.1109/VISUAL.1993.398875;10.1109/VISUAL.1997.663898;10.1109/VISUAL.1997.663859;10.1109/VISUAL.1994.346312	Flow Visualization, Level-Sets, Feature Extraction,Multiscale Representation, Texture Mapping	University of Technology##University of Technology##University of Technology
Vis	2000	Hardware-accelerated texture advection for unsteady flow visualization	10.1109/VISUAL.2000.885689	http://dx.doi.org/10.1109/VISUAL.2000.885689	155	162	C		Bruno Jobard;Gordon Erlebacher;M. Yousuff Hussaini	Sch. of Comput. Sci. & Inf. Technol., Tallahassee, FL, USA|c|;;	10.1109/VISUAL.1995.480817;10.1109/VISUAL.1998.745324	unsteady, vector field, pathlines, streakline, advection, texture, hardware, OpenGL	Sch. of Comput. Sci. & Inf. Technol., Tallahassee, FL, USA|c|;;
Vis	2000	A flow-guided streamline seeding strategy	10.1109/VISUAL.2000.885690	http://dx.doi.org/10.1109/VISUAL.2000.885690	163	170	C		Vivek Verma;David T. Kao;Alex T. Pang	Dept. of Comput. Sci., Univ. of Southern California, Los Angeles, CA, USA|c|;;	10.1109/VISUAL.1990.146359;10.1109/VISUAL.1998.745291;10.1109/VISUAL.1991.175773;10.1109/VISUAL.1994.346312;10.1109/VISUAL.1990.146360;10.1109/VISUAL.1995.480819;10.1109/VISUAL.1997.663899;10.1109/VISUAL.1998.745295;10.1109/VISUAL.1999.809906	seed placement, streamline, critical point, Voronoi diagram, Poisson disk distribution	UCSC Â¾ NASA Ames Research Center##UCSC Â¾ NASA Ames Research Center##UCSC Â¾ NASA Ames Research Center##UCSC Â¾ NASA Ames Research Center
Vis	2000	Enabling level-of-detail matching for exterior scene synthesis	10.1109/VISUAL.2000.885691	http://dx.doi.org/10.1109/VISUAL.2000.885691	171	178	C		Randy K. Scoggins;Robert J. Moorhead II;Raghu Machiraju	Eng. Res. & Dev. Center, US Army Corp. of Eng., Vicksburg, MS, USA|c|;;	10.1109/VISUAL.1996.568126;10.1109/VISUAL.1998.745282	multiresolution model, level-of-detail, rendering, image metrics, perception, terrain visualization	Mississippi State University##The Ohio State University##Mississippi State University
Vis	2000	Visual cues for imminent object contact in realistic virtual environment	10.1109/VISUAL.2000.885692	http://doi.ieeecomputersociety.org/10.1109/VISUAL.2000.885692	179	185	C		Helen H. Hu;Amy Ashurst Gooch;William B. Thompson;Brian E. Smits;John J. Rieser;Peter Shirley	University of Utah		virtual reality, head mounted displays, human visual perception	University of Utah##University of Utah##University of Utah##University of Utah##University of Utah##University of Utah
Vis	2000	Basic research for coloring multichannel MRI data	10.1109/VISUAL.2000.885693	http://dx.doi.org/10.1109/VISUAL.2000.885693	187	194	C		Shigeru Muraki;Toshiharu Nakai;Yasuyo Kita	MITI, Electrotech. Lab., Ibaraki, Japan|c|;;	10.1109/VISUAL.1996.568113	color MRI, independent component analysis, transfer function	
Vis	2000	Volume illustration: non-photorealistic rendering of volume models	10.1109/VISUAL.2000.885694	http://dx.doi.org/10.1109/VISUAL.2000.885694	195	202	C		David S. Ebert;Penny Rheingans	Dept. of Comput. Sci. & Electr. Eng., Maryland Univ., Baltimore, MD, USA|c|;	10.1109/VISUAL.1996.568111;10.1109/VISUAL.1998.745294;10.1109/VISUAL.1995.480795;10.1109/VISUAL.2000.885696;10.1109/VISUAL.1998.745319;10.1109/VISUAL.1999.809905;10.1109/VISUAL.1999.809932;10.1109/VISUAL.1990.146391	Volume rendering, non-photorealistic rendering,illustration, lighting models, shading, visualization	Computer Science and Electrical Engineering University of Maryland Baltimore County##Computer Science and Electrical Engineering University of Maryland Baltimore County
Vis	2000	Pen-and-ink rendering in volume visualisation	10.1109/VISUAL.2000.885696	http://dx.doi.org/10.1109/VISUAL.2000.885696	203	210	C		Steve M. F. Treavett;Min Chen	Dept. of Comput. Sci., Univ. of Wales, Swansea, UK|c|;	10.1109/VISUAL.1996.568110	Volume rendering, non-photorealistic rendering, pen-and-ink rendering, 3D texture mapping	University of Wales Swansea##University of Wales Swansea
Vis	2000	Two-level volume rendering - fusing MIP and DVR	10.1109/VISUAL.2000.885697	http://dx.doi.org/10.1109/VISUAL.2000.885697	211	218	C		Helwig Hauser;Lukas Mroz;Gian Italo Bischi;Eduard Gröller	VRVis Res. Centre, Wien Univ. of Technol., Austria|c|;;;	10.1109/VISUAL.1998.745311;10.1109/VISUAL.1999.809887;10.1109/VISUAL.1996.568113	visualization, volume rendering, dynamical systems,medical applications	VRVis Center Vienna##University of Urbino##Vienna Univ. of Technology##Vienna University of Technology
Vis	2000	FastSplats: optimized splatting on rectilinear grids	10.1109/VISUAL.2000.885698	http://dx.doi.org/10.1109/VISUAL.2000.885698	219	226	C		Jian Huang;Roger Crawfis;Naeem Shareef;Klaus Mueller	Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA|c|;;;	10.1109/VISUAL.1999.809909;10.1109/VISUAL.1993.398877;10.1109/VISUAL.1999.809872		Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA|c|;;;
Vis	2000	Texturing techniques for terrain visualization	10.1109/VISUAL.2000.885699	http://dx.doi.org/10.1109/VISUAL.2000.885699	227	234	C		Jürgen Döllner;Konstantin Baumann;Klaus H. Hinrichs	Dept. of Comput. Sci., Munster Univ., Germany|c|;;	10.1109/VISUAL.1998.745322;10.1109/VISUAL.1998.745285;10.1109/VISUAL.1999.809869;10.1109/VISUAL.1998.745283;10.1109/VISUAL.1998.745342;10.1109/VISUAL.1995.480805;10.1109/VISUAL.1999.809900;10.1109/VISUAL.1998.745280	Terrain Rendering, Texture Mapping, Multiresolution, Level of Detail, 3D Maps	University of MÃ¼nster##University of MÃ¼nster##University of MÃ¼nster
Vis	2000	Simplification of surface annotations	10.1109/VISUAL.2000.885700	http://dx.doi.org/10.1109/VISUAL.2000.885700	235	242	C		Frank Suits;James T. Klosowski;William Horn;Gérard Lecina	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;;	10.1109/VISUAL.1998.745285	simplification, polygonal path, mesh, CAD/CAM, FEM, cartography	IBM T. J. Watson Research Center â€ Dassault SystÃ¨mes##IBM T. J. Watson Research Center â€ Dassault SystÃ¨mes##IBM T. J. Watson Research Center â€ Dassault SystÃ¨mes##IBM T. J. Watson Research Center â€ Dassault SystÃ¨mes
Vis	2000	Uniform frequency images: adding geometry to images to produce space-efficient textures	10.1109/VISUAL.2000.885701	http://dx.doi.org/10.1109/VISUAL.2000.885701	243	250	C		Adam Hunter;Jonathan D. Cohen	Johns Hopkins Univ., MD, USA|c|;		texture mapping, Fourier analysis, sampling, parameterization, visualization	The Johns Hopkins University##The Johns Hopkins University
Vis	2000	Image based rendering with stable frame rates	10.1109/VISUAL.2000.885702	http://doi.ieeecomputersociety.org/10.1109/VISUAL.2000.885702	251	258	C		Huamin Qu;Ming Wan;Jiafa Qin;Arie E. Kaufman	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;	10.1109/VISUAL.1992.235190;10.1109/VISUAL.1998.745305;10.1109/VISUAL.1999.809900	Image-based rendering, ray casting, voxel-based modeling, terrain rendering	State University of New York at Stony Brook##State University of New York at Stony Brook##State University of New York at Stony Brook##State University of New York at Stony Brook
Vis	2000	Topology preserving and controlled topology simplifying multiresolution isosurface extraction	10.1109/VISUAL.2000.885703	http://dx.doi.org/10.1109/VISUAL.2000.885703	259	266	C		Thomas Gerstner;Renato Pajarola	Dept. of Appl. Math., Bonn Univ., Germany|c|;	10.1109/VISUAL.1996.568127;10.1109/VISUAL.1997.663907;10.1109/VISUAL.1997.663909;10.1109/VISUAL.1998.745300;10.1109/VISUAL.1994.346334;10.1109/VISUAL.1997.663869	tetrahedral grid refinement, implicit surface approximation, level-of-detail, topological genus, critical points	University of Bonn##University of Bonn
Vis	2000	Isosurfacing in higher dimensions	10.1109/VISUAL.2000.885704	http://dx.doi.org/10.1109/VISUAL.2000.885704	267	273	C		Praveen Bhaniramka;Rephael Wenger;Roger Crawfis	Silicon Graphics Comput. Syst., Mountain View, CA, USA|c|;;	10.1109/VISUAL.1992.235222;10.1109/VISUAL.1998.745315;10.1109/VISUAL.1993.398869;10.1109/VISUAL.1997.663885;10.1109/VISUAL.1999.809879;10.1109/VISUAL.1996.568103;10.1109/VISUAL.1997.663886;10.1109/VISUAL.1991.175821;10.1109/VISUAL.1991.175782;10.1109/VISUAL.1998.745298		Silicon Graphics Comput. Syst., Mountain View, CA, USA|c|;;
Vis	2000	Semi-regular mesh extraction from volumes	10.1109/VISUAL.2000.885705	http://dx.doi.org/10.1109/VISUAL.2000.885705	275	282	C		Zoë J. Wood;Peter Schröder;David E. Breen;Mathieu Desbrun	California Inst. of Technol., Pasadena, CA, USA|c|;;;	10.1109/VISUAL.2000.885703	Semi-regular meshes, subdivision, volumes, surface extraction, implicit functions, level set methods	USC##USC##USC##USC##USC
Vis	2000	Scanline surfacing: building separating surfaces from planar contours	10.1109/VISUAL.2000.885706	http://dx.doi.org/10.1109/VISUAL.2000.885706	283	289	C		David M. Weinstein	Sch. of Comput., Utah Univ., Salt Lake City, UT, USA|c|	10.1109/VISUAL.1997.663887;10.1109/VISUAL.1994.346337	separating surfaces, planar contours, surface construction, scanline	University of Utah
Vis	2000	Navigating high-dimensional spaces to support design steering	10.1109/VISUAL.2000.885707	http://dx.doi.org/10.1109/VISUAL.2000.885707	291	296	C		Helen Wright;Ken Brodlie;Tim David	Dept. of Comput. Sci., Hull Univ., UK|c|;;	10.1109/VISUAL.1999.809921;10.1109/VISUAL.1995.485157;10.1109/VISUAL.1998.745351;10.1109/VISUAL.1993.398895;10.1109/VISUAL.1993.398857;10.1109/VISUAL.1995.485143	Computational steering, design steering, concept design, multidimensional visualization, scientific data visualization	University of Hull##University of Leeds##University of Leeds
Vis	2000	Visualization of multi-dimensional data with vector-fusion	10.1109/VISUAL.2000.885708	http://dx.doi.org/10.1109/VISUAL.2000.885708	297	302	C		R. R. Johnson	Dept. of Comput. Sci., Utah Univ., Salt Lake City, UT, USA|c|		Multidimensional Visualization, Vector Data Fusion, Multidimensional Geometry	University of Utah nDV-LLC
Vis	2000	Real-world relativity: image-based special relativistic visualization	10.1109/VISUAL.2000.885709	http://dx.doi.org/10.1109/VISUAL.2000.885709	303	310	C		Daniel Weiskopf;Daniel Kobras;Hanns Ruder	Inst. of Astron. & Astrophys., Tubingen Univ., Germany|c|;;	10.1109/VISUAL.1990.146368	image-based rendering, plenoptic function, scientific visualization, special relativity	University of TÃ¼bingen
Vis	2000	Visualizing geodesics	10.1109/VISUAL.2000.885710	http://dx.doi.org/10.1109/VISUAL.2000.885710	311	318	C		Ingrid Hotz;Hans Hagen	Dept. of Comput. Sci., Kaiserslautern Univ., Germany|c|;	10.1109/VISUAL.1992.235196	geodesics, visualization features	University of Kaiserslautern##University of Kaiserslautern
Vis	2000	Geometric compression for interactive transmission	10.1109/VISUAL.2000.885711	http://dx.doi.org/10.1109/VISUAL.2000.885711	319	326	C		Olivier Devillers;Pierre-Marie Gandoin	Inst. Nat. de Recherche en Inf. et Autom., Sophia Antipolis, France|c|;	10.1109/VISUAL.1997.663902;10.1109/VISUAL.1999.809902;10.1109/VIS.1999.10000	geometry, compression, coding, interactivity, mesh, reconstruction, terrain models	INRIA Sophia Antipolis##INRIA Sophia Antipolis
Vis	2000	Toward a compelling sensation of telepresence: demonstrating a portal to a distant (static) office	10.1109/VISUAL.2000.885712	http://dx.doi.org/10.1109/VISUAL.2000.885712	327	333	C		Wei-Chao Chen;Herman Towles;Lars S. Nyland;Greg Welch;Henry Fuchs	Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;;	10.1109/VISUAL.1996.568125;10.1109/VISUAL.1997.663893	telepresence, tele-immersion, virtual reality, collaborative visualization, immersive display, augmented reality, human-computer interface	The University of North Carolina at Chapel Hill##The University of North Carolina at Chapel Hill##The University of North Carolina at Chapel Hill##The University of North Carolina at Chapel Hill##The University of North Carolina at Chapel Hill
Vis	2000	multi-user view-dependent rendering	10.1109/VISUAL.2000.885713	http://doi.ieeecomputersociety.org/10.1109/VISUAL.2000.885713	335	342	C		Jihad El-Sana	Ben-Gurion University in Israel	10.1109/VISUAL.1999.809877;10.1109/VISUAL.1995.480805		Ben-Gurion University Beer-Sheva
Vis	2000	Topology preserving compression of 2D vector fields	10.1109/VISUAL.2000.885714	http://dx.doi.org/10.1109/VISUAL.2000.885714	343	350	C		Suresh K. Lodha;Jose C. Renteria;Krishna M. Roskin	Dept. of Comput. Sci., California Univ., Santa Cruz, CA, USA|c|;;	10.1109/VISUAL.1999.809865;10.1109/VISUAL.1998.745291;10.1109/VISUAL.1999.809907;10.1109/VISUAL.1998.745297;10.1109/VISUAL.1999.809863;10.1109/VISUAL.1999.809897;10.1109/VISUAL.1991.175773;10.1109/VISUAL.1997.663858;10.1109/VISUAL.1998.745284	compression, topology, vector fields, error metrics,clustering	University of California##University of California##University of California
Vis	2000	A continuous clustering method for vector fields	10.1109/VISUAL.2000.885715	http://doi.ieeecomputersociety.org/10.1109/VISUAL.2000.885715	351	358	C		Harald Garcke;Tobias Preußer;Martin Rumpf;Alexandru Telea;Ulrich Weikard;Jarke J. van Wijk	Technical University Eindhoven, Eindhoven, NL	10.1109/VISUAL.1999.809865;10.1109/VISUAL.1995.480817;10.1109/VISUAL.1994.346313;10.1109/VISUAL.1999.809863;10.1109/VISUAL.1995.485141;10.1109/VISUAL.1999.809892;10.1109/VISUAL.1996.567777;10.1109/VISUAL.1999.809904		Technical University Eindhoven, Eindhoven, NL
Vis	2000	A topology simplification method for 2D vector fields	10.1109/VISUAL.2000.885716	http://dx.doi.org/10.1109/VISUAL.2000.885716	359	366	C		Xavier Tricoche;Gerik Scheuermann;Hans Hagen	Dept. of Comput. Sci., Kaiserslautern Univ., Germany|c|;;	10.1109/VISUAL.1999.809863;10.1109/VISUAL.1998.745318;10.1109/VISUAL.1991.175773;10.1109/VISUAL.1999.809907;10.1109/VISUAL.1997.663858	vector field topology, flow visualization, clustering,simplification	University of Kaiserslautern##University of Kaiserslautern##University of Kaiserslautern
Vis	2000	Constructing material interfaces from data sets with volume-fraction information	10.1109/VISUAL.2000.885717	http://dx.doi.org/10.1109/VISUAL.2000.885717	367	372	C		Kathleen S. Bonnell;Kenneth I. Joy;Bernd Hamann;Daniel Schikore;Mark A. Duchaineau	CIPIC, California Univ., Davis, CA, USA|c|;;;;	10.1109/VISUAL.1991.175782;10.1109/VISUAL.1997.663887;10.1109/VISUAL.1997.663869	Eulerian flow, material boundary surface, barycentric coordinates, volume fraction, Voronoi diagram	CIPIC, California Univ., Davis, CA, USA|c|;;;;
Vis	2000	New techniques for topologically correct surface reconstruction	10.1109/VISUAL.2000.885718	http://dx.doi.org/10.1109/VISUAL.2000.885718	373	380	C		Udo Adamy;Joachim Giesen;Matthias John	Inst. for Theor. Comput. Sci., Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;;	10.1109/VISUAL.1998.745286	surface reconstruction, gabriel graph, linear programming, topology	ETH ZÃ¼rich##ETH ZÃ¼rich##ETH ZÃ¼rich
Vis	2000	Polyhedral modeling	10.1109/VISUAL.2000.885719	http://dx.doi.org/10.1109/VISUAL.2000.885719	381	387	C		Georges-Pierre Bonneau;Stefanie Hahmann	CNRS, Univ. of Grenoble, France|c|;		triangular meshes, visual continuity, arbitrary topology, visualization	CNRS University of Grenoble##CNRS University of Grenoble
Vis	2000	Bicubic subdivision-surface wavelets for large-scale isosurface representation and visualization	10.1109/VISUAL.2000.885720	http://doi.ieeecomputersociety.org/10.1109/VISUAL.2000.885720	389	396	C		Martin Hering-Bertram;Mark A. Duchaineau;Bernd Hamann;Kenneth I. Joy	UC, Davis	10.1109/VISUAL.1994.346332;10.1109/VISUAL.1997.663871;10.1109/VISUAL.2000.885717		UC, Davis
Vis	2000	Anisotropic geometric diffusion in surface processing	10.1109/VISUAL.2000.885721	http://dx.doi.org/10.1109/VISUAL.2000.885721	397	405	C		Ulrich Clarenz;Udo Diewald;Martin Rumpf	Inst. for Appl. Math., Bonn Univ., Germany|c|;;	10.1109/VISUAL.1999.809904	Image Processing, Geometric Modeling, Numerical Analysis	University of Bonn##University of Bonn##University of Bonn
Vis	2000	Fairing of non-manifolds for visualization	10.1109/VISUAL.2000.885722	http://doi.ieeecomputersociety.org/10.1109/VISUAL.2000.885722	407	414	C		Andreas Hubeli;Markus H. Gross	ETH Zurich			ETH Zurich
Vis	2000	Interior/exterior classification of polygonal models	10.1109/VISUAL.2000.885723	http://doi.ieeecomputersociety.org/10.1109/VISUAL.2000.885723	415	422	C		Fakir S. Nooruddin;Greg Turk	Georgina Tech	10.1109/VISUAL.1997.663909;10.1109/VISUAL.1995.480795;10.1109/VISUAL.1996.568111	Visibility, Surface Classification, Rendering, Interior Surfaces	GVU Center##GVU Center
Vis	2000	Multi-resolution dynamic meshes with arbitrary deformations	10.1109/VISUAL.2000.885724	http://dx.doi.org/10.1109/VISUAL.2000.885724	423	430	C		Ariel Shamir;Chandrajit L. Bajaj;Valerio Pascucci	Center for Comput. Visualization, Texas Univ., Austin, TX, USA|c|;;	10.1109/VISUAL.1997.663865;10.1109/VISUAL.1999.809869;10.1109/VISUAL.1999.809910;10.1109/VISUAL.1999.809879;10.1109/VISUAL.1998.745329;10.1109/VISUAL.1996.568126;10.1109/VISUAL.1998.745282;10.1109/VISUAL.1997.663883		Center for Comput. Visualization, Texas Univ., Austin, TX, USA|c|;;
Vis	2000	Fast visualization methods for comparing dynamics: a case study in combustion	10.1109/VISUAL.2000.885725	http://dx.doi.org/10.1109/VISUAL.2000.885725	433	436	C		Kay A. Robbins;Michael Gorman	Div. of Comput. Sci., Texas Univ., San Antonio, TX, USA|c|;	10.1109/VISUAL.1999.809882;10.1109/VISUAL.1996.568117;10.1109/VISUAL.1995.485141	realtime visualization, steering, symmetry, tiling, pattern formation, movies	Div. of Comput. Sci., Texas Univ., San Antonio, TX, USA|c|;
Vis	2000	Mastering interactive surface rendering for Java-based diagnostic applications	10.1109/VISUAL.2000.885726	http://dx.doi.org/10.1109/VISUAL.2000.885726	437	440	C		Lukas Mroz;Rainer Wegenkittl;Eduard Gröller	Inst. of Comput. Graphics, Wien Univ. of Technol., Austria|c|;;	10.1109/VISUAL.1999.809911	volume visualization, surface rendering, medical applications, tomographic data	Vienna University of Technology##Vienna University of Technology##Vienna University of Technology
Vis	2000	A computational steering system for studying microwave interactions with missile bodies	10.1109/VISUAL.2000.885727	http://dx.doi.org/10.1109/VISUAL.2000.885727	441	444	C		J. Edward Swan II;Marco Lanzagorta;Doug Maxwell;Eddy Kuo;Jeffrey K. Uhlmann;Wendell Anderson;Haw-Jye Shyu;William Smith	Virtual Reality Lab., Naval Res. Lab., Washington, DC, USA|c|;;;;;;;		Modeling and Simulation, Scientific Visualization, Computational Steering, Inverse Steering, Virtual Reality	Virtual Reality Lab., Naval Res. Lab., Washington, DC, USA|c|;;;;;;;
Vis	2000	Four-dimensional non-linear ray tracing as a visualization tool for gravitational physics	10.1109/VISUAL.2000.885728	http://dx.doi.org/10.1109/VISUAL.2000.885728	445	448	C		Daniel Weiskopf	Inst. for Astron. & Astrophys., Tubingen Univ., Germany|c|	10.1109/VISUAL.1992.235196	differential geometry, four-dimensional spacetimes, general relativity, ray tracing, scientific visualization	University of TÃ¼bingen
Vis	2000	Combining local and remote visualization techniques for interactive volume rendering in medical applications	10.1109/VISUAL.2000.885729	http://dx.doi.org/10.1109/VISUAL.2000.885729	449	452	C		Klaus Engel;Thomas Ertl;Peter Hastreiter;Bernd Tomandl;K. Eberhardt	Visualization & Interactive Syst. Group, Stuttgart Univ., Germany|c|;;;;	10.1109/VISUAL.1996.568134	medical data visualization, volume visualization, distributed systems, PC graphics hardware, remote rendering	Neurocenter##University of Erlangen-Nuremberg##University of Erlangen-Nuremberg####University of Stuttgart
Vis	2000	An integrated visualization and design toolkit for flexible prosthetic heart valves	10.1109/VISUAL.2000.885730	http://dx.doi.org/10.1109/VISUAL.2000.885730	453	456	C		A. J. Fenlon;T. David;J. P. R. B. Walton	Sch. of Mech. Eng., Leeds Univ., UK|c|;;		Computational fluid dynamics, interactive design, prosthetic heart valves, visualization systems	University of Leeds##University of Leeds
Vis	2000	Immersive virtual reality for visualizing flow through an artery	10.1109/VISUAL.2000.885731	http://dx.doi.org/10.1109/VISUAL.2000.885731	457	460	C		Andrew S. Forsberg;David H. Laidlaw;Andries van Dam;Robert Michael Kirby;George E. Karniadakis;Jonathan L. Elion	Dept. of Comput. Sci., Brown Univ., Providence, RI, USA|c|;;;;;	10.1109/VISUAL.1991.175771		Brown University##Brown University##Brown University##Brown University##Brown University##Brown University
Vis	2000	Mastering interactive virtual bronchioscopy on a low-end PC	10.1109/VISUAL.2000.885732	http://dx.doi.org/10.1109/VISUAL.2000.885732	461	464	C		Rainer Wegenkittl;Anna Vilanova;Balint Hegedüs;Daniel Wagner;Martin C. Freund;Eduard Gröller	Tiani Medgraph GesmbH, Vienna, Austria|c|;;;;;	10.1109/VISUAL.1999.809912;10.1109/VISUAL.1998.745337;10.1109/VISUAL.1999.809911	medical visualization, virtual endoscopy, visualization system	Tiani Medgraph GesmbH##Tiani Medgraph GesmbH##Tiani Medgraph GesmbH##Tiani Medgraph GesmbH##Tiani Medgraph GesmbH##Tiani Medgraph GesmbH
Vis	2000	Interactive visualization of protein dynamics	10.1109/VISUAL.2000.885733	http://dx.doi.org/10.1109/VISUAL.2000.885733	465	468	C		Henk Huitema;Robert van Liere	Center for Math. & Comput. Sci., Amsterdam, Netherlands|c|;		molecular graphics, essential dynamics,animation, interactive exploration	Center for Math. & Comput. Sci., Amsterdam, Netherlands|c|;
Vis	2000	Interactive visualization of particle-in-cell simulations	10.1109/VISUAL.2000.885734	http://dx.doi.org/10.1109/VISUAL.2000.885734	469	472	C		Patric Ljung;Mark Dieckmann;Niclas Andersson;Anders Ynnerman	Dept. of Sci. & Technol., Linkopings Univ., Sweden|c|;;;		scientific visualization, interaction animation, volume rendering, texture maps, data streaming, plasma physics	Dept. of Sci. & Technol., Linkopings Univ., Sweden|c|;;;
Vis	2000	Visualization of time dependent confocal microscopy data	10.1109/VISUAL.2000.885735	http://dx.doi.org/10.1109/VISUAL.2000.885735	473	476	C		Wim C. de Leeuw;Robert van Liere;Pernette J. Verschure;Roel van Driel;Astrid E. Visser;Erik M. M. Manders	Centre for Math. & Comput. Sci., Amsterdam, Netherlands|c|;;;;;	10.1109/VISUAL.1990.146378;10.1109/VISUAL.1996.568136	biomedical imaging, volume visualization,virtual reality	BioCentrum Amsterdam##BioCentrum Amsterdam##BioCentrum Amsterdam##BioCentrum Amsterdam##CWI
Vis	2000	Visual data fusion for applications of high-resolution numerical weather prediction	10.1109/VISUAL.2000.885736	http://dx.doi.org/10.1109/VISUAL.2000.885736	477	480	C		Lloyd Treinish	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|	10.1109/VISUAL.1995.480821;10.1109/VISUAL.1998.745331	visualization, data fusion, user tasks, graphics design, meteorology, weather forecasting, demographics, energy demand prediction	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|
Vis	2000	Case study: a methodology for plume visualization with application to real-time acquisition and navigation	10.1109/VISUAL.2000.885737	http://dx.doi.org/10.1109/VISUAL.2000.885737	481	484	C		Karen G. Bemis;Deborah Silver;Peter A. Rona;Chengwei Feng	Inst. of Marine & Coastal Sci., Rutgers Univ., New Brunswick, NJ, USA|c|;;;	10.1109/VISUAL.1998.745347;10.1109/VISUAL.1995.480789;10.1109/VISUAL.1994.346297;10.1109/VISUAL.1993.398901;10.1109/VISUAL.1996.567807	oceanographic visualization, plume, acoustic imaging, centerlines	Rutgers University##Rutgers University##Rutgers University##Rutgers University
Vis	2000	Vector fields simplification-a case study of visualizing climate modeling and simulation data sets	10.1109/VISUAL.2000.885738	http://dx.doi.org/10.1109/VISUAL.2000.885738	485	488	C		Pak Chung Wong;Harlan Foote;L. Ruby Leung;Elizabeth Jurrus;Dan Adams;James J. Thomas	Pacific Northwest Lab., Richland, WA, USA|c|;;;;;	10.1109/VISUAL.1999.809907;10.1109/VISUAL.1999.809865	vector field visualization, time-varying fields, meteorology	Pacific Northwest Lab., Richland, WA, USA|c|;;;;;
Vis	2000	WEAVE: a system for visually linking 3-D and statistical visualizations applied to cardiac simulation and measurement data	10.1109/VISUAL.2000.885739	http://dx.doi.org/10.1109/VISUAL.2000.885739	489	492	C		Donna L. Gresh;Bernice E. Rogowitz;Raimond L. Winslow;David F. Scollan;Christina K. Yung	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;;;	10.1109/VISUAL.1992.235219;10.1109/VISUAL.1999.809894;10.1109/INFVIS.1995.528688;10.1109/VISUAL.1991.175794;10.1109/INFVIS.1996.559210	visualization, medical, heart, data synthesis	IBM T.J. Watson Research Center##IBM T.J. Watson Research Center##IBM T.J. Watson Research Center##IBM T.J. Watson Research Center##IBM T.J. Watson Research Center
Vis	2000	Visualizing high-dimensional predictive model quality	10.1109/VISUAL.2000.885740	http://dx.doi.org/10.1109/VISUAL.2000.885740	493	496	C		Penny Rheingans;Marie desJardins	Dept. of Comput. Sci. & Electr. Eng., Maryland Univ., Baltimore, MD, USA|c|;	10.1109/VISUAL.1997.663922;10.1109/INFVIS.1998.729565;10.1109/VISUAL.1990.146402;10.1109/VISUAL.1997.663868		University of Maryland##SRI International
Vis	2000	Visualizing volume data using physical models	10.1109/VISUAL.2000.885741	http://dx.doi.org/10.1109/VISUAL.2000.885741	497	500	C		David R. Nadeau;Michael J. Bailey	Supercomput. Center, California Univ., San Diego, La Jolla, CA, USA|c|;		scene graphs, volume graphics, volume visualization, physical models	University of California##University of California
Vis	2000	Visualizing DIII-D Tokamak magnetic field lines	10.1109/VISUAL.2000.885742	http://dx.doi.org/10.1109/VISUAL.2000.885742	501	504	C		Gregory L. Schussman;Kwan-Liu Ma;David P. Schissel;Todd Evans	Dept. of Comput. Sci., California Univ., Davis, CA, USA|c|;;;	10.1109/VISUAL.1996.567777	graphics hardware, haloed lines, illuminated lines, interactive visualization, magnetic field, plasma physics, tokamak	University of California##University of California##University of California##University of California##University of California
Vis	2000	Real-time visualization of the clear-up of a former US naval base	10.1109/VISUAL.2000.885743	http://dx.doi.org/10.1109/VISUAL.2000.885743	505	508	C		Paul Chapman;Derek Wills;Peter Stevens;Graham R. Brookes	Sonar Res. & Dev. Ltd., Beverley, UK|c|;;;	10.1109/VISUAL.1999.809926;10.1109/VISUAL.1998.745348	whole field modelling, seabed visualization, sonar technology	Sonar Research & Development Ltd +##Sonar Research & Development Ltd +##Sonar Research & Development Ltd +##Sonar Research & Development Ltd +##Sonar Research & Development Ltd +
Vis	2000	Scientific visualization of water quality in the Chesapeake bay	10.1109/VISUAL.2000.885744	http://doi.ieeecomputersociety.org/10.1109/VISUAL.2000.885744	509	512	C		Robert Stein;Alan M. Shih;M. Pauline Baker;Carl F. Cerco;Mark R. Noel	National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign	10.1109/VISUAL.1996.567752		University of Illinois at Urbana-Champaign##University of Illinois at Urbana-Champaign##University of Illinois at Urbana-Champaign##University of Illinois at Urbana-Champaign##University of Illinois at Urbana-Champaign
Vis	2000	Multi-resolution visualization techniques for nested weather models	10.1109/VISUAL.2000.885745	http://dx.doi.org/10.1109/VISUAL.2000.885745	513	516	C		Lloyd Treinish	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|	10.1109/VISUAL.1999.809918;10.1109/VISUAL.1990.146359;10.1109/VISUAL.1995.480821;10.1109/VISUAL.1999.809897	flow visualization, multi-resolution,visualization design, meteorology, weather forecasting	IBM Thomas J. Watson Research Center Yorktown Heights
InfoVis	2001	To draw a tree	10.1109/INFVIS.2001.963272	http://dx.doi.org/10.1109/INFVIS.2001.963272	3	3	M		Pat Hanrahan	Stanford University|c|			Stanford University|c|
InfoVis	2001	Visualizing time-series on spirals	10.1109/INFVIS.2001.963273	http://dx.doi.org/10.1109/INFVIS.2001.963273	7	13	C		Marc Weber;Marc Alexa;Wolfgang Müller 0004	Technische Universitat Darmstadt|c|;;	10.1109/VISUAL.1991.175794;10.1109/INFVIS.2000.885098;10.1109/INFVIS.1995.528685	Information Visualization, Graph Drawing, Visualization of Time-Series Data, Data Mining 	crcp Technische UniversitÃ¤t Darmstadt##crcp Technische UniversitÃ¤t Darmstadt##crcp Technische UniversitÃ¤t Darmstadt
InfoVis	2001	Change blindness in information visualization: a case study	10.1109/INFVIS.2001.963274	http://dx.doi.org/10.1109/INFVIS.2001.963274	15	22	C		Lucy T. Nowell;Elizabeth G. Hetzler;Ted Tanasse	Pacific Northwest National Laboratory|c|;;	10.1109/INFVIS.1997.636789;10.1109/INFVIS.2000.885099;10.1109/INFVIS.1995.528692;10.1109/INFVIS.1995.528686;10.1109/INFVIS.1995.528691		Pacific Northwest National Laboratory|c|;;
InfoVis	2001	Cluster stability and the use of noise in interpretation of clustering	10.1109/INFVIS.2001.963275	http://dx.doi.org/10.1109/INFVIS.2001.963275	23	30	C		George S. Davidson;Brian N. Wylie;Kevin W. Boyack	Sandia National Laboratories|c|;;	10.1109/INFVIS.1995.528686		Sandia National Laboratories|c|;;
InfoVis	2001	Technical note: visually encoding program test information to find faults in software	10.1109/INFVIS.2001.963277	http://dx.doi.org/10.1109/INFVIS.2001.963277	33	36	C		James R. Eagan;Mary Jean Harrold;James A. Jones;John T. Stasko	Georgia Institute of Technology Atlanta|c|;;;			Georgia Institute of Technology Atlanta##Georgia Institute of Technology Atlanta##Georgia Institute of Technology Atlanta##Georgia Institute of Technology Atlanta
InfoVis	2001	Getting along: composition of visualization paradigms	10.1109/INFVIS.2001.963278	http://dx.doi.org/10.1109/INFVIS.2001.963278	37	40	C		Alan Keahey	Visual Insights, Inc.|c|	10.1109/INFVIS.1997.636786;10.1109/VISUAL.1992.235217;10.1109/VISUAL.1991.175815;10.1109/INFVIS.1997.636718;10.1109/INFVIS.1997.636784;10.1109/INFVIS.1996.559214;10.1109/INFVIS.1998.729558		Visual Insights, Inc.|c|
InfoVis	2001	Animated exploration of dynamic graphs with radial layout	10.1109/INFVIS.2001.963279	http://dx.doi.org/10.1109/INFVIS.2001.963279	43	50	C		Ka-Ping Yee;Danyel Fisher;Rachna Dhamija;Marti A. Hearst	University of California|c|;;;	10.1109/INFVIS.1997.636718	graph drawing, animation, interaction	University of California##University of California##University of California
InfoVis	2001	Effective graph visualization via node grouping	10.1109/INFVIS.2001.963280	http://dx.doi.org/10.1109/INFVIS.2001.963280	51	58	C		Janet M. Six;Ioannis G. Tollis	The University of Texas|c|;		Graph Drawing, Graph Visualization, Force-Directed Drawing, Orthogonal Drawing, Node Grouping, Experimental Studies	The University of Texas|c|;
InfoVis	2001	Visualization of state transition graphs	10.1109/INFVIS.2001.963281	http://dx.doi.org/10.1109/INFVIS.2001.963281	59	66	C		Frank van Ham;Huub van de Wetering;Jarke J. van Wijk	Eindhoven University of Technology|c|;;	10.1109/INFVIS.1995.528691;10.1109/INFVIS.1995.528689		Eindhoven University of Technology##Eindhoven University of Technology##Eindhoven University of Technology
InfoVis	2001	Graph sketches	10.1109/INFVIS.2001.963282	http://dx.doi.org/10.1109/INFVIS.2001.963282	67	70	C		James Abello;Irene Finocchi;Jeffrey L. Korn	AT&T Labs-Research|c|;;	10.1109/INFVIS.2000.885089	visualization, massive data sets, graphs, hierarchies	University of Rome "##University of Rome "##University of Rome "
InfoVis	2001	Ordered treemap layouts	10.1109/INFVIS.2001.963283	http://dx.doi.org/10.1109/INFVIS.2001.963283	73	78	C		Ben Shneiderman;Martin Wattenberg	University of Maryland|c|;	10.1109/VISUAL.1992.235217;10.1109/VISUAL.1991.175815	treemaps, ordered treemaps, trees, hierarchies, information visualization 	University of Maryland##University of Maryland##University of Maryland##University of Maryland##University of Maryland
InfoVis	2001	Collapsible cylindrical trees: a fast hierarchical navigation technique	10.1109/INFVIS.2001.963284	http://dx.doi.org/10.1109/INFVIS.2001.963284	79	86	C		Raimund Dachselt;Jürgen Ebert	Dresden University of Technology|c|;	10.1109/INFVIS.1997.636718;10.1109/INFVIS.1995.528692;10.1109/VISUAL.1991.175815	visualization, web navigation, hierarchy, interactive tree, sitemap, 3D graphics, VRML, XML	Dresden University of Technology##Dresden University of Technology
InfoVis	2001	Botanical visualization of huge hierarchies	10.1109/INFVIS.2001.963285	http://dx.doi.org/10.1109/INFVIS.2001.963285	87	94	C		Ernst Kleiberg;Huub van de Wetering;Jarke J. van Wijk	Eindhoven University of Technology|c|;;	10.1109/INFVIS.1995.528689;10.1109/INFVIS.1999.801860	botanical tree, logical tree, huge hierarchy, strands, tree visualization, directory tree, phyllotaxis	Eindhoven University of Technology##Eindhoven University of Technology##Eindhoven University of Technology
InfoVis	2001	Semantic depth of field	10.1109/INFVIS.2001.963286	http://dx.doi.org/10.1109/INFVIS.2001.963286	97	104	C		Robert Kosara;Silvia Miksch;Helwig Hauser	Vienna University of Technology|c|;;	10.1109/VISUAL.2000.885698;10.1109/INFVIS.2000.885088	Depth of Field, Focus and Context, Information Visualization	Vienna University of Technology##Vienna University of Technology
InfoVis	2001	Interactive visualization of multiple query results	10.1109/INFVIS.2001.963287	http://dx.doi.org/10.1109/INFVIS.2001.963287	105	112	C		Susan L. Havre;Elizabeth G. Hetzler;Kenneth A. Perrine;Elizabeth Jurrus;Nancy Miller	Battelle Pacific Northwest Division|c|;;;;	10.1109/INFVIS.1998.729570;10.1109/VISUAL.1998.745302;10.1109/VISUAL.1993.398863		Battelle Pacific Northwest Division##Battelle Memorial Institute
InfoVis	2001	Pixel bar charts: a new technique for visualizing large multi-attribute data sets without aggregation	10.1109/INFVIS.2001.963288	http://dx.doi.org/10.1109/INFVIS.2001.963288	113	120	C		Daniel A. Keim;Ming C. Hao;Julian Ladisch;Meichun Hsu;Umeshwar Dayal	Hewlett Packard Research Laboratories|c|;;;;	10.1109/VISUAL.1995.485140;10.1109/VISUAL.1993.398870;10.1109/INFVIS.1999.801867;10.1109/VISUAL.1991.175794;10.1109/VISUAL.1990.146387;10.1109/VISUAL.1990.146402;10.1109/INFVIS.1995.528690;10.1109/VISUAL.1990.146386		University of Constance##University of Constance##University of Constance##University of Constance##University of Constance
InfoVis	2001	An empirical comparison of three commercial information visualization systems	10.1109/INFVIS.2001.963289	http://dx.doi.org/10.1109/INFVIS.2001.963289	123	130	C		Alfred Kobsa	University of California|c|	10.1109/INFVIS.1995.528688		University of California
InfoVis	2001	A comparison of 2-D visualizations of hierarchies	10.1109/INFVIS.2001.963290	http://dx.doi.org/10.1109/INFVIS.2001.963290	131	138	C		S. Todd Barlow;Padraic Neville	SAS Institute Inc.|c|;	10.1109/INFVIS.1998.729557;10.1109/VISUAL.1992.235217		SAS Institute Inc##SAS Institute Inc
InfoVis	2001	2D vs 3D, implications on spatial memory	10.1109/INFVIS.2001.963291	http://dx.doi.org/10.1109/INFVIS.2001.963291	139	145	C		Monica Tavanti;Mats Lind	University Sweden|c|;			Uppsala University##Uppsala University
InfoVis	2001	Case study: visualization for decision tree analysis in data mining	10.1109/INFVIS.2001.963292	http://dx.doi.org/10.1109/INFVIS.2001.963292	149	152	C		S. Todd Barlow;Padraic Neville	SAS Institute Inc.|c|;			SAS Institute Inc##SAS Institute Inc
InfoVis	2001	Case study: e-commerce clickstream visualization	10.1109/INFVIS.2001.963293	http://dx.doi.org/10.1109/INFVIS.2001.963293	153	156	C		Jeffrey Brainerd;Barry G. Becker	Blue Martini Software|c|;	10.1109/INFVIS.1998.729554;10.1109/INFVIS.1997.636718;10.1109/INFVIS.1998.729553;10.1109/INFVIS.2000.885089;10.1109/INFVIS.2000.885090;10.1109/INFVIS.1995.528697;10.1109/INFVIS.1996.559226;10.1109/INFVIS.2000.885101		Blue Martini Software|c|;
InfoVis	2001	Case study: design and assessment of an enhanced geographic information system for exploration of multivariate health statistics	10.1109/INFVIS.2001.963294	http://dx.doi.org/10.1109/INFVIS.2001.963294	159	162	C		Robert M. Edsall;Alan M. MacEachren;Linda Pickle	Arizona State University|c|;;	10.1109/INFVIS.1998.729563		Arizona State University##Arizona State University##Arizona State University
InfoVis	2001	Graphic data display for cardiovascular system	10.1109/INFVIS.2001.963295	http://dx.doi.org/10.1109/INFVIS.2001.963295	163	166	C		James Agutter;Noah Syroid;Frank Drews;Dwayne R. Westenskow;Julio C. Bermudez;David L. Strayer	University of Utah|c|;;;;;			University of Utah##University of Utah##University of Utah####University of Utah##University of Utah
InfoVis	2001	Battlespace visualization: a grand challenge	10.1109/INFVIS.2001.963296	http://dx.doi.org/10.1109/INFVIS.2001.963296	169	170	M		Jeffrey L. Posdamer	Sarnoff Corporation|c|;;;;;			Sarnoff Corporation|c|;;;;;
Vis	2001	Point set surfaces	10.1109/VISUAL.2001.964489	http://dx.doi.org/10.1109/VISUAL.2001.964489	21	28	C		Marc Alexa;Johannes Behr;Daniel Cohen-Or;Shachar Fleishman;David Levin;Cláudio T. Silva	Technische Hochschule Darmstadt, Germany|c|;;;;;	10.1109/VISUAL.1997.663930;10.1109/VISUAL.1998.745327	surface representation and reconstruction, moving least squares, point sample rendering, 3D acquisition	Tel Aviv University##Tel Aviv University##Tel Aviv University##Tel Aviv University##Tel Aviv University##Tel Aviv University##Tel Aviv University##Tel Aviv University
Vis	2001	EWA volume splatting	10.1109/VISUAL.2001.964490	http://dx.doi.org/10.1109/VISUAL.2001.964490	29	36	C		Matthias Zwicker;Hanspeter Pfister;Jeroen van Baar;Markus H. Gross	Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;;;	10.1109/VISUAL.1995.480796;10.1109/VISUAL.1997.663882;10.1109/VISUAL.1998.745309;10.1109/VISUAL.1996.567608;10.1109/VISUAL.1999.809909	Volume Rendering, Splatting, Antialiasing	Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;;;
Vis	2001	Hybrid simplification: combining multi-resolution polygon and point rendering	10.1109/VISUAL.2001.964491	http://dx.doi.org/10.1109/VISUAL.2001.964491	37	44	C		Jonathan D. Cohen;Daniel G. Aliaga;Weiqiand Zhang	Johns Hopkins Univ., Baltimore, MD, USA|c|;;	10.1109/VISUAL.1997.663909;10.1109/VISUAL.1996.568124;10.1109/VISUAL.1998.745314;10.1109/VISUAL.1998.745283;10.1109/VISUAL.1997.663883;10.1109/VISUAL.1998.745312;10.1109/VISUAL.2001.964492;10.1109/VISUAL.1997.663908;10.1109/VISUAL.1997.663865	rendering, simplification, multi-resolution, trianlge, points, hybrid	Johns Hopkins Univ., Baltimore, MD, USA|c|;;
Vis	2001	POP: A Hybrid Point and Polygon Rendering System for Large Data	10.1109/VISUAL.2001.964492	http://doi.ieeecomputersociety.org/10.1109/VISUAL.2001.964492	45	52	C		Baoquan Chen;Minh Xuan Nguye		10.1109/VISUAL.1998.745282	Rendering system, Spatial data structures, Level of detail algorithms, hybrid rendering systems	University of Minnesota at Twin Cities##University of Minnesota at Twin Cities
Vis	2001	Lagrangian-Eulerian Advection for Unsteady Flow Visualization	10.1109/VISUAL.2001.964493	http://doi.ieeecomputersociety.org/10.1109/VISUAL.2001.964492	53	60	C		Bruno Jobard;Gordon Erlebacher;M. Yousuff Hussaini		10.1109/VISUAL.2000.885689;10.1109/VISUAL.1994.346311;10.1109/VISUAL.1995.485146;10.1109/VISUAL.2000.885689		Florida State University##Florida State University##Florida State University
Vis	2001	Transport and anisotropic diffusion in time-dependent flow visualization	10.1109/VISUAL.2001.964494	http://dx.doi.org/10.1109/VISUAL.2001.964494	61	68	C		David Bürkle;Tobias Preußer;Martin Rumpf	Inst. fur Angewandte Math., Freiburg Univ., Germany|c|;;	10.1109/VISUAL.1995.480817;10.1109/VISUAL.1994.346312;10.1109/VISUAL.1999.809894;10.1109/VISUAL.1997.663898;10.1109/VISUAL.1999.809904;10.1109/VISUAL.1997.663912	flow visualization, multiscale image processing, non-linear diffusion, transport diffusion, upwind method	Inst. fur Angewandte Math., Freiburg Univ., Germany|c|;;
Vis	2001	Enridged Contour Maps	10.1109/VISUAL.2001.964495	http://doi.ieeecomputersociety.org/10.1109/VISUAL.2001.964495	69	74	C		Jarke J. van Wijk;Alexandru Telea		10.1109/INFVIS.1995.528686;10.1109/INFVIS.1999.801860;10.1109/VISUAL.1993.398875	Contours, mapping, height fields, multivariate visualization, flow visualization	Eindhoven University of Technology##Eindhoven University of Technology
Vis	2001	Visualization of Sports using Motion Trajectories: Providing Insights into Performance, Style, and Strategy	10.1109/VISUAL.2001.964496	http://doi.ieeecomputersociety.org/10.1109/VISUAL.2001.964496	75	82	C		Gopal Sarma Pingali;Agata Opalach;Yves Jean;Ingrid Carlbom		10.1109/VISUAL.1997.663893	sports visualization, virtual environment, telepresence, real-time video analysis, multi-camera tracking, multimedia indexing	Ingrid Carlbom Â¾##Murray Hill
Vis	2001	Undersampling and oversampling in sample based shape modeling	10.1109/VISUAL.2001.964497	http://dx.doi.org/10.1109/VISUAL.2001.964497	83	90	C		Tamal K. Dey;Joachim Giesen;Samrat Goswami;James Hudson;Rephael Wenger;Wulue Zhao	Ohio State Univ., Columbus, OH, USA|c|;;;;;	10.1109/VISUAL.1997.663909;10.1109/VISUAL.2000.885718	Computational Geometry, Surface Reconstruction, Geometric Modeling, Mesh Generation, Polygonal Mesh Reduction, Polygonal Modeling, Shape Recognition	Ohio State University Columbus##Ohio State University Columbus##Ohio State University Columbus##Ohio State University Columbus##Ohio State University Columbus##Ohio State University Columbus
Vis	2001	Optimal regular volume sampling	10.1109/VISUAL.2001.964498	http://dx.doi.org/10.1109/VISUAL.2001.964498	91	98	C		Thomas Theußl;Torsten Möller;Eduard Gröller	Inst. of Comput. Graphics & Algorithms, Technische Univ. Wien, Vienna, Austria|c|;;	10.1109/VISUAL.1994.346331	volume data,Cartesiangrid,close packing,hexagonal sampling, body centered cubic	Simon Fraser University##Simon Fraser University##Simon Fraser University##Simon Fraser University
Vis	2001	Simplicial subdivisions and sampling artifacts	10.1109/VISUAL.2001.964499	http://dx.doi.org/10.1109/VISUAL.2001.964499	99	106	C		Hamish Carr;Torsten Möller;Jack Snoeyink	Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC, Canada|c|;;	10.1109/VISUAL.1997.663887;10.1109/VISUAL.1996.568103;10.1109/VISUAL.1991.175782;10.1109/VISUAL.1997.663869;10.1109/VISUAL.1997.663885;10.1109/VISUAL.1997.663886		Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC, Canada|c|;;
Vis	2001	A simple algorithm for surface denoising	10.1109/VISUAL.2001.964500	http://dx.doi.org/10.1109/VISUAL.2001.964500	107	112	C		Jianbo Peng;Vasily Strela;Denis Zorin	New York Univ., NY, USA|c|;;	10.1109/VISUAL.2000.885721	Meshes, multiresolution surfaces, Gaussian scale mixture model, denoising	New York University##New York University##New York University
Vis	2001	Attribute preserving dataset simplification	10.1109/VISUAL.2001.964501	http://dx.doi.org/10.1109/VISUAL.2001.964501	113	120	C		Jason D. Walter;Christopher G. Healey	Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA|c|;	10.1109/VISUAL.1998.745296;10.1109/VISUAL.1998.745312;10.1109/VISUAL.1999.809869	dataset management, mesh simplification, principal component analysis, scientific visualization	North Carolina State University##North Carolina State University
Vis	2001	A memory insensitive technique for large model simplification	10.1109/VISUAL.2001.964502	http://dx.doi.org/10.1109/VISUAL.2001.964502	121	126	C		Peter Lindstrom;Cláudio T. Silva	Center for Appl. Sci. Comput., Lawrence Livermore Nat. Lab., Berkeley, CA, USA|c|;	10.1109/VISUAL.2001.964503;10.1109/VISUAL.1999.809910;10.1109/VISUAL.1995.480813;10.1109/VISUAL.1997.663895;10.1109/VISUAL.1998.745299;10.1109/VISUAL.1997.663888;10.1109/VISUAL.1998.745314;10.1109/VISUAL.1998.745282	polygonal surface simplification, large data, out-of-core algorithms, external sorting, quadric error metrics	LLNL##LLNL##LLNL
Vis	2001	Efficient Adaptive Simplification of Massive Meshes	10.1109/VISUAL.2001.964503	http://doi.ieeecomputersociety.org/10.1109/VISUAL.2001.964503	127	134	C		Eric Shaffer;Michael Garland		10.1109/VISUAL.2001.964502;10.1109/VISUAL.1998.745282;10.1109/VISUAL.1998.745314	surface simplification, massive meshes, quadric error metric, recursive partitioning, out-of-core simplification	University of Illinois at Urbanaâ€“Champaign##University of Illinois at Urbanaâ€“Champaign
Vis	2001	Connectivity shapes	10.1109/VISUAL.2001.964504	http://dx.doi.org/10.1109/VISUAL.2001.964504	135	142	C		Martin Isenburg;Stefan Gumhold;Craig Gotsman	North Carolina Univ., Chapel Hill, NC, USA|c|;;		Natural embedding, mesh connectivity, implicit geometry, polygon meshes, shape compression	University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill
Vis	2001	Quantitative comparative evaluation of 2D vector field visualization methods	10.1109/VISUAL.2001.964505	http://dx.doi.org/10.1109/VISUAL.2001.964505	143	150	C		David H. Laidlaw;Robert Michael Kirby;J. Scott Davidson;Timothy S. Miller;Marco da Silva;William H. Warren;Michael J. Tarr	Dept. of Comput. Sci., Brown Univ., Providence, RI, USA|c|;;;;;;	10.1109/VISUAL.1991.175773;10.1109/VISUAL.1999.809905	Scientific Visualization, User Study, Line-integral Convolution, Two-dimensional Vector Fields, Streamlines, Iconic Textures, Image-guided Streamlines, Jittered Grid Icons, Critical Point, Advection, Fluid Dynamics, Fluid Flow	Brown University##Brown University##Brown University##Brown University##Brown University##Brown University##Brown University
Vis	2001	A tetrahedra-based stream surface algorithm	10.1109/VISUAL.2001.964506	http://dx.doi.org/10.1109/VISUAL.2001.964506	151	158	C		Gerik Scheuermann;Tom Bobach;Hans Hagen;Karim Mahrous;Bernd Hamann;Kenneth I. Joy;Wolfgang Kollmann	Dept. of Comput. Sci., Kaiserslautern Univ., Germany|c|;;;;;;	10.1109/VISUAL.1993.398875;10.1109/VISUAL.1992.235211;10.1109/VISUAL.1995.485145;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1997.663910	vector field visualization, flow visualization, tetrahedral grid, unstructured grid, flow surface	Dept. of Comput. Sci., Kaiserslautern Univ., Germany|c|;;;;;;
Vis	2001	Continuous topology simplification of planar vector fields	10.1109/VISUAL.2001.964507	http://dx.doi.org/10.1109/VISUAL.2001.964507	159	166	C		Xavier Tricoche;Gerik Scheuermann;Hans Hagen	Dept. of Comput. Sci., Kaiserslautern Univ., Germany|c|;;	10.1109/VISUAL.2000.885716;10.1109/VISUAL.1998.745318;10.1109/VISUAL.1991.175773;10.1109/VISUAL.1999.809907	vector field topology, flow visualization, unstructured grid, simplification	Dept. of Comput. Sci., Kaiserslautern Univ., Germany|c|;;
Vis	2001	PixelFlex: a reconfigurable multi-projector display system	10.1109/VISUAL.2001.964508	http://dx.doi.org/10.1109/VISUAL.2001.964508	167	554	C		Ruigang Yang;David Gotz;Justin Hensley;Herman Towles;Michael S. Brown	Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;;	10.1109/VISUAL.2000.885685;10.1109/VISUAL.1999.809890;10.1109/VISUAL.1999.809883;10.1109/VISUAL.2000.885712	large-format projection display, camera-based registration and calibration	University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill
Vis	2001	Dynamic Shadow Removal from Front Projection Displays	10.1109/VISUAL.2001.964509	http://doi.ieeecomputersociety.org/10.1109/VISUAL.2001.964509	175	182	C		Christopher O. Jaynes;Stephen B. Webb;R. Matt Steele;Michael S. Brown;W. Brent Seales		10.1109/VISUAL.1999.809883;10.1109/VISUAL.1999.809890;10.1109/VISUAL.2000.885684;10.1109/VISUAL.2000.885685;10.1109/VISUAL.2000.885712	Large-scale display, shadow removal, immersive media, calibration	University of Kentucky##University of Kentucky##University of Kentucky##University of Kentucky##University of Kentucky
Vis	2001	The "Which Blair project": a quick visual method for evaluating perceptual color maps	10.1109/VISUAL.2001.964510	http://dx.doi.org/10.1109/VISUAL.2001.964510	183	190	C		Bernice E. Rogowitz;Alan D. Kalvin	IBM Thomas J. Watson Res. Center, Hawthorne, NY, USA|c|;	10.1109/VISUAL.1995.480803	Perceptual color scales, visual artifacts in visualization, Internet color, human color vision	IBM T.J. Watson Research Center##IBM T.J. Watson Research Center
Vis	2001	Circular incident edge lists: a data structure for rendering complex unstructured grids	10.1109/VISUAL.2001.964511	http://dx.doi.org/10.1109/VISUAL.2001.964511	191	198	C		Bruno Lévy;Guillaume Caumon;Stephane Conreaux;Xavier Cavin	ISA (INRIA Lorraine), Vandoeuvre-les-Nancy, France|c|;;;	10.1109/VISUAL.1996.567606	Volume Rendering, Iso-Surfaces, Unstructured Grids, Combinatorial Topology	ISA (Inria Lorraine) Loria, rue du Jardin Botanique##ISA (Inria Lorraine) Loria, rue du Jardin Botanique##ISA (Inria Lorraine) Loria, rue du Jardin Botanique##ISA (Inria Lorraine) Loria, rue du Jardin Botanique
Vis	2001	Hardware-software-balanced resampling for the interactive visualization of unstructured grids	10.1109/VISUAL.2001.964512	http://dx.doi.org/10.1109/VISUAL.2001.964512	199	206	C		Manfred Weiler;Thomas Ertl	Visualization & Interactive Syst. Group, Stuttgart Univ., Germany|c|;	10.1109/VISUAL.1996.567606		University of Stuttgart##University of Stuttgart
Vis	2001	The perspective shear-warp algorithm in a virtual environment	10.1109/VISUAL.2001.964513	http://dx.doi.org/10.1109/VISUAL.2001.964513	207	213	C		Jürgen P. Schulze;Roland Niemeier;Ulrich Lang	High Performance Comput. Centre, Stuttgart, Germany|c|;;	10.1109/VISUAL.1996.567603;10.1109/VISUAL.1999.809872	Volume Rendering, Perspective Shear-Warp, Virtual Environments	High Performance Computing Center Stuttgart (HLRS)##High Performance Computing Center Stuttgart (HLRS)##High Performance Computing Center Stuttgart (HLRS)
Vis	2001	Cell-projection of cyclic meshes	10.1109/VISUAL.2001.964514	http://dx.doi.org/10.1109/VISUAL.2001.964514	215	222	C		Martin Kraus;Thomas Ertl	Visualization & Interactive Syst. Group, Stuttgart, Germany|c|;	10.1109/VISUAL.2000.885683	cell-projection, direct volume rendering, tetrahedral meshes, unstructured meshes, visibility cycles, visibility ordering, visibility sorting, volume visualization	UniversitÃ¤t Stuttgart##UniversitÃ¤t Stuttgart
Vis	2001	Fast detection of meaningful isosurfaces for volume data visualization	10.1109/VISUAL.2001.964515	http://dx.doi.org/10.1109/VISUAL.2001.964515	223	230	C		Vladimir Pekar;Rafael Wiemker;Daniel Bystrov	Philips Res. Lab., Hamburg, Germany|c|;;	10.1109/VISUAL.1995.480803;10.1109/VISUAL.1997.663875;10.1109/VISUAL.1996.568113	Volume data visualization, surface rendering, volume rendering, isosurfaces, divergence theorem	Philips Research Laboratories##Philips Research Laboratories##Philips Research Laboratories
Vis	2001	Salient iso-surface detection with model-independent statistical signatures	10.1109/VISUAL.2001.964516	http://dx.doi.org/10.1109/VISUAL.2001.964516	231	238	C		Shivaraj Tenginakai;Jinho Lee;Raghu Machiraju	Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA|c|;;	10.1109/VISUAL.1998.745319;10.1109/VISUAL.1997.663875;10.1109/VISUAL.1996.568113	Iso-values, Transfer Functions, Surface Extraction, Direct Volume Rendering	The Ohio State University##The Ohio State University##The Ohio State University
Vis	2001	Distance-field based skeletons for virtual navigation	10.1109/VISUAL.2001.964517	http://dx.doi.org/10.1109/VISUAL.2001.964517	239	246	C		Ming Wan;Frank Dachille;Arie E. Kaufman	Boeing Co., Seattle, WA, USA|c|;;	10.1109/VISUAL.1997.663915;10.1109/VISUAL.2000.885675	Distance fields, path planning, centerline, camera control, virtual navigation, volumetric environment, physically based modeling, virtual colonoscopy	Boeing Co., Seattle, WA, USA|c|;;
Vis	2001	A complete distance field representation	10.1109/VISUAL.2001.964518	http://dx.doi.org/10.1109/VISUAL.2001.964518	247	254	C		Jian Huang;Roger Crawfis;Shao-Chiung Lu;Shuh-Yuan Liou	Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA|c|;;;;	10.1109/VISUAL.1993.398877;10.1109/VISUAL.1995.485152;10.1109/VISUAL.2000.885698	distance fields, volume modeling, polygonal surfaces, point-based models, graphics	The Ohio State University##The Ohio State University##The Ohio State University##Visteon Inc##Ford Motor Company
Vis	2001	Interactive volume rendering using multi-dimensional transfer functions and direct manipulation widgets	10.1109/VISUAL.2001.964519	http://dx.doi.org/10.1109/VISUAL.2001.964519	255	262	C		Joe Michael Kniss;Gordon L. Kindlmann;Charles D. Hansen	Sch. of Comput., Utah Univ., Salt Lake City, UT, USA|c|;;	10.1109/VISUAL.1995.480803;10.1109/VISUAL.1999.809908;10.1109/VISUAL.1999.809889;10.1109/VISUAL.1996.568113;10.1109/VISUAL.1997.663875	volume visualization, direct volume rendering, multi-dimensional transfer functions, direct manipulation widgets, graphics hardware	University of Utah##University of Utah##University of Utah
Vis	2001	Texture Hardware Assisted Rendering of Time-Varying Volume Data	10.1109/VISUAL.2001.964520	http://doi.ieeecomputersociety.org/10.1109/VISUAL.2001.964520	263	270	C		Eric B. Lum;Kwan-Liu Ma;John Clyne		10.1109/VISUAL.1999.809910;10.1109/VISUAL.1994.346321;10.1109/VISUAL.1995.480809;10.1109/VISUAL.1994.346341;10.1109/VISUAL.1999.809879	Compression, high performance computing, out-of-core processing, PC, scientific visualization, texture hardware, time-varying data, transform encoding, volume rendering	University of California##University of California##University of California
Vis	2001	Accelerated volume ray-casting using texture mapping	10.1109/VISUAL.2001.964521	http://dx.doi.org/10.1109/VISUAL.2001.964521	271	278	C		Rüdiger Westermann;Bernd Sevenich	Sci. Visualization & Imaging Group, Univ. of Technol., Aachen, Germany|c|;	10.1109/VISUAL.1997.663880;10.1109/VISUAL.1998.745713;10.1109/VISUAL.1997.663888;10.1109/VISUAL.1990.146391;10.1109/VISUAL.1993.398852;10.1109/VISUAL.1999.809911	Volume Rendering, Ray-Casting, Texture Mapping, Visualization, Graphics Hardware	University of Technology Aachen##University of Technology Aachen
Vis	2001	RTVR-a flexible Java library for interactive volume rendering	10.1109/VISUAL.2001.964522	http://dx.doi.org/10.1109/VISUAL.2001.964522	279	286	C		Lukas Mroz;Helwig Hauser	VRVis Research Center, Vienna, Austria|c|;	10.1109/VISUAL.2000.885726;10.1109/VISUAL.1998.745311;10.1109/VISUAL.2000.885694;10.1109/VISUAL.2000.885729;10.1109/VISUAL.1994.346340;10.1109/VISUAL.1999.809878;10.1109/VISUAL.2000.885697	interactive volume visualization,Internet-based visualization, Java	VRVis Research Center##VRVis Research Center
Vis	2001	Multiresolution feature extraction for unstructured meshes	10.1109/VISUAL.2001.964523	http://dx.doi.org/10.1109/VISUAL.2001.964523	287	294	C		Andreas Hubeli;Markus H. Gross	Dept. of Comput. Sci., Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;	10.1109/VISUAL.2000.885721;10.1109/VISUAL.2000.885722	Surface Representations, Geometric Modeling, Triangle Decimation, Multiresolution Models, Feature Extraction	ETH Zurich##ETH Zurich
Vis	2001	Fast extraction of adaptive multiresolution meshes with guaranteed properties from volumetric data	10.1109/VISUAL.2001.964524	http://dx.doi.org/10.1109/VISUAL.2001.964524	295	302	C		Marcel Gavriliu;Joel Carranza;David E. Breen;Alan H. Barr	Comput. Sci. Dept., California Inst. of Technol., USA|c|;;;	10.1109/VISUAL.2000.885705		Comput. Sci. Dept., California Inst. of Technol., USA|c|;;;
Vis	2001	Wavelet representation of contour sets	10.1109/VISUAL.2001.964525	http://dx.doi.org/10.1109/VISUAL.2001.964525	303	310	C		Martin Hering-Bertram;Daniel E. Laney;Mark A. Duchaineau;Charles D. Hansen;Bernd Hamann;Kenneth I. Joy	SCI Inst., Utah Univ., Salt Lake City, UT, USA|c|;;;;;	10.1109/VISUAL.1994.346332;10.1109/VISUAL.2000.885720;10.1109/VISUAL.2000.885716;10.1109/VISUAL.2000.885705	Contours, Geometry Compression, Iso-surfaces, Level Sets, Multiresolution Methods, Wavelets	SCI Inst., Utah Univ., Salt Lake City, UT, USA|c|;;;;;
Vis	2001	User-centric viewpoint computation for haptic exploration and manipulation	10.1109/VISUAL.2001.964526	http://dx.doi.org/10.1109/VISUAL.2001.964526	311	318	C		Miguel A. Otaduy;Ming C. Lin	Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;	10.1109/VISUAL.2000.885686;10.1109/VISUAL.1996.568108		University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill
Vis	2001	Fitting Subdivision Surfaces	10.1109/VISUAL.2001.964527	http://doi.ieeecomputersociety.org/10.1109/VISUAL.2001.964527	319	324	C		Nathan Litke;Adi Levin;Peter Schröder			Animation, CAD, Curves & Surfaces, Geometric Modeling, Digital Geometry Processing, Subdivision Schemes, Approximation, Quasi-Interpolation, Catmull-Clark	Tel Aviv University##Tel Aviv University##Tel Aviv University
Vis	2001	Nonmanifold subdivision	10.1109/VISUAL.2001.964528	http://dx.doi.org/10.1109/VISUAL.2001.964528	325	332	C		Lexing Ying;Denis Zorin	New York Univ., NY, USA|c|;	10.1109/VISUAL.1999.809870	Subdivision surfaces, Nonmanifold surfaces, Geometric modeling	New York University *##New York University *
Vis	2001	Normal bounds for subdivision-surface interference detection	10.1109/VISUAL.2001.964529	http://dx.doi.org/10.1109/VISUAL.2001.964529	333	340	C		Eitan Grinspun;Peter Schröder	;		Subdivision Surfaces, Multiresolution Surfaces, Self-interference, Gauss map, Loop's Scheme	
Vis	2001	Smooth approximation and rendering of large scattered data sets	10.1109/VISUAL.2001.964530	http://dx.doi.org/10.1109/VISUAL.2001.964530	341	348	C		Jörg Haber;Frank Zeilfelder;Oleg Davydov;Hans-Peter Seidel	Max-Planck-Inst. fur Inf., Saarbrucken, Germany|c|;;;	10.1109/VISUAL.1997.663860	scattered data approximation, least squares approximation, terrain visualization, data compression	Justus-Liebig-UniversitÃ¤t Giessen##Justus-Liebig-UniversitÃ¤t Giessen##Justus-Liebig-UniversitÃ¤t Giessen##Justus-Liebig-UniversitÃ¤t Giessen
Vis	2001	Real-time decompression and visualization of animated volume data	10.1109/VISUAL.2001.964531	http://dx.doi.org/10.1109/VISUAL.2001.964531	349	356	C		Stefan Guthe;Wolfgang Straßer	WSI/GRIS, Tubingen Univ., Germany|c|;	10.1109/VISUAL.1997.663878	Time critical Visualization, Compression for Visualization, Volume Rendering	WSI/GRIS University of TÃ¼bingen##WSI/GRIS University of TÃ¼bingen
Vis	2001	Compressing large polygonal models	10.1109/VISUAL.2001.964532	http://dx.doi.org/10.1109/VISUAL.2001.964532	357	262	C		Jeffrey Ho;Kuang-chih Lee;David J. Kriegman	Beckman Inst. for Adv. Sci. & Technol., Illinois Univ., Urbana, IL, USA|c|;;	10.1109/VISUAL.1997.663902;10.1109/VISUAL.1998.745327;10.1109/VISUAL.1999.809870	compression algorithms	Beckman Institute##Beckman Institute##Beckman Institute
Vis	2001	Visualization of large terrains made easy	10.1109/VISUAL.2001.964533	http://dx.doi.org/10.1109/VISUAL.2001.964533	363	370	C		Peter Lindstrom;Valerio Pascucci	Center for Appl. Sci. Comput., Lawrence Livermore Nat. Lab., CA, USA|c|;	10.1109/VISUAL.1997.663860;10.1109/VISUAL.1997.663895;10.1109/VISUAL.1998.745280;10.1109/VISUAL.1997.663863;10.1109/VISUAL.1995.480805;10.1109/VISUAL.1997.663862;10.1109/VISUAL.2000.885699;10.1109/VISUAL.1998.745342;10.1109/VISUAL.1996.568125;10.1109/VISUAL.1998.745282		Lawrence Livermore National Laboratory##Lawrence Livermore National Laboratory
Vis	2001	Integrating occlusion culling with view-dependent rendering	10.1109/VISUAL.2001.964534	http://dx.doi.org/10.1109/VISUAL.2001.964534	371	378	C		Jihad El-Sana;Neta Sokolovsky;Cláudio T. Silva	Dept. of Comput. Sci., Ben-Gurion Univ. of the Negev, Beer-Sheva, Israel|c|;;	10.1109/VISUAL.1999.809877;10.1109/VISUAL.1999.809875;10.1109/VISUAL.1997.663860;10.1109/VISUAL.1996.568117;10.1109/VISUAL.2000.885724;10.1109/VISUAL.1998.745283;10.1109/VISUAL.1995.480805		Ben-Gurion University##Ben-Gurion University##Ben-Gurion University##Ben-Gurion University
Vis	2001	Approximate shading for the re-illumination of synthetic images	10.1109/VISUAL.2001.964535	http://dx.doi.org/10.1109/VISUAL.2001.964535	379	386	C		Randy K. Scoggins;Raghu Machiraju;Robert J. Moorhead II	US Army Eng. R&D Center, Vicksburg, MS, USA|c|;;	10.1109/VISUAL.1999.809869;10.1109/VISUAL.2000.885691	rendering, level-of-detail, image metrics, perception	US Army Eng. R&D Center, Vicksburg, MS, USA|c|;;
Vis	2001	Volume Rendering of Fine Details Within Medical Data	10.1109/VISUAL.2001.964537	http://doi.ieeecomputersociety.org/10.1109/VISUAL.2001.964537	387	394	C		Feng Dong;Gordon Clapworthy;Meleagros A. Krokos		10.1109/VISUAL.1997.663882;10.1109/VISUAL.1994.346340;10.1109/VISUAL.1999.809911;10.1109/VISUAL.1998.745309;10.1109/VISUAL.1999.809909;10.1109/VISUAL.1998.745311;10.1109/VISUAL.1997.663848	Volume Rendering, Fine Details, Medical Visualization, Image Processing, Volume Textures	De Montfort University##De Montfort University##De Montfort University
Vis	2001	Visualization and interaction techniques for the exploration of vascular structures	10.1109/VISUAL.2001.964538	http://dx.doi.org/10.1109/VISUAL.2001.964538	395	402	C		Horst K. Hahn;Bernhard Preim;Dirk Selle;Heinz-Otto Peitgen	MeVis-Center for Med. Diagnostic Syst., Bremen, Germany|c|;;;	10.1109/VISUAL.1997.663917	vessel visualization, medical visualization, computer-assisted surgery	MeVis-Center for Med. Diagnostic Syst., Bremen, Germany|c|;;;
Vis	2001	Variational classification for visualization of 3D ultrasound data	10.1109/VISUAL.2001.964539	http://dx.doi.org/10.1109/VISUAL.2001.964539	403	410	C		Raanan Fattal;Dani Lischinski	Sch. of Comput. Sci. & Eng., Jerusalem, Israel|c|;	10.1109/VISUAL.1993.398877;10.1109/VISUAL.1997.663875	3D ultrasound, classification, isosurface extraction, opacity function, splatting, the variational principle, volume rendering	The Hebrew University of Jerusalem##The Hebrew University of Jerusalem
Vis	2001	Nonlinear virtual colon unfolding	10.1109/VISUAL.2001.964540	http://dx.doi.org/10.1109/VISUAL.2001.964540	411	418	C		Anna Vilanova;Rainer Wegenkittl;Andreas König 0002;Eduard Gröller	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;	10.1109/INFVIS.1997.636786;10.1109/VISUAL.1999.809914	Volume Rendering, Virtual Endoscopy	Vienna University of Technology â€ Tiani Medgraph##Vienna University of Technology â€ Tiani Medgraph##Vienna University of Technology â€ Tiani Medgraph##Vienna University of Technology â€ Tiani Medgraph
Vis	2001	PingTV: A Case Study in Visual Network Monitoring	10.1109/VISUAL.2001.964541	http://doi.ieeecomputersociety.org/10.1109/VISUAL.2001.964541	421	424	C		Alexander Gubin;William Yurcik;Larry Brumbaugh			network visualization, active network measurement, real-time television monitoring system	Lucent Technologies Network Systems Naperville##Illinois State University##Illinois State University
Vis	2001	Case study: medical Web service for the automatic 3D documentation for neuroradiological diagnosis	10.1109/VISUAL.2001.964542	http://dx.doi.org/10.1109/VISUAL.2001.964542	425	428	C		Sabine Iserhardt-Bauer;Peter Hastreiter;Thomas Ertl;K. Eberhardt;Bernd Tomandl	Visualization & Interactive Syst. Group, Stuttgart Univ., Germany|c|;;;;	10.1109/VISUAL.2000.885729	Medical visualization, segmentation, automatic web service, video generation	University of Stuttgart##Neurocenter##University of Stuttgart##University of Erlangen-Nuremberg##University of Erlangen-Nuremberg
Vis	2001	Case study: visual debugging of cluster hardware	10.1109/VISUAL.2001.964543	http://dx.doi.org/10.1109/VISUAL.2001.964543	429	432	C		Patricia Crossno;Rena A. Haynes	Sandia Nat. Labs., Albuquerque, NM, USA|c|;	10.1109/VISUAL.1999.809919	visual debugging, hardware modeling, design analysis, performance optimization	Sandia Nat. Labs., Albuquerque, NM, USA|c|;
Vis	2001	Case study on real-time visualization of virtual Tubingen on commodity PC hardware	10.1109/VISUAL.2001.964544	http://dx.doi.org/10.1109/VISUAL.2001.964544	433	436	C		Michael Meißner;Jasmina Orman;Stephan J. Braun	WSI, Tubingen Univ., Germany|c|;;		Virtual Environments, Virtual Reality, Spatial Cognition, PC Graphics Cards, Culling, levels-of-detail, Texture Compression	WSI, Tubingen Univ., Germany|c|;;
Vis	2001	An immersive virtual environment for DT-MRI volume visualization applications: a case study	10.1109/VISUAL.2001.964545	http://dx.doi.org/10.1109/VISUAL.2001.964545	437	440	C		Song Zhang 0004;Çagatay Demiralp;Daniel F. Keefe;M. DaSilva;David H. Laidlaw;Benjamin D. Greenberg;Peter J. Basser;Carlo Pierpaoli;E. A. Chiocca;Thomas S. Deisboeck	;;;;;;;;;	10.1109/VISUAL.1999.809894;10.1109/VISUAL.2000.885731;10.1109/VISUAL.1998.745336;10.1109/VISUAL.1999.809886	Scientific Visualization, DT-MRI, Diffusion, Medical Imaging, Virtual Reality	Brown University##Brown University##Brown University##Brown University##Brown University##Brown University##Brown University##Brown University##Brown University##Brown University
Vis	2001	Chromatin decondensation: case study of tracking features in confocal data	10.1109/VISUAL.2001.964546	http://dx.doi.org/10.1109/VISUAL.2001.964546	441	444	C		Wim C. de Leeuw;Robert van Liere	Center for Math. & Comput. Sci., CWI, Amsterdam, Netherlands|c|;	10.1109/VISUAL.2000.885735	feature tracking, multidimensional visualization, biomedical imaging	CWI##CWI
Vis	2001	Case study: an environment for understanding protein simulations using game graphics	10.1109/VISUAL.2001.964547	http://dx.doi.org/10.1109/VISUAL.2001.964547	445	448	C		Donna L. Gresh;Frank Suits;Yuk Yin Sham	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|;;	10.1109/VISUAL.1995.480793	visualization, proteins, computational biology, molecular modeling, molecular dynamics, game graphics, DirectX	IBM T.J. Watson Research Center##IBM T.J. Watson Research Center##IBM T.J. Watson Research Center
Vis	2001	Surgical simulator for hysteroscopy: a case study of visualization in surgical training	10.1109/VISUAL.2001.964548	http://dx.doi.org/10.1109/VISUAL.2001.964548	449	452	C		Kevin Montgomery;Wm. LeRoy Heinrichs;Cynthia Bruyns;Simon Wildermuth;Christopher J. Hasser;Stephanie Ozenne;David Bailey	Nat. Biocomputation Center, Stanford, CA, USA|c|;;;;;;		surgical simulation, hysteroscopy, haptics	Stanford University##Stanford University##Stanford University##Stanford University##Immersion Corporation##Immersion Corporation##Immersion Corporation
Vis	2001	Case study: reconstruction, visualization and quantification of neuronal fiber pathways	10.1109/VISUAL.2001.964549	http://dx.doi.org/10.1109/VISUAL.2001.964549	453	456	C		Zhaohua Ding;John C. Gore;Adam W. Anderson	Dept. of Diagnostic Radiol., Yale Univ. Sch. of Med., New Haven, CT, USA|c|;;		neuronal fiber pathway, diffusion tensor imaging	Yale University School of Medicine##Yale University School of Medicine##Yale University School of Medicine
Vis	2001	Visualizing 2D probability distributions from EOS satellite image-derived data sets: a case study	10.1109/VISUAL.2001.964550	http://dx.doi.org/10.1109/VISUAL.2001.964550	457	460	C		David T. Kao;Jennifer L. Dungan;Alex T. Pang	NASA Ames Res. Center, Moffett Field, CA, USA|c|;;		uncertainty, probability density function, geostatistics, conditional simulation, data assimilation	UCSC##UCSC##UCSC##UCSC
Vis	2001	Case study: application of feature tracking to analysis of autoignition simulation data	10.1109/VISUAL.2001.964551	http://dx.doi.org/10.1109/VISUAL.2001.964551	461	464	C		Wendy S. Koegler	Sandia Nat. Labs., Livermore, CA, USA|c|	10.1109/VISUAL.1998.745288	feature detection, feature tracking, combustion, autoignition	Sandia Nat. Labs., Livermore, CA, USA|c|
Vis	2001	Case study: visualization of particle track data	10.1109/VISUAL.2001.964552	http://dx.doi.org/10.1109/VISUAL.2001.964552	465	468	C		Xiaoming Wei;Arie E. Kaufman;Timothy J. Hallman	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;	10.1109/INFVIS.1997.636786;10.1109/INFVIS.1996.559214;10.1109/VISUAL.1994.346340		State University of New York at Stony Brook Relativistic Heavy Ion Collider Project (RHIC)##State University of New York at Stony Brook Relativistic Heavy Ion Collider Project (RHIC)##State University of New York at Stony Brook Relativistic Heavy Ion Collider Project (RHIC)
Vis	2001	Case study: interacting with cortical flat maps of the human brain	10.1109/VISUAL.2001.964553	http://dx.doi.org/10.1109/VISUAL.2001.964553	469	472	C		Monica K. Hurdal;Kevin W. Kurtz;David C. Banks	Int. Neuroimaging Consortium, Univ. of Minneapolis, MN, USA|c|;;		Conformal, Cortical Features, Human Brain, Flat Map, Interaction, MRI, Neuroscience, Surface	Florida State University and International Neuroimaging Consortium VA Medical Center University of Minneapolis##Florida State University and International Neuroimaging Consortium VA Medical Center University of Minneapolis##Florida State University and International Neuroimaging Consortium VA Medical Center University of Minneapolis
Vis	2001	4D space-time techniques: a medical imaging case study	10.1109/VISUAL.2001.964554	http://dx.doi.org/10.1109/VISUAL.2001.964554	473	476	C		Melanie Tory;Niklas Röber;Torsten Möller;Anna Celler;M. Stella Atkins	Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada|c|;;;;	10.1109/VISUAL.1993.398877;10.1109/VISUAL.1998.745294;10.1109/VISUAL.1999.809886	health, display algorithms, animations, 4D visualization, MRI, dynamic SPECT, direct volume rendering, isosurface, glyph	Simon Fraser University##Otto-von-Guericke University of Magdeburg##Simon Fraser University##Vancouver Hospital and Health Sciences Centre##Simon Fraser University
Vis	2001	Computed tomography angiography: a case study of peripheral vessel investigation	10.1109/VISUAL.2001.964555	http://dx.doi.org/10.1109/VISUAL.2001.964555	477	480	C		Armin Kanitsar;Rainer Wegenkittl;Petr Felkel;Dominik Fleischmann;Dominique Sandner;Eduard Gröller	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;;;		Computed Tomography Angiography (CTA), semi automatic segmentation, optimal path computation	Vienna University of Technology##Vienna University of Technology##Vienna University of Technology##Vienna University of Technology##Vienna University of Technology##Vienna University of Technology
Vis	2001	Graphical strategies to convey functional relationships in the human brain: a case study	10.1109/VISUAL.2001.964556	http://dx.doi.org/10.1109/VISUAL.2001.964556	481	484	C		Tomihisa Welsh;Klaus Mueller;Wei Zhu;Nora D. Volkow;Jeffrey Meade	State Univ. of New York, Stony Brook, NY, USA|c|;;;;			State University of New York at Stony Brook and Brookhaven National Laboratory##State University of New York at Stony Brook and Brookhaven National Laboratory##State University of New York at Stony Brook and Brookhaven National Laboratory##State University of New York at Stony Brook and Brookhaven National Laboratory##State University of New York at Stony Brook and Brookhaven National Laboratory
Vis	2001	A case study on interactive exploration and guidance aids for visualizing historical data	10.1109/VISUAL.2001.964557	http://dx.doi.org/10.1109/VISUAL.2001.964557	485	488	C		Stanislav L. Stoev;Wolfgang Straßer	Tubingen Univ., Germany|c|;	10.1109/VISUAL.1993.398847	Visualization, Historical Data, Interaction, Time-dependent Data, Visualization Techniques	University of TÃ¼bingen##University of TÃ¼bingen
Vis	2001	The MetVR case study: meteorological visualization in an immersive virtual environment	10.1109/VISUAL.2001.964559	http://dx.doi.org/10.1109/VISUAL.2001.964559	489	492	C		Sean Ziegeler;Robert J. Moorhead II;Paul J. Croft;Duanjun Lu	NSF Eng. Res. Center, Mississippi State Univ., MS, USA|c|;;;		virtual environments, virtual reality, immersion, visualization, meteorology	NSF Engineering Research Center Mississippi State University Mississippi State##NSF Engineering Research Center Mississippi State University Mississippi State##Jackson State University Jackson##Jackson State University Jackson
Vis	2001	Archaeological Data Visualization in VR: Analysis of Lamp Finds at the Great Temple of Petra, a Case Study	10.1109/VISUAL.2001.964560	http://doi.ieeecomputersociety.org/10.1109/VISUAL.2001.964560	493	496	C		Daniel Acevedo Feliz;Eileen Vote;David H. Laidlaw;Martha Sharp Joukowsky			Scientific Visualization, Archaeological Data Analysis, Immersive Virtual Reality Interfaces	Brown University
Vis	2001	Virtual Temporal Bone Dissection: A Case Study	10.1109/VISUAL.2001.964561	http://doi.ieeecomputersociety.org/10.1109/VISUAL.2001.964561	497	500	C		Jason Bryan;Don Stredney;Gregory J. Wiet;Dennis Sessanna			Temporal Bone Dissection	The Ohio State University####The Ohio State University##
Vis	2001	Semi-immersive space mission design and visualization: case study of the "Terrestrial Planet Finder" mission	10.1109/VISUAL.2001.964562	http://dx.doi.org/10.1109/VISUAL.2001.964562	501	504	C		Ken Museth;Alan H. Barr;Martin W. Lo	Dept. of Comput. Sci., California Inst. of Technol., Pasadena, CA, USA|c|;;			California Institute of Technology Pasadena##California Institute of Technology Pasadena##California Institute of Technology Pasadena
Vis	2001	Wind Tunnel Data Fusion and Immersive Visualization: A Case Study	10.1109/VISUAL.2001.964563	http://doi.ieeecomputersociety.org/10.1109/VISUAL.2001.964563	505	508	C		Kurt Severance;Paul Brewster;Barry Lazos;Daniel F. Keefe		10.1109/VISUAL.1998.745331	Data fusion, Photogrammetry, Line Integral Convolution, Reconstruction, Oil flow, Particle Image Velocimetry, Wind tunnel, Landing gear, Texture mapping, Image-based rendering, VRML	NASA Langley Research Center##NASA Langley Research Center##NASA Langley Research Center##NASA Langley Research Center
Vis	2001	A virtual environment for simulated rat dissection: a case study of visualization for astronaut training	10.1109/VISUAL.2001.964564	http://dx.doi.org/10.1109/VISUAL.2001.964564	509	601	C		Kevin Montgomery;Wm. LeRoy Heinrichs;Cynthia Bruyns;Simon Wildermuth	Nat. Biocomputation Center, Stanford Univ., CA, USA|c|;;			Stanford University##Stanford University##Stanford University
InfoVis	2002	Internet traffic: visualization, discovery, and very large displays	10.1109/INFVIS.2002.1173140	http://dx.doi.org/10.1109/INFVIS.2002.1173140	3	4	M		William S. Cleveland	Dept. Stat. Res., Bell Labs., Holmdel, NJ, USA|c|			Dept. Stat. Res., Bell Labs., Holmdel, NJ, USA|c|
InfoVis	2002	Multiscale visualization using data cubes	10.1109/INFVIS.2002.1173141	http://dx.doi.org/10.1109/INFVIS.2002.1173141	7	14	C		Chris Stolte;Diane Tang;Pat Hanrahan	Stanford Univ., CA, USA|c|;;	10.1109/INFVIS.2000.885086		Stanford University##Stanford University##Stanford University
InfoVis	2002	Visualization schemas for flexible information visualization	10.1109/INFVIS.2002.1173142	http://dx.doi.org/10.1109/INFVIS.2002.1173142	15	22	C		Chris North;Nathan Conklin;Varun Saini	Dept. of Comput. Sci., Virginia Polytech. Inst. & State Univ., Blacksburg, VA, USA|c|;;	10.1109/INFVIS.1995.528688;10.1109/INFVIS.1997.636788		Virginia Polytechnic Institute and State University Blacksburg##Virginia Polytechnic Institute and State University Blacksburg##Virginia Polytechnic Institute and State University Blacksburg
InfoVis	2002	Building a visual database for example-based graphics generation	10.1109/INFVIS.2002.1173143	http://dx.doi.org/10.1109/INFVIS.2002.1173143	23	30	C		Michelle X. Zhou;Min Chen;Ying Feng	IBM Thomas J. Watson Res. Center, Hawthorne, NY, USA|c|;;	10.1109/INFVIS.1996.559211		IBM Thomas J. Watson Res. Center, Hawthorne, NY, USA|c|;;
InfoVis	2002	Efficient cartogram generation: a comparison	10.1109/INFVIS.2002.1173144	http://dx.doi.org/10.1109/INFVIS.2002.1173144	33	36	C		Daniel A. Keim;Stephen C. North;Christian Panse;Jörn Schneidewind	AT&T Shannon Lab., Florham Park, NJ, USA|c|;;;	10.1109/VISUAL.1998.745301;10.1109/VISUAL.1998.745303		AT&T Shannon Lab., Florham Park, NJ, USA|c|;;;
InfoVis	2002	Visualizing data with bounded uncertainty	10.1109/INFVIS.2002.1173145	http://dx.doi.org/10.1109/INFVIS.2002.1173145	37	40	C		Christopher Olston;Jock D. Mackinlay	Stanford Univ., CA, USA|c|;	10.1109/VISUAL.1994.346317;10.1109/VISUAL.2000.885679;10.1109/INFVIS.1999.801858	uncertainty visualization, bounded uncertainty	Stanford University##Stanford University
InfoVis	2002	Graphical encoding for information visualization: an empirical study	10.1109/INFVIS.2002.1173146	http://dx.doi.org/10.1109/INFVIS.2002.1173146	43	50	C		Lucy T. Nowell;Robert S. Schulman;Deborah Hix	Battelle Pacific Northwest Lab., Richland, WA, USA|c|;;			Battelle Pacific Northwest Richland##Battelle Pacific Northwest Richland##Battelle Pacific Northwest Richland##Battelle Pacific Northwest Richland##Battelle Pacific Northwest Richland
InfoVis	2002	The illusion of perceived metric 3D structure	10.1109/INFVIS.2002.1173147	http://dx.doi.org/10.1109/INFVIS.2002.1173147	51	56	C		Mats Lind;Geoffrey P. Bingham;Camilla Forsell	Dept. of Inf. Sci., Uppsala Univ., Sweden|c|;;	10.1109/INFVIS.2001.963291		Uppsala University Uppsala##Uppsala University Uppsala
InfoVis	2002	SpaceTree: supporting exploration in large node link tree, design evolution and empirical evaluation	10.1109/INFVIS.2002.1173148	http://dx.doi.org/10.1109/INFVIS.2002.1173148	57	64	C		Catherine Plaisant;Jesse Grosjean;Benjamin B. Bederson	Human-Comput. Interaction Lab., Maryland Univ., MD, USA|c|;;	10.1109/VISUAL.1996.567745		Laboratory University of Maryland##Laboratory University of Maryland##Laboratory University of Maryland
InfoVis	2002	Process visualization with levels of detail	10.1109/INFVIS.2002.1173149	http://dx.doi.org/10.1109/INFVIS.2002.1173149	67	70	C		Kresimir Matkovic;Helwig Hauser;Reinhard Sainitzer;Eduard Gröller	VRVis Res. Center, Vienna, Austria|c|;;;	10.1109/INFVIS.1998.729558;10.1109/INFVIS.2001.963286	process visualization, information visualization, levels of detail, focus+context visualization	VRVis Research Center in Vienna##VRVis Research Center in Vienna##VRVis Research Center in Vienna##VRVis Research Center in Vienna##VRVis Research Center in Vienna
InfoVis	2002	Case study: visualizing sets of evolutionary trees	10.1109/INFVIS.2002.1173150	http://dx.doi.org/10.1109/INFVIS.2002.1173150	71	74	C		Nina Amenta;Jeff Klingner	Texas Univ., Austin, TX, USA|c|;	10.1109/VISUAL.1996.567787;10.1109/VISUAL.1993.398870		University of Texas at Austin##University of Texas at Austin
InfoVis	2002	InterRing: an interactive tool for visually navigating and manipulating hierarchical structures	10.1109/INFVIS.2002.1173151	http://dx.doi.org/10.1109/INFVIS.2002.1173151	77	84	C		Jing Yang 0001;Matthew O. Ward;Elke A. Rundensteiner	Dept. of Comput. Sci., Worcester Polytech. Inst., MA, USA|c|;;	10.1109/INFVIS.2001.963290;10.1109/INFVIS.2001.963285;10.1109/INFVIS.1997.636718;10.1109/INFVIS.1999.801858;10.1109/INFVIS.1995.528689;10.1109/INFVIS.2001.963283;10.1109/VISUAL.1991.175815;10.1109/INFVIS.2000.885091;10.1109/INFVIS.1999.801860;10.1109/INFVIS.2001.963284;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2001.963281;10.1109/INFVIS.1998.729557	radial space-filling hierarchy visualizations, multi-focus distortion, structure-based brushing	Dept. of Comput. Sci., Worcester Polytech. Inst., MA, USA|c|;;
InfoVis	2002	A space-optimized tree visualization	10.1109/INFVIS.2002.1173152	http://dx.doi.org/10.1109/INFVIS.2002.1173152	85	92	C		Quang Vinh Nguyen;Mao Lin Huang	Fac. of Inf. Technol., Univ. of Technol., Sydney, NSW, Australia|c|;	10.1109/INFVIS.1998.729555;10.1109/VISUAL.1991.175815		University of Technology##University of Technology##University of Technology
InfoVis	2002	Beamtrees: compact visualization of large hierarchies	10.1109/INFVIS.2002.1173153	http://dx.doi.org/10.1109/INFVIS.2002.1173153	93	100	C		Frank van Ham;Jarke J. van Wijk	Dept. of Math. & Comput. Sci., Technische Universiteit Eindhoven, Netherlands|c|;	10.1109/INFVIS.2001.963283;10.1109/INFVIS.2001.963290;10.1109/INFVIS.1999.801860;10.1109/VISUAL.1991.175815		Dept. of Math. & Comput. Sci., Technische Universiteit Eindhoven, Netherlands|c|;
InfoVis	2002	Visualizing biosequence data using texture mapping	10.1109/INFVIS.2002.1173154	http://dx.doi.org/10.1109/INFVIS.2002.1173154	103	109	C		Praveen R. Thiagarajan;Guang R. Gao	Biotechnol. Inst., Delaware Univ., Newark, DE, USA|c|;	10.1109/VISUAL.1998.745322;10.1109/INFVIS.2001.963278		University of Delaware##University of Delaware
InfoVis	2002	Arc diagrams: visualizing structure in strings	10.1109/INFVIS.2002.1173155	http://dx.doi.org/10.1109/INFVIS.2002.1173155	110	116	C		Martin Wattenberg	IBM Res., Cambridge, MA, USA|c|	10.1109/INFVIS.1995.528685;10.1109/VISUAL.1993.398883	string, sequence, visualization, arc diagram, music, text, code	IBM Research
InfoVis	2002	Interactive information visualization of a million items	10.1109/INFVIS.2002.1173156	http://dx.doi.org/10.1109/INFVIS.2002.1173156	117	124	C		Jean-Daniel Fekete;Catherine Plaisant	Human Comput. Interaction Lab., Maryland Univ., Baltimore, MD, USA|c|;	10.1109/INFVIS.2001.963274;10.1109/VISUAL.1991.175815;10.1109/INFVIS.2001.963279;10.1109/INFVIS.1995.528685;10.1109/VISUAL.1996.567774		University of Maryland##University of Maryland
InfoVis	2002	Angular brushing of extended parallel coordinates	10.1109/INFVIS.2002.1173157	http://dx.doi.org/10.1109/INFVIS.2002.1173157	127	130	C		Helwig Hauser;Florian Ledermann;Helmut Doleisch	VRVis Res. Center, Vienna, Austria|c|;;	10.1109/INFVIS.1996.559216;10.1109/VISUAL.2000.885739;10.1109/VISUAL.1994.346302;10.1109/VISUAL.1995.485139;10.1109/VISUAL.1990.146402	information visualization, parallel coordinates, brushing, linear correlations, focus+context visualization	VRVis Research Center in Vienna##VRVis Research Center in Vienna##VRVis Research Center in Vienna
InfoVis	2002	Multiple foci drill-down through tuple and attribute aggregation polyarchies in tabular data	10.1109/INFVIS.2002.1173158	http://dx.doi.org/10.1109/INFVIS.2002.1173158	131	134	C		Nathan Conklin;Sandeep Prabhakar;Chris North	Dept. of Comput. Sci., Virginia Polytech. Inst. & State Univ., Blacksburg, VA, USA|c|;;	10.1109/INFVIS.2000.885086;10.1109/INFVIS.1997.636761;10.1109/INFVIS.1996.559210		Virginia Polytechnic Institute and State University Blacksburg##Virginia Polytechnic Institute and State University Blacksburg##Virginia Polytechnic Institute and State University Blacksburg
InfoVis	2002	ACE: a fast multiscale eigenvectors computation for drawing huge graphs	10.1109/INFVIS.2002.1173159	http://dx.doi.org/10.1109/INFVIS.2002.1173159	137	144	C		Yehuda Koren;Liran Carmel;David Harel	Dept. of Comput. Sci. & Appl. Math., Weizmann Inst. of Sci., Rehovot, Israel|c|;;		algebraic multigrid, multiscale/multilevel optimization, graph drawing, generalized eigenvalue problem, Fiedler vector, force directed layout, the Hall energy	The Weizmann Institute of Science##The Weizmann Institute of Science##The Weizmann Institute of Science
InfoVis	2002	Visual unrolling of network evolution and the analysis of dynamic discourse	10.1109/INFVIS.2002.1173160	http://dx.doi.org/10.1109/INFVIS.2002.1173160	145	151	C		Ulrik Brandes;Steven R. Corman	Dept. of Comput. & Inf. Sci., Konstanz Univ., Germany|c|;	10.1109/INFVIS.2001.963279		University of Konstanz##University of Konstanz
InfoVis	2002	A hybrid layout algorithm for sub-quadratic multidimensional scaling	10.1109/INFVIS.2002.1173161	http://dx.doi.org/10.1109/INFVIS.2002.1173161	152	158	C		Alistair Morrison;Greg Ross;Matthew Chalmers	Dept. of Comput. Sci., Glasgow Univ., UK|c|;;	10.1109/VISUAL.1996.567787		Dept. of Comput. Sci., Glasgow Univ., UK|c|;;
InfoVis	2002	Demystifying venture capital investing	10.1109/INFVIS.2002.1173162	http://dx.doi.org/10.1109/INFVIS.2002.1173162	161	164	C		Mei C. Chuah	Accenture Technol. Labs., Palo Alto, CA, USA|c|	10.1109/INFVIS.2001.963273		Accenture Technol. Labs., Palo Alto, CA, USA|c|
InfoVis	2002	Visual path analysis	10.1109/INFVIS.2002.1173163	http://dx.doi.org/10.1109/INFVIS.2002.1173163	165	168	C		Alan Keahey;Stephen G. Eick	;	10.1109/INFVIS.2001.963293		;
InfoVis	2002	Display design for the eye and mind	10.1109/INFVIS.2002.1173164	http://dx.doi.org/10.1109/INFVIS.2002.1173164	171	171	M		Stephen M. Kosslyn	Harvard University|c|			Harvard University|c|
Vis	2002	Integration of measurement tools in medical 3d visualizations	10.1109/VISUAL.2002.1183752	http://dx.doi.org/10.1109/VISUAL.2002.1183752	21	28	C		Bernhard Preim;Christian Tietjen;Wolf Spindler;Heinz-Otto Peitgen	Center for Med. Diagnostic Syst. & Visualization, MeVis, Bremen, Germany|c|;;;		medical visualization, computer-assisted surgery, quantitative analysis, interaction techniques	Center for Med. Diagnostic Syst. & Visualization, MeVis, Bremen, Germany|c|;;;
Vis	2002	Fast visualization of plane-like structures in voxel data	10.1109/VISUAL.2002.1183753	http://dx.doi.org/10.1109/VISUAL.2002.1183753	29	36	C		Steffen Prohaska;Hans-Christian Hege	Dept. for Sci. Visualization, Zuse Inst. Berlin, Germany|c|;		skeletonization, thinning, distance transform, triangulation, visualization	Zuse Institute Berlin (ZIB)##Zuse Institute Berlin (ZIB)
Vis	2002	CPR - curved planar reformation	10.1109/VISUAL.2002.1183754	http://dx.doi.org/10.1109/VISUAL.2002.1183754	37	44	C		Armin Kanitsar;Dominik Fleischmann;Rainer Wegenkittl;Petr Felkel;Eduard Gröller	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;;	10.1109/VISUAL.2001.964555;10.1109/VISUAL.2001.964538	computed tomography angiography, vessel analysis, curved planar reformation	Vienna University of Technology University of Vienna Vienna##Vienna University of Technology University of Vienna Vienna##Vienna University of Technology University of Vienna Vienna##Vienna University of Technology University of Vienna Vienna##Vienna University of Technology University of Vienna Vienna##Vienna University of Technology University of Vienna Vienna
Vis	2002	Direct surface extraction from 3D freehand ultrasound images	10.1109/VISUAL.2002.1183755	http://dx.doi.org/10.1109/VISUAL.2002.1183755	45	52	C		Youwei Zhang;Robert Rohling;Dinesh K. Pai	Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC, Canada|c|;;	10.1109/VISUAL.1991.175782;10.1109/VISUAL.1994.346295	Radial Basis Functions, Ultrasound, Isosurface, 3D Freehand Ultrasound, Direct Surface Extraction, Unstructured data	The University of British Columbia##The University of British Columbia##The University of British Columbia
Vis	2002	Interactive rendering of large volume data sets	10.1109/VISUAL.2002.1183757	http://dx.doi.org/10.1109/VISUAL.2002.1183757	53	60	C		Stefan Guthe;Michael Wand;Julius Gonser;Wolfgang Straßer	WSI/GRIS, Tubingen Univ., Germany|c|;;;	10.1109/VISUAL.2001.964531;10.1109/VISUAL.1999.809908;10.1109/VISUAL.1999.809889;10.1109/VISUAL.1993.398845;10.1109/VISUAL.2001.964519	Compression Algorithms, Level of Detail Algorithms, Scientific Visualization, Volume Rendering, Wavelets	University of TÃ¼bingen##University of TÃ¼bingen##University of TÃ¼bingen##University of TÃ¼bingen
Vis	2002	Semotus Visum: a flexible remote visualization framework	10.1109/VISUAL.2002.1183758	http://dx.doi.org/10.1109/VISUAL.2002.1183758	61	68	C		Eric Luke;Charles D. Hansen	Sci. Comput. & Imaging Inst., Utah Univ., Salt Lake City, UT, USA|c|;	10.1109/VISUAL.1997.663891;10.1109/VISUAL.1999.809878;10.1109/VISUAL.1998.745300	remote visualization, client/server	University of Utah##University of Utah
Vis	2002	Out-of-core rendering of massive geometric environments	10.1109/VISUAL.2002.1183759	http://dx.doi.org/10.1109/VISUAL.2002.1183759	69	76	C		Gokul Varadhan;Dinesh Manocha	Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;	10.1109/VISUAL.2001.964502;10.1109/VISUAL.1997.663927;10.1109/VISUAL.1997.663888;10.1109/VISUAL.2001.964503	external memory, large datasets, walkthroughs, visibility, LODs, prefetching	University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill
Vis	2002	Optimized view-dependent rendering for large polygonal datasets	10.1109/VISUAL.2002.1183760	http://dx.doi.org/10.1109/VISUAL.2002.1183760	77	84	C		Jihad El-Sana;Eitan Bachmant	Dept. of Comput. Sci., Ben-Gurion Univ. of the Negev, Beer-Sheva, Israel|c|;	10.1109/VISUAL.1999.809877;10.1109/VISUAL.1997.663860;10.1109/VISUAL.2000.885724;10.1109/VISUAL.1998.745283;10.1109/VISUAL.1995.480805	Surface Simplification, Level of Detail, Multiresolution Hierarchies, View-Dependent Rendering	Gurion University of the Negev *##Gurion University of the Negev *
Vis	2002	Volumetric shadows using splatting	10.1109/VISUAL.2002.1183761	http://dx.doi.org/10.1109/VISUAL.2002.1183761	85	92	C		Caixia Zhang;Roger Crawfis	Dept. of Comput. & Inf. Sci., Ohio State Univ., Columbus, OH, USA|c|;	10.1109/VISUAL.1998.745309;10.1109/VISUAL.1999.809909;10.1109/VISUAL.2000.885698;10.1109/VISUAL.2002.1183764	visualization, volume rendering, shadows, illumination	The Ohio State University##The Ohio State University
Vis	2002	Volume clipping via per-fragment operations in texture-based volume visualization	10.1109/VISUAL.2002.1183762	http://dx.doi.org/10.1109/VISUAL.2002.1183762	93	100	C		Daniel Weiskopf;Klaus Engel;Thomas Ertl	Visualization & Interactive Syst. Group, Stuttgart Univ., Germany|c|;;	10.1109/VISUAL.1999.809892;10.1109/VISUAL.2001.964519;10.1109/VISUAL.1999.809884	volume rendering, clipping, hardware acceleration	University of Stuttgart##University of Stuttgart##University of Stuttgart
Vis	2002	Interactive spectral volume rendering	10.1109/VISUAL.2002.1183763	http://dx.doi.org/10.1109/VISUAL.2002.1183763	101	108	C		Steven Bergner;Torsten Möller;Mark S. Drew;Graham D. Finlayson	Dept. of Simulation & Graphics, Magdeburg Univ., Germany|c|;;;	10.1109/VISUAL.2001.964519;10.1109/VISUAL.2001.964515;10.1109/VISUAL.1997.663875	spectral volume rendering, post-illumination, interactive re-lighting	University of Magdeburg Simon Fraser University University of East Anglia##University of Magdeburg Simon Fraser University University of East Anglia##University of Magdeburg Simon Fraser University University of East Anglia##University of Magdeburg Simon Fraser University University of East Anglia##University of Magdeburg Simon Fraser University University of East Anglia
Vis	2002	Interactive translucent volume rendering and procedural modeling	10.1109/VISUAL.2002.1183764	http://dx.doi.org/10.1109/VISUAL.2002.1183764	109	116	C		Joe Michael Kniss;Simon Premoze;Charles D. Hansen;David S. Ebert	Sci. Comput. & Imaging Inst., Utah Univ., Salt Lake City, UT, USA|c|;;;	10.1109/VISUAL.1990.146391	volume rendering, shading model, volume modeling, procedural modeling	University of Utah Â§School of Electrical and Computer Engineering Purdue University##University of Utah Â§School of Electrical and Computer Engineering Purdue University##University of Utah Â§School of Electrical and Computer Engineering Purdue University##University of Utah Â§School of Electrical and Computer Engineering Purdue University
Vis	2002	A multiphase approach to efficient surface simplification	10.1109/VISUAL.2002.1183765	http://dx.doi.org/10.1109/VISUAL.2002.1183765	117	124	C		Michael Garland;Eric Shaffer	Illinois Univ., Urbana, IL, USA|c|;	10.1109/VISUAL.2001.964502;10.1109/VISUAL.2001.964503;10.1109/VISUAL.1998.745282;10.1109/VISUAL.1998.745314	multiphase simplification, quadric error metrics, massive meshes, out-of-core simplification	University of Illinois at Urbanaâ€“Champaign##University of Illinois at Urbanaâ€“Champaign
Vis	2002	Geometric surface smoothing via anisotropic diffusion of normals	10.1109/VISUAL.2002.1183766	http://dx.doi.org/10.1109/VISUAL.2002.1183766	125	132	C		Tolga Tasdizen;Ross T. Whitaker;Paul Burchard;Stanley Osher	Sch. of Comput., Utah Univ., Salt Lake City, UT, USA|c|;;;		anisotropic diffusion, surface fairing, geometric surface processing, intrinsic Laplacian of curvature, level sets	Sch. of Comput., Utah Univ., Salt Lake City, UT, USA|c|;;;
Vis	2002	TetFusion: an algorithm for rapid tetrahedral mesh simplification	10.1109/VISUAL.2002.1183767	http://dx.doi.org/10.1109/VISUAL.2002.1183767	133	140	C		Prashant Chopra;Joerg Meyer	Eng. Res. Center, Mississippi State Univ., MS, USA|c|;	10.1109/VISUAL.1998.745329;10.1109/VISUAL.1997.663883;10.1109/VISUAL.1999.809868;10.1109/VISUAL.2000.885680;10.1109/VISUAL.1998.745315;10.1109/VISUAL.1999.809901	mesh simplification, multi resolution, level-of-detail, unstructured meshes	Mississippi State University##Mississippi State University
Vis	2002	Compressing polygon mesh geometry with parallelogram prediction	10.1109/VISUAL.2002.1183768	http://dx.doi.org/10.1109/VISUAL.2002.1183768	141	146	C		Martin Isenburg;Pierre Alliez	North Carolina Univ., Chapel Hill, NC, USA|c|;	10.1109/VIS.1999.10000;10.1109/VISUAL.2000.885711;10.1109/VISUAL.1999.809902	mesh compression, polygon meshes, geometric coding, linear prediction, parallelogram rule	University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill
Vis	2002	Probabilistic surfaces: point based primitives to show surface uncertainty	10.1109/VISUAL.2002.1183769	http://dx.doi.org/10.1109/VISUAL.2002.1183769	147	153	C		Gevorg Grigoryan;Penny Rheingans	Maryland Univ., Baltimore, MD, USA|c|;	10.1109/VISUAL.1996.568105;10.1109/VISUAL.2000.885679;10.1109/VISUAL.2001.964492;10.1109/VISUAL.1995.480802	uncertainty, visualizing surface uncertainty, points as display primitives	University of Maryland Baltimore County Penny Rheingans University of Maryland Baltimore County
Vis	2002	PMR: point to mesh rendering, a feature-based approach	10.1109/VISUAL.2002.1183770	http://dx.doi.org/10.1109/VISUAL.2002.1183770	155	162	C		Tamal K. Dey;James Hudson	Ohio State Univ., Columbus, OH, USA|c|;	10.1109/VISUAL.2001.964489;10.1109/VISUAL.2001.964492;10.1109/VISUAL.2001.964491;10.1109/VISUAL.1997.663909	rendering, feature, multi-resolution, level of details, Voronoi diagram	The Ohio State University##The Ohio State University
Vis	2002	Efficient simplification of point-sampled surfaces	10.1109/VISUAL.2002.1183771	http://dx.doi.org/10.1109/VISUAL.2002.1183771	163	170	C		Mark Pauly;Markus H. Gross;Leif Kobbelt	Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;;	10.1109/VISUAL.2001.964503;10.1109/VISUAL.1999.809896;10.1109/VISUAL.2001.964502;10.1109/VISUAL.2001.964489;10.1109/VISUAL.2000.885722		Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;;
Vis	2002	Exploring scalar fields using critical isovalues	10.1109/VISUAL.2002.1183772	http://dx.doi.org/10.1109/VISUAL.2002.1183772	171	178	C		Gunther H. Weber;Gerik Scheuermann;Hans Hagen;Bernd Hamann	AG Graphische Datenverarbeitung und Computergeometrie, Kaiserslautern Univ., Germany|c|;;;	10.1109/VISUAL.1990.146401;10.1109/VISUAL.1997.663875;10.1109/VISUAL.1998.745284;10.1109/VISUAL.1999.809932;10.1109/VISUAL.1991.175782;10.1109/VISUAL.2000.885703;10.1109/VISUAL.2000.885705	scalar field topology, critical point, volume visualization, data exploration, isosurfaces, marching cubes	University of Kaiserslautern##University of Kaiserslautern##University of Kaiserslautern##University of California
Vis	2002	Level set segmentation from multiple non-uniform volume datasets	10.1109/VISUAL.2002.1183773	http://dx.doi.org/10.1109/VISUAL.2002.1183773	179	186	C		Ken Museth;David E. Breen;Leonid Zhukov;Ross T. Whitaker	Dept. of Comput. Sci., California Inst. of Technol., Pasadena, CA, USA|c|;;;		segmentation, visualization, level set models, 3D reconstruction	University of Utah##University of Utah##University of Utah##University of Utah
Vis	2002	Efficient computation of the topology of level sets	10.1109/VISUAL.2002.1183774	http://dx.doi.org/10.1109/VISUAL.2002.1183774	187	194	C		Valerio Pascucci;Kree Cole-McLaughlin	Center of Appl. Sci. Comput., Lawrence Livermore Nat. Lab., CA, USA|c|;	10.1109/VISUAL.1997.663875	Isosurfaces, Level Set Topology, Betti Numbers	Lawrence Livermore National Laboratory##Lawrence Livermore National Laboratory
Vis	2002	Fast and reliable space leaping for interactive volume rendering	10.1109/VISUAL.2002.1183775	http://dx.doi.org/10.1109/VISUAL.2002.1183775	195	202	C		Ming Wan;Aamir Sadiq;Arie E. Kaufman	Boeing Co., Seattle, WA, USA|c|;;		virtual navigation, volume visualization, ray-casting optimization, space leaping	Boeing Co., Seattle, WA, USA|c|;;
Vis	2002	A new object-order ray-casting algorithm	10.1109/VISUAL.2002.1183776	http://dx.doi.org/10.1109/VISUAL.2002.1183776	203	210	C		Benjamin Mora;Jean-Pierre Jessel;René Caubet	Inst. de Recherche en Informatique de Toulouse (IRIT), Univ. Paul Sabatier, Toulouse, France|c|;;	10.1109/VISUAL.2001.964498;10.1109/VISUAL.2001.964521;10.1109/VISUAL.1999.809889;10.1109/VISUAL.1998.745309;10.1109/VISUAL.2000.885698;10.1109/VISUAL.1999.809911;10.1109/VISUAL.1999.809909;10.1109/VISUAL.1994.346331;10.1109/VISUAL.1995.480792	Volume Rendering, Scientific Visualization, Medical Imaging, Ray Tracing	UniversitÃ© Paul Sabatier##UniversitÃ© Paul Sabatier##UniversitÃ© Paul Sabatier
Vis	2002	Non-photorealistic volume rendering using stippling techniques	10.1109/VISUAL.2002.1183777	http://dx.doi.org/10.1109/VISUAL.2002.1183777	211	218	C		Aidong Lu;Christopher J. Morris;David S. Ebert;Penny Rheingans;Charles D. Hansen	Purdue Univ., West Lafayette, IN, USA|c|;;;;	10.1109/VISUAL.1997.663894;10.1109/VISUAL.2001.964492;10.1109/VISUAL.2000.885694;10.1109/VISUAL.2001.964490;10.1109/VISUAL.2001.964522;10.1109/VISUAL.2000.885696	non-photorealistic rendering, volume rendering, scientific visualization, medical imaging	Purdue University##Purdue University##Purdue University##Purdue University
Vis	2002	Interactive visualization of complex plant ecosystems	10.1109/VISUAL.2002.1183778	http://dx.doi.org/10.1109/VISUAL.2002.1183778	219	226	C		Oliver Deussen;Carsten Colditz;Marc Stamminger;George Drettakis	Fac. of Comput. Sci., Dresden Univ. of Technol., Germany|c|;;;	10.1109/VISUAL.1997.663860;10.1109/VISUAL.2001.964491;10.1109/VISUAL.2001.964492	Synthetic Plants, Ecosystems, Point-based rendering, Level-of-detail Algorithms	Dresden University of Technology##Dresden University of Technology##Sophia Antipolis##Sophia Antipolis
Vis	2002	Simulating fire with texture splats	10.1109/VISUAL.2002.1183779	http://dx.doi.org/10.1109/VISUAL.2002.1183779	227	234	C		Xiaoming Wei;Wei Li 0004;Klaus Mueller;Arie E. Kaufman	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;;	10.1109/VISUAL.1993.398877	Fire Modeling, Textured Splatting, Lattice Boltzmann Model, Graphics Hardware	State University Of New York At Stony Brook Stony Brook##State University Of New York At Stony Brook Stony Brook##State University Of New York At Stony Brook Stony Brook##State University Of New York At Stony Brook Stony Brook
Vis	2002	Visualizing dynamic molecular conformations	10.1109/VISUAL.2002.1183780	http://dx.doi.org/10.1109/VISUAL.2002.1183780	235	242	C		Johannes Schmidt-Ehrenberg;Daniel Baum;Hans-Christian Hege	Zuse Inst. Berlin (ZIB), Germany|c|;;	10.1109/VISUAL.2000.885733	uncertainty visualization, molecular conformation analysis, molecular modeling, drug design	Zuse Inst. Berlin (ZIB), Germany|c|;;
Vis	2002	GeneVis: visualization tools for genetic regulatory network dynamics	10.1109/VISUAL.2002.1183781	http://dx.doi.org/10.1109/VISUAL.2002.1183781	243	250	C		Charles A. H. Baker;M. Sheelagh T. Carpendale;Przemyslaw Prusinkiewicz;Michael G. Surette	Dept. of Comput. Sci., Calgary Univ., Alta., Canada|c|;;;		biological visualization, visualization, multi-representation, genetic networks, lenses, focus and context	University of Calgary##University of Calgary##University of Calgary##University of Calgary
Vis	2002	Isometric embedding by surface reconstruction from distances	10.1109/VISUAL.2002.1183782	http://dx.doi.org/10.1109/VISUAL.2002.1183782	251	257	C		Ingrid Hotz	Dept. of Comput. Sci., Kaiserslautern Univ., Germany|c|	10.1109/VISUAL.1992.235193;10.1109/VISUAL.1998.745316	isometric embedding, metric, tensor fields	University of Kaiserslautern
Vis	2002	Fast view-dependent level-of-detail rendering using cached geometry	10.1109/VISUAL.2002.1183783	http://dx.doi.org/10.1109/VISUAL.2002.1183783	259	265	C		Joshua Levenberg	California Univ., Berkeley, CA, USA|c|	10.1109/VISUAL.1997.663860;10.1109/VISUAL.1996.567600;10.1109/VISUAL.1998.745280;10.1109/VISUAL.2001.964533;10.1109/VISUAL.1996.568126;10.1109/VISUAL.1998.745282	view-dependent mesh, level of detail, height fields, terrain, binary triangle trees, triangle bintree, multiresolution meshes, displacement maps, frame-to-frame coherence	University of California at Berkeley
Vis	2002	Visibility-guided simplification	10.1109/VISUAL.2002.1183784	http://dx.doi.org/10.1109/VISUAL.2002.1183784	267	274	C		Eugene Zhang;Greg Turk	GVU Center & Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;	10.1109/VISUAL.1999.809869;10.1109/VISUAL.2000.885723	Visualization, Visibility, Mesh Simplification, Rendering	GVU Center and College of Computing##GVU Center and College of Computing
Vis	2002	Maximum entropy light source placement	10.1109/VISUAL.2002.1183785	http://dx.doi.org/10.1109/VISUAL.2002.1183785	275	282	C		Stefan Gumhold	WSI/GRIS, Tubingen Univ., Germany|c|		Lighting Design, Visualization, Illumination, Maximum Entropy, Optimization, User Study	University of TÃ¼bingen
Vis	2002	Computing singularities of 3D vector fields with geometric algebra	10.1109/VISUAL.2002.1183786	http://dx.doi.org/10.1109/VISUAL.2002.1183786	283	289	C		Stephen Mann;Alyn P. Rockwood	Waterloo Univ., Ont., Canada|c|;	10.1109/VISUAL.1997.663858;10.1109/VISUAL.1997.663871	Geometric Algebra, 3D Vector Fields, Singularities	University of Waterloo##University of Waterloo
Vis	2002	Seamster: inconspicuous low-distortion texture seam layout	10.1109/VISUAL.2002.1183787	http://dx.doi.org/10.1109/VISUAL.2002.1183787	291	298	C		Alla Sheffer;John C. Hart	Dept. of Comput. Sci., Technion-Israel Inst. of Technol., Haifa, Israel|c|;	10.1109/VISUAL.2000.885723	Texture Mapping, Visibility Classification	Technion I.I.T##Technion I.I.T
Vis	2002	Face-based luminance matching for perceptual colormap generation	10.1109/VISUAL.2002.1183788	http://dx.doi.org/10.1109/VISUAL.2002.1183788	299	306	C		Gordon L. Kindlmann;Erik Reinhard;Sarah H. Creem-Regehr	Sch. of Comput., Utah Univ., Salt Lake City, UT, USA|c|;;	10.1109/VISUAL.1995.480803;10.1109/VISUAL.1992.235201;10.1109/VISUAL.2001.964510	Colormaps, Color Scales, Isoluminance, Brightness Matching, Perceptually-based Visualization	University of Utah##University of Utah##University of Utah
Vis	2002	Geometric verification of swirling features in flow fields	10.1109/VISUAL.2002.1183789	http://dx.doi.org/10.1109/VISUAL.2002.1183789	307	314	C		Ming Jiang 0005;Raghu Machiraju;David S. Thompson	Ohio State Univ., Columbus, OH, USA|c|;;	10.1109/VISUAL.1999.809896;10.1109/VISUAL.1998.745333;10.1109/VISUAL.1998.745296;10.1109/VISUAL.1993.398877	feature verification, vortex detection, flow field visualization	The Ohio State University##The Ohio State University##The Ohio State University
Vis	2002	Comparative evaluation of visualization and experimental results using image comparison metrics	10.1109/VISUAL.2002.1183790	http://dx.doi.org/10.1109/VISUAL.2002.1183790	315	322	C		Hualin Zhou;Min Chen;Michael F. Webster	Univ. of Wales, Swansea, UK|c|;;	10.1109/VISUAL.1999.809873;10.1109/VISUAL.1996.568140;10.1109/VISUAL.1998.745332	scientific visualization, comparative visualization, image comparison, error metrics, human vision system, rheology	University of Wales Swansea##University of Wales Swansea##University of Wales Swansea
Vis	2002	A model for the visualization exploration process	10.1109/VISUAL.2002.1183791	http://dx.doi.org/10.1109/VISUAL.2002.1183791	323	330	C		T. J. Jankun-Kelly;Kwan-Liu Ma;Michael Gertz	Comput. Sci. Dept., California Univ., Davis, CA, USA|c|;;	10.1109/VISUAL.2002.1183816;10.1109/INFVIS.1998.729560;10.1109/VISUAL.1999.809871;10.1109/VISUAL.1995.480821;10.1109/VISUAL.1993.398857;10.1109/VISUAL.1992.235203;10.1109/VISUAL.1995.480801;10.1109/VISUAL.1994.346304	visualization process, visualization models, scientific and information visualization, collaboration, XML	University of California##University of California##University of California
Vis	2002	Sea of images	10.1109/VISUAL.2002.1183792	http://dx.doi.org/10.1109/VISUAL.2002.1183792	331	338	C		Daniel G. Aliaga;Thomas A. Funkhouser;Dimah Yanovsky;Ingrid Carlbom	Lucent Technol. Bell Labs, NJ, USA|c|;;;	10.1109/VISUAL.1995.480797	image-based rendering, capture, reconstruction, interactive, walkthrough	Lucent Technol. Bell Labs, NJ, USA|c|;;;
Vis	2002	Scalable alignment of large-format multi-projector displays using camera homography trees	10.1109/VISUAL.2002.1183793	http://dx.doi.org/10.1109/VISUAL.2002.1183793	339	346	C		Han Chen;Rahul Sukthankar;Grant Wallace;Kai Li	Comput. Sci., Princeton Univ., NJ, USA|c|;;;	10.1109/VISUAL.1999.809883;10.1109/VISUAL.2001.964508;10.1109/VISUAL.2000.885685	large-format tiled projection display, display wall, camera-projector systems, camera-based registration and calibration, automatic alignment, scalability, simulation, evaluation	Princeton University The Robotics Institute##Princeton University The Robotics Institute##Princeton University The Robotics Institute##Princeton University The Robotics Institute
Vis	2002	Efficient compression and rendering of multi-resolution meshes	10.1109/VISUAL.2002.1183794	http://dx.doi.org/10.1109/VISUAL.2002.1183794	347	354	C		Zachi Karni;Alexander Bogomjakov;Craig Gotsman	Fac. of Comput. Sci., Technion - Israel Inst. of Technol., Haifa, Israel|c|;;	10.1109/VIS.1999.10000;10.1109/VISUAL.2000.885711;10.1109/VISUAL.1999.809902	progressive compression, wavelets, geometry coding, rendering	Technion â€“ Israel Institute of Technology##Technion â€“ Israel Institute of Technology##Technion â€“ Israel Institute of Technology
Vis	2002	Bounded-distortion piecewise mesh parameterization	10.1109/VISUAL.2002.1183795	http://dx.doi.org/10.1109/VISUAL.2002.1183795	355	362	C		Olga Sorkine-Hornung;Daniel Cohen-Or;Rony Goldenthal;Dani Lischinski	Sch. of Comput. Sci., Tel Aviv Univ., Israel|c|;;;		atlas, mesh partitioning, parameterization, surface flattening, texture mapping, 3D painting	Computer Science Tel-Aviv University##Computer Science Tel-Aviv University##Computer Science Tel-Aviv University##Computer Science Tel-Aviv University
Vis	2002	XFastMesh: fast view-dependent meshing from external memory	10.1109/VISUAL.2002.1183796	http://dx.doi.org/10.1109/VISUAL.2002.1183796	363	370	C		Christopher DeCoro;Renato Pajarola	Dept. of Inf. & Comput. Sci., California Univ., Irvine, CA, USA|c|;	10.1109/VISUAL.1997.663860;10.1109/VISUAL.2001.964502;10.1109/VISUAL.1998.745283;10.1109/VISUAL.2001.964503;10.1109/VISUAL.1996.568126;10.1109/VISUAL.1998.745282	level-of-detail, multiresolution modeling, out-of-core rendering, interactive large-scale visualization	University of California##University of California
Vis	2002	Tensor field visualisation using adaptive filtering of noise fields combined with glyph rendering	10.1109/VISUAL.2002.1183797	http://dx.doi.org/10.1109/VISUAL.2002.1183797	371	378	C		Andreas Sigfridsson;Tino Ebbers;Einar Heiberg;Lars Wigström	Dept. of Medicine & Care, Linkoping Univ., Sweden|c|;;;	10.1109/VISUAL.1992.235193;10.1109/VISUAL.1999.809905;10.1109/VISUAL.1998.745294;10.1109/VISUAL.1995.480817	Tensor, Visualization, Volume rendering, Glyph rendering, Hybrid rendering, Strain-rate	LinkÃ¶pings Universitet##LinkÃ¶pings Universitet##LinkÃ¶pings Universitet##LinkÃ¶pings Universitet
Vis	2002	Volume deformation for tensor visualization	10.1109/VISUAL.2002.1183798	http://dx.doi.org/10.1109/VISUAL.2002.1183798	379	386	C		Xiaoqiang Zheng;Alex T. Pang	Dept. of Comput. Sci., California Univ., Santa Cruz, CA, USA|c|;	10.1109/VISUAL.1998.745316;10.1109/VISUAL.1999.809905;10.1109/VISUAL.1993.398849;10.1109/VISUAL.1991.175789;10.1109/VISUAL.1992.235193;10.1109/VISUAL.1998.745294	stress, strain, shear, symmetric tensors, anti-symmetric tensors, anisotropic tensors	University of California##University of California
Vis	2002	Oriented tensor reconstruction: tracing neural pathways from diffusion tensor MRI	10.1109/VISUAL.2002.1183799	http://dx.doi.org/10.1109/VISUAL.2002.1183799	387	394	C		Leonid Zhukov;Alan H. Barr	Dept. of Comput. Sci., California Inst. of Technol., Pasadena, CA, USA|c|;	10.1109/VISUAL.1999.809886;10.1109/VISUAL.1992.235193;10.1109/VISUAL.1999.809894;10.1109/VISUAL.1998.745294;10.1109/VISUAL.1991.175771	Diffusion tensors, adaptive filtering, moving least squares, streamlines, fiber tracing, pathways, salient features	California Institute of Technology##California Institute of Technology
Vis	2002	QuadTIN: quadtree based triangulated irregular networks	10.1109/VISUAL.2002.1183800	http://dx.doi.org/10.1109/VISUAL.2002.1183800	395	402	C		Renato Pajarola;Marc Antonijuan;Roberto Lario	Dept. of Inf. & Comput. Sci., California Univ., Irvine, CA, USA|c|;;	10.1109/VISUAL.1997.663860;10.1109/VISUAL.2001.964533;10.1109/VISUAL.1998.745282;10.1109/VISUAL.1998.745280	multiresolution triangulation, real-time terrain visualization, triangulated irregular networks, level-of-detail	University of California Irvine La Salle University##University of California Irvine La Salle University##University of California Irvine La Salle University
Vis	2002	Horizon occlusion culling for real-time rendering of hierarchical terrains	10.1109/VISUAL.2002.1183801	http://dx.doi.org/10.1109/VISUAL.2002.1183801	403	409	C		Brandon Lloyd;Parris K. Egbert	Brigham Young Univ., Provo, UT, USA|c|;	10.1109/VISUAL.1998.745322;10.1109/VISUAL.1998.745280;10.1109/VISUAL.1997.663863;10.1109/VISUAL.1997.663860;10.1109/VISUAL.1998.745282	rendering algorithms, visibility, occlusion culling	Brigham Young University##Brigham Young University
Vis	2002	Evaluation of a multimodal interface for 3D terrain visualization	10.1109/VISUAL.2002.1183802	http://dx.doi.org/10.1109/VISUAL.2002.1183802	411	418	C		David M. Krum;Olugbenga Omoteso;William Ribarsky;Thad Starner;Larry F. Hodges	Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;;;;		multimodal interaction, evaluation, navigation, speech recognition, gesture recognition, virtual reality, mobile visualization, GIS	GVU Center##GVU Center##GVU Center##GVU Center##GVU Center
Vis	2002	Assisted navigation for large information spaces	10.1109/VISUAL.2002.1183803	http://dx.doi.org/10.1109/VISUAL.2002.1183803	419	426	C		Brent M. Dennis;Christopher G. Healey	Dept. of Comput. Sci., North Carolina State Univ., Raleigh, NC, USA|c|;	10.1109/VISUAL.1995.480803	camera planning, information visualization, multidimensional visualization, navigation, scientific visualization	North Carolina State University##North Carolina State University
Vis	2002	BM3D: motion estimation in time dependent volume data	10.1109/VISUAL.2002.1183804	http://dx.doi.org/10.1109/VISUAL.2002.1183804	427	433	C		Wim C. de Leeuw;Robert van Liere	Center for Math. & Comput. Sci., CWI, Amsterdam, Netherlands|c|;	10.1109/VISUAL.2001.964546	feature tracking, vector fields, volume visualization, biomedical imaging	CWI##CWI
Vis	2002	Kinetic visualization: a technique for illustrating 3D shape and structure	10.1109/VISUAL.2002.1183805	http://dx.doi.org/10.1109/VISUAL.2002.1183805	435	442	C		Eric B. Lum;Aleksander Stompel;Kwan-Liu Ma	Dept. of Comput. Sci., California Univ., Davis, CA, USA|c|;;	10.1109/VISUAL.2000.885742	animation, visual perception, particle systems, scientific visualization, volume rendering	University of California at Davis##University of California at Davis##University of California at Davis
Vis	2002	A radial focus+context visualization for multi-dimensional functions	10.1109/VISUAL.2002.1183806	http://dx.doi.org/10.1109/VISUAL.2002.1183806	443	450	C		Sanjini Jayaraman;Chris North	Center for Human Comput. Interaction, Virginia Polytech. Inst. & State Univ., Blacksburg, VA, USA|c|;	10.1109/INFVIS.1997.636793;10.1109/INFVIS.1995.528688;10.1109/VISUAL.1993.398859;10.1109/INFVIS.1998.729558	visualization, multidimensional functions	Virginia Polytechnic Institute and State University Blacksburg##Virginia Polytechnic Institute and State University Blacksburg
Vis	2002	BLIC: Bi-Level Isosurface Compression	10.1109/VISUAL.2002.1183807	http://dx.doi.org/10.1109/VISUAL.2002.1183807	451	458	C		Gabriel Taubin	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|	10.1109/VISUAL.1997.663848;10.1109/VISUAL.2000.885705	3D Geometry Compression, Algorithms, Graphics	IBM T. J. Watson Research Center
Vis	2002	Approximating normals for marching cubes applied to locally supported isosurfaces	10.1109/VISUAL.2002.1183808	http://dx.doi.org/10.1109/VISUAL.2002.1183808	459	466	C		Gregory M. Nielson;Adam Huang;Steve Sylvester	Comput. Sci. & Eng., Arizona State Univ., Tempe, AZ, USA|c|;;	10.1109/VISUAL.1991.175782	isosurface, normal vectors, marching cubes, triangular mesh, topology, Gouraud shading, approximation	Arizona State University##Arizona State University##Arizona State University
Vis	2002	Volume warping for adaptive isosurface extraction	10.1109/VISUAL.2002.1183809	http://dx.doi.org/10.1109/VISUAL.2002.1183809	467	474	C		Laurent Balmelli;Christopher J. Morris;Gabriel Taubin;Fausto Bernardini	IBM Thomas J. Watson Res. Center, Hawthorne, NY, USA|c|;;;	10.1109/VISUAL.1996.568127;10.1109/VISUAL.2000.885705	isosurfaces, adaptive isosurface extraction, volume warping, adaptive tessellation	IBM Research T.J. Watson Center Hawthorne##IBM Research T.J. Watson Center Hawthorne##IBM Research T.J. Watson Center Hawthorne##IBM Research T.J. Watson Center Hawthorne
Vis	2002	Interactive view-dependent rendering of large isosurfaces	10.1109/VISUAL.2002.1183810	http://dx.doi.org/10.1109/VISUAL.2002.1183810	475	482	C		Benjamin F. Gregorski;Mark A. Duchaineau;Peter Lindstrom;Valerio Pascucci;Kenneth I. Joy	Center for Appl. Sci. Comput., Lawrence Livermore Nat. Lab., CA, USA|c|;;;;	10.1109/VISUAL.2000.885681;10.1109/VISUAL.2001.964533;10.1109/VISUAL.1999.809878;10.1109/VISUAL.2001.964502;10.1109/VISUAL.1997.663869;10.1109/VISUAL.2000.885705;10.1109/VISUAL.1998.745300;10.1109/VISUAL.1997.663860;10.1109/VISUAL.2001.964524;10.1109/VISUAL.2000.885703	View-Dependent Rendering, Isosurfaces, Multiresolution Tetrahedal Meshes, Multiresolution Techniques	Lawrence Livermore National Laboratory##Lawrence Livermore National Laboratory##Lawrence Livermore National Laboratory##Lawrence Livermore National Laboratory##Lawrence Livermore National Laboratory
Vis	2002	Case study: hardware-accelerated selective LIC volume rendering	10.1109/VISUAL.2002.1183811	http://dx.doi.org/10.1109/VISUAL.2002.1183811	485	488	C		Yasuko Suzuki;Issei Fujishiro;Li Chen;Hiroko Nakamura	Mitsubishi Electr. Corp., Japan|c|;;;	10.1109/VISUAL.1996.567777;10.1109/VISUAL.1999.809906;10.1109/VISUAL.1997.663912;10.1109/VISUAL.1999.809892	Flow visualization, flow topology, significance map, illumination model	Mitsubishi Electric Corp##Mitsubishi Electric Corp##Mitsubishi Electric Corp##Mitsubishi Electric Corp
Vis	2002	Christmas tree case study: computed tomography as a tool for mastering complex real world objects with applications in computer graphics	10.1109/VISUAL.2002.1183812	http://dx.doi.org/10.1109/VISUAL.2002.1183812	489	492	C		Armin Kanitsar;Thomas Theußl;Lukas Mroz;Milos Srámek;Anna Vilanova;Balázs Csébfalvi;Jirí Hladuvka;Dominik Fleischmann;Michael Knapp;Rainer Wegenkittl;Petr Felkel;Stefan Guthe;Werner Purgathofer;Eduard Gröller	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;;;;;;;;;;;;	10.1109/VISUAL.2001.964522;10.1109/VISUAL.2001.964555;10.1109/VISUAL.2001.964531;10.1109/VISUAL.1994.346320	modeling, computed tomography, volume visualization	Austrian Academy of Sciences â€ Tiani Medgraph â€¡ VRVis Research Center##Austrian Academy of Sciences â€ Tiani Medgraph â€¡ VRVis Research Center##Austrian Academy of Sciences â€ Tiani Medgraph â€¡ VRVis Research Center##Austrian Academy of Sciences â€ Tiani Medgraph â€¡ VRVis Research Center##Austrian Academy of Sciences â€ Tiani Medgraph â€¡ VRVis Research Center##Austrian Academy of Sciences â€ Tiani Medgraph â€¡ VRVis Research Center##Austrian Academy of Sciences â€ Tiani Medgraph â€¡ VRVis Research Center##Austrian Academy of Sciences â€ Tiani Medgraph â€¡ VRVis Research Center##Austrian Academy of Sciences â€ Tiani Medgraph â€¡ VRVis Research Center##Austrian Academy of Sciences â€ Tiani Medgraph â€¡ VRVis Research Center##Austrian Academy of Sciences â€ Tiani Medgraph â€¡ VRVis Research Center##Austrian Academy of Sciences â€ Tiani Medgraph â€¡ VRVis Research Center##Austrian Academy of Sciences â€ Tiani Medgraph â€¡ VRVis Research Center##Austrian Academy of Sciences â€ Tiani Medgraph â€¡ VRVis Research Center##Austrian Academy of Sciences â€ Tiani Medgraph â€¡ VRVis Research Center##Austrian Academy of Sciences â€ Tiani Medgraph â€¡ VRVis Research Center##Austrian Academy of Sciences â€ Tiani Medgraph â€¡ VRVis Research Center##Austrian Academy of Sciences â€ Tiani Medgraph â€¡ VRVis Research Center##Austrian Academy of Sciences â€ Tiani Medgraph â€¡ VRVis Research Center##Austrian Academy of Sciences â€ Tiani Medgraph â€¡ VRVis Research Center##Austrian Academy of Sciences â€ Tiani Medgraph â€¡ VRVis Research Center##University of Vienna Â¶ VIS Institute of Computer Graphics and Algorithms
Vis	2002	Case study: Visualization and analysis of high Rayleigh number - 3D convection in the Earth's mantle	10.1109/VISUAL.2002.1183813	http://dx.doi.org/10.1109/VISUAL.2002.1183813	493	496	C		Gordon Erlebacher;David A. Yuen;Fabien Dubuffet	Sch. of Computational Sci. & Inf. Technol., Florida State Univ., Tallahassee, FL, USA|c|;;	10.1109/VISUAL.1990.146359	mantle convection, plumes, volume rendering, unsteady flow, feature extraction, critical points	Florida State University##University of Minnesota##University of Minnesota
Vis	2002	Immersive volume visualization of seismic simulations: A case study of techniques invented and lessons learned	10.1109/VISUAL.2002.1183814	http://dx.doi.org/10.1109/VISUAL.2002.1183814	497	500	C		Prashant Chopra;Joerg Meyer;Antonio Fernandez	Eng. Res. Center, Mississippi State Univ., MS, USA|c|;;	10.1109/VISUAL.1998.745329;10.1109/VISUAL.1997.663883;10.1109/VISUAL.2000.885680;10.1109/VISUAL.1998.745315	mesh simplification, multi resolution, level-of-detail, unstructured meshes	Mississippi State University##Mississippi State University##Mississippi State University
Vis	2002	Case study: A look of performance expression	10.1109/VISUAL.2002.1183815	http://dx.doi.org/10.1109/VISUAL.2002.1183815	501	504	C		Rumi Hiraga	Bunkyo Univ., Japan|c|	10.1109/VISUAL.1997.663931	Music Performance, Expressive Cue, Performance Visualization, Understanding Performance	Bunkyo University
Vis	2002	Case study: Interactive visualization for Internet security	10.1109/VISUAL.2002.1183816	http://dx.doi.org/10.1109/VISUAL.2002.1183816	505	508	C		Soon Tee Teoh;Kwan-Liu Ma;Shyhtsun Felix Wu;Xiaoliang Zhao	Dept. of Comput. Sci., California Univ., Davis, CA, USA|c|;;;		anomaly detection, graph drawing, information visualization, network security	University of California##University of California##University of California##Carolina State University
Vis	2002	PRIMA: A case study of using information visualization techniques for patient record analysis	10.1109/VISUAL.2002.1183817	http://dx.doi.org/10.1109/VISUAL.2002.1183817	509	512	C		Donna L. Gresh;David A. Rabenhorst;Amnon Shabo;Shimon Slavin	IBM Thomas J. Watson Res. Center, NY, USA|c|;;;		visualization, information visualization, bioinformatics, medical records	IBM T.J. Watson Research Center##IBM T.J. Watson Research Center##IBM T.J. Watson Research Center##IBM T.J. Watson Research Center
Vis	2002	Case study: A virtual environment for genomic data visualization	10.1109/VISUAL.2002.1183818	http://dx.doi.org/10.1109/VISUAL.2002.1183818	513	516	C		R. Mark Adams;Blaze Stancampiano;Michael McKenna;David Small	Variagenics Inc., Cambridge, MA, USA|c|;;;		Bioinformatics, Human Factors, 3-Dimensional Interaction, Multi-scale Model, Data Navigation, Virtual Environment	Variagenics Inc##Variagenics Inc##Variagenics Inc##Variagenics Inc##Variagenics Inc
Vis	2002	Case study: Visual debugging of finite element codes	10.1109/VISUAL.2002.1183819	http://dx.doi.org/10.1109/VISUAL.2002.1183819	517	520	C		Patricia Crossno;David H. Rogers;Christopher J. Garasi	Sandia Nat. Labs., USA|c|;;	10.1109/VISUAL.1999.809919;10.1109/VISUAL.2001.964543	visual debugging, parallel finite element codes and simulations	Sandia Nat. Labs., USA|c|;;
Vis	2002	Case study: Interactive rendering of adaptive mesh refinement data	10.1109/VISUAL.2002.1183820	http://dx.doi.org/10.1109/VISUAL.2002.1183820	521	524	C		Sanghun Park;Chandrajit L. Bajaj;Vinay Siddavanahalli	Texas Univ., Austin, TX, USA|c|;;	10.1109/VISUAL.1993.398877	AMR, K-d trees, Octree, Hierarchical splatting, Texture mapping	University of Texas at Austin##University of Texas at Austin##University of Texas at Austin##University of Texas at Austin##University of Texas at Austin##University of Texas at Austin
Vis	2002	A case study in selective visualization of unsteady 3D flow	10.1109/VISUAL.2002.1183821	http://dx.doi.org/10.1109/VISUAL.2002.1183821	525	528	C		Dirk Bauer;Ronald Peikert;Mie Sato;Mirjam Sick	Dept. of Comput. Sci., Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;;;	10.1109/VISUAL.1994.346327;10.1109/VISUAL.2001.964493	Flow Visualization, Feature Extraction, Particle Tracing	Dept. of Comput. Sci., Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;;;
Vis	2002	Case study: Visualizing ocean flow vertical motions using Lagrangian-Eulerian time surfaces	10.1109/VISUAL.2002.1183822	http://dx.doi.org/10.1109/VISUAL.2002.1183822	529	532	C		Josh Grant;Gordon Erlebacher;James F. O'Brien	Center for Ocean-Atmos. Prediction Studies, Florida State Univ., Tallahassee, FL, USA|c|;;	10.1109/VISUAL.1999.809895;10.1109/VISUAL.2001.964493;10.1109/VISUAL.2000.885688;10.1109/VISUAL.1996.568149	unsteady vector fields, time surfaces, ocean currents, vertical velocity	Florida State University##Florida State University##
Vis	2002	A case study on multiresolution visualization of local rainfall from weather radar measurements	10.1109/VISUAL.2002.1183823	http://dx.doi.org/10.1109/VISUAL.2002.1183823	533	536	C		Thomas Gerstner;Dirk Meetschen;Susanne Crewell;Michael Griebel;Clemens Simmer	Dept. for Appl. Math., Bonn Univ., Germany|c|;;;;	10.1109/VISUAL.1995.480800;10.1109/VISUAL.1997.663869;10.1109/VISUAL.2000.885745	triangular and tetrahedral grid refinement, multiresolution isosurface extraction, level-of-detail	University of Bonn##University of Bonn##University of Bonn##University of Bonn##University of Bonn##
Vis	2002	Rendering the first star in the Universe - A case study	10.1109/VISUAL.2002.1183824	http://dx.doi.org/10.1109/VISUAL.2002.1183824	537	540	C		Ralf Kähler;Donna J. Cox;Robert Patterson;Stuart Levy;Hans-Christian Hege;Tom Abel	Zuse Inst., Berlin, Germany|c|;;;;;	10.1109/VISUAL.2002.1183820	3D texture based volume rendering, adaptive mesh refinement data, CAVE applications, data visualization	Zuse Institute Berlin (ZIB)##National Center for Supercomputing Applications (NCSA)##National Center for Supercomputing Applications (NCSA)##National Center for Supercomputing Applications (NCSA)##Zuse Institute Berlin (ZIB)####Penn State University
Vis	2002	NASA's great zooms: a case study	10.1109/VISUAL.2002.1183825	http://dx.doi.org/10.1109/VISUAL.2002.1183825	541	544	C		Gregory W. Shirah;Horace Mitchell	;		visualization, remote sensing, renderman, shader, georegistration, color matching	
Vis	2002	A case study on automatic camera placement and motion for visualizing historical data	10.1109/VISUAL.2002.1183826	http://dx.doi.org/10.1109/VISUAL.2002.1183826	545	548	C		Stanislav L. Stoev;Wolfgang Straßer	Tubingen Univ., Germany|c|;	10.1109/VISUAL.2001.964557	Automatic Camera Control, Visualization, Historical Data, Time-dependent Data, Visualization Techniques	University of T Â¨ ubingen##University of T Â¨ ubingen
Vis	2002	Case study on the adaptation of interactive visualization applications to Web-based production for operational mesoscale weather models	10.1109/VISUAL.2002.1183827	http://dx.doi.org/10.1109/VISUAL.2002.1183827	549	552	C		Lloyd Treinish	IBM Thomas J. Watson Res. Center, Yorktown Heights, NY, USA|c|	10.1109/VISUAL.2000.885736;10.1109/VISUAL.1995.480821;10.1109/VISUAL.2000.885678;10.1109/VISUAL.2000.885745	visualization, meteorology, world-wide-web	IBM Thomas J. Watson Research Center
Vis	2002	Exploring surface characteristics with interactive Gaussian images (a case study)	10.1109/VISUAL.2002.1183828	http://dx.doi.org/10.1109/VISUAL.2002.1183828	553	556	C		Bradley C. Lowekamp;Penny Rheingans;Terry S. Yoo	Maryland Univ., Baltimore, MD, USA|c|;;	10.1109/VISUAL.2001.964529	Computational Geometry, Gauss map, Illumination and shading, Interactive visualization	University of Maryland Baltimore County Penny Rheingans University of Maryland Baltimore County Terry S. Yoo National Library of Medicine
Vis	2002	A case study on the applications of a generic library for low-cost polychromatic passive stereo	10.1109/VISUAL.2002.1183829	http://dx.doi.org/10.1109/VISUAL.2002.1183829	557	560	C		Simon Stegmaier;Dirc Rose;Thomas Ertl	Visualization & Interactive Syst. Group, Stuttgart Univ., Germany|c|;;	10.1109/VISUAL.1999.809918	Stereo Graphics, OpenGL, Preloading	University of Stuttgart##University of Stuttgart##University of Stuttgart
Vis	2002	Case study: the "Office of Real Soon Now" for visualization	10.1109/VISUAL.2002.1183830	http://dx.doi.org/10.1109/VISUAL.2002.1183830	561	564	C		Samuel P. Uselton			display, projection, panoramic image display	Lawrence Livermore National Laboratory
InfoVis	2003	IEEE Symposium on Information Visualization 2003 (IEEE Cat. No.03TH8714)	10.1109/INFVIS.2003.1249000	http://dx.doi.org/10.1109/INFVIS.2003.1249000			M		Tamara Munzner;Steven C. North				
InfoVis	2003	Thinking with visualization	10.1109/INFVIS.2003.1249001	http://dx.doi.org/10.1109/INFVIS.2003.1249001	3	3	M		Colin Ware	Data Visualization Research Lab|c|			Data Visualization Research Lab|c|
InfoVis	2003	Exploding the frame: designing for wall-size computer displays	10.1109/INFVIS.2003.1249002	http://dx.doi.org/10.1109/INFVIS.2003.1249002	7		M		Ben Shedd	Princeton Univ., NJ, USA|c|			Princeton Univ., NJ, USA|c|
InfoVis	2003	Information esthetics: from MoMa to wall street	10.1109/INFVIS.2003.1249003	http://dx.doi.org/10.1109/INFVIS.2003.1249003	11	11	M		W. Bradford Paley	Digital Image Design & Columbia University|c|			Digital Image Design & Columbia University|c|
InfoVis	2003	Smooth and efficient zooming and panning	10.1109/INFVIS.2003.1249004	http://dx.doi.org/10.1109/INFVIS.2003.1249004	15	23	C		Jarke J. van Wijk;Wim A. A. Nuij	Dept. of Math. & Comput. Sci., Technische Universiteit Eindvohen, Netherlands|c|;	10.1109/INFVIS.2003.1249030	Navigation, zooming, panning, scrolling, scale space	Dept. of Math. & Comput. Sci., Technische Universiteit Eindvohen, Netherlands|c|;
InfoVis	2003	A model of multi-scale perceptual organization in information graphics	10.1109/INFVIS.2003.1249005	http://dx.doi.org/10.1109/INFVIS.2003.1249005	23	30	C		Martin Wattenberg;Danyel Fisher	Collaborative User Experience Group, IBM Res., White Plains, NY, USA|c|;		Visualization, Perceptual Organization, Scale Space, Design Methodology	University of California##University of California
InfoVis	2003	Exploring high-D spaces with multiform matrices and small multiples	10.1109/INFVIS.2003.1249006	http://dx.doi.org/10.1109/INFVIS.2003.1249006	31	38	C		Alan M. MacEachren;Xiping Dai;Frank Hardisty;Diansheng Guo;Eugene Lengerich	Dept. of Geogr., Pennsylvania State Univ., University Park, VA, USA|c|;;;;	10.1109/VISUAL.1991.175815;10.1109/INFVIS.1998.729559	geovisualization, EDA, scatterplot matrix,bivariate map, space-filling visualization, conditional entropy, small multiples, conditioning, GeoVISTA Studio 	The Pennsylvania State University##The Pennsylvania State University##The Pennsylvania State University##The Pennsylvania State University##The Pennsylvania State University
InfoVis	2003	Design choices when architecting visualizations	10.1109/INFVIS.2003.1249007	http://dx.doi.org/10.1109/INFVIS.2003.1249007	41	48	C		Diane Tang;Chris Stolte;Robert Bosch	Stanford Univ., CA, USA|c|;;	10.1109/INFVIS.1996.559213;10.1109/INFVIS.2002.1173156;10.1109/VISUAL.1995.480801;10.1109/INFVIS.1998.729560;10.1109/INFVIS.2002.1173141;10.1109/INFVIS.2000.885086;10.1109/VISUAL.1992.235219	information visualization, system architecture, semantic meta-data, data transformations, design tradeoffs	Stanford University##Stanford University##Stanford University
InfoVis	2003	Edgelens: an interactive method for managing edge congestion in graphs	10.1109/INFVIS.2003.1249008	http://dx.doi.org/10.1109/INFVIS.2003.1249008	51	58	C		Nelson Wong;M. Sheelagh T. Carpendale;Saul Greenberg	Dept. of Comput. Sci., Calgary Univ., Alta., Canada|c|;;	10.1109/INFVIS.1997.636786;10.1109/INFVIS.1996.559214	 Navigation, graph layout, distortion lens, information visualization, edge congestion, interactive visualization	University of Calgary##University of Calgary##University of Calgary
InfoVis	2003	MoireGraphs: radial focus+context visualization and interaction for graphs with visual nodes	10.1109/INFVIS.2003.1249009	http://dx.doi.org/10.1109/INFVIS.2003.1249009	59	66	C		T. J. Jankun-Kelly;Kwan-Liu Ma	Mississippi State Univ., Starkville, MS, USA|c|;	10.1109/INFVIS.2000.885091;10.1109/INFVIS.1997.636718;10.1109/INFVIS.1996.559214;10.1109/INFVIS.2001.963279;10.1109/INFVIS.2002.1173151	information visualization, focus+context, radial graph layout, graph drawing	Mississippi State University University of California##Mississippi State University University of California
InfoVis	2003	Visualizing evolving networks: minimum spanning trees versus pathfinder networks	10.1109/INFVIS.2003.1249010	http://dx.doi.org/10.1109/INFVIS.2003.1249010	67	74	C		Chaomei Chen;Steven Morris	Coll. of Inf. Sci. & Technol., Drexel Univ., Philadelphia, PA, USA|c|;	10.1109/INFVIS.2001.963285;10.1109/INFVIS.2002.1173160;10.1109/VISUAL.1999.809927	Network evolution, network visualization, co-citation networks, Pathfinder networks, minimum spanning trees	Oklahoma State University##Oklahoma State University
InfoVis	2003	Multiscale Visualization of Small World Networks	10.1109/INFVIS.2003.1249011	http://doi.ieeecomputersociety.org/10.1109/INFVIS.2003.1249011	75	84	C		David Auber;Yves Chiricota;Fabien Jourdan;Guy Melançon			Small world networks, multiscale graphs,clustering metric, semantic zooming	Univ. QuÃ©bec Ã Chicoutimi##Univ. QuÃ©bec Ã Chicoutimi##Univ. QuÃ©bec Ã Chicoutimi##Univ. QuÃ©bec Ã Chicoutimi##LIRMM##LIRMM
InfoVis	2003	Improving Hybrid MDS with Pivot-Based Searching	10.1109/INFVIS.2003.1249012	http://doi.ieeecomputersociety.org/10.1109/INFVIS.2003.1249012	85	90	C		Alistair Morrison;Matthew Chalmers		10.1109/INFVIS.2002.1173150;10.1109/INFVIS.2002.1173159;10.1109/VISUAL.1996.567787;10.1109/INFVIS.2002.1173161	Multidimensional scaling, MDS, spring models, hybrid algorithms, pivots, near-neighbour search, force directed placement	University of Glasgow##University of Glasgow
InfoVis	2003	A virtual workspace for hybrid multidimensional scaling algorithms	10.1109/INFVIS.2003.1249013	http://dx.doi.org/10.1109/INFVIS.2003.1249013	91	96	C		Greg Ross;Matthew Chalmers	Dept. of Comput. Sci., Glasgow Univ., UK|c|;	10.1109/INFVIS.2003.1249012;10.1109/VISUAL.1996.567787	Data-flow, visual programming, multidimensional scaling, multiple views, hybrid algorithms, complexity	University of Glasgow##University of Glasgow
InfoVis	2003	Dynamic visualization of transient data streams	10.1109/INFVIS.2003.1249014	http://dx.doi.org/10.1109/INFVIS.2003.1249014	97	104	C		Pak Chung Wong;Harlan Foote;Dan Adams;Wendy Cowley;James J. Thomas	PNNL, Richland, WA, USA|c|;;;;	10.1109/VISUAL.1996.567787;10.1109/VISUAL.1997.663866;10.1109/INFVIS.2002.1173161;10.1109/INFVIS.1995.528686;10.1109/INFVIS.1999.801855	Dynamic Visualization, Text Visualization, Remote Sensing Imagery, Transient Data Stream	PNNL, Richland, WA, USA|c|;;;;
InfoVis	2003	Interactive hierarchical dimension ordering, spacing and filtering for exploration of high dimensional datasets	10.1109/INFVIS.2003.1249015	http://dx.doi.org/10.1109/INFVIS.2003.1249015	105	112	C		Jing Yang 0001;Wei Peng;Matthew O. Ward;Elke A. Rundensteiner	Dept. of comuter Sci., Worcester Polytech. Inst., MA, USA|c|;;;	10.1109/VISUAL.1990.146386;10.1109/VISUAL.1990.146402;10.1109/INFVIS.1998.729559;10.1109/VISUAL.1994.346302;10.1109/INFVIS.2000.885086;10.1109/VISUAL.1995.485140;10.1109/INFVIS.2002.1173151	Dimension ordering, dimension spacing, dimension filtering, multidimensional visualization, high dimensional datasets	Dept. of comuter Sci., Worcester Polytech. Inst., MA, USA|c|;;;
InfoVis	2003	Mapping nominal values to numbers for effective visualization	10.1109/INFVIS.2003.1249016	http://dx.doi.org/10.1109/INFVIS.2003.1249016	113	120	C		Geraldine E. Rosario;Elke A. Rundensteiner;David C. Brown;Matthew O. Ward	Dept. of Comput. Sci., Worcester Polytech. Inst., USA|c|;;;	10.1109/VISUAL.1990.146386;10.1109/VISUAL.1990.146402;10.1109/INFVIS.1998.729559;10.1109/VISUAL.1994.346302	 nominal data, visualization, dimension reduction, correspondence analysis, quantification, clustering, classing	Worcester Polytechnic Institute##Worcester Polytechnic Institute##Worcester Polytechnic Institute##Worcester Polytechnic Institute
InfoVis	2003	Visualization of Labeled Data Using Linear Transformation	10.1109/INFVIS.2003.1249017	http://doi.ieeecomputersociety.org/10.1109/INFVIS.2003.1249017	121	128	C		Yehuda Koren;Liran Carmel	The Weizmann Institute of Science, Rehovot, Israel	10.1109/INFVIS.2002.1173159;10.1109/INFVIS.2001.963275;10.1109/INFVIS.2002.1173161	visualization, dimensionality-reduction, projection, principal component analysis, Fisher's linear discriminant analysis, eigenprojection, classification	The Weizmann Institute of Science##The Weizmann Institute of Science
InfoVis	2003	Intelligently resolving point occlusion	10.1109/INFVIS.2003.1249018	http://dx.doi.org/10.1109/INFVIS.2003.1249018	131	136	C		Marjan Trutschl;Georges G. Grinstein;Urska Cvek	LSU Comput. Sci., LSU Health Sci. Center, Shreveport, LA, USA|c|;;	10.1109/VISUAL.1990.146402	data visualization, information visualization, design, data points, data density, occlusion, identifiable points, jitter, neural networks	LSU Computer Science LSU Health Sciences Center Shreveport##LSU Computer Science LSU Health Sciences Center Shreveport##LSU Computer Science LSU Health Sciences Center Shreveport
InfoVis	2003	Constant density displays using diversity sampling	10.1109/INFVIS.2003.1249019	http://dx.doi.org/10.1109/INFVIS.2003.1249019	137	144	C		Mark Derthick;Michael G. Christel;Alexander G. Hauptmann;Howard D. Wactlar	Human-Comput. Interaction Inst., Carnegie Mellon Univ., Pittsburgh, PA, USA|c|;;;	10.1109/INFVIS.1998.729570	Information Visualization, Collage	Carnegie Mellon University Pittsburgh##Carnegie Mellon University Pittsburgh
InfoVis	2003	Empirical comparison of dynamic query sliders and brushing histograms	10.1109/INFVIS.2003.1249020	http://dx.doi.org/10.1109/INFVIS.2003.1249020	147	153	C		Qing Li;Chris North	Dept. of Comput. Sci., Virginia Polytech. Inst & State Univ., Blacksburg, VA, USA|c|;	10.1109/INFVIS.1999.801862	Dynamic query, slider, histogram, usability study, information visualization, multidimensional visualization	Virginia Polytechnic Institute and State University Blacksburg##Virginia Polytechnic Institute and State University Blacksburg
InfoVis	2003	An experimental evaluation of continuous semantic zooming in program visualization	10.1109/INFVIS.2003.1249021	http://dx.doi.org/10.1109/INFVIS.2003.1249021	155	162	C		Kenneth L. Summers;Timothy E. Goldsmith;Steve Kubica;Thomas P. Caudell	Center for High Performance Comput., New Mexico Univ., Albuquerque, NM, USA|c|;;;	10.1109/INFVIS.1997.636784	Program visualization, Human subjects testing, Visual program languages	The University of New##The University of New Mexico Steve Kubica â€¡ Khoral, Inc
InfoVis	2003	Conveying shape with texture: an experimental investigation of the impact of texture type on shape categorization judgments	10.1109/INFVIS.2003.1249022	http://dx.doi.org/10.1109/INFVIS.2003.1249022	163	170	C		Sunghee Kim;Haleh Hagh-Shenas;Victoria Interrante	Minnesota Univ., Minneapolis, MN, USA|c|;;		shape perception, texture, principal directions	University of Minnesota##University of Minnesota##University of Minnesota
InfoVis	2003	Coordinated graph and scatter-plot views for the visual exploration of microarray time-series data	10.1109/INFVIS.2003.1249023	http://dx.doi.org/10.1109/INFVIS.2003.1249023	173	180	C		Paul Craig;Jessie B. Kennedy	Sch. of Comput., Napier Univ., Edinburgh, UK|c|;	10.1109/INFVIS.2002.1173157	Bioinformatics, Microarrays, Information Visualization, Time-Series, Multiple-views	Napier University##Napier University
InfoVis	2003	Compound brushing	10.1109/INFVIS.2003.1249024	http://dx.doi.org/10.1109/INFVIS.2003.1249024	181	188	C		Hong Chen	SAS Inst. Inc., Cary, NC, USA|c|	10.1109/VISUAL.1995.485139;10.1109/INFVIS.2002.1173157;10.1109/INFVIS.2000.885092;10.1109/VISUAL.1994.346302;10.1109/INFVIS.1996.559216	brushing, selection, dynamic graphics, data visualization, higraph, visual programming, dynamic query	SAS Institute Inc
InfoVis	2003	Causality visualization using animated growing polygons	10.1109/INFVIS.2003.1249025	http://dx.doi.org/10.1109/INFVIS.2003.1249025	189	196	C		Niklas Elmqvist;Philippas Tsigas	Dept. of Comput. Sci., Chalmers Univ. of Technol., Goteborg, Sweden|c|;	10.1109/INFVIS.1998.729561	causal relations, information visualization, interactive animation	Chalmers University of Technology##Chalmers University of Technology
InfoVis	2003	Visualization of large-scale customer satisfaction surveys using a parallel coordinate tree	10.1109/INFVIS.2003.1249026	http://dx.doi.org/10.1109/INFVIS.2003.1249026	197	201	C		Dominique Brodbeck;Luc Girardin	Macrofocus GmbH, Zurich, Switzerland|c|;	10.1109/VISUAL.1991.175815;10.1109/VISUAL.1990.146402;10.1109/INFVIS.2001.963274;10.1109/INFVIS.2001.963285	parallel coordinates,focus+context, hierarchical data, satisfaction survey	Macrofocus GmbH, Zurich, Switzerland|c|;
InfoVis	2003	FundExplorer: supporting the diversification of mutual fund portfolios using context treemaps	10.1109/INFVIS.2003.1249027	http://dx.doi.org/10.1109/INFVIS.2003.1249027	203	208	C		Christoph Csallner;Marcus Handte;Othmar Lehmann;John T. Stasko	Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;;;	10.1109/INFVIS.2002.1173156;10.1109/VISUAL.1992.235217	information visualization, context, treemap, distortion, query, financial data, stock market, FundExplore	Georgia Institute of Technology Atlanta##Georgia Institute of Technology Atlanta##Georgia Institute of Technology Atlanta##Georgia Institute of Technology Atlanta
InfoVis	2003	Thread Arcs: an email thread visualization	10.1109/INFVIS.2003.1249028	http://dx.doi.org/10.1109/INFVIS.2003.1249028	211	218	C		Bernard Kerr		10.1109/INFVIS.2002.1173155;10.1109/INFVIS.2001.963290	conversations, discussions, electronic mail, email, information visualization, threads, tree structures, user interfaces	
InfoVis	2003	BARD: A visualization tool for biological sequence analysis	10.1109/INFVIS.2003.1249029	http://doi.ieeecomputersociety.org/10.1109/INFVIS.2003.1249029	219	225	C		Rhazes Spell;Rachael Brady;Fred Dietrich	Duke University	10.1109/INFVIS.2002.1173155	sequence analysis, comparative genomics, visualization, arc diagram, BARD	Duke University##Duke University##Duke University
InfoVis	2003	Using multilevel call matrices in large software projects	10.1109/INFVIS.2003.1249030	http://dx.doi.org/10.1109/INFVIS.2003.1249030	227	232	C		Frank van Ham	Dept. of Math. & Comput. Sci., Technische Universiteit Eindhoven, Netherlands|c|	10.1109/INFVIS.2002.1173141;10.1109/INFVIS.2003.1249004;10.1109/VISUAL.1991.175815	software visualization, multilevel visualization, call matrix	Universiteit Eindhoven
InfoVis	2003	Between aesthetics and utility: designing ambient information visualizations	10.1109/INFVIS.2003.1249031	http://dx.doi.org/10.1109/INFVIS.2003.1249031	233	240	C		Tobias Skog;Sara Ljungblad;Lars Erik Holmquist	Future Applications Lab, Viktoria Inst., Goteborg, Sweden|c|;;		Ambient information visualization, informative art, ambient displays, calm technology	Future Applications Lab, Viktoria Inst., Goteborg, Sweden|c|;;
InfoVis	2003	Developing architectural lighting representations	10.1109/INFVIS.2003.1249032	http://doi.ieeecomputersociety.org/10.1109/INFVIS.2003.1249032	241	248	C		Daniel C. Glaser;Roger Tan;John F. Canny;Ellen Yi-Luen Do	U.C. Berkeley		information visualization, qualitative analysis, ethnographic fieldwork, architectural lighting design, energy efficiency	Interdisciplinary Doctoral Program U.C. Berkeley##Interdisciplinary Doctoral Program U.C. Berkeley##Interdisciplinary Doctoral Program U.C. Berkeley##Interdisciplinary Doctoral Program U.C. Berkeley##Interdisciplinary Doctoral Program U.C. Berkeley
Vis	2003	IEEE Visualization 2003 (IEEE Cat. No.03CH37496)	10.1109/VISUAL.2003.1250348	http://dx.doi.org/10.1109/VISUAL.2003.1250348			M		Greg Turk;Jarke J. van Wijk;Robert J. Moorhead II				
Vis	2003	The visualization market: open source vs. commercial approaches	10.1109/VISUAL.2003.1250350	http://dx.doi.org/10.1109/VISUAL.2003.1250350	21	24	M		Jeremy Jaech;Stephen C. North;Mike Peery;Will Schroeder;James J. Thomas	;;;;			
Vis	2003	Exploring curved anatomic structures with surface sections	10.1109/VISUAL.2003.1250351	http://dx.doi.org/10.1109/VISUAL.2003.1250351	27	34	C		Laurent Saroul;Sebastian Gerlach;Roger D. Hersch	Ecole Polytechnique Federale de Lausanne, Switzerland|c|;;	10.1109/VISUAL.2002.1183754	visualization, anatomic structures, curved sections, surface extraction, interactive flattening	Ecole Polytechnique FÃ©dÃ©rale de Lausanne*##Ecole Polytechnique FÃ©dÃ©rale de Lausanne*##Ecole Polytechnique FÃ©dÃ©rale de Lausanne*
Vis	2003	Psychophysical scaling of a cardiovascular information display	10.1109/VISUAL.2003.1250352	http://dx.doi.org/10.1109/VISUAL.2003.1250352	35	42	C		Robert Albert;Noah Syroid;Yinqi Zhang;James Agutter;Frank Drews;David L. Strayer;George Hutchinson;Dwayne R. Westenskow	Appl. Med. Visualizations, West Valley, UT, USA|c|;;;;;;;	10.1109/INFVIS.2001.963295	Psychophysical Scaling, Anesthesia, Patient Vital Sign Monitor	University of Utah####University of Utah##University of Utah##General Electric Medical Systems##University of Utah
Vis	2003	Advanced curved planar reformation: flattening of vascular structures	10.1109/VISUAL.2003.1250353	http://dx.doi.org/10.1109/VISUAL.2003.1250353	43	50	C		Armin Kanitsar;Rainer Wegenkittl;Dominik Fleischmann;Eduard Gröller	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;	10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2001.964555;10.1109/VISUAL.2001.964538	computed tomography angiography, vessel analysis, curved planar reformation	TIANI Medgraph Vienna University of Technology Stanford University##TIANI Medgraph Vienna University of Technology Stanford University##TIANI Medgraph Vienna University of Technology Stanford University##TIANI Medgraph Vienna University of Technology Stanford University##TIANI Medgraph Vienna University of Technology Stanford University
Vis	2003	Counting cases in marching cubes: toward a generic algorithm for producing substitopes	10.1109/VISUAL.2003.1250354	http://dx.doi.org/10.1109/VISUAL.2003.1250354	51	58	C		David C. Banks;Stephen A. Linton	Florida State Univ., Gainesville, FL, USA|c|;	10.1109/VISUAL.2000.885704;10.1109/VISUAL.1997.663886;10.1109/VISUAL.1996.568103;10.1109/VISUAL.1996.568121;10.1109/VISUAL.1995.480806;10.1109/VISUAL.1991.175780;10.1109/VISUAL.1997.663887;10.1109/VISUAL.2001.964564	level set, isosurface, orbit, group action, Marching Cubes, separating surfaces, geometric substitution, substitope	Florida State University##Florida State University
Vis	2003	MC<sup>*</sup>: star functions for marching cubes	10.1109/VISUAL.2003.1250355	http://dx.doi.org/10.1109/VISUAL.2003.1250355	59	66	C		Gregory M. Nielson	Arizona State Univ., Tempe, AZ, USA|c|	10.1109/VISUAL.1991.175782	 Marching Cubes, isosurfaces, triangular mesh	Arizona State University
Vis	2003	Extraction of topologically simple isosurfaces from volume datasets	10.1109/VISUAL.2003.1250356	http://dx.doi.org/10.1109/VISUAL.2003.1250356	67	74	C		Andrzej Szymczak;James Vanderhyde	Georgia Tech, USA|c|;	10.1109/VISUAL.2002.1183774;10.1109/VISUAL.2000.885703;10.1109/VISUAL.2000.885704	 Isosurface, Topology, Genus	Georgia Tech, USA|c|;
Vis	2003	Interactive deformation and visualization of level set surfaces using graphics hardware	10.1109/VISUAL.2003.1250357	http://dx.doi.org/10.1109/VISUAL.2003.1250357	75	82	C		Aaron E. Lefohn;Joe Michael Kniss;Charles D. Hansen;Ross T. Whitaker	Sch. of Comput. & Imaging Inst., Utah Univ., Salt Lake, UT, USA|c|;;;	10.1109/VISUAL.2002.1183766;10.1109/VISUAL.2003.1250412;10.1109/VISUAL.2003.1250369	Deformable Models, Image Segmentation, Volume Visualization, GPU, Level Sets, Streaming Computation	University of Utah##University of Utah##University of Utah##University of Utah
Vis	2003	Signed distance transform using graphics hardware	10.1109/VISUAL.2003.1250358	http://dx.doi.org/10.1109/VISUAL.2003.1250358	83	90	C		Christian Sigg;Ronald Peikert;Markus H. Gross	Dept. of Comput. Sci., ETH Zurich, Switzerland|c|;;	10.1109/VISUAL.2001.964518;10.1109/VISUAL.2001.964517	Distance field, distance transform, Voronoi diagram, fragment program, scan conversion	Dept. of Comput. Sci., ETH Zurich, Switzerland|c|;;
Vis	2003	Piecewise C<sup>1</sup> continuous surface reconstruction of noisy point clouds via local implicit quadric regression	10.1109/VISUAL.2003.1250359	http://dx.doi.org/10.1109/VISUAL.2003.1250359	91	98	C		Hui Xie;Jianning Wang;Jing Hua;Hong Qin;Arie E. Kaufman	Dept. of Comput. Sci., Stony Brook univrsity, NY, USA|c|;;;;	10.1109/VISUAL.2001.964489	Computer Graphics, Surface Reconstruction, Point Cloud, Surface Representation, Solid Modeling, Moving Least Squares, Shepard's Method	Stony Brook University##Stony Brook University##Stony Brook University##Stony Brook University##Stony Brook University
Vis	2003	Feature-sensitive subdivision and isosurface reconstruction	10.1109/VISUAL.2003.1250360	http://dx.doi.org/10.1109/VISUAL.2003.1250360	99	106	C		Gokul Varadhan;Shankar Krishnan;Young J. Kim;Dinesh Manocha	North Carolina Univ., Chapel Hill, NC, USA|c|;;;	10.1109/VISUAL.2001.964518;10.1109/VISUAL.1996.568127	Implicit modeling, Boolean operations, Marching Cubes, Distance fields, Subdivision	University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill
Vis	2003	A texture-based framework for spacetime-coherent visualization of time-dependent vector fields	10.1109/VISUAL.2003.1250361	http://dx.doi.org/10.1109/VISUAL.2003.1250361	107	114	C		Daniel Weiskopf;Gordon Erlebacher;Thomas Ertl	Inst. of Visualization & Interactive Syst., Stuttgart Univ., Germany|c|;;	10.1109/VISUAL.2001.964493;10.1109/VISUAL.1999.809906	 time-dependent vector fields, unsteady flow visualization, LIC, texture advection, hardware acceleration	University of Stuttgart##Florida State University##University of Stuttgart
Vis	2003	Effectively visualizing multi-valued flow data using color and texture	10.1109/VISUAL.2003.1250362	http://dx.doi.org/10.1109/VISUAL.2003.1250362	115	121	C		Timothy Urness;Victoria Interrante;Ivan Marusic;Ellen Longmire;Bharathram Ganapathisubramani	Dept. of Comput. Sci. & Eng., Minnesota Univ., USA|c|;;;;	10.1109/VISUAL.1999.809905;10.1109/VISUAL.1997.663897;10.1109/VISUAL.1996.568118;10.1109/VISUAL.2002.1183788;10.1109/VISUAL.1996.567784;10.1109/VISUAL.1998.745294;10.1109/VISUAL.1998.745292	flow visualization, line integral convolution, multi-variate data visualization, color, texture	Mechanics University of Minnesota##Mechanics University of Minnesota##Mechanics University of Minnesota
Vis	2003	Image based flow visualization for curved surfaces	10.1109/VISUAL.2003.1250363	http://dx.doi.org/10.1109/VISUAL.2003.1250363	123	130	C		Jarke J. van Wijk	Dept. of Math. & Comput. Sci., Technische Universiteit Eindhoven, Netherlands|c|	10.1109/VISUAL.2002.1183805;10.1109/VISUAL.1995.480817;10.1109/VISUAL.2003.1250377;10.1109/VISUAL.2000.885689;10.1109/VISUAL.1999.809896;10.1109/VISUAL.2001.964493;10.1109/VISUAL.1995.480795	Flow visualization, texture mapping, line integral convolution, surface rendering	Technische Universiteit Eindhoven
Vis	2003	Image space based visualization of unsteady flow on surfaces	10.1109/VISUAL.2003.1250364	http://dx.doi.org/10.1109/VISUAL.2003.1250364	131	138	C		Robert S. Laramee;Bruno Jobard;Helwig Hauser	VRVis Res. Center, Graz, Austria|c|;;	10.1109/VISUAL.2001.964493;10.1109/VISUAL.1994.346313;10.1109/VISUAL.1995.480817	Unsteady flow visualization, computational fluid dynamics (CFD), surface representation, texture mapping	Helwig Hauser â€ â€ VRVis Research Center##University of Pau
Vis	2003	A multi-resolution data structure for two-dimensional Morse-Smale functions	10.1109/VISUAL.2003.1250365	http://dx.doi.org/10.1109/VISUAL.2003.1250365	139	146	C		Peer-Timo Bremer;Herbert Edelsbrunner;Bernd Hamann;Valerio Pascucci	Center for Image Process. & Integrated Comput., California Univ., Davis, CA, USA|c|;;;	10.1109/VISUAL.1998.745314;10.1109/VISUAL.2000.885703	Critical point theory, Morse-Smale complexes, terrains, simplification, multi-resolution data structure	University of California##Lawrence Livermore National Laboratory
Vis	2003	Planet-sized batched dynamic adaptive meshes (P-BDAM)	10.1109/VISUAL.2003.1250366	http://dx.doi.org/10.1109/VISUAL.2003.1250366	147	154	C		Paolo Cignoni;Fabio Ganovelli;Enrico Gobbetti;Fabio Marton;Federico Ponchio;Roberto Scopigno	ISTI - CNR, Pisa, Italy|c|;;;;;	10.1109/VISUAL.1997.663860;10.1109/VISUAL.2002.1183783;10.1109/VISUAL.1997.663902;10.1109/VISUAL.1998.745282;10.1109/VISUAL.2000.885699;10.1109/VISUAL.2002.1183800;10.1109/VISUAL.1996.567600;10.1109/VISUAL.1998.745280;10.1109/VISUAL.1999.809902;10.1109/VISUAL.1996.568126	 Multiresolution, terrains, huge dataset	ISTI -CNR##ISTI -CNR##ISTI -CNR##ISTI -CNR##ISTI -CNR
Vis	2003	Real-time refinement and simplification of adaptive triangular meshes	10.1109/VISUAL.2003.1250367	http://dx.doi.org/10.1109/VISUAL.2003.1250367	155	162	C		Vasily Volkov;Ling Li	Moscow Inst. of Phys. & Technol., Russia|c|;	10.1109/VISUAL.2002.1183796;10.1109/VISUAL.2000.885705;10.1109/VISUAL.1997.663860;10.1109/VISUAL.2001.964533;10.1109/VISUAL.1996.568126;10.1109/VISUAL.1998.745282	adaptive meshes, refinement and simplification, subdivision, multiresoluton, level of detail, frame-to-frame coherence, out-of-core visualization	Moscow Institute of Physics and Technology##Moscow Institute of Physics and Technology
Vis	2003	Interactive view-dependent rendering with conservative occlusion culling in complex environments	10.1109/VISUAL.2003.1250368	http://dx.doi.org/10.1109/VISUAL.2003.1250368	163	170	C		Sung-Eui Yoon;Brian Salomon;Dinesh Manocha	North Carolina Univ., Chapel Hill, NC, USA|c|;;	10.1109/VISUAL.2002.1183760;10.1109/VISUAL.2001.964534;10.1109/VISUAL.2002.1183796	Interactive Display, View-Dependent Rendering, Occlusion Culling, Level of Detail, Multiresolution Hierarchies	University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill
Vis	2003	Fast volume segmentation with simultaneous visualization using programmable graphics hardware	10.1109/VISUAL.2003.1250369	http://dx.doi.org/10.1109/VISUAL.2003.1250369	171	176	C		Anthony J. Sherbondy;Michael Houston;Sandy Napel	Stanford Univ., CA, USA|c|;;	10.1109/VISUAL.2003.1250357	 region growing, diffusion, segmentation, graphics processor, streaming computation	Stanford University##Stanford University##Stanford University
Vis	2003	Hybrid segmentation and exploration of the human lungs	10.1109/VISUAL.2003.1250370	http://dx.doi.org/10.1109/VISUAL.2003.1250370	177	184	C		Dirk Bartz;Dirk Mayer;Jan Fischer;Sebastian Ley;Ángel del Río;Steffi Thust;Claus Peter Heussel;Hans-Ulrich Kauczor;Wolfgang Straßer	Visual Comput. for Medicine, Eberhard-Karls-Univ. Tubingen, Germany|c|;;;;;;;;	10.1109/VISUAL.2000.885732	Tracheo-bronchial tree, segmentation, multi-slice CT, virtual endoscopy	Johannes-Gutenberg-University Mainz Mainz####Johannes-Gutenberg-University Mainz Mainz####Johannes-Gutenberg-University Mainz Mainz##Johannes-Gutenberg-University Mainz Mainz##Johannes-Gutenberg-University Mainz Mainz##WSI/GRIS Eberhard-Karls-University TÃ¼bingen TÃ¼bingen
Vis	2003	Feature-space analysis of unstructured meshes	10.1109/VISUAL.2003.1250371	http://dx.doi.org/10.1109/VISUAL.2003.1250371	185	192	C		Ariel Shamir	The Interdisciplinary Center, Herzliya, Israel|c|	10.1109/VISUAL.1999.809869;10.1109/VISUAL.1998.745312;10.1109/VISUAL.2001.964519;10.1109/VISUAL.1997.663875	unstructured meshes, segmentation, clustering, feature-extraction, mean-shift	The Interdisciplinary Center, Herzliya, Israel|c|
Vis	2003	Clifford convolution and pattern matching on vector fields	10.1109/VISUAL.2003.1250372	http://dx.doi.org/10.1109/VISUAL.2003.1250372	193	200	C		Julia Ebling;Gerik Scheuermann	Kaiserslautern, Germany|c|;	10.1109/VISUAL.2000.885716;10.1109/VISUAL.1997.663858	 Flow Visualization, Convolution, Pattern Matching	University of Kaiserslautern##University of Kaiserslautern
Vis	2003	Space efficient fast isosurface extraction for large datasets	10.1109/VISUAL.2003.1250373	http://dx.doi.org/10.1109/VISUAL.2003.1250373	201	208	C		Udeepta Bordoloi;Han-Wei Shen	Dept. of Comput. & Inf. Sci., Ohio State Univ., USA|c|;	10.1109/VISUAL.1998.745299;10.1109/VISUAL.1997.663895;10.1109/VISUAL.1996.568121;10.1109/VISUAL.1991.175780;10.1109/VISUAL.1995.480806	 Isosurface, Compression, Transform Coding, Quantization	The Ohio State University##The Ohio State University
Vis	2003	Volume tracking using higher dimensional isosurfacing	10.1109/VISUAL.2003.1250374	http://dx.doi.org/10.1109/VISUAL.2003.1250374	209	216	C		Guangfeng Ji;Han-Wei Shen;Rephael Wenger	Dept. of Comput. & Inf. Sci., Ohio State Univ., USA|c|;;	10.1109/VISUAL.2000.885704;10.1109/VISUAL.1998.745288;10.1109/VISUAL.1996.568103;10.1109/VISUAL.2002.1183774;10.1109/VISUAL.1996.567807;10.1109/VISUAL.2000.885703;10.1109/VISUAL.1995.480789;10.1109/VISUAL.1997.663886	tracking, isosurface, interval volume, higher dimensional isosurfacing	The Ohio State University##The Ohio State University##The Ohio State University
Vis	2003	Out-of-core isosurface extraction of time-varying fields over irregular grids	10.1109/VISUAL.2003.1250375	http://dx.doi.org/10.1109/VISUAL.2003.1250375	217	224	C		Yi-Jen Chiang	Dept. of Comput. & Inf. Sci., Polytech. Univ., Brooklyn, NY, USA|c|	10.1109/VISUAL.1995.480806;10.1109/VISUAL.1998.745299;10.1109/VISUAL.1997.663895;10.1109/VISUAL.1996.568121;10.1109/VISUAL.2003.1250373;10.1109/VISUAL.1997.663888;10.1109/VISUAL.1998.745298	isosurface extraction, out-of-core techniques, time-varying fields, irregular grids	Polytechnic University
Vis	2003	Saddle connectors - an approach to visualizing the topological skeleton of complex 3D vector fields	10.1109/VISUAL.2003.1250376	http://dx.doi.org/10.1109/VISUAL.2003.1250376	225	232	C		Holger Theisel;Tino Weinkauf;Hans-Christian Hege;Hans-Peter Seidel	MPI Informatik Saarbrucken, Germany|c|;;;	10.1109/VISUAL.2000.885714;10.1109/VISUAL.1999.809874;10.1109/VISUAL.1998.745284;10.1109/VISUAL.1998.745291;10.1109/VISUAL.1999.809907;10.1109/VISUAL.1992.235211;10.1109/VISUAL.1993.398875;10.1109/VISUAL.2001.964506;10.1109/VISUAL.2000.885716;10.1109/VISUAL.2001.964507	3D flow visualization, vector field topology, critical points, separatrices	MPI Informatik SaarbrÃ¼cken##
Vis	2003	3D IBFV: hardware-accelerated 3D flow visualization	10.1109/VISUAL.2003.1250377	http://dx.doi.org/10.1109/VISUAL.2003.1250377	233	240	C		Alexandru Telea;Jarke J. van Wijk	Dept. of Math. & Comput. Sci., Technische Universiteit Eindhoven, Netherlands|c|;	10.1109/VISUAL.1999.809892;10.1109/VISUAL.1997.663897	Flow Visualization, Hardware Acceleration, Texture Advection, OpenGL	Technische Universiteit Eindhoven##Technische Universiteit Eindhoven
Vis	2003	Chameleon: an interactive texture-based rendering framework for visualizing three-dimensional vector fields	10.1109/VISUAL.2003.1250378	http://dx.doi.org/10.1109/VISUAL.2003.1250378	241	248	C		Guo-Shi Li;Udeepta Bordoloi;Han-Wei Shen	Dept. of Comput. & Inf. Sci., Ohio State Univ., USA|c|;;	10.1109/VISUAL.1996.567784;10.1109/VISUAL.1993.398846;10.1109/VISUAL.1993.398877;10.1109/VISUAL.1992.235211;10.1109/VISUAL.1996.567777;10.1109/VISUAL.1997.663912	3D flow visualization, vector field visualization, volume rendering, texture mapping	Dept. of Comput. & Inf. Sci., Ohio State Univ., USA|c|;;
Vis	2003	HyperLIC	10.1109/VISUAL.2003.1250379	http://dx.doi.org/10.1109/VISUAL.2003.1250379	249	256	C		Xiaoqiang Zheng;Alex T. Pang	Comput. Sci. Dept., California Univ., Santa Cruz, CA, USA|c|;	10.1109/VISUAL.2002.1183797;10.1109/VISUAL.2002.1183799;10.1109/VISUAL.1997.663912;10.1109/VISUAL.1999.809886	 hyperstreamlines, LIC, symmetric tensors, anisotropy, animation, direct volume rendering	University of California##University of California
Vis	2003	Quasi-static approach approximation for 6 degrees-of-freedom haptic rendering	10.1109/VISUAL.2003.1250380	http://dx.doi.org/10.1109/VISUAL.2003.1250380	257	262	C		Ming Wan;William A. McNeely	The Boeing Co., Seattle, WA, USA|c|;	10.1109/VISUAL.2000.885687	6-DOF haptics, physically based modeling, voxel sampling, quasi-static approximation, virtual coupling	The Boeing Co., Seattle, WA, USA|c|;
Vis	2003	A constraint-based technique for haptic volume exploration	10.1109/VISUAL.2003.1250381	http://dx.doi.org/10.1109/VISUAL.2003.1250381	263	269	C		Milan Ikits;J. Dean Brederson;Charles D. Hansen;Christopher R. Johnson 0001	Sci. Comput. & Imaging Inst., Utah Univ., USA|c|;;;	10.1109/VISUAL.2001.964545;10.1109/VISUAL.2000.885686;10.1109/VISUAL.1996.568108	haptic rendering, immersive visualization, human-computer interaction	University of Utah##University of Utah##University of Utah##University of Utah
Vis	2003	Voxels on fire	10.1109/VISUAL.2003.1250382	http://dx.doi.org/10.1109/VISUAL.2003.1250382	271	278	C		Ye Zhao;Xiaoming Wei;Zhe Fan;Arie E. Kaufman;Hong Qin	Center for Visual Comput., Stony Brook Univ., NY, USA|c|;;;;	10.1109/VISUAL.2002.1183779;10.1109/VISUAL.1993.398879	Fire Propagation, Distance Field, Lattice Boltzmann Model, Splatting, GPU Acceleration	Stony Brook University Stony Brook##Stony Brook University Stony Brook##Stony Brook University Stony Brook##Stony Brook University Stony Brook##Stony Brook University Stony Brook
Vis	2003	Visually accurate multi-field weather visualization	10.1109/VISUAL.2003.1250383	http://dx.doi.org/10.1109/VISUAL.2003.1250383	279	286	C		Kirk Riley;David S. Ebert;Charles D. Hansen;Jason J. Levit	Purdue Univ., West Lafayette, IN, USA|c|;;;		Multi-Field Visualization, Visually Accurate Visualization, Weather Visualization	Purdue Univ., West Lafayette, IN, USA|c|;;;
Vis	2003	Acceleration techniques for GPU-based volume rendering	10.1109/VISUAL.2003.1250384	http://dx.doi.org/10.1109/VISUAL.2003.1250384	287	292	C		Jens H. Krüger;Rüdiger Westermann	Comput. Graphics & Visualization Group, Tech. Univ. Munich, Germany|c|;	10.1109/VISUAL.1999.809889;10.1109/VISUAL.1997.663880;10.1109/VISUAL.1993.398852;10.1109/VISUAL.2002.1183764	Volume Rendering, Programmable Graphics Hardware, Ray-Casting	Technical University Munich##Technical University Munich
Vis	2003	Compression domain volume rendering	10.1109/VISUAL.2003.1250385	http://dx.doi.org/10.1109/VISUAL.2003.1250385	293	300	C		Jens Schneider;Rüdiger Westermann	Comput. Graphics & Visualization Group, Tech. Univ. Munich, Germany|c|;	10.1109/VISUAL.1999.809910;10.1109/VISUAL.2002.1183757;10.1109/VISUAL.2001.964520;10.1109/VISUAL.2002.1183771;10.1109/VISUAL.2002.1183764;10.1109/VISUAL.2001.964519	Volume Rendering, Vector Quantization, Texture Compression, Graphics Hardware	Technical University Munich##Technical University Munich
Vis	2003	High-quality two-level volume rendering of segmented data sets on consumer graphics hardware	10.1109/VISUAL.2003.1250386	http://dx.doi.org/10.1109/VISUAL.2003.1250386	301	308	C		Markus Hadwiger;Christoph Berger;Helwig Hauser	VRVis Res. Center, Austria|c|;;	10.1109/VISUAL.1998.745311;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2002.1183777;10.1109/VISUAL.2000.885694	volume rendering, segmentation, non-photorealistic rendering, consumer graphics hardware	VRVis Res. Center, Austria|c|;;
Vis	2003	Hardware-based nonlinear filtering and segmentation using high-level shading languages	10.1109/VISUAL.2003.1250387	http://dx.doi.org/10.1109/VISUAL.2003.1250387	309	316	C		Ivan Viola;Armin Kanitsar;Eduard Gröller	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;	10.1109/VISUAL.2002.1183766;10.1109/VISUAL.2002.1183762;10.1109/VISUAL.1999.809934	 Non-linear Filtering, Segmentation, Hardware Acceleration	Vienna University of Technology##Vienna University of Technology##Vienna University of Technology##Vienna University of Technology
Vis	2003	Empty space skipping and occlusion clipping for texture-based volume rendering	10.1109/VISUAL.2003.1250388	http://dx.doi.org/10.1109/VISUAL.2003.1250388	317	324	C		Wei Li 0004;Klaus Mueller;Arie E. Kaufman	Dept. of Comput. Sci., Stony Brook Univ., NY, USA|c|;;	10.1109/VISUAL.1992.235231;10.1109/VISUAL.2001.964519;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.1999.809908;10.1109/VISUAL.2002.1183776	Graphics hardware, texture-based volume rendering, empty space skipping, occlusion clipping, orthogonal opacity map	Stony Brook University##Stony Brook University##Stony Brook University
Vis	2003	Hierarchical clustering for unstructured volumetric scalar fields	10.1109/VISUAL.2003.1250389	http://dx.doi.org/10.1109/VISUAL.2003.1250389	325	332	C		Christopher S. Co;Bjørn Heckel;Hans Hagen;Bernd Hamann;Kenneth I. Joy	Dept. of Comput. Sci., Univ. of California, Davis, CA, USA|c|;;;;	10.1109/VISUAL.2001.964503;10.1109/VISUAL.1998.745329;10.1109/VISUAL.1999.809863;10.1109/VISUAL.1996.568127;10.1109/VISUAL.2002.1183771	scalar field simplification, multiresolution data representation, hierarchical clustering, principal component analysis, radial basis function	University of California##University of Kaiserslautern##University of California
Vis	2003	Hardware-based ray casting for tetrahedral meshes	10.1109/VISUAL.2003.1250390	http://dx.doi.org/10.1109/VISUAL.2003.1250390	333	340	C		Manfred Weiler;Martin Kraus;Markus Merz;Thomas Ertl	Visualization & Interactive Syst. Group, Univ. of Stutgart, Germany|c|;;;	10.1109/VISUAL.2000.885683	ray casting, pixel shading, programmable graphics hardware, cell projection, tetrahedral meshes, unstructured meshes, volume visualization, pre-integrated volume rendering	University of Stuttgart##University of Stuttgart##University of Stuttgart##University of Stuttgart
Vis	2003	Visibility culling using plenoptic opacity functions for large volume visualization	10.1109/VISUAL.2003.1250391	http://dx.doi.org/10.1109/VISUAL.2003.1250391	341	348	C		Jinzhu Gao;Jian Huang;Han-Wei Shen;James Arthur Kohl	Ohio State Univ., USA|c|;;;	10.1109/VISUAL.2002.1183757;10.1109/VISUAL.2002.1183784;10.1109/VISUAL.1998.745713;10.1109/VISUAL.2001.964519;10.1109/VISUAL.1998.745300;10.1109/VISUAL.2001.964515;10.1109/VISUAL.2000.885698	visibility culling, volume rendering, plenoptic opacity function, large data visualization	The Ohio State Univ##The Ohio State Univ##The Ohio State Univ##The Ohio State Univ
Vis	2003	Conveying shape and features with image-based relighting	10.1109/VISUAL.2003.1250392	http://dx.doi.org/10.1109/VISUAL.2003.1250392	349	354	C		David Akers;Frank Losasso;Jeff Klingner;Maneesh Agrawala;John Rick;Pat Hanrahan	Stanford Univ., USA|c|;;;;;		Visualization, Relighting, Image Composition, Scientfic Illustration, Technical Illustration, Photography, Lighting Design	Stanford University##Stanford University##Stanford University##Stanford University##Stanford University##Stanford University
Vis	2003	Vicinity shading for enhanced perception of volumetric data	10.1109/VISUAL.2003.1250394	http://dx.doi.org/10.1109/VISUAL.2003.1250394	355	362	C		A. James Stewart	Sch. of Comput., Queen''s Univ., Kingston, Ont., Canada|c|	10.1109/VISUAL.2002.1183761;10.1109/VISUAL.2002.1183764	volume rendering, shading model, diffuse illumination, perceptual cues	Sch. of Comput., Queen''s Univ., Kingston, Ont., Canada|c|
Vis	2003	LightKit: a lighting system for effective visualization	10.1109/VISUAL.2003.1250395	http://dx.doi.org/10.1109/VISUAL.2003.1250395	363	370	C		Michael Halle;Jeanette C. Meng	Harvard Med. Sch., Harvard Univ., USA|c|;	10.1109/VISUAL.2002.1183785	Visualization, lighting design, light color	Harvard Med. Sch., Harvard Univ., USA|c|;
Vis	2003	Mental registration of 2D and 3D visualizations (an empirical study)	10.1109/VISUAL.2003.1250396	http://dx.doi.org/10.1109/VISUAL.2003.1250396	371	378	C		Melanie Tory	Sch. of Comput. Sci., Simon Fraser Univ., USA|c|	10.1109/VISUAL.1992.235203;10.1109/VISUAL.1997.663914	2D and 3D visualization, mental registration,slice, orthographic projection, empirical study, experiment	Simon Fraser University
Vis	2003	Visualization of noisy and biased volume data using first and second order derivative techniques	10.1109/VISUAL.2003.1250397	http://dx.doi.org/10.1109/VISUAL.2003.1250397	379	385	C		Marc P. Persoon;Iwo Serlie;Frits H. Post;Roel Truyen;Frans Vos	Comput. Graphics & CAD/CAM Group, Delft Univ. of Technol., Netherlands|c|;;;;		virtual colonoscopy, bias field, medical imaging, surface extraction, direct volume rendering	Delft University of Technology##Delft University of Technology##Delft University of Technology####Delft University of Technology##
Vis	2003	Fairing scalar fields by variational modeling of contours	10.1109/VISUAL.2003.1250398	http://dx.doi.org/10.1109/VISUAL.2003.1250398	387	392	C		Martin Hering-Bertram	Univ. of Kaiserslautern, Germany|c|		Contours, Fairing, Variational Modeling	University of Kaiserslautern
Vis	2003	Visualization of volume data with quadratic super splines	10.1109/VISUAL.2003.1250399	http://dx.doi.org/10.1109/VISUAL.2003.1250399	393	400	C		Christian Rössl;Frank Zeilfelder;Günther Nürnberger;Hans-Peter Seidel	Max-Planck-Inst. fur Informatik, Saarbrucken, Germany|c|;;;	10.1109/VISUAL.1998.745713;10.1109/VISUAL.1997.663907;10.1109/VISUAL.1996.567602;10.1109/VISUAL.1994.346331;10.1109/VISUAL.2001.964530;10.1109/VISUAL.2001.964499	volume rendering, reconstruction, quadratic super splines, tetrahedral partition, Bernstein-Bezier techniques, isosurface rendering, ray-casting	UniversitÃ¤t Mannheim##UniversitÃ¤t Mannheim####
Vis	2003	Using deformations for browsing volumetric data	10.1109/VISUAL.2003.1250400	http://dx.doi.org/10.1109/VISUAL.2003.1250400	401	408	C		Michael J. McGuffin;Liviu Tancau;Ravin Balakrishnan	Dept. of Comput. Sci., Univ. of Toronto, Ont., Canada|c|;;		volumetric data, volume data, deformations, browsing, layers, interaction techniques, 3D widgets	University of Toronto##University of Toronto##University of Toronto
Vis	2003	Video visualization	10.1109/VISUAL.2003.1250401	http://dx.doi.org/10.1109/VISUAL.2003.1250401	409	416	C		Gareth Daniel;Min Chen	Univ. of Wales Swansea, UK|c|;	10.1109/VISUAL.2002.1183790	 Video visualization, volume rendering, video surveillance, change detection, image-swept volume	University of Wales Swansea##University of Wales Swansea
Vis	2003	High dimensional direct rendering of time-varying volumetric data	10.1109/VISUAL.2003.1250402	http://dx.doi.org/10.1109/VISUAL.2003.1250402	417	424	C		Jonathan Woodring;Chaoli Wang;Han-Wei Shen	Ohio State Univ., USA|c|;;	10.1109/VISUAL.2001.964519;10.1109/VISUAL.1993.398869;10.1109/VISUAL.1992.235222	time-varying data, hyperslice, hyperprojection, integration operator, transfer function, raycasting, volume rendering	The Ohio State University##The Ohio State University##The Ohio State University
Vis	2003	A frequency-sensitive point hierarchy for images and volumes	10.1109/VISUAL.2003.1250403	http://dx.doi.org/10.1109/VISUAL.2003.1250403	425	432	C		Tomihisa Welsh;Klaus Mueller	Center for Visual Comput., Comput. Sci., Stony Brook Univ., USA|c|;	10.1109/VISUAL.2002.1183770;10.1109/VISUAL.2001.964498;10.1109/VISUAL.2002.1183776;10.1109/VISUAL.2001.964492;10.1109/VISUAL.2001.964491;10.1109/VISUAL.2002.1183757	volume rendering, point-based rendering, splatting	Center for Visual Comput., Comput. Sci., Stony Brook Univ., USA|c|;
Vis	2003	Hierarchical splatting of scattered data	10.1109/VISUAL.2003.1250404	http://dx.doi.org/10.1109/VISUAL.2003.1250404	433	440	C		Matthias Hopf;Thomas Ertl	Visualization & Interactive Syst. Group, Univ. of Stuttgart, Germany|c|;	10.1109/VISUAL.1997.663882;10.1109/VISUAL.2002.1183820;10.1109/VISUAL.1999.809909;10.1109/VISUAL.2001.964490;10.1109/VISUAL.2001.964489;10.1109/VISUAL.2002.1183771	Volume Rendering, Scattered Data, Splatting, Hierarchical Visualization	University of Stuttgart##University of Stuttgart
Vis	2003	A framework for sample-based rendering with O-buffers	10.1109/VISUAL.2003.1250405	http://dx.doi.org/10.1109/VISUAL.2003.1250405	441	448	C		Huamin Qu;Arie E. Kaufman;Ran Shao;Ankush Kumar	Dept. of Comput. Sci., Stony Brook Univ., NY, USA|c|;;;	10.1109/VISUAL.2001.964492;10.1109/VISUAL.1999.809869;10.1109/VISUAL.1998.745312;10.1109/VISUAL.2000.885680;10.1109/VISUAL.2001.964491;10.1109/VISUAL.2000.885702	Sample-based rendering, image-based rendering, hybrid rendering, irregular sampling, hierarchy, offset, frame buffer, layered depth image	Stony Brook University##Stony Brook University##Stony Brook University##Stony Brook University
Vis	2003	Monte Carlo volume rendering	10.1109/VISUAL.2003.1250406	http://dx.doi.org/10.1109/VISUAL.2003.1250406	449	456	C		Balázs Csébfalvi;László Szirmay-Kalos	Dept. of Control Eng. & Inf. Technol., Budapest Tech. Univ., Hungary|c|;	10.1109/VISUAL.2002.1183757;10.1109/VISUAL.2001.964490;10.1109/VISUAL.2002.1183777	 X-ray volume rendering, Monte Carlo integration, importance sampling, progressive refinement	Technical University of Budapest##
Vis	2003	Visibility based methods and assessment for detail-recovery	10.1109/VISUAL.2003.1250407	http://dx.doi.org/10.1109/VISUAL.2003.1250407	457	464	C		Marco Tarini;Paolo Cignoni;Roberto Scopigno	ISTI, CNR, Pisa, Italy|c|;;	10.1109/VISUAL.2002.1183784;10.1109/VISUAL.1998.745285	simplification, texture mapping, detail recovery, normal mapping, texture for geometry	Istituto di Scienza e Tecnologie dell'Informazione -Consiglio Nazionale delle Ricerche##Istituto di Scienza e Tecnologie dell'Informazione -Consiglio Nazionale delle Ricerche##Istituto di Scienza e Tecnologie dell'Informazione -Consiglio Nazionale delle Ricerche
Vis	2003	Large mesh simplification using processing sequences	10.1109/VISUAL.2003.1250408	http://dx.doi.org/10.1109/VISUAL.2003.1250408	465	472	C		Martin Isenburg;Peter Lindstrom;Stefan Gumhold;Jack Snoeyink	North Carolina Univ., Chapel Hill, NC, USA|c|;;;	10.1109/VISUAL.2001.964502;10.1109/VISUAL.2001.964503;10.1109/VISUAL.1996.568125;10.1109/VISUAL.1998.745282;10.1109/VISUAL.2001.964532;10.1109/VISUAL.2002.1183765	Out-of-core algorithms, processing sequences, mesh simplification, large meshes	University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill
Vis	2003	Appearance-preserving view-dependent visualization	10.1109/VISUAL.2003.1250409	http://dx.doi.org/10.1109/VISUAL.2003.1250409	473	480	C		Justin Jang;William Ribarsky;Chris Shaw 0002;Peter Wonka	GVU Center, Georgia Inst. of Technol., Atlanta, Georgia|c|;;;	10.1109/VISUAL.1998.745342;10.1109/VISUAL.1999.809869;10.1109/VISUAL.1998.745312;10.1109/VISUAL.1999.809924;10.1109/VISUAL.2002.1183760	 view-dependent, level of detail, mesh simplification, appearance-preserving, multiresolution models	GVU Center##GVU Center##GVU Center##GVU Center
Vis	2003	Shape simplification based on the medial axis transform	10.1109/VISUAL.2003.1250410	http://dx.doi.org/10.1109/VISUAL.2003.1250410	481	488	C		Roger C. Tam;Wolfgang Heidrich	Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC, Canada|c|;		medial axis transform, shape simplification, topology preservation	University of British Columbia##University of British Columbia
Vis	2003	Adaptive design of a global opacity transfer function for direct volume rendering of ultrasound data	10.1109/VISUAL.2003.1250411	http://dx.doi.org/10.1109/VISUAL.2003.1250411	489	496	C		Dieter Hönigmann;Johannes Ruisz;Christoph Haider	Adv. Comput. Vision GmbH, ACV, Vienna, Austria|c|;;	10.1109/VISUAL.1997.663875;10.1109/VISUAL.1996.568113	3D ultrasound, direct volume rendering, transfer function	Advanced Computer Vision GmbH â€“ ACV##Advanced Computer Vision GmbH â€“ ACV##Advanced Computer Vision GmbH â€“ ACV##Advanced Computer Vision GmbH â€“ ACV
Vis	2003	Gaussian transfer functions for multi-field volume visualization	10.1109/VISUAL.2003.1250412	http://dx.doi.org/10.1109/VISUAL.2003.1250412	497	504	C		Joe Michael Kniss;Simon Premoze;Milan Ikits;Aaron E. Lefohn;Charles D. Hansen;Emil Praun	Inst. of Sci. Comput. & Imaging, Utah Univ., Salt Lake, UT, USA|c|;;;;;	10.1109/VISUAL.1999.809889;10.1109/VISUAL.2000.885683;10.1109/VISUAL.2001.964521	Volume Rendering, Transfer Functions, Multi-field visualization	University of Utah##University of Utah##University of Utah##University of Utah##University of Utah##University of Utah
Vis	2003	A novel interface for higher-dimensional classification of volume data	10.1109/VISUAL.2003.1250413	http://dx.doi.org/10.1109/VISUAL.2003.1250413	505	512	C		Fan-Yin Tzeng;Eric B. Lum;Kwan-Liu Ma	Dept. of Comput. Sci., California Univ., Davis, CA, USA|c|;;	10.1109/VISUAL.1998.745319;10.1109/VISUAL.2001.964519;10.1109/VISUAL.1999.809932;10.1109/VISUAL.1997.663875;10.1109/VISUAL.1996.568113	classification, graphics hardware, interactive visualization, multidimensional transfer function, neural network, user interface design, volume visualization	University of California at Davis##University of California at Davis##University of California at Davis
Vis	2003	Curvature-based transfer functions for direct volume rendering: methods and applications	10.1109/VISUAL.2003.1250414	http://dx.doi.org/10.1109/VISUAL.2003.1250414	513	520	C		Gordon L. Kindlmann;Ross T. Whitaker;Tolga Tasdizen;Torsten Möller	Inst. of Sci. Comput. & Imaging, Utah Univ., Salt Lake, UT, USA|c|;;;	10.1109/VISUAL.2000.885696;10.1109/VISUAL.2002.1183766;10.1109/VISUAL.1995.480795;10.1109/VISUAL.2000.885694;10.1109/VISUAL.1994.346331;10.1109/VISUAL.2002.1183777	volume rendering, implicit surface curvature, convolution-based differentiation, non-photorealistic rendering, surface processing, uncertainty visualization, flowline curvature	University of Utah##University of Utah##University of Utah##Simon Fraser University
Vis	2003	A visual exploration process for the analysis of Internet routing data	10.1109/VISUAL.2003.1250415	http://dx.doi.org/10.1109/VISUAL.2003.1250415	523	530	C		Soon Tee Teoh;Kwan-Liu Ma;Shyhtsun Felix Wu	Dept. of Comput. Sci., California Univ., Davis, CA, USA|c|;;	10.1109/VISUAL.2002.1183816	 information visualization, text visualization, network visualization , internet stability, homeland security	University of California##University of California##University of California
Vis	2003	Visualization, optimization, business strategy: a case study	10.1109/VISUAL.2003.1250416	http://dx.doi.org/10.1109/VISUAL.2003.1250416	531	538	C		Donna L. Gresh;Eugene I. Kelton	IBM T.J. Watson Res. Center, Yorktown Heights, NY, USA|c|;	10.1109/INFVIS.2000.885086;10.1109/VISUAL.2002.1183817	visualization, information visualization, optimization, VisAD	IBM T.J. Watson Research Center Eugene I. Kelton â€ IBM Integrated Technology Services
Vis	2003	Interactive 3D visualization of rigid body systems	10.1109/VISUAL.2003.1250417	http://dx.doi.org/10.1109/VISUAL.2003.1250417	539	546	C		Zoltan Konyha;Kresimir Matkovic;Helwig Hauser	VRVis Res. Center, Austria|c|;;	10.1109/VISUAL.1993.398849;10.1109/VISUAL.1995.485141	rigid body dynamics, rigid body simulation, glyph based visualization, iconic visualization, automotive industry	VRVis Res. Center, Austria|c|;;
Vis	2003	Visualizing industrial CT volume data for nondestructive testing applications	10.1109/VISUAL.2003.1250418	http://dx.doi.org/10.1109/VISUAL.2003.1250418	547	554	C		Runzhen Huang;Kwan-Liu Ma;Patrick S. McCormick;William Ward	California Univ., Davis, CA, USA|c|;;;		Computed tomography, feature extraction, hardware-acceleration rendering, image processing, interactive visualization, nondestructive testing and evaluation, scientific visualization, surface modeling, user interface, volume rendering	University of California at Davis##University of California at Davis##University of California at Davis##University of California at Davis
Vis	2003	Visualization of steep breaking waves and thin spray sheets around a ship	10.1109/VISUAL.2003.1250419	http://dx.doi.org/10.1109/VISUAL.2003.1250419	555	559	C		Paul Adams;Douglas Dommermuth	ERDC, Major Shared Resource Center, Vicksburg, MS, USA|c|;	10.1109/VISUAL.1999.809891;10.1109/VISUAL.2000.885704;10.1109/VISUAL.2002.1183821;10.1109/VISUAL.1997.663869	isosurfaces, marching cubes, multilevel parallelism	ERDC, Major Shared Resource Center, Vicksburg, MS, USA|c|;
Vis	2003	Accelerating large data analysis by exploiting regularities	10.1109/VISUAL.2003.1250420	http://dx.doi.org/10.1109/VISUAL.2003.1250420	561	568	C		David Ellsworth;Patrick J. Moran	Adv. Manage. Technol. Inc., NASA Ames Res. Center, Moffett Field, CA, USA|c|;	10.1109/VISUAL.1999.809910;10.1109/VISUAL.1998.745299;10.1109/VISUAL.1997.663888;10.1109/VISUAL.1997.663895;10.1109/VISUAL.1994.346311;10.1109/VISUAL.1999.809879;10.1109/VISUAL.1999.809891;10.1109/VISUAL.1998.745298;10.1109/VISUAL.1992.235219;10.1109/VISUAL.1994.346304;10.1109/VISUAL.1991.175818;10.1109/VISUAL.1995.480821	 regularity finding, data models, object-oriented, C++, templates, scientific visualization, paging, demand-driven evaluation	Management Technologies Incorporated NASA Ames Research Center##Management Technologies Incorporated NASA Ames Research Center
Vis	2003	Visualizing spatial and temporal variability in coastal observatories	10.1109/VISUAL.2003.1250421	http://dx.doi.org/10.1109/VISUAL.2003.1250421	569	574	C		Walter Jiménez;Wagner Toledo Corrêa;Cláudio T. Silva;António M. Baptista	OGI Sch. of Sci. & Eng., Oregon Health & Sci. Univ., Portland, OR, USA|c|;;;	10.1109/VISUAL.1999.809865;10.1109/VISUAL.1999.809908	coastal observatories, environmental observation and forecasting systems, coasts, estuaries, Columbia River	OGI School of Science & Engineering##OGI School of Science & Engineering##OGI School of Science & Engineering##OGI School of Science & Engineering
Vis	2003	Producing high-quality visualizations of large-scale simulation	10.1109/VISUAL.2003.1250422	http://dx.doi.org/10.1109/VISUAL.2003.1250422	575	580	C		Voicu Popescu;Christoph M. Hoffmann;Sami Kilic;Mete Sozen;Scott Meador	Purdue Univ., USA|c|;;;;			ITaP Purdue University##ITaP Purdue University##ITaP Purdue University##ITaP Purdue University##ITaP Purdue University##ITaP Purdue University##ITaP Purdue University
Vis	2003	Interactive protein manipulation	10.1109/VISUAL.2003.1250423	http://dx.doi.org/10.1109/VISUAL.2003.1250423	581	588	C		Oliver Kreylos;Nelson L. Max;Bernd Hamann;Silvia N. Crivelli;E. Wes Bethel	Dept. of Comput. Sci., Univ. of California, Davis, CA, USA|c|;;;;		Protein Structure Prediction, Protein Manipulation, Inverse Kinematics, Molecular Modeling, Molecular Visualization, Interactive Visualization, Computational Science	Dept. of Comput. Sci., Univ. of California, Davis, CA, USA|c|;;;;
Vis	2003	Holographic video display of time-series volumetric medical data	10.1109/VISUAL.2003.1250424	http://dx.doi.org/10.1109/VISUAL.2003.1250424	589	596	C		Wendy Plesniak;Michael Halle;Steven D. Pieper;William M. Wells III;Marianna Jakab;Dominik S. Meier;Stephen A. Benton;Charles R. G. Guttmann;Ron Kikinis	;;;;;;;;		electro-holography, holographic video, computer generated holograms, autostereoscopic display, medical imaging	Isomics, Inc##############
Vis	2003	Heart-muscle fiber reconstruction from diffusion tensor MRI	10.1109/VISUAL.2003.1250425	http://dx.doi.org/10.1109/VISUAL.2003.1250425	597	602	C		Leonid Zhukov;Alan H. Barr	Dept. of Comput. Sci., California Inst. of Technol., USA|c|;	10.1109/VISUAL.2002.1183799;10.1109/VISUAL.1996.567777	 Diffusion tensors, DT-MRI, fiber tracing, adaptive filtering, moving least squares, streamlines	California Institute of Technology##California Institute of Technology
Vis	2003	Which comes first, usability or utility?	10.1109/VISUAL.2003.1250426	http://dx.doi.org/10.1109/VISUAL.2003.1250426	605	606	M		Georges G. Grinstein;Alfred Kobsa;Catherine Plaisant;Ben Shneiderman;John T. Stasko	University of Massachusetts Lowell|c|;;;			University of Massachusetts Lowell|c|;;;
Vis	2003	Interoperability of visualization software and data models is not an achievable goal	10.1109/VISUAL.2003.1250427	http://dx.doi.org/10.1109/VISUAL.2003.1250427	607	610	M		E. Wes Bethel;Greg Abram;John Shalf;Randy Frank;James P. Ahrens;Steven G. Parker;Nagiza F. Samatova;Mark C. Miller	Lawrence Berkeley National Laboratory|c|			Lawrence Berkeley National Laboratory|c|
Vis	2003	Information and scientific visualization: separate but equal or happy together at last	10.1109/VISUAL.2003.1250428	http://dx.doi.org/10.1109/VISUAL.2003.1250428	611	614	M		Theresa-Marie Rhyne;Melanie Tory;Tamara Munzner;Matthew O. Ward;Christopher R. Johnson 0001;David H. Laidlaw	North Carolina State University|c|;;;;;			North Carolina State University|c|;;;;;
Vis	2003	Do I really see a bone?	10.1109/VISUAL.2003.1250429	http://dx.doi.org/10.1109/VISUAL.2003.1250429	615	617	M		Raghu Machiraju;Christopher R. Johnson 0001;Terry S. Yoo;Roger Crawfis;David S. Ebert;Don Stredney	The Ohio State University|c|;;;;;			The Ohio State University|c|;;;;;
Vis	2003	Visualization experiences and issues in deep space exploration	10.1109/VISUAL.2003.1250430	http://dx.doi.org/10.1109/VISUAL.2003.1250430	619	621	M		John R. Wright;Scott Burleigh;Makoto Maruya;Scott Maxwell;René Pischel	Jet Propulsion Laboratory|c|;;;;			Jet Propulsion Laboratory|c|;;;;
InfoVis	2004	A Comparison of the Readability of Graphs Using Node-Link and Matrix-Based Representations	10.1109/INFVIS.2004.1	http://dx.doi.org/10.1109/INFVIS.2004.1	17	24	C		Mohammad Ghoniem;Jean-Daniel Fekete;Philippe Castagliola	Ecole des Mines de Nantes|c|;;	10.1109/INFVIS.2003.1249030	Visualization of graphs, adjacency matrices, node-link representation, readability, evaluation	Ecole des Mines de Nantes##INRIA Futurs/LRI##UniversitÃ© Paris-Sud
InfoVis	2004	A Knowledge Task-Based Framework for Design and Evaluation of Information Visualizations	10.1109/INFVIS.2004.10	http://dx.doi.org/10.1109/INFVIS.2004.10	143	150	C		Robert A. Amar;John T. Stasko	Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA|c|;	10.1109/INFVIS.1995.528686;10.1109/INFVIS.2003.1249032;10.1109/INFVIS.2003.1249030;10.1109/INFVIS.2001.963289;10.1109/INFVIS.2003.1249029;10.1109/VISUAL.1990.146375	Information visualization, analytic gap, theory, framework, evaluation, knowledge tasks	Georgia Institute of Technology Atlanta##Georgia Institute of Technology Atlanta
InfoVis	2004	BinX: Dynamic Exploration of Time Series Datasets Across Aggregation Levels	10.1109/INFVIS.2004.11	http://dx.doi.org/10.1109/INFVIS.2004.11	2	2	M		Lior Berry;Tamara Munzner	University of British Columbia|c|;			University of British Columbia|c|;
InfoVis	2004	Building Highly-Coordinated Visualizations in Improvise	10.1109/INFVIS.2004.12	http://dx.doi.org/10.1109/INFVIS.2004.12	159	166	C		Chris Weaver	Dept. of Comput. Sci., Wisconsin Univ., Madison, WI|c|	10.1109/INFVIS.2002.1173141;10.1109/INFVIS.2000.885086	coordinated queries, coordination, exploratory visualization, multiple views, visual abstraction language	University of Wisconsinâ€“Madison
InfoVis	2004	Capstone Address: Visualization as a Medium for Capturing and Sharing Thoughts	10.1109/INFVIS.2004.13	http://dx.doi.org/10.1109/INFVIS.2004.13	xiii	xiii	M		Steven F. Roth				
InfoVis	2004	Case Study: Visualizing Visualization	10.1109/INFVIS.2004.14	http://dx.doi.org/10.1109/INFVIS.2004.14	r5	r5	M		Frank van Ham	Technische Universiteit Eindhoven|c|			Technische Universiteit Eindhoven|c|
InfoVis	2004	Clutter Reduction in Multi-Dimensional Data Visualization Using Dimension Reordering	10.1109/INFVIS.2004.15	http://dx.doi.org/10.1109/INFVIS.2004.15	89	96	C		Wei Peng;Matthew O. Ward;Elke A. Rundensteiner	Dept. of Comput. Sci., Worcester Polytech. Inst., MA|c|;;	10.1109/INFVIS.2003.1249015;10.1109/VISUAL.1996.567800;10.1109/VISUAL.1990.146386;10.1109/INFVIS.1998.729559;10.1109/VISUAL.1999.809866;10.1109/INFVIS.1996.559215;10.1109/INFVIS.2000.885086	Multidimensional visualization, dimension order, visual clutter, visual structure	Worcester Polytechnic Institute##Worcester Polytechnic Institute##Worcester Polytechnic Institute
InfoVis	2004	Creating and Managing "Lookmarks" in ParaView	10.1109/INFVIS.2004.16	http://dx.doi.org/10.1109/INFVIS.2004.16	19	19	M		Eric T. Stanton;W. Philip Kegelmeyer	Sandia National Laboratories|c|;			Sandia National Laboratories|c|;
InfoVis	2004	Distortion-Based Visualization for Long-Term Continuous Acoustic Monitoring	10.1109/INFVIS.2004.17	http://dx.doi.org/10.1109/INFVIS.2004.17	21	21	M		Fujio Tsutsumi;Norihiko Itoh;Takashi Onoda	Central Research Institute of Electric Power Industry|c|;;			
InfoVis	2004	Dynamic Drawing of Clustered Graphs	10.1109/INFVIS.2004.18	http://dx.doi.org/10.1109/INFVIS.2004.18	191	198	C		Yaniv Frishman;Ayellet Tal	Dept. of Comput. Sci., Technion-Israel Inst. of Technol., Haifa|c|;	10.1109/INFVIS.1999.801859	graph drawing, dynamic layout, mobile objects, software visualization	Technion -Israel Institute of Technology##Technion -Israel Institute of Technology
InfoVis	2004	Evaluating a System for Interactive Exploration of Large, Hierarchically Structured Document Repositories	10.1109/INFVIS.2004.19	http://dx.doi.org/10.1109/INFVIS.2004.19	127	134	C		Michael Granitzer;Wolfgang Kienreich;Vedran Sabol;Keith Andrews;Werner Klieber	Know-Center, Graz|c|;;;;	10.1109/VISUAL.1996.567787;10.1109/INFVIS.1997.636718	information visualisation, navigation, document retrieval, hierarchical repositories, knowledge management, information management, force-directed placement, Voronoi	Technical University Know-Center Graz##Technical University Know-Center Graz##Technical University Know-Center Graz##Technical University Know-Center Graz##Technical University Know-Center Graz##Technical University Know-Center Graz##Technical University Know-Center Graz
InfoVis	2004	A History Mechanism for Visual Data Mining	10.1109/INFVIS.2004.2	http://dx.doi.org/10.1109/INFVIS.2004.2	49	56	C		Matthias Kreuseler;Thomas Nocke;Heidrun Schumann	SD Industries GmbH, Gundelfingen|c|;;	10.1109/INFVIS.1998.729560;10.1109/VISUAL.2002.1183791;10.1109/VISUAL.2000.885676;10.1109/INFVIS.2003.1249009;10.1109/VISUAL.1999.809871	Visual data mining, Visualization, History, Undo/Redo	SD Industries GmbH##University of Rostock Rostock##University of Rostock Rostock
InfoVis	2004	EventScope: Bringing Remote Experience of Mars to the Public through Telepresence	10.1109/INFVIS.2004.20	http://dx.doi.org/10.1109/INFVIS.2004.20	16	16	M		Eben Myers;Peter Coppin;Michael Wagner;Karl Fischer;Luisa Lu;W. Ronald McCloskey;David Seneker	Platform Digital, LLC|c|;;;;;;			Platform Digital, LLC|c|;;;;;;
InfoVis	2004	Expand-Ahead: A Space-Filling Strategy for Browsing Trees	10.1109/INFVIS.2004.21	http://dx.doi.org/10.1109/INFVIS.2004.21	119	126	C		Michael J. McGuffin;Gord Davison;Ravin Balakrishnan	Dept. of Comput. Sci., Toronto Univ., Ont.|c|;;	10.1109/INFVIS.2002.1173148;10.1109/INFVIS.2002.1173152	tree browsing and navigation, focus+context, expand-ahead, automatic expansion, space filling, adaptive user interfaces	University of Toronto##University of Toronto##University of Toronto
InfoVis	2004	Exploring and Visualizing the History of InfoVis	10.1109/INFVIS.2004.22	http://dx.doi.org/10.1109/INFVIS.2004.22	r6	r6	M		Daniel A. Keim;Helmut Barro;Christian Panse;Jörn Schneidewind;Mike Sips	University of Konstanz|c|;;;;			University of Konstanz|c|;;;;
InfoVis	2004	Exploring InfoVis Publication History with Tulip	10.1109/INFVIS.2004.23	http://dx.doi.org/10.1109/INFVIS.2004.23	r10	r10	M		Maylis Delest;Tamara Munzner;David Auber;Jean-Philippe Domenger	Université de Bordeaux I|c|;;;			Université de Bordeaux I|c|;;;
InfoVis	2004	EZEL: a Visual Tool for Performance Assessment of Peer-to-Peer File-Sharing Network	10.1109/INFVIS.2004.25	http://dx.doi.org/10.1109/INFVIS.2004.25	41	48	C		Lucian Voinea;Alexandru Telea;Jarke J. van Wijk	Technische Univ. Eindhoven|c|;;	10.1109/INFVIS.1999.801853;10.1109/INFVIS.1999.801860;10.1109/INFVIS.1999.801852;10.1109/INFVIS.2001.963279;10.1109/INFVIS.1999.801859;10.1109/INFVIS.2002.1173149	process visualization, distributed file systems visualization, P2P file-sharing networks visualization, small displays	Technische Universiteit Eindhoven##Technische Universiteit Eindhoven##Technische Universiteit Eindhoven
InfoVis	2004	faMailiar & Intimacy-Based Email Visualization	10.1109/INFVIS.2004.26	http://dx.doi.org/10.1109/INFVIS.2004.26	14	14	M		Mirko Mandic;Andruid Kerne	Texas A&M University|c|;			Texas A&M University|c|;
InfoVis	2004	GeoTime Information Visualization	10.1109/INFVIS.2004.27	http://dx.doi.org/10.1109/INFVIS.2004.27	25	32	C		Thomas Kapler;William Wright	;	10.1109/INFVIS.2003.1249006	3-D visualization, spatiotemporal, geospatial, interactive visualization, visual data analysis, link analysis	Oculus Info Inc##Oculus Info Inc
InfoVis	2004	Histographs: Interactive Clustering of Stacked Graphs	10.1109/INFVIS.2004.28	http://dx.doi.org/10.1109/INFVIS.2004.28	17	17	M		Pin Ren;Benjamin Watson	Northwestern University|c|;			Northwestern University|c|;
InfoVis	2004	Hypothesis Visualization	10.1109/INFVIS.2004.29	http://dx.doi.org/10.1109/INFVIS.2004.29	4	4	M		Diane Cluxton;Stephen G. Eick;Jie Yun	SSS Research, Inc.|c|;;			SSS Research, Inc.|c|;;
InfoVis	2004	A Rank-by-Feature Framework for Unsupervised Multidimensional Data Exploration Using Low Dimensional Projections	10.1109/INFVIS.2004.3	http://dx.doi.org/10.1109/INFVIS.2004.3	65	72	C		Jinwook Seo;Ben Shneiderman	Dept. of Comput. Sci., Maryland Univ., College Park, MD|c|;	10.1109/VISUAL.1994.346302;10.1109/VISUAL.1990.146402;10.1109/INFVIS.2003.1249015;10.1109/INFVIS.1998.729559	information visualization, exploratory data analysis, dynamic query, feature detection/selection, statistical graphics	University of Maryland##University of Maryland
InfoVis	2004	IN-SPIRE InfoVis 2004 Contest Entry	10.1109/INFVIS.2004.37	http://dx.doi.org/10.1109/INFVIS.2004.37	r2	r2	M		Pak Chung Wong;Elizabeth G. Hetzler;Christian Posse;Mark A. Whiting;Susan L. Havre;Nick Cramer;Anuj R. Shah;Mudita Singhal;Alan Turner;James J. Thomas	Pacific Northwest National Laboratory|c|;;;;;;;;;			Pacific Northwest National Laboratory|c|;;;;;;;;;
InfoVis	2004	Information Visualization Research: Citation and Co-Citation Highlights	10.1109/INFVIS.2004.38	http://dx.doi.org/10.1109/INFVIS.2004.38	r11	r11	M		Chaomei Chen	Drexel University|c|			Drexel University|c|
InfoVis	2004	InfoVisExplorer	10.1109/INFVIS.2004.39	http://dx.doi.org/10.1109/INFVIS.2004.39	r7	r7	M		Jaroslav Tyman;Grant P. Gruetzmacher;John T. Stasko	Georgia Institute of Technology|c|;;			Georgia Institute of Technology|c|;;
InfoVis	2004	An Associative Information Visualizer	10.1109/INFVIS.2004.4	http://dx.doi.org/10.1109/INFVIS.2004.4	r8	r8	M		Howard D. White;Xia Lin;Jan W. Buzydlowski	Drexel University|c|;;			Drexel University|c|;;
InfoVis	2004	Interactive Exploration of the AFS File System	10.1109/INFVIS.2004.40	http://dx.doi.org/10.1109/INFVIS.2004.40	7	7	M		Joshua Foster;Kalpathi R. Subramanian;Robert Herring;Gail-Joon Ahn	University of North Carolina at Charlotte|c|;;;			University of North Carolina at Charlotte|c|;;;
InfoVis	2004	Interactive Poster: Visual Mining of Business Process Data	10.1109/INFVIS.2004.41	http://dx.doi.org/10.1109/INFVIS.2004.41	10	10	M		Ming C. Hao;Daniel A. Keim;Umeshwar Dayal;Jörn Schneidewind	Hewlett Packard Research Laboratories|c|;;;			Hewlett Packard Research Laboratories|c|;;;
InfoVis	2004	Interactive Visualization Approaches to the Analysis of System Identification Data	10.1109/INFVIS.2004.42	http://dx.doi.org/10.1109/INFVIS.2004.42	11	11	M		Jimmy Johansson;Patric Ljung;David Lindgren;Matthew D. Cooper	Link&#246;ping University|c|;;;			Link&#246;ping University|c|;;;
InfoVis	2004	Interactive Visualization of Small World Graphs	10.1109/INFVIS.2004.43	http://dx.doi.org/10.1109/INFVIS.2004.43	199	206	C		Frank van Ham;Jarke J. van Wijk	Dept. of Math. & Comput. Sci., Technische Universiteit Eindhoven|c|;	10.1109/INFVIS.1997.636718;10.1109/INFVIS.1995.528686;10.1109/VISUAL.2000.885677;10.1109/INFVIS.2003.1249011	Graph Visualization, Graph Drawing, Clustering, Small World Graphs	Universiteit Eindhoven##Universiteit Eindhoven
InfoVis	2004	Keynote Address: From Information Visualization to Sensemaking: Connecting the Mind's Eye to the Mind's Muscle	10.1109/INFVIS.2004.44	http://dx.doi.org/10.1109/INFVIS.2004.44	xii	xii	M		Stuart K. Card				
InfoVis	2004	Major Information Visualization Authors, Papers and Topics in the ACM Library	10.1109/INFVIS.2004.45	http://dx.doi.org/10.1109/INFVIS.2004.45	r1	r1	M		Weimao Ke;Katy Börner;Lalitha Viswanath	Indiana University|c|;;			Indiana University|c|;;
InfoVis	2004	Matrix Zoom: A Visual Interface to Semi-External Graphs	10.1109/INFVIS.2004.46	http://dx.doi.org/10.1109/INFVIS.2004.46	183	190	C		James Abello;Frank van Ham	DIMACS, Rutgers Univ., Piscataway, NJ|c|;	10.1109/INFVIS.2003.1249030	Graph Visualization, Hierarchy Trees, Clustering, External Memory Algorithms, Cancer Data, Phone Traffic	Rutgers University Piscataway##Universiteit Eindhoven
InfoVis	2004	Metric-Based Network Exploration and Multiscale Scatterplot	10.1109/INFVIS.2004.47	http://dx.doi.org/10.1109/INFVIS.2004.47	135	142	C		Yves Chiricota;Fabien Jourdan;Guy Melançon	Quebec Univ., Chicoutimi, Que.|c|;;	10.1109/VISUAL.1995.485139;10.1109/INFVIS.1999.801858;10.1109/INFVIS.1997.636791;10.1109/INFVIS.2003.1249005;10.1109/INFVIS.2003.1249011;10.1109/INFVIS.2000.885090	Graph navigation, exploration, scatterplot, multiscale perceptual organization, clustering, filtering, blurring	UniversitÃ© du QuÃ©becQuÃ©becÃ Chicoutimi##UniversitÃ© du QuÃ©becQuÃ©becÃ Chicoutimi##UniversitÃ© du QuÃ©becQuÃ©becÃ Chicoutimi
InfoVis	2004	MonkEllipse: Visualizing the History of Information Visualization	10.1109/INFVIS.2004.48	http://dx.doi.org/10.1109/INFVIS.2004.48	r9	r9	M		Tzu-Wei Hsu;Lee Inman;Dave McColgin;Kevin Stamper	Georgia Institute of Technology|c|;;;			Georgia Institute of Technology|c|;;;
InfoVis	2004	Non-Euclidean Spring Embedders	10.1109/INFVIS.2004.49	http://dx.doi.org/10.1109/INFVIS.2004.49	207	214	C		Stephen G. Kobourov;Kevin Wampler	Dept. of Comput. Sci., Arizona Univ., Tucson, AZ|c|;	10.1109/INFVIS.1997.636718;10.1109/INFVIS.2002.1173159	force-directed algorithms, spring embedders, non-Euclidean geometry, hyperbolic space, spherical space, graph drawing, information visualization	University of Arizona##University of Arizona
InfoVis	2004	An Evaluation of Microarray Visualization Tools for Biological Insight	10.1109/INFVIS.2004.5	http://dx.doi.org/10.1109/INFVIS.2004.5	1	8	C		Purvi Saraiya;Chris North;Karen Duca	Dept. of Comput. Sci., Virginia Polytech. Inst. & State Univ., Blacksburg, VA|c|;;	10.1109/INFVIS.2001.963289	Data visualization, empirical evaluation, insight, high throughput experiments, microarray data, bioinformatics	Virginia Polytechnic Institute and State University Blacksburg##Virginia Polytechnic Institute and State University Blacksburg##Virginia Polytechnic Institute and State University Blacksburg
InfoVis	2004	One-For-All: Visualization of the Information Visualization Symposia	10.1109/INFVIS.2004.50	http://dx.doi.org/10.1109/INFVIS.2004.50	r12	r12	M		Soon Tee Teoh;Kwan-Liu Ma	University of California at Davis|c|;			
InfoVis	2004	Paint Inspired Color Mixing and Compositing for Visualization	10.1109/INFVIS.2004.52	http://dx.doi.org/10.1109/INFVIS.2004.52	113	118	C		Nathan Gossett;Baoquan Chen	Minnesota Univ., Minneapolis, MN|c|;	10.1109/VISUAL.2003.1250362	RYB, Color Mixing, Perception	University of Minnesota at Twin Cities##University of Minnesota at Twin Cities
InfoVis	2004	PhylloTrees: Harnessing Nature's Phyllotactic Patterns for Tree Layout	10.1109/INFVIS.2004.53	http://dx.doi.org/10.1109/INFVIS.2004.53	3	3	M		M. Sheelagh T. Carpendale;Anand Agarawala	University of Calgary|c|;			University of Calgary|c|;
InfoVis	2004	RankSpiral: Toward Enhancing Search Results Visualizations	10.1109/INFVIS.2004.56	http://dx.doi.org/10.1109/INFVIS.2004.56	18	18	M		Anselm Spoerri	Rutgers University|c|			Rutgers University|c|
InfoVis	2004	RecMap: Rectangular Map Approximations	10.1109/INFVIS.2004.57	http://dx.doi.org/10.1109/INFVIS.2004.57	33	40	C		Roland Heilmann;Daniel A. Keim;Christian Panse;Mike Sips	;;;	10.1109/VISUAL.1998.745303;10.1109/VISUAL.1991.175815;10.1109/INFVIS.2002.1173144	Geographic Visualization, Information Visualization, Database and Data Mining Visualization	University of Konstanz##University of Konstanz##University of Konstanz##University of Konstanz
InfoVis	2004	Resource Systems Reference Database	10.1109/INFVIS.2004.58	http://dx.doi.org/10.1109/INFVIS.2004.58	13	13	M		David Lu;Lauren Dietrich	Futurefarmers|c|;			Futurefarmers|c|;
InfoVis	2004	Rethinking Visualization: A High-Level Taxonomy	10.1109/INFVIS.2004.59	http://dx.doi.org/10.1109/INFVIS.2004.59	151	158	C		Melanie Tory;Torsten Möller	Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC|c|;	10.1109/VISUAL.1990.146375;10.1109/INFVIS.2000.885092;10.1109/INFVIS.1997.636792;10.1109/INFVIS.1999.801856	visualization, taxonomy, classification, design model, user model, conceptual model	Simon Fraser University##Simon Fraser University
InfoVis	2004	An Experimental Investigation of Magnification Lens Offset and Its Impact on Imagery Analysis	10.1109/INFVIS.2004.6	http://dx.doi.org/10.1109/INFVIS.2004.6	5	5	M		Erika Darling;Chris Newbern;Nikhil Kalghatgi;Aaron Burgman;Kristine Recktenwald	The Mitre Corporation|c|;;;;			The Mitre Corporation|c|;;;;
InfoVis	2004	Steerable, Progressive Multidimensional Scaling	10.1109/INFVIS.2004.60	http://dx.doi.org/10.1109/INFVIS.2004.60	57	64	C		Matt Williams;Tamara Munzner	British Columbia Univ., Vancouver, BC|c|;	10.1109/INFVIS.2002.1173150;10.1109/INFVIS.2003.1249013;10.1109/INFVIS.2001.963275;10.1109/INFVIS.2002.1173159;10.1109/INFVIS.2002.1173161;10.1109/VISUAL.1996.567787;10.1109/INFVIS.1995.528686;10.1109/INFVIS.2003.1249012	dimensionality reduction, multidimensional scaling	University of British Columbia##University of British Columbia
InfoVis	2004	TextPool: Visualizing Live Text Streams	10.1109/INFVIS.2004.63	http://dx.doi.org/10.1109/INFVIS.2004.63	1	1	M		Conrad Albrecht-Buehler;Benjamin Watson;David A. Shamma	Northwestern University|c|;;			Northwestern University|c|;;
InfoVis	2004	The InfoVis Toolkit	10.1109/INFVIS.2004.64	http://dx.doi.org/10.1109/INFVIS.2004.64	167	174	C		Jean-Daniel Fekete	Univ. de Paris-Sud, Orsay|c|	10.1109/INFVIS.2003.1249008;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2002.1173156;10.1109/INFVIS.1995.528688;10.1109/INFVIS.2002.1173148	Information Visualization, Toolkit, Graphics, Integration	INRIA Futurs/LRI
InfoVis	2004	Time-Varying Data Visualization Using Information Flocking Boids	10.1109/INFVIS.2004.65	http://dx.doi.org/10.1109/INFVIS.2004.65	97	104	C		Andrew Vande Moere	Key Centre of Design Comput. & Cognition, Sydney Univ., NSW|c|		time-varying information visualization, artificial life, 3D information visualization, motion, boids	University of Sydney
InfoVis	2004	Topological Fisheye Views for Visualizing Large Graphs	10.1109/INFVIS.2004.66	http://dx.doi.org/10.1109/INFVIS.2004.66	175	182	C		Emden R. Gansner;Yehuda Koren;Stephen C. North	AT&T Labs., NJ|c|;;	10.1109/INFVIS.1997.636718;10.1109/INFVIS.2003.1249011	topological fisheye,large graph visualization	AT&T Labs., NJ|c|;;
InfoVis	2004	Tracking User Interactions Within Visualizations	10.1109/INFVIS.2004.67	http://dx.doi.org/10.1109/INFVIS.2004.67	9	9	M		Dennis P. Groth;Benjamin W. Murphy	Indiana University|c|;			Indiana University|c|;
InfoVis	2004	Uncovering Clusters in Crowded Parallel Coordinates Visualizations	10.1109/INFVIS.2004.68	http://dx.doi.org/10.1109/INFVIS.2004.68	81	88	C		Almir Olivette Artero;Maria Cristina Ferreira de Oliveira;Haim Levkowitz	Dept. of Comput. Sci., Sao Paulo Univ.|c|;;	10.1109/VISUAL.1994.346302	information visualization, visual clustering, density-based visualization, visual data mining	University of SÃ£o Paulo##University of SÃ£o Paulo##University of SÃ£o Paulo
InfoVis	2004	Understanding Eight Years of InfoVis Conferences Using PaperLens	10.1109/INFVIS.2004.69	http://dx.doi.org/10.1109/INFVIS.2004.69	r3	r3	M		Bongshin Lee;Mary Czerwinski;George G. Robertson;Benjamin B. Bederson	University of Maryland and Microsoft Research|c|;;;			University of Maryland and Microsoft Research|c|;;;
InfoVis	2004	ARNA: Interactive Comparison and Alignment of RNA Secondary Structure	10.1109/INFVIS.2004.7	http://dx.doi.org/10.1109/INFVIS.2004.7	8	8	M		Gerald Gainant;David Auber	University of Bordeaux 1|c|;			University of Bordeaux 1|c|;
InfoVis	2004	User Experiments with Tree Visualization Systems	10.1109/INFVIS.2004.70	http://dx.doi.org/10.1109/INFVIS.2004.70	9	16	C		Alfred Kobsa	California Univ., Irvine, CA|c|	10.1109/VISUAL.1991.175815;10.1109/INFVIS.2002.1173148;10.1109/INFVIS.2001.963285;10.1109/INFVIS.1999.801860;10.1109/INFVIS.2001.963289;10.1109/INFVIS.2001.963290;10.1109/INFVIS.2002.1173153	information visualization, experimental comparison, task performance, accuracy, user satisfaction, user interaction, design recommendations	University of California
InfoVis	2004	Value and Relation Display for Interactive Exploration of High Dimensional Datasets	10.1109/INFVIS.2004.71	http://dx.doi.org/10.1109/INFVIS.2004.71	73	80	C		Jing Yang 0001;Anilkumar Patro;Shiping Huang;Nishant K. Mehta;Matthew O. Ward;Elke A. Rundensteiner	Dept. of Comput. Sci., Worcester Polytech. Inst., MA|c|;;;;;	10.1109/INFVIS.1998.729559;10.1109/INFVIS.2003.1249015;10.1109/VISUAL.1994.346302;10.1109/INFVIS.2003.1249014;10.1109/INFVIS.1995.528686;10.1109/VISUAL.1995.485140	Multi-dimensional visualization, pixel-oriented, multi-dimensional scaling, high dimensional datasets	Dept. of Comput. Sci., Worcester Polytech. Inst., MA|c|;;;;;
InfoVis	2004	VIM: A Framework for Intelligence Analysis	10.1109/INFVIS.2004.72	http://dx.doi.org/10.1109/INFVIS.2004.72	22	22	M		Alan Keahey;Kenneth C. Cox	Visintuit LLC|c|;			Visintuit LLC|c|;
InfoVis	2004	Visual Browsing of Remote and Distributed Data	10.1109/INFVIS.2004.73	http://dx.doi.org/10.1109/INFVIS.2004.73	12	12	M		Parthasarathy Krishnaswamy;Stephen G. Eick;Robert L. Grossman	University of Illinois at Chicago|c|;;			University of Illinois at Chicago|c|;;
InfoVis	2004	Visualizing and Interacting with Multi-Tree Hierarchical Data	10.1109/INFVIS.2004.74	http://dx.doi.org/10.1109/INFVIS.2004.74	15	15	M		Mahnas Jean Mohammadi-Aragh;T. J. Jankun-Kelly	Mississippi State University|c|;			Mississippi State University|c|;
InfoVis	2004	Visualizing E-mail with a Semantically Zoomable Interface	10.1109/INFVIS.2004.75	http://dx.doi.org/10.1109/INFVIS.2004.75	6	6	M		Ellen Diep;Robert J. K. Jacob	Tufts University|c|;			Tufts University|c|;
InfoVis	2004	Visualizing High Dimensional Datasets Using Partiview	10.1109/INFVIS.2004.76	http://dx.doi.org/10.1109/INFVIS.2004.76	20	20	M		Dinoj Surendran;Stuart Levy	University of Chicago|c|;			University of Chicago|c|;
InfoVis	2004	WilmaScope Graph Visualisation	10.1109/INFVIS.2004.77	http://dx.doi.org/10.1109/INFVIS.2004.77	r4	r4	M		Adel Ahmed;Tim Dwyer;Colin Murray;Le Song;Ying Xin Wu	University of Sydney,|c|;;;;			University of Sydney,|c|;;;;
InfoVis	2004	Artifacts of the Presence Era: Using Information Visualization to Create an Evocative Souvenir	10.1109/INFVIS.2004.8	http://dx.doi.org/10.1109/INFVIS.2004.8	105	111	C		Fernanda B. Viégas;Ethan Perry;Ethan Howe;Judith S. Donath	Media Lab., MIT, Cambridge, MA|c|;;;		visualization, history, public space	Media Lab., MIT, Cambridge, MA|c|;;;
Vis	2004	Building an Ontology of Visualization	10.1109/VISUAL.2004.10	http://dx.doi.org/10.1109/VISUAL.2004.10	7	7	M		David J. Duke;Ken Brodlie;David A. Duce	University of Leeds|c|;;			University of Leeds|c|;;
Vis	2004	Surface reconstruction of noisy and defective data sets	10.1109/VISUAL.2004.101	http://dx.doi.org/10.1109/VISUAL.2004.101	259	266	C		Hui Xie;Kevin T. McDonnell;Hong Qin	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;	10.1109/VISUAL.2003.1250359	Computer Graphics, Surface Reconstruction, Surface Representation, MPU implicits, Modified Shepard's Method	State University of New York at Stony Brook##State University of New York at Stony Brook##State University of New York at Stony Brook
Vis	2004	TetSplat: real-time rendering and volume clipping of large unstructured tetrahedral meshes	10.1109/VISUAL.2004.102	http://dx.doi.org/10.1109/VISUAL.2004.102	433	440	C		Ken Museth;Santiago V. Lombeyda	Linkoping Inst. of Technol., Sweden|c|;	10.1109/VISUAL.2000.885703;10.1109/VISUAL.1998.745329;10.1109/VISUAL.2000.885680;10.1109/VISUAL.1997.663869	Large volumetric data, tetrahedral meshes, real-time visualization, point-based rendering, constructive solid geometry	LinkÃ¶ping Institute of Technology##LinkÃ¶ping Institute of Technology
Vis	2004	TexMol: interactive visual exploration of large flexible multi-component molecular complexes	10.1109/VISUAL.2004.103	http://dx.doi.org/10.1109/VISUAL.2004.103	243	250	C		Chandrajit L. Bajaj;Peter Djeu;Vinay Siddavanahalli;Anthony Thane	Center for Computational Visualization, Texas Univ., Austin, TX, USA|c|;;;	10.1109/VISUAL.1993.398882;10.1109/VISUAL.1998.745320	molecular visualization, image-based rendering, texture-based rendering, imposter rendering, volume rendering, programmable graphics hardware, level-of-detail, hierarchy, multiresolution, synchronous view, computer graphics	University of Texas at Austin Austin##University of Texas at Austin Austin##University of Texas at Austin Austin##University of Texas at Austin Austin
Vis	2004	The VesselGlyph: focus & context visualization in CT-angiography	10.1109/VISUAL.2004.104	http://dx.doi.org/10.1109/VISUAL.2004.104	385	392	C		Matús Straka;Michal Cervenanský;Alexandra La Cruz;Arnold Köchl;Milos Srámek;Eduard Gröller;Dominik Fleischmann	Comm. for Sci. Visualization, Austrian Acad. of Sci., Austria|c|;;;;;;	10.1109/VISUAL.2001.964538;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2001.964555	focus & context technique, direct volume rendering, curved planar reformation, vessel visualization	Austrian Academy of Sciences##Comenius University##Stanford University Medical Center##Vienna University of Technology##Vienna University of Technology
Vis	2004	Topological lines in 3D tensor fields	10.1109/VISUAL.2004.105	http://dx.doi.org/10.1109/VISUAL.2004.105	313	320	C		Xiaoqiang Zheng;Alex T. Pang	Dept. of Comput. Sci., California Univ., Santa Cruz, CA, USA|c|;	10.1109/VISUAL.1998.745316;10.1109/VISUAL.1999.809894;10.1109/VISUAL.1993.398849;10.1109/VISUAL.2003.1250379;10.1109/VISUAL.2002.1183798;10.1109/VISUAL.1994.346326;10.1109/VISUAL.1999.809905;10.1109/VISUAL.1998.745294;10.1109/VISUAL.1999.809886	hyperstreamlines, real symmetric tensors, degenerate tensors, tensor topology, topological lines	University of California##University of California
Vis	2004	Topology visualization of the optical power flow through a novel C-shaped nano-aperture	10.1109/VISUAL.2004.106	http://dx.doi.org/10.1109/VISUAL.2004.106	337	344	C		Liying Sun;Rajesh Batra;Xiaolei Shi;Lambertus Hesselink	Dept. of Phys., Stanford Univ., CA, USA|c|;;;	10.1109/VISUAL.1999.809874	energy flow topology, Finite-Difference-Time-Domain (fdtd), C-aperture, vector field visualization	Stanford University##Stanford University##Stanford University##Stanford University
Vis	2004	Tracking of vector field singularities in unstructured 3D time-dependent datasets	10.1109/VISUAL.2004.107	http://dx.doi.org/10.1109/VISUAL.2004.107	329	336	C		Christoph Garth;Xavier Tricoche;Gerik Scheuermann	Dept. of Comput. Sci., Kaiserslautern Univ., Germany|c|;;	10.1109/VISUAL.2003.1250376;10.1109/VISUAL.2002.1183786;10.1109/VISUAL.1991.175773;10.1109/VISUAL.1997.663910	flow visualization, topology tracking, time-dependent datasets, vortex breakdown	University of Kaiserslautern##University of Kaiserslautern##University of Kaiserslautern
Vis	2004	Vector Wavelet Thresholding for Vector Field Denoising	10.1109/VISUAL.2004.108	http://dx.doi.org/10.1109/VISUAL.2004.108	25	25	M		Michel A. Westenberg;Thomas Ertl	University of Stuttgart|c|;			University of Stuttgart|c|;
Vis	2004	VisBiz: A Simplified Visualization of Business Operation	10.1109/VISUAL.2004.109	http://dx.doi.org/10.1109/VISUAL.2004.109	1	1	M		Ming C. Hao;Daniel A. Keim;Umeshwar Dayal	Hewlett Packard Research Laboratories|c|;;			Hewlett Packard Research Laboratories|c|;;
Vis	2004	Capillary Histology Imagery Visualization and Exploration	10.1109/VISUAL.2004.11	http://dx.doi.org/10.1109/VISUAL.2004.11	30	30	M		Michael Gleicher;Tom Brunet;K. Evan Nowak;Liz Osten;Matt McElwee;Kevin Tanty;Adam Gepner;Garet Lahvis	University of Wisconsin-Madison|c|;;;;;;;			University of Wisconsin-Madison|c|;;;;;;;
Vis	2004	Visibility culling for time-varying volume rendering using temporal occlusion coherence	10.1109/VISUAL.2004.110	http://dx.doi.org/10.1109/VISUAL.2004.110	147	154	C		Jinzhu Gao;Han-Wei Shen;Jian Huang;James Arthur Kohl	Oak Ridge State Lab., Ohio State Univ., Columbus, OH, USA|c|;;;	10.1109/VISUAL.1994.346321;10.1109/VISUAL.1998.745713;10.1109/VISUAL.2001.964520;10.1109/VISUAL.1999.809910;10.1109/VISUAL.1999.809879;10.1109/VISUAL.1993.398869;10.1109/VISUAL.2001.964531;10.1109/VISUAL.2002.1183757;10.1109/VISUAL.2003.1250374;10.1109/VISUAL.1998.745300;10.1109/VISUAL.2000.885698;10.1109/VISUAL.2003.1250402	visibility culling, time-varying data visualization, volume rendering, plenoptic opacity function, large data visualization	The Ohio State Univ. Oak Ridge National Lab##The Ohio State Univ. Oak Ridge National Lab##The Ohio State Univ. Oak Ridge National Lab##The Ohio State Univ. Oak Ridge National Lab
Vis	2004	Visual Inspection Methods for Quality Control in Automotive Engineering	10.1109/VISUAL.2004.111	http://dx.doi.org/10.1109/VISUAL.2004.111	3	3	M		Hans Hagen;Andreas Disch;Jochen Ehret;Ralf Klein;Sascha Köhn;Dirk Zeckzer;Michael Münchhofen	DFKI GmbH|c|;;;;;;			DFKI GmbH|c|;;;;;;
Vis	2004	Visualization in grid computing environments	10.1109/VISUAL.2004.112	http://dx.doi.org/10.1109/VISUAL.2004.112	155	162	C		Ken Brodlie;David A. Duce;Julian R. Gallop;Musbah Shahop Sagar;J. P. R. B. Walton;Jason D. Wood	Sch. of Comput., Leeds Univ., UK|c|;;;;;	10.1109/VISUAL.1997.663890	grid computing, visualization systems, XML, computational steering, visualization reference models	CCLRC Rutherford Appleton Laboratory##Oxford Brookes University####University of Leeds
Vis	2004	Visualization of intricate flow structures for vortex breakdown analysis	10.1109/VISUAL.2004.113	http://dx.doi.org/10.1109/VISUAL.2004.113	187	194	C		Xavier Tricoche;Christoph Garth;Gordon L. Kindlmann;Eduard Deines;Gerik Scheuermann;Markus Rütten;Charles D. Hansen	Utah Univ., Salt Lake City, UT, USA|c|;;;;;;	10.1109/VISUAL.2001.964519;10.1109/VISUAL.1998.745296;10.1109/VISUAL.1991.175773;10.1109/VISUAL.1997.663910;10.1109/VISUAL.1999.809896;10.1109/VISUAL.2003.1250414;10.1109/VISUAL.2003.1250376;10.1109/VISUAL.2001.964489;10.1109/VISUAL.1993.398875;10.1109/VISUAL.1991.175789;10.1109/VISUAL.1994.346314	flow visualization, vortex analysis, parametric topology, cutting planes, volume rendering	University of Utah##University of Utah##University of Utah##University of Utah##University of Utah##University of Utah##University of Utah
Vis	2004	Visualization of Nanoparticle Formation in Turbulent Flows	10.1109/VISUAL.2004.114	http://dx.doi.org/10.1109/VISUAL.2004.114	23	23	M		P. Coleman Saunders;Sean C. Garrick;Victoria Interrante	University of Minnesota|c|;;			University of Minnesota|c|;;
Vis	2004	Visualization of salt-induced stress perturbations	10.1109/VISUAL.2004.115	http://dx.doi.org/10.1109/VISUAL.2004.115	369	376	C		Patricia Crossno;David H. Rogers;Rebecca M. Brannon;David Coblentz	Sandia Nat. Labs., Albuquerque, NM, USA|c|;;;	10.1109/VISUAL.1997.663929;10.1109/VISUAL.1992.235193;10.1109/VISUAL.1998.745294;10.1109/VISUAL.1993.398849;10.1109/VISUAL.1995.485141;10.1109/VISUAL.1999.809894;10.1109/VISUAL.1999.809905;10.1109/VISUAL.2002.1183819;10.1109/VISUAL.2002.1183797;10.1109/VISUAL.1997.663857;10.1109/VISUAL.1994.346326	tensor field visualization, Mohr's circles, visual debugging, finite element codes and simulations	Sandia Nat. Labs., Albuquerque, NM, USA|c|;;;
Vis	2004	Visualization of the Interaction of Multiple Sclerosis Lesions with Adjacent White Matter Fibers Using Streamtubes and Streamsurfaces	10.1109/VISUAL.2004.116	http://dx.doi.org/10.1109/VISUAL.2004.116	29	29	M		Song Zhang 0004;David H. Laidlaw;Jack Simon;Mark Brown;David Miller	Brown University|c|;;;;			Brown University|c|;;;;
Vis	2004	Visualization of Topological Defects in Nematic Liquid Crystals Using Streamtubes, Streamsurfaces and Ellipsoids	10.1109/VISUAL.2004.117	http://dx.doi.org/10.1109/VISUAL.2004.117	21	21	M		Vadim A. Slavin;David H. Laidlaw;Robert Pelcovits;Song Zhang 0004;George Loriot;Andrew Callan-Jones	Brown University|c|;;;;;			Brown University|c|;;;;;
Vis	2004	Visualization of Vortices in Simulated Airflow around Bat Wings During Flight	10.1109/VISUAL.2004.118	http://dx.doi.org/10.1109/VISUAL.2004.118	20	20	M		Eduardo Hueso;Igor Pivkin;Sharon Swartz;David H. Laidlaw;George E. Karniadakis;Kenneth Breuer	Brown University|c|;;;;;			Brown University|c|;;;;;
Vis	2004	Visualizing Botanical Trees over Four Seasons	10.1109/VISUAL.2004.119	http://dx.doi.org/10.1109/VISUAL.2004.119	13	13	M		Derek Bradley	Carleton University|c|			Carleton University|c|
Vis	2004	Self-illustrating phenomena	10.1109/VISUAL.2004.12	http://dx.doi.org/10.1109/VISUAL.2004.12	xix		M		Pat Hanrahan	Comput. Sci. & Electr. Eng., Stanford Univ., CA, USA|c|			Comput. Sci. & Electr. Eng., Stanford Univ., CA, USA|c|
Vis	2004	Visualizing competitive behaviors in multi-user virtual environments	10.1109/VISUAL.2004.120	http://dx.doi.org/10.1109/VISUAL.2004.120	163	170	C		Nate Hoobler;Greg Humphreys;Maneesh Agrawala	Virginia Univ., Charlottesville, VA, USA|c|;;		Visualization, Games, Spectating	University of Virginia##University of Virginia##University of Virginia
Vis	2004	Visualizing cortical waves and timing from data	10.1109/VISUAL.2004.121	http://dx.doi.org/10.1109/VISUAL.2004.121	401	408	C		Kay A. Robbins;Mark A. Robinson;David M. Senseman	Texas Univ., San Antonio, TX, USA|c|;;	10.1109/VISUAL.2001.964493;10.1109/VISUAL.1990.146402;10.1109/VISUAL.2000.885686	waves, neural networks, PCA, KL decomposition, wave subspaces, flow visualization	University of Texas at San Antonio University of Texas at San Antonio University of Texas at San Antonio Cajal Neuroscience Research Center Cajal Neuroscience Research Center##University of Texas at San Antonio University of Texas at San Antonio University of Texas at San Antonio Cajal Neuroscience Research Center Cajal Neuroscience Research Center##University of Texas at San Antonio University of Texas at San Antonio University of Texas at San Antonio Cajal Neuroscience Research Center Cajal Neuroscience Research Center
Vis	2004	Visualizing gyrokinetic simulations	10.1109/VISUAL.2004.122	http://dx.doi.org/10.1109/VISUAL.2004.122	59	66	C		David Crawford;Kwan-Liu Ma;Min-Yu Huang;Scott Klasky;Stéphane Ethier	Dept. of Comput. Sci., California Univ., Davis, CA, USA|c|;;;;	10.1109/VISUAL.2001.964520;10.1109/VISUAL.2003.1250402;10.1109/VISUAL.2003.1250385	graphics hardware, non-rectilinear mesh, plasma physics, scientific visualization, texture methods, volume visualization	University of California at Davis##University of California at Davis##University of California at Davis##University of California at Davis##University of California at Davis
Vis	2004	Visualizing the Energetics of the Dissociation of a Metastable Molecule	10.1109/VISUAL.2004.123	http://dx.doi.org/10.1109/VISUAL.2004.123	15	15	M		David Guzman;Reuben Reyes;Karla Vega;Kelly P. Gaither;Robert Wyatt	University of Texas at Austin|c|;;;;			University of Texas at Austin|c|;;;;
Vis	2004	Visualizing the Evolution of Horned Lizards Using 3D Morphing Techniques	10.1109/VISUAL.2004.124	http://dx.doi.org/10.1109/VISUAL.2004.124	16	16	M		Reuben Reyes;Wendy L. Hodges;Kelly P. Gaither	University of Texas at Austin|c|;;			University of Texas at Austin|c|;;
Vis	2004	Visualizing Turbulent Flow	10.1109/VISUAL.2004.125	http://dx.doi.org/10.1109/VISUAL.2004.125	22	22	M		Gregory P. Johnson;Kelly P. Gaither;Victor Calo	University of Texas at Austin|c|;;			University of Texas at Austin|c|;;
Vis	2004	Vol-a-Tile - A Tool for Interactive Exploration of Large Volumetric Data on Scalable Tiled Displays	10.1109/VISUAL.2004.126	http://dx.doi.org/10.1109/VISUAL.2004.126	19	19	M		Nicholas Schwarz;Shalini Venkataraman;Luc Renambot;Naveen K. Krishnaprasad;Venkatram Vishwanath;Jason Leigh;Andrew E. Johnson;Graham Kent;Atul Nayak	University of Illinois at Chicago|c|;;;;;;;;			University of Illinois at Chicago|c|;;;;;;;;
Vis	2004	Volume refinement fairing isosurfaces	10.1109/VISUAL.2004.127	http://dx.doi.org/10.1109/VISUAL.2004.127	449	455	C		Martin Hering-Bertram	TU Kaiserslautern, Germany|c|	10.1109/VISUAL.2003.1250398;10.1109/VISUAL.2003.1250414;10.1109/VISUAL.2003.1250399;10.1109/VISUAL.2000.885721	adaptive mesh refinement, isosurfaces, sub-division, variational modeling, volume fairing	TU Kaiserslautern, Germany|c|
Vis	2004	Vorticity based flow analysis and visualization for Pelton turbine design optimization	10.1109/VISUAL.2004.128	http://dx.doi.org/10.1109/VISUAL.2004.128	179	186	C		Filip Sadlo;Ronald Peikert;Etienne Parkinson	Comput. Sci. Dept., Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;;	10.1109/VISUAL.2003.1250372;10.1109/VISUAL.1996.567807;10.1109/VISUAL.1998.745317;10.1109/VISUAL.1992.235211;10.1109/VISUAL.2000.885690;10.1109/VISUAL.1998.745295;10.1109/VISUAL.1994.346327;10.1109/VISUAL.2001.964506;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1999.809907;10.1109/VISUAL.2002.1183789	flow visualization, feature extraction, line placement	Etienne.Parkinson@vatech-hydro.ch####ETH ZÃ¼rich
Vis	2004	Centroidal Voronoi tessellation based algorithms for vector fields visualization and segmentation	10.1109/VISUAL.2004.13	http://dx.doi.org/10.1109/VISUAL.2004.13	43	50	C		Qiang Du;Xiaoqiang Wang	Dept. of Math., Pennsylvania State Univ., University Park, PA, USA|c|;	10.1109/VISUAL.1999.809865;10.1109/VISUAL.1995.480817	Flow Visualization, Vector Field, Simplification, Segmentation, Clustering, Centroidal Voronoi tessellation	Dept. of Math., Pennsylvania State Univ., University Park, PA, USA|c|;
Vis	2004	Code Checking and Visualization of an Architecture Design	10.1109/VISUAL.2004.14	http://dx.doi.org/10.1109/VISUAL.2004.14	10	10	M		Rong Xu;Wawan Solihin;Zhiyong Huang	National University of Singapore and novaCITYNETS Pte. Ltd.|c|;;			National University of Singapore and novaCITYNETS Pte. Ltd.|c|;;
Vis	2004	Compatible triangulations of spatial decompositions	10.1109/VISUAL.2004.15	http://dx.doi.org/10.1109/VISUAL.2004.15	211	217	C		William J. Schroeder;Berk Geveci;Mathieu Malaterre	;;	10.1109/VISUAL.1996.568127;10.1109/VISUAL.1997.663869;10.1109/VISUAL.1997.663886	triangulation, tetrahedrization, adaptive grid, clipping, contouring, template, Delaunay, parallel	Kitware, Inc##Kitware, Inc##Kitware, Inc
Vis	2004	Compression, Segmentation, and Modeling of Large-Scale Filamentary Volumetric Data	10.1109/VISUAL.2004.16	http://dx.doi.org/10.1109/VISUAL.2004.16	31	31	M		Bruce H. McCormick;Purna Doddapaneni;David Mayerich;Zeki Melek;John Keyser	Texas A&M University|c|;;;;			Texas A&M University|c|;;;;
Vis	2004	Constrained inverse volume rendering for planetary nebulae	10.1109/VISUAL.2004.18	http://dx.doi.org/10.1109/VISUAL.2004.18	83	90	C		Marcus A. Magnor;Gordon L. Kindlmann;Charles D. Hansen	;;;		volumetric modeling, inverse rendering, volume rendering, volume reconstruction, planetary nebulae	MPI Informatik##SCI Institute University of Utah##SCI Institute University of Utah##University of New Mexico
Vis	2004	Context-Adaptive Mobile Visualization and Information Management	10.1109/VISUAL.2004.19	http://dx.doi.org/10.1109/VISUAL.2004.19	8	8	M		Jochen Ehret;Achim Ebert;Lars Schuchardt;Heidrun Steinmetz;Hans Hagen	German Research Center for Artificial Intelligence|c|;;;;			German Research Center for Artificial Intelligence|c|;;;;
Vis	2004	2D Maps for Visual Analysis and Retrieval in Large Multi-Feature 3D Model Databases	10.1109/VISUAL.2004.2	http://dx.doi.org/10.1109/VISUAL.2004.2	2	2	M		Benjamin Bustos;Daniel A. Keim;Christian Panse;Tobias Schreck	University of Konstanz|c|;;;			University of Konstanz|c|;;;
Vis	2004	DaMI - Data Management for Multimedial Information Systems	10.1109/VISUAL.2004.21	http://dx.doi.org/10.1109/VISUAL.2004.21	9	9	M		Hans Hagen;Gerhard Steinebach;Michael Münchhofen;Inga Scheler;Maja Ruby;Michael Wadlé	University of Kaiserslautern|c|;;;;;			University of Kaiserslautern|c|;;;;;
Vis	2004	Depth Enhanced Panoramas	10.1109/VISUAL.2004.22	http://dx.doi.org/10.1109/VISUAL.2004.22	11	11	M		Gleb Bahmutov;Voicu Popescu;Elisha Sacks	Purdue University|c|;;			Purdue University|c|;;
Vis	2004	Detection and visualization of anomalous structures in molecular dynamics simulation data	10.1109/VISUAL.2004.23	http://dx.doi.org/10.1109/VISUAL.2004.23	465	472	C		Sameep Mehta;Kaden Hazzard;Raghu Machiraju;Srinivasan Parthasarathy 0001;John Wilkins	Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH, USA|c|;;;;	10.1109/VISUAL.1995.480793;10.1109/VISUAL.2002.1183753	Feature Extraction, Scientific Data Visualization, Data Mining, Iso-surface, Transfer Functions, Molecular Dynamics	The Ohio State University##The Ohio State University##The Ohio State University##The Ohio State University##The Ohio State University
Vis	2004	Dispersion simulation and visualization for urban security	10.1109/VISUAL.2004.24	http://dx.doi.org/10.1109/VISUAL.2004.24	553	560	C		Feng Qiu;Ye Zhao;Zhe Fan;Xiaoming Wei;Haik Lorenz;Jianning Wang;Suzanne Yoakum-Stover;Arie E. Kaufman;Klaus Mueller	Dept. of Comput. Sci., Stony Brook Univ., NY, USA|c|;;;;;;;;	10.1109/VISUAL.2003.1250382;10.1109/VISUAL.2002.1183764;10.1109/VISUAL.2002.1183779;10.1109/VISUAL.1993.398877	Lattice Boltzmann Model, GPU, Visualization	Stony Brook University##Stony Brook University##Stony Brook University##Stony Brook University##Stony Brook University##Stony Brook University##Stony Brook University##Stony Brook University##Stony Brook University
Vis	2004	Display of vector fields using a reaction-diffusion model	10.1109/VISUAL.2004.25	http://dx.doi.org/10.1109/VISUAL.2004.25	115	122	C		Allen R. Sanderson;Christopher R. Johnson 0001;Robert Michael Kirby	Sci. Comput. & Imaging Inst., Utah Univ., Salt Lake City, UT, USA|c|;;	10.1109/VISUAL.1999.809865;10.1109/VISUAL.1995.480817;10.1109/VISUAL.1995.485141;10.1109/VISUAL.2000.885688;10.1109/VISUAL.1996.567784;10.1109/VISUAL.1992.235211;10.1109/VISUAL.1992.235225;10.1109/TVCG.2009.126;10.1109/VISUAL.1996.567777;10.1109/VISUAL.2003.1250357;10.1109/VISUAL.1999.809904;10.1109/VISUAL.1999.809905;10.1109/VISUAL.1991.175789;10.1109/VISUAL.1997.663897	Vector Field Visualization, Flow Visualization, Reaction-Diffusion, Vector Fields	University of Utah##University of Utah##University of Utah
Vis	2004	DTI Fiber Clustering in the Whole Brain	10.1109/VISUAL.2004.26	http://dx.doi.org/10.1109/VISUAL.2004.26	28	28	M		Song Zhang 0004;David H. Laidlaw	Brown University|c|;			Brown University|c|;
Vis	2004	Dual contouring with topology-preserving simplification using enhanced cell representation	10.1109/VISUAL.2004.27	http://dx.doi.org/10.1109/VISUAL.2004.27	505	512	C		Nan Zhang 0011;Wei Hong;Arie E. Kaufman	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;	10.1109/VISUAL.1994.346308;10.1109/VISUAL.2001.964503;10.1109/VISUAL.2003.1250356;10.1109/VISUAL.2003.1250360;10.1109/VISUAL.2002.1183810;10.1109/VISUAL.1996.568127;10.1109/VISUAL.2000.885703	isosurface simplification, isosurface extraction, topology preservation, vertex clustering	Stony Brook University##Stony Brook University##Stony Brook University
Vis	2004	Dual marching cubes	10.1109/VISUAL.2004.28	http://dx.doi.org/10.1109/VISUAL.2004.28	489	496	C		Gregory M. Nielson	Arizona Univ., Tucson, AZ, USA|c|	10.1109/VISUAL.2002.1183807;10.1109/VISUAL.1991.175782	Marching Cubes, isosurfaces, triangular mesh, dual graph, segmented data, smoothing	Arizona State University
Vis	2004	Efficient point-based isosurface exploration using the span-triangle	10.1109/VISUAL.2004.29	http://dx.doi.org/10.1109/VISUAL.2004.29	441	448	C		Bartosz von Rymon-Lipinski;Nils Hanssen;Thomas Jansen 0005;Lutz Ritter;Erwin Keeve	;;;;	10.1109/VISUAL.1991.175780;10.1109/VISUAL.2001.964489;10.1109/VISUAL.1996.568121;10.1109/VISUAL.1995.480806	Point-Based Visualization, Isosurfaces, Hardware Acceleration, Large Data Set Visualization, Visualization in Medicine	
Vis	2004	A graphics hardware-based vortex detection and visualization system	10.1109/VISUAL.2004.3	http://dx.doi.org/10.1109/VISUAL.2004.3	195	202	C		Simon Stegmaier;Thomas Ertl	Inst. of Visualization & Interactive Syst., Stuttgart Univ., Germany|c|;	10.1109/VISUAL.2003.1250361;10.1109/VISUAL.1998.745288;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.1999.809934;10.1109/VISUAL.1998.745296	Features in Volume Data Sets, Flow Visualization, Hardware Acceleration, 3D Vector Field Visualization	University of Stuttgart##University of Stuttgart
Vis	2004	Exploration of the brain's white matter pathways with dynamic queries	10.1109/VISUAL.2004.30	http://dx.doi.org/10.1109/VISUAL.2004.30	377	384	C		David Akers;Anthony J. Sherbondy;Rachel Mackenzie;Robert F. Dougherty;Brian A. Wandell	Stanford Univ., CA, USA|c|;;;;	10.1109/VISUAL.1999.809894;10.1109/VISUAL.1999.809886;10.1109/VISUAL.2002.1183799	Visualization, DTI, MR Tractography	Stanford University##Stanford University##Stanford University##Stanford University##Stanford University
Vis	2004	Fast Rendering of Foveated Volume in the Wavelet Domain	10.1109/VISUAL.2004.31	http://dx.doi.org/10.1109/VISUAL.2004.31	26	26	M		Hang Yu;Ee-Chien Chang;Zhiyong Huang;Zhijian Zheng	National University of Singapore|c|;;;			National University of Singapore|c|;;;
Vis	2004	Flow field clustering via algebraic multigrid	10.1109/VISUAL.2004.32	http://dx.doi.org/10.1109/VISUAL.2004.32	35	42	C		Michael Griebel;Tobias Preußer;Martin Rumpf;Marc Alexander Schweitzer;Alexandru Telea	Inst. for Numerical Simulation, Bonn Univ., Germany|c|;;;;	10.1109/VISUAL.1999.809865;10.1109/VISUAL.2003.1250372;10.1109/VISUAL.2003.1250377;10.1109/VISUAL.2003.1250363;10.1109/VISUAL.1999.809863	algebraic multigrid, multiscale visualization, flow visualization	Inst. for Numerical Simulation, Bonn Univ., Germany|c|;;;;
Vis	2004	Force-Feedback-Enhanced Navigation for Interactive Visualization of Coronary Vessels	10.1109/VISUAL.2004.33	http://dx.doi.org/10.1109/VISUAL.2004.33	32	32	M		Thomas Wischgoll;Elke Moritz;Jörg Meyer	University of California at Irvine|c|;;			University of California at Irvine|c|;;
Vis	2004	Generating realistic images from hydrothermal plume data	10.1109/VISUAL.2004.34	http://dx.doi.org/10.1109/VISUAL.2004.34	91	98	C		Kristina Santilli;Karen G. Bemis;Deborah Silver;Jamshed Dastur;Peter A. Rona	Rutgers Univ., NJ, USA|c|;;;;	10.1109/VISUAL.2000.885737;10.1109/VISUAL.2003.1250383;10.1109/VISUAL.1998.745347	Applications of volume graphics and volume visualization, Earth / Space / and Environmental Sciences Visualization, PC-based volume graphics, Volume Rendering	Rutgers University##Rutgers University##Rutgers University##Rutgers University##Rutgers University
Vis	2004	Generating sub-resolution detail in images and volumes using constrained texture synthesis	10.1109/VISUAL.2004.35	http://dx.doi.org/10.1109/VISUAL.2004.35	75	82	C		Lujin Wang;Klaus Mueller	;		texture synthesis, semantic zoom	Stony Brook University##Stony Brook University
Vis	2004	Guaranteed quality triangulation of molecular skin surfaces	10.1109/VISUAL.2004.36	http://dx.doi.org/10.1109/VISUAL.2004.36	481	488	C		Ho-Lun Cheng;Xinwei Shi	Sch. of Comput., Nat. Univ. of Singapore, Singapore|c|;		Smooth surfaces, meshing, guaranteed quality triangulation, homeomorphism, Morse-Smale complex	National University of Singapore##National University of Singapore
Vis	2004	Haptic display of interaction between textured models	10.1109/VISUAL.2004.37	http://dx.doi.org/10.1109/VISUAL.2004.37	297	304	C		Miguel A. Otaduy;Nitin Jain;Avneesh Sud;Ming C. Lin	Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;	10.1109/VISUAL.2003.1250380	haptics, textures, graphics hardware	University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill
Vis	2004	Hardware-accelerated adaptive EWA volume splatting	10.1109/VISUAL.2004.38	http://dx.doi.org/10.1109/VISUAL.2004.38	67	74	C		Wei Chen;Liu Ren;Matthias Zwicker;Hanspeter Pfister	Zhejiang Univ., Hangzhou, China|c|;;;	10.1109/VISUAL.1993.398877;10.1109/VISUAL.1997.663882;10.1109/VISUAL.2003.1250403;10.1109/VISUAL.1998.745309;10.1109/VISUAL.1996.567608;10.1109/VISUAL.1999.809909;10.1109/VISUAL.1995.480797;10.1109/VISUAL.2001.964490;10.1109/VISUAL.2000.885698	Direct volume rendering, volume splatting, EWA filter, hardware acceleration	Zhejiang University##Carnegie Mellon University
Vis	2004	Hierarchy Based 3D Visualization of Large Software Structures	10.1109/VISUAL.2004.39	http://dx.doi.org/10.1109/VISUAL.2004.39	4	4	M		Michael Balzer;Oliver Deussen	University of Konstanz|c|;			University of Konstanz|c|;
Vis	2004	Adaptive 4-8 texture hierarchies	10.1109/VISUAL.2004.4	http://dx.doi.org/10.1109/VISUAL.2004.4	219	226	C		Lok M. Hwa;Mark A. Duchaineau;Kenneth I. Joy	California Univ., Davis, CA, USA|c|;;	10.1109/VISUAL.2001.964533;10.1109/VISUAL.1997.663860;10.1109/VISUAL.2002.1183783;10.1109/VISUAL.1998.745282;10.1109/VISUAL.1998.745280;10.1109/VISUAL.2000.885699;10.1109/VISUAL.1995.480813;10.1109/VISUAL.2003.1250366	Large Data Set Visualization, Level-of-Detail Techniques, View-Dependent Visualization, Adaptive Textures, Out-of-Core Algorithms	University of California##University of California
Vis	2004	ImageSurfer: a tool for visualizing correlations between two volume scalar fields	10.1109/VISUAL.2004.46	http://dx.doi.org/10.1109/VISUAL.2004.46	529	536	C		Dennis Jen;Peter Parente;Jonathan Robbins;Chris Weigle;Russell M. Taylor II;Alain Burette;Richard Weinberg	Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;;;;	10.1109/VISUAL.2001.964519;10.1109/VISUAL.1996.568133;10.1109/VISUAL.2000.885735	scientific visualization, volume visualization, data exploration, biology, confocal microscopy, immunofluorescence	University of North Carolina##University of North Carolina##University of North Carolina##University of North Carolina##University of North Carolina##University of North Carolina##University of North Carolina
Vis	2004	Immersive design of DMA molecules with a tangible interface	10.1109/VISUAL.2004.47	http://dx.doi.org/10.1109/VISUAL.2004.47	227	234	C		Steven Schkolne;Hiroshi Ishii;Peter Schröder	;;		tangible user interface, molecular visualization, props, molecular modeling, spatial construction, virtual reality, augmented reality, responsive workbench, DNA design	
Vis	2004	Importance-driven volume rendering	10.1109/VISUAL.2004.48	http://dx.doi.org/10.1109/VISUAL.2004.48	139	145	C		Ivan Viola;Armin Kanitsar;Eduard Gröller	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;	10.1109/VISUAL.2003.1250406;10.1109/INFVIS.1996.559215;10.1109/VISUAL.1996.568110;10.1109/VISUAL.2000.885694;10.1109/VISUAL.2001.964519;10.1109/VISUAL.2000.885697;10.1109/VISUAL.2000.885696	view-dependent visualization, volume rendering, focus+context techniques, level-of-detail techniques, non-photorealistic techniques	Vienna University of Technology##Vienna University of Technology##Vienna University of Technology
Vis	2004	Anisotropic volume rendering for extremely dense, thin line data	10.1109/VISUAL.2004.5	http://dx.doi.org/10.1109/VISUAL.2004.5	107	114	C		Gregory L. Schussman;Kwan-Liu Ma	Stanford Linear Accelerator Center, Menlo Park, CA, USA|c|;		anisotropic lighting, line data, scientific visualization, vector field, volume rendering	University of California at Davis##University of California at Davis
Vis	2004	Interactive design of multi-perspective images for visualizing urban landscapes	10.1109/VISUAL.2004.50	http://dx.doi.org/10.1109/VISUAL.2004.50	537	544	C		Augusto Román;Gaurav Garg;Marc Levoy	Comput. Graphics Lab., Stanford Univ., CA, USA|c|;;		cross-slits image, multi-perspective image, city block	Stanford University##Stanford University####
Vis	2004	Interactive exploration of large remote micro-CT scans	10.1109/VISUAL.2004.51	http://dx.doi.org/10.1109/VISUAL.2004.51	345	352	C		Steffen Prohaska;Andrei Hutanu;Ralf Kähler;Hans-Christian Hege	Sci. Visualization Dept., Zuse Inst. Berlin, Germany|c|;;;	10.1109/VISUAL.2000.885729;10.1109/VISUAL.2002.1183758;10.1109/VISUAL.2002.1183757;10.1109/VISUAL.1999.809891;10.1109/VISUAL.2002.1183764;10.1109/VISUAL.1999.809908;10.1109/VISUAL.1997.663888	large data, out-of-core-methods, remote visualization, multiresolution visualization	Zuse Institute Berlin (ZIB)##Zuse Institute Berlin (ZIB)##Zuse Institute Berlin (ZIB)##Zuse Institute Berlin (ZIB)
Vis	2004	Interactive point-based isosurface extraction	10.1109/VISUAL.2004.52	http://dx.doi.org/10.1109/VISUAL.2004.52	457	464	C		Yarden Livnat;Xavier Tricoche	Sci. Comput. & Imaging Inst., Utah Univ., Salt Lake City, UT, USA|c|;	10.1109/VISUAL.1998.745713;10.1109/VISUAL.1998.745299;10.1109/VISUAL.1997.663895;10.1109/VISUAL.1995.480806;10.1109/VISUAL.1996.568123;10.1109/VISUAL.2002.1183810;10.1109/VISUAL.1991.175780;10.1109/VISUAL.1998.745300;10.1109/VISUAL.1994.346334	Isosurface, point-based, view-dependent, large datasets, interactive	University of Utah##University of Utah
Vis	2004	Interactive Poster: Grid-Enabled Collaborative Scientific Visualization Environment	10.1109/VISUAL.2004.53	http://dx.doi.org/10.1109/VISUAL.2004.53	18	18	M		Eric Christopher Wyatt;Patrick O'Leary	Northern Arizona University|c|;			Northern Arizona University|c|;
Vis	2004	Interactive Poster: Illustrating Different Convection Velocities of Turbulent Flow	10.1109/VISUAL.2004.54	http://dx.doi.org/10.1109/VISUAL.2004.54	24	24	M		Timothy Urness;Victoria Interrante;Ellen Longmire;Ivan Marusic;Bharathram Ganapathisubramani	University of Minnesota|c|;;;;			University of Minnesota|c|;;;;
Vis	2004	Interactive terascale particle visualization	10.1109/VISUAL.2004.55	http://dx.doi.org/10.1109/VISUAL.2004.55	353	360	C		David Ellsworth;Bryan Green;Patrick J. Moran	NASA Ames Res. Center, Moffett Field, CA, USA|c|;;	10.1109/VISUAL.2003.1250375;10.1109/VISUAL.1998.745299;10.1109/VISUAL.1997.663888;10.1109/VISUAL.2003.1250420;10.1109/VISUAL.1994.346311;10.1109/VISUAL.1998.745343;10.1109/VISUAL.1995.480821	visualization, particle tracing, large data, out-of-core, PC hardware, clusters, computational fluid dynamics	Advanced Management Technology, Inc. NASA Ames Research Center##Advanced Management Technology, Inc. NASA Ames Research Center##Advanced Management Technology, Inc. NASA Ames Research Center
Vis	2004	Interactive thickness visualization of articular cartilage	10.1109/VISUAL.2004.56	http://dx.doi.org/10.1109/VISUAL.2004.56	521	527	C		Matej Mlejnek;Anna Vilanova;Eduard Gröller	ICGA, Vienna Univ. of Technol., Austria|c|;;	10.1109/VISUAL.2002.1183795;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2001.964540	visualization in medicine, applications of visualization	ICGA Vienna University of Technology##ICGA Vienna University of Technology##ICGA Vienna University of Technology
Vis	2004	Introducing Topological Attributes for Objective-Based Visualization	10.1109/VISUAL.2004.57	http://dx.doi.org/10.1109/VISUAL.2004.57	6	6	M		Yuriko Takeshima;Shigeo Takahashi;Issei Fujishiro;Gregory M. Nielson	JAERI|c|;;;			JAERI|c|;;;
Vis	2004	Intuitive and interactive modification of large finite element models	10.1109/VISUAL.2004.58	http://dx.doi.org/10.1109/VISUAL.2004.58	361	368	C		Dirc Rose;Katrin Bidmon;Thomas Ertl	Visualization & Interactive Syst. Group, Stuttgart Univ., Germany|c|;;	10.1109/VISUAL.2002.1183829	finite element modeling, interaction, manipulators, autostereoscopy	University of Stuttgart##University of Stuttgart##University of Stuttgart
Vis	2004	Investigating swirl and tumble flow with a comparison of visualization techniques	10.1109/VISUAL.2004.59	http://dx.doi.org/10.1109/VISUAL.2004.59	51	58	C		Robert S. Laramee;Daniel Weiskopf;Jürgen Schneider;Helwig Hauser	VRV, Vienna, Austria|c|;;;	10.1109/VISUAL.1999.809918;10.1109/VISUAL.1999.809895;10.1109/VISUAL.2000.885690;10.1109/VISUAL.2003.1250363;10.1109/VISUAL.2003.1250377;10.1109/VISUAL.2003.1250361;10.1109/VISUAL.2003.1250364	Flow visualization, computational fluid dynamics (CFD), swirl flow, tumble flow, visualization systems, engine simulation, in-cylinder flow	VIS##University of Stuttgart
Vis	2004	Atlas-Aware Laplacian Smoothing	10.1109/VISUAL.2004.6	http://dx.doi.org/10.1109/VISUAL.2004.6	27	27	M		Peter G. Sibley;Gabriel Taubin	Brown University|c|;			Brown University|c|;
Vis	2004	JointViewer - An Interactive System for Exploring Orthopedic Data	10.1109/VISUAL.2004.60	http://dx.doi.org/10.1109/VISUAL.2004.60	35	35	M		G. Elisabeta Marai;Çagatay Demiralp;Stuart Andrews;David H. Laidlaw	Brown University|c|;;;			Brown University|c|;;;
Vis	2004	The human visual system: how is its design related to the physics of the natural environment?	10.1109/VISUAL.2004.61	http://dx.doi.org/10.1109/VISUAL.2004.61	xviii		M		Wilson S. Geisler	Dept. of Psychol., Texas Univ., Austin, TX, USA|c|			Dept. of Psychol., Texas Univ., Austin, TX, USA|c|
Vis	2004	Light Collages: lighting design for effective visualization	10.1109/VISUAL.2004.62	http://dx.doi.org/10.1109/VISUAL.2004.62	281	288	C		Chang Ha Lee;Xuejun Hao;Amitabh Varshney	Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA|c|;;	10.1109/VISUAL.2003.1250394;10.1109/VISUAL.2003.1250392;10.1109/VISUAL.2003.1250395;10.1109/VISUAL.2002.1183785	Lighting design, scientific illustration, inconsistent lighting, light placement, silhouette enhancement, proximity shadows	UMIACS University of Maryland at College Park College Park##UMIACS University of Maryland at College Park College Park##UMIACS University of Maryland at College Park College Park
Vis	2004	Light weight space leaping using ray coherence	10.1109/VISUAL.2004.63	http://dx.doi.org/10.1109/VISUAL.2004.63	19	26	C		Sarang Lakare;Arie E. Kaufman	Dept. of Comput. Sci., Stony Brook Univ., NY, USA|c|;	10.1109/VISUAL.1993.398852;10.1109/VISUAL.1999.809914;10.1109/VISUAL.1990.146377;10.1109/VISUAL.1998.745713;10.1109/VISUAL.2002.1183775	Direct Volume Rendering, Space Leaping, Empty Space Skipping, Ray Coherence, Volume Rendering Acceleration	Stony Brook University Stony Brook##Stony Brook University Stony Brook
Vis	2004	Lighting transfer functions using gradient aligned sampling	10.1109/VISUAL.2004.64	http://dx.doi.org/10.1109/VISUAL.2004.64	289	296	C		Eric B. Lum;Kwan-Liu Ma	California Univ., Davis, CA, USA|c|;	10.1109/VISUAL.2001.964519;10.1109/VISUAL.2000.885697;10.1109/VISUAL.1990.146391;10.1109/VISUAL.1999.809886	direct volume rendering, volume visualization, multi-dimensional transfer functions, shading, transfer functions	University of California Davis##University of California Davis
Vis	2004	Linear and cubic box splines for the body centered cubic lattice	10.1109/VISUAL.2004.65	http://dx.doi.org/10.1109/VISUAL.2004.65	11	18	C		Alireza Entezari;Ramsay Dyer;Torsten Möller	Graphics, Usability, & Visualization Lab., Simon Fraser Univ., Burnaby, BC, Canada|c|;;	10.1109/VISUAL.1993.398851;10.1109/VISUAL.2001.964498;10.1109/VISUAL.1997.663848;10.1109/VISUAL.1994.346331;10.1109/VISUAL.2001.964499	Body Centered Cubic Lattice, Reconstruction, Optimal Regular Sampling	Simon Fraser University##Simon Fraser University##Simon Fraser University
Vis	2004	Linking Representation with Meaning	10.1109/VISUAL.2004.66	http://dx.doi.org/10.1109/VISUAL.2004.66	5	5	M		David J. Duke	University of Leeds|c|			University of Leeds|c|
Vis	2004	Live Range Visibility Constraints for Adaptive Terrain Visualization	10.1109/VISUAL.2004.67	http://dx.doi.org/10.1109/VISUAL.2004.67	12	12	M		Xiaohong Bao;Renato Pajarola;Michael Shafae	University of California at Irvine|c|;;			University of California at Irvine|c|;;
Vis	2004	Local and global comparison of continuous functions	10.1109/VISUAL.2004.68	http://dx.doi.org/10.1109/VISUAL.2004.68	275	280	C		Herbert Edelsbrunner;John Harer;Vijay Natarajan;Valerio Pascucci	Dept. of Comput. Sci. & Math., Duke Univ., Durham, NC, USA|c|;;;		Visualization, Riemannian manifolds, smooth functions, time-varying data, comparison measure, differential forms	Dept. of Comput. Sci. & Math., Duke Univ., Durham, NC, USA|c|;;;
Vis	2004	LoD volume rendering of FEA data	10.1109/VISUAL.2004.69	http://dx.doi.org/10.1109/VISUAL.2004.69	417	424	C		Shyh-Kuang Ueng;Yan-Jen Su;Chi-Tang Chang	Dept. of Comput. Sci., Nat. Taiwan Ocean Univ., Keelung, Taiwan|c|;;	10.1109/VISUAL.1999.809908;10.1109/VISUAL.1995.485144;10.1109/VISUAL.2002.1183767;10.1109/VISUAL.2000.885680;10.1109/VISUAL.2000.885682;10.1109/VISUAL.2000.885680;10.1109/VISUAL.2001.964490;10.1109/VISUAL.1993.398877;10.1109/VISUAL.1992.235228;10.1109/VISUAL.1998.745309;10.1109/VISUAL.1999.809909	Volume rendering, splatting method, level-of-detail, unstructured data, scientific visualization	National Taiwan Ocean University##National Taiwan Ocean University##National Taiwan Ocean University
Vis	2004	Augmented reality with tangible auto-fabricated models for molecular biology applications	10.1109/VISUAL.2004.7	http://dx.doi.org/10.1109/VISUAL.2004.7	235	241	C		Alexandre Gillet;Michel F. Sanner;Daniel Stoffler;David S. Goodsell;Arthur J. Olson	;;;;		Molecular Modeling, Molecular Visualization, Augmented Reality	The Scripps Research Institute##The Scripps Research Institute##The Scripps Research Institute##The Scripps Research Institute##The Scripps Research Institute
Vis	2004	Methods for efficient, high quality volume resampling in the frequency domain	10.1109/VISUAL.2004.70	http://dx.doi.org/10.1109/VISUAL.2004.70	3	10	C		Aili Li;Klaus Mueller;Thomas Ernst	Comput. Sci. Dept., State Univ. of New York, Stony Brook, NY, USA|c|;;	10.1109/VISUAL.1994.346331	resampling, filters, Fourier Transform	Comput. Sci. Dept., State Univ. of New York, Stony Brook, NY, USA|c|;;
Vis	2004	Modeling Decomposing Objects under Combustion	10.1109/VISUAL.2004.71	http://dx.doi.org/10.1109/VISUAL.2004.71	14	14	M		Zeki Melek;John Keyser	Texas A&M University|c|;			Texas A&M University|c|;
Vis	2004	Non-linear model fitting to parameterize diseased blood vessels	10.1109/VISUAL.2004.72	http://dx.doi.org/10.1109/VISUAL.2004.72	393	400	C		Alexandra La Cruz;Matús Straka;Arnold Köchl;Milos Srámek;Eduard Gröller;Dominik Fleischmann	Vienna Univ. of Technol., Austria|c|;;;;;	10.1109/VISUAL.2001.964555	Visualization, Segmentation, Blood Vessel Detection	Vienna University of Technology##Vienna University of Technology##Vienna University of Technology##Vienna University of Technology##Vienna University of Technology##Vienna University of Technology##Vienna University of Technology
Vis	2004	On the role of color in the perception of motion in animated visualizations	10.1109/VISUAL.2004.73	http://dx.doi.org/10.1109/VISUAL.2004.73	305	312	C		Daniel Weiskopf	Inst. of Visualization & Interactive Syst., Stuttgart Univ., Germany|c|	10.1109/VISUAL.2002.1183788;10.1109/VISUAL.2003.1250362;10.1109/VISUAL.2003.1250361;10.1109/VISUAL.1997.663874	Color, luminance, motion detection, perception, human visual system, flow visualization, information visualization	University of Stuttgart
Vis	2004	On the Visualization of Time-Varying Structured Grids Using a 3D Warp Texture	10.1109/VISUAL.2004.74	http://dx.doi.org/10.1109/VISUAL.2004.74	17	17	M		Yuan Chen;Jonathan D. Cohen;Subodh Kumar	Johns Hopkins University|c|;;			Johns Hopkins University|c|;;
Vis	2004	Optimal global conformal surface parameterization	10.1109/VISUAL.2004.75	http://dx.doi.org/10.1109/VISUAL.2004.75	267	274	C		Miao Jin;Yalin Wang;Shing-Tung Yau;Xianfeng Gu	Dept. of Comput. Sci., State Univ. of New York, Stony Brook, NY, USA|c|;;;		Computational geometry and object modeling, Curve / surface / solid and object representations, Surface parameterization	UCLA##UCLA##UCLA##UCLA
Vis	2004	Panel 1: Can We Determine the Top Unresolved Problems of Visualization?	10.1109/VISUAL.2004.76	http://dx.doi.org/10.1109/VISUAL.2004.76	563	566	M		Theresa-Marie Rhyne;William L. Hibbard;Christopher R. Johnson 0001;Chaomei Chen;Steve Eick	North Carolina State University|c|;;;;			North Carolina State University|c|;;;;
Vis	2004	Panel 2: In the Eye of the Beholder: The Role of Perception in Scientific Visualization	10.1109/VISUAL.2004.77	http://dx.doi.org/10.1109/VISUAL.2004.77	567	568	M		Kelly P. Gaither;David S. Ebert;Bill Geisler;David H. Laidlaw	University of Texas at Austin|c|;;;;			University of Texas at Austin|c|;;;;
Vis	2004	Panel 3: The Future Visualization Platform	10.1109/VISUAL.2004.78	http://dx.doi.org/10.1109/VISUAL.2004.78	569	571	M		Greg Johnson;David S. Ebert;Charles D. Hansen;David Kirk;Bill Mark;Hanspeter Pfister	University of Texas at Austin|c|;;;;;			University of Texas at Austin|c|;;;;;
Vis	2004	Panel 4: What Should We Teach in a Scientific Visualization Class?	10.1109/VISUAL.2004.79	http://dx.doi.org/10.1109/VISUAL.2004.79	573	575	M		Jon D. Genetti;Michael J. Bailey;David H. Laidlaw;Robert J. Moorhead II;Ross T. Whitaker	University of Alaska Fairbanks|c|;;;;;			University of Alaska Fairbanks|c|;;;;;
Vis	2004	Physically based methods for tensor field visualization	10.1109/VISUAL.2004.80	http://dx.doi.org/10.1109/VISUAL.2004.80	123	130	C		Ingrid Hotz;Louis Feng;Hans Hagen;Bernd Hamann;Kenneth I. Joy;Boris Jeremic	IDAV, California Univ., Davis, CA, USA|c|;;;;;	10.1109/VISUAL.1998.745316;10.1109/VISUAL.1999.809894;10.1109/VISUAL.1993.398849;10.1109/VISUAL.2002.1183798;10.1109/VISUAL.1994.346326;10.1109/VISUAL.2002.1183782;10.1109/VISUAL.2002.1183799;10.1109/VISUAL.2003.1250379	tensors field, stress tensor, strain tensor, LIC	IDAV##IDAV##Technical University of Kaiserslautern##IDAV##IDAV##University of California
Vis	2004	Pixel-exact rendering of spacetime finite element solutions	10.1109/VISUAL.2004.81	http://dx.doi.org/10.1109/VISUAL.2004.81	425	432	C		Yuan Zhou;Michael Garland;Robert Haber	Dept. of Comput. Sci., Illinois Univ., Urbana, IL, USA|c|;;	10.1109/VISUAL.2000.885704;10.1109/VISUAL.1990.146361;10.1109/VISUAL.2003.1250354;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2003.1250386	pixel-exact visualization, pixel shaders, spacetime finite elements, discontinuous Galerkin methods	University of Illinois at Urbanaâ€“Champaign##University of Illinois at Urbanaâ€“Champaign##University of Illinois at Urbanaâ€“Champaign
Vis	2004	PQuad: visualization of predicted peptides and proteins	10.1109/VISUAL.2004.82	http://dx.doi.org/10.1109/VISUAL.2004.82	473	480	C		Susan L. Havre;Mudita Singhal;Deborah A. Payne;Bobbie-Jo M. Webb-Robertson	Pacific Northwest Nat. Lab., Richland, WA, USA|c|;;;	10.1109/INFVIS.1995.528685	visualization, metaphor, context, proteomics, differential proteomics, difference visualization	Pacific Northwest Nat. Lab., Richland, WA, USA|c|;;;
Vis	2004	Projecting tetrahedra without rendering artifacts	10.1109/VISUAL.2004.85	http://dx.doi.org/10.1109/VISUAL.2004.85	27	34	C		Martin Kraus;Wei Qiao;David S. Ebert	Purdue Univ., West Lafayette, IN, USA|c|;;	10.1109/VISUAL.2000.885683;10.1109/VISUAL.2003.1250390;10.1109/VISUAL.2001.964514;10.1109/VISUAL.2003.1250384	volume visualization, volume rendering, cell projection, projected tetrahedra, perspective interpolation, dithering, programmable graphics hardware	Purdue University##Purdue University##Purdue University
Vis	2004	Quick-VDR: interactive view-dependent rendering of massive models	10.1109/VISUAL.2004.86	http://dx.doi.org/10.1109/VISUAL.2004.86	131	138	C		Sung-Eui Yoon;Brian Salomon;Russell Gayle;Dinesh Manocha	Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;	10.1109/VISUAL.2002.1183760;10.1109/VISUAL.2003.1250366;10.1109/VISUAL.2001.964503;10.1109/VISUAL.2002.1183796;10.1109/VISUAL.1998.745282;10.1109/VISUAL.2001.964534;10.1109/VISUAL.2003.1250368;10.1109/VISUAL.2001.964502	Interactive display, view-dependent rendering, occlusion culling, external-memory algorithm, levels-of-detail	Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;
Vis	2004	Radial hermite operators for scattered point cloud data with normal vectors and applications to implicitizing polygon mesh surfaces for generalized CSG operations and smoothing	10.1109/VISUAL.2004.87	http://dx.doi.org/10.1109/VISUAL.2004.87	203	210	C		Gregory M. Nielson	Arizona State Univ., AZ, USA|c|	10.1109/VISUAL.2002.1183766;10.1109/VISUAL.2003.1250358;10.1109/VISUAL.2004.28;10.1109/VISUAL.2002.1183782;10.1109/VISUAL.1996.567602;10.1109/VISUAL.2002.1183808;10.1109/VISUAL.2003.1250398;10.1109/VISUAL.2003.1250359	Surface reconstruction, point clouds, isosurfaces, polygon mesh	Arizona State University
Vis	2004	Real-time motion estimation and visualization on graphics cards	10.1109/VISUAL.2004.88	http://dx.doi.org/10.1109/VISUAL.2004.88	545	552	C		Robert Strzodka;Christoph S. Garbe	Caesar Res. Center, Bonn, Germany|c|;	10.1109/VISUAL.1999.809934;10.1109/VISUAL.2003.1250361;10.1109/VISUAL.2003.1250401;10.1109/VISUAL.2003.1250357	motion estimation, motion visualization, structure tensor, eigenvector analysis, real-time processing, graphics hardware	Caesar Res. Center, Bonn, Germany|c|;
Vis	2004	Real-Time Volume Rendering of Four Channel Data Sets	10.1109/VISUAL.2004.89	http://dx.doi.org/10.1109/VISUAL.2004.89	34	34	M		Jürgen P. Schulze;Alexander Rice	Brown University|c|;			Brown University|c|;
Vis	2004	Automatic Fast Detection of Tumor Suspect Areas on CT Scan	10.1109/VISUAL.2004.9	http://dx.doi.org/10.1109/VISUAL.2004.9	33	33	M		Matei Mancas;Bernard Gosselin;Benoit M. Macq	Polytechnique de Mons|c|;;			Polytechnique de Mons|c|;;
Vis	2004	Rendering implicit flow volumes	10.1109/VISUAL.2004.90	http://dx.doi.org/10.1109/VISUAL.2004.90	99	106	C		Daqing Xue;Caixia Zhang;Roger Crawfis	Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH, USA|c|;;	10.1109/VISUAL.2001.964519;10.1109/VISUAL.1993.398846;10.1109/VISUAL.2000.885688;10.1109/VISUAL.1991.175789;10.1109/VISUAL.2003.1250364;10.1109/VISUAL.1992.235211;10.1109/VISUAL.1996.567777;10.1109/VISUAL.2000.885704;10.1109/VISUAL.1999.809909;10.1109/VISUAL.2003.1250376;10.1109/VISUAL.2003.1250377;10.1109/VISUAL.1993.398875;10.1109/VISUAL.2003.1250378;10.1109/VISUAL.1999.809892	interval volume rendering, implicit stream flow, flow visualization, graphics hardware	The Ohio State University##The Ohio State University##The Ohio State University
Vis	2004	Rendering planar cuts through quadratic and cubic finite elements	10.1109/VISUAL.2004.91	http://dx.doi.org/10.1109/VISUAL.2004.91	409	416	C		Michael Brasher;Robert Haimes	Aerosp. Computational Design Lab., MIT, MA, USA|c|;		Higher Order Elements, Programmable Shaders, Cut-planes	Massachusetts Institute of Technology##Massachusetts Institute of Technology
Vis	2004	Rough interface reconstruction using the level set method	10.1109/VISUAL.2004.94	http://dx.doi.org/10.1109/VISUAL.2004.94	251	258	C		Yootai Kim;Raghu Machiraju;David S. Thompson	Ohio State Univ., Columbus, OH, USA|c|;;		point sampled data, surface reconstruction, level set method, shock filter, total variation preserving, rough surface	The Ohio State University##The Ohio State University##The Ohio State University
Vis	2004	Scout: a hardware-accelerated system for quantitatively driven visualization and analysis	10.1109/VISUAL.2004.95	http://dx.doi.org/10.1109/VISUAL.2004.95	171	178	C		Patrick S. McCormick;Jeff T. Inman;James P. Ahrens;Charles D. Hansen;Greg Roth	Advanced Comput. Lab., Los Alamos Nat. Lab., NM, USA|c|;;;;	10.1109/VISUAL.1995.480821;10.1109/VISUAL.1999.809864;10.1109/VISUAL.2001.964519;10.1109/VISUAL.2003.1250357	Visualization systems, hardware acceleration, multi-variate visualization, volume rendering	Advanced Comput. Lab., Los Alamos Nat. Lab., NM, USA|c|;;;;
Vis	2004	Simplifying flexible isosurfaces using local geometric measures	10.1109/VISUAL.2004.96	http://dx.doi.org/10.1109/VISUAL.2004.96	497	504	C		Hamish Carr;Jack Snoeyink;Michiel van de Panne	Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC, Canada|c|;;	10.1109/VISUAL.2001.964499;10.1109/VISUAL.2002.1183774	Isosurfaces, contourtrees, topological simplification	University of British Columbia##
Vis	2004	STEPS - an application for simulation of transsphenoidal endonasal pituitary surgery	10.1109/VISUAL.2004.98	http://dx.doi.org/10.1109/VISUAL.2004.98	513	520	C		André Neubauer;Stefan Wolfsberger;Marie-Thérèse Forster;Lukas Mroz;Rainer Wegenkittl;Katja Bühler	VRVis Res. Center, Vienna, Austria|c|;;;;;	10.1109/VISUAL.2000.885732;10.1109/VISUAL.2000.885702;10.1109/VISUAL.2000.885673	virtual endoscopy, ray casting, iso-surfacing, pituitary surgery	Tiani Medgraph AG Vienna########Tiani Medgraph AG Vienna##Tiani Medgraph AG Vienna
Vis	2004	Stream line and path line oriented topology for 2D time-dependent vector fields	10.1109/VISUAL.2004.99	http://dx.doi.org/10.1109/VISUAL.2004.99	321	328	C		Holger Theisel;Tino Weinkauf;Hans-Christian Hege;Hans-Peter Seidel	Max-Planck-Inst. fur Inf., Saarbrucken, Germany|c|;;;	10.1109/VISUAL.1999.809907;10.1109/VISUAL.2000.885714;10.1109/VISUAL.1993.398849;10.1109/VISUAL.1991.175773;10.1109/VISUAL.1996.567777;10.1109/VISUAL.2000.885716;10.1109/VISUAL.2001.964507;10.1109/VISUAL.2003.1250376	flow visualization, vector field topology, bifurcations, stream lines, path lines	MPI Informatik SaarbrÃ¼cken##INTRODUCTION
InfoVis	2005	Baby names, visualization, and social data analysis	10.1109/INFVIS.2005.1532122	http://dx.doi.org/10.1109/INFVIS.2005.1532122	1	7	C		Martin Wattenberg	IBM Res., White Plains, NY|c|	10.1109/INFVIS.2004.8;10.1109/INFVIS.2000.885098	Design Study, Time-Varying Data Visualization, Human-Computer Interaction	IBM Research
InfoVis	2005	A sky dome visualisation for identification of astronomical orientations	10.1109/INFVIS.2005.1532123	http://dx.doi.org/10.1109/INFVIS.2005.1532123	8	15	C		Georg Zotti;Eduard Gröller	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol.|c|;		 Archaeology, Astronomy, data mining	Vienna University of Technology##Vienna University of Technology
InfoVis	2005	Interactive visualization of genealogical graphs	10.1109/INFVIS.2005.1532124	http://dx.doi.org/10.1109/INFVIS.2005.1532124	16	23	C		Michael J. McGuffin;Ravin Balakrishnan	Dept. of Comput. Sci., Toronto Univ., Ont.|c|;	10.1109/INFVIS.2004.21;10.1109/INFVIS.1997.636718;10.1109/VISUAL.1991.175815;10.1109/INFVIS.2002.1173148	genealogy, genealogies, family trees, kinship, multi-trees, graph drawing, graph theory, graph browsing and navigation	University of Toronto##University of Toronto
InfoVis	2005	The visual code navigator: an interactive toolset for source code investigation	10.1109/INFVIS.2005.1532125	http://dx.doi.org/10.1109/INFVIS.2005.1532125	24	31	C		Gerard Lommerse;Freek Nossin;Lucian Voinea;Alexandru Telea	Technische Universiteit Eindhoven|c|;;;	10.1109/INFVIS.1999.801860;10.1109/VISUAL.2001.964495	source code visualization, multiple views, treemaps, pixel-filling displays, source code analysis	Technische Universiteit Eindhoven##Technische Universiteit Eindhoven##Technische Universiteit Eindhoven##Technische Universiteit Eindhoven
InfoVis	2005	Vizster: visualizing online social networks	10.1109/INFVIS.2005.1532126	http://dx.doi.org/10.1109/INFVIS.2005.1532126	32	39	C		Jeffrey Heer;Danah Boyd	Comput. Sci. Div., California Univ., Berkeley, CA|c|;	10.1109/INFVIS.2004.1	social networks, visualization, graphs, community,data mining, exploration, play	University of California
InfoVis	2005	PRISAD: a partitioned rendering infrastructure for scalable accordion drawing	10.1109/INFVIS.2005.1532127	http://dx.doi.org/10.1109/INFVIS.2005.1532127	41	48	C		James Slack;Kristian Hildebrand;Tamara Munzner	British Columbia Univ., Vancouver, BC, Canada|c|;;	10.1109/INFVIS.2002.1173156;10.1109/INFVIS.2004.64	Focus+Context, Information Visualization, Real Time Rendering, Progressive Rendering	British Columbia Univ., Vancouver, BC, Canada|c|;;
InfoVis	2005	Voronoi treemaps	10.1109/INFVIS.2005.1532128	http://dx.doi.org/10.1109/INFVIS.2005.1532128	49	56	C		Michael Balzer;Oliver Deussen	Dept. of Comput. & Inf. Sci., Konstanz Univ., Germany|c|;	10.1109/INFVIS.2004.19;10.1109/INFVIS.2001.963283;10.1109/VISUAL.1991.175815;10.1109/VISUAL.2004.13;10.1109/VISUAL.1992.235217;10.1109/INFVIS.1999.801860	Voronoi Treemaps, Information Visualization, Hierarchies, Trees, Treemaps, Voronoi Tessellations	University of Konstanz##University of Konstanz
InfoVis	2005	Elastic hierarchies: combining treemaps and node-link diagrams	10.1109/INFVIS.2005.1532129	http://dx.doi.org/10.1109/INFVIS.2005.1532129	57	64	C		Shengdong Zhao;Michael J. McGuffin;Mark H. Chignell	Toronto Univ., Ont., Canada|c|;;	10.1109/INFVIS.2000.885091;10.1109/INFVIS.2002.1173148	Elastic Hierarchies, Treemaps, node-link diagrams, hybrids, combinations, overview+detail, multiple views, trees, interaction techniques, interactive visualization	University of Toronto##University of Toronto##University of Toronto
InfoVis	2005	Dig-CoLa: directed graph layout through constrained energy minimization	10.1109/INFVIS.2005.1532130	http://dx.doi.org/10.1109/INFVIS.2005.1532130	65	72	C		Tim Dwyer;Yehuda Koren	Sch. of Comput. Sci. & Software Eng., Monash Univ., Australia|c|;			Monash University##Monash University
InfoVis	2005	Dynamic visualization of graphs with extended labels	10.1109/INFVIS.2005.1532131	http://dx.doi.org/10.1109/INFVIS.2005.1532131	73	80	C		Pak Chung Wong;Patrick Mackey;Ken Perrine;James R. Eagan;Harlan Foote;James J. Thomas	Pacific Northwest Nat. Lab., Richland, WA, USA|c|;;;;;		Graph Label Placement, Dynamic Animation, Graph Visualization, Information Visualization	Georgia Institute of Technology####
InfoVis	2005	An evaluation of content browsing techniques for hierarchical space-filling visualizations	10.1109/INFVIS.2005.1532132	http://dx.doi.org/10.1109/INFVIS.2005.1532132	81	88	C		Kang Shi;Pourang Irani;Pak Ching Li	Dept. of Comput. Sci., Manitoba Univ., Winnipeg, Man., Canada|c|;;	10.1109/INFVIS.2000.885091;10.1109/INFVIS.2004.21	browsing, distortion, hierarchy navigation, focus+context, drill-down, space-filling visualization, TreeMap, semantic zooming	University of Manitoba##University of Manitoba
InfoVis	2005	Turning the bucket of text into a pipe	10.1109/INFVIS.2005.1532133	http://dx.doi.org/10.1109/INFVIS.2005.1532133	89	94	C		Elizabeth G. Hetzler;Vernon L. Crow;Deborah A. Payne;Alan Turner	Pacific Northwest Nat. Lab., Richland, WA, USA|c|;;;	10.1109/INFVIS.2001.963274;10.1109/INFVIS.2002.1173160;10.1109/INFVIS.2003.1249014;10.1109/INFVIS.1999.801853	Information Visualization, Dynamic visualization, User interaction design, real-time updating	Pacific Northwest Nat. Lab., Richland, WA, USA|c|;;;
InfoVis	2005	Visual correlation for situational awareness	10.1109/INFVIS.2005.1532134	http://dx.doi.org/10.1109/INFVIS.2005.1532134	95	102	C		Yarden Livnat;James Agutter;Shaun Moon;Stefano Foresti	Sci. Comput. & Imaging Inst., Utah Univ., USA|c|;;;	10.1109/VISUAL.2003.1250415	situation awareness, network intrusion, visualization	University of Utah##University of Utah##University of Utah##University of Utah
InfoVis	2005	Highlighting conflict dynamics in event data	10.1109/INFVIS.2005.1532135	http://dx.doi.org/10.1109/INFVIS.2005.1532135	103	110	C		Ulrik Brandes;Daniel Fleischer;Jürgen Lerner	Dept. of Comput. & Inf. Sci., Konstanz Univ., Germany|c|;;		information visualization, text mining, event analysis, time-dependent visualization	University of Konstanz##University of Konstanz##University of Konstanz
InfoVis	2005	Low-level components of analytic activity in information visualization	10.1109/INFVIS.2005.1532136	http://dx.doi.org/10.1109/INFVIS.2005.1532136	111	117	C		Robert A. Amar;James R. Eagan;John T. Stasko	Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;;	10.1109/VISUAL.1990.146375;10.1109/INFVIS.1998.729560;10.1109/INFVIS.2000.885092;10.1109/INFVIS.2004.5;10.1109/INFVIS.2001.963289	Analytic activity, taxonomy, knowledge discovery, design, evaluation	Georgia Institute of Technology##Georgia Institute of Technology##Georgia Institute of Technology
InfoVis	2005	Simple 3D glyphs for spatial multivariate data	10.1109/INFVIS.2005.1532137	http://dx.doi.org/10.1109/INFVIS.2005.1532137	119	124	C		Camilla Forsell;Stefan Seipel;Mats Lind	Dept. of Inf. Sci., Uppsala Univ., Sweden|c|;;		multidimensional visualization, perception, 3D glyphs	Uppsala University Uppsala##University of GÃ¤vle GÃ¤vle##Uppsala University Uppsala
InfoVis	2005	Revealing structure within clustered parallel coordinates displays	10.1109/INFVIS.2005.1532138	http://dx.doi.org/10.1109/INFVIS.2005.1532138	125	132	C		Jimmy Johansson;Patric Ljung;Mikael Jern;Matthew D. Cooper	Norrkoping Visualization & Interaction Studio, Linkoping Univ., Sweden|c|;;;	10.1109/VISUAL.1990.146402;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2004.68	Parallel coordinates, clustering, transfer function, feature animation	Norrkoping Visualization & Interaction Studio, Linkoping Univ., Sweden|c|;;;
InfoVis	2005	Parallel sets: visual analysis of categorical data	10.1109/INFVIS.2005.1532139	http://dx.doi.org/10.1109/INFVIS.2005.1532139	133	140	C		Fabian Bendix;Robert Kosara;Helwig Hauser	VRVis Res. Center, Vienna, Austria|c|;;	10.1109/VISUAL.1990.146386;10.1109/VISUAL.1990.146402;10.1109/INFVIS.2003.1249016;10.1109/INFVIS.2002.1173157	 categorical data, meta information, interaction	VRVis Res. Center, Vienna, Austria|c|;;
InfoVis	2005	Multivariate glyphs for multi-object clusters	10.1109/INFVIS.2005.1532140	http://dx.doi.org/10.1109/INFVIS.2005.1532140	141	148	C		Eleanor Boyle Chlan;Penny Rheingans	Whiting Sch. of Eng., Johns Hopkins Univ., Baltiomore, MD, USA|c|;	10.1109/INFVIS.1995.528691;10.1109/VISUAL.1996.568111;10.1109/VISUAL.1999.809866;10.1109/VISUAL.2000.885677	information visualization, multivariate visualization, distribution, aggregated data	Johns Hopkins University##Johns Hopkins University
InfoVis	2005	An interactive 3D integration of parallel coordinates and star glyphs	10.1109/INFVIS.2005.1532141	http://dx.doi.org/10.1109/INFVIS.2005.1532141	149	156	C		Elena Fanea;M. Sheelagh T. Carpendale;Tobias Isenberg 0001	Dept. of Comput. Sci., Calgary Univ., Alta., Canada|c|;;	10.1109/VISUAL.1995.485139;10.1109/INFVIS.2003.1249024;10.1109/INFVIS.2003.1249008;10.1109/INFVIS.2002.1173157;10.1109/INFVIS.2004.71;10.1109/INFVIS.2003.1249015;10.1109/INFVIS.2004.15;10.1109/INFVIS.2004.68;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2002.1173151;10.1109/VISUAL.1994.346302;10.1109/VISUAL.1997.663866;10.1109/VISUAL.1990.146402	Parallel Glyphs, parallel coordinates, star glyphs, multi-dimensional data sets, 3D visualization	University of Calgary##University of Calgary##University of Calgary
InfoVis	2005	Graph-theoretic scagnostics	10.1109/INFVIS.2005.1532142	http://dx.doi.org/10.1109/INFVIS.2005.1532142	157	164	C		Leland Wilkinson;Anushka Anand;Robert L. Grossman	SPSS Inc., Chicago, IL, USA|c|;;	10.1109/INFVIS.2003.1249006;10.1109/INFVIS.2004.3;10.1109/INFVIS.2004.15	visualization, statistical graphics	SPSS Inc. Northwestern University##SPSS Inc. Northwestern University##SPSS Inc. Northwestern University
InfoVis	2005	Visualizing coordination in situ	10.1109/INFVIS.2005.1532143	http://dx.doi.org/10.1109/INFVIS.2005.1532143	165	172	C		Chris Weaver	Comput. Sci. Dept., Univ. of Wisconsin-Madison, Madison, WI, USA|c|	10.1109/INFVIS.2002.1173141;10.1109/INFVIS.2004.12;10.1109/INFVIS.2004.64;10.1109/INFVIS.1996.559213;10.1109/INFVIS.1997.636792;10.1109/INFVIS.2002.1173142;10.1109/INFVIS.2000.885092;10.1109/INFVIS.2002.1173163	coordination, exploratory visualization, linked views, software visualization, metavisualization	University of Wisconsinâ€“Madison
InfoVis	2005	Two-tone pseudo coloring: compact visualization for one-dimensional data	10.1109/INFVIS.2005.1532144	http://dx.doi.org/10.1109/INFVIS.2005.1532144	173	180	C		Takafumi Saito;Hiroko Miyamura;Mitsuyoshi Yamamoto;Hiroki Saito;Yuka Hoshiya;Takumi Kaseda	Tokyo Univ. of Agric. & Technol., Japan|c|;;;;;		pseudo color, overview, detail, focus+context, data density	Tokyo University of Agriculture and Technology##Tokyo University of Agriculture and Technology##Tokyo University of Agriculture and Technology##Tokyo University of Agriculture and Technology##Tokyo University of Agriculture and Technology##Tokyo University of Agriculture and Technology##Tokyo University of Agriculture and Technology
InfoVis	2005	A note on space-filling visualizations and space-filling curves	10.1109/INFVIS.2005.1532145	http://dx.doi.org/10.1109/INFVIS.2005.1532145	181	186	C		Martin Wattenberg	IBM Res., White Plains, NY, USA|c|	10.1109/INFVIS.2001.963283;10.1109/INFVIS.2002.1173152	Hierarchy Visualization	IBM Research
InfoVis	2005	An optimization-based approach to dynamic visual context management	10.1109/INFVIS.2005.1532146	http://dx.doi.org/10.1109/INFVIS.2005.1532146	187	194	C		Zhen Wen;Michelle X. Zhou;Vikram Aggarwal	IBM T. J. Watson Res. Center, Hawthorne, NY, USA|c|;;	10.1109/INFVIS.2000.885091;10.1109/INFVIS.2000.885093;10.1109/INFVIS.1997.636718	intelligent multimodal interfaces, visual context management, automated generation of visualization, visual momentum	IBM T. J. Watson Res. Center, Hawthorne, NY, USA|c|;;
InfoVis	2005	Adapting the cognitive walkthrough method to assess the usability of a knowledge domain visualization	10.1109/INFVIS.2005.1532147	http://dx.doi.org/10.1109/INFVIS.2005.1532147	195	202	C		Kenneth R. Allendoerfer;Serge Aluker;Gulshan Panjwani;Jason M. Proctor;David Sturtz;Mirjana Vukovic;Chaomei Chen	Coll. of Inf. Sci. & Technol., Drexel Univ., Philadelphia, PA, USA|c|;;;;;;		Cognitive Walkthrough, usability inspection methods, bibliographic networks	Coll. of Inf. Sci. & Technol., Drexel Univ., Philadelphia, PA, USA|c|;;;;;;
InfoVis	2005	Importance-driven visualization layouts for large time series data	10.1109/INFVIS.2005.1532148	http://dx.doi.org/10.1109/INFVIS.2005.1532148	203	210	C		Ming C. Hao;Umeshwar Dayal;Daniel A. Keim;Tobias Schreck	Hewlett-Packard Labs., Palo Alto, CA, USA|c|;;;	10.1109/INFVIS.1999.801867;10.1109/INFVIS.1999.801851;10.1109/VISUAL.1995.485140;10.1109/INFVIS.1999.801860;10.1109/INFVIS.2000.885086	Information Visualization, Time Series, Space-Filling Layout Generation	Hewlett-Packard Laboratories##Hewlett-Packard Laboratories##University of Konstanz##University of Konstanz
InfoVis	2005	Temporal visualization of planning polygons for efficient partitioning of geo-spatial data	10.1109/INFVIS.2005.1532149	http://dx.doi.org/10.1109/INFVIS.2005.1532149	211	218	C		Poonam Shanbhag;Penny Rheingans;Marie desJardins	Maryland Univ., Baltimore, MD, USA|c|;;	10.1109/INFVIS.2001.963273;10.1109/INFVIS.2001.963274	Temporal visualization, time-dependent attributes, spatial data, multi-attribute visualization, resource allocation	University of Maryland##University of Maryland##University of Maryland
InfoVis	2005	Flow map layout	10.1109/INFVIS.2005.1532150	http://dx.doi.org/10.1109/INFVIS.2005.1532150	219	224	C		Doantam Phan;Ling Xiao;Ron B. Yeh;Pat Hanrahan;Terry Winograd	Stanford Univ., CA, USA|c|;;;	10.1109/INFVIS.1995.528697;10.1109/INFVIS.1996.559226	flow maps, GIS, hierarchical clustering	Stanford University##Stanford University##Stanford University##Stanford University##Stanford University
InfoVis	2005	Visualization of graphs with associated timeseries data	10.1109/INFVIS.2005.1532151	http://dx.doi.org/10.1109/INFVIS.2005.1532151	225	232	C		Purvi Saraiya;Peter Lee 0005;Chris North	Dept. of Comput. Sci., Virginia Polytech. Inst. & State Univ., Blacksburg, VA, USA|c|;;	10.1109/INFVIS.2004.1;10.1109/INFVIS.1996.559226;10.1109/INFVIS.2003.1249009	Graph visualization, data overlay, timeseries data analysis, usability experiments	Virginia Polytechnic Institute and State University Blacksburg##Virginia Polytechnic Institute and State University Blacksburg##Virginia Polytechnic Institute and State University Blacksburg
InfoVis	2005	Interactive Sankey diagrams	10.1109/INFVIS.2005.1532152	http://dx.doi.org/10.1109/INFVIS.2005.1532152	233	240	C		Patrick Riehmann;Manfred Hanfler;Bernd Fröhlich 0001	Fac. of Media, Bauhaus Univ. Weimar, Germany|c|;;	10.1109/VISUAL.1993.398870;10.1109/INFVIS.1996.559226	Sankey diagram, flow diagram	Bauhaus University Weimar##Bauhaus University Weimar##Bauhaus University Weimar
InfoVis	2005	Turning information visualization innovations into commercial products: lessons to guide the next success	10.1109/INFVIS.2005.1532153	http://dx.doi.org/10.1109/INFVIS.2005.1532153	241	244	M		Ben Shneiderman;Ramana Rao;Keith Andrews;Christopher Ahlberg;Dominique Brodbeck;Tony Jewitt;Jock D. Mackinlay	Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA|c|;;;;;;			Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA|c|;;;;;;
Vis	2005	2D asymmetric tensor analysis	10.1109/VISUAL.2005.1532770	http://dx.doi.org/10.1109/VISUAL.2005.1532770	3	10	C		Xiaoqiang Zheng;Alex T. Pang	Comput. Sci. Dept., California Univ., Santa Cruz, CA, USA|c|;	10.1109/VISUAL.1997.663929;10.1109/VISUAL.1998.745291;10.1109/VISUAL.1994.346326;10.1109/VISUAL.1994.346326;10.1109/VISUAL.2004.80;10.1109/VISUAL.1998.745294;10.1109/VISUAL.1999.809886	critical points, general tensors, symmetric tensors,degenerate tensors, tensor topology, topological lines, hyperstream-lines	University of California##University of California
Vis	2005	Exploring 2D tensor fields using stress nets	10.1109/VISUAL.2005.1532771	http://dx.doi.org/10.1109/VISUAL.2005.1532771	11	18	C		Andrew T. Wilson;Rebecca M. Brannon	Sandia Nat. Labs., Albuquerque, NM, USA|c|;	10.1109/VISUAL.1998.745316;10.1109/VISUAL.1992.235193;10.1109/VISUAL.2002.1183799;10.1109/VISUAL.1994.346326;10.1109/VISUAL.1999.809894;10.1109/VISUAL.2000.885690;10.1109/VISUAL.1993.398849	tensor field, stress tensor, streamlines,controlled density streamlines, crack propagation	Sandia Nat. Labs., Albuquerque, NM, USA|c|;
Vis	2005	Illuminated lines revisited	10.1109/VISUAL.2005.1532772	http://dx.doi.org/10.1109/VISUAL.2005.1532772	19	26	C		Ovidio Mallo;Ronald Peikert;Christian Sigg;Filip Sadlo	Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;;;	10.1109/VISUAL.2004.5;10.1109/VISUAL.2003.1250378;10.1109/VISUAL.2002.1183797;10.1109/VISUAL.1996.567777;10.1109/VISUAL.1997.663912	Field lines, illumination, vector field visualization,texture mapping, graphics hardware	Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;;;
Vis	2005	HOT-lines: tracking lines in higher order tensor fields	10.1109/VISUAL.2005.1532773	http://dx.doi.org/10.1109/VISUAL.2005.1532773	27	34	C		Mario Hlawitschka;Gerik Scheuermann	Inst. for Comput. Sci., Leipzig Univ., Germany|c|;	10.1109/VISUAL.2004.105;10.1109/VISUAL.1992.235193;10.1109/VISUAL.2000.885716;10.1109/VISUAL.2002.1183797;10.1109/VISUAL.1994.346326	Higher order tensors, spherical harmonics, tensor lines, tractography, vector/tensor visualization, visualization in medicine, DT-MRI	University of Leipzig Leipzig##University of Leipzig Leipzig
Vis	2005	Visualizing tensor fields in geomechanics	10.1109/VISUAL.2005.1532774	http://dx.doi.org/10.1109/VISUAL.2005.1532774	35	42	C		Alisa Neeman;Boris Jeremic;Alex T. Pang	Comput. Sci. Dept., UCSC, CA, USA|c|;;	10.1109/VISUAL.1998.745294;10.1109/VISUAL.1999.809886	symmetric tensors, stress tensor, seismic moment tensor, anisotropic, deviatoric, double couple, compensated linear vector dipole	UCSC##UCSC##UCSC
Vis	2005	Framework for visualizing higher-order basis functions	10.1109/VISUAL.2005.1532776	http://dx.doi.org/10.1109/VISUAL.2005.1532776	43	50	C		William J. Schroeder;François Bertel;Mathieu Malaterre;David C. Thompson;Philippe P. Pébay;Robert M. O'Bara;Saurabh Tendulkar	;;;;;;	10.1109/VISUAL.1997.663886;10.1109/VISUAL.2004.15;10.1109/VISUAL.1991.175818;10.1109/VISUAL.1995.480821	 finite element, basis function, tessellation, framework	Simmetrix##Simmetrix##Simmetrix##Simmetrix##Simmetrix##Simmetrix##Simmetrix##Simmetrix##Simmetrix##Simmetrix##Simmetrix##Simmetrix
Vis	2005	Visualization of white matter tracts with wrapped streamlines	10.1109/VISUAL.2005.1532777	http://dx.doi.org/10.1109/VISUAL.2005.1532777	51	58	C		Frank Enders;Natascha Sauber;Dorit Merhof;Peter Hastreiter;Christopher Nimsky;Marc Stamminger	Dept. of Neurosurg., Erlangen-Nurnberg Univ., Erlangen, Germany|c|;;;;;	10.1109/VISUAL.2001.964524;10.1109/VISUAL.1999.809894;10.1109/VISUAL.1999.809886;10.1109/VISUAL.2001.964549;10.1109/VISUAL.2004.30;10.1109/VISUAL.2001.964519;10.1109/VISUAL.1991.175771	Diffusion Tensor Imaging, Tractography, White Matter Tracts, Clustering	Dept. of Neurosurg., Erlangen-Nurnberg Univ., Erlangen, Germany|c|;;;;;
Vis	2005	Fast and reproducible fiber bundle selection in DTI visualization	10.1109/VISUAL.2005.1532778	http://dx.doi.org/10.1109/VISUAL.2005.1532778	59	64	C		Jorik Blaas;Charl P. Botha;Bart Peters;Frans Vos;Frits H. Post	Data Visualization Group, Delft Univ. of Technol., Netherlands|c|;;;;	10.1109/VISUAL.1999.809894;10.1109/VISUAL.2004.30	 diffusion tensor imaging, tractography, white matter	Delft University of Technology##Delft University of Technology##Academic Medical Centre##Delft University of Technology##Delft University of Technology
Vis	2005	Evaluation of fiber clustering methods for diffusion tensor imaging	10.1109/VISUAL.2005.1532779	http://dx.doi.org/10.1109/VISUAL.2005.1532779	65	72	C		Bart Moberts;Anna Vilanova;Jarke J. van Wijk	Dept. of Math. & Comput. Sci., Technische Univ. Eindhoven, Netherlands|c|;;	10.1109/VISUAL.2001.964549	Diffusion Tensor Imaging, Fiber tracking, Clustering,Clustering Validation, External Indices	Technische Universiteit Eindhoven Eindhoven##Technische Universiteit Eindhoven Eindhoven##Technische Universiteit Eindhoven Eindhoven
Vis	2005	The application of GPU particle tracing to diffusion tensor field visualization	10.1109/VISUAL.2005.1532780	http://dx.doi.org/10.1109/VISUAL.2005.1532780	73	78	C		Polina Kondratieva;Jens H. Krüger;Rüdiger Westermann	Comput. Graphics & Visualization Group, Technische Univ. Munchen, Germany|c|;;	10.1109/VISUAL.1999.809886;10.1109/VISUAL.2002.1183799;10.1109/VISUAL.1992.235193;10.1109/VISUAL.1999.809894;10.1109/VISUAL.1998.745294	Diffusion Tensors, Dynamic Visualization, GPU Particle Tracing and Streamlines, Medical Visualization	Technische UniversitÃ¤tUniversitÂ¨UniversitÃ¤t M Â¨ unchen##Technische UniversitÃ¤tUniversitÂ¨UniversitÃ¤t M Â¨ unchen##Technische UniversitÃ¤tUniversitÂ¨UniversitÃ¤t M Â¨ unchen##Technische UniversitÃ¤tUniversitÂ¨UniversitÃ¤t M Â¨ unchen
Vis	2005	The value of visualization	10.1109/VISUAL.2005.1532781	http://dx.doi.org/10.1109/VISUAL.2005.1532781	79	86	C		Jarke J. van Wijk	Dept. of Math. & Comput. Sci., Technische Univ. Eindhoven, Netherlands|c|	10.1109/VISUAL.1991.175815;10.1109/INFVIS.2004.70;10.1109/VISUAL.2001.964505;10.1109/VISUAL.2003.1250354;10.1109/INFVIS.2001.963285;10.1109/INFVIS.1999.801851	Visualization, evaluation	Technische Universiteit Eindhoven
Vis	2005	On the optimization of visualizations of complex phenomena	10.1109/VISUAL.2005.1532782	http://dx.doi.org/10.1109/VISUAL.2005.1532782	87	94	C		Donald H. House;Alethea Bair;Colin Ware	Texas A&M Univ., College Station, TX, USA|c|;;	10.1109/VISUAL.1996.568113;10.1109/VISUAL.1996.567784	perception, visualization evaluation,layered surfaces, genetic algorithm, data mining, principal component analysis, neural networks	Texas A&M University##Texas A&M University##Texas A&M University
Vis	2005	Curve-skeleton applications	10.1109/VISUAL.2005.1532783	http://dx.doi.org/10.1109/VISUAL.2005.1532783	95	102	C		Nicu D. Cornea;Deborah Silver;Patrick Min	Rutgers Univ., NJ, USA|c|;;	10.1109/VISUAL.2004.34;10.1109/VISUAL.2004.104;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.1994.346327;10.1109/VISUAL.1999.809912;10.1109/VISUAL.2003.1250353;10.1109/VISUAL.2001.964517	skeleton, curve-skeleton	Rutgers University##Rutgers University##John Cabot University
Vis	2005	Sort-middle multi-projector immediate-mode rendering in Chromium	10.1109/VISUAL.2005.1532784	http://dx.doi.org/10.1109/VISUAL.2005.1532784	103	110	C		Jorge Luis Williams;Robert E. Hiromoto	Dept. of Comput. Sci., Idaho Univ., Moscow, ID, USA|c|;		Cluster Rendering, Sort-Middle, Multi-Projector, Tile Displays, Immediate-Mode Rendering	University of Idaho##University of Idaho##University of Idaho
Vis	2005	COTS cluster-based sort-last rendering: performance evaluation and pipelined implementation	10.1109/VISUAL.2005.1532785	http://dx.doi.org/10.1109/VISUAL.2005.1532785	111	118	C		Xavier Cavin;Christophe Mion;Alain Filbois	;;		cluster-based visualization, sort-last rendering, parallel image compositing	
Vis	2005	OpenGL multipipe SDK: a toolkit for scalable parallel rendering	10.1109/VISUAL.2005.1532786	http://dx.doi.org/10.1109/VISUAL.2005.1532786	119	126	C	We describe OpenGL multipipe SDK (MPK), a toolkit for scalable parallel rendering based on OpenGL. MPK provides a uniform application programming interface (API) to manage scalable graphics applications across many different graphics subsystems. MPK-based applications run seamlessly from single-processor, single-pipe desktop systems to large multi-processor, multipipe scalable graphics systems. The application is oblivious of the system configuration, which can be specified through a configuration file at run time. To scale application performance, MPK uses a decomposition system that supports different modes for task partitioning and implements optimized CPU-based composition algorithms. MPK also provides a customizable image composition interface, which can be used to apply post-processing algorithms on raw pixel data obtained from executing sub-tasks on multiple graphics pipes in parallel. This can be used to implement parallel versions of any CPU-based algorithm, not necessarily used for rendering. In this paper, we motivate the need for a scalable graphics API and discuss the architecture of MPK. We present MPK's graphics configuration interface, introduce the notion of compound-based decomposition schemes and describe our implementation. We present some results from our work on a couple of target system architectures and conclude with future directions of research in this area.	Praveen Bhaniramka;Philippe C. D. Robert;Stefan Eilemann	;;	10.1109/VISUAL.1999.809890	Scalable Rendering, Parallel Rendering, Immersive Environments, Scalable Graphics Hardware	
Vis	2005	A shader-based parallel rendering framework	10.1109/VISUAL.2005.1532787	http://dx.doi.org/10.1109/VISUAL.2005.1532787	127	134	C	Existing parallel or remote rendering solutions rely on communicating pixels, OpenGL commands, scene-graph changes or application-specific data. We propose an intermediate solution based on a set of independent graphics primitives that use hardware shaders to specify their visual appearance. Compared to an OpenGL based approach, it reduces the complexity of the model by eliminating most fixed function parameters while giving access to the latest functionalities of graphics cards. It also suppresses the OpenGL state machine that creates data dependencies making primitive re-scheduling difficult. Using a retained-mode communication protocol transmitting changes between each frame, combined with the possibility to use shaders to implement interactive data processing operations instead of sending final colors and geometry, we are able to optimize the network load. High level information such as bounding volumes is used to setup advanced schemes where primitives are issued in parallel, routed according to their visibility, merged and re-ordered when received for rendering. Different optimization algorithms can be efficiently implemented, saving network bandwidth or reducing texture switches for instance. We present performance results based on two VTK applications, a parallel iso-surface extraction and a parallel volume renderer. We compare our approach with Chromium. Results show that our approach leads to significantly better performance and scalability, while offering easy access to hardware accelerated rendering algorithms.	Jérémie Allard;Bruno Raffin	ID-IMAG, CNRS, France|c|;	10.1109/VISUAL.1995.480821;10.1109/VISUAL.2002.1183812	 Distributed Rendering, Shaders, Volume Rendering	ID-IMAG##ID-IMAG
Vis	2005	VisTrails: enabling interactive multiple-view visualizations	10.1109/VISUAL.2005.1532788	http://dx.doi.org/10.1109/VISUAL.2005.1532788	135	142	C	VisTrails is a new system that enables interactive multiple-view visualizations by simplifying the creation and maintenance of visualization pipelines, and by optimizing their execution. It provides a general infrastructure that can be combined with existing visualization systems and libraries. A key component of VisTrails is the visualization trail (vistrail), a formal specification of a pipeline. Unlike existing dataflow-based systems, in VisTrails there is a clear separation between the specification of a pipeline and its execution instances. This separation enables powerful scripting capabilities and provides a scalable mechanism for generating a large number of visualizations. VisTrails also leverages the vistrail specification to identify and avoid redundant operations. This optimization is especially useful while exploring multiple visualizations. When variations of the same pipeline need to be executed, substantial speedups can be obtained by caching the results of overlapping subsequences of the pipelines. In this paper, we describe the design and implementation of VisTrails, and show its effectiveness in different application scenarios.	Louis Bavoil;Steven P. Callahan;Carlos Eduardo Scheidegger;Huy T. Vo;Patricia Crossno;Cláudio T. Silva;Juliana Freire	Sci. Comput. & Imaging Inst., Utah Univ., Salt Lake City, UT, USA|c|;;;;;;	10.1109/VISUAL.1998.745299;10.1109/INFVIS.2004.2;10.1109/VISUAL.2004.112;10.1109/VISUAL.2002.1183791	interrogative visualization, dataflow, caching, coordinated views	University of Utah##University of Utah####University of Utah##University of Utah####University of Utah##University of Utah
Vis	2005	Build-by-number: rearranging the real world to visualize novel architectural spaces	10.1109/VISUAL.2005.1532789	http://dx.doi.org/10.1109/VISUAL.2005.1532789	143	150	C	We present build-by-number, a technique for quickly designing architectural structures that can be rendered photorealistically at interactive rates. We combine image-based capturing and rendering with procedural modeling techniques to allow the creation of novel structures in the style of real-world structures. Starting with a simple model recovered from a sparse image set, the model is divided into feature regions, such as doorways, windows, and brick. These feature regions essentially comprise a mapping from model space to image space, and can be recombined to texture a novel model. Procedural rules for the growth and reorganization of the model are automatically derived to allow for very fast editing and design. Further, the redundancies marked by the feature labeling can be used to perform automatic occlusion replacement and color equalization in the finished scene, which is rendered using view-dependent texture mapping on standard graphics hardware. Results using four captured scenes show that a great variety of novel structures can be created very quickly once a captured scene is available, and rendered with a degree of realism comparable to the original scene.	Daniel R. Bekins;Daniel G. Aliaga	Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN, USA|c|;			Purdue University##Purdue University
Vis	2005	Phonon tracing for auralization and visualization of sound	10.1109/VISUAL.2005.1532790	http://dx.doi.org/10.1109/VISUAL.2005.1532790	151	158	C	We present a new particle tracing approach for the simulation of mid- and high-frequency sound. Inspired by the photorealism obtained by methods like photon mapping, we develop a similar method for the physical simulation of sound within rooms. For given source and listener positions, our method computes a finite-response filter accounting for the different reflections at various surfaces with frequency-dependent absorption coefficients. Convoluting this filter with an anechoic input signal reproduces a realistic aural impression of the simulated room. We do not consider diffraction effects due to low frequencies, since these can be better computed by finite elements. Our method allows the visualization of a wave front propagation using color-coded blobs traversing the paths of individual phonons.	Martin Hering-Bertram;Eduard Deines;Jan Mohring;Jevgenijs Jegorovs;Hans Hagen	TU Kaiserslautern, Germany|c|;;;;		 acoustics, auralization, raytracing, photon mapping	TU Kaiserslautern##TU Kaiserslautern##TU Kaiserslautern##TU Kaiserslautern##TU Kaiserslautern##TU Kaiserslautern##TU Kaiserslautern##TU Kaiserslautern
Vis	2005	The visible radio: process visualization of a software-defined radio	10.1109/VISUAL.2005.1532791	http://dx.doi.org/10.1109/VISUAL.2005.1532791	159	165	C	In this case study, a data-oriented approach is used to visualize a complex digital signal processing pipeline. The pipeline implements a frequency modulated (FM) software-defined radio (SDR). SDR is an emerging technology where portions of the radio hardware, such as filtering and modulation, are replaced by software components. We discuss how an SDR implementation is instrumented to illustrate the processes involved in FM transmission and reception. By using audio-encoded images, we illustrate the processes involved in radio, such as how filters are used to reduce noise, the nature of a carrier wave, and how frequency modulation acts on a signal. The visualization approach used in this work is very effective in demonstrating advanced topics in digital signal processing and is a useful tool for experimenting with the software radio design.	Matthew Hall;Alex Betts;Donna J. Cox;David Pointer;Volodymyr V. Kindratenko	Nat. Center for Supercomput. Appl., Illinois Univ., Urbana, IL, USA|c|;;;;		visualization metaphor, visualization of mathematics, radio, SDR	University of Illinois at Urbana-Champaign##University of Illinois at Urbana-Champaign##University of Illinois at Urbana-Champaign##University of Illinois at Urbana-Champaign##University of Illinois at Urbana-Champaign
Vis	2005	Query-driven visualization of large data sets	10.1109/VISUAL.2005.1532792	http://dx.doi.org/10.1109/VISUAL.2005.1532792	167	174	C	We present a practical and general-purpose approach to large and complex visual data analysis where visualization processing, rendering and subsequent human interpretation is constrained to the subset of data deemed interesting by the user. In many scientific data analysis applications, interesting data can be defined by compound Boolean range queries of the form (temperature > 1000) AND (70 < pressure < 90). As data sizes grow larger, a central challenge is to answer such queries as efficiently as possible. Prior work in the visualization community has focused on answering range queries for scalar fields within the context of accelerating the search phase of isosurface algorithms. In contrast, our work describes an approach that leverages state-of-the-art indexing technology from the scientific data management community called bitmap indexing. Our implementation, which we call DEX (short for dextrous data explorer), uses bitmap indexing to efficiently answer multivariate, multidimensional data queries to provide input to a visualization pipeline. We present an analysis overview and benchmark results that show bitmap indexing offers significant storage and performance improvements when compared to previous approaches for accelerating the search phase of isosurface algorithms. More importantly, since bitmap indexing supports complex multidimensional, multivariate range queries, it is more generally applicable to scientific data visualization and analysis problems. In addition to benchmark performance and analysis, we apply DEX to a typical scientific visualization problem encountered in combustion simulation data analysis.	Kurt Stockinger;John Shalf;Kesheng Wu;E. Wes Bethel	Computational Res. Div., Lawrence Berkeley Lab., CA, USA|c|;;;	10.1109/VISUAL.1999.809864;10.1109/VISUAL.2004.95;10.1109/VISUAL.1998.745299;10.1109/VISUAL.1996.568121	query-driven visualization, visual analytics, bitmap index, multivariate visualization, large data visualization, data analysis, scientific data management	University of California##University of California##University of California##University of California##University of California
Vis	2005	Visualization of time-dependent remote adaptive mesh refinement data	10.1109/VISUAL.2005.1532793	http://dx.doi.org/10.1109/VISUAL.2005.1532793	175	182	C	Analysis of phenomena that simultaneously occur on different spatial and temporal scales requires adaptive, hierarchical schemes to reduce computational and storage demands. Adaptive mesh refinement (AMR) schemes support both refinement in space that results in a time-dependent grid topology, as well as refinement in time that results in updates at higher rates for refined levels. Visualization of AMR data requires generating data for absent refinement levels at specific time steps. We describe a solution starting from a given set of "key frames" with potentially different grid topologies. The presented work was developed in a project involving several research institutes that collaborate in the field of cosmology and numerical relativity. AMR data results from simulations that are run on dedicated compute machines and is thus stored centrally, whereas the analysis of the data is performed on the local computers of the scientists. We built a distributed solution using remote procedure calls (RPC). To keep the application responsive, we split the bulk data transfer from the RPC response and deliver it asynchronously as a binary stream. The number of network round-trips is minimized by using high level operations. In summary, we provide an application for exploratory visualization of remotely stored AMR data.	Ralf Kähler;Steffen Prohaska;Andrei Hutanu;Hans-Christian Hege	Zuse-lnstitute Berlin, Germany|c|;;;	10.1109/VISUAL.2002.1183820;10.1109/VISUAL.2004.51;10.1109/VISUAL.2002.1183824	Time-Varying Data Visualization, Visualization over Networks, Multiresolution Visualization	Zuse-Institute Berlin (ZIB)##Zuse-Institute Berlin (ZIB)##Zuse-Institute Berlin (ZIB)##Zuse-Institute Berlin (ZIB)
Vis	2005	Distributed data management for large volume visualization	10.1109/VISUAL.2005.1532794	http://dx.doi.org/10.1109/VISUAL.2005.1532794	183	189	C	We propose a distributed data management scheme for large data visualization that emphasizes efficient data sharing and access. To minimize data access time and support users with a variety of local computing capabilities, we introduce an adaptive data selection method based on an "enhanced time-space partitioning" (ETSP) tree that assists with effective visibility culling, as well as multiresolution data selection. By traversing the tree, our data management algorithm can quickly identify the visible regions of data, and, for each region, adaptively choose the lowest resolution satisfying user-specified error tolerances. Only necessary data elements are accessed and sent to the visualization pipeline. To further address the issue of sharing large-scale data among geographically distributed collaborative teams, we have designed an infrastructure for integrating our data management technique with a distributed data storage system provided by logistical networking (LoN). Data sets at different resolutions are generated and uploaded to LoN for wide-area access. We describe a parallel volume rendering system that verifies the effectiveness of our data storage, selection and access scheme.	Jinzhu Gao;Jian Huang;C. Ryan Johnson;Scott Atchley;James Arthur Kohl	Oak Ridge Nat. Lab., TN, USA|c|;;;	10.1109/VISUAL.2002.1183758;10.1109/VISUAL.2002.1183757;10.1109/VISUAL.1999.809910;10.1109/VISUAL.1998.745300;10.1109/VISUAL.2004.110;10.1109/VISUAL.2004.112;10.1109/VISUAL.1999.809879	large data visualization, distributed storage, logistical networking, visibility culling, volume rendering, multiresolution rendering	Oak Ridge National Lab##Oak Ridge National Lab##Oak Ridge National Lab##Oak Ridge National Lab##Oak Ridge National Lab##Oak Ridge National Lab
Vis	2005	A contract based system for large data visualization	10.1109/VISUAL.2005.1532795	http://dx.doi.org/10.1109/VISUAL.2005.1532795	191	198	C	VisIt is a richly featured visualization tool that is used to visualize some of the largest simulations ever run. The scale of these simulations requires that optimizations are incorporated into every operation VisIt performs. But the set of applicable optimizations that VisIt can perform is dependent on the types of operations being done. Complicating the issue, VisIt has a plugin capability that allows new, unforeseen components to be added, making it even harder to determine which optimizations can be applied. We introduce the concept of a contract to the standard data flow network design. This contract enables each component of the data flow network to modify the set of optimizations used. In addition, the contract allows for new components to be accommodated gracefully within VisIt's data flow network system.	Hank Childs;Eric Brugger;Kathleen S. Bonnell;Jeremy S. Meredith;Mark C. Miller;Brad Whitlock;Nelson L. Max	California Univ., Davis, CA, USA|c|;;;;;;	10.1109/VISUAL.1996.567752;10.1109/VISUAL.1990.146416;10.1109/VISUAL.1995.480821;10.1109/VISUAL.1991.175794;10.1109/VISUAL.1997.663895	large data set visualization, data flow networks, contract-based system	University of California##University of California##University of California##University of California##University of California##University of California##University of California
Vis	2005	Interactive rendering of large unstructured grids using dynamic level-of-detail	10.1109/VISUAL.2005.1532796	http://dx.doi.org/10.1109/VISUAL.2005.1532796	199	206	C	We describe a new dynamic level-of-detail (LOD) technique that allows real-time rendering of large tetrahedral meshes. Unlike approaches that require hierarchies of tetrahedra, our approach uses a subset of the faces that compose the mesh. No connectivity is used for these faces so our technique eliminates the need for topological information and hierarchical data structures. By operating on a simple set of triangular faces, our algorithm allows a robust and straightforward graphics hardware (GPU) implementation. Because the subset of faces processed can be constrained to arbitrary size, interactive rendering is possible for a wide range of data sets and hardware configurations.	Steven P. Callahan;João Luiz Dihl Comba;Peter Shirley;Cláudio T. Silva	Sci. Comput. & Imaging Inst., Utah State Univ., Logan, UT, USA|c|;;;	10.1109/VISUAL.2004.102;10.1109/VISUAL.1999.809908;10.1109/VISUAL.1998.745283;10.1109/VISUAL.2004.85;10.1109/VISUAL.2003.1250390;10.1109/VISUAL.2002.1183778;10.1109/VISUAL.1998.745329;10.1109/VISUAL.2002.1183767;10.1109/VISUAL.2000.885711	 interactive volume rendering, multiresolution meshes, level-of-detail, tetrahedral meshes	University of Utah##UFRGS##University of Utah##University of Utah
Vis	2005	Batched multi triangulation	10.1109/VISUAL.2005.1532797	http://dx.doi.org/10.1109/VISUAL.2005.1532797	207	214	C	The multi triangulation framework (MT) is a very general approach for managing adaptive resolution in triangle meshes. The key idea is arranging mesh fragments at different resolution in a directed acyclic graph (DAG) which encodes the dependencies between fragments, thereby encompassing a wide class of multiresolution approaches that use hierarchies or DAGs with predefined topology. On current architectures, the classic MT is however unfit for real-time rendering, since DAG traversal costs vastly dominate raw rendering costs. In this paper, we redesign the MT framework in a GPU friendly fashion, moving its granularity from triangles to precomputed optimized triangle patches. The patches can be conveniently tri-stripped and stored in secondary memory to be loaded on demand, ready to be sent to the GPU using preferential paths. In this manner, central memory only contains the DAG structure and CPU workload becomes negligible. The major contributions of this work are: a new out-of-core multiresolution framework, that, just like the MT, encompasses a wide class of multiresolution structures; a robust and elegant way to build a well conditioned MT DAG by introducing the concept of V-partitions, that can encompass various state of the art multiresolution algorithms; an efficient multithreaded rendering engine and a general subsystem for the external memory processing and simplification of huge meshes.	Paolo Cignoni;Fabio Ganovelli;Enrico Gobbetti;Fabio Marton;Federico Ponchio;Roberto Scopigno	ISTI, CNR, Italy|c|;;;;;	10.1109/VISUAL.1997.663860;10.1109/VISUAL.2002.1183783;10.1109/VISUAL.1998.745282;10.1109/VISUAL.1996.567600;10.1109/VISUAL.2002.1183796;10.1109/VISUAL.2004.86		ISTI, CNR, Italy|c|;;;;;
Vis	2005	View-dependent rendering of multiresolution texture-atlases	10.1109/VISUAL.2005.1532798	http://dx.doi.org/10.1109/VISUAL.2005.1532798	215	222	C	Real-time rendering of massively textured 3D scenes usually involves two major problems: Large numbers of texture switches are a well-known performance bottleneck and the set of simultaneously visible textures is limited by the graphics memory. This paper presents a level-of-detail texturing technique that overcomes both problems. In a preprocessing step, the technique creates a hierarchical data structure for all textures used by scene objects, and it derives texture atlases at different resolutions. At runtime, our texturing technique requires only a small set of these texture atlases, which represent scene textures in an appropriate size depending on the current camera position and screen resolution. Independent of the number and total size of all simultaneously visible textures, the achieved frame rates are similar to that of rendering the scene without any texture switches. Since the approach includes dynamic texture loading, the total size of the textures is only limited by the hard disk capacity. The technique is applicable for any 3D scenes whose scene objects are primarily distributed in a plane, such as in the case of 3D city models or outdoor scenes in computer games. Our approach has been successfully applied to massively textured, large-scale 3D city models.	Henrik Buchholz;Jürgen Döllner	Hasso-Plattner Inst., Potsdam Univ., Germany|c|;	10.1109/VISUAL.1998.745322;10.1109/VISUAL.2004.4;10.1109/VISUAL.2000.885699	Multiresolution textures, texture level-of-detail, realtime rendering, view-dependent rendering	Hasso-Plattner Institute University of Potsdam##Plattner Institute University of Potsdam
Vis	2005	Exploiting frame-to-frame coherence for accelerating high-quality volume raycasting on graphics hardware	10.1109/VISUAL.2005.1532799	http://dx.doi.org/10.1109/VISUAL.2005.1532799	223	230	C	GPU-based raycasting offers an interesting alternative to conventional slice-based volume rendering due to the inherent flexibility and the high quality of the generated images. Recent advances in graphics hardware allow for the ray traversal and volume sampling to be executed on a per-fragment level completely on the GPU leading to interactive framerates. In this work we present optimization techniques that improve the performance and quality of GPU-based volume raycasting. We apply a hybrid image/object space approach to accelerate the ray traversal in animation sequences that works for both isosurface rendering and semi-transparent volume rendering. An empty-space-leaping technique that exploits the spatial coherence between consecutively rendered images is used to estimate the optimal initial ray sampling point for each image pixel. These can double the rendering performance for typical volumetric data sets without sacrificing image quality. The achieved speed-up allows for further improvements of image quality. We demonstrate an object space antialiasing technique based on selective super-sampling at sharp creases and silhouette edges which also benefits from exploiting frame-to-frame coherence.	Thomas Klein;Magnus Strengert;Simon Stegmaier;Thomas Ertl	Inst. for Visualization & Interactive Syst., Stuttgart Univ., Germany|c|;;;	10.1109/VISUAL.2002.1183764;10.1109/VISUAL.1993.398852;10.1109/VISUAL.2001.964521;10.1109/VISUAL.2003.1250388;10.1109/VISUAL.2002.1183775;10.1109/VISUAL.2003.1250390;10.1109/VISUAL.2002.1183776;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2004.63	Volume Raycasting, Programmable Graphics Hardware, Frame-to-Frame Coherence, Space Leaping	University of Stuttgart##University of Stuttgart##University of Stuttgart##University of Stuttgart
Vis	2005	Streaming meshes	10.1109/VISUAL.2005.1532800	http://dx.doi.org/10.1109/VISUAL.2005.1532800	231	238	C	Recent years have seen an immense increase in the complexity of geometric data sets. Today's gigabyte-sized polygon models can no longer be completely loaded into the main memory of common desktop PCs. Unfortunately, current mesh formats, which were designed years ago when meshes were orders of magnitudes smaller, do not account for this. Using such formats to store large meshes is inefficient and complicates all subsequent processing. We describe a streaming format for polygon meshes that is simple enough to replace current offline mesh formats and is more suitable for representing large data sets. Furthermore, it is an ideal input and output format for I/O-efficient out-of-core algorithms that process meshes in a streaming, possibly pipelined, fashion. This paper chiefly concerns the underlying theory and the practical aspects of creating and working with this new representation. In particular, we describe desirable qualities for streaming meshes and methods for converting meshes from a traditional to a streaming format. A central theme of this paper is the issue of coherent and compatible layouts of the mesh vertices and polygons. We present metrics and diagrams that characterize the coherence of a mesh layout and suggest appropriate strategies for improving its "streamability". To this end, we outline several out-of-core algorithms for reordering meshes with poor coherence, and present results for a menagerie of well known and generally incoherent surface meshes.	Martin Isenburg;Peter Lindstrom	North Carolina Univ., Chapel Hill, NC, USA|c|;	10.1109/INFVIS.2002.1173159;10.1109/VISUAL.1997.663895;10.1109/VISUAL.2001.964532;10.1109/VISUAL.2003.1250408		University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill
Vis	2005	Stream-processing points	10.1109/VISUAL.2005.1532801	http://dx.doi.org/10.1109/VISUAL.2005.1532801	239	246	C	With the growing size of captured 3D models it has become increasingly important to provide basic efficient processing methods for large unorganized raw surface-sample point data sets. In this paper we introduce a novel stream-based (and out-of-core) point processing framework. The proposed approach processes points in an orderly sequential way by sorting them and sweeping along a spatial dimension. The major advantages of this new concept are: (1) support of extensible and concatenate local operators called stream operators, (2) low main-memory usage and (3) applicability to process very large data sets out-of-core.	Renato Pajarola	Dept. of Informatics, Zurich Univ., Switzerland|c|	10.1109/VISUAL.2001.964489;10.1109/VISUAL.2000.885721;10.1109/VISUAL.2002.1183770;10.1109/VISUAL.2003.1250408;10.1109/VISUAL.2005.1532800;10.1109/VISUAL.2002.1183771	point processing, sequential processing, normal estimation, curvature estimation, fairing	University of ZÃ¼rich
Vis	2005	VolumeExplorer: roaming large volumes to couple visualization and data processing for oil and gas exploration	10.1109/VISUAL.2005.1532802	http://dx.doi.org/10.1109/VISUAL.2005.1532802	247	254	C	In this paper, we present a volume roaming system dedicated to oil and gas exploration. Our system combines probe-based volume rendering with data processing and computing. The daily oil production and the estimation of the world proven-reserves directly affect the barrel price and have a strong impact on the economy. Among others, production and correct estimation are linked to the accuracy of the sub-surface model used for predicting oil reservoirs shape and size. Geoscientists build this model from the interpretation of seismic data, i.e. 3D images of the subsurface obtained from geophysical surveys. Our system couples visualization and data processing for the interpretation of seismic data. It is based on volume roaming along with efficient volume paging to manipulate the multi-gigabyte data sets commonly acquired during seismic surveys. Our volume rendering lenses implement high quality pre-integrated volume rendering with accurate lighting. They use a generic multi-modal volume rendering system that blends several volumes in the spirit of the "stencil" paradigm used in 2D painting programs. In addition, our system can interactively display non-polygonal isosurfaces painted with an attribute. Beside the visualization algorithms, automatic extraction of local features of the subsurface model also take full advantage of the volume paging.	Laurent Castanie;Bruno Lévy;Fabien Bosquet	;;	10.1109/VISUAL.2004.46;10.1109/VISUAL.1997.663878;10.1109/VISUAL.2005.1532785;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2000.885683;10.1109/VISUAL.1999.809908;10.1109/VISUAL.2002.1183757;10.1109/VISUAL.1999.809889	Oil and gas exploration, seismic interpretation, large volumes, volume bricking, out-of-core, volume roaming, paging, texture-based volume visualization, multi-modal rendering, programmable graphics hardware	
Vis	2005	Reflection nebula visualization	10.1109/VISUAL.2005.1532803	http://dx.doi.org/10.1109/VISUAL.2005.1532803	255	262	C	Stars form in dense clouds of interstellar gas and dust. The residual dust surrounding a young star scatters and diffuses its light, making the star's "cocoon" of dust observable from Earth. The resulting structures, called reflection nebulae, are commonly very colorful in appearance due to wavelength-dependent effects in the scattering and extinction of light. The intricate interplay of scattering and extinction cause the color hues, brightness distributions, and the apparent shapes of such nebulae to vary greatly with viewpoint. We describe an interactive visualization tool for realistically rendering the appearance of arbitrary 3D dust distributions surrounding one or more illuminating stars. Our rendering algorithm is based on the physical models used in astrophysics research. The tool can be used to create virtual fly-throughs of reflection nebulae for interactive desktop visualizations, or to produce scientifically accurate animations for educational purposes, e.g., in planetarium shows. The algorithm is also applicable to investigate on-the-fly the visual effects of physical parameter variations, exploiting visualization technology to help gain a deeper and more intuitive understanding of the complex interaction of light and dust in real astrophysical settings.	Marcus A. Magnor;Kristian Hildebrand;Andrei Lintu;Andrew J. Hanson	;;;	10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2004.18	volume rendering, global illumination, dust, nebula,astronomy	MPI Informatik##MPI Informatik##MPI Informatik##MPI Informatik
Vis	2005	Multimodal exploration of the fourth dimension	10.1109/VISUAL.2005.1532804	http://dx.doi.org/10.1109/VISUAL.2005.1532804	263	270	C	We present a multimodal paradigm for exploring topological surfaces embedded in four dimensions; we exploit haptic methods in particular to overcome the intrinsic limitations of 3D graphics images and 3D physical models. The basic problem is that, just as 2D shadows of 3D curves lose structure where lines cross, 3D graphics projections of smooth 4D topological surfaces are interrupted where one surface intersects another. Furthermore, if one attempts to trace real knotted ropes or a plastic models of self-intersecting surfaces with a fingertip, one inevitably collides with parts of the physical artifact. In this work, we exploit the free motion of a computer-based haptic probe to support a continuous motion that follows the local continuity of the object being explored. For our principal test case of 4D-embedded surfaces projected to 3D, this permits us to follow the full local continuity of the surface as though in fact we were touching an actual 4D object. We exploit additional sensory cues to provide supplementary or redundant information. For example, we can use audio tags to note the relative 4D depth of illusory 3D surface intersections produced by projection from 4D, as well as providing automated refinement of the tactile exploration path to eliminate jitter and snagging, resulting in a much cleaner exploratory motion than a bare uncorrected motion. Visual enhancements provide still further improvement to the feedback: by opening a view-direction-defined cutaway into the interior of the 3D surface projection, we allow the viewer to keep the haptic probe continuously in view as it traverses any touchable part of the object. Finally, we extend the static tactile exploration framework using a dynamic mode that links each stylus motion to a change in orientation that creates at each instant a maximal-area screen projection of a neighborhood of the current point of interest. This minimizes 4D distortion and permits true metric sizes to be deduced locally at any point. All these methods combine to reveal the full richness of the complex spatial relationships of the target shapes, and to overcome many expected perceptual limitations in 4D visualization.	Andrew J. Hanson;Hui Zhang 0006	Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA|c|;	10.1109/VISUAL.1995.480804	 multimodal, haptics, visualization	Indiana University##Indiana University
Vis	2005	High performance volume splatting for visualization of neurovascular data	10.1109/VISUAL.2005.1532805	http://dx.doi.org/10.1109/VISUAL.2005.1532805	271	278	C	A new technique is presented to increase the performance of volume splatting by using hardware accelerated point sprites. This allows creating screen aligned elliptical splats for high quality volume splatting at very low cost on the GPU. Only one vertex per splat is stored on the graphics card. GPU generated point sprite texture coordinates are used for computing splats and per-fragment 3D-texture coordinates on the fly. Thus, only 6 bytes per splat are stored on the GPU and vertex shader load is 25% in comparison to applying textured quads. For eight predefined viewing directions, depth-sorting of the splats is performed in a pre-processing step where the resulting indices are stored on the GPU. Thereby, there is no data transfer between CPU and GPU during rendering. Post-classificative two dimensional transfer functions with lighting for scalar data and tagged volumes were implemented. Thereby, we focused on the visualization of neurovascular structures, where typically no more than 2% of the voxels contribute to the resulting 3D-representation. A comparison with a 3D-texture-based slicing algorithm showed frame rates up to 11 times higher for the presented approach on current CPUs. The presented technique was evaluated with a broad medical database and its value for highly sparse volume visualization is shown.	Fernando Vega Higuera;Peter Hastreiter;Rudolf Fahlbusch;Günther Greiner	Dept. of Neurosurg. & Comput. Graphics Group, Univ. of Erlangen, Germany|c|;;;	10.1109/VISUAL.2004.38;10.1109/VISUAL.1997.663882;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.1996.567608;10.1109/VISUAL.2003.1250404;10.1109/VISUAL.2001.964519;10.1109/VISUAL.2003.1250388;10.1109/VISUAL.2001.964490;10.1109/VISUAL.1999.809909;10.1109/VISUAL.2003.1250386	volume visualization, volume splatting, neurovascular structures, segmented data	Group University of Erlangen##Group University of Erlangen##Group University of Erlangen##Group University of Erlangen##Group University of Erlangen
Vis	2005	Teniae coli guided navigation and registration for virtual colonoscopy	10.1109/VISUAL.2005.1532806	http://dx.doi.org/10.1109/VISUAL.2005.1532806	279	285	C	We present a new method for guiding virtual colonoscopic navigation and registration by using teniae coli as anatomical landmarks. As most existing protocols require a patient to be scanned in both supine and prone positions to increase sensitivity in detecting colonic polyps, reference and registration between scans are necessary. However, the conventional centerline approach, generating only the longitudinal distance along the colon, lacks the necessary orientation information to synchronize the virtual navigation cameras in both scanned positions. In this paper we describe a semi-automatic method to detect teniae coli from a colonic surface model reconstructed from CT colonography. Teniae coli are three bands of longitudinal smooth muscle on the surface of the colon. They form a triple helix structure from the appendix to the sigmoid colon and are ideal references for virtual navigation. Our method was applied to 3 patients resulting in 6 data sets (supine and prone scans). The detected teniae coli matched well with our visual inspection. In addition, we demonstrate that polyps visible on both scans can be located and matched more efficiently with the aid of a teniae coli guided navigation implementation.	Adam Huang;Dave Roy;Marek Franaszek;Ronald M. Summers	Diagnostic Radiol. Dept., Nat. Inst. of Health, Bethesda, MD, USA|c|;;;	10.1109/VISUAL.2002.1183808;10.1109/VISUAL.2001.964540	virtual colonoscopy, CT colonography, virtual endoscopy, camera control, computer-aided diagnosis, colon flattening, parameterization	Diagnostic Radiol. Dept., Nat. Inst. of Health, Bethesda, MD, USA|c|;;;
Vis	2005	Statistically quantitative volume visualization	10.1109/VISUAL.2005.1532807	http://dx.doi.org/10.1109/VISUAL.2005.1532807	287	294	C	Visualization users are increasingly in need of techniques for assessing quantitative uncertainty and error in the images produced. Statistical segmentation algorithms compute these quantitative results, yet volume rendering tools typically produce only qualitative imagery via transfer function-based classification. This paper presents a visualization technique that allows users to interactively explore the uncertainty, risk, and probabilistic decision of surface boundaries. Our approach makes it possible to directly visualize the combined "fuzzy" classification results from multiple segmentations by combining these data into a unified probabilistic data space. We represent this unified space, the combination of scalar volumes from numerous segmentations, using a novel graph-based dimensionality reduction scheme. The scheme both dramatically reduces the dataset size and is suitable for efficient, high quality, quantitative visualization. Lastly, we show that the statistical risk arising from overlapping segmentations is a robust measure for visualizing features and assigning optical properties.	Joe Michael Kniss;Robert L. Van Uitert Jr.;Abraham Stephens;Guo-Shi Li;Tolga Tasdizen;Charles D. Hansen	Utah Univ., Salt Lake City, UT, USA|c|;;;;;	10.1109/VISUAL.2003.1250386;10.1109/VISUAL.1998.745311;10.1109/VISUAL.2004.48;10.1109/VISUAL.1997.663875	volume visualization, uncertainty, classification, risk analysis	University of Utah##University of Utah##University of Utah##University of Utah##University of Utah##University of Utah
Vis	2005	Scale-invariant volume rendering	10.1109/VISUAL.2005.1532808	http://dx.doi.org/10.1109/VISUAL.2005.1532808	295	302	C	As standard volume rendering is based on an integral in physical space (or "coordinate space"), it is inherently dependent on the scaling of this space. Although this dependency is appropriate for the realistic rendering of semitransparent volumetric objects, it has several unpleasant consequences for volume visualization. In order to overcome these disadvantages, a new variant of the volume rendering integral is proposed, which is defined in data space instead of physical space. Apart from achieving scale invariance, this new method supports the rendering of isosurfaces of uniform opacity and color, independently of the local gradient or" the visualized scalar field. Moreover, it reveals certain structures in scalar fields even with constant transfer functions. Furthermore, it can be defined as the limit of infinitely many semitransparent isosurfaces, and is therefore based on an intuitive and at the same time precise definition. In addition to the discussion of these features of scale-invariant volume rendering, efficient adaptations of existing volume rendering algorithms and extensions for silhouette enhancement and local illumination by transmitted light are presented.	Martin Kraus		10.1109/VISUAL.2000.885683;10.1109/VISUAL.2000.885694;10.1109/VISUAL.1994.346331	volume visualization, volume rendering, isosurfaces, silhouette enhancement, volume shading, translucence	
Vis	2005	Rendering tetrahedral meshes with higher-order attenuation functions for digital radiograph reconstruction	10.1109/VISUAL.2005.1532809	http://dx.doi.org/10.1109/VISUAL.2005.1532809	303	310	C	This paper presents a novel method for computing simulated x-ray images, or DRRs (digitally reconstructed radiographs), of tetrahedral meshes with higher-order attenuation functions. DRRs are commonly used in computer assisted surgery (CAS), with the attenuation function consisting of a voxelized CT study, which is viewed from different directions. Our application of DRRs is in intra-operative "2D-3D" registration, i.e., finding the pose of the CT dataset given a small number of patient radiographs. We register 2D patient images with a statistical tetrahedral model, which encodes the CT intensity numbers as Bernstein polynomials, and includes knowledge about typical shape variation modes. The unstructured grid is more suitable for applying deformations than a rectilinear grid, and the higher-order polynomials provide a better approximation of the actual density than constant or linear models. The infra-operative environment demands a fast method for creating the DRRs, which we present here. We demonstrate this application through the creation and use of a deformable atlas of human pelvis bones. Compared with other works on rendering unstructured grids, the main contributions of this work are: 1) Simple and perspective-correct interpolation of the thickness of a tetrahedral cell. 2) Simple and perspective-correct interpolation of front and back barycentric coordinates with respect to the cell. 3) Computing line integrals of higher-order functions. 4) Capability of applying shape deformations and variations in the attenuation function without significant performance loss. The method does not depend on for pre-integration, and does not require depth-sorting of the visualized cells. We present imaging and timing results of implementing the algorithm, and discuss the impact of using higher-order functions on the quality of the result and the performance.	Ofri Sadowsky;Jonathan D. Cohen;Russell H. Taylor	Johns Hopkins Univ., Laurel, MD, USA|c|;;	10.1109/VISUAL.2000.885683;10.1109/VISUAL.2004.85	volume rendering, unstructured grids, projected tetrahedra, DRR, higher-order volumetric functions	Johns Hopkins University##Johns Hopkins University##Johns Hopkins University
Vis	2005	Prefiltered Gaussian reconstruction for high-quality rendering of volumetric data sampled on a body-centered cubic grid	10.1109/VISUAL.2005.1532810	http://dx.doi.org/10.1109/VISUAL.2005.1532810	311	318	C	In this paper a novel high-quality reconstruction scheme is presented. Although our method is mainly proposed to reconstruct volumetric data sampled on an optimal body-centered cubic (BCC) grid, it can be easily adapted lo the conventional regular rectilinear grid as well. The reconstruction process is decomposed into two steps. The first step, which is considered to be a preprocessing, is a discrete Gaussian deconvolution performed only once in the frequency domain. Afterwards, the second step is a spatial-domain convolution with a truncated Gaussian kernel, which is used to interpolate arbitrary samples for ray casting. Since the preprocessing is actually a discrete prefiltering, we call our technique prefiltered Gaussian reconstruction (PGR). It is shown that the impulse response of PGR well approximates the ideal reconstruction kernel. Therefore the quality of PGR is much higher than that of previous reconstruction techniques proposed for optimally sampled data, which are based on linear and cubic box splines adapted to the BCC grid. Concerning the performance, PGR is slower than linear box-spline reconstruction but significantly faster than cubic box-spline reconstruction.	Balázs Csébfalvi	Dept. of Control Eng. & Inf. Technol., Budapest Univ., Hungary|c|	10.1109/VISUAL.2004.70;10.1109/VISUAL.2004.65;10.1109/VISUAL.2001.964498;10.1109/VISUAL.1997.663848;10.1109/VISUAL.1994.346331;10.1109/VISUAL.2001.964499	Body-Centered Cubic Grid, Reconstruction, Optimal Regular Volume Sampling, Radial Basis Function Interpolation	Dept. of Control Eng. & Inf. Technol., Budapest Univ., Hungary|c|
Vis	2005	VolQD: direct volume rendering of multi-million atom quantum dot simulations	10.1109/VISUAL.2005.1532811	http://dx.doi.org/10.1109/VISUAL.2005.1532811	319	326	C	In this work we present a hardware-accelerated direct volume rendering system for visualizing multivariate wave functions in semiconducting quantum dot (QD) simulations. The simulation data contains the probability density values of multiple electron orbitals for up to tens of millions of atoms, computed by the NEMO3-D quantum device simulator software run on large-scale cluster architectures. These atoms form two interpenetrating crystalline face centered cubic lattices (FCC), where each FCC cell comprises the eight corners of a cubic cell and six additional face centers. We have developed compact representation techniques for the FCC lattice within PC graphics hardware texture memory, hardware-accelerated linear and cubic reconstruction schemes, and new multi-field rendering techniques utilizing logarithmic scale transfer functions. Our system also enables the user to drill down through the simulation data and execute statistical queries using general-purpose computing on the GPU (GPGPU).	Wei Qiao;David S. Ebert;Alireza Entezari;Marek Korkusinski;Gerhard Klimeck	Purdue Univ., West Lafayette, IN, USA|c|;;;;	10.1109/VISUAL.2003.1250414;10.1109/VISUAL.2004.85;10.1109/VISUAL.2004.95;10.1109/VISUAL.2004.65;10.1109/VISUAL.2000.885683;10.1109/VISUAL.2001.964498	volume visualization, volume rendering, programmable graphics hardware, face-centered cubic lattice, reconstruction filter, quantum dots, atomistic simulation	Purdue University##Purdue University##Purdue University##Purdue University##Purdue University
Vis	2005	High dynamic range volume visualization	10.1109/VISUAL.2005.1532812	http://dx.doi.org/10.1109/VISUAL.2005.1532812	327	334	C	High resolution volumes require high precision compositing to preserve detailed structures. This is even more desirable for volumes with high dynamic range values. After the high precision intermediate image has been computed, simply rounding up pixel values to regular display scales loses the computed details. In this paper, we present a novel high dynamic range volume visualization method for rendering volume data with both high spatial and intensity resolutions. Our method performs high precision volume rendering followed by dynamic tone mapping to preserve details on regular display devices. By leveraging available high dynamic range image display algorithms, this dynamic tone mapping can be automatically adjusted to enhance selected features for the final display. We also present a novel transfer function design interface with nonlinear magnification of the density range and logarithmic scaling of the color/opacity range to facilitate high dynamic range volume visualization. By leveraging modern commodity graphics hardware and out-of-core acceleration, our system can produce an effective visualization of huge volume data.	Xiaoru Yuan;Minh X. Nguyen;Baoquan Chen;David H. Porter	Dept. of Comput. Sci. & Eng;, Minnesota Univ., MN, USA|c|;;;	10.1109/INFVIS.1997.636718;10.1109/VISUAL.1999.809908	Volume Rendering, High Dynamic Range, Focus+Context Techniques, User Interfaces, Transfer Function Design, Non-linear Magnification	University of Minnesota at Twin Cities##University of Minnesota at Twin Cities##University of Minnesota at Twin Cities##University of Minnesota at Twin Cities##University of Minnesota at Twin Cities
Vis	2005	Volume rendering of smoke propagation CFD data	10.1109/VISUAL.2005.1532813	http://dx.doi.org/10.1109/VISUAL.2005.1532813	335	341	C	The evacuation of buildings in the event of a fire requires careful planning of ventilation and evacuation routes during early architectural design stages. Different designs are evaluated by simulating smoke propagation using computational fluid dynamics (CFD). Visibility plays a decisive role in finding the nearest fire exit. This paper presents real-time volume rendering of transient smoke propagation conforming to standardized visibility distances. We visualize time dependent smoke particle concentration on unstructured tetrahedral meshes using a direct volume rendering approach. Due to the linear transfer function of the optical model commonly used in fire protection engineering, accurate pre-integration of diffuse color across tetrahedra can be carried out with a single 2D texture lookup. We reduce rounding errors during frame buffer blending by applying randomized dithering if high accuracy frame buffers are unavailable on the target platform. A simple absorption-based lighting model is evaluated in a preprocessing step using the same rendering approach. Back-illuminated exit signs are commonly used to indicate the escape route. As light emitting objects are visible further than reflective objects, the transfer function in front of illuminated exit signs must be adjusted with a deferred rendering pass.	Oliver Staubli;Christian Sigg;Ronald Peikert;Markus H. Gross;Daniel Gubler	Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;;;;	10.1109/VISUAL.2000.885683;10.1109/VISUAL.2003.1250390;10.1109/VISUAL.1993.398846;10.1109/VISUAL.2004.85;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2003.1250385	 volume rendering, flow visualization	Eidgenossische Tech. Hochschule, Zurich, Switzerland|c|;;;;
Vis	2005	Hardware-accelerated simulated radiography	10.1109/VISUAL.2005.1532815	http://dx.doi.org/10.1109/VISUAL.2005.1532815	343	350	C	We present the application of hardware accelerated volume rendering algorithms to the simulation of radiographs as an aid to scientists designing experiments, validating simulation codes, and understanding experimental data. The techniques presented take advantage of 32-bit floating point texture capabilities to obtain solutions to the radiative transport equation for X-rays. The hardware accelerated solutions are accurate enough to enable scientists to explore the experimental design space with greater efficiency than the methods currently in use. An unsorted hexahedron projection algorithm is presented for curvilinear hexahedral meshes that produces simulated radiographs in the absorption-only regime. A sorted tetrahedral projection algorithm is presented that simulates radiographs of emissive materials. We apply the tetrahedral projection algorithm to the simulation of experimental diagnostics for inertial confinement fusion experiments on a laser at the University of Rochester.	Daniel E. Laney;Steven P. Callahan;Nelson L. Max;Cláudio T. Silva;Steven Langer;Randall Frank	Lawrence Livermore Nat. Lab., Berkeley, CA, USA|c|;;;;;	10.1109/VISUAL.2000.885683;10.1109/VISUAL.2004.85;10.1109/VISUAL.2003.1250390	 volume rendering, hardware acceleration	Lawrence Livermore National Laboratory##Lawrence Livermore National Laboratory##Lawrence Livermore National Laboratory##Lawrence Livermore National Laboratory##Lawrence Livermore National Laboratory##Lawrence Livermore National Laboratory
Vis	2005	Fast visualization by shear-warp on quadratic super-spline models using wavelet data decompositions	10.1109/VISUAL.2005.1532816	http://dx.doi.org/10.1109/VISUAL.2005.1532816	351	358	C	We develop the first approach Tor interactive volume visualization based on a sophisticated rendering method of shear-warp type, wavelet data encoding techniques, and a trivariate spline model, which has been introduced recently. As a first step of our algorithm, we apply standard wavelet expansions to represent and decimate the given gridded three-dimensional data. Based on this data encoding, we give a sophisticated version of the shear-warp based volume rendering method. Our new algorithm visits each voxel only once taking advantage of the particular data organization of octrees. In addition, the hierarchies of the data guide the local (re)construction of the quadratic super-spline models, which we apply as a pure visualization tool. The low total degree of the polynomial pieces allows to numerically approximate the volume rendering integral efficiently. Since the coefficients of the splines are almost immediately available from the given data, Bernstein-Bezier techniques can be fully employed in our algorithms. In this way, we demonstrate that these models can be successfully applied to full volume rendering of hierarchically organized data. Our computational results show that (even when hierarchical approximations are used) the new approach leads to almost artifact-free visualizations of high quality for complicated and noise-contaminated volume data sets, while the computational effort is considerable low, i.e. our current implementation yields 1-2 frames per second for parallel perspective rendering a 2563 volume data set (using simple opacity transfer functions) in a 5122 view-port.	Gregor Schlosser;Jürgen Hesser;Frank Zeilfelder;Christian Rössl;Reinhard Männer;Günther Nürnberger;Hans-Peter Seidel	ICM, Mannheim Univ., Germany|c|;;;;;;	10.1109/VISUAL.1998.745713;10.1109/VISUAL.2001.964513;10.1109/VISUAL.1994.346331;10.1109/VISUAL.1990.146391	Volume Rendering, Quadratic Super-Splines, Shear-Warp Algorithm, Hierarchical Data Encoding	UniversitÃ¤t Mannheim####UniversitÃ¤t Mannheim######UniversitÃ¤t Mannheim####ICM
Vis	2005	Dataset traversal with motion-controlled transfer functions	10.1109/VISUAL.2005.1532817	http://dx.doi.org/10.1109/VISUAL.2005.1532817	359	366	C	In this paper, we describe a methodology and implementation for interactive dataset traversal using motion-controlled transfer functions. Dataset traversal here refers lo the process of translating a transfer function along a specific path. In scientific visualization, it is often necessary to manipulate transfer functions in order to visualize datasets more effectively. This manipulation of transfer functions is usually performed globally, i.e., a new transfer function is applied to the entire dataset. Our approach allows one to locally manipulate transfer functions while controling its movement along a traversal path. The method we propose allows the user to select a traversal path within the dataset, based on the shape of the volumetric model and manipulate a transfer function along this path. Examples of dataset traversal include the animation of transfer functions along a pre-defined path, the simulation of flow in vascular structures, and the visualization of convoluted shapes. For example, this type of traversal is often used in medical illustration to highlight flow in blood vessels. We present an interactive implementation of our method using graphics hardware, based on the decomposition of the volume. We show examples of our approach using a variety of volumetric datasets, and we also demonstrate that with our novel decomposition, the rendering process is faster.	Carlos D. Correa;Deborah Silver	Dept. of Electr. & Comput. Eng., State Univ. of New Jersey, Newark, NJ, USA|c|;	10.1109/VISUAL.2003.1250388;10.1109/VISUAL.2002.1183820;10.1109/VISUAL.2002.1183777;10.1109/VISUAL.2003.1250386;10.1109/VISUAL.2004.48;10.1109/VISUAL.2001.964517	Dataset traversal, illustrative visualization, volume manipulation, animation, transfer functions	The State University of New Jersey Piscataway##The State University of New Jersey Piscataway
Vis	2005	The magic volume lens: an interactive focus+context technique for volume rendering	10.1109/VISUAL.2005.1532818	http://dx.doi.org/10.1109/VISUAL.2005.1532818	367	374	C	The size and resolution of volume datasets in science and medicine are increasing at a rate much greater than the resolution of the screens used to view them. This limits the amount of data that can be viewed simultaneously, potentially leading to a loss of overall context of the data when the user views or zooms into a particular area of interest. We propose a focus+context framework that uses various standard and advanced magnification lens rendering techniques to magnify the features of interest, while compressing the remaining volume regions without clipping them away completely. Some of these lenses can be interactively configured by the user to specify the desired magnification patterns, while others are feature-adaptive. All our lenses are accelerated on the GPU. They allow the user to interactively manage the available screen area, dedicating more area to the more resolution-important features.	Lujin Wang;Ye Zhao;Klaus Mueller;Arie E. Kaufman	Center for Visual Comput., Comput. Sci., Stony Brook Univ., NY, USA|c|;;;	10.1109/INFVIS.1997.636786;10.1109/INFVIS.1996.559215;10.1109/INFVIS.1996.559214;10.1109/VISUAL.2001.964552;10.1109/VISUAL.2003.1250386;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2004.48;10.1109/VISUAL.2003.1250400;10.1109/VISUAL.2000.885697	Focus+Context Techniques,Lens,Volume Rendering, Hardware-assisted Volume Rendering	Stony Brook University##Stony Brook University##Stony Brook University##Stony Brook University
Vis	2005	Effectively visualizing large networks through sampling	10.1109/VISUAL.2005.1532819	http://dx.doi.org/10.1109/VISUAL.2005.1532819	375	382	C	We study the problem of visualizing large networks and develop techniques for effectively abstracting a network and reducing the size to a level that can be clearly viewed. Our size reduction techniques are based on sampling, where only a sample instead of the full network is visualized. We propose a randomized notion of "focus" that specifies a part of the network and the degree to which it needs to be magnified. Visualizing a sample allows our method to overcome the scalability issues inherent in visualizing massive networks. We report some characteristics that frequently occur in large networks and the conditions under which they are preserved when sampling from a network. This can be useful in selecting a proper sampling scheme that yields a sample with similar characteristics as the original network. Our method is built on top of a relational database, thus it can be easily and efficiently implemented using any off-the-shelf database software. As a proof of concept, we implement our methods and report some of our experiments over the movie database and the connectivity graph of the Web.	Davood Rafiei;Stephen Curial	Dept. of Comput. Sci., Alberta Univ., Edmonton, Alta., Canada|c|	10.1109/INFVIS.2001.963282;10.1109/INFVIS.2004.66;10.1109/INFVIS.2002.1173148;10.1109/INFVIS.2003.1249011	visualizing the Web, large network visualization, network sampling	University of Alberta##University of Alberta
Vis	2005	Opening the black box - data driven visualization of neural networks	10.1109/VISUAL.2005.1532820	http://dx.doi.org/10.1109/VISUAL.2005.1532820	383	390	C	Artificial neural networks are computer software or hardware models inspired by the structure and behavior of neurons in the human nervous system. As a powerful learning tool, increasingly neural networks have been adopted by many large-scale information processing applications but there is no a set of well defined criteria for choosing a neural network. The user mostly treats a neural network as a black box and cannot explain how learning from input data was done nor how performance can be consistently ensured. We have experimented with several information visualization designs aiming to open the black box to possibly uncover underlying dependencies between the input data and the output data of a neural network. In this paper, we present our designs and show that the visualizations not only help us design more efficient neural networks, but also assist us in the process of using neural networks for problem solving such as performing a classification task.	Fan-Yin Tzeng;Kwan-Liu Ma	Dept. of Comput. Sci., California Univ., Davis, CA, USA|c|;	10.1109/INFVIS.2002.1173157;10.1109/VISUAL.1999.809866	Artificial Neural Network, Information Visualization, Visualization Application, Classification, Machine Learning	University of California at Davis##University of California at Davis
Vis	2005	Interactive visual analysis and exploration of injection systems simulations	10.1109/VISUAL.2005.1532821	http://dx.doi.org/10.1109/VISUAL.2005.1532821	391	398	C	Simulations often generate large amounts of data that require use of SciVis techniques for effective exploration of simulation results. In some cases, like 1D theory of fluid dynamics, conventional SciVis techniques are not very useful. One such example is a simulation of injection systems that is becoming more and more important due to an increasingly restrictive emission regulations. There are many parameters and correlations among them that influence the simulation results. We describe how basic information visualization techniques can help in visualizing, understanding and analyzing this kind of data. The Com Vis tool is developed and used to analyze and explore the data. Com Vis supports multiple linked views and common information visualization displays such as 2D and 3D scatter-plot, histogram, parallel coordinates, pie-chart, etc. A diesel common rail injector with 2/2 way valve is used for a case study. Data sets were generated using a commercially available AVL HYDSIM simulation tool for dynamic analysis of hydraulic and hydro-mechanical systems, with the main application area in the simulation of fuel injection systems.	Kresimir Matkovic;Mario Jelovic;Josip Juric;Zoltan Konyha;Denis Gracanin	VRVis Res. Center, Vienna, Austria|c|;;;;	10.1109/INFVIS.1997.636793;10.1109/VISUAL.2000.885739;10.1109/VISUAL.1990.146402	Information visualization, visual exploration, simulation, injection system	VRVis Res. Center, Vienna, Austria|c|;;;;
Vis	2005	Quality mesh generation for molecular skin surfaces using restricted union of balls	10.1109/VISUAL.2005.1532822	http://dx.doi.org/10.1109/VISUAL.2005.1532822	399	405	C	Quality surface meshes for molecular models are desirable in the studies of protein shapes and functionalities. However, there is still no robust software that is capable to generate such meshes with good quality. In this paper, we present a Delaunay-based surface triangulation algorithm generating quality surface meshes for the molecular skin model. We expand the restricted union of balls along the surface and generate an ╬Á-sampling of the skin surface incrementally. At the same time, a quality surface mesh is extracted from the Delaunay triangulation of the sample points. The algorithm supports robust and efficient implementation and guarantees the mesh quality and topology as well. Our results facilitate molecular visualization and have made a contribution towards generating quality volumetric tetrahedral meshes for the macromolecules.	Ho-Lun Cheng;Xinwei Shi	Sch. of Comput., Nat. Univ. of Singapore, Singapore|c|;	10.1109/VISUAL.2004.36	Smooth surfaces, meshing, restricted union of balls, Delaunay triangulation, guaranteed quality triangulation, homeomorphism	National University of Singapore##National University of Singapore
Vis	2005	Surface reconstruction via contour metamorphosis: an Eulerian approach with Lagrangian particle tracking	10.1109/VISUAL.2005.1532823	http://dx.doi.org/10.1109/VISUAL.2005.1532823	407	414	C	We present a robust method for 3D reconstruction of closed surfaces from sparsely sampled parallel contours. A solution to this problem is especially important for medical segmentation, where manual contouring of 2D imaging scans is still extensively used. Our proposed method is based on a morphing process applied to neighboring contours that sweeps out a 3D surface. Our method is guaranteed to produce closed surfaces that exactly pass through the input contours, regardless of the topology of the reconstruction. Our general approach consecutively morphs between sets of input contours using an Eulerian formulation (i.e. fixed grid) augmented with Lagrangian particles (i.e. interface tracking). This is numerically accomplished by propagating the input contours as 2D level sets with carefully constructed continuous speed functions. Specifically this involves particle advection to estimate distances between the contours, monotonicity constrained spline interpolation to compute continuous speed functions without overshooting, and state-of-the-art numerical techniques for solving the level set equations. We demonstrate the robustness of our method on a variety of medical, topographic and synthetic data sets.	Ola Nilsson;David E. Breen;Ken Museth	Linkoping Univ., Sweden|c|;;	10.1109/VISUAL.1996.567812;10.1109/VISUAL.2002.1183773;10.1109/VISUAL.1998.745281;10.1109/VISUAL.1995.480820	3D reconstruction, contours, level sets	LinkÃ¶ping University##
Vis	2005	Reconstructing manifold and non-manifold surfaces from point clouds	10.1109/VISUAL.2005.1532824	http://dx.doi.org/10.1109/VISUAL.2005.1532824	415	422	C	This paper presents a novel approach for surface reconstruction from point clouds. The proposed technique is general in the sense that it naturally handles both manifold and non-manifold surfaces, providing a consistent way for reconstructing closed surfaces as well as surfaces with boundaries. It is also robust in the presence of noise, irregular sampling and surface gaps. Furthermore, it is fast, parallelizable and easy to implement because it is based on simple local operations. In this approach, surface reconstruction consists of three major steps: first, the space containing the point cloud is subdivided, creating a voxel representation. Then, a voxel surface is computed using gap filling and topological thinning operations. Finally, the resulting voxel surface is converted into a polygonal mesh. We demonstrate the effectiveness of our approach by reconstructing polygonal models from range scans of real objects as well as from synthetic data.	Jianning Wang;Manuel Menezes de Oliveira Neto;Arie E. Kaufman	Stony Brook Univ., NY, USA|c|;;	10.1109/VISUAL.2001.964489;10.1109/VISUAL.2001.964528	surface reconstruction, non-manifold surfaces, topological thinning	CVC##Stony Brook University
Vis	2005	Marching diamonds for unstructured meshes	10.1109/VISUAL.2005.1532825	http://dx.doi.org/10.1109/VISUAL.2005.1532825	423	429	C	We present a higher-order approach to the extraction of isosurfaces from unstructured meshes. Existing methods use linear interpolation along each mesh edge to find isosurface intersections. In contrast, our method determines intersections by performing barycentric interpolation over diamonds formed by the tetrahedra incident to each edge. Our method produces smoother, more accurate isosurfaces. Additionally, interpolating over diamonds, rather than linearly interpolating edge endpoints. enables us to identify up to two isosurface intersections per edge. This paper details how our new technique extracts isopoints, and presents a simple connection strategy for forming a triangle mesh isosurface.	John C. Anderson;Janine Bennett;Kenneth I. Joy	Comput. Sci. Dept., California Univ., Davis, CA, USA|c|;;	10.1109/VISUAL.1994.346331;10.1109/VISUAL.1991.175782	isosurface extraction, interpolation, unstructured mesh	University of California##University of California##University of California
Vis	2005	Evolutionary morphing	10.1109/VISUAL.2005.1532826	http://dx.doi.org/10.1109/VISUAL.2005.1532826	431	438	C	We introduce a technique to visualize the gradual evolutionary change of the shapes of living things as a morph between known three-dimensional shapes. Given geometric computer models of anatomical shapes for some collection of specimens - here the skulls of the some of the extant members of a family of monkeys - an evolutionary tree for the group implies a hypothesis about the way in which the shape changed through time. We use a statistical model which expresses the value of some continuous variable at an internal point in the tree as a weighted average of the values at the leaves. The framework of geometric morphometrics can then be used to define a shape-space, based on the correspondences of landmark points on the surfaces, within which these weighted averages can be realized as actual surfaces. Our software provides tools for performing and visualizing such an analysis in three dimensions. Beginning with laser range scans of crania, we use our landmark editor to interactively place landmark points on the surface. We use these to compute a "tree-morph" that smoothly interpolates the shapes across the tree. Each intermediate shape in the morph is a linear combination of all of the input surfaces. We create a surface model for an intermediate shape by warping all the input meshes towards the correct shape and then blending them together. To do the blending, we compute a weighted average of their associated trivariate distance functions and then extract a surface from the resulting function. We implement this idea using the squared distance function, rather than the usual signed distance function, in a novel way.	David F. Wiley;Nina Amenta;Dan A. Alcantara;Deboshmita Ghosh;Yong Joo Kil;Eric Delson;Will Harcourt-Smith;Katherine St. John;F. James Rohlf;Bernd Hamann	Dept. of Comput. Sci., California Univ., Davis, CA, USA|c|;;;;;;;;;		morphometrics, morphing, surface blending, merging, warping, distance fields, extremal surface	University of California##University of California##University of California##University of California##University of California##University of California##University of California##University of California##University of California##University of California##University of California
Vis	2005	Hardware-accelerated 3D visualization of mass spectrometry data	10.1109/VISUAL.2005.1532827	http://dx.doi.org/10.1109/VISUAL.2005.1532827	439	446	C	We present a system for three-dimensional visualization of complex liquid chromatography-mass spectrometry (LCMS) data. Every LCMS data point has three attributes: time, mass, and intensity. Instead of the traditional visualization of two-dimensional subsets of the data, we visualize it as a height field or terrain in 3D. Unlike traditional terrains, LCMS data has non-linear sampling and consists mainly of tall needle-like features. We adapt the level-of-detail techniques of geometry clipmaps for hardware-accelerated rendering of LCMS data. The data is cached in video memory as a set of nested rectilinear grids centered about the view frustum. We introduce a simple compression scheme and dynamically stream data from the CPU to the GPU as the viewpoint moves. Our system allows interactive investigation of complex LCMS data with close to one billion data points at up to 130 frames per second, depending on the view conditions.	Jose De Corral;Hanspeter Pfister	Waters Corp., Milford, MA, USA|c|;	10.1109/VISUAL.1996.567600;10.1109/VISUAL.1998.745282;10.1109/VISUAL.1997.663860	Mass Spectrometry, Terrain Rendering, GPU Rendering	Waters Corporation##Waters Corporation
Vis	2005	Differential protein expression analysis via liquid-chromatography/mass-spectrometry data visualization	10.1109/VISUAL.2005.1532828	http://dx.doi.org/10.1109/VISUAL.2005.1532828	447	454	C	Differential protein expression analysis is one of the main challenges in proteomics. It denotes the search for proteins, whose encoding genes are differentially expressed under a given experimental setup. An important task in this context is to identify the differentially expressed proteins or, more generally, all proteins present in the sample. One of the most promising and recently widely used approaches for protein identification is to cleave proteins into peptides, separate the peptides using liquid chromatography, and determine the masses of the separated peptides using mass spectrometry. The resulting data needs to be analyzed and matched against protein sequence databases. The analysis step is typically done by searching for intensity peaks in a large number of 2D graphs. We present an interactive visualization tool for the exploration of liquid-chromatography/mass-spectrometry data in a 3D space, which allows for the understanding of the data in its entirety and a detailed analysis of regions of interest. We compute differential expression over the liquid-chromatography/mass-spectrometry domain and embed it visually in our system. Our exploration tool can treat single liquid-chromatography/mass-spectrometry data sets as well as data acquired using multi-dimensional protein identification technology. For efficiency purposes we perform a peak-preserving data resampling and multiresolution hierarchy generation prior to visualization.	Lars Linsen;Julia Löcherbach;Matthias Berth;Jörg Bernhardt	Dept. of Math. & Comput. Sci., Ernst-Moritz-Arndt-Univ., Greifswald, Germany|c|;;;;	10.1109/VISUAL.1997.663907	interactive visual exploration, hierarchical data representation, visualization in bioinformatics, proteomics	UniversitÃ¤t Greifswald Greifswald##UniversitÃ¤t Greifswald Greifswald##Ernst-Moritz-Arndt-UniversitÃ¤t Greifswald Greifswald
Vis	2005	The software interface to the 3D-force microscope	10.1109/VISUAL.2005.1532829	http://dx.doi.org/10.1109/VISUAL.2005.1532829	455	462	C	We have developed a real-time experiment-control and data-display system for a novel microscope, the 3D-force microscope (3DFM), which is designed for nanometer-scale and nanoNewton-force biophysical experiments. The 3DFM software suite synthesizes the several data sources from the 3DFM into a coherent view and provides control over data collection and specimen manipulation. Herein, we describe the system architecture designed to handle the several feedback loops and data flows present in the microscope and its control system. We describe the visualization techniques used in the 3DFM software suite, where used, and on which types of data. We present feedback from our scientist-users regarding the usefulness of these techniques, and we also present lessons learned from our successive implementations.	David Marshburn;Chris Weigle;Benjamin G. Wilde;Russell M. Taylor II;Kalpit Desai;J. K. Fisher;Jeremy Cribb;E. Timothy O'Brien;Richard Superfine	Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;;;;;;;;	10.1109/VISUAL.1997.663923;10.1109/VISUAL.1996.568110;10.1109/VISUAL.1996.568136	applications of visualization, multimodal visualization, haptics, force, scientific visualization, interactive graphics, virtual worlds, microscopy	University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill
Vis	2005	Opening the can of worms: an exploration tool for vortical flows	10.1109/VISUAL.2005.1532830	http://dx.doi.org/10.1109/VISUAL.2005.1532830	463	470	C	Gaining a comprehensive understanding of turbulent flows still poses one of the great challenges in fluid dynamics. A well-established approach to advance this research is the analysis of the vortex structures contained in the flow. In order to be able to perform this analysis efficiently, supporting visualization tools with clearly defined requirements are needed. In this paper, we present a visualization system which matches these requirements to a large extent. The system consists of two components. The first component analyzes the flow by means of a novel combination of vortex core line detection and the λ2 method. The second component is a vortex browser which allows for an interactive exploration and manipulation of the vortices detected and separated during the first phase. Our system improves the reliability and applicability of existing vortex detection methods and allows for a more efficient study of vortical flows which is demonstrated in an evaluation performed by experts.	Simon Stegmaier;Ulrich Rist;Thomas Ertl	Inst. for Visualization & Interactive Syst., Stuttgart Univ., Germany|c|;;	10.1109/VISUAL.1990.146359;10.1109/VISUAL.1998.745297;10.1109/VISUAL.1994.346327;10.1109/VISUAL.2004.3;10.1109/VISUAL.1998.745288;10.1109/VISUAL.1998.745296	Flow Features, Vortex Detection, Interactive Manipulation, 3D Vector Field Visualization	University of Stuttgart##University of Stuttgart##University of Stuttgart
Vis	2005	Strategy for seeding 3D streamlines	10.1109/VISUAL.2005.1532831	http://dx.doi.org/10.1109/VISUAL.2005.1532831	471	478	C	This paper presents a strategy for seeding streamlines in 3D flow fields. Its main goal is to capture the essential flow patterns and to provide sufficient coverage in the field while reducing clutter. First, critical points of the flow field are extracted to identify regions with important flow patterns that need to be presented. Different seeding templates are then used around the vicinity of the different critical points. Because there is significant variability in the flow pattern even for the same type of critical point, our template can change shape depending on how far the critical point is from transitioning into another type of critical point. To accomplish this, we introduce the ╬▒-╬▓ map of 3D critical points. Next, we use Poisson seeding to populate the empty regions. Finally, we filter the streamlines based on their geometric and spatial properties. Altogether, this multi-step strategy reduces clutter and yet captures the important 3D flow features.	Xiaohong Ye;David Kao;Alex T. Pang	Comput. Sci. Dept., UCSC, USA|c|;;	10.1109/VISUAL.2000.885690;10.1109/VISUAL.1996.567777;10.1109/VISUAL.2000.885688;10.1109/VISUAL.1999.809865;10.1109/VISUAL.1991.175771;10.1109/VISUAL.2003.1250376	streamlines, flow guided, feature based, filtering, critical points, variable templates	UCSC##UCSC##UCSC
Vis	2005	Farthest point seeding for efficient placement of streamlines	10.1109/VISUAL.2005.1532832	http://dx.doi.org/10.1109/VISUAL.2005.1532832	479	486	C	We propose a novel algorithm for placement of streamlines from two-dimensional steady vector or direction fields. Our method consists of placing one streamline at a time by numerical integration starting at the furthest away from all previously placed streamlines. Such a farthest point seeding strategy leads to high quality placements by favoring long streamlines, while retaining uniformity with the increasing density. Our greedy approach generates placements of comparable quality with respect to the optimization approach from Turk and Banks, while being 200 times faster. Simplicity, robustness as well as efficiency is achieved through the use of a Delaunay triangulation to model the streamlines, address proximity queries and determine the biggest voids by exploiting the empty circle property. Our method handles variable density and extends to multiresolution.	Abdelkrim Mebarki;Pierre Alliez;Olivier Devillers	INRIA Sophia-Antipolis, France|c|;;	10.1109/VISUAL.2000.885690	Streamline placement, farthest point seeding, Delaunay triangulation, variable density, multiresolution	INRIA Sophia-Antipolis##INRIA
Vis	2005	View selection for volume rendering	10.1109/VISUAL.2005.1532833	http://dx.doi.org/10.1109/VISUAL.2005.1532833	487	494	C	In a visualization of a three-dimensional dataset, the insights gained are dependent on what is occluded and what is not. Suggestion of interesting viewpoints can improve both the speed and efficiency of data understanding. This paper presents a view selection method designed for volume rendering. It can be used to find informative views for a given scene, or to find a minimal set of representative views which capture the entire scene. It becomes particularly useful when the visualization process is non-interactive - for example, when visualizing large datasets or time-varying sequences. We introduce a viewpoint "goodness" measure based on the formulation of entropy from information theory. The measure takes into account the transfer function, the data distribution and the visibility of the voxels. Combined with viewpoint properties like view-likelihood and view-stability, this technique can be used as a guide, which suggests "interesting" viewpoints for further exploration. Domain knowledge is incorporated into the algorithm via an importance transfer function or volume. This allows users to obtain view selection behaviors tailored to their specific situations. We generate a view space partitioning, and select one representative view for each partition. Together, this set of views encapsulates the "interesting" and distinct views of the data. Viewpoints in this set can be used as starting points for interactive exploration of the data, thus reducing the human effort in visualization. In non-interactive situations, such a set can be used as a representative visualization of the dataset from all directions.	Udeepta Bordoloi;Han-Wei Shen	Ohio State Univ., Columbus, OH, USA|c|;	10.1109/VISUAL.2000.885694;10.1109/VISUAL.2003.1250386;10.1109/VISUAL.2005.1532834;10.1109/VISUAL.2001.964516	viewpoint selection, view space partitioning, volume rendering, entropy, visibility	The Ohio State Univesity##The Ohio State Univesity
Vis	2005	A feature-driven approach to locating optimal viewpoints for volume visualization	10.1109/VISUAL.2005.1532834	http://dx.doi.org/10.1109/VISUAL.2005.1532834	495	502	C	Optimal viewpoint selection is an important task because it considerably influences the amount of information contained in the 2D projected images of 3D objects, and thus dominates their first impressions from a psychological point of view. Although several methods have been proposed that calculate the optimal positions of viewpoints especially for 3D surface meshes, none has been done for solid objects such as volumes. This paper presents a new method of locating such optimal viewpoints when visualizing volumes using direct volume rendering. The major idea behind our method is to decompose an entire volume into a set of feature components, and then find a globally optimal viewpoint by finding a compromise between locally optimal viewpoints for the components. As the feature components, the method employs interval volumes and their combinations that characterize the topological transitions of isosurfaces according to the scalar field. Furthermore, opacity transfer functions are also utilized to assign different weights to the decomposed components so that users can emphasize features of specific interest in the volumes. Several examples of volume datasets together with their optimal positions of viewpoints are exhibited in order to demonstrate that the method can effectively guide naive users to find optimal projections of volumes.	Shigeo Takahashi;Issei Fujishiro;Yuriko Takeshima;Tomoyuki Nishita	Tokyo Univ., Japan|c|;;;	10.1109/VISUAL.1995.480789;10.1109/VISUAL.2004.96;10.1109/VISUAL.2002.1183774;10.1109/VISUAL.2005.1532833;10.1109/VISUAL.1997.663875;10.1109/VISUAL.2002.1183785	viewpoint selection, viewpoint entropy, direct volume rendering, interval volumes, level-set graphs	The University of Tokyo##The University of Tokyo##The University of Tokyo##The University of Tokyo
Vis	2005	Visualizing intersecting surfaces with nested-surface techniques	10.1109/VISUAL.2005.1532835	http://dx.doi.org/10.1109/VISUAL.2005.1532835	503	510	C	This paper describes the adaptation and evaluation of existing nested-surface visualization techniques for the problem of displaying intersecting surfaces. For this work, we collaborated with a neurosurgeon who is comparing multiple tumor segmentations with the goal of increasing the segmentation accuracy and reliability. A second collaborator, a physicist, aims to validate geometric models of specimens against atomic-force microscope images of actual specimens. These collaborators are interested in comparing both surface shape and inter-surface distances. Many commonly employed techniques for visually comparing multiple surfaces (side-by-side, wireframe, colormaps, uniform translucence) do not simultaneously convey inter-surface distance and the shapes of two or more surfaces. This paper describes a simple geometric partitioning of intersecting surfaces that enables the application of existing nested-surface techniques, such as texture-modulated translucent rendering of exteriors, to a broader range of visualization problems. Three user studies investigate the performance of existing techniques and a new shadow-casting glyph technique. The results of the first user study show that texture glyphs on partitioned, intersecting surfaces can convey inter-surface distance better than directly mapping distance to a red-gray-blue color scale on a single surface. The results of the second study show similar results for conveying local surface orientation. The results of the third user study show that adding cast shadows to texture glyphs can increase the understanding of inter-surface distance in static images, but can be overpowered by the shape cues from a simple rocking motion.	Chris Weigle;Russell M. Taylor II	Dept. of Comput. Sci., North Carolina Univ., Chapel Hill, NC, USA|c|;	10.1109/VISUAL.1996.568118;10.1109/VISUAL.1996.568111;10.1109/INFVIS.2003.1249022;10.1109/VISUAL.2000.885723	perception, user study, transparent surfaces, nested surfaces, intersecting surfaces, two-surface visualization, scientific visualization	University of North Carolina at Chapel Hill##University of North Carolina at Chapel Hill
Vis	2005	Understanding visualization through spatial ability differences	10.1109/VISUAL.2005.1532836	http://dx.doi.org/10.1109/VISUAL.2005.1532836	511	518	C	Little is known about the cognitive abilities which influence the comprehension of scientific and information visualizations and what properties of the visualization affect comprehension. Our goal in this paper is to understand what makes visualizations difficult. We address this goal by examining the spatial ability differences in a diverse population selected for spatial ability variance. For example, how is, spatial ability related to visualization comprehension? What makes a particular visualization difficult or time intensive for specific groups of subjects? In this paper, we present the results of an experiment designed to answer these questions. Fifty-six subjects were tested on a basic visualization task and given standard paper tests of spatial abilities. An equal number of males and females were recruited in this study in order to increase spatial ability variance. Our results show that high spatial ability is correlated with accuracy on our three-dimensional visualization test, but not with time. High spatial ability subjects also had less difficulty with object complexity and the hidden properties of an object.	Maria C. Velez;Deborah Silver;Marilyn Tremaine	Center for Adv. Inf. Process., Rutgers State Univ., NJ, USA|c|;;	10.1109/INFVIS.2003.1249022;10.1109/VISUAL.2003.1250396	Gender differences, orthogonal projections, spatial ability, standardized testing	the State University of New##the State University of New##the State University of New
Vis	2005	Eyegaze analysis of displays with combined 2D and 3D views	10.1109/VISUAL.2005.1532837	http://dx.doi.org/10.1109/VISUAL.2005.1532837	519	526	C	Displays combining both 2D and 3D views have been shown to support higher performance on certain visualization tasks. However, it is not clear how best to arrange a combination of 2D and 3D views spatially in a display. In this study, we analyzed the eyegaze strategies of participants using two arrangements of 2D and 3D views to estimate the relative position of objects in a 3D scene. Our results show that the 3D view was used significantly more often than individual 2D views in both displays, indicating the importance of the 3D view for successful task completion. However, viewing patterns were significantly different between the two displays: transitions through centrally-placed views were always more frequent, and users avoided saccades between views that were far apart. Although the change in viewing strategy did not result in significant performance differences, error analysis indicates that a 3D overview in the center may reduce the number of serious errors compared to a 3D overview placed off to the side.	Melanie Tory;M. Stella Atkins;Arthur E. Kirkpatrick;Marios Nicolaou;Guang-Zhong Yang	Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC, Canada|c|;;;;	10.1109/VISUAL.2003.1250396;10.1109/VISUAL.1997.663914	visualization, 2D/3D combination display, user study, experiment, eyegaze analysis	University of British Columbia School of Computing Science Simon Fraser University##University of British Columbia School of Computing Science Simon Fraser University##University of British Columbia School of Computing Science Simon Fraser University##University of British Columbia School of Computing Science Simon Fraser University##University of British Columbia School of Computing Science Simon Fraser University##University of British Columbia School of Computing Science Simon Fraser University
Vis	2005	Visualizing data with motion	10.1109/VISUAL.2005.1532838	http://dx.doi.org/10.1109/VISUAL.2005.1532838	527	534	C	This paper describes an experimental study of three perceptual properties of motion: flicker, direction, and velocity. Our goal is to understand how to apply these properties to represent data in a visualization environment. Results from our experiments show that all three properties can encode multiple data values, but that minimum visual differences are needed to ensure rapid and accurate target detection: flicker must be coherent and must have a cycle length of 120 milliseconds or greater, direction must differ by at least 20┬░, and velocity must differ by at least 0.43┬░ of subtended visual angle. We conclude with an overview of how we are applying our results to real-world data, and then discuss future work we plan to pursue.	Daniel E. Huber;Christopher G. Healey	;	10.1109/VISUAL.1990.146373	direction, flicker, motion, multidimensional, perception, velocity, visualization	North Carolina State University##North Carolina State University##North Carolina State University
Vis	2005	Topology-based simplification for feature extraction from 3D scalar fields	10.1109/VISUAL.2005.1532839	http://dx.doi.org/10.1109/VISUAL.2005.1532839	535	542	C	In this paper, we present a topological approach for simplifying continuous functions defined on volumetric domains. We introduce two atomic operations that remove pairs of critical points of the function and design a combinatorial algorithm that simplifies the Morse-Smale complex by repeated application of these operations. The Morse-Smale complex is a topological data structure that provides a compact representation of gradient flow between critical points of a function. Critical points paired by the Morse-Smale complex identify topological features and their importance. The simplification procedure leaves important critical points untouched, and is therefore useful for extracting desirable features. We also present a visualization of the simplified topology.	Attila Gyulassy;Vijay Natarajan;Valerio Pascucci;Peer-Timo Bremer;Bernd Hamann	Dept. of Comput. Sci., California Univ., Davis, CA, USA|c|;	10.1109/VISUAL.1999.809907;10.1109/VISUAL.2000.885680;10.1109/VISUAL.2004.96;10.1109/VISUAL.2001.964507	Morse theory, Morse-Smale complexes, computational topology, multiresolution, simplification, feature detection, 3D scalar fields	Dept. of Comput. Sci., California Univ., Davis, CA, USA|c|;
Vis	2005	Topology-driven surface mappings with robust feature alignment	10.1109/VISUAL.2005.1532840	http://dx.doi.org/10.1109/VISUAL.2005.1532840	543	550	C	Topological concepts and techniques have been broadly applied in computer graphics and geometric modeling. However, the homotopy type of a mapping between two surfaces has not been addressed before. In this paper, we present a novel solution to the problem of computing continuous maps with different homotopy types between two arbitrary triangle meshes with the same topology. Inspired by the rich theory of topology as well as the existing body of work on surface mapping, our newly-developed mapping techniques are both fundamental and unique, offering many attractive advantages. First, our method allows the user to change the homotopy type or global structure of the mapping with minimal intervention. Moreover, to locally affect shape correspondence, we articulate a new technique that robustly satisfies hard feature constraints, without the use of heuristics to ensure validity. In addition to acting as a useful tool for computer graphics applications, our method can be used as a rigorous and practical mechanism for the visualization of abstract topological concepts such as homotopy type of surface mappings, homology basis, fundamental domain, and universal covering space. At the core of our algorithm is a procedure for computing the canonical homology basis and using it as a common cut graph for any surface with the same topology. We demonstrate our results by applying our algorithm to shape morphing in this paper.	Christopher Carner;Miao Jin;Xianfeng Gu;Hong Qin	Stony Brook Univ., NY, USA|c|;;;	10.1109/VISUAL.2002.1183795	Surface parameterization, Riemannian surface structure, Computational topology, Shape morphing	Stony Brook University##Stony Brook University##Stony Brook University##Stony Brook University
Vis	2005	Topological structures of 3D tensor fields	10.1109/VISUAL.2005.1532841	http://dx.doi.org/10.1109/VISUAL.2005.1532841	551	558	C	Tensor topology is useful in providing a simplified and yet detailed representation of a tensor field. Recently the field of 3D tensor topology is advanced by the discovery that degenerate tensors usually form lines in their most basic configurations. These lines form the backbone for further topological analysis. A number of ways for extracting and tracing the degenerate tensor lines have also been proposed. In this paper, we complete the previous work by studying the behavior and extracting the separating surfaces emanating from these degenerate lines. First, we show that analysis of eigenvectors around a 3D degenerate tensor can be reduced to 2D. That is, in most instances, the 3D separating surfaces are just the trajectory of the individual 2D separatrices which includes trisectors and wedges. But the proof is by no means trivial since it is closely related to perturbation theory around a pair of singular slate. Such analysis naturally breaks down at the tangential points where the degenerate lines pass through the plane spanned by the eigenvectors associated with the repeated eigenvalues. Second, we show that the separatrices along a degenerate line may switch types (e.g. trisectors to wedges) exactly at the points where the eigenplane is tangential to the degenerate curve. This property leads to interesting and yet complicated configuration of surfaces around such transition points. Finally, we apply the technique to several common data sets to verify its correctness.	Xiaoqiang Zheng;Beresford N. Parlett;Alex T. Pang	Comput. Sci. Dept., UCSC, Santa Cruz, CA, USA|c|;;	10.1109/VISUAL.2004.105;10.1109/VISUAL.1999.809894;10.1109/VISUAL.1994.346326;10.1109/VISUAL.2004.113;10.1109/VISUAL.2003.1250376	separating surface, trisectors, wedges, symmetric tensors, hyperstreamlines, degenerate tensors, tensor topology, topological line	UCSC##UCSC
Vis	2005	Extracting higher order critical points and topological simplification of 3D vector fields	10.1109/VISUAL.2005.1532842	http://dx.doi.org/10.1109/VISUAL.2005.1532842	559	566	C	This paper presents an approach to extracting and classifying higher order critical points of 3D vector fields. To do so, we place a closed convex surface s around the area of interest. Then we show that the complete 3D classification of a critical point into areas of different flow behavior is equivalent to extracting the topological skeleton of an appropriate 2D vector field on s, if each critical point is equipped with an additional bit of information. Out of this skeleton, we create an icon which replaces the complete topological structure inside s for the visualization. We apply our method to find a simplified visual representation of clusters of critical points, leading to expressive visualizations of topologically complex 3D vector fields.	Tino Weinkauf;Holger Theisel;Kuangyu Shi;Hans-Christian Hege;Hans-Peter Seidel	ZIB, Berlin, Germany|c|;;;;	10.1109/VISUAL.1999.809907;10.1109/VISUAL.2002.1183786;10.1109/VISUAL.2000.885714;10.1109/VISUAL.1991.175773;10.1109/VISUAL.2000.885716;10.1109/VISUAL.2001.964507;10.1109/VISUAL.2003.1250376		ZIB, Berlin, Germany|c|;;;;
Vis	2005	Visualization of the genus of knots	10.1109/VISUAL.2005.1532843	http://dx.doi.org/10.1109/VISUAL.2005.1532843	567	574	C	The genus of a knot or link can be defined via Seifert surfaces. A Seifert surface of a knot or link is an oriented surface whose boundary coincides with that, knot or link. Schematic images of these surfaces are shown in every text book on knot theory, but from these it is hard to understand their shape and structure. In this paper the visualization of such surfaces is discussed. A method is presented to produce different styles of surfaces for knots and links, starting from the so-called braid representation. Also, it is shown how closed oriented surfaces can be generated in which the knot is embedded, such that the knot subdivides the surface into two parts. These closed surfaces provide a direct visualization of the genus of a knot.	Jarke J. van Wijk;Arjeh M. Cohen	Dept. of Math. & Comput. Sci., Eindhoven Univ. of Technol., Netherlands|c|;		Visualization, knot theory, topology, genus, Seifert surfaces	Technische Universiteit Eindhoven##Technische Universiteit Eindhoven
Vis	2005	Visualizing the tightening of knots	10.1109/VISUAL.2005.1532844	http://dx.doi.org/10.1109/VISUAL.2005.1532844	575	582	C	The study of physical models for knots has recently received much interest in the mathematics community. In this paper, we consider the ropelength model, which considers knots tied in an idealized rope. This model is interesting in pure mathematics, and has been applied to the study of a variety of problems in the natural sciences as well. Modeling and visualizing the tightening of knots in this idealized rope poses some interesting challenges in computer graphics. In particular, self-contact in a deformable rope model is a difficult problem which cannot be handled by standard techniques. In this paper, we describe a solution based on reformulating the contact problem and using constrained-gradient techniques from nonlinear optimization. The resulting animations reveal new properties of the tightening flow and provide new insights into the geometric structure of tight knots and links.	Jason Cantarella;Michael Piatek;Eric Rawdon	Georgia Univ., Athens, GA, USA|c|;;		collision detection, contact, flexible models, tight knots, ideal knots, ropelength, nonlinear optimization, constrained least squares	University of Georgia##University of Georgia##University of Georgia
Vis	2005	Visualization in the Einstein Year 2005: a case study on explanatory and illustrative visualization of relativity and astrophysics	10.1109/VISUAL.2005.1532845	http://dx.doi.org/10.1109/VISUAL.2005.1532845	583	590	C	In this application paper, we report on over fifteen years of experience with relativistic and astrophysical visualization, which has been culminating in a substantial engagement for visualization in the Einstein Year 2005 - the 100th anniversary of Einstein's publications on special relativity, the photoelectric effect, and Brownian motion. This paper focuses on explanatory and illustrative visualizations used to communicate aspects of the difficult theories of special and general relativity, their geometric structure, and of the related fields of cosmology and astrophysics. We discuss visualization strategies, motivated by physics education and didactics of mathematics, and describe what kind of visualization methods have proven to be useful for different types of media, such as still images in popular-science magazines, film contributions to TV shows, oral presentations, or interactive museum installations. Although our visualization tools build upon existing methods and implementations, these techniques have been improved by several novel technical contributions like image-based special relativistic rendering on GPUs, an extension of general relativistic ray tracing to manifolds described by multiple charts, GPU-based interactive visualization of gravitational light deflection, as well as planetary terrain rendering. The usefulness and effectiveness of our visualizations are demonstrated by reporting on experiences with, and feedback from, recipients of visualizations and collaborators.	Daniel Weiskopf;Marc Borchers;Thomas Ertl;Martin Falk;Oliver Fechtig;Regine Frank;Frank Grave;Andreas King;Ute Kraus;Thomas Müller 0005;Hans-Peter Nollert;Isabel Rica Mendez;Hanns Ruder;Corvin Zahn;Michael Zatloukal;Tobias Schafhitzel;Sonja Schär	Graphics, Visualisation, & Usability Lab., Simon Fraser Univ., Burnaby, BC, Canada|c|;;;;;;;;;;;;;;;;	10.1109/VISUAL.2000.885709;10.1109/VISUAL.2000.885728;10.1109/VISUAL.2000.885694;10.1109/VISUAL.2003.1250366;10.1109/VISUAL.2004.18	Visualization, explanatory computer graphics, illustrative visualization, special relativity, general relativity, astrophysics, visualization of mathematics, terrain rendering	Fraser University##University of TÃ¼bingen##University of Stuttgart##University of Stuttgart##University of TÃ¼bingen##University of TÃ¼bingen##University of TÃ¼bingen##University of TÃ¼bingen##University of TÃ¼bingen##University of TÃ¼bingen##University of TÃ¼bingen##University of TÃ¼bingen##University of TÃ¼bingen##University of Stuttgart##Historisches Museum Bern##University of TÃ¼bingen##University of TÃ¼bingen
Vis	2005	A handheld flexible display system	10.1109/VISUAL.2005.1532846	http://dx.doi.org/10.1109/VISUAL.2005.1532846	591	597	C	A new close range virtual reality system is introduced that allows intuitive and immersive user interaction with computer generated objects. A projector with a special spherical lens is combined with a flexible, tracked rear projection screen that users hold in their hands. Unlike normal projectors, the spherical lens allows for a 180 degree field of view and nearly infinite depth of focus. This allows the user to move the screen around the environment and use it as a virtual "slice" to examine the interior of 3D volumes. This provides a concrete correspondence between the virtual representation of the 3D volume and how that volume would actually appear if its real counterpart was sliced open. The screen can also be used as a "magic window" to view the mesh of the volume from different angles prior to taking cross sections of it. Real time rendering of the desired 3D volume or mesh is accomplished using current graphics hardware. Additional applications of the system are also discussed.	Jonathan Konieczny;Clement Shimizu;Gary W. Meyer;D'nardo Colucci	Digital Technol. Center, Minnesota Univ., Minneapolis, MN, USA|c|;;;	10.1109/VISUAL.2001.964508;10.1109/VISUAL.2003.1250351	visualization, virtual reality, user interfaces, projectors, volume rendering, curved sections	University of Minnesota##University of Minnesota##University of Minnesota
Vis	2005	Profile Flags: a novel metaphor for probing of T<sub>2</sub> maps	10.1109/VISUAL.2005.1532847	http://dx.doi.org/10.1109/VISUAL.2005.1532847	599	606	C	This paper describes a tool for the visualization of T2 maps of knee cartilage. Given the anatomical scan, and the T2 map of the cartilage, we combine the information on the shape and the quality of the cartilage in a single image. The Profile Flag is an intuitive 3D glyph for probing and annotating of the underlying data. It comprises a bulletin board pin-like shape with a small flag on top of it. While moving the glyph along the reconstructed surface of an object, the curve data measured along the pin's needle and in its neighborhood are shown on the flag. The application area of the Profile Flag is manifold, enabling the visualization of profile data of dense but in-homogeneous objects. Furthermore, it extracts the essential part of the data without removing or even reducing the context information. By sticking Profile Flags into the investigated structure, one or more significant locations can be annotated by showing the local characteristics of the data at that locations. In this paper we are demonstrating the properties of the tool by visualizing T2 maps of knee cartilage.	Matej Mlejnek;Pierre Ermes;Anna Vilanova;Rob van der Rijt;Harrie van den Bosch;Frans A. Gerritsen;Eduard Gröller	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;;;;	10.1109/VISUAL.2000.885733;10.1109/VISUAL.1993.398849;10.1109/VISUAL.2002.1183752;10.1109/VISUAL.2004.56	visualization in medicine, applications of visualization	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;;;;;;
Vis	2005	Eyelet particle tracing - steady visualization of unsteady flow	10.1109/VISUAL.2005.1532848	http://dx.doi.org/10.1109/VISUAL.2005.1532848	607	614	C	It is a challenging task to visualize the behavior of time-dependent 3D vector fields. Most of the time an overview of unsteady fields is provided via animations, but, unfortunately, animations provide only transient impressions of momentary flow. In this paper we present two approaches to visualize time varying fields with fixed geometry. Path lines and streak lines represent such a steady visualization of unsteady vector fields, but because of occlusion and visual clutter it is useless to draw them all over the spatial domain. A selection is needed. We show how bundles of streak lines and path lines, running at different times through one point in space, like through an eyelet, yield an insightful visualization of flow structure ("eyelet lines"). To provide a more intuitive and appealing visualization we also explain how to construct a surface from these lines. As second approach, we use a simple measurement of local changes of a field over time to determine regions with strong changes. We visualize these regions with isosurfaces to give an overview of the activity in the dataset. Finally we use the regions as a guide for placing eyelets.	Alexander Wiebel;Gerik Scheuermann	Dept. of Comput. Sci., Leipzig Univ., Germany|c|;	10.1109/VISUAL.2001.964493;10.1109/VISUAL.1995.485146;10.1109/VISUAL.2004.107;10.1109/VISUAL.1992.235211;10.1109/VISUAL.1993.398848;10.1109/VISUAL.2004.113;10.1109/VISUAL.1993.398850;10.1109/VISUAL.2003.1250372;10.1109/VISUAL.1996.568121;10.1109/VISUAL.2004.99	3D Vector Field Visualization, Time-Varying Data Visualization, Flow Visualization, Vector/Tensor Visualization	University of Leipzig##University of Leipzig
Vis	2005	Interpolation and visualization for advected scalar fields	10.1109/VISUAL.2005.1532849	http://dx.doi.org/10.1109/VISUAL.2005.1532849	615	622	C	Doppler radars are useful facilities for weather forecasting. The data sampled by using Doppler radars are used to measure the distributions and densities of rain drops, snow crystals, hail stones, or even insects in the atmosphere. In this paper, we propose to build up a graphics-based software system for visualizing Doppler radar data. In the system, the reflectivity data gathered by using Doppler radars are post-processed to generate virtual cloud images which reveal the densities of precipitation in the air. An optical flow based method is adopted to compute the velocities of clouds, advected by winds. Therefore, the movement of clouds is depicted. The cloud velocities are also used to interpolate reflectivities for arbitrary time steps. Therefore, the reflectivities at any time can be produced. Our system composes of three stages. At the first stage, the raw radar data are re-sampled and filtered to create a multiple resolution data structure, based on a pyramid structure. At the second stage, a numeric method is employed to compute cloud velocities in the air and to interpolate radar reflectivity data at given time steps. The radar reflectivity data and cloud velocities are displayed at the last stage. The reflectivities are rendered by using splatting methods to produce semi-transparent cloud images. Two kinds of media are created for analyzing the reflectivity data. The first kind media consists of a group of still images of clouds which displays the distribution and density of water in the air. The second type media is a short animation of cloud images to show the formation and movement of the clouds. To show the advection of clouds, the cloud velocities are displayed by using two dimensional images. In these images, the velocities are represented by arrows and superimposed on cloud images. To enhance image quality, gradients and diffusion of the radar data are computed and used in the rendering process. Therefore the cloud structures are better portrayed. In order to achieve interactive visualization, our system is also comprised with a view-dependent visualization module. The radar data at far distance are rendered in lower resolutions, while the data closer to the eye position is rendered in details.	Shyh-Kuang Ueng;Sheng-Chuan Wang	Dept. of Comput. Sci., Nat. Taiwan Ocean Univ., Taipei, Taiwan|c|;	10.1109/VISUAL.2004.69;10.1109/VISUAL.2001.964490;10.1109/VISUAL.1999.809916;10.1109/VISUAL.2002.1183823	Doppler radar, volume rendering, optical flow, level of details, vector field visualization	National Taiwan Ocean University##National Taiwan Ocean University
Vis	2005	Visual analysis and exploration of fluid flow in a cooling jacket	10.1109/VISUAL.2005.1532850	http://dx.doi.org/10.1109/VISUAL.2005.1532850	623	630	C	We present a visual analysis and exploration of fluid flow through a cooling jacket. Engineers invest a large amount of time and serious effort to optimize the flow through this engine component because of its important role in transferring heat away from the engine block. In this study we examine the design goals that engineers apply in order to construct an ideal-as-possible cooling jacket geometry and use a broad range of visualization tools in order to analyze, explore, and present the results. We systematically employ direct, geometric, and texture-based flow visualization techniques as well as automatic feature extraction and interactive feature-based methodology. And we discuss the relative advantages and disadvantages of these approaches as well as the challenges, both technical and perceptual with this application. The result is a feature-rich state-of-the-art flow visualization analysis applied to an important and complex data set from real-world computational fluid dynamics simulations.	Robert S. Laramee;Christoph Garth;Helmut Doleisch;Jürgen Schneider;Helwig Hauser;Hans Hagen	VRVis Res. Center, Vienna, Austria|c|;;;;;	10.1109/VISUAL.1999.809895;10.1109/VISUAL.1992.235211;10.1109/VISUAL.1997.663910;10.1109/VISUAL.1996.568137;10.1109/VISUAL.2004.107;10.1109/VISUAL.2004.113;10.1109/VISUAL.1998.745333;10.1109/VISUAL.2002.1183821;10.1109/VISUAL.2003.1250376;10.1109/VISUAL.2002.1183822;10.1109/VISUAL.2004.59;10.1109/VISUAL.2004.128	flow visualization, vector field visualization, feature-extraction, feature-based visualization, computational fluid dynamics (CFD), cooling jacket, visualization systems, engine simulation,heat transfer	VRVis Research Center in Vienna####VRVis Research Center in Vienna####VRVis Research Center in Vienna##
Vis	2005	Extraction of parallel vector surfaces in 3D time-dependent fields and application to vortex core line tracking	10.1109/VISUAL.2005.1532851	http://dx.doi.org/10.1109/VISUAL.2005.1532851	631	638	C	We introduce an approach to tracking vortex core lines in time-dependent 3D flow fields which are defined by the parallel vectors approach. They build surface structures in the 4D space-time domain. To extract them, we introduce two 4D vector fields which act as feature flow fields, i.e., their integration gives the vortex core structures. As part of this approach, we extract and classify local bifurcations of vortex core lines in space-time. Based on a 4D stream surface integration, we provide an algorithm to extract the complete vortex core structure. We apply our technique to a number of test data sets.	Holger Theisel;Jan Sahner;Tino Weinkauf;Hans-Christian Hege;Hans-Peter Seidel	MPI Saarbrucken, Germany|c|;;;;	10.1109/VISUAL.2004.99;10.1109/VISUAL.1994.346327;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1992.235211;10.1109/VISUAL.1993.398875;10.1109/VISUAL.2001.964506;10.1109/VISUAL.1998.745290;10.1109/VISUAL.1998.745296	flow visualization, vortex core lines, bifurcations	MPI Saarbrucken, Germany|c|;;;;
Vis	2005	Particle and texture based spatiotemporal visualization of time-dependent vector fields	10.1109/VISUAL.2005.1532852	http://dx.doi.org/10.1109/VISUAL.2005.1532852	639	646	C	We propose a hybrid particle and texture based approach for the visualization of time-dependent vector fields. The underlying space-time framework builds a dense vector field representation in a two-step process: 1) particle-based forward integration of trajectories in spacetime for temporal coherence, and 2) texture-based convolution along another set of paths through the spacetime for spatially correlated patterns. Particle density is controlled by stochastically injecting and removing particles, taking into account the divergence of the vector field. Alternatively, a uniform density can be maintained by placing exactly one particle in each cell of a uniform grid, which leads to particle-in-cell forward advection. Moreover, we discuss strategies of previous visualization methods for unsteady flow and show how they address issues of spatiotemporal coherence and dense visual representations. We demonstrate how our framework is capable of realizing several of these strategies. Finally, we present an efficient GPU implementation that facilitates an interactive visualization of unsteady 2D flow on Shader Model 3 compliant graphics hardware.	Daniel Weiskopf;Frederik Schramm;Gordon Erlebacher;Thomas Ertl	Graphics, Usability, & Visualization Lab., Simon Fraser Univ., Burnaby, BC, Canada|c|;;;	10.1109/VISUAL.2003.1250377;10.1109/VISUAL.2003.1250363;10.1109/VISUAL.2003.1250361;10.1109/VISUAL.2000.885689;10.1109/VISUAL.2003.1250402;10.1109/VISUAL.2003.1250364	Unsteady flow visualization, visualization framework, LIC, texture advection, particle systems, GPU methods	Simon Fraser University##University of Stuttgart##Florida State University##University of Stuttgart
Vis	2005	Texture-based visualization of uncertainty in flow fields	10.1109/VISUAL.2005.1532853	http://dx.doi.org/10.1109/VISUAL.2005.1532853	647	654	C	In this paper, we present two novel texture-based techniques to visualize uncertainty in time-dependent 2D flow fields. Both methods use semi-Lagrangian texture advection to show flow direction by streaklines and convey uncertainty by blurring these streaklines. The first approach applies a cross advection perpendicular to the flow direction. The second method employs isotropic diffusion that can be implemented by Gaussian filtering. Both methods are derived from a generic filtering process that is incorporated into the traditional texture advection pipeline. Our visualization methods allow for a continuous change of the density of flow representation by adapting the density of particle injection. All methods can be mapped to efficient GPU implementations. Therefore, the user can interactively control all important characteristics of the system like particle density, error influence, or dye injection to create meaningful illustrations of the underlying uncertainty. Even though there are many sources of uncertainties, we focus on uncertainty that occurs during data acquisition. We demonstrate the usefulness of our methods for the example of real-world fluid flow data measured with the particle image velocimetry (PIV) technique. Furthermore, we compare these techniques with an adapted multi-frequency noise approach.	Ralf P. Botchen;Daniel Weiskopf	Stuttgart Univ., Germany|c|;;	10.1109/VISUAL.1996.567784;10.1109/VISUAL.2000.885689;10.1109/VISUAL.1996.568116	Uncertainty visualization, unsteady flow visualization, texture advection, GPU programming	University of Stuttgart##University of Stuttgart##University of Stuttgart
Vis	2005	Example-based volume illustrations	10.1109/VISUAL.2005.1532854	http://dx.doi.org/10.1109/VISUAL.2005.1532854	655	662	C	Scientific illustrations use accepted conventions and methodologies to effectively convey object properties and improve our understanding. We present a method to illustrate volume datasets by emulating example illustrations. As with technical illustrations, our volume illustrations more clearly delineate objects, enrich details, and artistically visualize volume datasets. For both color and scalar 3D volumes, we have developed an automatic color transfer method based on the clustering and similarities in the example illustrations and volume sources. As an extension to 2D Wang tiles, we provide a new, general texture synthesis method for Wang cubes that solves the edge discontinuity problem. We have developed a 2D illustrative slice viewer and a GPU-based direct volume rendering system that uses these non-periodic 3D textures to generate illustrative results similar to the 2D examples. Both applications simulate scientific illustrations to provide more information than the original data and visualize objects more effectively, while only requiring simple user interaction.	Aidong Lu;David S. Ebert	Purdue Univ., West Lafayette, IN, USA|c|;	10.1109/VISUAL.2004.35;10.1109/VISUAL.2000.885694;10.1109/VISUAL.2003.1250386;10.1109/VISUAL.1999.809905	Volume Illustration, Example-based Rendering, Wang Cubes, Texture Synthesis, Color Transfer	Purdue University & UNC Charlotte##Purdue University & UNC Charlotte
Vis	2005	Illustrative display of hidden iso-surface structures	10.1109/VISUAL.2005.1532855	http://dx.doi.org/10.1109/VISUAL.2005.1532855	663	670	C	Indirect volume rendering is a widespread method for the display of volume datasets. It is based on the extraction of polygonal iso-surfaces from volumetric data, which are then rendered using conventional rasterization methods. Whereas this rendering approach is fast and relatively easy to implement, it cannot easily provide an understandable display of structures occluded by the directly visible iso-surface. Simple approaches like alpha-blending for transparency when drawing the iso-surface often generate a visually complex output, which is difficult to interpret. Moreover, such methods can significantly increase the computational complexity of the rendering process. In this paper, we therefore propose a new approach for the illustrative indirect rendering of volume data in real-time. This algorithm emphasizes the silhouette of objects represented by the iso-surface. Additionally, shading intensities on objects are reproduced with a monochrome hatching technique. Using a specially designed two-pass rendering process, structures behind the front layer of the iso-surface are automatically extracted with a depth peeling method. The shapes of these hidden structures are also displayed as silhouette outlines. As an additional option, the geometry of explicitly specified inner objects can be displayed with constant translucency. Although these inner objects always remain visible, a specific shading and depth attenuation method is used to convey the depth relationships. We describe the implementation of the algorithm, which exploits the programmability of state-of-the-art graphics processing units (GPUs). The algorithm described in this paper does not require any preprocessing of the input data or a manual definition of inner structures. Since the presented method works on iso-surfaces, which are stored as polygonal datasets, it can also be applied to other types of polygonal models.	Jan Fischer;Dirk Bartz;Wolfgang Straßer	Visual Comput. for Medicine, Tubingen Univ., Germany|c|;;	10.1109/VISUAL.2002.1183777;10.1109/VISUAL.2000.885694;10.1109/VISUAL.2003.1250387;10.1109/VISUAL.2000.885723;10.1109/VISUAL.2004.48	illustrative rendering, non-photorealistic rendering, transparency, indirect volume rendering, hatching, shading language	GRIS University of TÃ¼bingen##GRIS University of TÃ¼bingen##GRIS University of TÃ¼bingen
Vis	2005	VolumeShop: an interactive system for direct volume illustration	10.1109/VISUAL.2005.1532856	http://dx.doi.org/10.1109/VISUAL.2005.1532856	671	678	C	Illustrations play a major role in the education process. Whether used to teach a surgical or radiologic procedure, to illustrate normal or aberrant anatomy, or to explain the functioning of a technical device, illustration significantly impacts learning. Although many specimens are readily available as volumetric data sets, particularly in medicine, illustrations are commonly produced manually as static images in a time-consuming process. Our goal is to create a fully dynamic three-dimensional illustration environment which directly operates on volume data. Single images have the aesthetic appeal of traditional illustrations, but can be interactively altered and explored. In this paper we present methods to realize such a system which combines artistic visual styles and expressive visualization techniques. We introduce a novel concept for direct multi-object volume visualization which allows control of the appearance of inter-penetrating objects via two-dimensional transfer functions. Furthermore, a unifying approach to efficiently integrate many non-photorealistic rendering models is presented. We discuss several illustrative concepts which can be realized by combining cutaways, ghosting, and selective deformation. Finally, we also propose a simple interface to specify objects of interest through three-dimensional volumetric painting. All presented methods are integrated into VolumeShop, an interactive hardware-accelerated application for direct volume illustration.	Stefan Bruckner;Eduard Gröller	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria|c|;	10.1109/VISUAL.2000.885694;10.1109/VISUAL.2002.1183777;10.1109/VISUAL.2004.62;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2004.48;10.1109/VISUAL.2004.64	illustrative visualization, volume rendering, focus+context techniques	Vienna University of Technology##Vienna University of Technology
Vis	2005	Illustration-inspired techniques for visualizing time-varying data	10.1109/VISUAL.2005.1532857	http://dx.doi.org/10.1109/VISUAL.2005.1532857	679	686	C	Traditionally, time-varying data has been visualized using snapshots of the individual time steps or an animation of the snapshots shown in a sequential manner. For larger datasets with many time-varying features, animation can be limited in its use, as an observer can only track a limited number of features over the last few frames. Visually inspecting each snapshot is not practical either for a large number of time-steps. We propose new techniques inspired from the illustration literature to convey change over time more effectively in a time-varying dataset. Speedlines are used extensively by cartoonists to convey motion, speed, or change over different panels. Flow ribbons are another technique used by cartoonists to depict motion in a single frame. Strobe silhouettes are used to depict previous positions of an object to convey the previous positions of the object to the user. These illustration-inspired techniques can be used in conjunction with animation to convey change over time.	Alark Joshi;Penny Rheingans	Maryland Univ., Baltimore, MD, USA|c|;	10.1109/VISUAL.2001.964520;10.1109/VISUAL.1999.809910;10.1109/VISUAL.1994.346321;10.1109/VISUAL.1996.567807;10.1109/VISUAL.1999.809879;10.1109/VISUAL.2005.1532858;10.1109/VISUAL.2002.1183777;10.1109/VISUAL.2000.885694;10.1109/VISUAL.2003.1250386	Flow visualization, Non-photorealistic rendering, time-varying data, illustration	University of Maryland Baltimore County##University of Maryland Baltimore County
Vis	2005	Illustration and photography inspired visualization of flows and volumes	10.1109/VISUAL.2005.1532858	http://dx.doi.org/10.1109/VISUAL.2005.1532858	687	694	C	Understanding and analyzing complex volumetrically varying data is a difficult problem. Many computational visualization techniques have had only limited success in succinctly portraying the structure of three-dimensional turbulent flow. Motivated by both the extensive history and success of illustration and photographic flow visualization techniques, we have developed a new interactive volume rendering and visualization system for flows and volumes that simulates and enhances traditional illustration, experimental advection, and photographic flow visualization techniques. Our system uses a combination of varying focal and contextual illustrative styles, new advanced two-dimensional transfer functions, enhanced Schlieren and shadowgraphy shaders, and novel oriented structure enhancement techniques to allow interactive visualization, exploration, and comparative analysis of scalar, vector, and time-varying volume datasets. Both traditional illustration techniques and photographic flow visualization techniques effectively reduce visual clutter by using compact oriented structure information to convey three-dimensional structures. Therefore, a key to the effectiveness of our system is using one-dimensional (Schlieren and shadowgraphy) and two-dimensional (silhouette) oriented structural information to reduce visual clutter, while still providing enough three-dimensional structural information for the user's visual system to understand complex three-dimensional flow data. By combining these oriented feature visualization techniques with flexible transfer function controls, we can visualize scalar and vector data, allow comparative visualization of flow properties in a succinct, informative manner, and provide continuity for visualizing time-varying datasets.	Nikolai A. Svakhine;Yun Jang;David S. Ebert;Kelly P. Gaither	Purdue Univ., West Lafayette, IN, USA|c|;;;	10.1109/VISUAL.1995.485141;10.1109/VISUAL.1993.398846;10.1109/VISUAL.2003.1250378;10.1109/VISUAL.1996.567777;10.1109/VISUAL.1997.663912;10.1109/VISUAL.2003.1250361;10.1109/VISUAL.1999.809905;10.1109/VISUAL.2000.885694;10.1109/VISUAL.2000.885689;10.1109/VISUAL.2005.1532857;10.1109/VISUAL.2000.885696;10.1109/VISUAL.1993.398877	interactive volume illustration, flow visualization, non-photorealistic rendering, photographic techniques	Purdue University##Purdue University##Purdue University##Purdue University
Vis	2005	Visualization with stylized line primitives	10.1109/VISUAL.2005.1532859	http://dx.doi.org/10.1109/VISUAL.2005.1532859	695	702	C	Line primitives are a very powerful visual attribute used for scientific visualization and in particular for 3D vector-field visualization. We extend the basic line primitives with additional visual attributes including color, line width, texture and orientation. To implement the visual attributes we represent the stylized line primitives as generalized cylinders. One important contribution of our work is an efficient rendering algorithm for stylized lines, which is hybrid in the sense that it uses both CPU and GPU based rendering. We improve the depth perception with a shadow algorithm. We present several applications for the visualization with stylized lines among which are the visualizations of 3D vector fields and molecular structures.	Carsten Stoll;Stefan Gumhold;Hans-Peter Seidel	Max-Planck-Inst. fur Inf., Saarbrucken, Germany|c|;;	10.1109/VISUAL.2004.5;10.1109/VISUAL.1996.567777;10.1109/VISUAL.1998.745317	 rendering, vector fields, streamlines	
InfoVis	2006	ASK-graphView: a large scale graph visualization system	10.1109/TVCG.2006.120	http://dx.doi.org/10.1109/TVCG.2006.120	669	676	J	We describe ASK-GraphView, a node-link-based graph visualization system that allows clustering and interactive navigation of large graphs, ranging in size up to 16 million edges. The system uses a scalable architecture and a series of increasingly sophisticated clustering algorithms to construct a hierarchy on an arbitrary, weighted undirected input graph. By lowering the interactivity requirements we can scale to substantially bigger graphs. The user is allowed to navigate this hierarchy in a top down manner by interactively expanding individual clusters. ASK-GraphView also provides facilities for filtering and coloring, annotation and cluster labeling	James Abello;Frank van Ham;Neeraj Krishnan	Rutgers Univ., New Brunswick, NJ|c|;;	10.1109/INFVIS.2004.46;10.1109/INFVIS.2005.1532127;10.1109/INFVIS.2004.66;10.1109/INFVIS.1997.636718;10.1109/INFVIS.2004.43	Information visualization, graph visualization, graph clustering	
InfoVis	2006	Balancing Systematic and Flexible Exploration of Social Networks	10.1109/TVCG.2006.122	http://dx.doi.org/10.1109/TVCG.2006.122	693	700	J	Social network analysis (SNA) has emerged as a powerful method for understanding the importance of relationships in networks. However, interactive exploration of networks is currently challenging because: (1) it is difficult to find patterns and comprehend the structure of networks with many nodes and links, and (2) current systems are often a medley of statistical methods and overwhelming visual output which leaves many analysts uncertain about how to explore in an orderly manner. This results in exploration that is largely opportunistic. Our contributions are techniques to help structural analysts understand social networks more effectively. We present SocialAction, a system that uses attribute ranking and coordinated views to help users systematically examine numerous SNA measures. Users can (1) flexibly iterate through visualizations of measures to gain an overview, filter nodes, and find outliers, (2) aggregate networks using link structure, find cohesive subgroups, and focus on communities of interest, and (3) untangle networks by viewing different link types separately, or find patterns across different link types using a matrix overview. For each operation, a stable node layout is maintained in the network visualization so users can make comparisons. SocialAction offers analysts a strategy beyond opportunism, as it provides systematic, yet flexible, techniques for exploring social networks	Adam Perer;Ben Shneiderman	Dept. of Comput. Sci., Maryland Univ., College Park, MD|c|;	10.1109/INFVIS.2003.1249011;10.1109/INFVIS.2004.43;10.1109/INFVIS.2004.1;10.1109/VAST.2006.261426;10.1109/INFVIS.1997.636718;10.1109/INFVIS.2004.66;10.1109/INFVIS.2005.1532126	Social networks, interactive graph visualization, attribute ranking, coordinated views, exploratory data analysis	
InfoVis	2006	Complex Logarithmic Views for Small Details in Large Contexts	10.1109/TVCG.2006.126	http://dx.doi.org/10.1109/TVCG.2006.126	845	852	J	Commonly known detail in context techniques for the two-dimensional Euclidean space enlarge details and shrink their context using mapping functions that introduce geometrical compression. This makes it difficult or even impossible to recognize shapes for large differences in magnification factors. In this paper we propose to use the complex logarithm and the complex root functions to show very small details even in very large contexts. These mappings are conformal, which means they only locally rotate and scale, thus keeping shapes intact and recognizable. They allow showing details that are orders of magnitude smaller than their surroundings in combination with their context in one seamless visualization. We address the utilization of this universal technique for the interaction with complex two-dimensional data considering the exploration of large graphs and other examples	Joachim Böttger;Michael Balzer;Oliver Deussen	Dept. of Comput. & Inf. Sci., Konstanz Univ.|c|;;	10.1109/INFVIS.1997.636786;10.1109/INFVIS.2005.1532128;10.1109/INFVIS.1996.559214	Detail in context, complex logarithm, conformal mappings, analytic functions, interaction	
InfoVis	2006	Dynamic Map Labeling	10.1109/TVCG.2006.136	http://dx.doi.org/10.1109/TVCG.2006.136	773	780	J	We address the problem of filtering, selecting and placing labels on a dynamic map, which is characterized by continuous zooming and panning capabilities. This consists of two interrelated issues. The first is to avoid label popping and other artifacts that cause confusion and interrupt navigation, and the second is to label at interactive speed. In most formulations the static map labeling problem is NP-hard, and a fast approximation might have O(n log n) complexity. Even this is too slow during interaction, when the number of labels shown can be several orders of magnitude less than the number in the map. In this paper we introduce a set of desiderata for "consistent" dynamic map labeling, which has qualities desirable for navigation. We develop a new framework for dynamic labeling that achieves the desiderata and allows for fast interactive display by moving all of the selection and placement decisions into the preprocessing phase. This framework is general enough to accommodate a variety of selection and placement algorithms. It does not appear possible to achieve our desiderata using previous frameworks. Prior to this paper, there were no formal models of dynamic maps or of dynamic labels; our paper introduces both. We formulate a general optimization problem for dynamic map labeling and give a solution to a simple version of the problem. The simple version is based on label priorities and a versatile and intuitive class of dynamic label placements we call "invariant point placements". Despite these restrictions, our approach gives a useful and practical solution. Our implementation is incorporated into the G-Vis system which is a full-detail dynamic map of the continental USA. This demo is available through any browser	Ken Been;Eli Daiches;Chee-Keng Yap	Yeshiva Univ.|c|;;		Map labeling, dynamic maps, human-computer interface, label placement, label selection, label filtering, label consistency,computational cartography, GIS, HCI, realtime, preprocessing	
InfoVis	2006	Enabling Automatic Clutter Reduction in Parallel Coordinate Plots	10.1109/TVCG.2006.138	http://dx.doi.org/10.1109/TVCG.2006.138	717	724	J	We have previously shown that random sampling is an effective clutter reduction technique and that a sampling lens can facilitate focus+context viewing of particular regions. This demands an efficient method of estimating the overlap or occlusion of large numbers of intersecting lines in order to automatically adjust the sampling rate within the lens. This paper proposes several ways for measuring occlusion in parallel coordinate plots. An empirical study into the accuracy and efficiency of the occlusion measures show that a probabilistic approach combined with a 'binning' technique is very fast and yet approaches the accuracy of the more expensive 'true' complete measurement	Geoffrey P. Ellis;Alan J. Dix	Lancaster Univ.|c|;	10.1109/VISUAL.2004.5;10.1109/VISUAL.2005.1532819;10.1109/INFVIS.2004.64;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2004.15	Sampling, random sampling, lens, clutter, occlusion, density reduction, overplotting, information visualisation, parallel coordinates 	
InfoVis	2006	FacetMap: A Scalable Search and Browse Visualization	10.1109/TVCG.2006.142	http://dx.doi.org/10.1109/TVCG.2006.142	797	804	J	The dominant paradigm for searching and browsing large data stores is text-based: presenting a scrollable list of search results in response to textual search term input. While this works well for the Web, there is opportunity for improvement in the domain of personal information stores, which tend to have more heterogeneous data and richer metadata. In this paper, we introduce FacetMap, an interactive, query-driven visualization, generalizable to a wide range of metadata-rich data stores. FacetMap uses a visual metaphor for both input (selection of metadata facets as filters) and output. Results of a user study provide insight into tradeoffs between FacetMap's graphical approach and the traditional text-oriented approach	Greg Smith;Mary Czerwinski;Brian Meyers;Daniel C. Robbins;George G. Robertson;Desney S. Tan	;;;;	10.1109/INFVIS.1998.729570;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2002.1173156;10.1109/INFVIS.1995.528685;10.1109/VISUAL.1991.175815	Graphical visualization, interactive information retrieval, faceted metadata	
InfoVis	2006	Hierarchical Edge Bundles: Visualization of Adjacency Relations in Hierarchical Data	10.1109/TVCG.2006.147	http://dx.doi.org/10.1109/TVCG.2006.147	741	748	J	A compound graph is a frequently encountered type of data set. Relations are given between items, and a hierarchy is defined on the items as well. We present a new method for visualizing such compound graphs. Our approach is based on visually bundling the adjacency edges, i.e., non-hierarchical edges, together. We realize this as follows. We assume that the hierarchy is shown via a standard tree visualization method. Next, we bend each adjacency edge, modeled as a B-spline curve, toward the polyline defined by the path via the inclusion edges from one node to another. This hierarchical bundling reduces visual clutter and also visualizes implicit adjacency edges between parent nodes that are the result of explicit adjacency edges between their respective child nodes. Furthermore, hierarchical edge bundling is a generic method which can be used in conjunction with existing tree visualization techniques. We illustrate our technique by providing example visualizations and discuss the results based on an informal evaluation provided by potential users of such visualizations	Danny Holten	Technische Univ. Eindhoven|c|	10.1109/INFVIS.2004.1;10.1109/INFVIS.2003.1249008;10.1109/INFVIS.2005.1532150;10.1109/INFVIS.2003.1249030;10.1109/INFVIS.2005.1532129;10.1109/INFVIS.1997.636718;10.1109/INFVIS.2002.1173152	Network visualization, edge bundling, edge aggregation, edge concentration, curves, graph visualization, tree visualization, node-link diagrams, hierarchies, treemaps	
InfoVis	2006	IPSep-CoLa: An Incremental Procedure for Separation Constraint Layout of Graphs	10.1109/TVCG.2006.156	http://dx.doi.org/10.1109/TVCG.2006.156	821	828	J	Existing information-visualization techniques that target small screens are usually limited to exploring a few hundred items. In this article we present a scatterplot tool for personal digital assistants that allows the handling of many thousands of items. The application's scalability is achieved by incorporating two alternative interaction techniques: a geometric-semantic zoom that provides smooth transition between overview and detail, and a fisheye distortion that displays the focus and context regions of the scatterplot in a single view. A user study with 24 participants was conducted to compare the usability and efficiency of both techniques when searching a book database containing 7500 items. The study was run on a pen-driven Wacom board simulating a PDA interface. While the results showed no significant difference in task-completion times, a clear majority of 20 users preferred the fisheye view over the zoom interaction. In addition, other dependent variables such as user satisfaction and subjective rating of orientation and navigation support revealed a preference for the fisheye distortion. These findings partly contradict related research and indicate that, when using a small screen, users place higher value on the ability to preserve navigational context than they do on the ease of use of a simplistic, metaphor-based interaction style	Tim Dwyer;Yehuda Koren;Kim Marriott	Konstanz Univ.|c|;;	10.1109/INFVIS.2005.1532130	Graph drawing, constraints, stress majorization, force directed algorithms,multidimensional scaling	
InfoVis	2006	MatrixExplorer: a Dual-Representation System to Explore Social Networks	10.1109/TVCG.2006.160	http://dx.doi.org/10.1109/TVCG.2006.160	677	684	J	MatrixExplorer is a network visualization system that uses two representations: node-link diagrams and matrices. Its design comes from a list of requirements formalized after several interviews and a participatory design session conducted with social science researchers. Although matrices are commonly used in social networks analysis, very few systems support the matrix-based representations to visualize and analyze networks. MatrixExplorer provides several novel features to support the exploration of social networks with a matrix-based representation, in addition to the standard interactive filtering and clustering functions. It provides tools to reorder (layout) matrices, to annotate and compare findings across different layouts and find consensus among several clusterings. MatrixExplorer also supports node-link diagram views which are familiar to most users and remain a convenient way to publish or communicate exploration results. Matrix and node-link representations are kept synchronized at all stages of the exploration process	Nathalie Henry Riche;Jean-Daniel Fekete	LRI|c|;	10.1109/INFVIS.2004.64	social networks visualization, node-link diagrams, matrix-based representations, exploratory process, matrix ordering, interactive clustering, consensus	
InfoVis	2006	Measuring Data Abstraction Quality in Multiresolution Visualizations	10.1109/TVCG.2006.161	http://dx.doi.org/10.1109/TVCG.2006.161	709	716	J	Data abstraction techniques are widely used in multiresolution visualization systems to reduce visual clutter and facilitate analysis from overview to detail. However, analysts are usually unaware of how well the abstracted data represent the original dataset, which can impact the reliability of results gleaned from the abstractions. In this paper, we define two data abstraction quality measures for computing the degree to which the abstraction conveys the original dataset: the histogram difference measure and the nearest neighbor measure. They have been integrated within XmdvTool, a public-domain multiresolution visualization system for multivariate data analysis that supports sampling as well as clustering to simplify data. Several interactive operations are provided, including adjusting the data abstraction level, changing selected regions, and setting the acceptable data abstraction quality level. Conducting these operations, analysts can select an optimal data abstraction level. Also, analysts can compare different abstraction methods using the measures to see how well relative data density and outliers are maintained, and then select an abstraction method that meets the requirement of their analytic tasks	Qingguang Cui;Matthew O. Ward;Elke A. Rundensteiner;Jing Yang 0001	Worcester Polytech. Inst., MA|c|;;;	10.1109/INFVIS.2004.19;10.1109/VISUAL.2005.1532819;10.1109/INFVIS.2004.15;10.1109/VISUAL.1995.485139;10.1109/INFVIS.2000.885088	Metrics, Clustering, Sampling, Multiresolution Visualization	
InfoVis	2006	Multi-Scale Banking to 45 Degrees	10.1109/TVCG.2006.163	http://dx.doi.org/10.1109/TVCG.2006.163	701	708	J	In his text Visualizing Data, William Cleveland demonstrates how the aspect ratio of a line chart can affect an analyst's perception of trends in the data. Cleveland proposes an optimization technique for computing the aspect ratio such that the average absolute orientation of line segments in the chart is equal to 45 degrees. This technique, called banking to 45deg, is designed to maximize the discriminability of the orientations of the line segments in the chart. In this paper, we revisit this classic result and describe two new extensions. First, we propose alternate optimization criteria designed to further improve the visual perception of line segment orientations. Second, we develop multi-scale banking, a technique that combines spectral analysis with banking to 45deg. Our technique automatically identifies trends at various frequency scales and then generates a banked chart for each of these scales. We demonstrate the utility of our techniques in a range of visualization tools and analysis examples	Jeffrey Heer;Maneesh Agrawala	Comput. Sci. Div., California Univ., Berkeley, CA|c|;		Information visualization, banking to 45 degrees, line charts, time-series, sparklines, graphical perception	
InfoVis	2006	Network Visualization by Semantic Substrates	10.1109/TVCG.2006.166	http://dx.doi.org/10.1109/TVCG.2006.166	733	740	J	Networks have remained a challenge for information visualization designers because of the complex issues of node and link layout coupled with the rich set of tasks that users present. This paper offers a strategy based on two principles: (1) layouts are based on user-defined semantic substrates, which are non-overlapping regions in which node placement is based on node attributes, (2) users interactively adjust sliders to control link visibility to limit clutter and thus ensure comprehensibility of source and destination. Scalability is further facilitated by user control of which nodes are visible. We illustrate our semantic substrates approach as implemented in NVSS 1.0 with legal precedent data for up to 1122 court cases in three regions with 7645 legal citations	Ben Shneiderman;Aleks Aris	Dept. of Comput. Sci., Maryland Univ., College Park, MD|c|;	10.1109/INFVIS.2004.1;10.1109/INFVIS.2005.1532124;10.1109/INFVIS.2005.1532126	Network visualization, semantic substrate, information visualization, graphical user interfaces	
InfoVis	2006	Smashing Peacocks Further: Drawing Quasi-Trees from Biconnected Components	10.1109/TVCG.2006.177	http://dx.doi.org/10.1109/TVCG.2006.177	813	820	J	Quasi-trees, namely graphs with tree-like structure, appear in many application domains, including bioinformatics and computer networks. Our new SPF approach exploits the structure of these graphs with a two-level approach to drawing, where the graph is decomposed into a tree of biconnected components. The low-level biconnected components are drawn with a force-directed approach that uses a spanning tree skeleton as a starting point for the layout. The higher-level structure of the graph is a true tree with meta-nodes of variable size that contain each biconnected component. That tree is drawn with a new area-aware variant of a tree drawing algorithm that handles high-degree nodes gracefully, at the cost of allowing edge-node overlaps. SPF performs an order of magnitude faster than the best previous approaches, while producing drawings of commensurate or improved quality.	Daniel Archambault;Tamara Munzner;David Auber	University of British Columbia|c|;;	10.1109/INFVIS.1997.636718	Graph and network visualization, quasi-tree	
InfoVis	2006	Software Design Patterns for Information Visualization	10.1109/TVCG.2006.178	http://dx.doi.org/10.1109/TVCG.2006.178	853	860	J	Despite a diversity of software architectures supporting information visualization, it is often difficult to identify, evaluate, and re-apply the design solutions implemented within such frameworks. One popular and effective approach for addressing such difficulties is to capture successful solutions in design patterns, abstract descriptions of interacting software components that can be customized to solve design problems within a particular context. Based upon a review of existing frameworks and our own experiences building visualization software, we present a series of design patterns for the domain of information visualization. We discuss the structure, context of use, and interrelations of patterns spanning data representation, graphics, and interaction. By representing design knowledge in a reusable form, these patterns can be used to facilitate software design, implementation, and evaluation, and improve developer education and communication	Jeffrey Heer;Maneesh Agrawala	Comput. Sci. Div., California Univ., Berkeley, CA|c|;	10.1109/INFVIS.1998.729560;10.1109/INFVIS.2002.1173141;10.1109/INFVIS.2003.1249007;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2004.12;10.1109/INFVIS.2004.64	Design patterns, information visualization, software engineering, object-oriented programming	
InfoVis	2006	Spatial Analysis of News Sources	10.1109/TVCG.2006.179	http://dx.doi.org/10.1109/TVCG.2006.179	765	772	J	People in different places talk about different things. This interest distribution is reflected by the newspaper articles circulated in a particular area. We use data from our large-scale newspaper analysis system (Lydia) to make entity datamaps, a spatial visualization of the interest in a given named entity. Our goal is to identify entities which display regional biases. We develop a model of estimating the frequency of reference of an entity in any given city from the reference frequency centered in surrounding cities, and techniques for evaluating the spatial significance of this distribution	Andrew Mehler;Yunfan Bao;Xin Li 0003;Yue Wang;Steven Skiena	Dept. of Comput. Sci., Stony Brook Univ.|c|;;;;		GIS, geographic visualization, text and document visualization, information analytics, WWW data visualization, spidering, newspapers	
InfoVis	2006	The Perceptual Scalability of Visualization	10.1109/TVCG.2006.184	http://dx.doi.org/10.1109/TVCG.2006.184	837	844	J	Larger, higher resolution displays can be used to increase the scalability of information visualizations. But just how much can scalability increase using larger displays before hitting human perceptual or cognitive limits? Are the same visualization techniques that are good on a single monitor also the techniques that are best when they are scaled up using large, high-resolution displays? To answer these questions we performed a controlled experiment on user performance time, accuracy, and subjective workload when scaling up data quantity with different space-time-attribute visualizations using a large, tiled display. Twelve college students used small multiples, embedded bar matrices, and embedded time-series graphs either on a 2 megapixel (Mp) display or with data scaled up using a 32 Mp tiled display. Participants performed various overview and detail tasks on geospatially-referenced multidimensional time-series data. Results showed that current designs are perceptually scalable because they result in a decrease in task completion time when normalized per number of data attributes along with no decrease in accuracy. It appears that, for the visualizations selected for this study, the relative comparison between designs is generally consistent between display sizes. However, results also suggest that encoding is more important on a smaller display while spatial grouping is more important on a larger display. Some suggestions for designers are provided based on our experience designing visualizations for large displays.	Beth Yost;Chris North	IEEE|c|;	10.1109/INFVIS.2002.1173156	Information visualization, large displays, empirical evaluation	
InfoVis	2006	Topographic Visualization of Prefix Propagation in the Internet	10.1109/TVCG.2006.185	http://dx.doi.org/10.1109/TVCG.2006.185	725	732	J	We propose a new metaphor for the visualization of prefixes propagation in the Internet. Such a metaphor is based on the concept of topographic map and allows to put in evidence the relative importance of the Internet Service Providers (ISPs) involved in the routing of the prefix. Based on the new metaphor we propose an algorithm for computing layouts and experiment with such algorithm on a test suite taken from the real Internet. The paper extends the visualization approach of the BGPlay service, which is an Internet routing monitoring tool widely used by ISP operators	Pier Francesco Cortese;Giuseppe Di Battista;Antonello Moneta;Maurizio Patrignani;Maurizio Pizzonia	Dipt. di Informatica e Automazione, Rome Univ.|c|;;;;	10.1109/INFVIS.2004.18;10.1109/INFVIS.2001.963279;10.1109/INFVIS.2002.1173160	Interdomain Routing, Internet Visualization, Graph Drawing, Spring Embedder	
InfoVis	2006	User Interaction with Scatterplots on Small Screens - A Comparative Evaluation of Geometric-Semantic Zoom and Fisheye Distortion	10.1109/TVCG.2006.187	http://dx.doi.org/10.1109/TVCG.2006.187	829	836	J	Existing information-visualization techniques that target small screens are usually limited to exploring a few hundred items. In this article we present a scatterplot tool for Personal Digital Assistants that allows the handling of many thousands of items. The application's scalability is achieved by incorporating two alternative interaction techniques: a geometric-semantic zoom that provides smooth transition between overview and detail, and a fisheye distortion that displays the focus and context regions of the scatterplot in a single view. A user study with 24 participants was conducted to compare the usability and efficiency of both techniques when searching a book database containing 7500 items. The study was run on a pen-driven Wacom board simulating a PDA interface. While the results showed no significant difference in task-completion times, a clear majority of 20 users preferred the fisheye view over the zoom interaction. In addition, other dependent variables such as user satisfaction and subjective rating of orientation and navigation support revealed a preference for the fisheye distortion. These findings partly contradict related research and indicate that, when using a small screen, users place higher value on the ability to preserve navigational context than they do on the ease of use of a simplistic, metaphor-based interaction style. 	Thorsten Büring;Jens Gerken;Harald Reiterer	University of Konstanz, Germany	10.1109/INFVIS.1999.801854;10.1109/INFVIS.2002.1173156	Small screen, PDA, scatterplot, zoom, fisheye, focus+context	
InfoVis	2006	Visual Analysis of Multivariate State Transition Graphs	10.1109/TVCG.2006.192	http://dx.doi.org/10.1109/TVCG.2006.192	685	692	J	We present a new approach for the visual analysis of state transition graphs. We deal with multivariate graphs where a number of attributes are associated with every node. Our method provides an interactive attribute-based clustering facility. Clustering results in metric, hierarchical and relational data, represented in a single visualization. To visualize hierarchically structured quantitative data, we introduce a novel technique: the bar tree. We combine this with a node-link diagram to visualize the hierarchy and an arc diagram to visualize relational data. Our method enables the user to gain significant insight into large state transition graphs containing tens of thousands of nodes. We illustrate the effectiveness of our approach by applying it to a real-world use case. The graph we consider models the behavior of an industrial wafer stepper and contains 55 043 nodes and 289 443 edges	A. Johannes Pretorius;Jarke J. van Wijk	Dept. of Math. & Comput. Sci., Technische Univ. Eindhoven|c|;	10.1109/INFVIS.2002.1173153;10.1109/INFVIS.2002.1173155;10.1109/VISUAL.1991.175796;10.1109/VISUAL.2002.1183778;10.1109/INFVIS.2003.1249028	Graph visualization, multivariate visualization, interactive clustering, state spaces, transition systems, finite state machines	
InfoVis	2006	Visual Exploration of Complex Time-Varying Graphs	10.1109/TVCG.2006.193	http://dx.doi.org/10.1109/TVCG.2006.193	805	812	J	Many graph drawing and visualization algorithms, such as force-directed layout and line-dot rendering, work very well on relatively small and sparse graphs. However, they often produce extremely tangled results and exhibit impractical running times for highly non-planar graphs with large edge density. And very few graph layout algorithms support dynamic time-varying graphs; applying them independently to each frame produces distracting temporally incoherent visualizations. We have developed a new visualization technique based on a novel approach to hierarchically structuring dense graphs via stratification. Using this structure, we formulate a hierarchical force-directed layout algorithm that is both efficient and produces quality graph layouts. The stratification of the graph also allows us to present views of the data that abstract away many small details of its structure. Rather than displaying all edges and nodes at once, resulting in a convoluted rendering, we present an interactive tool that filters edges and nodes using the graph hierarchy and allows users to drill down into the graph for details. Our layout algorithm also accommodates time-varying graphs in a natural way,  producing a temporally coherent animation that can be used to analyze and extract trends from dynamic graph data. For example, we demonstrate the use of our method to explore financial correlation data for the U.S. stock market in the period from 1990 to 2005. The user can easily analyze the time-varying correlation graph of the market, uncovering information such as market sector trends, representative stocks for portfolio construction, and the interrelationship of stocks over time.	Gautam Kumar;Michael Garland	British Columbia Univ., Vancouver, BC|c|;;	10.1109/INFVIS.2004.43;10.1109/INFVIS.2004.66	Graph and network visualization, financial data visualization, hierarchy visualization, time series data	
InfoVis	2006	Visualization of Barrier Tree Sequences	10.1109/TVCG.2006.196	http://dx.doi.org/10.1109/TVCG.2006.196	781	788	J	Dynamical models that explain the formation of spatial structures of RNA molecules have reached a complexity that requires novel visualization methods that help to analyze the validity of these models. We focus on the visualization of so-called folding landscapes of a growing RNA molecule. Folding landscapes describe the energy of a molecule as a function of its spatial configuration; thus they are huge and high dimensional. Their most salient features, however, are encapsulated by their so-called barrier tree that reflects the local minima and their connecting saddle points. For each length of the growing RNA chain there exists a folding landscape. We visualize the sequence of folding landscapes by an animation of the corresponding barrier trees. To generate the animation, we adapt the foresight layout with tolerance algorithm for general dynamic graph layout problems. Since it is very general, we give a detailed description of each phase: constructing a supergraph for the trees, layout of that supergraph using a modified DOT algorithm, and presentation techniques for the final animation	Christian Heine 0002;Gerik Scheuermann;Christoph Flamm;Ivo L. Hofacker;Peter F. Stadler	Dept. of Comput. Sci., Leipzig Univ.|c|;;;;	10.1109/INFVIS.2004.18	Graph drawing, dynamic graph, RNA folding, energy landscape, fitness landscape, barrier tree	
InfoVis	2006	Visualization of Geo-spatial Point Sets via Global Shape Transformation and Local Pixel Placement	10.1109/TVCG.2006.198	http://dx.doi.org/10.1109/TVCG.2006.198	749	756	J	In many applications, data is collected and indexed by geo-spatial location. Discovering interesting patterns through visualization is an important way of gaining insight about such data. A previously proposed approach is to apply local placement functions such as PixelMaps that transform the input data set into a solution set that preserves certain constraints while making interesting patterns more obvious and avoid data loss from overplotting. In experience, this family of spatial transformations can reveal fine structures in large point sets, but it is sometimes difficult to relate those structures to basic geographic features such as cities and regional boundaries. Recent information visualization research has addressed other types of transformation functions that make spatially-transformed maps with recognizable shapes. These types of spatial-transformation are called global shape functions. In particular, cartogram-based map distortion has been studied. On the other hand, cartogram-based distortion does not handle point sets readily. In this study, we present a framework that allows the user to specify a global shape function and a local placement function. We combine cartogram-based layout (global shape) with PixelMaps (local placement), obtaining some of the benefits of each toward improved exploration of dense geo-spatial data sets	Christian Panse;Mike Sips;Daniel A. Keim;Stephen C. North	Eidgenossische Tech. Hochschule, Zurich|c|;;;	10.1109/VISUAL.1998.745303;10.1109/INFVIS.2004.57;10.1109/VISUAL.2003.1250410	Geo-spatial Data, Shape Transformation, Cartogram, Pixel Visualization	
InfoVis	2006	Visualizing Business Data with Generalized Treemaps	10.1109/TVCG.2006.200	http://dx.doi.org/10.1109/TVCG.2006.200	789	796	J	Business data is often presented using simple business graphics. These familiar visualizations are effective for providing overviews, but fall short for the presentation of large amounts of detailed information. Treemaps can provide such detail, but are often not easy to understand. We present how standard treemap algorithms can be adapted such that the results mimic familiar business graphics. Specifically, we present the use of different layout algorithms per level, a number of variations of the squarified algorithm, the use of variable borders, and the use of non-rectangular shapes. The combined use of these leads to histograms, pie charts and a variety of other styles	Roel Vliegen;Jarke J. van Wijk;Erik-Jan van der Linden	MagnaView|c|;;	10.1109/VISUAL.2005.1532781;10.1109/INFVIS.2001.963290;10.1109/VISUAL.1991.175815;10.1109/INFVIS.2005.1532125;10.1109/INFVIS.1999.801859	Information visualization, treemap, business graphics, hierarchical data	
InfoVis	2006	Worldmapper: The World as You've Never Seen it Before	10.1109/TVCG.2006.202	http://dx.doi.org/10.1109/TVCG.2006.202	757	764	J	This paper describes the Worldmapper project, which makes use of novel visualization techniques to represent a broad variety of social and economic data about the countries of the world. The goal of the project is to use the map projections known as cartograms to depict comparisons and relations between different territories, and its execution raises many interesting design challenges that were not all apparent at the outset. We discuss the approaches taken towards these challenges, some of which may have considerably broad application. We conclude by commenting on the positive initial response to the Worldmapper images published on the Web, which we believe is due, at least in part, to the particular effectiveness of the cartogram as a tool for communicating quantitative geographic data	Danny Dorling;Anna Barford;Mark Newman	Univ. of Sheffield|c|;;		Geographic Visualization, Computer Graphics, Worldmapper, Data Visualization, Social Visualization, Cartogram	
VAST	2006	Collaborative Visual Analytics: Inferring from the Spatial Organization and Collaborative Use of Information	10.1109/VAST.2006.261415	http://dx.doi.org/10.1109/VAST.2006.261415	137	144	C	We introduce a visual analytics environment for the support of remote-collaborative sense-making activities. Team members use their individual graphical interfaces to collect, organize and comprehend task-relevant information relative to their areas of expertise. A system of computational agents infers possible relationships among information items through the analysis of the spatial and temporal organization and collaborative use of information. The computational agents support the exchange of information among team members to converge their individual contributions. Our system allows users to navigate vast amounts of shared information effectively and remotely dispersed team members to work independently without diverting from common objectives as well as to minimize the necessary amount of verbal communication	Paul E. Keel	Comput. Sci. & Artificial Intelligence Lab., Massachusetts Inst. of Technol.|c|		Visual analytics, Spatial information organization, Indirect human computer interaction, Indirect collaboration, Agents, Sense-making	
VAST	2006	Beyond Usability: Evaluation Aspects of Visual Analytic Environments	10.1109/VAST.2006.261416	http://dx.doi.org/10.1109/VAST.2006.261416	145	150	C	A new field of research, visual analytics, has been introduced. This has been defined as "the science of analytical reasoning facilitated by interactive visual interfaces" (Thomas and Cook, 2005). Visual analytic environments, therefore, support analytical reasoning using visual representations and interactions, with data representations and transformation capabilities, to support production, presentation, and dissemination. As researchers begin to develop visual analytic environments, it is advantageous to develop metrics and methodologies to help researchers measure the progress of their work and understand the impact their work has on the users who work in such environments. This paper presents five areas or aspects of visual analytic environments that should be considered as metrics and methodologies for evaluation are developed. Evaluation aspects need to include usability, but it is necessary to go beyond basic usability. The areas of situation awareness, collaboration, interaction, creativity, and utility are proposed as the five evaluation areas for initial consideration. The steps that need to be undertaken to develop systematic evaluation methodologies and metrics for visual analytic environments are outlined	Jean Scholtz	Pacific Northwest Nat. Lab., Richland, WA|c|	10.1109/VISUAL.1990.146375;10.1109/INFVIS.2004.10;10.1109/INFVIS.1997.636794	visualization, analytic environments, metrics	
VAST	2006	Visualizing the Performance of Computational Linguistics Algorithms	10.1109/VAST.2006.261417	http://dx.doi.org/10.1109/VAST.2006.261417	151	157	C	We have built a visualization system and analysis portal for evaluating the performance of computational linguistics algorithms. Our system focuses on algorithms that classify and cluster documents by assigning weights to words and scoring each document against high dimensional reference concept vectors. The visualization and algorithm analysis techniques include confusion matrices, ROC curves, document visualizations showing word importance, and interactive reports. One of the unique aspects of our system is that the visualizations are thin-client Web-based components built using SVG visualization components	Stephen G. Eick;Justin Mauger;Alan Ratner	SSS Res., Inc., Naperville, IL|c|;;		AJAX, thin-client, SVG, ROC curves, confusion matrices, document categorization	
VAST	2006	Scentindex: Conceptually Reorganizing Subject Indexes for Reading	10.1109/VAST.2006.261418	http://dx.doi.org/10.1109/VAST.2006.261418	159	166	C	A great deal of analytical work is done in the context of reading, in digesting the semantics of the material, the identification of important entities, and capturing the relationship between entities. Visual analytic environments, therefore, must encompass reading tools that enable the rapid digestion of large amount of reading material. Other than plain text search, subject indexes, and basic highlighting, tools are needed for rapid foraging of text. In this paper, we describe a technique that presents an enhanced subject index for a book by conceptually reorganizing it to suit particular expressed user information needs. Users first enter information needs via keywords describing the concepts they are trying to retrieve and comprehend. Then our system, called ScentIndex, computes what index entries are conceptually related and reorganizes and displays these index entries on a single page. We also provide a number of navigational cues to help users peruse over this list of index entries and find relevant passages quickly. Compared to regular reading of a paper book, our study showed that users are more efficient and more accurate in finding, comparing, and comprehending material in our system	Ed Huai-hsin Chi;Lichan Hong;Julie Heiser;Stuart K. Card	Palo Alto Res. Center, CA|c|;;;		Book Index, eBooks, Information Scent, contextualization, personalized information access	
VAST	2006	VAST 2006 Contest - A Tale of Alderwood	10.1109/VAST.2006.261420	http://dx.doi.org/10.1109/VAST.2006.261420	215	216	M	Visual analytics experts realize that one effective way to push the field forward and to develop metrics for measuring the performance of various visual analytics components is to hold an annual competition. The first visual analytics science and technology (VAST) contest was held in conjunction with the 2006 IEEE VAST Symposium. The competition entailed the identification of possible political shenanigans in the fictitious town of Alderwood. A synthetic data set was made available as well as tasks. We summarize how we prepared and advertised the contest, developed some initial metrics for evaluation, and selected the winners. The winners were invited to participate at an additional live competition at the symposium to provide them with feedback from senior analysts	Georges G. Grinstein;Theresa A. O'Connell;Sharon J. Laskowski;Catherine Plaisant;Jean Scholtz;Mark A. Whiting	Univ. of Massachusetts Lowell, MA|c|;;;;;			
VAST	2006	A Visual Interface for Multivariate Temporal Data: Finding Patterns of Events across Multiple Histories	10.1109/VAST.2006.261421	http://dx.doi.org/10.1109/VAST.2006.261421	167	174	C	Finding patterns of events over time is important in searching patient histories, Web logs, news stories, and criminal activities. This paper presents PatternFinder, an integrated interface for query and result-set visualization for search and discovery of temporal patterns within multivariate and categorical data sets. We define temporal patterns as sequences of events with inter-event time spans. PatternFinder allows users to specify the attributes of events and time spans to produce powerful pattern queries that are difficult to express with other formalisms. We characterize the range of queries PatternFinder supports as users vary the specificity at which events and time spans are defined. Pattern Finder's query capabilities together with coupled ball-and-chain and tabular visualizations enable users to effectively query, explore and analyze event patterns both within and across data entities (e.g. patient histories, terrorist groups, Web logs, etc.)	Jerry Alan Fails;Amy K. Karlson;Layla Shahamat;Ben Shneiderman	Dept. of Comput. Sci., Maryland Univ.|c|;;;	10.1109/INFVIS.2001.963273	Temporal query, information visualization, user interface	
VAST	2006	User Interfaces for the Exploration of Hierarchical Multi-dimensional Data	10.1109/VAST.2006.261422	http://dx.doi.org/10.1109/VAST.2006.261422	175	182	C	A variety of user interfaces have been developed to support the querying of hierarchical multi-dimensional data in an OLAP setting such as pivot tables and Polaris. They are used to regularly check portions of a dataset and to explore a new dataset for the first time. In this paper, we establish criteria for OLAP user interface capabilities to facilitate comparison. Two criteria are the number of displayed dimensions along which comparisons can be made and the number of dimensions that are viewable at once - visual comparison depth and width. We argue that interfaces with greater visual comparison depth support regular checking of known data by users that know roughly where to look, while interfaces with greater comparison width support exploration of new data by users that have no a priori starting point and need to scan all dimensions. Pivot tables and Polaris are examples of the former. The main contribution of this paper is to introduce a new scalable interface that uses parallel dimension axis which supports the latter, greater visual comparison width. We compare our approach to both table based and parallel coordinate based interfaces. We present an implementation of our interface SGViewer, user scenarios and provide an evaluation that supports the usability of our interface	Mark Sifer	Sch. of Econ. & Inf. Syst., Wollongong Univ., NSW|c|	10.1109/INFVIS.2002.1173157;10.1109/INFVIS.2005.1532139	Data exploration, OLAP, visualization, parallel coordinates	
VAST	2006	Pixnostics: Towards Measuring the Value of Visualization	10.1109/VAST.2006.261423	http://dx.doi.org/10.1109/VAST.2006.261423	199	206	C	During the last two decades a wide variety of advanced methods for the visual exploration of large data sets have been proposed. For most of these techniques user interaction has become a crucial element, since there are many situations in which a user or an analyst has to select the right parameter settings from among many or select a subset of the available attribute space for the visualization process, in order to construct valuable visualizations that provide insight, into the data and reveal interesting patterns. The right choice of input parameters is often essential, since suboptimal parameter settings or the investigation of irrelevant data dimensions make the exploration process more time consuming and may result in wrong conclusions. In this paper we propose a novel method for automatically determining meaningful parameter- and attribute settings based on the information content of the resulting visualizations. Our technique called Pixnostics, in analogy to Scagnostics (Wilkinson et al., 2005), automatically analyses pixel images resulting from diverse parameter mappings and ranks them according to the potential value for the user. This allows a more effective and more efficient visual data analysis process, since the attribute/parameter space is reduced to meaningful selections and thus the analyst obtains faster insight into the data. Real world applications are provided to show the benefit of the proposed approach	Jörn Schneidewind;Mike Sips;Daniel A. Keim	Konstanz Univ.|c|;;	10.1109/INFVIS.2005.1532145;10.1109/INFVIS.2005.1532142;10.1109/VISUAL.2005.1532782;10.1109/VISUAL.2005.1532781;10.1109/INFVIS.2000.885092	Visual Data Exploration, Visualization technique, Visual Analytics	
VAST	2006	Exploratory Visualization of Multivariate Data with Variable Quality	10.1109/VAST.2006.261424	http://dx.doi.org/10.1109/VAST.2006.261424	183	190	C	Real-world data is known to be imperfect, suffering from various forms of defects such as sensor variability, estimation errors, uncertainty, human errors in data entry, and gaps in data gathering. Analysis conducted on variable quality data can lead to inaccurate or incorrect results. An effective visualization system must make users aware of the quality of their data by explicitly conveying not only the actual data content, but also its quality attributes. While some research has been conducted on visualizing uncertainty in spatio-temporal data and univariate data, little work has been reported on extending this capability into multivariate data visualization. In this paper we describe our approach to the problem of visually exploring multivariate data with variable quality. As a foundation, we propose a general approach to defining quality measures for tabular data, in which data may experience quality problems at three granularities: individual data values, complete records, and specific dimensions. We then present two approaches to visual mapping of quality information into display space. In particular, one solution embeds the quality measures as explicit values into the original dataset by regarding value quality and record quality as new data dimensions. The other solution is to superimpose the quality information within the data visualizations using additional visual variables. We also report on user studies conducted to assess alternate mappings of quality attributes to visual variables for the second method. In addition, we describe case studies that expose some of the advantages and disadvantages of these two approaches	Zaixian Xie;Shiping Huang;Matthew O. Ward;Elke A. Rundensteiner	Dept. of Comput. Sci., Worcester Polytech. Inst., MA|c|;;;	10.1109/VISUAL.2000.885679;10.1109/INFVIS.2002.1173145;10.1109/VISUAL.1995.485139;10.1109/INFVIS.2004.10	Uncertainty visualization, multivariate visualization, data quality	
VAST	2006	Semantic Image Browser: Bridging Information Visualization with Automated Intelligent Image Analysis	10.1109/VAST.2006.261425	http://dx.doi.org/10.1109/VAST.2006.261425	191	198	C	Browsing and retrieving images from large image collections are becoming common and important activities. Semantic image analysis techniques, which automatically detect high level semantic contents of images for annotation, are promising solutions toward this problem. However, few efforts have been made to convey the annotation results to users in an intuitive manner to enable effective image browsing and retrieval. There is also a lack of methods to monitor and evaluate the automatic image analysis algorithms due to the high dimensional nature of image data, features, and contents. In this paper, we propose a novel, scalable semantic image browser by applying existing information visualization techniques to semantic image analysis. This browser not only allows users to effectively browse and search in large image databases according to the semantic content of images, but also allows analysts to evaluate their annotation process through interactive visual exploration. The major visualization components of this browser are multi-dimensional scaling (MDS) based image layout, the value and relation (VaR) display that allows effective high dimensional visualization without dimension reduction, and a rich set of interaction tools such as search by sample images and content relationship detection. Our preliminary user study showed that the browser was easy to use and understand, and effective in supporting image browsing and retrieval tasks	Jing Yang 0001;Jianping Fan 0001;Daniel Hubball;Yuli Gao;Hangzai Luo;William Ribarsky;Matthew O. Ward	Dept. of Comput. Sci., Univ. of North Carolina at Charlotte, NC|c|;;;;;;	10.1109/INFVIS.1999.801855;10.1109/INFVIS.1995.528686;10.1109/INFVIS.2003.1249009;10.1109/VISUAL.1995.485140;10.1109/INFVIS.2004.71	Image retrieval, image layout, semantic image classification, multi-dimensional visualization, visual analytics	
VAST	2006	NetLens: Iterative Exploration of Content-Actor Network Data	10.1109/VAST.2006.261426	http://dx.doi.org/10.1109/VAST.2006.261426	91	98	C	Networks have remained a challenge for information retrieval and visualization because of the rich set of tasks that users want to accomplish. This paper offers an abstract content-actor network data model, a classification of tasks, and a tool to support them. The NetLens interface was designed around the abstract content-actor network data model to allow users to pose a series of elementary queries and iteratively refine visual overviews and sorted lists. This enables the support of complex queries that are traditionally hard to specify. NetLens is general and scalable in that it applies to any dataset that can be represented with our abstract data model. This paper describes NetLens applying a subset of the ACM Digital Library consisting of about 4,000 papers from the CM I conference written by about 6,000 authors. In addition, we are now working on a collection of half a million emails, and a dataset of legal cases	Hyunmo Kang;Catherine Plaisant;Bongshin Lee;Benjamin B. Bederson	Univ. of Maryland Inst. for Adv. Comput. Studies|c|;;;	10.1109/INFVIS.2004.1;10.1109/INFVIS.1996.559210;10.1109/INFVIS.2005.1532136	Human-Computer Interaction, information visualization, network visualization, content-actor network data, iterative query refinement, incremental data exploration, user interfaces, digital library, piccolo	
VAST	2006	Avian Flu Case Study with nSpace and GeoTime	10.1109/VAST.2006.261427	http://dx.doi.org/10.1109/VAST.2006.261427	27	34	C	GeoTime and nSpace are new analysis tools that provide innovative visual analytic capabilities. This paper uses an epidemiology analysis scenario to illustrate and discuss these new investigative methods and techniques. In addition, this case study is an exploration and demonstration of the analytical synergy achieved by combining GeoTime's geo-temporal analysis capabilities, with the rapid information triage, scanning and sense-making provided by nSpace. A fictional analyst works through the scenario from the initial brainstorming through to a final collaboration and report. With the efficient knowledge acquisition and insights into large amounts of documents, there is more time for the analyst to reason about the problem and imagine ways to mitigate threats. The use of both nSpace and GeoTime initiated a synergistic exchange of ideas, where hypotheses generated in either software tool could be cross-referenced, refuted, and supported by the other tool	Pascale Proulx;Sumeet Tandon;Adam Bodnar;David Schroh;Robert Harper 0002;William Wright	Oculus Info Inc., Toronto, Ont.|c|;;;;;	10.1109/INFVIS.2004.27	visual analytics, information visualization, human information interaction, sense making, geo-spatial information systems, temporal analysis, user centered design	
VAST	2006	Visual Analysis of Historic Hotel Visitation Patterns	10.1109/VAST.2006.261428	http://dx.doi.org/10.1109/VAST.2006.261428	35	42	C	Understanding the space and time characteristics of human interaction in complex social networks is a critical component of visual tools for intelligence analysis, consumer behavior analysis, and human geography. Visual identification and comparison of patterns of recurring events is an essential feature of such tools. In this paper, we describe a tool for exploring hotel visitation patterns in and around Rebersburg, Pennsylvania from 1898-1900. The tool uses a wrapping spreadsheet technique, called reruns, to display cyclic patterns of geographic events in multiple overlapping natural and artificial calendars. Implemented as an improvise visualization, the tool is in active development through a iterative process of data collection, hypothesis, design, discovery, and evaluation in close collaboration with historical geographers. Several discoveries have inspired ongoing data collection and plans to expand exploration to include historic weather records and railroad schedules. Distributed online evaluations of usability and usefulness have resulted in numerous feature and design recommendations	Chris Weaver;David Fyfe;Anthony C. Robinson;Deryck Holdsworth;Donna Peuquet;Alan M. MacEachren	Dept. of Geogr., Pennsylvania State Univ.|c|;;;;;	10.1109/INFVIS.2004.12;10.1109/INFVIS.2002.1173155;10.1109/INFVIS.2004.64	Geovisualization, exploratory visualization, historical geography, coordinated multiple views, travel pattern analysis	
VAST	2006	D-Dupe: An Interactive Tool for Entity Resolution in Social Networks	10.1109/VAST.2006.261429	http://dx.doi.org/10.1109/VAST.2006.261429	43	50	C	Visualizing and analyzing social networks is a challenging problem that has been receiving growing attention. An important first step, before analysis can begin, is ensuring that the data is accurate. A common data quality problem is that the data may inadvertently contain several distinct references to the same underlying entity; the process of reconciling these references is called entity-resolution. D-Dupe is an interactive tool that combines data mining algorithms for entity resolution with a task-specific network visualization. Users cope with complexity of cleaning large networks by focusing on a small subnetwork containing a potential duplicate pair. The subnetwork highlights relationships in the social network, making the common relationships easy to visually identify. D-Dupe users resolve ambiguities either by merging nodes or by marking them distinct. The entity resolution process is iterative: as pairs of nodes are resolved, additional duplicates may be revealed; therefore, resolution decisions are often chained together. We give examples of how users can flexibly apply sequences of actions to produce a high quality entity resolution result. We illustrate and evaluate the benefits of D-Dupe on three bibliographic collections. Two of the datasets had already been cleaned, and therefore should not have contained duplicates; despite this fact, many duplicates were rapidly identified using D-Dupe's unique combination of entity resolution algorithms within a task-specific visual interface	Mustafa Bilgic 0001;Louis Licamele;Lise Getoor;Ben Shneiderman	Maryland Univ., College Park, MD|c|;;;		Data cleaning and integration, user interfaces, visual analytics, visual data mining	
VAST	2006	Interactive Visual Synthesis of Analytic Knowledge	10.1109/VAST.2006.261430	http://dx.doi.org/10.1109/VAST.2006.261430	51	58	C	A visual investigation involves both the examination of existing information and the synthesis of new analytic knowledge. This is a progressive process in which newly synthesized knowledge becomes the foundation for future discovery. In this paper, we present a novel system supporting interactive, progressive synthesis of analytic knowledge. Here we use the term "analytic knowledge" to refer to concepts that a user derives from existing data along with the evidence supporting such concepts. Unlike existing visual analytic-tools, which typically support only exploration of existing information, our system offers two unique features. First, we support user-system cooperative visual synthesis of analytic knowledge from existing data. Specifically, users can visually define new concepts by annotating existing information, and refine partially formed concepts by linking additional evidence or manipulating related concepts. In response to user actions, our system can automatically manage the evolving corpus of synthesized knowledge and its corresponding evidence. Second, we support progressive visual analysis of synthesized knowledge. This feature allows analysts to visually explore both existing knowledge and synthesized knowledge, dynamically incorporating earlier analytic conclusions into the ensuing discovery process. We have applied our system to two complex but very different analytic applications. Our preliminary evaluation shows the promise of our work	David Gotz;Michelle X. Zhou;Vikram Aggarwal	IBM T. J. Watson Res. Center, Yorktown Heights, NY|c|;;	10.1109/INFVIS.2005.1532146;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.2001.963287;10.1109/INFVIS.1996.559210	Visual Analytics, Intelligence analysis, Problem solving environments, Visual Knowledge Discovery	
VAST	2006	Visual Analysis of Conflicting Opinions	10.1109/VAST.2006.261431	http://dx.doi.org/10.1109/VAST.2006.261431	59	66	C	Understanding the nature and dynamics of conflicting opinions is a profound and challenging issue. In this paper we address several aspects of the issue through a study of more than 3,000 Amazon customer reviews of the controversial bestseller The Da Vinci Code, including 1,738 positive and 918 negative reviews. The study is motivated by critical questions such as: what are the differences between positive and negative reviews? What is the origin of a particular opinion? How do these opinions change over time? To what extent can differentiating features be identified from unstructured text? How accurately can these features predict the category of a review? We first analyze terminology variations in these reviews in terms of syntactic, semantic, and statistic associations identified by TermWatch and use term variation patterns to depict underlying topics. We then select the most predictive terms based on log likelihood tests and demonstrate that this small set of terms classifies over 70% of the conflicting reviews correctly. This feature selection process reduces the dimensionality of the feature space from more than 20,000 dimensions to a couple of hundreds. We utilize automatically generated decision trees to facilitate the understanding of conflicting opinions in terms of these highly predictive terms. This study also uses a number of visualization and modeling tools to identify not only what positive and negative reviews have in common, but also they differ and evolve over time	Chaomei Chen;Fidelia Ibekwe-Sanjuan;Eric SanJuan;Chris Weaver	Drexel Univ., Philadelphia, PA|c|;;;	10.1109/INFVIS.2002.1173155	Visual Analytics, Intelligence analysis, Problemsolving environments, Visual Knowledge Discovery	
VAST	2006	Have Green - A Visual Analytics Framework for Large Semantic Graphs	10.1109/VAST.2006.261432	http://dx.doi.org/10.1109/VAST.2006.261432	67	74	C	A semantic graph is a network of heterogeneous nodes and links annotated with a domain ontology. In intelligence analysis, investigators use semantic graphs to organize concepts and relationships as graph nodes and links in hopes of discovering key trends, patterns, and insights. However, as new information continues to arrive from a multitude of sources, the size and complexity of the semantic graphs will soon overwhelm an investigator's cognitive capacity to carry out significant analyses. We introduce a powerful visual analytics framework designed to enhance investigators' natural analytical capabilities to comprehend and analyze large semantic graphs. The paper describes the overall framework design, presents major development accomplishments to date, and discusses future directions of a new visual analytics system known as Have Green	Pak Chung Wong;George Chin Jr.;Harlan Foote;Patrick Mackey;James J. Thomas	Pacific Northwest Nat. Lab., Richland, WA|c|;;;;	10.1109/INFVIS.2003.1249014;10.1109/INFVIS.2005.1532131	Visual Analytics, Graph and Network Visualization, Information Analytics, Information Visualization	
VAST	2006	Exploring Large-Scale Video News via Interactive Visualization	10.1109/VAST.2006.261433	http://dx.doi.org/10.1109/VAST.2006.261433	75	82	C	In this paper, we have developed a novel visualization framework to enable more effective visual analysis of large-scale news videos, where keyframes and keywords are automatically extracted from news video clips and visually represented according to their interestingness measurement to help audiences rind news stories of interest at first glance. A computational approach is also developed to quantify the interestingness measurement of video clips. Our experimental results have shown that our techniques for intelligent news video analysis have the capacity to enable more effective visualization of large-scale news videos. Our news video visualization system is very useful for security applications and for general audiences to quickly find news topics of interest from among many channels	Hangzai Luo;Jianping Fan 0001;Jing Yang 0001;William Ribarsky;Shin'ichi Satoh	Dept. of Comput. Sci., North Carolina Univ., Charlotte, NC|c|;;;;	10.1109/INFVIS.1998.729570;10.1109/INFVIS.2003.1249019;10.1109/VISUAL.1991.175815	News Visualization, Semantic Video Classification	
VAST	2006	Interactive Visualization and Analysis of Network and Sensor Data on Mobile Devices	10.1109/VAST.2006.261434	http://dx.doi.org/10.1109/VAST.2006.261434	83	90	C	Mobile devices are rapidly gaining popularity due to their small size and their wide range of functionality. With the constant improvement in wireless network access, they are an attractive option not only for day to day use. but also for in-field analytics by first responders in widespread areas. However, their limited processing, display, graphics and power resources pose a major challenge in developing effective applications. Nevertheless, they are vital for rapid decision making in emergencies when combined with appropriate analysis tools. In this paper, we present an efficient, interactive visual analytic system using a PDA to visualize network information from Purdue's Ross-Ade Stadium during football games as an example of in-held data analytics combined with text and video analysis. With our system, we can monitor the distribution of attendees with mobile devices throughout the stadium through their access of information and association/disassociation from wireless access points, enabling the detection of crowd movement and event activity. Through correlative visualization and analysis of synchronized video (instant replay video) and text information (play statistics) with the network activity, we can provide insightful information to network monitoring personnel, safety personnel and analysts. This work provides a demonstration and testbed for mobile sensor analytics that will help to improve network performance and provide safety personnel with information for better emergency planning and guidance	Avin Pattath;Brian D. Bue;Yun Jang;David S. Ebert;Xuan Zhong;Aaron Ault;Edward J. Coyle	Regional Visualization & Analytics Center, Purdue Univ., West Lafayette, IN|c|;;;;;;	10.1109/INFVIS.2004.27;10.1109/VISUAL.2001.964496;10.1109/INFVIS.2005.1532135;10.1109/INFVIS.2005.1532131;10.1109/INFVIS.2000.885097	mobile visualization, network visualization, visual analytics	
VAST	2006	Interactive Wormhole Detection in Large Scale Wireless Networks	10.1109/VAST.2006.261435	http://dx.doi.org/10.1109/VAST.2006.261435	99	106	C	Wormhole attacks in wireless networks can severely deteriorate the network performance and compromise the security through spoiling the routing protocols and weakening the security enhancements. This paper develops an approach, interactive visualization of wormholes (IVoW), to monitor and detect such attacks in large scale wireless networks in real time. We characterize the topology features of a network under wormhole attacks through the node position changes and visualize the information at dynamically adjusted scales. We integrate an automatic detection algorithm with appropriate user interactions to handle complicated scenarios that include a large number of moving nodes and multiple worm-hole attackers. Various visual forms have been adopted to assist the understanding and analysis of the reconstructed network topology and improve the detection accuracy. Extended simulation has demonstrated that the proposed approach can effectively locate the fake neighbor connections without introducing many false alarms. IVoW does not require the wireless nodes to be equipped with any special hardware, thus avoiding any additional cost. The proposed approach demonstrates that interactive visualization can be successfully combined with network security mechanisms to greatly improve the intrusion detection capabilities	Weichao Wang;Aidong Lu	Kansas Univ.|c|;	10.1109/VISUAL.1996.567787;10.1109/VISUAL.2005.1532819;10.1109/INFVIS.2002.1173161;10.1109/INFVIS.2004.60	Interactive Detection, Wormhole Attacks, Visualization on Network Security, Wireless Networks, Topology Visualization	
VAST	2006	Enhancing Visual Analysis of Network Traffic Using a Knowledge Representation	10.1109/VAST.2006.261436	http://dx.doi.org/10.1109/VAST.2006.261436	107	114	C	This paper presents a network traffic analysis system that couples visual analysis with a declarative knowledge representation. The system supports multiple iterations of the sense-making loop of analytic reasoning by allowing users to save discoveries as they are found and to reuse them in future iterations. We show how the knowledge representation can be used to improve both the visual representations and the basic analytical tasks of filtering and changing level of detail. We describe how the system can be used to produce models of network patterns, and show results from classifying one day of network traffic in our laboratory	Ling Xiao;John Gerth;Pat Hanrahan	Stanford Univ., Palo Alto, CA|c|;;	10.1109/INFVIS.1996.559226	network traffic visualization, visual analysis	
VAST	2006	Accelerating Network Traffic Analytics Using Query-Driven Visualization	10.1109/VAST.2006.261437	http://dx.doi.org/10.1109/VAST.2006.261437	115	122	C	Realizing operational analytics solutions where large and complex data must be analyzed in a time-critical fashion entails integrating many different types of technology. This paper focuses on an interdisciplinary combination of scientific data management and visualization/analysis technologies targeted at reducing the time required for data filtering, querying, hypothesis testing and knowledge discovery in the domain of network connection data analysis. We show that use of compressed bitmap indexing can quickly answer queries in an interactive visual data analysis application, and compare its performance with two alternatives for serial and parallel filtering/querying on 2.5 billion records' worth of network connection data collected over a period of 42 weeks. Our approach to visual network connection data exploration centers on two primary factors: interactive ad-hoc and multiresolution query formulation and execution over n dimensions and visual display of the n-dimensional histogram results. This combination is applied in a case study to detect a distributed network scan and to then identify the set of remote hosts participating in the attack. Our approach is sufficiently general to be applied to a diverse set of data understanding problems as well as used in conjunction with a diverse set of analysis and visualization tools	E. Wes Bethel;Scott Campbell;Eli Dart;Kurt Stockinger;Kesheng Wu	Lawrence Berkeley Nat. Lab., California Univ.|c|;;;;	10.1109/VISUAL.1999.809930;10.1109/VISUAL.2005.1532792	query-driven visualization, network security, data mining, visual analytics	
VAST	2006	Monitoring Network Traffic with Radial Traffic Analyzer	10.1109/VAST.2006.261438	http://dx.doi.org/10.1109/VAST.2006.261438	123	128	C	Extensive spread of malicious code on the Internet and also within intranets has risen the user's concern about what kind of data is transferred between her or his computer and other hosts on the network. Visual analysis of this kind of information is a challenging task, due to the complexity and volume of the data type considered, and requires special design of appropriate visualization techniques. In this paper, we present a scalable visualization toolkit for analyzing network activity of computer hosts on a network. The visualization combines network packet volume and type distribution information with geographic information, enabling the analyst to use geographic distortion techniques such as the HistoMap technique to become aware of the traffic components in the course of the analysis. The presented analysis tool is especially useful to compare important network load characteristics in a geographically aware display, to relate communication partners, and to identify the type of network traffic occurring. The results of the analysis are helpful in understanding typical network communication activities, and in anticipating potential performance bottlenecks or problems. It is suited for both off-line analysis of historic data, and via animation for on-line monitoring of packet-based network traffic in real time	Daniel A. Keim;Florian Mansmann;Jörn Schneidewind;Tobias Schreck	Databases, Data Min. & Visualization Group, Konstanz Univ.|c|;;;	10.1109/INFVIS.2000.885091;10.1109/INFVIS.1998.729557	Visual Analytics, Network Traffic Monitoring, Information Visualization and Geography-based Solutions	
VAST	2006	Toward a Multi-Analyst, Collaborative Framework for Visual Analytics	10.1109/VAST.2006.261439	http://dx.doi.org/10.1109/VAST.2006.261439	129	136	C	We describe a framework for the display of complex, multidimensional data, designed to facilitate exploration, analysis, and collaboration among multiple analysts. This framework aims to support human collaboration by making it easier to share representations, to translate from one point of view to another, to explain arguments, to update conclusions when underlying assumptions change, and to justify or account for decisions or actions. Multidimensional visualization techniques are used with interactive, context-sensitive, and tunable graphs. Visual representations are flexibly generated using a knowledge representation scheme based on annotated logic; this enables not only tracking and fusing different viewpoints, but also unpacking them. Fusing representations supports the creation of multidimensional meta-displays as well as the translation or mapping from one point of view to another. At the same time, analysts also need to be able to unpack one another's complex chains of reasoning, especially if they have reached different conclusions, and to determine the implications, if any, when underlying assumptions or evidence turn out to be false. The framework enables us to support a variety of scenarios as well as to systematically generate and test experimental hypotheses about the impact of different kinds of visual representations upon interactive collaboration by teams of distributed analysts	Susan Brennan;Klaus Mueller;Gregory J. Zelinsky;I. V. Ramakrishnan;David Scott Warren;Arie E. Kaufman	Stony Brook Univ., NY|c|;;;;;		visual analytics, collaborative and distributed visualization, data management and knowledge representation, visual knowledge discovery	
VAST	2006	Time Tree: Exploring Time Changing Hierarchies	10.1109/VAST.2006.261450	http://dx.doi.org/10.1109/VAST.2006.261450	3	10	C	Intelligence analysis often involves the task of gathering information about an organization. Knowledge about individuals in an organization and their relationships, often represented as a hierarchical organization chart, is crucial for understanding the organization. However, it is difficult for intelligence analysts to follow all individuals in an organization. Existing hierarchy visualizations have largely focused on the visualization of fixed structures and can not effectively depict the evolution of a hierarchy over time. We introduce TimeTree, a novel visualization tool designed to enable exploration of a changing hierarchy. TimeTree enables analysts to navigate the history of an organization, identify events associated with a specific entity (visualized on a TimeSlider), and explore an aggregate view of an individual's career path (a CareerTree). We demonstrate the utility of TimeTree by investigating a set of scenarios developed by an expert intelligence analyst. The scenarios are evaluated using a real dataset composed of eighteen thousand career events from more than eight thousand individuals. Insights gained from this analysis are presented	Stuart K. Card;Bongwon Suh;Bryan A. Pendleton;Bryan Heer;John W. Bodnar	Palo Alto Res. Center, CA|c|;;;;	10.1109/INFVIS.2003.1249010;10.1109/VISUAL.1991.175815	TimeTree, DOI Tree, tree visualization,organizational chart, timeseries data, visual analytics	
VAST	2006	Visual Exploration of Spatio-temporal Relationships for Scientific Data	10.1109/VAST.2006.261451	http://dx.doi.org/10.1109/VAST.2006.261451	11	18	C	Spatio-temporal relationships among features extracted from temporally-varying scientific datasets can provide useful information about the evolution of an individual feature and its interactions with other features. However, extracting such useful relationships without user guidance is cumbersome and often an error prone process. In this paper, we present a visual analysis system that interactively discovers such relationships from the trajectories of derived features. We describe analysis algorithms to derive various spatial and spatio-temporal relationships. A visual interface is presented using which the user can interactively select spatial and temporal extents to guide the knowledge discovery process. We show the usefulness of our proposed algorithms on datasets originating from computational fluid dynamics. We also demonstrate how the derived relationships can help in explaining the occurrence of critical events like merging and bifurcation of the vortices	Bryan Mehta;Srinivasan Parthasarathy 0001;Raghu Machiraju	Comput. Sci. & Eng., Ohio State Univ., Columbus, OH|c|;;	10.1109/VISUAL.2002.1183789	Knowledge Discovery, Scientific Analytics, Trajectory Analysis, Feature Extraction, Spatio-temporal Predicates, Visual Analytics	
VAST	2006	Visual Analytics of Paleoceanographic Conditions	10.1109/VAST.2006.261452	http://dx.doi.org/10.1109/VAST.2006.261452	19	26	C	Decade scale oceanic phenomena like El Nino are correlated with weather anomalies all over the globe. Only by understanding the events that produced the climatic conditions in the past will it be possible to forecast abrupt climate changes and prevent disastrous consequences for human beings and their environment. Paleoceanography research is a collaborative effort that requires the analysis of paleo time-series, which are obtained from a number of independent techniques and instruments and produced by a variety of different researchers and/or laboratories. The complexity of these phenomena that consist of massive, dynamic and often conflicting data can only be faced by means of analytical reasoning supported by a highly interactive visual interface. This paper presents an interactive visual analysis environment for paleoceanography that permits to gain insight into the paleodata and allow the control and steering of the analytical methods involved in the reconstruction of the climatic conditions of the past	Roberto Therón	Departamento de Informalica y Automatica, Univ. de Salamanca|c|		Infovis, parallel coordinates, multiple linked views, exploratory analysis	
Vis	2006	A Generic and Scalable Pipeline for GPU Tetrahedral Grid Rendering	10.1109/TVCG.2006.110	http://dx.doi.org/10.1109/TVCG.2006.110	1345	1352	J	Recent advances in algorithms and graphics hardware have opened the possibility to render tetrahedral grids at interactive rates on commodity PCs. This paper extends on this work in that it presents a direct volume rendering method for such grids which supports both current and upcoming graphics hardware architectures, large and deformable grids, as well as different rendering options. At the core of our method is the idea to perform the sampling of tetrahedral elements along the view rays entirely in local barycentric coordinates. Then, sampling requires minimum GPU memory and texture access operations, and it maps efficiently onto a feed-forward pipeline of multiple stages performing computation and geometry construction. We propose to spawn rendered elements from one single vertex. This makes the method amenable to upcoming Direct3D 10 graphics hardware which allows to create geometry on the GPU. By only modifying the algorithm slightly it can be used to render per-pixel iso-surfaces and to perform tetrahedral cell projection. As our method neither requires any pre-processing nor an intermediate grid representation it can efficiently deal with dynamic and large 3D meshes	Joachim Georgii;Rüdiger Westermann	Comput. Graphics & Visualization Group, Technische Univ. Munchen|c|;	10.1109/VISUAL.2003.1250390;10.1109/VISUAL.1997.663853;10.1109/VISUAL.2000.885683;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2001.964512;10.1109/VISUAL.1996.567606	Direct volume rendering, unstructured grids, programmable graphics hardware	
Vis	2006	A Novel Visualization Model for Web Search Results	10.1109/TVCG.2006.111	http://dx.doi.org/10.1109/TVCG.2006.111	981	988	J	This paper presents an interactive visualization system, named WebSearchViz, for visualizing the Web search results and facilitating users' navigation and exploration. The metaphor in our model is the solar system with its planets and asteroids revolving around the sun. Location, color, movement, and spatial distance of objects in the visual space are used to represent the semantic relationships between a query and relevant Web pages. Especially, the movement of objects and their speeds add a new dimension to the visual space, illustrating the degree of relevance among a query and Web search results in the context of users' subjects of interest. By interacting with the visual space, users are able to observe the semantic relevance between a query and a resulting Web page with respect to their subjects of interest, context information, or concern. Users' subjects of interest can be dynamically changed, redefined, added, or deleted from the visual space	Tien Nguyen;Jun Zhang	Dept. of Electr. & Comput. Eng., Iowa State Univ., Ames, IA|c|;	10.1109/INFVIS.1995.528691;10.1109/INFVIS.2001.963287;10.1109/INFVIS.1995.528692;10.1109/INFVIS.1998.729553;10.1109/INFVIS.1999.801864;10.1109/INFVIS.2000.885099	Visualization model, Web search results, movement, speed	
Vis	2006	A Pipeline for Computer Aided Polyp Detection	10.1109/TVCG.2006.112	http://dx.doi.org/10.1109/TVCG.2006.112	861	868	J	We present a novel pipeline for computer-aided detection (CAD) of colonic polyps by integrating texture and shape analysis with volume rendering and conformal colon flattening. Using our automatic method, the 3D polyp detection problem is converted into a 2D pattern recognition problem. The colon surface is first segmented and extracted from the CT data set of the patient's abdomen, which is then mapped to a 2D rectangle using conformal mapping. This flattened image is rendered using a direct volume rendering technique with a translucent electronic biopsy transfer function. The polyps are detected by a 2D clustering method on the flattened image. The false positives are further reduced by analyzing the volumetric shape and texture features. Compared with shape based methods, our method is much more efficient without the need of computing curvature and other shape parameters for the whole colon surface. The final detection results are stored in the 2D image, which can be easily incorporated into a virtual colonoscopy (VC) system to highlight the polyp locations. The extracted colon surface mesh can be used to accelerate the volumetric ray casting algorithm used to generate the VC endoscopic view. The proposed automatic CAD pipeline is incorporated into an interactive VC system, with a goal of helping radiologists detect polyps faster and with higher accuracy	Wei Hong;Feng Qiu;Arie E. Kaufman	Dept. of Comput. Sci., Stony Brook Univ., NY|c|;;	10.1109/VISUAL.2001.964540;10.1109/VISUAL.2004.27;10.1109/VISUAL.1992.235231;10.1109/VISUAL.2003.1250384	Computer Aided Detection, Virtual Colonoscopy, Texture Analysis, Volume Rendering	
Vis	2006	A Spectral Analysis of Function Composition and its Implications for Sampling in Direct Volume Visualization	10.1109/TVCG.2006.113	http://dx.doi.org/10.1109/TVCG.2006.113	1353	1360	J	In this paper we investigate the effects of function composition in the form g(f(x)) = h(x) by means of a spectral analysis of h. We decompose the spectral description of h(x) into a scalar product of the spectral description of g(x) and a term that solely depends on f(x) and that is independent of g(x). We then use the method of stationary phase to derive the essential maximum frequency of g(f(x)) bounding the main portion of the energy of its spectrum. This limit is the product of the maximum frequency of g(x) and the maximum derivative of f(x). This leads to a proper sampling of the composition h of the two functions g and f. We apply our theoretical results to a fundamental open problem in volume rendering - the proper sampling of the rendering integral after the application of a transfer function. In particular, we demonstrate how the sampling criterion can be incorporated in adaptive ray integration, visualization with multi-dimensional transfer functions, and pre-integrated volume rendering	Steven Bergner;Torsten Möller;Daniel Weiskopf;David J. Muraki	GrUVi-Lab, Simon Fraser Univ., Burnaby, BC|c|;;;	10.1109/VISUAL.2003.1250388;10.1109/VISUAL.2005.1532812;10.1109/VISUAL.2003.1250412;10.1109/VISUAL.1993.398852;10.1109/VISUAL.2000.885683;10.1109/VISUAL.2001.964519;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.1999.809908	volume rendering, transfer function, signal processing, Fourier transform, adaptive sampling	
Vis	2006	A Trajectory-Preserving Synchronization Method for Collaborative Visualization	10.1109/TVCG.2006.114	http://dx.doi.org/10.1109/TVCG.2006.114	989	996	J	In the past decade, a lot of research work has been conducted to support collaborative visualization among remote users over the networks, allowing them to visualize and manipulate shared data for problem solving. There are many applications of collaborative visualization, such as oceanography, meteorology and medical science. To facilitate user interaction, a critical system requirement for collaborative visualization is to ensure that remote users would perceive a synchronized view of the shared data. Failing this requirement, the user's ability in performing the desirable collaborative tasks would be affected. In this paper, we propose a synchronization method to support collaborative visualization. It considers how interaction with dynamic objects is perceived by application participants under the existence of network latency, and remedies the motion trajectory of the dynamic objects. It also handles the false positive and false negative collision detection problems. The new method is particularly well designed for handling content changes due to unpredictable user interventions or object collisions. We demonstrate the effectiveness of our method through a number of experiments	Lewis W. F. Li;Frederick W. B. Li;Rynson W. H. Lau	Dept. of Comput. Sci., City Univ. of Hong Kong|c|;;	10.1109/VISUAL.1997.663890;10.1109/VISUAL.1997.663896	Collaborative visualization, network latency, motion synchronization, distributed synchronization	
Vis	2006	Ambient Occlusion and Edge Cueing for Enhancing Real Time Molecular Visualization	10.1109/TVCG.2006.115	http://dx.doi.org/10.1109/TVCG.2006.115	1237	1244	J	The paper presents a set of combined techniques to enhance the real-time visualization of simple or complex molecules (up to order of 106 atoms) space fill mode. The proposed approach includes an innovative technique for efficient computation and storage of ambient occlusion terms, a small set of GPU accelerated procedural impostors for space-fill and ball-and-stick rendering, and novel edge-cueing techniques. As a result, the user's understanding of the three-dimensional structure under inspection is strongly increased (even for'still images), while the rendering still occurs in real time.	Marco Tarini;Paolo Cignoni;Claudio Montani	Universita dell''Insubria, Varese|c|;;	10.1109/VISUAL.2000.885694;10.1109/VISUAL.2003.1250394		
Vis	2006	An Advanced Evenly-Spaced Streamline Placement Algorithm	10.1109/TVCG.2006.116	http://dx.doi.org/10.1109/TVCG.2006.116	965	972	J	This paper presents an advanced evenly-spaced streamline placement algorithm for fast, high-quality, and robust layout of flow lines. A fourth-order Runge-Kutta integrator with adaptive step size and error control is employed for rapid accurate streamline advection. Cubic Hermite polynomial interpolation with large sample-spacing is adopted to create fewer evenly-spaced samples along each streamline to reduce the amount of distance checking. We propose two methods to enhance placement quality. Double queues are used to prioritize topological seeding and to favor long streamlines to minimize discontinuities. Adaptive distance control based on the local flow variance is explored to reduce cavities. Furthermore, we propose a universal, effective, fast, and robust loop detection strategy to address closed and spiraling streamlines. Our algorithm is an order-of-magnitude faster than Jobard and Lefer's algorithm with better placement quality and over 5 times faster than Mebarki et al.'s algorithm with comparable placement quality, but with a more robust solution to loop detection	Zhanping Liu;Robert J. Moorhead II;Joe Groner	HPC, Mississippi State Univ., MS|c|;;	10.1109/VISUAL.2000.885690;10.1109/VISUAL.1998.745295;10.1109/VISUAL.2005.1532831;10.1109/VISUAL.2005.1532832	Flow visualization, evenly-spaced streamlines, streamline placement, seeding strategy, closed streamlines	
Vis	2006	An Atmospheric Visual Analysis and Exploration System	10.1109/TVCG.2006.117	http://dx.doi.org/10.1109/TVCG.2006.117	1157	1164	J	Meteorological research involves the analysis of multi-field, multi-scale, and multi-source data sets. Unfortunately, traditional atmospheric visualization systems only provide tools to view a limited number of variables and small segments of the data. These tools are often restricted to 2D contour or vector plots or 3D isosurfaces. The meteorologist must mentally synthesize the data from multiple plots to glean the information needed to produce a coherent picture of the weather phenomenon of interest. In order to provide better tools to meteorologists and reduce system limitations, we have designed an integrated atmospheric visual analysis and exploration system for interactive analysis of weather data sets. Our system allows for the integrated visualization of 1D, 2D, and 3D atmospheric data sets in common meteorological grid structures and utilizes a variety of rendering techniques. These tools provide meteorologists with new abilities to analyze their data and answer questions on regions of interest, ranging from physics-based atmospheric rendering to illustrative rendering containing particles and glyphs. In this paper, we discuss the use and performance of our visual analysis for two important meteorological applications. The first application is warm rain formation in small cumulus clouds. In this, our three-dimensional, interactive visualization of modeled drop trajectories within spatially correlated fields from a cloud simulation has provided researchers with new insight. Our second application is improving and validating severe storm models, specifically the weather research and forecasting (WRF) model. This is done through correlative visualization of WRF model and experimental Doppler storm data	Yuyan Song;Jing Ye;Nikolai A. Svakhine;Sonia Lasher-Trapp;Mike Baldwin;David S. Ebert	Purdue Univ., West Lafayette, IN|c|;;;;;	10.1109/VISUAL.2000.885745;10.1109/VISUAL.2003.1250390;10.1109/VISUAL.1998.745330;10.1109/VISUAL.1992.235215;10.1109/VISUAL.1996.568113;10.1109/VISUAL.2003.1250383;10.1109/VISUAL.1990.146361	weather visualization, grid structures, transfer function, volume rendering, volume visualization, glyph rendering, warm rain entrainment process	
Vis	2006	Analyzing Complex FTMS Simulations: a Case Study in High-Level Visualization of Ion Motions	10.1109/TVCG.2006.118	http://dx.doi.org/10.1109/TVCG.2006.118	1037	1044	J	Current practice in particle visualization renders particle position data directly onto the screen as points or glyphs. Using a camera placed at a fixed position, particle motions can be visualized by rendering trajectories or by animations. Applying such direct techniques to large, time dependent particle data sets often results in cluttered images in which the dynamic properties of the underlying system are difficult to interpret. In this case study we take an alternative approach to the visualization of ion motions. Instead of rendering ion position data directly, we first extract meaningful motion information from the ion position data and then map this information onto geometric primitives. Our goal is to produce high-level visualizations that reflect the physicists' way of thinking about ion dynamics. Parameterized geometric icons are defined to encode motion information of clusters of related ions. In addition, a parameterized camera control mechanism is used to analyze relative instead of only absolute ion motions. We apply the techniques to simulations of Fourier transform mass spectrometry (FTMS) experiments. The data produced by such simulations can amount to 5.104 ions and 105 timesteps. This paper discusses the requirements, design and informal evaluation of the implemented system	Wojciech Burakiewicz;Robert van Liere	;	10.1109/VISUAL.2001.964552;10.1109/VISUAL.2004.121;10.1109/VISUAL.2000.885733;10.1109/VISUAL.2000.885734	Particle visualization, motion, motion features	
Vis	2006	Analyzing Vortex Breakdown Flow Structures by Assignment of Colors to Tensor Invariants	10.1109/TVCG.2006.119	http://dx.doi.org/10.1109/TVCG.2006.119	1189	1196	J	Topological methods are often used to describe flow structures in fluid dynamics and topological flow field analysis usually relies on the invariants of the associated tensor fields. A visual impression of the local properties of tensor fields is often complex and the search of a suitable technique for achieving this is an ongoing topic in visualization. This paper introduces and assesses a method of representing the topological properties of tensor fields and their respective flow patterns with the use of colors. First, a tensor norm is introduced, which preserves the properties of the tensor and assigns the tensor invariants to values of the RGB color space. Secondly, the RGB colors of the tensor invariants are transferred to corresponding hue values as an alternative color representation. The vectorial tensor invariants field is reduced to a scalar hue field and visualization of iso-surfaces of this hue value field allows us to identify locations with equivalent flow topology. Additionally highlighting by the maximum of the eigenvalue difference field reflects the magnitude of the structural change of the flow. The method is applied on a vortex breakdown flow structure inside a cylinder with a rotating lid	Markus Rütten;Min S. Chong	German Aerosp. Center|c|;	10.1109/VISUAL.2003.1250379;10.1109/VISUAL.1997.663858;10.1109/VISUAL.2004.99;10.1109/VISUAL.2004.80;10.1109/VISUAL.2004.113;10.1109/VISUAL.1994.346326;10.1109/VISUAL.1993.398849	Flow visualization, Tensor field Topology, Invariants	
Vis	2006	Asynchronous Distributed Calibration for Scalable and Reconfigurable Multi-Projector Displays	10.1109/TVCG.2006.121	http://dx.doi.org/10.1109/TVCG.2006.121	1101	1108	J	Centralized techniques have been used until now when automatically calibrating (both geometrically and photometrically) large high-resolution displays created by tiling multiple projectors in a 2D array. A centralized server managed all the projectors and also the camera(s) used to calibrate the display. In this paper, we propose an asynchronous distributed calibration methodology via a display unit called the plug-and-play projector (PPP). The PPP consists of a projector, camera, computation and communication unit, thus creating a self-sufficient module that enables an asynchronous distributed architecture for multi-projector displays. We present a single-program-multiple-data (SPMD) calibration algorithm that runs on each PPP and achieves a truly scalable and reconfigurable display without any input from the user. It instruments novel capabilities like adding/removing PPPs from the display dynamically, detecting faults, and reshaping the display to a reasonable rectangular shape to react to the addition/removal/faults. To the best of our knowledge, this is the first attempt to realize a completely asynchronous and distributed calibration architecture and methodology for multi-projector displays	Ezekiel S. Bhasker;Pinaki Sinha;Aditi Majumder	Dept. of Comput. Sci., California Univ., Irvine, CA|c|;;	10.1109/VISUAL.2002.1183793;10.1109/VISUAL.2000.885685;10.1109/VISUAL.2000.885684;10.1109/VISUAL.1999.809883;10.1109/VISUAL.2001.964508	Multi-projector displays, projector-camera systems, geometric and color calibration, distributed algorithms	
Vis	2006	Caricaturistic Visualization	10.1109/TVCG.2006.123	http://dx.doi.org/10.1109/TVCG.2006.123	1085	1092	J	Caricatures are pieces of art depicting persons or sociological conditions in a non-veridical way. In both cases caricatures are referring to a reference model. The deviations from the reference model are the characteristic features of the depicted subject. Good caricatures exaggerate the characteristics of a subject in order to accent them. The concept of caricaturistic visualization is based on the caricature metaphor. The aim of caricaturistic visualization is an illustrative depiction of characteristics of a given dataset by exaggerating deviations from the reference model. We present the general concept of caricaturistic visualization as well as a variety of examples. We investigate different visual representations for the depiction of caricatures. Further, we present the caricature matrix, a technique to make differences between datasets easily identifiable	Peter Rautek;Ivan Viola;Eduard Gröller	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol.|c|;;	10.1109/VISUAL.2005.1532856;10.1109/VISUAL.2004.48;10.1109/VISUAL.2005.1532857;10.1109/VISUAL.2005.1532835	Illustrative Visualization, Focus+Context Techniques, Volume Visualization	
Vis	2006	ClearView: An Interactive Context Preserving Hotspot Visualization Technique	10.1109/TVCG.2006.124	http://dx.doi.org/10.1109/TVCG.2006.124	941	948	J	Volume rendered imagery often includes a barrage of 3D information like shape, appearance and topology of complex structures, and it thus quickly overwhelms the user. In particular, when focusing on a specific region a user cannot observe the relationship between various structures unless he has a mental picture of the entire data. In this paper we present ClearView, a GPU-based, interactive framework for texture-based volume ray-casting that allows users which do not have the visualization skills for this mental exercise to quickly obtain a picture of the data in a very intuitive and user-friendly way. ClearView is designed to enable the user to focus on particular areas in the data while preserving context information without visual clutter. ClearView does not require additional feature volumes as it derives any features in the data from image information only. A simple point-and-click interface enables the user to interactively highlight structures in the data. ClearView provides an easy to use interface to complex volumetric data as it only uses transparency in combination with a few specific shaders to convey focus and context information	Jens H. Krüger;Jens Schneider;Rüdiger Westermann	Comput. Graphics & Visualization Group, Technische Univ. Munchen|c|;;	10.1109/VISUAL.2000.885694;10.1109/VISUAL.2003.1250400;10.1109/VISUAL.1996.568110;10.1109/VISUAL.2002.1183762;10.1109/VISUAL.2002.1183777;10.1109/VISUAL.1999.809882;10.1109/VISUAL.2000.885694;10.1109/VISUAL.2004.48;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2005.1532856;10.1109/VISUAL.2005.1532818	Focus & Context, GPU rendering, volume raycasting	
Vis	2006	Comparative Visualization for Wave-based and Geometric Acoustics	10.1109/TVCG.2006.125	http://dx.doi.org/10.1109/TVCG.2006.125	1173	1180	J	We present a comparative visualization of the acoustic simulation results obtained by two different approaches that were combined into a single simulation algorithm. The first method solves the wave equation on a volume grid based on finite elements. The second method, phonon tracing, is a geometric approach that we have previously developed for interactive simulation, visualization and modeling of room acoustics. Geometric approaches of this kind are more efficient than FEM in the high and medium frequency range. For low frequencies they fail to represent diffraction, which on the other hand can be simulated properly by means of FEM. When combining both methods we need to calibrate them properly and estimate in which frequency range they provide comparable results. For this purpose we use an acoustic metric called gain and display the resulting error. Furthermore we visualize interference patterns, since these depend not only on diffraction, but also exhibit phase-dependent amplification and neutralization effects	Eduard Deines;Martin Hering-Bertram;Jan Mohring;Jevgenijs Jegorovs;Frank Michel;Hans Hagen;Gregory M. Nielson	IRTG, Kaiserslautern|c|;;;;;;	10.1109/VISUAL.2005.1532790	Acoustic simulation, comparative visualization, ray tracing, finite element method, phonon map	
Vis	2006	Composite Rectilinear Deformation for Stretch and Squish Navigation	10.1109/TVCG.2006.127	http://dx.doi.org/10.1109/TVCG.2006.127	901	908	J	We present the first scalable algorithm that supports the composition of successive rectilinear deformations. Earlier systems that provided stretch and squish navigation could only handle small datasets. More recent work featuring rubber sheet navigation for large datasets has focused on rendering and on application-specific issues. However, no algorithm has yet been presented for carrying out such navigation methods; our paper addresses this problem. For maximum flexibility with large datasets, a stretch and squish navigation algorithm should allow for millions of potentially deformable regions. However, typical usage only changes the extents of a small subset k of these n regions at a time. The challenge is to avoid computations that are linear in n, because a single deformation can affect the absolute screen-space location of every deformable region. We provide an O(klogn) algorithm that supports any application that can lay out a dataset on a generic grid, and show an implementation that allows navigation of trees and gene sequences with millions of items in sub-millisecond time	James Slack;Tamara Munzner	Dept. of Comput. Sci., British Columbia Univ., Vancouver, BC|c|;	10.1109/INFVIS.1997.636786;10.1109/INFVIS.2005.1532127;10.1109/INFVIS.2002.1173156;10.1109/INFVIS.2005.1532127;10.1109/VISUAL.2002.1183791	Focus+Context, information visualization, real time rendering, navigation	
Vis	2006	Concurrent Visualization in a Production Supercomputing Environment	10.1109/TVCG.2006.128	http://dx.doi.org/10.1109/TVCG.2006.128	997	1004	J	We describe a concurrent visualization pipeline designed for operation in a production supercomputing environment. The facility was initially developed on the NASA Ames "Columbia" supercomputer for a massively parallel forecast model (GEOS4). During the 2005 Atlantic hurricane season, GEOS4 was run 4 times a day under tight time constraints so that its output could be included in an ensemble prediction that was made available to forecasters at the National Hurricane Center. Given this time-critical context, we designed a configurable concurrent pipeline to visualize multiple global fields without significantly affecting the runtime model performance or reliability. We use MPEG compression of the accruing images to facilitate live low-bandwidth distribution of multiple visualization streams to remote sites. We also describe the use of our concurrent visualization framework with a global ocean circulation model, which provides a 864-fold increase in the temporal resolution of practically achievable animations. In both the atmospheric and oceanic circulation models, the application scientists gained new insights into their model dynamics, due to the high temporal resolution animations attainable	David Ellsworth;Bryan Green;Chris Henze;Patrick J. Moran;Timothy Sandstrom	AMTl, NASA Ames Res. Center, Moffett Field, CA|c|;;;;	10.1109/VISUAL.2005.1532795	Supercomputing, concurrent visualization, interactive visual computing, time-varying data, high temporal resolution visualization, GEOS4 global climate model, hurricane visualization, ECCO, ocean modeling	
Vis	2006	Detection and Visualization of Defects in 3D Unstructured Models of Nematic Liquid Crystals	10.1109/TVCG.2006.133	http://dx.doi.org/10.1109/TVCG.2006.133	1045	1052	J	A method for the semi-automatic detection and visualization of defects in models of nematic liquid crystals (NLCs) is introduced; this method is suitable for unstructured models, a previously unsolved problem. The detected defects - also known as disclinations - are regions were the alignment of the liquid crystal rapidly changes over space; these defects play a large role in the physical behavior of the NLC substrate. Defect detection is based upon a measure of total angular change of crystal orientation (the director) over a node neighborhood via the use of a nearest neighbor path. Visualizations based upon the detection algorithm clearly identify complete defect regions as opposed to incomplete visual descriptions provided by cutting-plane and isosurface approaches. The introduced techniques are currently in use by scientists studying the dynamics of defect change	Ketan Mehta;T. J. Jankun-Kelly	Mississippi State Univ., MS|c|;	10.1109/TVCG.2006.181;10.1109/TVCG.2006.182;10.1109/VISUAL.1997.663894;10.1109/VISUAL.2004.23;10.1109/VISUAL.2001.964507	scientific visualization, disclination, nematic liquid crystal, defects, unstructured grid, feature extraction	
Vis	2006	Diffusion Tensor Visualization with Glyph Packing	10.1109/TVCG.2006.134	http://dx.doi.org/10.1109/TVCG.2006.134	1329	1336	J	A common goal of multivariate visualization is to enable data inspection at discrete points, while also illustrating larger-scale continuous structures. In diffusion tensor visualization, glyphs are typically used to meet the first goal, and methods such as texture synthesis or fiber tractography can address the second. We adapt particle systems originally developed for surface modeling and anisotropic mesh generation to enhance the utility of glyph-based tensor visualizations. By carefully distributing glyphs throughout the field (either on a slice, or in the volume) into a dense packing, using potential energy profiles shaped by the local tensor value, we remove undue visual emphasis of the regular sampling grid of the data, and the underlying continuous features become more apparent. The method is demonstrated on a DT-MRI scan of a patient with a brain tumor	Gordon L. Kindlmann;Carl-Fredrik Westin	Dept. of Radiol., Harvard Med. Sch., Boston, MA|c|;	10.1109/VISUAL.2004.25;10.1109/VISUAL.1998.745294;10.1109/VISUAL.2004.80;10.1109/VISUAL.2002.1183797;10.1109/VISUAL.1995.485141;10.1109/VISUAL.1999.809905;10.1109/VISUAL.2003.1250379	Diffusion tensor, glyphs, particle systems, anisotropic sampling, fiber tractography	
Vis	2006	Distributed Shared Memory for Roaming Large Volumes	10.1109/TVCG.2006.135	http://dx.doi.org/10.1109/TVCG.2006.135	1299	1306	J	We present a cluster-based volume rendering system for roaming very large volumes. This system allows to move a gigabyte-sized probe inside a total volume of several tens or hundreds of gigabytes in real-time. While the size of the probe is limited by the total amount of texture memory on the cluster, the size of the total data set has no theoretical limit. The cluster is used as a distributed graphics processing unit that both aggregates graphics power and graphics memory. A hardware-accelerated volume renderer runs in parallel on the cluster nodes and the final image compositing is implemented using a pipelined sort-last rendering algorithm. Meanwhile, volume bricking and volume paging allow efficient data caching. On each rendering node, a distributed hierarchical cache system implements a global software-based distributed shared memory on the cluster. In case of a cache miss, this system first checks page residency on the other cluster nodes instead of directly accessing local disks. Using two gigabit Ethernet network interfaces per node, we accelerate data fetching by a factor of 4 compared to directly accessing local disks. The system also implements asynchronous disk access and texture loading, which makes it possible to overlap data loading, volume slicing and rendering for optimal volume roaming	Laurent Castanie;Christophe Mion;Xavier Cavin;Bruno Lévy	ALICE Group, INRIA, Lorraine|c|;;;	10.1109/VISUAL.2005.1532794;10.1109/VISUAL.1997.663888;10.1109/VISUAL.2005.1532785;10.1109/VISUAL.2005.1532802	Large volumes, volume roaming, out-of-core, hierarchical caching, distributed shared memory, hardware-accelerated volume visualization, graphics hardware, parallel rendering, graphics cluster	
Vis	2006	Dynamic View Selection for Time-Varying Volumes	10.1109/TVCG.2006.137	http://dx.doi.org/10.1109/TVCG.2006.137	1109	1116	J	Animation is an effective way to show how time-varying phenomena evolve over time. A key issue of generating a good animation is to select ideal views through which the user can perceive the maximum amount of information from the time-varying dataset. In this paper, we first propose an improved view selection method for static data. The method measures the quality of a static view by analyzing the opacity, color and curvature distributions of the corresponding volume rendering images from the given view. Our view selection metric prefers an even opacity distribution with a larger projection area, a larger area of salient features' colors with an even distribution among the salient features, and more perceived curvatures. We use this static view selection method and a dynamic programming approach to select time-varying views. The time-varying view selection maximizes the information perceived from the time-varying dataset based on the constraints that the time-varying view should show smooth changes of direction and near-constant speed. We also introduce a method that allows the user to generate a smooth transition between any two views in a given time step, with the perceived information maximized as well. By combining the static and dynamic view selection methods, the users are able to generate a time-varying view that shows the maximum amount of information from a time-varying data set	Guangfeng Ji;Han-Wei Shen	Ohio State Univ., Columbus, OH|c|;	10.1109/VISUAL.2003.1250414;10.1109/VISUAL.1996.567807;10.1109/VISUAL.1999.809893;10.1109/INFVIS.2003.1249004;10.1109/VISUAL.2005.1532834;10.1109/VISUAL.2005.1532857;10.1109/VISUAL.2005.1532833;10.1109/VISUAL.2002.1183785;10.1109/VISUAL.2003.1250402	Static view selection, image based method, dynamic view selection, information entropy, optimization	
Vis	2006	Enhancing Depth Perception in Translucent Volumes	10.1109/TVCG.2006.139	http://dx.doi.org/10.1109/TVCG.2006.139	1117	1124	J	We present empirical studies that consider the effects of stereopsis and simulated aerial perspective on depth perception in translucent volumes. We consider a purely absorptive lighting model, in which light is not scattered or reflected, but is simply absorbed as it passes through the volume. A purely absorptive lighting model is used, for example, when rendering digitally reconstructed radiographs (DRRs), which are synthetic X-ray images reconstructed from CT volumes. Surgeons make use of DRRs in planning and performing operations, so an improvement of depth perception in DRRs may help diagnosis and surgical planning	Marta Kersten;James Stewart;Nikolaus F. Troje;Randy E. Ellis	Med. Comput. Lab., Queen''s Univ.|c|;;;		Stereo, Stereopsis, X-ray, Radiograph, Volume Rendering	
Vis	2006	Exploded Views for Volume Data	10.1109/TVCG.2006.140	http://dx.doi.org/10.1109/TVCG.2006.140	1077	1084	J	Exploded views are an illustration technique where an object is partitioned into several segments. These segments are displaced to reveal otherwise hidden detail. In this paper we apply the concept of exploded views to volumetric data in order to solve the general problem of occlusion. In many cases an object of interest is occluded by other structures. While transparency or cutaways can be used to reveal a focus object, these techniques remove parts of the context information. Exploded views, on the other hand, do not suffer from this drawback. Our approach employs a force-based model: the volume is divided into a part configuration controlled by a number of forces and constraints. The focus object exerts an explosion force causing the parts to arrange according to the given constraints. We show that this novel and flexible approach allows for a wide variety of explosion-based visualizations including view-dependent explosions. Furthermore, we present a high-quality GPU-based volume ray casting algorithm for exploded views which allows rendering and interaction at several frames per second	Stefan Bruckner;Eduard Gröller	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol.|c|;	10.1109/VISUAL.2003.1250400;10.1109/VISUAL.2005.1532783;10.1109/VISUAL.2005.1532856;10.1109/VISUAL.2005.1532807;10.1109/VISUAL.2003.1250384;10.1109/INFVIS.1996.559215;10.1109/VISUAL.2004.104;10.1109/VISUAL.2005.1532817	Illustrative visualization, exploded views, volume rendering	
Vis	2006	Extensions of the Zwart-Powell Box Spline for Volumetric Data Reconstruction on the Cartesian Lattice	10.1109/TVCG.2006.141	http://dx.doi.org/10.1109/TVCG.2006.141	1337	1344	J	In this article we propose a box spline and its variants for reconstructing volumetric data sampled on the Cartesian lattice. In particular we present a tri-variate box spline reconstruction kernel that is superior to tensor product reconstruction schemes in terms of recovering the proper Cartesian spectrum of the underlying function. This box spline produces a C2 reconstruction that can be considered as a three dimensional extension of the well known Zwart-Powell element in 2D. While its smoothness and approximation power are equivalent to those of the tri-cubic B-spline, we illustrate the superiority of this reconstruction on functions sampled on the Cartesian lattice and contrast it to tensor product B-splines. Our construction is validated through a Fourier domain analysis of the reconstruction behavior of this box spline. Moreover, we present a stable method for evaluation of this box spline by means of a decomposition. Through a convolution, this decomposition reduces the problem to evaluation of a four directional box spline that we previously published in its explicit closed form.	Alireza Entezari;Torsten Möller	Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC|c|;	10.1109/VISUAL.1994.346331;10.1109/VISUAL.1993.398851;10.1109/VISUAL.2005.1532811;10.1109/VISUAL.2004.65;10.1109/VISUAL.1997.663848	Volumetric data interpolation, reconstruction, box splines	
Vis	2006	Fast and Efficient Compression of Floating-Point Data	10.1109/TVCG.2006.143	http://dx.doi.org/10.1109/TVCG.2006.143	1245	1250	J	Large scale scientific simulation codes typically run on a cluster of CPUs that write/read time steps to/from a single file system. As data sets are constantly growing in size, this increasingly leads to I/O bottlenecks. When the rate at which data is produced exceeds the available I/O bandwidth, the simulation stalls and the CPUs are idle. Data compression can alleviate this problem by using some CPU cycles to reduce the amount of data needed to be transfered. Most compression schemes, however, are designed to operate offline and seek to maximize compression, not throughput. Furthermore, they often require quantizing floating-point values onto a uniform integer grid, which disqualifies their use in applications where exact values must be retained. We propose a simple scheme for lossless, online compression of floating-point data that transparently integrates into the I/O of many applications. A plug-in scheme for data-dependent prediction makes our scheme applicable to a wide variety of data used in visualization, such as unstructured meshes, point sets, images, and voxel grids. We achieve state-of-the-art compression rates and speeds, the latter in part due to an improved entropy coder. We demonstrate that this significantly accelerates I/O throughput in real simulation runs. Unlike previous schemes, our method also adapts well to variable-precision floating-point and integer data	Peter Lindstrom;Martin Isenburg	Lawrence Livermore Nat. Lab., Berkeley, CA|c|;	10.1109/VISUAL.1999.809868;10.1109/VISUAL.2000.885711;10.1109/VISUAL.2002.1183768;10.1109/VISUAL.1996.568138	High throughput, lossless compression, file compaction for I/O efficiency, fast entropy coding, range coder, predictive coding, large scale simulation and visualization	
Vis	2006	Feature Aligned Volume Manipulation for Illustration and Visualization	10.1109/TVCG.2006.144	http://dx.doi.org/10.1109/TVCG.2006.144	1069	1076	J	In this paper we describe a GPU-based technique for creating illustrative visualization through interactive manipulation of volumetric models. It is partly inspired by medical illustrations, where it is common to depict cuts and deformation in order to provide a better understanding of anatomical and biological structures or surgical processes, and partly motivated by the need for a real-time solution that supports the specification and visualization of such illustrative manipulation. We propose two new feature aligned techniques, namely surface alignment and segment alignment, and compare them with the axis-aligned techniques which were reported in previous work on volume manipulation. We also present a mechanism for defining features using texture volumes, and methods for computing correct normals for the deformed volume in respect to different alignments. We describe a GPU-based implementation to achieve real-time performance of the techniques and a collection of manipulation operators including peelers, retractors, pliers and dilators which are adaptations of the metaphors and tools used in surgical procedures and medical illustrations. Our approach is directly applicable in medical and biological illustration, and we demonstrate how it works as an interactive tool for focus+context visualization, as well as a generic technique for volume graphics	Carlos D. Correa;Deborah Silver;Min Chen	Dept. of Electr. & Comput. Eng., State Univ. of New Jersey, NJ|c|;;	10.1109/VISUAL.2003.1250400;10.1109/VISUAL.2000.885694	Illustrative visualization, Illustrative manipulation, GPU computing, volume rendering, volume deformation, computerassisted medical illustration	
Vis	2006	fine-grained Visualization Pipelines and Lazy Functional Languages	10.1109/TVCG.2006.145	http://dx.doi.org/10.1109/TVCG.2006.145	973	980	J	The pipeline model in visualization has evolved from a conceptual model of data processing into a widely used architecture for implementing visualization systems. In the process, a number of capabilities have been introduced, including streaming of data in chunks, distributed pipelines, and demand-driven processing. Visualization systems have invariably built on stateful programming technologies, and these capabilities have had to be implemented explicitly within the lower layers of a complex hierarchy of services. The good news for developers is that applications built on top of this hierarchy can access these capabilities without concern for how they are implemented. The bad news is that by freezing capabilities into low-level services expressive power and flexibility is lost. In this paper we express visualization systems in a programming language that more naturally supports this kind of processing model. Lazy functional languages support fine-grained demand-driven processing, a natural form of streaming, and pipeline-like function composition for assembling applications. The technology thus appears well suited to visualization applications. Using surface extraction algorithms as illustrative examples, and the lazy functional language Haskell, we argue the benefits of clear and concise expression combined with fine-grained, demand-driven computation. Just as visualization provides insight into data, functional abstraction provides new insight into visualization	David J. Duke;Malcolm Wallace;Rita Borgo;Colin Runciman	Sch. of Comput., Leeds Univ.|c|;;;	10.1109/VISUAL.1994.346311;10.1109/VISUAL.1999.809864;10.1109/VISUAL.1993.398880;10.1109/VISUAL.1999.809891;10.1109/VISUAL.2005.1532800;10.1109/VISUAL.1997.663888	Pipeline model, laziness, functional programming	
Vis	2006	Full Body Virtual Autopsies using a State-of-the-art Volume Rendering Pipeline	10.1109/TVCG.2006.146	http://dx.doi.org/10.1109/TVCG.2006.146	869	876	J	This paper presents a procedure for virtual autopsies based on interactive 3D visualizations of large scale, high resolution data from CT-scans of human cadavers. The procedure is described using examples from forensic medicine and the added value and future potential of virtual autopsies is shown from a medical and forensic perspective. Based on the technical demands of the procedure state-of-the-art volume rendering techniques are applied and refined to enable real-time, full body virtual autopsies involving gigabyte sized data on standard GPUs. The techniques applied include transfer function based data reduction using level-of-detail selection and multi-resolution rendering techniques. The paper also describes a data management component for large, out-of-core data sets and an extension to the GPU-based raycaster for efficient dual TF rendering. Detailed benchmarks of the pipeline are presented using data sets from forensic cases	Patric Ljung;Calle Winskog;Anders Persson;Claes Lundström;Anders Ynnerman	Div. for Visual Inf. Technol. & Applications, Linkoping Univ.|c|;;;;	10.1109/VISUAL.2002.1183757;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2005.1532794;10.1109/VISUAL.2003.1250391;10.1109/VISUAL.2005.1532799;10.1109/VISUAL.1999.809908	Forensics, autopsies, medical visualization, volume rendering, large scale data	
Vis	2006	High-Level User Interfaces for Transfer Function Design with Semantics	10.1109/TVCG.2006.148	http://dx.doi.org/10.1109/TVCG.2006.148	1021	1028	J	Many sophisticated techniques for the visualization of volumetric data such as medical data have been published. While existing techniques are mature from a technical point of view, managing the complexity of visual parameters is still difficult for nonexpert users. To this end, this paper presents new ideas to facilitate the specification of optical properties for direct volume rendering. We introduce an additional level of abstraction for parametric models of transfer functions. The proposed framework allows visualization experts to design high-level transfer function models which can intuitively be used by non-expert users. The results are user interfaces which provide semantic information for specialized visualization problems. The proposed method is based on principal component analysis as well as on concepts borrowed from computer animation	Christof Rezk-Salama;Maik Keller;Peter Kohlmann	Comput. Graphics & Multimedia Syst. Group, Siegen Univ.|c|;;	10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2003.1250413;10.1109/VISUAL.2002.1183764;10.1109/VISUAL.1998.745319;10.1109/VISUAL.2001.964519;10.1109/VISUAL.2003.1250412;10.1109/VISUAL.1996.568113;10.1109/VISUAL.1997.663875	Volume rendering, transfer function design, semantic models	
Vis	2006	High-Quality Extraction of Isosurfaces from Regular and Irregular Grids	10.1109/TVCG.2006.149	http://dx.doi.org/10.1109/TVCG.2006.149	1205	1212	J	Isosurfaces are ubiquitous in many fields, including visualization, graphics, and vision. They are often the main computational component of important processing pipelines (e.g., surface reconstruction), and are heavily used in practice. The classical approach to compute isosurfaces is to apply the Marching Cubes algorithm, which although robust and simple to implement, generates surfaces that require additional processing steps to improve triangle quality and mesh size. An important issue is that in some cases, the surfaces generated by Marching Cubes are irreparably damaged, and important details are lost which can not be recovered by subsequent processing. The main motivation of this work is to develop a technique capable of constructing high-quality and high-fidelity isosurfaces. We propose a new advancing front technique that is capable of creating high-quality isosurfaces from regular and irregular volumetric datasets. Our work extends the guidance field framework of Schreiner et al. to implicit surfaces, and improves it in significant ways. In particular, we describe a set of sampling conditions that guarantee that surface features will be captured by the algorithm. We also describe an efficient technique to compute a minimal guidance field, which greatly improves performance. Our experimental results show that our technique can generate high-quality meshes from complex datasets	John M. Schreiner;Carlos Eduardo Scheidegger;Cláudio T. Silva	SCI Inst., Utah Univ., Salt Lake City, UT|c|;;	10.1109/VISUAL.1991.175782;10.1109/VISUAL.2000.885705;10.1109/VISUAL.1997.663930;10.1109/VISUAL.2003.1250414;10.1109/VISUAL.2004.52	Isosurface Extraction, Curvature, Advancing Front	
Vis	2006	Hub-based Simulation and Graphics Hardware Accelerated Visualization for Nanotechnology Applications	10.1109/TVCG.2006.150	http://dx.doi.org/10.1109/TVCG.2006.150	1061	1068	J	The Network for computational nanotechnology (NCN) has developed a science gateway at nanoHUB.org for nanotechnology education and research. Remote users can browse through online seminars and courses, and launch sophisticated nanotechnology simulation tools, all within their Web browser. Simulations are supported by a middleware that can route complex jobs to grid supercomputing resources. But what is truly unique about the middleware is the way that it uses hardware accelerated graphics to support both problem setup and result visualization. This paper describes the design and integration of a remote visualization framework into the nanoHUB for interactive visual analytics of nanotechnology simulations. Our services flexibly handle a variety of nanoscience simulations, render them utilizing graphics hardware acceleration in a scalable manner, and deliver them seamlessly through the middleware to the user. Rendering is done only on-demand, as needed, so each graphics hardware unit can simultaneously support many user sessions. Additionally, a novel node distribution scheme further improves our system's scalability. Our approach is not only efficient but also cost-effective. Only half-dozen render nodes are anticipated to support hundreds of active tool sessions on the nanoHUB. Moreover, this architecture and visual analytics environment provides capabilities that can serve many areas of scientific simulation and analysis beyond nanotechnology with its ability to interactively analyze and visualize multivariate scalar and vector fields	Wei Qiao;Michael McLennan;Rick Kennell;David S. Ebert;Gerhard Klimeck	Purdue Univ., West Lafayette, IN|c|;;;;	10.1109/VISUAL.2002.1183758;10.1109/VISUAL.2003.1250377;10.1109/VISUAL.2005.1532795;10.1109/VISUAL.1992.235211;10.1109/VISUAL.2005.1532811;10.1109/VISUAL.2003.1250361;10.1109/VISUAL.2000.885683;10.1109/VISUAL.2005.1532794;10.1109/VISUAL.2005.1532793;10.1109/VISUAL.1994.346315;10.1109/VISUAL.2000.885689	remote visualization, volume visualization, flow visualization, graphics hardware, nanotechnology simulation	
Vis	2006	Hybrid Visualization for White Matter Tracts using Triangle Strips and Point Sprites	10.1109/TVCG.2006.151	http://dx.doi.org/10.1109/TVCG.2006.151	1181	1188	J	Diffusion tensor imaging is of high value in neurosurgery, providing information about the location of white matter tracts in the human brain. For their reconstruction, streamline techniques commonly referred to as fiber tracking model the underlying fiber structures and have therefore gained interest. To meet the requirements of surgical planning and to overcome the visual limitations of line representations, a new real-time visualization approach of high visual quality is introduced. For this purpose, textured triangle strips and point sprites are combined in a hybrid strategy employing GPU programming. The triangle strips follow the fiber streamlines and are textured to obtain a tube-like appearance. A vertex program is used to orient the triangle strips towards the camera. In order to avoid triangle flipping in case of fiber segments where the viewing and segment direction are parallel, a correct visual representation is achieved in these areas by chains of point sprites. As a result, high quality visualization similar to tubes is provided allowing for interactive multimodal inspection. Overall, the presented approach is faster than existing techniques of similar visualization quality and at the same time allows for real-time rendering of dense bundles encompassing a high number of fibers, which is of high importance for diagnosis and surgical planning	Dorit Merhof;Markus Sonntag;Frank Enders;Christopher Nimsky;Peter Hastreiter;Günther Greiner	Dept. of Neurosurgery, Univ. Erlangen|c|;;;;;	10.1109/VISUAL.2005.1532859;10.1109/VISUAL.2005.1532772;10.1109/VISUAL.2002.1183799;10.1109/VISUAL.2005.1532773;10.1109/VISUAL.2005.1532778;10.1109/VISUAL.1996.567777;10.1109/VISUAL.2005.1532779;10.1109/VISUAL.2004.30	Diffusion tensor data, fiber tracking, streamline visualization	
Vis	2006	Importance-Driven Focus of Attention	10.1109/TVCG.2006.152	http://dx.doi.org/10.1109/TVCG.2006.152	933	940	J	This paper introduces a concept for automatic focusing on features within a volumetric data set. The user selects a focus, i.e., object of interest, from a set of pre-defined features. Our system automatically determines the most expressive view on this feature. A characteristic viewpoint is estimated by a novel information-theoretic framework which is based on the mutual information measure. Viewpoints change smoothly by switching the focus from one feature to another one. This mechanism is controlled by changes in the importance distribution among features in the volume. The highest importance is assigned to the feature in focus. Apart from viewpoint selection, the focusing mechanism also steers visual emphasis by assigning a visually more prominent representation. To allow a clear view on features that are normally occluded by other parts of the volume, the focusing for example incorporates cut-away views	Ivan Viola;Miquel Feixas;Mateu Sbert;Eduard Gröller	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol.|c|;;;	10.1109/VISUAL.2005.1532856;10.1109/VISUAL.2005.1532834;10.1109/INFVIS.2001.963286;10.1109/VISUAL.2005.1532833	Illustrative visualization, volume visualization, interacting with volumetric datasets, characteristic viewpoint estimation, focus+context techniques	
Vis	2006	Interactive Point-based Isosurface Exploration and High-quality Rendering	10.1109/TVCG.2006.153	http://dx.doi.org/10.1109/TVCG.2006.153	1267	1274	J	We present an efficient point-based isosurface exploration system with high quality rendering. Our system incorporates two point-based isosurface extraction and visualization methods: edge splatting and the edge kernel method. In a volume, two neighboring voxels define an edge. The intersection points between the active edges and the isosurface are used for exact isosurface representation. The point generation is incorporated in the GPU-based hardware-accelerated rendering, thus avoiding any overhead when changing the isovalue in the exploration. We call this method edge splatting. In order to generate high quality isosurface rendering regardless of the volume resolution and the view, we introduce an edge kernel method. The edge kernel upsamples the isosurface by subdividing every active cell of the volume data. Enough sample points are generated to preserve the exact shape of the isosurface defined by the trilinear interpolation of the volume data. By employing these two methods, we can achieve interactive isosurface exploration with high quality rendering	Haitao Zhang;Arie E. Kaufman	Stony Brook Univ., NY|c|;	10.1109/VISUAL.1998.745713;10.1109/VISUAL.2004.29;10.1109/VISUAL.1996.568121;10.1109/VISUAL.2004.52;10.1109/VISUAL.1998.745300	Isosurface, point-based visualization, isosurface extraction, hardware acceleration, GPU acceleration	
Vis	2006	Interactive Point-Based Rendering of Higher-Order Tetrahedral Data	10.1109/TVCG.2006.154	http://dx.doi.org/10.1109/TVCG.2006.154	1229	1236	J	Computational simulations frequently generate solutions defined over very large tetrahedral volume meshes containing many millions of elements. Furthermore, such solutions may often be expressed using non-linear basis functions. Certain solution techniques, such as discontinuous Galerkin methods, may even produce non-conforming meshes. Such data is difficult to visualize interactively, as it is far too large to fit in memory and many common data reduction techniques, such as mesh simplification, cannot be applied to non-conforming meshes. We introduce a point-based visualization system for interactive rendering of large, potentially non-conforming, tetrahedral meshes. We propose methods for adaptively sampling points from non-linear solution data and for decimating points at run time to fit GPU memory limits. Because these are streaming processes, memory consumption is independent of the input size. We also present an order-independent point rendering method that can efficiently render volumes on the order of 20 million tetrahedra at interactive rates	Yuan Zhou;Michael Garland	Dept. of Comput. Sci., Illinois Univ., Urbana, IL|c|;	10.1109/VISUAL.2003.1250406;10.1109/VISUAL.2005.1532796;10.1109/VISUAL.2005.1532776;10.1109/VISUAL.2005.1532809;10.1109/VISUAL.2003.1250404;10.1109/VISUAL.2002.1183757;10.1109/VISUAL.2002.1183771;10.1109/VISUAL.2004.91;10.1109/VISUAL.2003.1250390;10.1109/VISUAL.1999.809868;10.1109/VISUAL.2004.38;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2000.885683;10.1109/VISUAL.2002.1183778;10.1109/VISUAL.2005.1532808;10.1109/VISUAL.2003.1250389;10.1109/VISUAL.1995.480790;10.1109/VISUAL.2004.81;10.1109/VISUAL.2005.1532801	Interactive large higher-order tetrahedral volume visualization, point-based visualization	
Vis	2006	Interactive Visualization of Intercluster Galaxy Structures in the Horologium-Reticulum Supercluster	10.1109/TVCG.2006.155	http://dx.doi.org/10.1109/TVCG.2006.155	1149	1156	J	We present GyVe, an interactive visualization tool for understanding structure in sparse three-dimensional (3D) point data. The scientific goal driving the tool's development is to determine the presence of filaments and voids as defined by inferred 3D galaxy positions within the horologium-reticulum supercluster (HRS). GyVe provides visualization techniques tailored to examine structures defined by the intercluster galaxies. Specific techniques include: interactive user control to move between a global overview and local viewpoints, labelled axes and curved drop lines to indicate positions in the astronomical RA-DEC-cz coordinate system, torsional rocking and stereo to enhance 3D perception, and geometrically distinct glyphs to show potential correlation between intercluster galaxies and known clusters. We discuss the rationale for each design decision and review the success of the techniques in accomplishing the scientific goals. In practice, GyVe has been useful for gaining intuition about structures that were difficult to perceive with 2D projection techniques alone. For example, during their initial session with GyVe, our collaborators quickly confirmed scientific conclusions regarding the large-scale structure of the HRS previously obtained over months of study with 2D projections and statistical techniques. Further use of GyVe revealed the spherical shape of voids and showed that a presumed filament was actually two disconnected structures	Jameson Miller;Cory Quammen;Matthew Fleenor	Dept of Comput. Sci., North Carolina Univ., Chapel Hill, NC|c|;;	10.1109/VISUAL.1992.235181;10.1109/VISUAL.2002.1183824;10.1109/VISUAL.2003.1250404	Sparse point visualization, astronomy, cosmology	
Vis	2006	Isosurface Extraction and Spatial filtering using Persistent Octree (POT)	10.1109/TVCG.2006.157	http://dx.doi.org/10.1109/TVCG.2006.157	1283	1290	J	We propose a novel persistent octree (POT) indexing structure for accelerating isosurface extraction and spatial filtering from volumetric data. This data structure efficiently handles a wide range of visualization problems such as the generation of view-dependent isosurfaces, ray tracing, and isocontour slicing for high dimensional data. POT can be viewed as a hybrid data structure between the interval tree and the branch-on-need octree (BONO) in the sense that it achieves the asymptotic bound of the interval tree for identifying the active cells corresponding to an isosurface and is more efficient than BONO for handling spatial queries. We encode a compact octree for each isovalue. Each such octree contains only the corresponding active cells, in such a way that the combined structure has linear space. The inherent hierarchical structure associated with the active cells enables very fast filtering of the active cells based on spatial constraints. We demonstrate the effectiveness of our approach by performing view-dependent isosurfacing on a wide variety of volumetric data sets and 4D isocontour slicing on the time-varying Richtmyer-Meshkov instability dataset	Qingmin Shi;Joseph JáJá	Dept. of Electr. & Comput. Eng., Maryland Univ., College Park, MD|c|;	10.1109/VISUAL.1998.745713;10.1109/VISUAL.1991.175780;10.1109/VISUAL.1998.745299;10.1109/VISUAL.1996.568121;10.1109/VISUAL.1999.809910;10.1109/VISUAL.2002.1183810;10.1109/VISUAL.1998.745298;10.1109/VISUAL.1999.809879;10.1109/VISUAL.2004.52;10.1109/VISUAL.1998.745300;10.1109/VISUAL.2003.1250373	scientific visualization, isosurface extraction, indexing	
Vis	2006	Lines of Curvature for Polyp Detection in Virtual Colonoscopy	10.1109/TVCG.2006.158	http://dx.doi.org/10.1109/TVCG.2006.158	885	892	J	Computer-aided diagnosis (CAD) is a helpful addition to laborious visual inspection for preselection of suspected colonic polyps in virtual colonoscopy. Most of the previous work on automatic polyp detection makes use of indicators based on the scalar curvature of the colon wall and can result in many false-positive detections. Our work tries to reduce the number of false-positive detections in the preselection of polyp candidates. Polyp surface shape can be characterized and visualized using lines of curvature. In this paper, we describe techniques for generating and rendering lines of curvature on surfaces and we show that these lines can be used as part of a polyp detection approach. We have adapted existing approaches on explicit triangular surface meshes, and developed a new algorithm on implicit surfaces embedded in 3D volume data. The visualization of shaded colonic surfaces can be enhanced by rendering the derived lines of curvature on these surfaces. Features strongly correlated with true-positive detections were calculated on lines of curvature and used for the polyp candidate selection. We studied the performance of these features on 5 data sets that included 331 pre-detected candidates, of which 50 sites were true polyps. The winding angle had a significant discriminating power for true-positive detections, which was demonstrated by a Wilcoxon rank sum test with p<0.001. The median winding angle and inter-quartile range (IQR) for true polyps were 7.817 and 6.770-9.288 compared to 2.954 and 1.995-3.749 for false-positive detections	Lingxiao Zhao;Charl P. Botha;Javier Bescos;Roel Truyen;Frans Vos;Frits H. Post	Data Visualization Group, Delft Univ. of Technol.|c|;;;;;	10.1109/VISUAL.2005.1532832;10.1109/VISUAL.2000.885690;10.1109/VISUAL.2002.1183789;10.1109/VISUAL.1995.480795	Medical visualization, virtual colonoscopy, polyp detection, line of curvature, implicit surface	
Vis	2006	LOD Map - A Visual Interface for Navigating Multiresolution Volume Visualization	10.1109/TVCG.2006.159	http://dx.doi.org/10.1109/TVCG.2006.159	1029	1036	J	In multiresolution volume visualization, a visual representation of level-of-detail (LOD) quality is important for us to examine, compare, and validate different LOD selection algorithms. While traditional methods rely on ultimate images for quality measurement, we introduce the LOD map - an alternative representation of LOD quality and a visual interface for navigating multiresolution data exploration. Our measure for LOD quality is based on the formulation of entropy from information theory. The measure takes into account the distortion and contribution of multiresolution data blocks. A LOD map is generated through the mapping of key LOD ingredients to a treemap representation. The ordered treemap layout is used for relative stable update of the LOD map when the view or LOD changes. This visual interface not only indicates the quality of LODs in an intuitive way, but also provides immediate suggestions for possible LOD improvement through visually-striking features. It also allows us to compare different views and perform rendering budget control. A set of interactive techniques is proposed to make the LOD adjustment a simple and easy task. We demonstrate the effectiveness and efficiency of our approach on large scientific and medical data sets	Chaoli Wang;Han-Wei Shen	Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH|c|;	10.1109/VISUAL.1999.809871;10.1109/VISUAL.1999.809908;10.1109/VISUAL.2001.964519;10.1109/VISUAL.1995.480812;10.1109/VISUAL.2005.1532781;10.1109/VISUAL.2005.1532833;10.1109/INFVIS.2001.963283;10.1109/VISUAL.2005.1532834;10.1109/VISUAL.2002.1183757;10.1109/VISUAL.1997.663869;10.1109/VISUAL.2002.1183791;10.1109/VISUAL.1992.235230;10.1109/VISUAL.1997.663875	LOD map, knowledge representation, perceptual reasoning, multiresolution rendering, large volume visualization	
Vis	2006	Mesh Layouts for Block-Based Caches	10.1109/TVCG.2006.162	http://dx.doi.org/10.1109/TVCG.2006.162	1213	1220	J	Current computer architectures employ caching to improve the performance of a wide variety of applications. One of the main characteristics of such cache schemes is the use of block fetching whenever an uncached data element is accessed. To maximize the benefit of the block fetching mechanism, we present novel cache-aware and cache-oblivious layouts of surface and volume meshes that improve the performance of interactive visualization and geometric processing algorithms. Based on a general I/O model, we derive new cache-aware and cache-oblivious metrics that have high correlations with the number of cache misses when accessing a mesh. In addition to guiding the layout process, our metrics can be used to quantify the quality of a layout, e.g. for comparing different layouts of the same mesh and for determining whether a given layout is amenable to significant improvement. We show that layouts of unstructured meshes optimized for our metrics result in improvements over conventional layouts in the performance of visualization applications such as isosurface extraction and view-dependent rendering. Moreover, we improve upon recent cache-oblivious mesh layouts in terms of performance, applicability, and accuracy	Sung-Eui Yoon;Peter Lindstrom	Lawrence Livermore Nat. Lab., Berkeley, CA|c|;	10.1109/VISUAL.2004.86;10.1109/VISUAL.2003.1250408;10.1109/VISUAL.2001.964533;10.1109/VISUAL.1996.568125;10.1109/VISUAL.2005.1532800;10.1109/VISUAL.2002.1183794	Mesh and graph layouts, cache-aware and cache-oblivious layouts, metrics for cache coherence, data locality	
Vis	2006	Multi-variate, Time Varying, and Comparative Visualization with Contextual Cues	10.1109/TVCG.2006.164	http://dx.doi.org/10.1109/TVCG.2006.164	909	916	J	Time-varying, multi-variate, and comparative data sets are not easily visualized due to the amount of data that is presented to the user at once. By combining several volumes together with different operators into one visualized volume, the user is able to compare values from different data sets in space over time, run, or field without having to mentally switch between different renderings of individual data sets. In this paper, we propose using a volume shader where the user is given the ability to easily select and operate on many data volumes to create comparison relationships. The user specifies an expression with set and numerical operations and her data to see relationships between data fields. Furthermore, we render the contextual information of the volume shader by converting it to a volume tree. We visualize the different levels and nodes of the volume tree so that the user can see the results of suboperations. This gives the user a deeper understanding of the final visualization, by seeing how the parts of the whole are operationally constructed	Jonathan Woodring;Han-Wei Shen	Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH|c|;	10.1109/VISUAL.1993.398869;10.1109/VISUAL.2005.1532856;10.1109/VISUAL.2004.95;10.1109/VISUAL.2000.885694;10.1109/VISUAL.2003.1250402;10.1109/VISUAL.1992.235222	multi-variate, time-varying, comparative, focus + context	
Vis	2006	Multifield-Graphs: An Approach to Visualizing Correlations in Multifield Scalar Data	10.1109/TVCG.2006.165	http://dx.doi.org/10.1109/TVCG.2006.165	917	924	J	We present an approach to visualizing correlations in 3D multifield scalar data. The core of our approach is the computation of correlation fields, which are scalar fields containing the local correlations of subsets of the multiple fields. While the visualization of the correlation fields can be done using standard 3D volume visualization techniques, their huge number makes selection and handling a challenge. We introduce the multifield-graph to give an overview of which multiple fields correlate and to show the strength of their correlation. This information guides the selection of informative correlation fields for visualization. We use our approach to visually analyze a number of real and synthetic multifield datasets	Natascha Sauber;Holger Theisel;Hans-Peter Seidel	Max-Planck-Inst. fur Inf., Saarbrucken|c|;;	10.1109/VISUAL.1999.809865;10.1109/VISUAL.2004.68;10.1109/VISUAL.2004.46;10.1109/VISUAL.1999.809905;10.1109/VISUAL.2003.1250362	Visualization, multifield, correlation	
Vis	2006	Occlusion-Free Animation of Driving Routes for Car Navigation Systems	10.1109/TVCG.2006.167	http://dx.doi.org/10.1109/TVCG.2006.167	1141	1148	J	This paper presents a method for occlusion-free animation of geographical landmarks, and its application to a new type of car navigation system in which driving routes of interest are always visible. This is achieved by animating a nonperspective image where geographical landmarks such as mountain tops and roads are rendered as if they are seen from different viewpoints. The technical contribution of this paper lies in formulating the nonperspective terrain navigation as an inverse problem of continuously deforming a 3D terrain surface from the 2D screen arrangement of its associated geographical landmarks. The present approach provides a perceptually reasonable compromise between the navigation clarity and visual realism where the corresponding nonperspective view is fully augmented by assigning appropriate textures and shading effects to the terrain surface according to its geometry. An eye tracking experiment is conducted to prove that the present approach actually exhibits visually-pleasing navigation frames while users can clearly recognize the shape of the driving route without occlusion, together with the spatial configuration of geographical landmarks in its neighborhood	Shigeo Takahashi;Kenichi Yoshida;Kenji Shimada;Tomoyuki Nishita	Tokyo Univ., Chiba|c|;;;	10.1109/INFVIS.1997.636786;10.1109/VISUAL.2005.1532818	car navigation systems, nonperspective projection, occlusion-free animation, visual perception, temporal coherence	
Vis	2006	On Histograms and Isosurface Statistics	10.1109/TVCG.2006.168	http://dx.doi.org/10.1109/TVCG.2006.168	1259	1266	J	In this paper, we show that histograms represent spatial function distributions with a nearest neighbour interpolation. We confirm that this results in systematic underrepresentation of transitional features of the data, and provide new insight why this occurs. We further show that isosurface statistics, which use higher quality interpolation, give better representations of the function distribution. We also use our experimentally collected isosurface statistics to resolve some questions as to the formal complexity of isosurfaces	Hamish Carr;Brian Duffy;Brian Denby	Univ. Coll. Dublin|c|;;	10.1109/VISUAL.1994.346334;10.1109/VISUAL.2001.964519;10.1109/VISUAL.1994.346331;10.1109/VISUAL.1991.175782;10.1109/VISUAL.2001.964515;10.1109/VISUAL.2001.964516;10.1109/VISUAL.1997.663875	histograms, isosurfaces, isosurface statistics	
Vis	2006	Out-of-Core Remeshing of Large Polygonal Meshes	10.1109/TVCG.2006.169	http://dx.doi.org/10.1109/TVCG.2006.169	1221	1228	J	We propose an out-of-core method for creating semi-regular surface representations from large input surface meshes. Our approach is based on a streaming implementation of the MAPS remesher of Lee et al. Our remeshing procedure consists of two stages. First, a simplification process is used to obtain the base domain. During simplification, we maintain the mapping information between the input and the simplified meshes. The second stage of remeshing uses the mapping information to produce samples of the output semi-regular mesh. The out-of-core operation of our method is enabled by the synchronous streaming of a simplified mesh and the mapping information stored at the original vertices. The synchronicity of two streaming buffers is maintained using a specially designed write strategy for each buffer. Experimental results demonstrate the remeshing performance of the proposed method, as well as other applications that use the created mapping between the simplified and the original surface representations	Minsu Ahn;Igor Guskov;Seungyong Lee	Pohang Univ. of Sci. & Technol.|c|;;	10.1109/VISUAL.2001.964503;10.1109/VISUAL.2003.1250408;10.1109/VISUAL.2005.1532800;10.1109/VISUAL.1998.745282;10.1109/VISUAL.2001.964532	Out-of-core algorithm, semi-regular remeshing, shape compression	
Vis	2006	Outlier-Preserving Focus+Context Visualization in Parallel Coordinates	10.1109/TVCG.2006.170	http://dx.doi.org/10.1109/TVCG.2006.170	893	900	J	Focus+context visualization integrates a visually accentuated representation of selected data items in focus (more details, more opacity, etc.) with a visually deemphasized representation of the rest of the data, i.e., the context. The role of context visualization is to provide an overview of the data for improved user orientation and improved navigation. A good overview comprises the representation of both outliers and trends. Up to now, however, context visualization not really treated outliers sufficiently. In this paper we present a new approach to focus+context visualization in parallel coordinates which is truthful to outliers in the sense that small-scale features are detected before visualization and then treated specially during context visualization. Generally, we present a solution which enables context visualization at several levels of abstraction, both for the representation of outliers and trends. We introduce outlier detection and context generation to parallel coordinates on the basis of a binned data representation. This leads to an output-oriented visualization approach which means that only those parts of the visualization process are executed which actually affect the final rendering. Accordingly, the performance of this solution is much more dependent on the visualization size than on the data size which makes it especially interesting for large datasets. Previous approaches are outperformed, the new solution was successfully applied to datasets with up to 3 million data records and up to 50 dimensions	Matej Novotny;Helwig Hauser	Comenius Univ., Bratislava|c|;	10.1109/INFVIS.1997.636793;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2002.1173156;10.1109/VISUAL.1996.567800;10.1109/INFVIS.2005.1532138;10.1109/VISUAL.1990.146402	Parallel coordinates, focus+context visualization, outliers & trends, large data visualization	
Vis	2006	Progressive Volume Rendering of Large Unstructured Grids	10.1109/TVCG.2006.171	http://dx.doi.org/10.1109/TVCG.2006.171	1307	1314	J	We describe a new progressive technique that allows real-time rendering of extremely large tetrahedral meshes. Our approach uses a client-server architecture to incrementally stream portions of the mesh from a server to a client which refines the quality of the approximate rendering until it converges to a full quality rendering. The results of previous steps are re-used in each subsequent refinement, thus leading to an efficient rendering. Our novel approach keeps very little geometry on the client and works by refining a set of rendered images at each step. Our interactive representation of the dataset is efficient, light-weight, and high quality. We present a framework for the exploration of large datasets stored on a remote server with a thin client that is capable of rendering and managing full quality volume visualizations	Steven P. Callahan;Louis Bavoil;Valerio Pascucci;Cláudio T. Silva	Sci. Comput. & Imaging Inst., Utah Univ., Salt Lake City, UT|c|;;;	10.1109/VISUAL.2005.1532796;10.1109/VISUAL.1998.745713;10.1109/VISUAL.2003.1250390;10.1109/VISUAL.2004.102;10.1109/VISUAL.2005.1532793	Volume Rendering, Large Unstructured Grids, Client-Server, Progressive Rendering, Level-of-Detail	
Vis	2006	Real-Time Illustration of Vascular Structures	10.1109/TVCG.2006.172	http://dx.doi.org/10.1109/TVCG.2006.172	877	884	J	We present real-time vascular visualization methods, which extend on illustrative rendering techniques to particularly accentuate spatial depth and to improve the perceptive separation of important vascular properties such as branching level and supply area. The resulting visualization can and has already been used for direct projection on a patient's organ in the operation theater where the varying absorption and reflection characteristics of the surface limit the use of color. The important contributions of our work are a GPU-based hatching algorithm for complex tubular structures that emphasizes shape and depth as well as GPU-accelerated shadow-like depth indicators, which enable reliable comparisons of depth distances in a static monoscopic 3D visualization. In addition, we verify the expressiveness of our illustration methods in a large, quantitative study with 160 subjects	Felix Ritter;Christian Hansen 0001;Volker Dicken;Olaf Konrad-Verse;Bernhard Preim;Heinz-Otto Peitgen	MeVis GmbH|c|;;;;;	10.1109/VISUAL.2005.1532782;10.1109/VISUAL.2005.1532859;10.1109/VISUAL.2003.1250394;10.1109/VISUAL.2005.1532835;10.1109/VISUAL.2001.964538;10.1109/INFVIS.2003.1249022;10.1109/VISUAL.2005.1532855	Vessel visualization, functional realism, illustrative rendering, spatial perception, evaluation	
Vis	2006	Representing Higher-Order Singularities in Vector fields on Piecewise Linear Surfaces	10.1109/TVCG.2006.173	http://dx.doi.org/10.1109/TVCG.2006.173	1315	1322	J	Accurately representing higher-order singularities of vector fields defined on piecewise linear surfaces is a non-trivial problem. In this work, we introduce a concise yet complete interpolation scheme of vector fields on arbitrary triangulated surfaces. The scheme enables arbitrary singularities to be represented at vertices. The representation can be considered as a facet-based "encoding" of vector fields on piecewise linear surfaces. The vector field is described in polar coordinates over each facet, with a facet edge being chosen as the reference to define the angle. An integer called the period jump is associated to each edge of the triangulation to remove the ambiguity when interpolating the direction of the vector field between two facets that share an edge. To interpolate the vector field, we first linearly interpolate the angle of rotation of the vectors along the edges of the facet graph. Then, we use a variant of Nielson's side-vertex scheme to interpolate the vector field over the entire surface. With our representation, we remove the bound imposed on the complexity of singularities that a vertex can represent by its connectivity. This bound is a limitation generally exists in vertex-based linear schemes. Furthermore, using our data structure, the index of a vertex of a vector field can be combinatorily determined	Wan-Chiu Li;Bruno Vallet;Nicolas Ray;Bruno Lévy	INRIA-Alice|c|;;;	10.1109/VISUAL.2005.1532776;10.1109/VISUAL.1994.346313;10.1109/VISUAL.2003.1250363;10.1109/VISUAL.2005.1532842;10.1109/VISUAL.1999.809892;10.1109/VISUAL.1999.809897;10.1109/VISUAL.2000.885716;10.1109/VISUAL.2003.1250364	vector field visualization, higher-order singularities, line integral convolution, GPU	
Vis	2006	Saliency-guided Enhancement for Volume Visualization	10.1109/TVCG.2006.174	http://dx.doi.org/10.1109/TVCG.2006.174	925	932	J	Recent research in visual saliency has established a computational measure of perceptual importance. In this paper we present a visual-saliency-based operator to enhance selected regions of a volume. We show how we use such an operator on a user-specified saliency field to compute an emphasis field. We further discuss how the emphasis field can be integrated into the visualization pipeline through its modifications of regional luminance and chrominance. Finally, we validate our work using an eye-tracking-based user study and show that our new saliency enhancement operator is more effective at eliciting viewer attention than the traditional Gaussian enhancement operator	Youngmin Kim;Amitabh Varshney	Maryland Univ., College Park, MD|c|;	10.1109/VISUAL.2003.1250414;10.1109/VISUAL.2003.1250412;10.1109/VISUAL.2000.885694;10.1109/VISUAL.2002.1183777;10.1109/VISUAL.2004.64;10.1109/VISUAL.2000.885696	Saliency, visual attention, perceptual enhancement, volume rendering, non-photorealistic rendering	
Vis	2006	Scalable Data Servers for Large Multivariate Volume Visualization	10.1109/TVCG.2006.175	http://dx.doi.org/10.1109/TVCG.2006.175	1291	1298	J	Volumetric datasets with multiple variables on each voxel over multiple time steps are often complex, especially when considering the exponentially large attribute space formed by the variables in combination with the spatial and temporal dimensions. It is intuitive, practical, and thus often desirable, to interactively select a subset of the data from within that high-dimensional value space for efficient visualization. This approach is straightforward to implement if the dataset is small enough to be stored entirely in-core. However, to handle datasets sized at hundreds of gigabytes and beyond, this simplistic approach becomes infeasible and thus, more sophisticated solutions are needed. In this work, we developed a system that supports efficient visualization of an arbitrary subset, selected by range-queries, of a large multivariate time-varying dataset. By employing specialized data structures and schemes of data distribution, our system can leverage a large number of networked computers as parallel data servers, and guarantees a near optimal load-balance. We demonstrate our system of scalable data servers using two large time-varying simulation datasets	Markus Glatter;Jian Huang;Jinzhu Gao;Colin Mollenhour	Tennessee Univ., TN|c|;;;	10.1109/VISUAL.2005.1532792;10.1109/VISUAL.2005.1532794;10.1109/VISUAL.1999.809910;10.1109/VISUAL.1996.568121;10.1109/VISUAL.2003.1250412;10.1109/VISUAL.2001.964519;10.1109/VISUAL.1998.745311;10.1109/VISUAL.2000.885698	Parallel and distributed volume visualization, large Data Set Visualization, multi-variate Visualization, volume Visualization	
Vis	2006	Scalable WIM: Effective Exploration in Large-scale Astrophysical Environments	10.1109/TVCG.2006.176	http://dx.doi.org/10.1109/TVCG.2006.176	1005	1012	J	Navigating through large-scale virtual environments such as simulations of the astrophysical Universe is difficult. The huge spatial range of astronomical models and the dominance of empty space make it hard for users to travel across cosmological scales effectively, and the problem of wayfinding further impedes the user's ability to acquire reliable spatial knowledge of astronomical contexts. We introduce a new technique called the scalable world-in-miniature (WIM) map as a unifying interface to facilitate travel and wayfinding in a virtual environment spanning gigantic spatial scales: power-law spatial seating enables rapid and accurate transitions among widely separated regions; logarithmically mapped miniature spaces offer a global overview mode when the full context is too large; 3D landmarks represented in the WIM are enhanced by scale, positional, and directional cues to augment spatial context awareness; a series of navigation models are incorporated into the scalable WIM to improve the performance of travel tasks posed by the unique characteristics of virtual cosmic exploration. The scalable WIM user interface supports an improved physical navigation experience and assists pragmatic cognitive understanding of a visualization context that incorporates the features of large-scale astronomy	Yinggang Li;Chi-Wing Fu;Andrew J. Hanson	Indiana Univ., IN|c|;;		Astrophysical visualization, large-scale exploration, interaction techniques, world-in-miniature (WIM)	
Vis	2006	Subjective Quantification of Perceptual Interactions among some 2D Scientific Visualization Methods	10.1109/TVCG.2006.180	http://dx.doi.org/10.1109/TVCG.2006.180	1133	1140	J	We present an evaluation of a parameterized set of 2D icon-based visualization methods where we quantified how perceptual interactions among visual elements affect effective data exploration. During the experiment, subjects quantified three different design factors for each method: the spatial resolution it could represent, the number of data values it could display at each point, and the degree to which it is visually linear. The class of visualization methods includes Poisson-disk distributed icons where icon size, icon spacing, and icon brightness can be set to a constant or coupled to data values from a 2D scalar field. By only coupling one of those visual components to data, we measured filtering interference for all three design factors. Filtering interference characterizes how different levels of the constant visual elements affect the evaluation of the data-coupled element. Our novel experimental methodology allowed us to generalize this perceptual information, gathered using ad-hoc artificial datasets, onto quantitative rules for visualizing real scientific datasets. This work also provides a framework for evaluating visualizations of multi-valued data that incorporate additional visual cues, such as icon orientation or color	Daniel Acevedo Feliz;David H. Laidlaw	Dept. of Comput. Sci., Brown Univ., Providence, RI|c|;	10.1109/INFVIS.1997.636792;10.1109/INFVIS.2000.885092	Perception models, 2D visualization methods, visualization evaluation, perceptual interactions, visual design	
Vis	2006	Superellipsoid-based, Real Symmetric Traceless Tensor Glyphs Motivated by Nematic Liquid Crystal Alignment Visualization	10.1109/TVCG.2006.181	http://dx.doi.org/10.1109/TVCG.2006.181	1197	1204	J	A glyph-based method for visualizing the nematic liquid crystal alignment tensor is introduced. Unlike previous approaches, the glyph is based upon physically-linked metrics, not offsets of the eigenvalues. These metrics, combined with a set of superellipsoid shapes, communicate both the strength of the crystal's uniaxial alignment and the amount of biaxiality. With small modifications, our approach can visualize any real symmetric traceless tensor	T. J. Jankun-Kelly;Ketan Mehta	Dept. of Comput. Sci. & Eng., Mississippi State Univ., MS|c|;	10.1109/TVCG.2006.133;10.1109/VISUAL.2005.1532770;10.1109/VISUAL.2005.1532773;10.1109/TVCG.2006.182	scientific visualization, tensor visualization, symmetric traceless tensor, nematic liquid crystals	
Vis	2006	Techniques for the Visualization of Topological Defect Behavior in Nematic Liquid Crystals	10.1109/TVCG.2006.182	http://dx.doi.org/10.1109/TVCG.2006.182	1323	1328	J	We present visualization tools for analyzing molecular simulations of liquid crystal (LC) behavior. The simulation data consists of terabytes of data describing the position and orientation of every molecule in the simulated system over time. Condensed matter physicists study the evolution of topological defects in these data, and our visualization tools focus on that goal. We first convert the discrete simulation data to a sampled version of a continuous second-order tensor field and then use combinations of visualization methods to simultaneously display combinations of contractions of the tensor data, providing an interactive environment for exploring these complicated data. The system, built using AVS, employs colored cutting planes, colored isosurfaces, and colored integral curves to display fields of tensor contractions including Westin's scalar cl, cp , and cs metrics and the principal eigenvector. Our approach has been in active use in the physics lab for over a year. It correctly displays structures already known; it displays the data in a spatially and temporally smoother way than earlier approaches, avoiding confusing grid effects and facilitating the study of multiple time steps; it extends the use of tools developed for visualizing diffusion tensor data, re-interpreting them in the context of molecular simulations; and it has answered long-standing questions regarding the orientation of molecules around defects and the conformational changes of the defects.	Vadim A. Slavin;Robert Pelcovits;George Loriot;Andrew Callan-Jones;David H. Laidlaw	;;;;	10.1109/VISUAL.1998.745294;10.1109/VISUAL.2004.23	Tensor Visualization, Case Studies, Liquid Crystals, Molecular Modeling	
Vis	2006	Texturing of Layered Surfaces for Optimal Viewing	10.1109/TVCG.2006.183	http://dx.doi.org/10.1109/TVCG.2006.183	1125	1132	J	This paper is a contribution to the literature on perceptually optimal visualizations of layered three-dimensional surfaces. Specifically, we develop guidelines for generating texture patterns, which, when tiled on two overlapped surfaces, minimize confusion in depth-discrimination and maximize the ability to localize distinct features. We design a parameterized texture space and explore this texture space using a "human in the loop" experimental approach. Subjects are asked to rate their ability to identify Gaussian bumps on both upper and lower surfaces of noisy terrain fields. Their ratings direct a genetic algorithm, which selectively searches the texture parameter space to find fruitful areas. Data collected from these experiments are analyzed to determine what combinations of parameters work well and to develop texture generation guidelines. Data analysis methods include ANOVA, linear discriminant analysis, decision trees, and parallel coordinates. To confirm the guidelines, we conduct a post-analysis experiment, where subjects rate textures following our guidelines against textures violating the guidelines. Across all subjects, textures following the guidelines consistently produce high rated textures on an absolute scale, and are rated higher than those that did not follow the guidelines	Alethea Bair;Donald H. House;Colin Ware	Texas A&M Univ., College Station, TX|c|;;	10.1109/VISUAL.2005.1532782;10.1109/INFVIS.2003.1249022	perception, optimal visualization, layered surfaces, human-in-the-loop, genetic algorithm, data mining, linear discriminant analysis, parallel coordinates, decision trees	
Vis	2006	Understanding the Structure of the Turbulent Mixing Layer in Hydrodynamic Instabilities	10.1109/TVCG.2006.186	http://dx.doi.org/10.1109/TVCG.2006.186	1053	1060	J	When a heavy fluid is placed above a light fluid, tiny vertical perturbations in the interface create a characteristic structure of rising bubbles and falling spikes known as Rayleigh-Taylor instability. Rayleigh-Taylor instabilities have received much attention over the past half-century because of their importance in understanding many natural and man-made phenomena, ranging from the rate of formation of heavy elements in supernovae to the design of capsules for Inertial Confinement Fusion. We present a new approach to analyze Rayleigh-Taylor instabilities in which we extract a hierarchical segmentation of the mixing envelope surface to identify bubbles and analyze analogous segmentations of fields on the original interface plane. We compute meaningful statistical information that reveals the evolution of topological features and corroborates the observations made by scientists. We also use geometric tracking to follow the evolution of single bubbles and highlight merge/split events leading to the formation of the large and complex structures characteristic of the later stages. In particular we (i) Provide a formal definition of a bubble; (ii) Segment the envelope surface to identify bubbles; (iii) Provide a multi-scale analysis technique to produce statistical measures of bubble growth; (iv) Correlate bubble measurements with analysis of fields on the interface plane; (v) Track the evolution of individual bubbles over time. Our approach is based on the rigorous mathematical foundations of Morse theory and can be applied to a more general class of applications	David E. Laney;Peer-Timo Bremer;Ajith Mascarenhas;P. Miller;Valerio Pascucci	Lawrence Livermore Nat. Lab., Berkeley, CA|c|;;;;	10.1109/VISUAL.2003.1250376;10.1109/VISUAL.2002.1183772;10.1109/VISUAL.2005.1532842;10.1109/VISUAL.2000.885716;10.1109/VISUAL.2004.96;10.1109/VISUAL.2003.1250408;10.1109/VISUAL.2004.107;10.1109/VISUAL.1999.809907;10.1109/VISUAL.1998.745288;10.1109/VISUAL.2005.1532839	topology, multi-resolution, Morse theory	
Vis	2006	Using Difference Intervals for Time-Varying Isosurface Visualization	10.1109/TVCG.2006.188	http://dx.doi.org/10.1109/TVCG.2006.188	1275	1282	J	We present a novel approach to out-of-core time-varying isosurface visualization. We attempt to interactively visualize time-varying datasets which are too large to fit into main memory using a technique which is dramatically different from existing algorithms. Inspired by video encoding techniques, we examine the data differences between time steps to extract isosurface information. We exploit span space extraction techniques to retrieve operations necessary to update isosurface geometry from neighboring time steps. Because only the changes between time steps need to be retrieved from disk, I/O bandwidth requirements are minimized. We apply temporal compression to further reduce disk access and employ a point-based previewing technique that is refined in idle interaction cycles. Our experiments on computational simulation data indicate that this method is an extremely viable solution to large time-varying isosurface visualization. Our work advances the state-of-the-art by enabling all isosurfaces to be represented by a compact set of operations	Kenneth W. Waters;Christopher S. Co;Kenneth I. Joy	Inst. for Data Anal. & Visualization, California Univ., Davis, CA|c|;;	10.1109/VISUAL.1996.568121;10.1109/VISUAL.1998.745298;10.1109/VISUAL.2004.52;10.1109/VISUAL.2004.29;10.1109/VISUAL.1997.663895;10.1109/VISUAL.1999.809879	Isosurface, time-varying, span space, out-of-core, point-based rendering	
Vis	2006	Using Visual Cues of Contact to Improve Interactive Manipulation of Virtual Objects in Industrial Assembly/Maintenance Simulations	10.1109/TVCG.2006.189	http://dx.doi.org/10.1109/TVCG.2006.189	1013	1020	J	This paper describes a set of visual cues of contact designed to improve the interactive manipulation of virtual objects in industrial assembly/maintenance simulations. These visual cues display information of proximity, contact and effort between virtual objects when the user manipulates a part inside a digital mock-up. The set of visual cues encloses the apparition of glyphs (arrow, disk, or sphere) when the manipulated object is close or in contact with another part of the virtual environment. Light sources can also be added at the level of contact points. A filtering technique is proposed to decrease the number of glyphs displayed at the same time. Various effects - such as change in color, change in size, and deformation of shape - can be applied to the glyphs as a function of proximity with other objects or amplitude of the contact forces. A preliminary evaluation was conducted to gather the subjective preference of a group of participants during the simulation of an automotive assembly operation. The collected questionnaires showed that participants globally appreciated our visual cues of contact. The changes in color appeared to be preferred concerning the display of distances and proximity information. Size changes and deformation effects appeared to be preferred in terms of perception of contact forces between the parts. Last, light sources were selected to focus the attention of the user on the contact areas	Jean Sreng;Anatole Lécuyer;Christine Mégard;Claude Andriot	CEA LSI, Fontenay-aux-Roses|c|;;;	10.1109/VISUAL.2001.964526;10.1109/VISUAL.2000.885692	virtual prototyping, assembly/maintenance simulation, visual cues, glyph, light, contact, proximity, force	
Vis	2006	Visual Signatures in Video Visualization	10.1109/TVCG.2006.194	http://dx.doi.org/10.1109/TVCG.2006.194	1093	1100	J	Video visualization is a computation process that extracts meaningful information from original video data sets and conveys the extracted information to users in appropriate visual representations. This paper presents a broad treatment of the subject, following a typical research pipeline involving concept formulation, system development, a path-finding user study, and a field trial with real application data. In particular, we have conducted a fundamental study on the visualization of motion events in videos. We have, for the first time, deployed flow visualization techniques in video visualization. We have compared the effectiveness of different abstract visual representations of videos. We have conducted a user study to examine whether users are able to learn to recognize visual signatures of motions, and to assist in the evaluation of different visualization techniques. We have applied our understanding and the developed techniques to a set of application video clips. Our study has demonstrated that video visualization is both technically feasible and cost-effective. It has provided the first set of evidence confirming that ordinary users can be accustomed to the visual features depicted in video visualizations, and can learn to recognize visual signatures of a variety of motion events	Min Chen;Ralf P. Botchen;Rudy Hashim;Daniel Weiskopf;Thomas Ertl;Ian M. Thornton	Dept. of Comput. Sci., Swansea Univ.|c|;;;;;	10.1109/VISUAL.2003.1250401;10.1109/VISUAL.1991.175792;10.1109/VISUAL.1995.480819	Video visualization, volume visualization, flow visualization, human factors, user study, visual signatures, video processing, optical flow, GPU rendering	
Vis	2006	Visualization and Analysis of Large Data Collections: a Case Study Applied to Confocal Microscopy Data	10.1109/TVCG.2006.195	http://dx.doi.org/10.1109/TVCG.2006.195	1251	1258	J	In this paper we propose an approach in which interactive visualization and analysis are combined with batch tools for the processing of large data collections. Large and heterogeneous data collections are difficult to analyze and pose specific problems to interactive visualization. Application of the traditional interactive processing and visualization approaches as well as batch processing encounter considerable drawbacks for such large and heterogeneous data collections due to the amount and type of data. Computing resources are not sufficient for interactive exploration of the data and automated analysis has the disadvantage that the user has only limited control and feedback on the analysis process. In our approach, an analysis procedure with features and attributes of interest for the analysis is defined interactively. This procedure is used for offline processing of large collections of data sets. The results of the batch process along with "visual summaries" are used for further analysis. Visualization is not only used for the presentation of the result, but also as a tool to monitor the validity and quality of the operations performed during the batch process. Operations such as feature extraction and attribute calculation of the collected data sets are validated by visual inspection. This approach is illustrated by an extensive case study, in which a collection of confocal microscopy data sets is analyzed	Wim C. de Leeuw;Pernette J. Verschure;Robert van Liere	Swammerdam Inst. for Life Sci.|c|;;	10.1109/VISUAL.1998.745319;10.1109/VISUAL.1990.146378;10.1109/VISUAL.2000.885735;10.1109/VISUAL.2000.885678;10.1109/VISUAL.2005.1532788;10.1109/VISUAL.1996.568136	Biomedical visualization, features in volume data sets, large data set visualization	
Vis	2006	Visualization of fibrous and Thread-like Data	10.1109/TVCG.2006.197	http://dx.doi.org/10.1109/TVCG.2006.197	1165	1172	J	Thread-like structures are becoming more common in modern volumetric data sets as our ability to image vascular and neural tissue at higher resolutions improves. The thread-like structures of neurons and micro-vessels pose a unique problem in visualization since they tend to be densely packed in small volumes of tissue. This makes it difficult for an observer to interpret useful patterns from the data or trace individual fibers. In this paper we describe several methods for dealing with large amounts of thread-like data, such as data sets collected using knife-edge scanning microscopy (KESM) and serial block-face scanning electron microscopy (SBF-SEM). These methods allow us to collect volumetric data from embedded samples of whole-brain tissue. The neuronal and microvascular data that we acquire consists of thin, branching structures extending over very large regions. Traditional visualization schemes are not sufficient to make sense of the large, dense, complex structures encountered. In this paper, we address three methods to allow a user to explore a fiber network effectively. We describe interactive techniques for rendering large sets of neurons using self-orienting surfaces implemented on the GPU. We also present techniques for rendering fiber networks in a way that provides useful information about flow and orientation. Third, a global illumination framework is used to create high-quality visualizations that emphasize the underlying fiber structure. Implementation details, performance, and advantages and disadvantages of each approach are discussed	Zeki Melek;David Mayerich;Cem Yuksel;John Keyser	Dept. of Comput. Sci., Texas A&M Univ., College Station, TX|c|;;;	10.1109/VISUAL.2005.1532859;10.1109/VISUAL.2003.1250399;10.1109/VISUAL.2005.1532780	neuron visualization, GPU acceleration, global illumination, orientation filtering	
Vis	2006	Visualization Tools for Vorticity Transport Analysis in Incompressible Flow	10.1109/TVCG.2006.199	http://dx.doi.org/10.1109/TVCG.2006.199	949	956	J	Vortices are undesirable in many applications while indispensable in others. It is therefore of common interest to understand their mechanisms of creation. This paper aims at analyzing the transport of vorticity inside incompressible flow. The analysis is based on the vorticity equation and is performed along pathlines which are typically started in upstream direction from vortex regions. Different methods for the quantitative and explorative analysis of vorticity transport are presented and applied to CFD simulations of water turbines. Simulation quality is accounted for by including the errors of meshing and convergence into analysis and visualization. The obtained results are discussed and interpretations with respect to engineering questions are given	Filip Sadlo;Ronald Peikert;Mirjam Sick	Comput. Sci. Dept., ETH Zurich|c|;;	10.1109/VISUAL.1996.567807;10.1109/VISUAL.1999.809896;10.1109/VISUAL.2004.128	Flow visualization, vorticity transport, unsteady flow, linked views	
Vis	2006	Vortex Visualization for Practical Engineering Applications	10.1109/TVCG.2006.201	http://dx.doi.org/10.1109/TVCG.2006.201	957	964	J	In order to understand complex vortical flows in large data sets, we must be able to detect and visualize vortices in an automated fashion. In this paper, we present a feature-based vortex detection and visualization technique that is appropriate for large computational fluid dynamics data sets computed on unstructured meshes. In particular, we focus on the application of this technique to visualization of the flow over a serrated wing and the flow field around a spinning missile with dithering canards. We have developed a core line extraction technique based on the observation that vortex cores coincide with local extrema in certain scalar fields. We also have developed a novel technique to handle complex vortex topology that is based on k-means clustering. These techniques facilitate visualization of vortices in simulation data that may not be optimally resolved or sampled. Results are included that highlight the strengths and weaknesses of our approach. We conclude by describing how our approach can be improved to enhance robustness and expand its range of applicability	Monika Jankun-Kelly;Ming Jiang 0005;David S. Thompson;Raghu Machiraju	Computational Simulation & Design Center, Mississippi State Univ., MS|c|;;;	10.1109/VISUAL.1997.663894;10.1109/VISUAL.2002.1183789;10.1109/VISUAL.2005.1532830;10.1109/VISUAL.1998.745296;10.1109/VISUAL.1998.745288;10.1109/VISUAL.1999.809896	Vortex detection, vortex visualization, feature mining	
InfoVis	2007	Toward a Deeper Understanding of the Role of Interaction in Information Visualization	10.1109/TVCG.2007.70515	http://dx.doi.org/10.1109/TVCG.2007.70515	1224	1231	J	Even though interaction is an important part of information visualization (Infovis), it has garnered a relatively low level of attention from the Infovis community. A few frameworks and taxonomies of Infovis interaction techniques exist, but they typically focus on low-level operations and do not address the variety of benefits interaction provides. After conducting an extensive review of Infovis systems and their interactive capabilities, we propose seven general categories of interaction techniques widely used in Infovis: 1) Select, 2) Explore, 3) Reconfigure, 4) Encode, 5) Abstract/Elaborate, 6) Filter, and 7) Connect. These categories are organized around a user's intent while interacting with a system rather than the low-level interaction techniques provided by a system. The categories can act as a framework to help discuss and evaluate interaction techniques and hopefully lay an initial foundation toward a deeper understanding and a science of interaction.	Ji Soo Yi;Youn ah Kang;John T. Stasko;Julie A. Jacko	Georgia Inst. of Technol., Atlanta|c|;;;	10.1109/VISUAL.1994.346302;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.1996.559213;10.1109/VISUAL.1991.175794;10.1109/INFVIS.2005.1532126;10.1109/INFVIS.2000.885091;10.1109/INFVIS.1999.801860;10.1109/INFVIS.2000.885086	Information visualization, interaction, interaction techniques, taxonomy, visual analytics	
InfoVis	2007	VisLink: Revealing Relationships Amongst Visualizations	10.1109/TVCG.2007.70521	http://dx.doi.org/10.1109/TVCG.2007.70521	1192	1199	J	We present VisLink, a method by which visualizations and the relationships between them can be interactively explored. VisLink readily generalizes to support multiple visualizations, empowers inter-representational queries, and enables the reuse of the spatial variables, thus supporting efficient information encoding and providing for powerful visualization bridging. Our approach uses multiple 2D layouts, drawing each one in its own plane. These planes can then be placed and re-positioned in 3D space: side by side, in parallel, or in chosen placements that provide favoured views. Relationships, connections, and patterns between visualizations can be revealed and explored using a variety of interaction techniques including spreading activation and search filters.	Christopher Collins;M. Sheelagh T. Carpendale	Univ. of Toronto, Toronto|c|;	10.1109/VISUAL.2003.1250400;10.1109/VISUAL.1990.146402;10.1109/TVCG.2006.166;10.1109/VISUAL.1991.175815;10.1109/INFVIS.2003.1249008;10.1109/INFVIS.2001.963279;10.1109/TVCG.2006.147	Graph visualization, node-link diagrams, structural comparison, hierarchies, 3D visualization, edge aggregation	
InfoVis	2007	Visual Analysis of Network Traffic for Resource Planning, Interactive Monitoring, and Interpretation of Security Threats	10.1109/TVCG.2007.70522	http://dx.doi.org/10.1109/TVCG.2007.70522	1105	1112	J	The Internet has become a wild place: malicious code is spread on personal computers across the world, deploying botnets ready to attack the network infrastructure. The vast number of security incidents and other anomalies overwhelms attempts at manual analysis, especially when monitoring service provider backbone links. We present an approach to interactive visualization with a case study indicating that interactive visualization can be applied to gain more insight into these large data sets. We superimpose a hierarchy on IP address space, and study the suitability of Treemap variants for each hierarchy level. Because viewing the whole IP hierarchy at once is not practical for most tasks, we evaluate layout stability when eliding large parts of the hierarchy, while maintaining the visibility and ordering of the data of interest.	Florian Mansmann;Daniel A. Keim;Stephen C. North;Brian Rexroad;Daniel Sheleheda	Univ. of Konstanz, Konstanz|c|;;;;	10.1109/VAST.2006.261438;10.1109/INFVIS.2002.1173156;10.1109/INFVIS.2004.57;10.1109/VISUAL.1991.175815	Information visualization, network security, network monitoring, treemap	
InfoVis	2007	Visualizing Causal Semantics Using Animations	10.1109/TVCG.2007.70528	http://dx.doi.org/10.1109/TVCG.2007.70528	1254	1261	J	Michotte's theory of ampliation suggests that causal relationships are perceived by objects animated under appropriate spatiotemporal conditions. We extend the theory of ampliation and propose that the immediate perception of complex causal relations is also dependent on a set of structural and temporal rules. We designed animated representations, based on Michotte's rules, for showing complex causal relationships or causal semantics. In this paper we describe a set of animations for showing semantics such as causal amplification, causal strength, causal dampening, and causal multiplicity. In a two part study we compared the effectiveness of both the static and animated representations. The first study (N=44) asked participants to recall passages that were previously displayed using both types of representations. Participants were 8% more accurate in recalling causal semantics when they were presented using animations instead of static graphs. In the second study (N=112) we evaluated the intuitiveness of the representations. Our results showed that while users were as accurate with the static graphs as with the animations, they were 9% faster in matching the correct causal statements in the animated condition. Overall our results show that animated diagrams that are designed based on perceptual rules such as those proposed by Michotte have the potential to facilitate comprehension of complex causal relations.	Nivedita R. Kadaba;Pourang Irani;Jason Leboe	Univ. of Manitoba, Winnipeg|c|;;	10.1109/INFVIS.2003.1249025	Causality, visualization, semantics, animated graphs, perception, visualizing cause and effect, graph semantics	
InfoVis	2007	Visualizing Changes of Hierarchical Data using Treemaps	10.1109/TVCG.2007.70529	http://dx.doi.org/10.1109/TVCG.2007.70529	1286	1293	J	While the treemap is a popular method for visualizing hierarchical data, it is often difficult for users to track layout and attribute changes when the data evolve over time. When viewing the treemaps side by side or back and forth, there exist several problems that can prevent viewers from performing effective comparisons. Those problems include abrupt layout changes, a lack of prominent visual patterns to represent layouts, and a lack of direct contrast to highlight differences. In this paper, we present strategies to visualize changes of hierarchical data using treemaps. A new treemap layout algorithm is presented to reduce abrupt layout changes and produce consistent visual patterns. Techniques are proposed to effectively visualize the difference and contrast between two treemap snapshots in terms of the map items' colors, sizes, and positions. Experimental data show that our algorithm can achieve a good balance in maintaining a treemap's stability, continuity, readability, and average aspect ratio. A software tool is created to compare treemaps and generate the visualizations. User studies show that the users can better understand the changes in the hierarchy and layout, and more quickly notice the color and size differences using our method.	Ying Tu;Han-Wei Shen	Ohio State Univ., Columbus|c|;	10.1109/INFVIS.1999.801860;10.1109/INFVIS.2005.1532145;10.1109/TVCG.2006.200;10.1109/VISUAL.1991.175815	Treemap, tree comparison, visualize changes, treemap layout algorithm	
InfoVis	2007	A Taxonomy of Clutter Reduction for Information Visualisation	10.1109/TVCG.2007.70535	http://dx.doi.org/10.1109/TVCG.2007.70535	1216	1223	J	Information visualisation is about gaining insight into data through a visual representation. This data is often multivariate and increasingly, the datasets are very large. To help us explore all this data, numerous visualisation applications, both commercial and research prototypes, have been designed using a variety of techniques and algorithms. Whether they are dedicated to geo-spatial data or skewed hierarchical data, most of the visualisations need to adopt strategies for dealing with overcrowded displays, brought about by too much data to fit in too small a display space. This paper analyses a large number of these clutter reduction methods, classifying them both in terms of how they deal with clutter reduction and more importantly, in terms of the benefits and losses. The aim of the resulting taxonomy is to act as a guide to match techniques to problems where different criteria may have different importance, and more importantly as a means to critique and hence develop existing and new techniques.	Geoffrey P. Ellis;Alan J. Dix	Lancaster Univ, Lancaster|c|;	10.1109/INFVIS.2003.1249018;10.1109/INFVIS.2000.885092;10.1109/TVCG.2006.138;10.1109/VISUAL.2005.1532819;10.1109/INFVIS.2003.1249008;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2000.885091;10.1109/VISUAL.1998.745301;10.1109/INFVIS.1997.636789;10.1109/INFVIS.2002.1173156;10.1109/INFVIS.2003.1249019;10.1109/INFVIS.1997.636792;10.1109/INFVIS.1995.528685;10.1109/INFVIS.2004.15;10.1109/TVCG.2006.170	Clutter reduction, information visualisation, occlusion, large datasets, taxonomy	
InfoVis	2007	AdaptiviTree: Adaptive Tree Visualization for Tournament-Style Brackets	10.1109/TVCG.2007.70537	http://dx.doi.org/10.1109/TVCG.2007.70537	1113	1120	J	Online pick'em games, such as the recent NCAA college basketball March Madness tournament, form a large and rapidly growing industry. In these games, players make predictions on a tournament bracket that defines which competitors play each other and how they proceed toward a single champion. Throughout the course of the tournament, players monitor the brackets to track progress and to compare predictions made by multiple players. This is often a complex sense making task. The classic bracket visualization was designed for use on paper and utilizes an incrementally additive system in which the winner of each match-up is rewritten in the next round as the tournament progresses. Unfortunately, this representation requires a significant amount of space and makes it relatively difficult to get a quick overview of the tournament state since competitors take arbitrary paths through the static bracket. In this paper, we present AdaptiviTree, a novel visualization that adaptively deforms the representation of the tree and uses its shape to convey outcome information. AdaptiviTree not only provides a more compact and understandable representation, but also allows overlays that display predictions as well as other statistics. We describe results from a lab study we conducted to explore the efficacy of AdaptiviTree, as well as from a deployment of the system in a recent real-world sports tournament.	Desney S. Tan;Greg Smith;Bongshin Lee;George G. Robertson	Microsoft Res., Redmond|c|;;;	10.1109/INFVIS.2002.1173148;10.1109/INFVIS.2002.1173158;10.1109/INFVIS.1997.636718;10.1109/VAST.2006.261450	Online fantasy sports, tournament, bracket, picks, adaptive tree visualization	
InfoVis	2007	Animated Transitions in Statistical Data Graphics	10.1109/TVCG.2007.70539	http://dx.doi.org/10.1109/TVCG.2007.70539	1240	1247	J	In this paper we investigate the effectiveness of animated transitions between common statistical data graphics such as bar charts, pie charts, and scatter plots. We extend theoretical models of data graphics to include such transitions, introducing a taxonomy of transition types. We then propose design principles for creating effective transitions and illustrate the application of these principles in DynaVis, a visualization system featuring animated data graphics. Two controlled experiments were conducted to assess the efficacy of various transition types, finding that animated transitions can significantly improve graphical perception.	Jeffrey Heer;George G. Robertson	Univ. of California at Berkeley, Berkeley|c|;	10.1109/INFVIS.1999.801854;10.1109/INFVIS.2001.963279;10.1109/INFVIS.2002.1173148	Statistical data graphics, animation, transitions, information visualization, design, experiment	
InfoVis	2007	Browsing Zoomable Treemaps: Structure-Aware Multi-Scale Navigation Techniques	10.1109/TVCG.2007.70540	http://dx.doi.org/10.1109/TVCG.2007.70540	1248	1253	J	Treemaps provide an interesting solution for representing hierarchical data. However, most studies have mainly focused on layout algorithms and paid limited attention to the interaction with treemaps. This makes it difficult to explore large data sets and to get access to details, especially to those related to the leaves of the trees. We propose the notion of zoomable treemaps (ZTMs), an hybridization between treemaps and zoomable user interfaces that facilitates the navigation in large hierarchical data sets. By providing a consistent set of interaction techniques, ZTMs make it possible for users to browse through very large data sets (e.g., 700,000 nodes dispatched amongst 13 levels). These techniques use the structure of the displayed data to guide the interaction and provide a way to improve interactive navigation in treemaps.	Renaud Blanch;Eric Lecolinet	Univ. of Grenoble 1, Grenoble|c|;	10.1109/INFVIS.2004.21;10.1109/INFVIS.2005.1532128;10.1109/INFVIS.2005.1532129;10.1109/INFVIS.2002.1173156;10.1109/INFVIS.2004.46;10.1109/INFVIS.1999.801860;10.1109/TVCG.2006.200;10.1109/INFVIS.2002.1173148;10.1109/INFVIS.2005.1532132	Information visualization, multi-scale interaction, structure-aware navigation, zoomable treemaps	
InfoVis	2007	Casual Information Visualization: Depictions of Data in Everyday Life	10.1109/TVCG.2007.70541	http://dx.doi.org/10.1109/TVCG.2007.70541	1145	1152	J	Information visualization has often focused on providing deep insight for expert user populations and on techniques for amplifying cognition through complicated interactive visual models. This paper proposes a new subdomain for infovis research that complements the focus on analytic tasks and expert use. Instead of work-related and analytically driven infovis, we propose casual information visualization (or casual infovis) as a complement to more traditional infovis domains. Traditional infovis systems, techniques, and methods do not easily lend themselves to the broad range of user populations, from expert to novices, or from work tasks to more everyday situations. We propose definitions, perspectives, and research directions for further investigations of this emerging subfield. These perspectives build from ambient information visualization (Skog et al., 2003), social visualization, and also from artistic work that visualizes information (Viegas and Wattenberg, 2007). We seek to provide a perspective on infovis that integrates these research agendas under a coherent vocabulary and framework for design. We enumerate the following contributions. First, we demonstrate how blurry the boundary of infovis is by examining systems that exhibit many of the putative properties of infovis systems, but perhaps would not be considered so. Second, we explore the notion of insight and how, instead of a monolithic definition of insight, there may be multiple types, each with particular characteristics. Third, we discuss design challenges for systems intended for casual audiences. Finally we conclude with challenges for system evaluation in this emerging subfield.	Zachary Pousman;John T. Stasko;Michael Mateas	Georgia Inst.of Technol, Atlanta|c|;;	10.1109/INFVIS.2005.1532126;10.1109/INFVIS.2004.8;10.1109/INFVIS.2003.1249031;10.1109/INFVIS.2004.59;10.1109/VISUAL.1990.146375	Casual information visualization, ambient infovis, social infovis, editorial, design, evaluation	
InfoVis	2007	Exploring Multiple Trees through DAG Representations	10.1109/TVCG.2007.70556	http://dx.doi.org/10.1109/TVCG.2007.70556	1294	1301	J	We present a directed acyclic graph visualisation designed to allow interaction with a set of multiple classification trees, specifically to find overlaps and differences between groups of trees and individual trees. The work is motivated by the need to find a representation for multiple trees that has the space-saving property of a general graph representation and the intuitive parent-child direction cues present in individual representation of trees. Using example taxonomic data sets, we describe augmentations to the common barycenter DAG layout method that reveal shared sets of child nodes between common parents in a clearer manner. Other interactions such as displaying the multiple ancestor paths of a node when it occurs in several trees, and revealing intersecting sibling sets within the context of a single DAG representation are also discussed.	Martin Graham;Jessie B. Kennedy	Napier Univ, Edinburgh|c|;	10.1109/INFVIS.2005.1532129;10.1109/INFVIS.2002.1173148;10.1109/INFVIS.2002.1173153;10.1109/INFVIS.2000.885091;10.1109/VISUAL.1991.175815;10.1109/INFVIS.2004.70;10.1109/INFVIS.2005.1532152	Multiple trees, Directed Acyclic Graph	
InfoVis	2007	Geographically Weighted Visualization: Interactive Graphics for Scale-Varying Exploratory Analysis	10.1109/TVCG.2007.70558	http://dx.doi.org/10.1109/TVCG.2007.70558	1161	1168	J	We introduce a series of geographically weighted (GW) interactive graphics, or geowigs, and use them to explore spatial relationships at a range of scales. We visually encode information about geographic and statistical proximity and variation in novel ways through gw-choropleth maps, multivariate gw-boxplots, gw-shading and scalograms. The new graphic types reveal information about GW statistics at several scales concurrently. We impement these views in prototype software containing dynamic links and GW interactions that encourage exploration and refine them to consider directional geographies. An informal evaluation uses interactive GW techniques to consider Guerry's dataset of 'moral statistics', casting doubt on correlations originally proposed through visual analysis, revealing new local anomalies and suggesting multivariate geographic relationships. Few attempts at visually synthesising geography with multivariate statistical values at multiple scales have been reported. The geowigs proposed here provide informative representations of multivariate local variation, particularly when combined with interactions that coordinate views and result in gw-shading. We argue that they are widely applicable to area and point-based geographic data and provide a set of methods to support visual analysis using GW statistics through which the effects of geography can be explored at multiple scales.	Jason Dykes;Chris Brunsdon	City Univ., London|c|;		Geographical weighting, exploratory data analysis, scale, multivariate, directional, interaction, coordinated views	
InfoVis	2007	Hotmap: Looking at Geographic Attention	10.1109/TVCG.2007.70561	http://dx.doi.org/10.1109/TVCG.2007.70561	1184	1191	J	Understanding how people use online maps allows data acquisition teams to concentrate their efforts on the portions of the map that are most seen by users. Online maps represent vast databases, and so it is insufficient to simply look at a list of the most-accessed URLs. Hotmap takes advantage of the design of a mapping system's imagery pyramid to superpose a heatmap of the log files over the original maps. Users' behavior within the system can be observed and interpreted. This paper discusses the imagery acquisition task that motivated Hotmap, and presents several examples of information that Hotmap makes visible. We discuss the design choices behind Hotmap, including logarithmic color schemes; low-saturation background images; and tuning images to explore both infrequently-viewed and frequently-viewed spaces.	Danyel Fisher	Microsoft Res., Redmond|c|	10.1109/INFVIS.2005.1532122;10.1109/TVCG.2006.179	Geographical visualization, GIS, heatmap, server log analysis, online mapping systems, social navigation	
InfoVis	2007	Interactive Tree Comparison for Co-located Collaborative Information Visualization	10.1109/TVCG.2007.70568	http://dx.doi.org/10.1109/TVCG.2007.70568	1232	1239	J	In many domains, increased collaboration has lead to more innovation by fostering the sharing of knowledge, skills, and ideas. Shared analysis of information visualizations does not only lead to increased information processing power, but team members can also share, negotiate, and discuss their views and interpretations on a dataset and contribute unique perspectives on a given problem. Designing technologies to support collaboration around information visualizations poses special challenges and relatively few systems have been designed. We focus on supporting small groups collaborating around information visualizations in a co-located setting, using a shared interactive tabletop display. We introduce an analysis of challenges and requirements for the design of co-located collaborative information visualization systems. We then present a new system that facilitates hierarchical data comparison tasks for this type of collaborative work. Our system supports multi-user input, shared and individual views on the hierarchical data visualization, flexible use of representations, and flexible workspace organization to facilitate group work around visualizations.	Petra Isenberg;M. Sheelagh T. Carpendale	Univ. of Calgary, Calgary|c|;	10.1109/INFVIS.2000.885091;10.1109/TVCG.2006.184	Information visualization, collaboration, co-located work, hierarchical data comparison	
InfoVis	2007	Interactive Visual Exploration of a Large Spatio-temporal Dataset: Reflections on a Geovisualization Mashup.	10.1109/TVCG.2007.70570	http://dx.doi.org/10.1109/TVCG.2007.70570	1176	1183	J	Exploratory visual analysis is useful for the preliminary investigation of large structured, multifaceted spatio-temporal datasets. This process requires the selection and aggregation of records by time, space and attribute, the ability to transform data and the flexibility to apply appropriate visual encodings and interactions. We propose an approach inspired by geographical 'mashups' in which freely-available functionality and data are loosely but flexibly combined using de facto exchange standards. Our case study combines MySQL, PHP and the LandSerf GIS to allow Google Earth to be used for visual synthesis and interaction with encodings described in KML. This approach is applied to the exploration of a log of 1.42 million requests made of a mobile directory service. Novel combinations of interaction and visual encoding are developed including spatial 'tag clouds', 'tag maps', 'data dials' and multi-scale density surfaces. Four aspects of the approach are informally evaluated: the visual encodings employed, their success in the visual exploration of the dataset, the specific tools used and the 'mashup' approach. Preliminary findings will be beneficial to others considering using mashups for visualization. The specific techniques developed may be more widely applied to offer insights into the structure of multifarious spatio-temporal data of the type explored here.	Jo Wood;Jason Dykes;Aidan Slingsby;Keith Clarke	City Univ., London|c|;;;	10.1109/INFVIS.1995.528686;10.1109/INFVIS.2004.12	Large dataset visualization, text and document visualization, multiresolution visualization, geographic visualization, applications of infovis	
InfoVis	2007	Legible Cities: Focus-Dependent Multi-Resolution Visualization of Urban Relationships	10.1109/TVCG.2007.70574	http://dx.doi.org/10.1109/TVCG.2007.70574	1169	1175	J	Numerous systems have been developed to display large collections of data for urban contexts; however, most have focused on layering of single dimensions of data and manual calculations to understand relationships within the urban environment. Furthermore, these systems often limit the user's perspectives on the data, thereby diminishing the user's spatial understanding of the viewing region. In this paper, we introduce a highly interactive urban visualization tool that provides intuitive understanding of the urban data. Our system utilizes an aggregation method that combines buildings and city blocks into legible clusters, thus providing continuous levels of abstraction while preserving the user's mental model of the city. In conjunction with a 3D view of the urban model, a separate but integrated information visualization view displays multiple disparate dimensions of the urban data, allowing the user to understand the urban environment both spatially and cognitively in one glance. For our evaluation, expert users from various backgrounds viewed a real city model with census data and confirmed that our system allowed them to gain more intuitive and deeper understanding of the urban model from different perspectives and levels of abstraction than existing commercial urban visualization systems.	Remco Chang;Ginette Wessel;Robert Kosara;Eric Sauda;William Ribarsky	UNC Charlotte, Charlotte|c|;;;;	10.1109/INFVIS.2004.12;10.1109/VISUAL.1990.146402;10.1109/INFVIS.2005.1532149	Urban models, information visualization, multi-resolution	
InfoVis	2007	ManyEyes: a Site for Visualization at Internet Scale	10.1109/TVCG.2007.70577	http://dx.doi.org/10.1109/TVCG.2007.70577	1121	1128	J	We describe the design and deployment of Many Eyes, a public Web site where users may upload data, create interactive visualizations, and carry on discussions. The goal of the site is to support collaboration around visualizations at a large scale by fostering a social style of data analysis in which visualizations not only serve as a discovery tool for individuals but also as a medium to spur discussion among users. To support this goal, the site includes novel mechanisms for end-user creation of visualizations and asynchronous collaboration around those visualizations. In addition to describing these technologies, we provide a preliminary report on the activity of our users.	Fernanda B. Viégas;Martin Wattenberg;Frank van Ham;Jesse Kriss;Matthew M. McKeon	IBM Res., Yorktown Heights|c|;;;;	10.1109/INFVIS.2005.1532122;10.1109/VISUAL.1991.175820;10.1109/INFVIS.2003.1249007	Visualization, World Wide Web, Social Software, Social Data Analysis, Communication-Minded Visualization	
InfoVis	2007	Multi-Level Graph Layout on the GPU	10.1109/TVCG.2007.70580	http://dx.doi.org/10.1109/TVCG.2007.70580	1310	1319	J	This paper presents a new algorithm for force directed graph layout on the GPU. The algorithm, whose goal is to compute layouts accurately and quickly, has two contributions. The first contribution is proposing a general multi-level scheme, which is based on spectral partitioning. The second contribution is computing the layout on the GPU. Since the GPU requires a data parallel programming model, the challenge is devising a mapping of a naturally unstructured graph into a well-partitioned structured one. This is done by computing a balanced partitioning of a general graph. This algorithm provides a general multi-level scheme, which has the potential to be used not only for computation on the GPU, but also on emerging multi-core architectures. The algorithm manages to compute high quality layouts of large graphs in a fraction of the time required by existing algorithms of similar quality. An application for visualization of the topologies of ISP (Internet service provider) networks is presented.	Yaniv Frishman;Ayellet Tal	Israel Inst. of Technol., Haifa|c|;	10.1109/INFVIS.2004.66	Graph layout, GPU, graph partitioning	
InfoVis	2007	NodeTrix: a Hybrid Visualization of Social Networks	10.1109/TVCG.2007.70582	http://dx.doi.org/10.1109/TVCG.2007.70582	1302	1309	J	The need to visualize large social networks is growing as hardware capabilities make analyzing large networks feasible and many new data sets become available. Unfortunately, the visualizations in existing systems do not satisfactorily resolve the basic dilemma of being readable both for the global structure of the network and also for detailed analysis of local communities. To address this problem, we present NodeTrix, a hybrid representation for networks that combines the advantages of two traditional representations: node-link diagrams are used to show the global structure of a network, while arbitrary portions of the network can be shown as adjacency matrices to better support the analysis of communities. A key contribution is a set of interaction techniques. These allow analysts to create a NodeTrix visualization by dragging selections to and from node-link and matrix forms, and to flexibly manipulate the NodeTrix representation to explore the dataset and create meaningful summary visualizations of their findings. Finally, we present a case study applying NodeTrix to the analysis of the InfoVis 2004 coauthorship dataset to illustrate the capabilities of NodeTrix as both an exploration tool and an effective means of communicating results.	Nathalie Henry Riche;Jean-Daniel Fekete;Michael J. McGuffin	Univ. of Sydney, Sydney|c|;;	10.1109/TVCG.2006.160;10.1109/VAST.2006.261426;10.1109/INFVIS.2005.1532126;10.1109/INFVIS.2004.46;10.1109/TVCG.2006.193;10.1109/INFVIS.2005.1532129;10.1109/TVCG.2006.166;10.1109/TVCG.2006.147;10.1109/INFVIS.2004.64;10.1109/INFVIS.2003.1249011	Network visualization, Matrix visualization, Hybrid visualization, Aggregation, Interaction	
InfoVis	2007	Overview Use in Multiple Visual Information Resolution Interfaces	10.1109/TVCG.2007.70583	http://dx.doi.org/10.1109/TVCG.2007.70583	1278	1285	J	In interfaces that provide multiple visual information resolutions (VIR), low-VIR overviews typically sacrifice visual details for display capacity, with the assumption that users can select regions of interest to examine at higher VI Rs. Designers can create low VIRs based on multi-level structure inherent in the data, but have little guidance with single-level data. To better guide design tradeoff between display capacity and visual target perceivability, we looked at overview use in two multiple-VIR interfaces with high-VIR displays either embedded within, or separate from, the overviews. We studied two visual requirements for effective overview and found that participants would reliably use the low-VIR overviews only when the visual targets were simple and had small visual spans. Otherwise, at least 20% chose to use the high-VIR view exclusively. Surprisingly, neither of the multiple-VIR interfaces provided performance benefits when compared to using the high-VIR view alone. However, we did observe benefits in providing side-by-side comparisons for target matching. We conjecture that the high cognitive load of multiple-VIR interface interactions, whether real or perceived, is a more considerable barrier to their effective use than was previously considered.	Heidi Lam;Tamara Munzner;Robert Kincaid	Univ. of British Columbia, Vancouver|c|;;	10.1109/INFVIS.2005.1532136;10.1109/VISUAL.2005.1532838;10.1109/INFVIS.2004.59;10.1109/VISUAL.1990.146375	Multiple resolutions, overview use, user study	
InfoVis	2007	Scented Widgets: Improving Navigation Cues with Embedded Visualizations	10.1109/TVCG.2007.70589	http://dx.doi.org/10.1109/TVCG.2007.70589	1129	1136	J	This paper presents scented widgets, graphical user interface controls enhanced with embedded visualizations that facilitate navigation in information spaces. We describe design guidelines for adding visual cues to common user interface widgets such as radio buttons, sliders, and combo boxes and contribute a general software framework for applying scented widgets within applications with minimal modifications to existing source code. We provide a number of example applications and describe a controlled experiment which finds that users exploring unfamiliar data make up to twice as many unique discoveries using widgets imbued with social navigation data. However, these differences equalize as familiarity with the data increases.	Wesley Willett;Jeffrey Heer;Maneesh Agrawala	Univ. of California, Berkeley|c|;;	10.1109/INFVIS.1999.801862	Information visualization, user interface toolkits, information foraging, social navigation, social data analysis	
InfoVis	2007	Sequential Document Visualization	10.1109/TVCG.2007.70592	http://dx.doi.org/10.1109/TVCG.2007.70592	1208	1215	J	Documents and other categorical valued time series are often characterized by the frequencies of short range sequential patterns such as n-grams. This representation converts sequential data of varying lengths to high dimensional histogram vectors which are easily modeled by standard statistical models. Unfortunately, the histogram representation ignores most of the medium and long range sequential dependencies making it unsuitable for visualizing sequential data. We present a novel framework for sequential visualization of discrete categorical time series based on the idea of local statistical modeling. The framework embeds categorical time series as smooth curves in the multinomial simplex summarizing the progression of sequential trends. We discuss several visualization techniques based on the above framework and demonstrate their usefulness for document visualization.	Yi Mao;Joshua V. Dillon;Guy Lebanon	Purdue Univ., West Lafayette|c|;;	10.1109/VISUAL.1993.398863;10.1109/VISUAL.1998.745302;10.1109/INFVIS.2001.963287;10.1109/INFVIS.2001.963273;10.1109/INFVIS.2000.885097	Document visualization, multi-resolution analysis, local fitting	
InfoVis	2007	Show Me: Automatic Presentation for Visual Analysis	10.1109/TVCG.2007.70594	http://dx.doi.org/10.1109/TVCG.2007.70594	1137	1144	J	This paper describes Show Me, an integrated set of user interface commands and defaults that incorporate automatic presentation into a commercial visual analysis system called Tableau. A key aspect of Tableau is VizQL, a language for specifying views, which is used by Show Me to extend automatic presentation to the generation of tables of views (commonly called small multiple displays). A key research issue for the commercial application of automatic presentation is the user experience, which must support the flow of visual analysis. User experience has not been the focus of previous research on automatic presentation. The Show Me user experience includes the automatic selection of mark types, a command to add a single field to a view, and a pair of commands to build views for multiple fields. Although the use of these defaults and commands is optional, user interface logs indicate that Show Me is used by commercial users.	Jock D. Mackinlay;Pat Hanrahan;Chris Stolte	Tableau Software, Seattle|c|;;	10.1109/INFVIS.2000.885086	Automatic presentation, visual analysis, graphic design, best practices, data visualization, small multiples	
InfoVis	2007	Spatialization Design: Comparing Points and Landscapes	10.1109/TVCG.2007.70596	http://dx.doi.org/10.1109/TVCG.2007.70596	1262	1269	J	Spatializations represent non-spatial data using a spatial layout similar to a map. We present an experiment comparing different visual representations of spatialized data, to determine which representations are best for a non-trivial search and point estimation task. Primarily, we compare point-based displays to 2D and 3D information landscapes. We also compare a colour (hue) scale to a grey (lightness) scale. For the task we studied, point-based spatializations were far superior to landscapes, and 2D landscapes were superior to 3D landscapes. Little or no benefit was found for redundantly encoding data using colour or greyscale combined with landscape height. 3D landscapes with no colour scale (height-only) were particularly slow and inaccurate. A colour scale was found to be better than a greyscale for all display types, but a greyscale was helpful compared to height-only. These results suggest that point-based spatializations should be chosen over landscape representations, at least for tasks involving only point data itself rather than derived information about the data space.	Melanie Tory;David W. Sprague;Fuqu Wu;Wing Yan So;Tamara Munzner	Victoria Univ., Victoria|c|;;;;	10.1109/INFVIS.2004.60;10.1109/INFVIS.2004.19;10.1109/INFVIS.2002.1173146;10.1109/INFVIS.1995.528686	Spatialization, Information Landscape, User Study, Numerosity, 3D, 2D, Colour, Greyscale, Surface, Points	
InfoVis	2007	Visualization of Heterogeneous Data	10.1109/TVCG.2007.70617	http://dx.doi.org/10.1109/TVCG.2007.70617	1200	1207	J	Both the resource description framework (RDF), used in the semantic web, and Maya Viz u-forms represent data as a graph of objects connected by labeled edges. Existing systems for flexible visualization of this kind of data require manual specification of the possible visualization roles for each data attribute. When the schema is large and unfamiliar, this requirement inhibits exploratory visualization by requiring a costly up-front data integration step. To eliminate this step, we propose an automatic technique for mapping data attributes to visualization attributes. We formulate this as a schema matching problem, finding appropriate paths in the data model for each required visualization attribute in a visualization template.	Mike Cammarano;Xin Dong 0001;Bryan Chan;Jeff Klingner;Justin Talbot;Alon Y. Halevy;Pat Hanrahan	Stanford Univ., Stanford|c|;;;;;;	10.1109/INFVIS.2000.885086;10.1109/VISUAL.1994.346302;10.1109/INFVIS.1996.559210	Data integration, RDF, attribute inference	
InfoVis	2007	Visualizing the History of Living Spaces	10.1109/TVCG.2007.70621	http://dx.doi.org/10.1109/TVCG.2007.70621	1153	1160	J	The technology available to building designers now makes it possible to monitor buildings on a very large scale. Video cameras and motion sensors are commonplace in practically every office space, and are slowly making their way into living spaces. The application of such technologies, in particular video cameras, while improving security, also violates privacy. On the other hand, motion sensors, while being privacy-conscious, typically do not provide enough information for a human operator to maintain the same degree of awareness about the space that can be achieved by using video cameras. We propose a novel approach in which we use a large number of simple motion sensors and a small set of video cameras to monitor a large office space. In our system we deployed 215 motion sensors and six video cameras to monitor the 3,000-square-meter office space occupied by 80 people for a period of about one year. The main problem in operating such systems is finding a way to present this highly multidimensional data, which includes both spatial and temporal components, to a human operator to allow browsing and searching recorded data in an efficient and intuitive way. In this paper we present our experiences and the solutions that we have developed in the course of our work on the system. We consider this work to be the first step in helping designers and managers of building systems gain access to information about occupants' behavior in the context of an entire building in a way that is only minimally intrusive to the occupants' privacy.	Yuri A. Ivanov;Christopher Richard Wren;Alexander Sorokin;Ishwinder Kaur	Mitsubuishi Electr. Res. Labs.|c|;;;	10.1109/INFVIS.2004.27;10.1109/INFVIS.2005.1532122	Sensor networks, user interfaces, surveillance, timeline, spatio-temporal visualization	
InfoVis	2007	Weaving Versus Blending: a quantitative assessment of the information carrying capacities of two alternative methods for conveying multivariate data with color.	10.1109/TVCG.2007.70623	http://dx.doi.org/10.1109/TVCG.2007.70623	1270	1277	J	In many applications, it is important to understand the individual values of, and relationships between, multiple related scalar variables defined across a common domain. Several approaches have been proposed for representing data in these situations. In this paper we focus on strategies for the visualization of multivariate data that rely on color mixing. In particular, through a series of controlled observer experiments, we seek to establish a fundamental understanding of the information-carrying capacities of two alternative methods for encoding multivariate information using color: color blending and color weaving. We begin with a baseline experiment in which we assess participants' abilities to accurately read numerical data encoded in six different basic color scales defined in the L*a*b* color space. We then assess participants' abilities to read combinations of 2, 3, 4 and 6 different data values represented in a common region of the domain, encoded using either color blending or color weaving. In color blending a single mixed color is formed via linear combination of the individual values in L*a*b* space, and in color weaving the original individual colors are displayed side-by-side in a high frequency texture that fills the region. A third experiment was conducted to clarify some of the trends regarding the color contrast and its effect on the magnitude of the error that was observed in the second experiment. The results indicate that when the component colors are represented side-by-side in a high frequency texture, most participants' abilities to infer the values of individual components are significantly improved, relative to when the colors are blended. Participants' performance was significantly better with color weaving particularly when more than 2 colors were used, and even when the individual colors subtended only 3 minutes of visual angle in the texture. However, the information-carrying capacity of the color weaving approach has its limits. - - We found that participants' abilities to accurately interpret each of the individual components in a high frequency color texture typically falls off as the number of components increases from 4 to 6. We found no significant advantages, in either color blending or color weaving, to using color scales based on component hues thatare more widely separated in the L*a*b* color space. Furthermore, we found some indications that extra difficulties may arise when opponent hues are employed.	Haleh Hagh-Shenas;Sunghee Kim;Victoria Interrante;Christopher G. Healey	Boston Sci. Corp., Natick|c|;;;	10.1109/INFVIS.2005.1532140;10.1109/VISUAL.2003.1250362;10.1109/VISUAL.1999.809905;10.1109/INFVIS.2005.1532137	Color, perception, visualization, color weaving, color blending	
VAST	2007	InfoVis as Seen by the World Out There: 2007 in Review	10.1109/VAST.2007.4388989	http://dx.doi.org/10.1109/VAST.2007.4388989	x	x	M	How we as insiders see and understand InfoVis is quite different from how it is seen by most people in the world out there. Most people get only glimpses of what we do, and those glimpses rarely tell the story clearly. Think about the view of InfoVis that has been created in 2007 through marketing, blogs, and articles. This view is peppered with misperception. In this presentation, I'll take you on a tour of InfoVis' exposure in 2007: the highlights and the failures that have shaped the world's perception of our beloved and important work. The world needs what we do, but this need remains largely unsatisfied.	Stephen Few	Perceptual Edge, University of California, Berkeley|c|			
VAST	2007	Activity Analysis Using Spatio-Temporal Trajectory Volumes in Surveillance Applications	10.1109/VAST.2007.4388990	http://dx.doi.org/10.1109/VAST.2007.4388990	3	10	C	In this paper, we present a system to analyze activities and detect anomalies in a surveillance application, which exploits the intuition and experience of security and surveillance experts through an easy- to-use visual feedback loop. The multi-scale and location specific nature of behavior patterns in space and time is captured using a wavelet-based feature descriptor. The system learns the fundamental descriptions of the behavior patterns in a semi-supervised fashion by the higher order singular value decomposition of the space described by the training data. This training process is guided and refined by the users in an intuitive fashion. Anomalies are detected by projecting the test data into this multi-linear space and are visualized by the system to direct the attention of the user to potential problem spots. We tested our system on real-world surveillance data, and it satisfied the security concerns of the environment.	Firdaus Janoos;Shantanu Singh;M. Okan Irfanoglu;Raghu Machiraju;Richard E. Parent	Ohio State Univ., Columbus|c|;;;;	10.1109/TVCG.2006.194	wavelets, HOSVD, surveillance, anomaly detection, trajectory	
VAST	2007	FemaRepViz: Automatic Extraction and Geo-Temporal Visualization of FEMA National Situation Updates	10.1109/VAST.2007.4388991	http://dx.doi.org/10.1109/VAST.2007.4388991	11	18	C	An architecture for visualizing information extracted from text documents is proposed. In conformance with this architecture, a toolkit, FemaRepViz, has been implemented to extract and visualize temporal, geospatial, and summarized information from FEMA national update reports. Preliminary tests have shown satisfactory accuracy for FEMARepViz. A central component of the architecture is an entity extractor that extracts named entities like person names, location names, temporal references, etc. FEMARepViz is based on FactXtractor, an entity-extractor that works on text documents. The information extracted using FactXtractor is processed using GeoTagger, a geographical name disambiguation tool based on a novel clustering-based disambiguation algorithm. To extract relationships among entities, we propose a machine-learning based algorithm that uses a novel stripped dependency tree kernel. We illustrate and evaluate the usefulness of our system on the FEMA National Situation Updates. Daily reports are fetched by FEMARepViz from the FEMA website, segmented into coherent sections and each section is classified into one of several known incident types. We use concept Vista, Google maps and Google earth to visualize the events extracted from the text reports and allow the user to interactively filter the topics, locations, and time-periods of interest to create a visual analytics toolkit that is useful for rapid analysis of events reported in a large set of text documents.	Chi-Chun Pan;Prasenjit Mitra	Pennsylvania State Univ., State College|c|;		visual analytics, geo-temporal visualization, text processing, knowledge discovery, geospatial analytics	
VAST	2007	Stories in GeoTime	10.1109/VAST.2007.4388992	http://dx.doi.org/10.1109/VAST.2007.4388992	19	26	C	A story is a powerful abstraction used by intelligence analysts to conceptualize threats and understand patterns as part of the analytical process. This paper demonstrates a system that detects geo-temporal patterns and integrates story narration to increase analytic sense-making cohesion in GeoTime. The GeoTime geo-temporal event visualization tool was augmented with a story system that uses narratives, hypertext linked visualizations, visual annotations, and pattern detection to create an environment for analytic exploration and communication, thereby assisting the analyst in identifying, extracting, arranging and presenting stories within the data The story system lets analysts operate at the story level with higher-level abstractions of data, such as behaviors and events, while staying connected to the evidence. The story system was developed and evaluated in collaboration with analysts.	Ryan Eccles;Thomas Kapler;Robert Harper 0002;William Wright	Oculus Info. Inc., Toronto|c|;;;	10.1109/INFVIS.2004.27;10.1109/VAST.2006.261436	human information interaction, visual analytics, sense-making, narrative, pattern detection, story making, story telling	
VAST	2007	LAHVA: Linked Animal-Human Health Visual Analytics	10.1109/VAST.2007.4388993	http://dx.doi.org/10.1109/VAST.2007.4388993	27	34	C	Coordinated animal-human health monitoring can provide an early warning system with fewer false alarms for naturally occurring disease outbreaks, as well as biological, chemical and environmental incidents. This monitoring requires the integration and analysis of multi-field, multi-scale and multi-source data sets. In order to better understand these data sets, models and measurements at different resolutions must be analyzed. To facilitate these investigations, we have created an application to provide a visual analytics framework for analyzing both human emergency room data and veterinary hospital data. Our integrated visual analytic tool links temporally varying geospatial visualization of animal and human patient health information with advanced statistical analysis of these multi-source data. Various statistical analysis techniques have been applied in conjunction with a spatio-temporal viewing window. Such an application provides researchers with the ability to visually search the data for clusters in both a statistical model view and a spatio-temporal view. Our interface provides a factor specification/filtering component to allow exploration of causal factors and spread patterns. In this paper, we will discuss the application of our linked animal-human visual analytics (LAHVA) tool to two specific case studies. The first case study is the effect of seasonal influenza and its correlation with different companion animals (e.g., cats, dogs) syndromes. Here we use data from the Indiana Network for Patient Care (INPC) and Banfield Pet Hospitals in an attempt to determine if there are correlations between respiratory syndromes representing the onset of seasonal influenza in humans and general respiratory syndromes in cats and dogs. Our second case study examines the effect of the release of industrial wastewater in a community through companion animal surveillance.	Ross Maciejewski;Benjamin Tyner;Yun Jang;Cheng Zheng;Rimma V. Nehme;David S. Ebert;William S. Cleveland;Mourad Ouzzani;Shaun J. Grannis;Lawrence T. Glickman	Purdue Univ. Regional Visualization & Analytics Center (PURVAC), West Lafayette|c|;;;;;;;;;			
VAST	2007	Visual Analytics on Mobile Devices for Emergency Response	10.1109/VAST.2007.4388994	http://dx.doi.org/10.1109/VAST.2007.4388994	35	42	C	Using mobile devices for visualization provides a ubiquitous environment for accessing information and effective decision making. These visualizations are critical in satisfying the knowledge needs of operators in areas as diverse as education, business, law enforcement, protective services, medical services, scientific discovery, and homeland security. In this paper, we present an efficient and interactive mobile visual analytic system for increased situational awareness and decision making in emergency response and training situations. Our system provides visual analytics with locational scene data within a simple interface tailored to mobile device capabilities. In particular, we focus on processing and displaying sensor network data for first responders. To verify our system, we have used simulated data of The Station nightclub fire evacuation.	SungYe Kim;Yun Jang;Angela Mellema;David S. Ebert;Timothy W. Collins	Purdue Univ., West Lafayette|c|;;;;	10.1109/VAST.2006.261434	mobile visualization, visual analytics, emergency response	
VAST	2007	Visual Analytics Approach to User-Controlled Evacuation Scheduling	10.1109/VAST.2007.4388995	http://dx.doi.org/10.1109/VAST.2007.4388995	43	50	C	Application of the ideas of visual analytics is a promising approach to supporting decision making, in particular, where the problems have geographic (or spatial) and temporal aspects. Visual analytics may be especially helpful in time-critical applications, which pose hard challenges to decision support. We have designed a suite of tools to support transportation-planning tasks such as emergency evacuation of people from a disaster- affected area. The suite combines a tool for automated scheduling based on a genetic algorithm with visual analytics techniques allowing the user to evaluate tool results and direct its work. A transportation schedule, which is generated by the tool, is a complex construct involving geographical space, time, and heterogeneous objects (people and vehicles) with states and positions varying in time. We apply task-analytical approach to design techniques that could effectively support a human planner in the analysis of this complex information H. 1.2 [User/Machine Systems]: Human information processing - Visual Analytics; 1.6.9 [Visualization]: information visualization.	Gennady L. Andrienko;Natalia V. Andrienko;Ulrich Bartling	Fraunhofer Inst., Sankt Augustin|c|;;		Geovisualization, transportation planning, vehicle scheduling, task-centered design, coordinated multiple views	
VAST	2007	Thin Client Visualization	10.1109/VAST.2007.4388996	http://dx.doi.org/10.1109/VAST.2007.4388996	51	58	C	We have developed a Web 2.0 thin client visualization framework called GeoBoosttrade. Our framework focuses on geospatial visualization and using scalable vector graphics (SVG), AJAX, RSS and GeoRSS we have built a complete thin client component set. Our component set provides a rich user experience that is completely browser based. It includes maps, standard business charts, graphs, and time-oriented components. The components are live, interactive, linked, and support real time collaboration.	Stephen G. Eick;M. Andrew Eick;Jesse Fugitt;Brian Horst;Maxim Khailo;Russell A. Lankenau	SSS Res., Inc., Naperville|c|;;;;;		web 20, JavaScript, scalable vector graphics, visualization components, linked view visual analytics	
VAST	2007	IMAS: The Interactive Multigenomic Analysis System	10.1109/VAST.2007.4388997	http://dx.doi.org/10.1109/VAST.2007.4388997	59	66	C	This paper introduces a new Visual Analysis tool named IMAS (Interactive Multigenomic Analysis System), which combines common analysis tools such as Glimmer, BLAST, and Clustal-W into a unified Visual Analytic framework. IMAS displays the primary DNA sequence being analyzed by the biologist in a highly interactive, zoomable visual display. The user may analyze the sequence in a number of ways, and visualize these analyses in a coherent, sequence aligned form, with all related analysis products grouped together. This enables the user to rapidly perform analyses of DNA sequences without the need for tedious and error-prone cutting and pasting of sequence data from text files to and from web-based databases and data analysis services, as is now common practice.	Chris Shaw 0002;Greg A. Dasch;Marina E. Eremeeva	Simon Fraser Univ. Surrey, Surrey|c|;;		Bioinformatics, Visual Analytics	
VAST	2007	Balancing Interactive Data Management of Massive Data with Situational Awareness through Smart Aggregation	10.1109/VAST.2007.4388998	http://dx.doi.org/10.1109/VAST.2007.4388998	67	74	C	Designing a visualization system capable of processing, managing, and presenting massive data sets while maximizing the user's situational awareness (SA) is a challenging, but important, research question in visual analytics. Traditional data management and interactive retrieval approaches have often focused on solving the data overload problem at the expense of the user's SA. This paper discusses various data management strategies and the strengths and limitations of each approach in providing the user with SA. A new data management strategy, coined Smart Aggregation, is presented as a powerful approach to overcome the challenges of both massive data sets and maintaining SA. By combining automatic data aggregation with user-defined controls on what, how, and when data should be aggregated, we present a visualization system that can handle massive amounts of data while affording the user with the best possible SA. This approach ensures that a system is always usable in terms of both system resources and human perceptual resources. We have implemented our Smart Aggregation approach in a visual analytics system called VIAssist (Visual Assistant for Information Assurance Analysis) to facilitate exploration, discovery, and SA in the domain of Information Assurance.	Daniel R. Tesone;John R. Goodall	Appl. Visions Inc., Sacramento|c|;	10.1109/VAST.2006.261437;10.1109/VISUAL.2005.1532792;10.1109/INFVIS.2004.10	Data management, visual analytics, data retrieval, information visualization, smart aggregation, situational awareness	
VAST	2007	ClusterSculptor: A Visual Analytics Tool for High-Dimensional Data	10.1109/VAST.2007.4388999	http://dx.doi.org/10.1109/VAST.2007.4388999	75	82	C	Cluster analysis (CA) is a powerful strategy for the exploration of high-dimensional data in the absence of a-priori hypotheses or data classification models, and the results of CA can then be used to form such models. But even though formal models and classification rules may not exist in these data exploration scenarios, domain scientists and experts generally have a vast amount of non-compiled knowledge and intuition that they can bring to bear in this effort. In CA, there are various popular mechanisms to generate the clusters, however, the results from their non- supervised deployment rarely fully agree with this expert knowledge and intuition. To this end, our paper describes a comprehensive and intuitive framework to aid scientists in the derivation of classification hierarchies in CA, using k-means as the overall clustering engine, but allowing them to tune its parameters interactively based on a non-distorted compact visual presentation of the inherent characteristics of the data in high- dimensional space. These include cluster geometry, composition, spatial relations to neighbors, and others. In essence, we provide all the tools necessary for a high-dimensional activity we call cluster sculpting, and the evolving hierarchy can then be viewed in a space-efficient radial dendrogram. We demonstrate our system in the context of the mining and classification of a large collection of millions of data items of aerosol mass spectra, but our framework readily applies to any high-dimensional CA scenario.	Eun Ju Nam;Yiping Han;Klaus Mueller;Alla Zelenyuk;Dan Imre	Stony Brook Univ., Stony Brook|c|;;;;	10.1109/VISUAL.1997.663916;10.1109/INFVIS.2004.15;10.1109/INFVIS.1999.801859;10.1109/INFVIS.2004.68;10.1109/VISUAL.1990.146402	Visual Analytics, High-Dimensional Data, Visual Data Mining, Visualization in Earth/Space/ and Environmental Sciences	
VAST	2007	Analysis Guided Visual Exploration of Multivariate Data	10.1109/VAST.2007.4389000	http://dx.doi.org/10.1109/VAST.2007.4389000	83	90	C	Visualization systems traditionally focus on graphical representation of information. They tend not to provide integrated analytical services that could aid users in tackling complex knowledge discovery tasks. Users' exploration in such environments is usually impeded due to several problems: 1) valuable information is hard to discover when too much data is visualized on the screen; 2) Users have to manage and organize their discoveries off line, because no systematic discovery management mechanism exists; 3) their discoveries based on visual exploration alone may lack accuracy; 4) and they have no convenient access to the important knowledge learned by other users. To tackle these problems, it has been recognized that analytical tools must be introduced into visualization systems. In this paper, we present a novel analysis-guided exploration system, called the nugget management system (NMS). It leverages the collaborative effort of human comprehensibility and machine computations to facilitate users' visual exploration processes. Specifically, NMS first extracts the valuable information (nuggets) hidden in datasets based on the interests of users. Given that similar nuggets may be re-discovered by different users, NMS consolidates the nugget candidate set by clustering based on their semantic similarity. To solve the problem of inaccurate discoveries, localized data mining techniques are applied to refine the nuggets to best represent the captured patterns in datasets. Lastly, the resulting well-organized nugget pool is used to guide users' exploration. To evaluate the effectiveness of NMS, we integrated NMS into Xmd- vTool, a freeware multivariate visualization system. User studies were performed to compare the users' efficiency and accuracy in finishing tasks on real datasets, with and without the help of NMS. Our user studies confirmed the effectiveness of NMS.	Di Yang;Elke A. Rundensteiner;Matthew O. Ward	Worcester Polytech. Inst., Worcester|c|;;	10.1109/VISUAL.1994.346302;10.1109/VAST.2006.261415;10.1109/INFVIS.2004.71;10.1109/INFVIS.1997.636793;10.1109/VAST.2006.261430	Visual Analytics, Visual Knowledge Discovery, Discovery Management, Analysis Guided Exploration	
VAST	2007	Intelligent Visual Analytics Queries	10.1109/VAST.2007.4389001	http://dx.doi.org/10.1109/VAST.2007.4389001	91	98	C	Visualizations of large multi-dimensional data sets, occurring in scientific and commercial applications, often reveal interesting local patterns. Analysts want to identify the causes and impacts of these interesting areas, and they also want to search for similar patterns occurring elsewhere in the data set. In this paper we introduce the Intelligent Visual Analytics Query (IVQuery) concept that combines visual interaction with automated analytical methods to support analysts in discovering the special properties and relations of identified patterns. The idea of IVQuery is to interactively select focus areas in the visualization. Then, according to the characteristics of the selected areas, such as the data dimensions and records, IVQuery employs analytical methods to identify the relationships to other portions of the data set. Finally, IVQuery generates visual representations for analysts to view and refine the results. IVQuery has been applied successfully to different real-world data sets, such as data warehouse performance, product sales, and sever performance analysis, and demonstrates the benefits of this technique over traditional filtering and zooming techniques. The visual analytics query technique can be used with many different types of visual representation. In this paper we show how to use IVQuery with parallel coordinates, visual maps, and scatter plots.	Ming C. Hao;Umeshwar Dayal;Daniel A. Keim;D. Morent;Jörn Schneidewind	Hewlett Packard Lab., Palo Alto|c|;;;;	10.1109/TVCG.2006.200;10.1109/INFVIS.1998.729559;10.1109/VISUAL.1990.146402;10.1109/INFVIS.2000.885086;10.1109/VISUAL.1994.346302	Visual Analytics Query, Similarity Queries, Interactive Queries	
VAST	2007	Point Placement by Phylogenetic Trees and its Application to Visual Analysis of Document Collections	10.1109/VAST.2007.4389002	http://dx.doi.org/10.1109/VAST.2007.4389002	99	106	C	The task of building effective representations to visualize and explore collections with moderate to large number of documents is hard. It depends on the evaluation of some distance measure among texts and also on the representation of such relationships in bi- dimensional spaces. In this paper we introduce an alternative approach for building visual maps of documents based on their content similarity, through reconstruction of phylogenetic trees. The tree is capable of representing relationships that allows the user to quickly recover information detected by the similarity metric. For a variety of text collections of different natures we show that we can achieve improved exploration capability and more clear visualization of relationships amongst documents.	Ana M. Cuadros;Fernando Vieira Paulovich;Rosane Minghim;Guilherme P. Telles	Univ. de Sao Paulo, Sao Carlos|c|;;;	10.1109/INFVIS.1995.528686;10.1109/VISUAL.1996.567787	Document Visualization, Multidimensional Visualization, Document Analysis, Text Analytics, Phylogenetic Trees	
VAST	2007	Analyzing Large-Scale News Video Databases to Support Knowledge Visualization and Intuitive Retrieval	10.1109/VAST.2007.4389003	http://dx.doi.org/10.1109/VAST.2007.4389003	107	114	C	In this paper, we have developed a novel framework to enable more effective investigation of large-scale news video database via knowledge visualization. To relieve users from the burdensome exploration of well-known and uninteresting knowledge of news reports, a novel interestingness measurement for video news reports is presented to enable users to find news stories of interest at first glance and capture the relevant knowledge in large-scale video news databases efficiently. Our framework takes advantage of both automatic semantic video analysis and human intelligence by integrating with visualization techniques on semantic video retrieval systems. Our techniques on intelligent news video analysis and knowledge discovery have the capacity to enable more effective visualization and exploration of large-scale news video collections. In addition, news video visualization and exploration can provide valuable feedback to improve our techniques for intelligent news video analysis and knowledge discovery.	Hangzai Luo;Jianping Fan 0001;Jing Yang 0001;William Ribarsky;Shin'ichi Satoh	East China Normal Univ., Shanghai|c|;;;;	10.1109/INFVIS.1998.729570;10.1109/TVCG.2006.179;10.1109/INFVIS.1995.528686;10.1109/INFVIS.2000.885098;10.1109/VAST.2006.261433	Semantic Video Classification, Knowledge Discovery, Knowledge Visualization	
VAST	2007	Literature Fingerprinting: A New Method for Visual Literary Analysis	10.1109/VAST.2007.4389004	http://dx.doi.org/10.1109/VAST.2007.4389004	115	122	C	In computer-based literary analysis different types of features are used to characterize a text. Usually, only a single feature value or vector is calculated for the whole text. In this paper, we combine automatic literature analysis methods with an effective visualization technique to analyze the behavior of the feature values across the text. For an interactive visual analysis, we calculate a sequence of feature values per text and present them to the user as a characteristic fingerprint. The feature values may be calculated on different hierarchy levels, allowing the analysis to be done on different resolution levels. A case study shows several successful applications of our new method to known literature problems and demonstrates the advantage of our new visual literature fingerprinting.	Daniel A. Keim;Daniela Oelke	Univ. of Konstanz, Konstanz|c|;		Visual literature analysis, visual analytics, literature fingerprinting	
VAST	2007	NewsLab: Exploratory Broadcast News Video Analysis	10.1109/VAST.2007.4389005	http://dx.doi.org/10.1109/VAST.2007.4389005	123	130	C	In this paper, we introduce NewsLab, an exploratory visualization approach for the analysis of large scale broadcast news video collections containing many thousands of news stories over extended periods of time. A river metaphor is used to depict the thematic changes of the news over time. An interactive lens metaphor allows the playback of fine-grained video segments selected through the river overview. Multi-resolution navigation is supported via a hierarchical time structure as well as a hierarchical theme structure. Themes can be explored hierarchically according to their thematic structure, or in an unstructured fashion using various ranking criteria. A rich set of interactions such as filtering, drill-down/roll-up navigation, history animation, and keyword based search are also provided. Our case studies show how this set of tools can be used to find emerging topics in the news, compare different broadcasters, or mine the news for topics of interest.	Mohammad Ghoniem;Dongning Luo;Jing Yang 0001;William Ribarsky	UNC Charlotte, Charlotte|c|;;;	10.1109/VAST.2006.261433;10.1109/VAST.2006.261425;10.1109/VISUAL.1996.568118;10.1109/INFVIS.1998.729559;10.1109/INFVIS.1999.801858;10.1109/INFVIS.2005.1532122	Large data exploration, broadcast video analysis, time filtering, clustering, animation, comparative analysis	
VAST	2007	Jigsaw: Supporting Investigative Analysis through Interactive Visualization	10.1109/VAST.2007.4389006	http://dx.doi.org/10.1109/VAST.2007.4389006	131	138	C	Investigative analysts who work with collections of text documents connect embedded threads of evidence in order to formulate hypotheses about plans and activities of potential interest. As the number of documents and the corresponding number of concepts and entities within the documents grow larger, sense-making processes become more and more difficult for the analysts. We have developed a visual analytic system called Jigsaw that represents documents and their entities visually in order to help analysts examine reports more efficiently and develop theories about potential actions more quickly. Jigsaw provides multiple coordinated views of document entities with a special emphasis on visually illustrating connections between entities across the different documents.	John T. Stasko;Carsten Görg;Zhicheng Liu;Kanupriya Singhal	Georgia Inst. of Technol., Atlanta|c|;;;	10.1109/INFVIS.1995.528686;10.1109/INFVIS.2004.27;10.1109/VAST.2006.261432	Visual analytics, investigative analysis, intelligence analysis, information visualization, multiple views	
VAST	2007	SpiralView: Towards Security Policies Assessment through Visual Correlation of Network Resources with Evolution of Alarms	10.1109/VAST.2007.4389007	http://dx.doi.org/10.1109/VAST.2007.4389007	139	146	C	This article presents SpiralView, a visualization tool for helping system administrators to assess network policies. The tool is meant to be a complementary support to the routine activity of network monitoring, enabling a retrospective view on the alarms generated during and extended period of time. The tool permits to reason about how alarms distribute over time and how they correlate with network resources (e.g., users, IPs, applications, etc.), supporting the analysts in understanding how the network evolves and thus in devising new security policies for the future. The spiral visualization plots alarms in time, and, coupled with interactive bar charts and a users/applications graph view, is used to present network data and perform queries. The user is able to segment the data in meaningful subsets, zoom on specific related information, and inspect for relationships between alarms, users, and applications. In designing the visualizations and their interaction, and through tests with security experts, several ameliorations over the standard techniques have been provided.	Enrico Bertini;Patrick Hertzog;Denis Lalanne	Univ. of Fribourg, Fribourg|c|;;	10.1109/INFVIS.2001.963273;10.1109/INFVIS.2001.963279;10.1109/INFVIS.2003.1249020	Network security, Intrusion Detection, Visualization, Data Exploration	
VAST	2007	Session Viewer: Visual Exploratory Analysis of Web Session Logs	10.1109/VAST.2007.4389008	http://dx.doi.org/10.1109/VAST.2007.4389008	147	154	C	Large-scale session log analysis typically includes statistical methods and detailed log examinations. While both methods have merits, statistical methods can miss previously unknown sub- populations in the data and detailed analyses may have selection biases. We therefore built Session Viewer, a visualization tool to facilitate and bridge between statistical and detailed analyses. Taking a multiple-coordinated view approach, Session Viewer shows multiple session populations at the Aggregate, Multiple, and Detail data levels to support different analysis styles. To bridge between the statistical and the detailed analysis levels, Session Viewer provides fluid traversal between data levels and side-by-side comparison at all data levels. We describe an analysis of a large-scale web usage study to demonstrate the use of Session Viewer, where we quantified the importance of grouping sessions based on task type.	Heidi Lam;Daniel M. Russell;Diane Tang;Tamara Munzner	Univ. of British Columbia Google, Vancouver|c|;;;	10.1109/INFVIS.1998.729553;10.1109/INFVIS.2003.1249006;10.1109/INFVIS.2004.2;10.1109/INFVIS.1996.559227	Web session log analysis, visual exploratory data analysis, information visualization	
VAST	2007	WireVis: Visualization of Categorical, Time-Varying Data From Financial Transactions	10.1109/VAST.2007.4389009	http://dx.doi.org/10.1109/VAST.2007.4389009	155	162	C	Large financial institutions such as Bank of America handle hundreds of thousands of wire transactions per day. Although most transactions are legitimate, these institutions have legal and financial obligations in discovering those that are suspicious. With the methods of fraudulent activities ever changing, searching on predefined patterns is often insufficient in detecting previously undiscovered methods. In this paper, we present a set of coordinated visualizations based on identifying specific keywords within the wire transactions. The different views used in our system depict relationships among keywords and accounts over time. Furthermore, we introduce a search-by-example technique which extracts accounts that show similar transaction patterns. In collaboration with the Anti-Money Laundering division at Bank of America, we demonstrate that using our tool, investigators are able to detect accounts and transactions that exhibit suspicious behaviors.	Remco Chang;Mohammad Ghoniem;Robert Kosara;William Ribarsky;Jing Yang 0001;Evan A. Suma;Caroline Ziemkiewicz;Daniel A. Kern;Agus Sudjianto	UNC at Charlotte, Charlotte|c|;;;;;;;;	10.1109/INFVIS.1999.801851;10.1109/INFVIS.1995.528686;10.1109/TVCG.2006.160;10.1109/INFVIS.2004.46	Fraud detection, financial data visualization, categorial and time-varying data	
VAST	2007	Us vs. Them: Understanding Social Dynamics in Wikipedia with Revert Graph Visualizations	10.1109/VAST.2007.4389010	http://dx.doi.org/10.1109/VAST.2007.4389010	163	170	C	Wikipedia is a wiki-based encyclopedia that has become one of the most popular collaborative on-line knowledge systems. As in any large collaborative system, as Wikipedia has grown, conflicts and coordination costs have increased dramatically. Visual analytic tools provide a mechanism for addressing these issues by enabling users to more quickly and effectively make sense of the status of a collaborative environment. In this paper we describe a model for identifying patterns of conflicts in Wikipedia articles. The model relies on users' editing history and the relationships between user edits, especially revisions that void previous edits, known as "reverts". Based on this model, we constructed Revert Graph, a tool that visualizes the overall conflict patterns between groups of users. It enables visual analysis of opinion groups and rapid interactive exploration of those relationships via detail drill- downs. We present user patterns and case studies that show the effectiveness of these techniques, and discuss how they could generalize to other systems.	Bongwon Suh;Ed Huai-hsin Chi;Bryan A. Pendleton;Aniket Kittur	Palo Alto Res. Center, Palo Alto|c|;;;	10.1109/TVCG.2006.122;10.1109/INFVIS.2005.1532126	Wikipedia, wiki, revert, graph, collaboration, user model, visualization	
VAST	2007	Design Considerations for Collaborative Visual Analytics	10.1109/VAST.2007.4389011	http://dx.doi.org/10.1109/VAST.2007.4389011	171	178	C	Information visualization leverages the human visual system to support the process of sensemaking, in which information is collected, organized, and analyzed to generate knowledge and inform action. Though most research to date assumes a single-user focus on perceptual and cognitive processes, in practice, sensemaking is often a social process involving parallelization of effort, discussion, and consensus building. This suggests that to fully support sensemaking, interactive visualization should also support social interaction. However, the most appropriate collaboration mechanisms for supporting this interaction are not immediately clear. In this article, we present design considerations for asynchronous collaboration in visual analysis environments, highlighting issues of work parallelization, communication, and social organization. These considerations provide a guide for the design and evaluation of collaborative visualization systems.	Jeffrey Heer;Maneesh Agrawala	Univ. of California, Berkeley|c|;	10.1109/VISUAL.1991.175820;10.1109/TVCG.2006.178;10.1109/TVCG.2006.202;10.1109/VAST.2006.261439	visualization, analysis, collaboration, design, computer-supported cooperative work	
VAST	2007	Visual Analysis of Controversy in User-generated Encyclopedias	10.1109/VAST.2007.4389012	http://dx.doi.org/10.1109/VAST.2007.4389012	179	186	C	Wikipedia is a large and rapidly growing Web-based collaborative authoring environment, where anyone on the Internet can create, modify, and delete pages about encyclopedic topics. A remarkable property of some Wikipedia pages is that they are written by up to thousands of authors who may have contradicting opinions. In this paper we show that a visual analysis of the "who revises whom"- network gives deep insight into controversies. We propose a set of analysis and visualization techniques that reveal the dominant authors of a page, the roles they play, and the alters they confront. Thereby we provide tools to understand how Wikipedia authors collaborate in the presence of controversy.	Ulrik Brandes;Jürgen Lerner	Univ. of Konstanz, Konstanz|c|;	10.1109/VAST.2006.261431	Wikipedia, social network analysis, controversy	
VAST	2007	DataMeadow: A Visual Canvas for Analysis of Large-Scale Multivariate Data	10.1109/VAST.2007.4389013	http://dx.doi.org/10.1109/VAST.2007.4389013	187	194	C	Supporting visual analytics of multiple large-scale multidimensional datasets requires a high degree of interactivity and user control beyond the conventional challenges of visualizing such datasets. We present the DataMeadow, a visual canvas providing rich interaction for constructing visual queries using graphical set representations called DataRoses. A DataRose is essentially a starplot of selected columns in a dataset displayed as multivariate visualizations with dynamic query sliders integrated into each axis. The purpose of the DataMeadow is to allow users to create advanced visual queries by iteratively selecting and filtering into the multidimensional data. Furthermore, the canvas provides a clear history of the analysis that can be annotated to facilitate dissemination of analytical results to outsiders. Towards this end, the DataMeadow has a direct manipulation interface for selection, filtering, and creation of sets, subsets, and data dependencies using both simple and complex mouse gestures. We have evaluated our system using a qualitative expert review involving two researchers working in the area. Results from this review are favorable for our new method.	Niklas Elmqvist;John T. Stasko;Philippas Tsigas	Univ. Paris-Sud, Paris|c|;;	10.1109/INFVIS.2000.885086;10.1109/VISUAL.1990.146386;10.1109/VISUAL.1991.175815;10.1109/INFVIS.2003.1249026;10.1109/VAST.2006.261439;10.1109/INFVIS.2005.1532139;10.1109/VAST.2006.261424;10.1109/VAST.2006.261452;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.1997.636793;10.1109/VAST.2006.261422;10.1109/VAST.2006.261430;10.1109/INFVIS.2003.1249016;10.1109/VISUAL.1999.809866;10.1109/VISUAL.1990.146375	Multivariate data, visual analytics, parallel coordinates, dynamic queries, iterative analysis, starplot, small multiples	
VAST	2007	VAST to Knowledge: Combining tools for exploration and mining	10.1109/VAST.2007.4389015	http://dx.doi.org/10.1109/VAST.2007.4389015	197	198	M	The investigation of the VAST Contest collection provided a valuable test for text mining techniques. Our group has focused on creating analytical tools to unveil relevant patterns and to aid with the content navigation in such text collections. Our results show how such an approach, in combination with visualization techniques, can ease the discovery process especially when multiple tools founded on the same approach to data mining are used in complement to and in concert with one another.	Loretta Auvil;Xavier Llorà;Duane Searsmith;Kelly Searsmith	Univ. of Illinois at Urbana-Champaign, Urbana|c|;;;			
VAST	2007	VAST 2007 Contest Interactive Poster: Data Analysis Using NdCore and REGGAE	10.1109/VAST.2007.4389016	http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=4389016	199	200	M	ATS intelligent discovery analyzed the VAST 2007 contest data set using two of its proprietary applications, NdCore and REGGAE (relationship generating graph analysis engine). The paper describes these tools and how they were used to discover the contest's scenarios of wildlife law enforcement, endangered species issues, and ecoterrorism.	Lynn Schwendiman;Jonathan McLean;Jonathan Larson	ATS Intelligent Discovery, Silverdale|c|;;			
VAST	2007	Visual Analytics with Jigsaw	10.1109/VAST.2007.4389017	http://dx.doi.org/10.1109/VAST.2007.4389017	201	202	M	This article briefly introduces the Jigsaw system and describes how we used it in analysis activities for the VAST '07 Contest. Jigsaw is a visual analytic system that provides multiple coordinated views to show connections between entities that are extracted from a collection of documents.	Carsten Görg;Zhicheng Liu;Neel Parekh;Kanupriya Singhal;John T. Stasko	Georgia Inst. of Technol., Atlanta|c|;;;;			
VAST	2007	Something's "Fishy" at Global Ways and Gill Breeders - Analysis with nSpace and GeoTime	10.1109/VAST.2007.4389018	http://dx.doi.org/10.1109/VAST.2007.4389018	203	204	M	GeoTime and nSpace are two interactive visual analytics tools that support the process of analyzing massive and complex datasets. The two tools were used to examine and interpret the 2007 VAST contest dataset. This poster paper describes how the capabilities of the tools were used to facilitate and expedite every stage of an analyst workflow.	Lynn Chien;Annie Tat;William Wright	;;			
VAST	2007	TextPlorer: An application supporting text analysis	10.1109/VAST.2007.4389019	http://dx.doi.org/10.1109/VAST.2007.4389019	205	206	M	TexPlorer is an integrated system for exploring and analyzing large amounts of text documents. The data processing modules of TexPlorer consist of named entity extraction, entity relation extraction, hierarchical clustering, and text summarization tools. Using a timeline tool, tree-view, table-view, and concept maps, TexPlorer provides an analytical interface for exploring a set of text documents from different perspectives and allows users to explore vast amount of text documents efficiently.	Chi-Chun Pan;Anuj R. Jaiswal;Junyan Luo;Anthony C. Robinson	Pennsylvania State Univ., State College|c|;;;			
VAST	2007	University of British Columbia & Simon Fraser University - The Bricolage	10.1109/VAST.2007.4389020	http://dx.doi.org/10.1109/VAST.2007.4389020	207	208	M	This abstract presents a bricolage approach to the 2007 VAST contest. The analytical process we used is presented across four stages of sensemaking. Several tools were used throughout our approach, and we present their strengths and weaknesses for specific aspects of the analytical process. In addition, we review the details of both individual and collaborative techniques for solving visual analytics problems.	William Chao;Daniel Ha;Kevin I.-J. Ho;Linda T. Kaastra;Minjung Kim;Andrew Wade	Simon Fraser Univ., Columbia|c|;;;;;			
VAST	2007	VisPad: Integrating Visualization, Navigation and Synthesis	10.1109/VAST.2007.4389021	http://dx.doi.org/10.1109/VAST.2007.4389021	209	210	M	We present a new framework - VisPad - to support the user to revisit the visual exploration process, and to synthesize and disseminate information. It offers three integrated views. The data view allows the user to interactively explore the data. The navigation view captures the exploration process. It enables the user to revisit any particular state and reuse it. The knowledge view enables the user to record his/her findings and the relations between these findings.	Yedendra Babu Shrinivasan;Jarke J. van Wijk	Tech. Univ. Eindhoven, Eindhoven|c|;			
VAST	2007	C-GROUP: A Visual Analytic Tool for Pairwise Analysis of Dynamic Group Membership	10.1109/VAST.2007.4389022	http://dx.doi.org/10.1109/VAST.2007.4389022	211	212	M	C-GROUP is a tool for analyzing dynamic group membership in social networks over time. Unlike most network visualization tools, which show the group structure within an entire network, or the group membership for a single actor, C-GROUP allows users to focus their analysis on a pair of individuals of interest. And unlike most dynamic social network visualization tools, which focus on the addition and deletion of nodes (actors) and edges (relationships) over time, C-GROUP focuses on changing group memberships over time. C-GROUP provides users with a flexible interface for defining (and redefining) groups interactively, and allows users to view the changing group memberships for the pair over time. This helps to highlight the similarities and differences between the individuals and their evolving group memberships. C-GROUP allows users to dynamically select the time granularity of the temporal evolution and supports two novel visual representations of the evolving group memberships. This flexibility gives users alternate views that are appropriate for different network sizes and provides users with different insights into the grouping behavior.	Hyunmo Kang;Lise Getoor;Lisa Singh	Univ. of Maryland, College Park|c|;;			
VAST	2007	Situation Awareness Tool for Global Argus	10.1109/VAST.2007.4389023	http://dx.doi.org/10.1109/VAST.2007.4389023	213	214	M	We present a visualization tool to enhance situation awareness for Global Argus, a system that tracks and detects indications and warnings of biological events in near real time. Because Global Argus generates massive amounts of data daily, its analysts often struggle to interpret the information. To overcome this problem, we have developed the Global Argus situation awareness tool (GASAT) using the InteleView/World Wind geographical information system. This tool allows users to visualize current and past events in a particular region, and thus to understand how events evolve over time. Combined with the other tools that we are developing, GASAT will contribute to enhanced situation awareness in the tracking and detection of biological events.	Jae Choi;Sang-joon Lee;Sarah Gigitashvilli;James Wilson	Georgetown Univ., Washington|c|;;;			
VAST	2007	Spectra transformed for model-testing and visual exploration	10.1109/VAST.2007.4389024	http://dx.doi.org/10.1109/VAST.2007.4389024	215	216	M	The presence of highly tangled patterns in spectra and other serial data exacerbates the difficulty of performing visual comparison between a test model for a particular pattern and the data. The use of a simple map that plants peaks in the data directly onto their corresponding position in a residual plot with respect to a chosen test model not only retrieves the advantages of dynamic regression plotting, but in practical cases also causes patterns in the data to congregate in meaningful ways with respect to more than one reference curve in the plane. The technique is demonstrated on a polyphonic music signal.	Palmyra Catravas	Union Coll., Schenectady|c|			
VAST	2007	Formalizing Analytical Discourse in Visual Analytics	10.1109/VAST.2007.4389025	http://dx.doi.org/10.1109/VAST.2007.4389025	217	218	M	This paper presents a theory of analytical discourse and a formal model of the intentional structure of visual analytic reasoning process. Our model rests on the theory of collaborative discourse, and allows for cooperative human-machine communication in visual interactive dialogues. Using a sample discourse from a crisis management scenario, we demonstrated the utility of our theory in characterizing the discourse context and collaboration. In particular, we view analytical discourse as plans consisting of complex mental attitude towards analytical tasks and issues. Under this view, human reasoning and computational analysis become integral part of the collaborative plan that evolves through discourse.	Guoray Cai	Penn State Univ., University Park|c|			
VAST	2007	Sunfall: A Collaborative Visual Analytics System for Astrophysics	10.1109/VAST.2007.4389026	http://dx.doi.org/10.1109/VAST.2007.4389026	219	220	M	Computational and experimental sciences produce and collect ever- larger and complex datasets, often in large-scale, multi-institution projects. The inability to gain insight into complex scientific phenomena using current software tools is a bottleneck facing virtually all endeavors of science. In this paper, we introduce Sunfall, a collaborative visual analytics system developed for the Nearby Supernova Factory, an international astrophysics experiment and the largest data volume supernova search currently in operation. Sunfall utilizes novel interactive visualization and analysis techniques to facilitate deeper scientific insight into complex, noisy, high-dimensional, high-volume, time-critical data. The system combines novel image processing algorithms, statistical analysis, and machine learning with highly interactive visual interfaces to enable collaborative, user-driven scientific exploration of supernova image and spectral data. Sunfall is currently in operation at the Nearby Supernova Factory; it is the first visual analytics system in production use at a major astrophysics project.	Cecilia R. Aragon;Stephen J. Bailey;Sarah S. Poon;Karl J. Runge;Rollin C. Thomas	Lawrence Berkeley Nat. Lab., Berkeley|c|;;;;			
VAST	2007	Visual Analysis of Dynamic Networks with Geological Clustering	10.1109/VAST.2007.4389027	http://dx.doi.org/10.1109/VAST.2007.4389027	221	222	M	Many dynamic networks have associated geological information. Here we present two complementing visual analysis methods for such networks. The first one provides an overview with summerized information while the second one presents a more detailed view. The geological information is encoded in the network layout, which is designed to help maintain user's mental map. We also combined visualization with social network analysis to facilitate knowledge discovery, especially to understand network changes in the context overall evolution. Both methods are applied to the "History of the FIFA World Cup Competition" data set.	Adel Ahmed;Xiaoyan Fu;Seok-Hee Hong;Quan Hoang Nguyen;Kai Xu	;;;;			
VAST	2007	From Tasks to Tools: A Field Study in Collaborative Visual Analytics	10.1109/VAST.2007.4389028	http://dx.doi.org/10.1109/VAST.2007.4389028	223	224	M	This poster presents an exploratory field study of a VAST 2007 contest entry. We applied cognitive task analysis (CTA), grounded theory (GT), and activity theory (AT), to analysis of field notes and interviews from participants. Our results are described in the context of activity theory and sensemaking, two theoretical perspectives that we have found to be particularly useful in understanding analytic tasks.	Daniel Ha;Minjung Kim;Andrew Wade;William Chao;Kevin I.-J. Ho;Linda T. Kaastra;Brian D. Fisher;John Dill	Simon Fraser Univ., Burnaby|c|;;;;;;;			
VAST	2007	Outlook for Visual Analytics Research Funding	10.1109/VAST.2007.4389030	http://dx.doi.org/10.1109/VAST.2007.4389030	227	227	M	Visual Analytics has become a rapidly growing field of study. It is also a field that is addressing very significant real world problems in homeland security, business analytics, emergency management, genetics and bioinformatics, investigative analysis, medical analytics, and other areas. For both these reasons, it is attracting new funding and will continue to do so in the future. Visual analytics has also become an international field, with significant research efforts in Canada, Europe, and Australia, as well as the U.S. There is significant new research funding in Canada and Germany with other efforts being discussed, including a major program sponsored by the European Union. The contributors to this panel are some of the primary thought leaders providing research funding or involved in setting up the funding apparatus. We have asked them to present their needs, funding programs, and expectations from the research community. They all come from different perspectives, different missions, and different expectations. They will present their views of the range of activity in both the U.S. and internationally and discuss what is coming. Come learn about these programs, initiatives, and plans, and how you can contribute.	James J. Thomas;Daniel A. Keim;Joe Kielman;Lawrence J. Rosenblum	Pacific Northwest National Laboratory|c|;;;			
VAST	2007	VAST 2007 Contest - Blue Iguanodon	10.1109/VAST.2007.4389032	http://dx.doi.org/10.1109/VAST.2007.4389032	231	232	M	Visual analytics experts realize that one effective way to push the field forward and to develop metrics for measuring the performance of various visual analytics components is to hold an annual competition. The second visual analytics science and technology (VAST) contest was held in conjunction with the 2007 IEEE VAST symposium. In this contest participants were to use visual analytic tools to explore a large heterogeneous data collection to construct a scenario and find evidence buried in the data of illegal and terrorist activities that were occurring. A synthetic data set was made available as well as tasks. In this paper we describe some of the advances we have made from the first competition held in 2006.	Georges G. Grinstein;Catherine Plaisant;Sharon J. Laskowski;Theresa A. O'Connell;Jean Scholtz;Mark A. Whiting	Univ. of Massachusetts, Lowell|c|;;;;;			
VAST	2007	VAST 2007 Contest - Analysis with nSpace and GeoTime	10.1109/VAST.2007.4389033	http://dx.doi.org/10.1109/VAST.2007.4389033	233	234	M	GeoTime and nSpace are two interactive visual analytics tools that support the process of analyzing massive and complex datasets. The two tools were used to examine and interpret the 2007 VAST contest dataset. This paper describes how the capabilities of the tools were used to facilitate and expedite every stage of the analysis.	Lynn Chien;Annie Tat;Thomas Kapler;Patricia Enns;Winniefried Kuan;William Wright	Oculus Info Inc., Toronto|c|;;;;;			
VAST	2007	Jigsaw meets Blue Iguanodon - The VAST 2007 Contest	10.1109/VAST.2007.4389034	http://dx.doi.org/10.1109/VAST.2007.4389034	235	236	M	This article describes our use of the Jigsaw system in working on the VAST 2007 contest. Jigsaw provides multiple views of a document collection and the individual entities within those documents, with a particular focus on exposing connections between entities. We describe how we refined the identified entities in order to better facilitate Jigsaw's use and how the different views helped us to uncover key parts of the underlying plot.	Carsten Görg;Zhicheng Liu;Neel Parekh;Kanupriyah Singhal;John T. Stasko	Georgia Inst. of Technol., Atlanta|c|;;;;			
VAST	2007	VAST to Knowledge: Combining tools for exploration and mining	10.1109/VAST.2007.4389035	http://dx.doi.org/10.1109/VAST.2007.4389035	237	238	M	The investigation of the VAST Contest collection provided a valuable test for text mining techniques. Our group has focused on creating analytical tools to unveil relevant patterns and to aid with the content navigation in such text collections. Our results show how such an approach, in combination with visualization techniques, can ease the discovery process especially when multiple tools founded on the same approach to data mining are used in complement to and in concert with one another.	Loretta Auvil;Xavier Llorà;Duane Searsmith;Kelly Searsmith	Automated Learning Group, National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign. e-mail: lauvil@uiuc.edu|c|;;;			
VAST	2007	Intelligence Analysis Using Titan	10.1109/VAST.2007.4389036	http://dx.doi.org/10.1109/VAST.2007.4389036	241	242	M	The open source Titan informatics toolkit project, which extends the visualization toolkit (VTK) to include information visualization capabilities, is being developed by Sandia National Laboratories in collaboration with Kitware. The VAST Contest provided us with an opportunity to explore various ideas for constructing an analysis tool, while allowing us to exercise our architecture in the solution of a complex problem. As amateur analysts, we found the experience both enlightening and fun.	Patricia Crossno;Brian N. Wylie;Andrew T. Wilson;John A. Greenfield;Eric T. Stanton;Timothy M. Shead;Lisa G. Ice;Kenneth Moreland;Jeffrey Baumes;Berk Geveci	Sandia Nat. Lab., Albuquerque|c|;;;;;;;;;			
VAST	2007	VAST 2007 Contest TexPlorer	10.1109/VAST.2007.4389037	http://dx.doi.org/10.1109/VAST.2007.4389037	243	244	M	TexPlorer is an integrated system for exploring and analyzing vast amount of text documents. The data processing modules of TexPlorer consist of named entity extraction, entity relation extraction, hierarchical clustering, and text summarization tools. Using time line tool, tree-view, table-view, and concept maps, TexPlorer provides visualizations from different aspects and allows analysts to explore vast amount of text documents efficiently.	Chi-Chun Pan;Anuj R. Jaiswal;Junyan Luo;Anthony C. Robinson;Prasenjit Mitra;Alan M. MacEachren;Ian Turton	Pennsylvania State Univ., University Park|c|;;;;;;			
VAST	2007	VAST 2007 Contest Data Analysis Using NdCore and REGGAE	10.1109/VAST.2007.4389038	http://dx.doi.org/10.1109/VAST.2007.4389038	245	246	M	ATS Intelligent Discovery analyzed the VAST 2007 contest data set using two of its proprietary applications, NdCore and REGGAE (Relationship Generating Graph Analysis Engine). The paper describes these tools and how they were used to discover the contest's scenarios of wildlife law enforcement, endangered species issues, and ecoterrorism.	Lynn Schwendiman;Jonathan McLean;Jonathan Larson	ATS, Silverdale|c|;;			
VAST	2007	University of British Columbia & Simon Fraser University - The Bricolage	10.1109/VAST.2007.4470207	http://dx.doi.org/10.1109/VAST.2007.4470207	239	240	M	This abstract presents a bricolage approach to the 2007 VAST contest. The analytical process we used is presented across four stages of sensemaking. Several tools were used throughout our approach, and we present their strengths and weaknesses for specific aspects of the analytical process. In addition, we review the details of both individual and collaborative techniques for solving visual analytics problems.	William Chao;Daniel Ha;Kevin I.-J. Ho;Linda T. Kaastra;Minjung Kim;Andrew Wade;Brian D. Fisher	;;;;;;			
Vis	2007	Transform Coding for Hardware-accelerated Volume Rendering	10.1109/TVCG.2007.70516	http://dx.doi.org/10.1109/TVCG.2007.70516	1600	1607	J	Hardware-accelerated volume rendering using the GPU is now the standard approach for real-time volume rendering, although limited graphics memory can present a problem when rendering large volume data sets. Volumetric compression in which the decompression is coupled to rendering has been shown to be an effective solution to this problem; however, most existing techniques were developed in the context of software volume rendering, and all but the simplest approaches are prohibitive in a real-time hardware-accelerated volume rendering context. In this paper we present a novel block-based transform coding scheme designed specifically with real-time volume rendering in mind, such that the decompression is fast without sacrificing compression quality. This is made possible by consolidating the inverse transform with dequantization in such a way as to allow most of the reprojection to be precomputed. Furthermore, we take advantage of the freedom afforded by offline compression in order to optimize the encoding as much as possible while hiding this complexity from the decoder. In this context we develop a new block classification scheme which allows us to preserve perceptually important features in the compression. The result of this work is an asymmetric transform coding scheme that allows very large volumes to be compressed and then decompressed in real-time while rendering on the GPU.	Nathaniel Fout;Kwan-Liu Ma	Univ. of California, Davis|c|;	10.1109/VISUAL.2002.1183757;10.1109/VISUAL.2001.964520;10.1109/VISUAL.2004.95;10.1109/VISUAL.1993.398845;10.1109/VISUAL.2003.1250357;10.1109/VISUAL.1995.480812;10.1109/VISUAL.2003.1250385	Volume Compression, Compressed Volume Rendering, Transform Coding, Hardware-accelerated Volume Rendering	
Vis	2007	Two-Level Approach to Efficient Visualization of Protein Dynamics	10.1109/TVCG.2007.70517	http://dx.doi.org/10.1109/TVCG.2007.70517	1616	1623	J	Proteins are highly flexible and large amplitude deformations of their structure, also called slow dynamics, are often decisive to their function. We present a two-level rendering approach that enables visualization of slow dynamics of large protein assemblies. Our approach is aligned with a hierarchical model of large scale molecules. Instead of constantly updating positions of large amounts of atoms, we update the position and rotation of residues, i.e., higher level building blocks of a protein. Residues are represented by one vertex only indicating its position and additional information defining the rotation. The atoms in the residues are generated on-the-fly on the GPU, exploiting the new graphics hardware geometry shader capabilities. Moreover, we represent the atoms by billboards instead of tessellated spheres. Our representation is then significantly faster and pixel precise. We demonstrate the usefulness of our new approach in the context of our collaborative bioinformatics project.	Ove Daae Lampe;Ivan Viola;Nathalie Reuter;Helwig Hauser	Christian Michelsen Res., Bergen|c|;;;	10.1109/VISUAL.2005.1532859;10.1109/INFVIS.1996.559215;10.1109/VISUAL.2000.885733;10.1109/TVCG.2006.115	Molecular visualization, hardware acceleration, protein dynamics	
Vis	2007	Uncertainty Visualization in Medical Volume Rendering Using Probabilistic Animation	10.1109/TVCG.2007.70518	http://dx.doi.org/10.1109/TVCG.2007.70518	1648	1655	J	Direct volume rendering has proved to be an effective visualization method for medical data sets and has reached wide-spread clinical use. The diagnostic exploration, in essence, corresponds to a tissue classification task, which is often complex and time-consuming. Moreover, a major problem is the lack of information on the uncertainty of the classification, which can have dramatic consequences for the diagnosis. In this paper this problem is addressed by proposing animation methods to convey uncertainty in the rendering. The foundation is a probabilistic Transfer Function model which allows for direct user interaction with the classification. The rendering is animated by sampling the probability domain over time, which results in varying appearance for uncertain regions. A particularly promising application of this technique is a "sensitivity lens" applied to focus regions in the data set. The methods have been evaluated by radiologists in a study simulating the clinical task of stenosis assessment, in which the animation technique is shown to outperform traditional rendering in terms of assessment accuracy.	Claes Lundström;Patric Ljung;Anders Persson;Anders Ynnerman	Linkoping Univ., Linkoping|c|;;;	10.1109/VISUAL.2005.1532807;10.1109/VISUAL.1992.235199;10.1109/VISUAL.2003.1250414	Uncertainty, probability, medical visualization, volume rendering, transfer function	
Vis	2007	Variable Interactions in Query-Driven Visualization	10.1109/TVCG.2007.70519	http://dx.doi.org/10.1109/TVCG.2007.70519	1400	1407	J	Our ability to generate ever-larger, increasingly-complex data, has established the need for scalable methods that identify, and provide insight into, important variable trends and interactions. Query-driven methods are among the small subset of techniques that are able to address both large and highly complex datasets. This paper presents a new method that increases the utility of query-driven techniques by visually conveying statistical information about the trends that exist between variables in a query. In this method, correlation fields, created between pairs of variables, are used with the cumulative distribution functions of variables expressed in a users query. This integrated use of cumulative distribution functions and correlation fields visually reveals, with respect to the solution space of the query, statistically important interactions between any three variables, and allows for trends between these variables to be readily identified. We demonstrate our method by analyzing interactions between variables in two flame-front simulations.	Luke J. Gosink;John C. Anderson;E. Wes Bethel;Kenneth I. Joy	Univ. of California, Davis|c|;;;	10.1109/VISUAL.2004.68;10.1109/VISUAL.2005.1532792;10.1109/VISUAL.1999.809866;10.1109/TVCG.2006.165;10.1109/VISUAL.2003.1250362	Multivariate Data, Query-Driven Visualization	
Vis	2007	Visual Analysis of the Air Pollution Problem in Hong Kong	10.1109/TVCG.2007.70523	http://dx.doi.org/10.1109/TVCG.2007.70523	1408	1415	J	We present a comprehensive system for weather data visualization. Weather data are multivariate and contain vector fields formed by wind speed and direction. Several well-established visualization techniques such as parallel coordinates and polar systems are integrated into our system. We also develop various novel methods, including circular pixel bar charts embedded into polar systems, enhanced parallel coordinates with S-shape axis, and weighted complete graphs. Our system was used to analyze the air pollution problem in Hong Kong and some interesting patterns have been found.	Huamin Qu;Wing-Yi Chan;Anbang Xu;Kai-Lun Chung;Alexis Kai-Hon Lau;Ping Guo	Hong Kong Univ. of Sci. & Technol., Hong Kong|c|;;;;;	10.1109/VISUAL.2000.885745;10.1109/VISUAL.1990.146402;10.1109/VISUAL.2000.885736;10.1109/INFVIS.2003.1249015;10.1109/TVCG.2006.165	Weather data visualization, polar system, parallel coordinates, air pollution, visual analytics	
Vis	2007	Visualization of Cosmological Particle-Based Datasets	10.1109/TVCG.2007.70526	http://dx.doi.org/10.1109/TVCG.2007.70526	1712	1718	J	We describe our visualization process for a particle-based simulation of the formation of the first stars and their impact on cosmic history. The dataset consists of several hundred time-steps of point simulation data, with each time-step containing approximately two million point particles. For each time-step, we interpolate the point data onto a regular grid using a method taken from the radiance estimate of photon mapping [21]. We import the resulting regular grid representation into ParaView [24], with which we extract isosurfaces across multiple variables. Our images provide insights into the evolution of the early universe, tracing the cosmic transition from an initially homogeneous state to one of increasing complexity. Specifically, our visualizations capture the build-up of regions of ionized gas around the first stars, their evolution, and their complex interactions with the surrounding matter. These observations will guide the upcoming James Webb Space Telescope, the key astronomy mission of the next decade.	Paul A. Navrátil;Jarrett Johnson;Volker Bromm	Univ. of Texas, Austin|c|;;	10.1109/VISUAL.2004.52;10.1109/VISUAL.2004.29	Interpolation, Isosurface, Astronomy, Cosmology	
Vis	2007	Visualizing Large-Scale Uncertainty in Astrophysical Data	10.1109/TVCG.2007.70530	http://dx.doi.org/10.1109/TVCG.2007.70530	1640	1647	J	Visualization of uncertainty or error in astrophysical data is seldom available in simulations of astronomical phenomena, and yet almost all rendered attributes possess some degree of uncertainty due to observational error. Uncertainties associated with spatial location typically vary significantly with scale and thus introduce further complexity in the interpretation of a given visualization. This paper introduces effective techniques for visualizing uncertainty in large-scale virtual astrophysical environments. Building upon our previous transparently scalable visualization architecture, we develop tools that enhance the perception and comprehension of uncertainty across wide scale ranges. Our methods include a unified color-coding scheme for representing log-scale distances and percentage errors, an ellipsoid model to represent positional uncertainty, an ellipsoid envelope model to expose trajectory uncertainty, and a magic-glass design supporting the selection of ranges of log-scale distance and uncertainty parameters, as well as an overview mode and a scalable WIM tool for exposing the magnitudes of spatial context and uncertainty.	Hongwei Li;Chi-Wing Fu;Yinggang Li;Andrew J. Hanson	Hong Kong Univ. of Sci. & Technol., Hong Kong|c|;;;	10.1109/VISUAL.2000.885679;10.1109/VISUAL.2002.1183769;10.1109/VISUAL.2003.1250404;10.1109/VISUAL.2005.1532807;10.1109/TVCG.2006.155;10.1109/TVCG.2006.176;10.1109/VISUAL.2004.25;10.1109/VISUAL.2005.1532853;10.1109/VISUAL.1996.568116;10.1109/VISUAL.2002.1183824;10.1109/VISUAL.1996.568105;10.1109/INFVIS.2002.1173145;10.1109/VISUAL.2005.1532803;10.1109/VISUAL.2004.18	Uncertainty visualization, large spatial scale, interstellar data, astronomy	
Vis	2007	Visualizing Whole-Brain DTI Tractography with GPU-based Tuboids and LoD Management	10.1109/TVCG.2007.70532	http://dx.doi.org/10.1109/TVCG.2007.70532	1488	1495	J	Diffusion tensor imaging (DTI) of the human brain, coupled with tractography techniques, enable the extraction of large- collections of three-dimensional tract pathways per subject. These pathways and pathway bundles represent the connectivity between different brain regions and are critical for the understanding of brain related diseases. A flexible and efficient GPU-based rendering technique for DTI tractography data is presented that addresses common performance bottlenecks and image-quality issues, allowing interactive render rates to be achieved on commodity hardware. An occlusion query-based pathway LoD management system for streamlines/streamtubes/tuboids is introduced that optimizes input geometry, vertex processing, and fragment processing loads, and helps reduce overdraw. The tuboid, a fully-shaded streamtube impostor constructed entirely on the GPU from streamline vertices, is also introduced. Unlike full streamtubes and other impostor constructs, tuboids require little to no preprocessing or extra space over the original streamline data. The supported fragment processing levels of detail range from texture-based draft shading to full raycast normal computation, Phong shading, environment mapping, and curvature-correct text labeling. The presented text labeling technique for tuboids provides adaptive, aesthetically pleasing labels that appear attached to the surface of the tubes. Furthermore, an occlusion query aggregating and scheduling scheme for tuboids is described that reduces the query overhead. Results for a tractography dataset are presented, and demonstrate that LoD-managed tuboids offer benefits over traditional streamtubes both in performance and appearance.	Vid Petrovic;James H. Fallon;Falko Kuester	Univ. of California at Irvine, Irvine|c|;;	10.1109/VISUAL.2002.1183799;10.1109/VISUAL.2005.1532859;10.1109/VISUAL.2004.30;10.1109/TVCG.2006.151;10.1109/VISUAL.2003.1250368;10.1109/TVCG.2006.197;10.1109/VISUAL.1996.567777	Tuboids, stream tubes, interactive gpu-centric rendering, neuronal pathways	
Vis	2007	A Flexible Multi-Volume Shader Framework for Arbitrarily Intersecting Multi-Resolution Datasets	10.1109/TVCG.2007.70534	http://dx.doi.org/10.1109/TVCG.2007.70534	1584	1591	J	We present a powerful framework for 3D-texture-based rendering of multiple arbitrarily intersecting volumetric datasets. Each volume is represented by a multi-resolution octree-based structure and we use out-of-core techniques to support extremely large volumes. Users define a set of convex polyhedral volume lenses, which may be associated with one or more volumetric datasets. The volumes or the lenses can be interactively moved around while the region inside each lens is rendered using interactively defined multi-volume shaders. Our rendering pipeline splits each lens into multiple convex regions such that each region is homogenous and contains a fixed number of volumes. Each such region is further split by the brick boundaries of the associated octree representations. The resulting puzzle of lens fragments is sorted in front-to-back or back-to-front order using a combination of a view-dependent octree traversal and a GPU-based depth peeling technique. Our current implementation uses slice-based volume rendering and allows interactive roaming through multiple intersecting multi-gigabyte volumes.	John Plate;Thorsten Holtkämper;Bernd Fröhlich 0001	Bauhaus-Univ. Weimar, Weimar|c|;;	10.1109/VISUAL.2003.1250406;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2002.1183762	Multi-volume visualization, constructive solid geometry, shading, display algorithms	
Vis	2007	A Unified Paradigm For Scalable Multi-Projector Displays	10.1109/TVCG.2007.70536	http://dx.doi.org/10.1109/TVCG.2007.70536	1360	1367	J	We present a general framework for the modeling and optimization of scalable multi-projector displays. Based on this framework, we derive algorithms that can robustly optimize the visual quality of an arbitrary combination of projectors without manual adjustment. When the projectors are tiled, we show that our framework automatically produces blending maps that outperform state-of-the-art projector blending methods. When all the projectors are superimposed, the framework can produce high-resolution images beyond the Nyquist resolution limits of component projectors. When a combination of tiled and superimposed projectors are deployed, the same framework harnesses the best features of both tiled and superimposed multi-projector projection paradigms. The framework creates for the first time a new unified paradigm that is agnostic to a particular configuration of projectors yet robustly optimizes for the brightness, contrast, and resolution of that configuration. In addition, we demonstrate that our algorithms support high resolution video at real-time interactive frame rates achieved on commodity graphics platforms. This work allows for inexpensive, compelling, flexible, and robust large scale visualization systems to be built and deployed very efficiently.	Niranjan Damera-Venkata;Nelson L. Chang;Jeffrey M. DiCarlo	Hewlett-Packard Lab., Palo Alto|c|;;	10.1109/VISUAL.1999.809883	Multi-projector displays, tiled displays, large format displays, blending, stitching, automatic geometric alignment, photometric correction, super-resolution, superimposed projection	
Vis	2007	An Effective Illustrative Visualization Framework Based on Photic Extremum Lines (PELs)	10.1109/TVCG.2007.70538	http://dx.doi.org/10.1109/TVCG.2007.70538	1328	1335	J	Conveying shape using feature lines is an important visualization tool in visual computing. The existing feature lines (e.g., ridges, valleys, silhouettes, suggestive contours, etc.) are solely determined by local geometry properties (e.g., normals and curvatures) as well as the view position. This paper is strongly inspired by the observation in human vision and perception that a sudden change in the luminance plays a critical role to faithfully represent and recover the 3D information. In particular, we adopt the edge detection techniques in image processing for 3D shape visualization and present photic extremum lines (PELs) which emphasize significant variations of illumination over 3D surfaces. Comparing with the existing feature lines, PELs are more flexible and offer users more freedom to achieve desirable visualization effects. In addition, the user can easily control the shape visualization by changing the light position, the number of light sources, and choosing various light models. We compare PELs with the existing approaches and demonstrate that PEL is a flexible and effective tool to illustrate 3D surface and volume for visual computing.	Xuexiang Xie;Ying He 0001;Feng Tian;Seah Hock Soon;Xianfeng Gu;Hong Qin	Nanyang Technol. Univ.|c|;;;;;	10.1109/VISUAL.2003.1250414;10.1109/VISUAL.2000.885694;10.1109/VISUAL.2002.1183777;10.1109/VISUAL.2005.1532856;10.1109/VISUAL.1995.480795	Surface and volume illustration, illumination, photic extremum lines (PELs), silhouettes, suggestive contours, ridges and valleys, digital geometry processing	
Vis	2007	Conjoint Analysis to Measure the Perceived Quality in Volume Rendering	10.1109/TVCG.2007.70542	http://dx.doi.org/10.1109/TVCG.2007.70542	1664	1671	J	Visualization algorithms can have a large number of parameters, making the space of possible rendering results rather high-dimensional. Only a systematic analysis of the perceived quality can truly reveal the optimal setting for each such parameter. However, an exhaustive search in which all possible parameter permutations are presented to each user within a study group would be infeasible to conduct. Additional complications may result from possible parameter co-dependencies. Here, we will introduce an efficient user study design and analysis strategy that is geared to cope with this problem. The user feedback is fast and easy to obtain and does not require exhaustive parameter testing. To enable such a framework we have modified a preference measuring methodology, conjoint analysis, that originated in psychology and is now also widely used in market research. We demonstrate our framework by a study that measures the perceived quality in volume rendering within the context of large parameter spaces.	Joachim Giesen;Klaus Mueller;Eva Schuberth;Lujin Wang;Peter Zolliker	Univ. des Saarlandes, Saarbrucken|c|;;;;	10.1109/TVCG.2006.137;10.1109/VISUAL.2005.1532834;10.1109/TVCG.2006.174;10.1109/VISUAL.2003.1250412;10.1109/INFVIS.2005.1532149;10.1109/TVCG.2006.113	Conjoint Analysis, Parameterized Algorithms, Volume Visualization	
Vis	2007	Construction of Simplified Boundary Surfaces from Serial-sectioned Metal Micrographs	10.1109/TVCG.2007.70543	http://dx.doi.org/10.1109/TVCG.2007.70543	1528	1535	J	We present a method for extracting boundary surfaces from segmented cross-section image data. We use a constrained Potts model to interpolate an arbitrary number of region boundaries between segmented images. This produces a segmented volume from which we extract a triangulated boundary surface using well-known marching tetrahedra methods. This surface contains staircase-like artifacts and an abundance of unnecessary triangles. We describe an approach that addresses these problems with a voxel-accurate simplification algorithm that reduces surface complexity by an order of magnitude. Our boundary interpolation and simplification methods are novel contributions to the study of surface extraction from segmented cross-sections. We have applied our method to construct polycrystal grain boundary surfaces from micrographs of a sample of the metal tantalum.	Scott E. Dillard;John Bingert;Dan Thoma;Bernd Hamann	Univ. of California, Davis|c|;;;	10.1109/VISUAL.2000.885706;10.1109/VISUAL.2005.1532823;10.1109/VISUAL.1997.663887	Surface extraction, Polygonal meshes, Visualization in Physical Sciences, Life Sciences and Engineering	
Vis	2007	Contextualized Videos: Combining Videos with Environment Models to Support Situational Understanding	10.1109/TVCG.2007.70544	http://dx.doi.org/10.1109/TVCG.2007.70544	1568	1575	J	Multiple spatially-related videos are increasingly used in security, communication, and other applications. Since it can be difficult to understand the spatial relationships between multiple videos in complex environments (e.g. to predict a person's path through a building), some visualization techniques, such as video texture projection, have been used to aid spatial understanding. In this paper, we identify and begin to characterize an overall class of visualization techniques that combine video with 3D spatial context. This set of techniques, which we call contextualized videos, forms a design palette which must be well understood so that designers can select and use appropriate techniques that address the requirements of particular spatial video tasks. In this paper, we first identify user tasks in video surveillance that are likely to benefit from contextualized videos and discuss the video, model, and navigation related dimensions of the contextualized video design space. We then describe our contextualized video testbed which allows us to explore this design space and compose various video visualizations for evaluation. Finally, we describe the results of our process to identify promising design patterns through user selection of visualization features from the design space, followed by user interviews.	Yi Wang;David M. Krum;Enylton Machado Coelho;Doug A. Bowman	Virginia Tech., Blacksburg|c|;;;	10.1109/VISUAL.2003.1250396;10.1109/TVCG.2006.194;10.1109/VISUAL.2003.1250401;10.1109/VISUAL.2003.1250400;10.1109/VISUAL.2005.1532836;10.1109/VISUAL.2005.1532782	situational awareness, videos, virtual environment models, design space, testbed design and evaluation	
Vis	2007	Cores of Swirling Particle Motion in Unsteady Flows	10.1109/TVCG.2007.70545	http://dx.doi.org/10.1109/TVCG.2007.70545	1759	1766	J	In nature and in flow experiments particles form patterns of swirling motion in certain locations. Existing approaches identify these structures by considering the behavior of stream lines. However, in unsteady flows particle motion is described by path lines which generally gives different swirling patterns than stream lines. We introduce a novel mathematical characterization of swirling motion cores in unsteady flows by generalizing the approach of Sujudi/Haimes to path lines. The cores of swirling particle motion are lines sweeping over time, i.e., surfaces in the space-time domain. They occur at locations where three derived 4D vectors become coplanar. To extract them, we show how to re-formulate the problem using the parallel vectors operator. We apply our method to a number of unsteady flow fields.	Tino Weinkauf;Jan Sahner;Holger Theisel;Hans-Christian Hege	Zuse Inst. Berlin, Berlin|c|;;;	10.1109/VISUAL.1999.809896;10.1109/VISUAL.2005.1532851;10.1109/VISUAL.1998.745296	unsteady flow visualization, feature extraction, particle motion	
Vis	2007	CoViCAD: Comprehensive Visualization of Coronary Artery Disease	10.1109/TVCG.2007.70550	http://dx.doi.org/10.1109/TVCG.2007.70550	1632	1639	J	We present novel, comprehensive visualization techniques for the diagnosis of patients with coronary artery disease using segmented cardiac MRI data. We extent an accepted medical visualization technique called the bull's eye plot by removing discontinuities, preserving the volumetric nature of the left ventricular wall and adding anatomical context. The resulting volumetric bull's eye plot can be used for the assessment of transmurality. We link these visualizations to a 3D view that presents viability information in a detailed anatomical context. We combine multiple MRI scans (whole heart anatomical data, late enhancement data) and multiple segmentations (polygonal heart model, late enhancement contours, coronary artery tree). By selectively combining different rendering techniques we obtain comprehensive yet intuitive visualizations of the various data sources.	Maurice Termeer;Javier Oliván Bescós;Marcel Breeuwer;Anna Vilanova;Frans A. Gerritsen;Eduard Gröller	Vienna Univ. of Technol., Vienna|c|;;;;;	10.1109/VISUAL.2003.1250386;10.1109/VISUAL.2002.1183754;10.1109/TVCG.2006.152;10.1109/VISUAL.2004.104	Cardiac MRI, late enhancement, viability, bull's eye plot	
Vis	2007	Efficient Computation and Visualization of Coherent Structures in Fluid Flow Applications	10.1109/TVCG.2007.70551	http://dx.doi.org/10.1109/TVCG.2007.70551	1464	1471	J	The recently introduced notion of Finite-Time Lyapunov Exponent to characterize Coherent Lagrangian Structures provides a powerful framework for the visualization and analysis of complex technical flows. Its definition is simple and intuitive, and it has a deep theoretical foundation. While the application of this approach seems straightforward in theory, the associated computational cost is essentially prohibitive. Due to the Lagrangian nature of this technique, a huge number of particle paths must be computed to fill the space-time flow domain. In this paper, we propose a novel scheme for the adaptive computation of FTLE fields in two and three dimensions that significantly reduces the number of required particle paths. Furthermore, for three-dimensional flows, we show on several examples that meaningful results can be obtained by restricting the analysis to a well-chosen plane intersecting the flow domain. Finally, we examine some of the visualization aspects of FTLE-based methods and introduce several new variations that help in the analysis of specific aspects of a flow.	Christoph Garth;Florian Gerhardt;Xavier Tricoche;Hans Hagen	Univ. of Kaiserslautern, Kaiserslautern|c|;;;	10.1109/VISUAL.2004.113	flow visualization, feature detection, 3D vector field visualization	
Vis	2007	Efficient Computation of Morse-Smale Complexes for Three-dimensional Scalar Functions	10.1109/TVCG.2007.70552	http://dx.doi.org/10.1109/TVCG.2007.70552	1440	1447	J	The Morse-Smale complex is an efficient representation of the gradient behavior of a scalar function, and critical points paired by the complex identify topological features and their importance. We present an algorithm that constructs the Morse-Smale complex in a series of sweeps through the data, identifying various components of the complex in a consistent manner. All components of the complex, both geometric and topological, are computed, providing a complete decomposition of the domain. Efficiency is maintained by representing the geometry of the complex in terms of point sets.	Attila Gyulassy;Vijay Natarajan;Valerio Pascucci;Bernd Hamann	Univ. of California, Davis|c|;;;	10.1109/VISUAL.2004.96;10.1109/VISUAL.2000.885680;10.1109/VISUAL.1998.745329;10.1109/VISUAL.1998.745312;10.1109/VISUAL.2005.1532839;10.1109/VISUAL.2000.885703	Morse theory, Morse-Smale complexes, computational topology, multiresolution, simplification, feature detection, 3D scalar fields	
Vis	2007	Efficient Surface Reconstruction using Generalized Coulomb Potentials	10.1109/TVCG.2007.70553	http://dx.doi.org/10.1109/TVCG.2007.70553	1512	1519	J	We propose a novel, geometrically adaptive method for surface reconstruction from noisy and sparse point clouds, without orientation information. The method employs a fast convection algorithm to attract the evolving surface towards the data points. The force field in which the surface is convected is based on generalized Coulomb potentials evaluated on an adaptive grid (i.e., an octree) using a fast, hierarchical algorithm. Formulating reconstruction as a convection problem in a velocity field generated by Coulomb potentials offers a number of advantages. Unlike methods which compute the distance from the data set to the implicit surface, which are sensitive to noise due to the very reliance on the distance transform, our method is highly resilient to shot noise since global, generalized Coulomb potentials can be used to disregard the presence of outliers due to noise. Coulomb potentials represent long-range interactions that consider all data points at once, and thus they convey global information which is crucial in the fitting process. Both the spatial and temporal complexities of our spatially-adaptive method are proportional to the size of the reconstructed object, which makes our method compare favorably with respect to previous approaches in terms of speed and flexibility. Experiments with sparse as well as noisy data sets show that the method is capable of delivering crisp and detailed yet smooth surfaces.	Andrei Jalba;Jos B. T. M. Roerdink	Univ. of Groningen, Groningen|c|;		Surface reconstruction, Implicit surfaces, Octrees, Generalized Coulomb potentials, Polygonization	
Vis	2007	Efficient Visualization of Lagrangian Coherent Structures by filtered AMR Ridge Extraction	10.1109/TVCG.2007.70554	http://dx.doi.org/10.1109/TVCG.2007.70554	1456	1463	J	This paper presents a method for filtered ridge extraction based on adaptive mesh refinement. It is applicable in situations where the underlying scalar field can be refined during ridge extraction. This requirement is met by the concept of Lagrangian coherent structures which is based on trajectories started at arbitrary sampling grids that are independent of the underlying vector field. The Lagrangian coherent structures are extracted as ridges in finite Lyapunov exponent fields computed from these grids of trajectories. The method is applied to several variants of finite Lyapunov exponents, one of which is newly introduced. High computation time due to the high number of required trajectories is a main drawback when computing Lyapunov exponents of 3-dimensional vector fields. The presented method allows a substantial speed-up by avoiding the seeding of trajectories in regions where no ridges are present or do not satisfy the prescribed filter criteria such as a minimum finite Lyapunov exponent.	Filip Sadlo;Ronald Peikert	ETH Zurich, Zurich|c|;	10.1109/VISUAL.1999.809896;10.1109/VISUAL.2004.99	Ridge extraction, flow visualization, coherent structures, vector field topology, unsteady vector fields	
Vis	2007	Enhancing Depth-Perception with Flexible Volumetric Halos	10.1109/TVCG.2007.70555	http://dx.doi.org/10.1109/TVCG.2007.70555	1344	1351	J	Volumetric data commonly has high depth complexity which makes it difficult to judge spatial relationships accurately. There are many different ways to enhance depth perception, such as shading, contours, and shadows. Artists and illustrators frequently employ halos for this purpose. In this technique, regions surrounding the edges of certain structures are darkened or brightened which makes it easier to judge occlusion. Based on this concept, we present a flexible method for enhancing and highlighting structures of interest using GPU-based direct volume rendering. Our approach uses an interactively defined halo transfer function to classify structures of interest based on data value, direction, and position. A feature-preserving spreading algorithm is applied to distribute seed values to neighboring locations, generating a controllably smooth field of halo intensities. These halo intensities are then mapped to colors and opacities using a halo profile function. Our method can be used to annotate features at interactive frame rates.	Stefan Bruckner;Eduard Gröller	Vienna Univ. of Technol., Vienna|c|;	10.1109/VISUAL.2003.1250414;10.1109/TVCG.2006.124;10.1109/VISUAL.2000.885694;10.1109/VISUAL.1997.663912;10.1109/VISUAL.2003.1250394;10.1109/TVCG.2006.172;10.1109/VISUAL.2004.64;10.1109/VISUAL.1991.175805;10.1109/TVCG.2006.139	Volume rendering, illustrative visualization, halos	
Vis	2007	Generalized Streak Lines: Analysis and Visualization of Boundary Induced Vortices	10.1109/TVCG.2007.70557	http://dx.doi.org/10.1109/TVCG.2007.70557	1735	1742	J	We present a method to extract and visualize vortices that originate from bounding walls of three-dimensional time- dependent flows. These vortices can be detected using their footprint on the boundary, which consists of critical points in the wall shear stress vector field. In order to follow these critical points and detect their transformations, affected regions of the surface are parameterized. Thus, an existing singularity tracking algorithm devised for planar settings can be applied. The trajectories of the singularities are used as a basis for seeding particles. This leads to a new type of streak line visualization, in which particles are released from a moving source. These generalized streak lines visualize the particles that are ejected from the wall. We demonstrate the usefulness of our method on several transient fluid flow datasets from computational fluid dynamics simulations.	Alexander Wiebel;Xavier Tricoche;Dominic Schneider;Heike Leitte;Gerik Scheuermann	Univ. Leipzig, Leipzig|c|;;;;	10.1109/VISUAL.2004.107;10.1109/TVCG.2006.173;10.1109/TVCG.2006.199;10.1109/VISUAL.1990.146359;10.1109/VISUAL.2005.1532851;10.1109/VISUAL.1999.809896	Skin friction, singularity tracking, vortex, generalized streak line, flow visualization, time-dependent vector fields	
Vis	2007	Grid With a View: Optimal Texturing for Perception of Layered Surface Shape	10.1109/TVCG.2007.70559	http://dx.doi.org/10.1109/TVCG.2007.70559	1656	1663	J	We present the results of two controlled studies comparing layered surface visualizations under various texture conditions. The task was to estimate surface normals, measured by accuracy of a hand-set surface normal probe. A single surface visualization was compared with the two-surfaces case under conditions of no texture and with projected grid textures. Variations in relative texture spacing on top and bottom surfaces were compared, as well as opacity of the top surface. Significant improvements are found for the textured cases over non-textured surfaces. Either larger or thinner top-surface textures, and lower top surface opacities are shown to give less bottom surface error. Top surface error appears to be highly resilient to changes in texture. Given the results we also present an example of how appropriate textures might be useful in volume visualization.	Alethea Bair;Donald H. House	Texas A&M Univ., College Station|c|;	10.1109/VISUAL.2005.1532782;10.1109/TVCG.2006.183;10.1109/VISUAL.2001.964505;10.1109/INFVIS.2003.1249022;10.1109/TVCG.2006.180	Perception, optimal visualization, texturing, layered surfaces	
Vis	2007	High-Quality Multimodal Volume Rendering for Preoperative Planning of Neurosurgical Interventions	10.1109/TVCG.2007.70560	http://dx.doi.org/10.1109/TVCG.2007.70560	1696	1703	J	Surgical approaches tailored to an individual patient's anatomy and pathology have become standard in neurosurgery. Precise preoperative planning of these procedures, however, is necessary to achieve an optimal therapeutic effect. Therefore, multiple radiological imaging modalities are used prior to surgery to delineate the patient's anatomy, neurological function, and metabolic processes. Developing a three-dimensional perception of the surgical approach, however, is traditionally still done by mentally fusing multiple modalities. Concurrent 3D visualization of these datasets can, therefore, improve the planning process significantly. In this paper we introduce an application for planning of individual neurosurgical approaches with high-quality interactive multimodal volume rendering. The application consists of three main modules which allow to (1) plan the optimal skin incision and opening of the skull tailored to the underlying pathology; (2) visualize superficial brain anatomy, function and metabolism; and (3) plan the patient-specific approach for surgery of deep-seated lesions. The visualization is based on direct multi-volume raycasting on graphics hardware, where multiple volumes from different modalities can be displayed concurrently at interactive frame rates. Graphics memory limitations are avoided by performing raycasting on bricked volumes. For preprocessing tasks such as registration or segmentation, the visualization modules are integrated into a larger framework, thus supporting the entire workflow of preoperative planning.	Johanna Beyer;Markus Hadwiger;Stefan Wolfsberger;Katja Bühler	VRVis Res. Center, Vienna|c|;;;	10.1109/VISUAL.2003.1250384;10.1109/VISUAL.1998.745311;10.1109/VISUAL.2003.1250386;10.1109/VISUAL.2004.98	Multimodal Volume Rendering, Hardware Assisted Raycasting, Surgery Planning	
Vis	2007	Illustrative Deformation for Data Exploration	10.1109/TVCG.2007.70565	http://dx.doi.org/10.1109/TVCG.2007.70565	1320	1327	J	Much of the visualization research has focused on improving the rendering quality and speed, and enhancing the perceptibility of features in the data. Recently, significant emphasis has been placed on focus+context (F+C) techniques (e.g., fisheye views and magnification lens) for data exploration in addition to viewing transformation and hierarchical navigation. However, most of the existing data exploration techniques rely on the manipulation of viewing attributes of the rendering system or optical attributes of the data objects, with users being passive viewers. In this paper, we propose a more active approach to data exploration, which attempts to mimic how we would explore data if we were able to hold it and interact with it in our hands. This involves allowing the users to physically or actively manipulate the geometry of a data object. While this approach has been traditionally used in applications, such as surgical simulation, where the original geometry of the data objects is well understood by the users, there are several challenges when this approach is generalized for applications, such as flow and information visualization, where there is no common perception as to the normal or natural geometry of a data object. We introduce a taxonomy and a set of transformations especially for illustrative deformation of general data exploration. We present combined geometric or optical illustration operators for focus+context visualization, and examine the best means for preventing the deformed context from being misperceived. We demonstrated the feasibility of this generalization with examples of flow, information and video visualization.	Carlos D. Correa;Deborah Silver;Mi Chen	State Univ. of New Jersey, Brunswick|c|;;	10.1109/VISUAL.2000.885696;10.1109/TVCG.2006.144;10.1109/VISUAL.2003.1250400;10.1109/TVCG.2006.152;10.1109/VISUAL.2003.1250401;10.1109/INFVIS.2004.59;10.1109/VISUAL.2002.1183777;10.1109/TVCG.2006.140;10.1109/VISUAL.2001.964519;10.1109/VISUAL.2004.48;10.1109/VISUAL.2000.885694;10.1109/VISUAL.2005.1532856;10.1109/VISUAL.2005.1532818	Volume deformation, focus+context visualization, interaction techniques	
Vis	2007	Interactive Isosurface Ray Tracing of Time-Varying Tetrahedral Volumes	10.1109/TVCG.2007.70566	http://dx.doi.org/10.1109/TVCG.2007.70566	1727	1734	J	We describe a system for interactively rendering isosurfaces of tetrahedral finite-element scalar fields using coherent ray tracing techniques on the CPU. By employing state-of-the art methods in polygonal ray tracing, namely aggressive packet/frustum traversal of a bounding volume hierarchy, we can accommodate large and time-varying unstructured data. In conjunction with this efficiency structure, we introduce a novel technique for intersecting ray packets with tetrahedral primitives. Ray tracing is flexible, allowing for dynamic changes in isovalue and time step, visualization of multiple isosurfaces, shadows, and depth-peeling transparency effects. The resulting system offers the intuitive simplicity of isosurfacing, guaranteed-correct visual results, and ultimately a scalable, dynamic and consistently interactive solution for visualizing unstructured volumes.	Ingo Wald;Heiko Friedrich;Aaron Knoll;Charles D. Hansen	Univ. of Utah, Santa Clara|c|;;;	10.1109/VISUAL.2005.1532796;10.1109/TVCG.2006.171;10.1109/VISUAL.2003.1250390;10.1109/TVCG.2006.110;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.1998.745713;10.1109/VISUAL.1998.745300	Ray Tracing, Isosurfaces, Unstructured meshes, Tetrahedra, Scalar Fields, Time-varying data	
Vis	2007	Interactive sound rendering in complex and dynamic scenes using frustum tracing	10.1109/TVCG.2007.70567	http://dx.doi.org/10.1109/TVCG.2007.70567	1672	1679	J	We present a new approach for real-time sound rendering in complex, virtual scenes with dynamic sources and objects. Our approach combines the efficiency of interactive ray tracing with the accuracy of tracing a volumetric representation. We use a four-sided convex frustum and perform clipping and intersection tests using ray packet tracing. A simple and efficient formulation is used to compute secondary frusta and perform hierarchical traversal. We demonstrate the performance of our algorithm in an interactive system for complex environments and architectural models with tens or hundreds of thousands of triangles. Our algorithm can perform real-time simulation and rendering on a high-end PC.	Christian Lauterbach;Anish Chandak;Dinesh Manocha	Univ. of North Carolina-Chapel Hill, Chapel Hill|c|;;	10.1109/TVCG.2006.125;10.1109/VISUAL.2005.1532790	Acoustic propagation,Interactive systems	
Vis	2007	Interactive Visual Analysis of Perfusion Data	10.1109/TVCG.2007.70569	http://dx.doi.org/10.1109/TVCG.2007.70569	1392	1399	J	Perfusion data are dynamic medical image data which characterize the regional blood flow in human tissue. These data bear a great potential in medical diagnosis, since diseases can be better distinguished and detected at an earlier stage compared to static image data. The wide-spread use of perfusion data is hampered by the lack of efficient evaluation methods. For each voxel, a time-intensity curve characterizes the enhancement of a contrast agent. Parameters derived from these curves characterize the perfusion and have to be integrated for diagnosis. The diagnostic evaluation of this multi-field data is challenging and time-consuming due to its complexity. For the visual analysis of such datasets, feature-based approaches allow to reduce the amount of data and direct the user to suspicious areas. We present an interactive visual analysis approach for the evaluation of perfusion data. For this purpose, we integrate statistical methods and interactive feature specification. Correlation analysis and Principal Component Analysis (PCA) are applied for dimension reduction and to achieve a better understanding of the inter-parameter relations. Multiple, linked views facilitate the definition of features by brushing multiple dimensions. The specification result is linked to all views establishing a focus+context style of visualization in 3D. We discuss our approach with respect to clinical datasets from the three major application areas: ischemic stroke diagnosis, breast tumor diagnosis, as well as the diagnosis of the coronary heart disease (CHD). It turns out that the significance of perfusion parameters strongly depends on the individual patient, scanning parameters, and data pre-processing.	Steffen Oeltze-Jafra;Helmut Doleisch;Helwig Hauser;Philipp Muigg;Bernhard Preim	Univ. of Magdeburg, Magdeburg|c|;;;;	10.1109/VISUAL.2000.885739	Multi-field Visualization, Visual Data Mining, Time-varying Volume Data, Integrating InfoVis/SciVis	
Vis	2007	Interactive Visualization of Volumetric White Matter Connectivity in DT-MRI Using a Parallel-Hardware Hamilton-Jacobi Solver	10.1109/TVCG.2007.70571	http://dx.doi.org/10.1109/TVCG.2007.70571	1480	1487	J	In this paper we present a method to compute and visualize volumetric white matter connectivity in diffusion tensor magnetic resonance imaging (DT-MRI) using a Hamilton-Jacobi (H-J) solver on the GPU (graphics processing unit). Paths through the volume are assigned costs that are lower if they are consistent with the preferred diffusion directions. The proposed method finds a set of voxels in the DTI volume that contain paths between two regions whose costs are within a threshold of the optimal path. The result is a volumetric optimal path analysis, which is driven by clinical and scientific questions relating to the connectivity between various known anatomical regions of the brain. To solve the minimal path problem quickly, we introduce a novel numerical algorithm for solving H-J equations, which we call the fast iterative method (FIM). This algorithm is well-adapted to parallel architectures, and we present a GPU-based implementation, which runs roughly 50-100 times faster than traditional CPU-based solvers for anisotropic H-J equations. The proposed system allows users to freely change the endpoints of interesting pathways and to visualize the optimal volumetric path between them at an interactive rate. We demonstrate the proposed method on some synthetic and real DT-MRI datasets and compare the performance with existing methods.	Won-Ki Jeong;P. Thomas Fletcher;Ran Tao;Ross T. Whitaker	Univ. of Utah, Salt Lake City|c|;;;	10.1109/VISUAL.2003.1250358;10.1109/VISUAL.2003.1250357	Diffusion tensor visualization, graphics hardware, interactivity	
Vis	2007	IStar: A Raster Representation for Scalable Image and Volume Data	10.1109/TVCG.2007.70572	http://dx.doi.org/10.1109/TVCG.2007.70572	1424	1431	J	Topology has been an important tool for analyzing scalar data and flow fields in visualization. In this work, we analyze the topology of multivariate image and volume data sets with discontinuities in order to create an efficient, raster-based representation we call IStar. Specifically, the topology information is used to create a dual structure that contains nodes and connectivity information for every segmentable region in the original data set. This graph structure, along with a sampled representation of the segmented data set, is embedded into a standard raster image which can then be substantially downsampled and compressed. During rendering, the raster image is upsampled and the dual graph is used to reconstruct the original function. Unlike traditional raster approaches, our representation can preserve sharp discontinuities at any level of magnification, much like scalable vector graphics. However, because our representation is raster-based, it is well suited to the real-time rendering pipeline. We demonstrate this by reconstructing our data sets on graphics hardware at real-time rates.	Joe Michael Kniss;Warren A. Hunt;Kristin Potter;Pradeep Sen	Univ. of New Mexico, Albuquerque|c|;;;	10.1109/VISUAL.2005.1532839;10.1109/VISUAL.2005.1532807	Topology, Compression, Image Representation	
Vis	2007	Lattice-Based Volumetric Global Illumination	10.1109/TVCG.2007.70573	http://dx.doi.org/10.1109/TVCG.2007.70573	1576	1583	J	We describe a novel volumetric global illumination framework based on the face-centered cubic (FCC) lattice. An FCC lattice has important advantages over a Cartesian lattice. It has higher packing density in the frequency domain, which translates to better sampling efficiency. Furthermore, it has the maximal possible kissing number (equivalent to the number of nearest neighbors of each site), which provides optimal 3D angular discretization among all lattices. We employ a new two-pass (illumination and rendering) global illumination scheme on an FCC lattice. This scheme exploits the angular discretization to greatly simplify the computation in multiple scattering and to minimize illumination information storage. The GPU has been utilized to further accelerate the rendering stage. We demonstrate our new framework with participating media and volume rendering with multiple scattering, where both are significantly faster than traditional techniques with comparable quality.	Feng Qiu;Fang Xu;Zhe Fan;Neophytos Neophytou;Arie E. Kaufman;Klaus Mueller	Stony Brook Univ., Stony Brook|c|;;;;;	10.1109/VISUAL.2004.65;10.1109/VISUAL.2001.964498;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2005.1532811	Volume visualization, volume rendering, participating media, lattice, FCC lattice, sampling, multiple scattering, GPU	
Vis	2007	Listener-based Analysis of Surface Importance for Acoustic Metrics	10.1109/TVCG.2007.70575	http://dx.doi.org/10.1109/TVCG.2007.70575	1680	1687	J	Acoustic quality in room acoustics is measured by well defined quantities, like definition, which can be derived from simulated impulse response filters or measured values. These take into account the intensity and phase shift of multiple reflections due to a wave front emanating from a sound source. Definition (D50) and clarity (C50) for example correspond to the fraction of the energy received in total to the energy received in the first 50 ms at a certain listener position. Unfortunately, the impulse response measured at a single point does not provide any information about the direction of reflections, and about the reflection surfaces which contribute to this measure. For the visualization of room acoustics, however, this information is very useful since it allows to discover regions with high contribution and provides insight into the influence of all reflecting surfaces to the quality measure. We use the phonon tracing method to calculate the contribution of the reflection surfaces to the impulse response for different listener positions. This data is used to compute importance values for the geometry taking a certain acoustic metric into account. To get a visual insight into the directional aspect, we map the importance to the reflecting surfaces of the geometry. This visualization indicates which parts of the surfaces need to be changed to enhance the chosen acoustic quality measure. We apply our method to the acoustic improvement of a lecture hall by means of enhancing the overall speech comprehensibility (clarity) and evaluate the results using glyphs to visualize the clarity (C50) values at listener positions throughout the room.	Frank Michel;Eduard Deines;Martin Hering-Bertram;Christoph Garth;Hans Hagen	IRTG Kaiserslautern, Kaiserslautern|c|;;;;	10.1109/TVCG.2006.125;10.1109/VISUAL.2005.1532790	Sound analytics, Applications of Visualization, Room Acoustics, Phonon Tracing, Acoustic Metric	
Vis	2007	LiveSync: Deformed Viewing Spheres for Knowledge-Based Navigation	10.1109/TVCG.2007.70576	http://dx.doi.org/10.1109/TVCG.2007.70576	1544	1551	J	Although real-time interactive volume rendering is available even for very large data sets, this visualization method is used quite rarely in the clinical practice. We suspect this is because it is very complicated and time consuming to adjust the parameters to achieve meaningful results. The clinician has to take care of the appropriate viewpoint, zooming, transfer function setup, clipping planes and other parameters. Because of this, most often only 2D slices of the data set are examined. Our work introduces LiveSync, a new concept to synchronize 2D slice views and volumetric views of medical data sets. Through intuitive picking actions on the slice, the users define the anatomical structures they are interested in. The 3D volumetric view is updated automatically with the goal that the users are provided with expressive result images. To achieve this live synchronization we use a minimal set of derived information without the need for segmented data sets or data-specific pre-computations. The components we consider are the picked point, slice view zoom, patient orientation, viewpoint history, local object shape and visibility. We introduce deformed viewing spheres which encode the viewpoint quality for the components. A combination of these deformed viewing spheres is used to estimate a good viewpoint. Our system provides the physician with synchronized views which help to gain deeper insight into the medical data with minimal user interaction.	Peter Kohlmann;Stefan Bruckner;Armin Kanitsar;Eduard Gröller	Vienna Univ. of Technol., Vienna|c|;;;	10.1109/VISUAL.2005.1532834;10.1109/TVCG.2006.152;10.1109/VISUAL.2005.1532833	Navigation, interaction, linked views, medical visualization, viewpoint selection	
Vis	2007	Molecular Surface Abstraction	10.1109/TVCG.2007.70578	http://dx.doi.org/10.1109/TVCG.2007.70578	1608	1615	J	In this paper we introduce a visualization technique that provides an abstracted view of the shape and spatio-physico-chemical properties of complex molecules. Unlike existing molecular viewing methods, our approach suppresses small details to facilitate rapid comprehension, yet marks the location of significant features so they remain visible. Our approach uses a combination of filters and mesh restructuring to generate a simplified representation that conveys the overall shape and spatio-physico-chemical properties (e.g. electrostatic charge). Surface markings are then used in the place of important removed details, as well as to supply additional information. These simplified representations are amenable to display using stylized rendering algorithms to further enhance comprehension. Our initial experience suggests that our approach is particularly useful in browsing collections of large molecules and in readily making comparisons between them.	Gregory Cipriano;Michael Gleicher	Univ. of Wisconsin, Madison|c|;	10.1109/VISUAL.1993.398882;10.1109/VISUAL.2002.1183769;10.1109/VISUAL.2005.1532822;10.1109/VISUAL.2002.1183780;10.1109/VISUAL.2004.62;10.1109/TVCG.2006.115	molecular surfaces, molecular visualization, surfaces, textures, cartographic labeling	
Vis	2007	Moment Invariants for the Analysis of 2D Flow fields	10.1109/TVCG.2007.70579	http://dx.doi.org/10.1109/TVCG.2007.70579	1743	1750	J	We present a novel approach for analyzing two-dimensional (2D) flow field data based on the idea of invariant moments. Moment invariants have traditionally been used in computer vision applications, and we have adapted them for the purpose of interactive exploration of flow field data. The new class of moment invariants we have developed allows us to extract and visualize 2D flow patterns, invariant under translation, scaling, and rotation. With our approach one can study arbitrary flow patterns by searching a given 2D flow data set for any type of pattern as specified by a user. Further, our approach supports the computation of moments at multiple scales, facilitating fast pattern extraction and recognition. This can be done for critical point classification, but also for patterns with greater complexity. This multi-scale moment representation is also valuable for the comparative visualization of flow field data. The specific novel contributions of the work presented are the mathematical derivation of the new class of moment invariants, their analysis regarding critical point features, the efficient computation of a novel feature space representation, and based upon this the development of a fast pattern recognition algorithm for complex flow structures.	Michael Schlemmer;Manuel Heringer;Florian Morr;Ingrid Hotz;Martin Hering-Bertram;Christoph Garth;Wolfgang Kollmann;Bernd Hamann;Hans Hagen	Univ. of Kaiserslautern, Kaiserslautern|c|;;;;;;;;	10.1109/VISUAL.2004.68;10.1109/VISUAL.1999.809873;10.1109/VISUAL.2005.1532858;10.1109/VISUAL.2003.1250372	Flow Visualization, Feature Detection, Pattern Extraction, Pattern Recognition, Image Processing	
Vis	2007	Navigating in a Shape Space of Registered Models	10.1109/TVCG.2007.70581	http://dx.doi.org/10.1109/TVCG.2007.70581	1552	1559	J	New product development involves people with different backgrounds. Designers, engineers, and consumers all have different design criteria, and these criteria interact. Early concepts evolve in this kind of collaborative context, and there is a need for dynamic visualization of the interaction between design shape and other shape-related design criteria. In this paper, a morphable model is defined from simplified representations of suitably chosen real cars, providing a continuous shape space to navigate, manipulate and visualize. Physical properties and consumer-provided scores for the real cars (such as 'weight' and 'sportiness') are estimated for new designs across the shape space. This coupling allows one to manipulate the shape directly while reviewing the impact on estimated criteria, or conversely, to manipulate the criterial values of the current design to produce a new shape with more desirable attributes.	Randall C. Smith;Richard R. Pawlicki;István Kókai;Jörg Finger;Thomas Vetter	GM R&D, Bangalore|c|;;;;		Morphable model, shape space, barycentric coordinates, design space	
Vis	2007	Querying and Creating Visualizations by Analogy	10.1109/TVCG.2007.70584	http://dx.doi.org/10.1109/TVCG.2007.70584	1560	1567	J	While there have been advances in visualization systems, particularly in multi-view visualizations and visual exploration, the process of building visualizations remains a major bottleneck in data exploration. We show that provenance metadata collected during the creation of pipelines can be reused to suggest similar content in related visualizations and guide semi-automated changes. We introduce the idea of query-by-example in the context of an ensemble of visualizations, and the use of analogies as first-class operations in a system to guide scalable interactions. We describe an implementation of these techniques in VisTrails, a publicly-available, open-source system.	Carlos Eduardo Scheidegger;Huy T. Vo;David Koop;Juliana Freire;Cláudio T. Silva	Univ. of Utah, Salt Lake|c|;;;;	10.1109/VISUAL.2005.1532781;10.1109/INFVIS.2004.2;10.1109/VISUAL.2004.112;10.1109/VISUAL.2005.1532788;10.1109/VISUAL.2005.1532795	visualization systems, query-by-example, analogy	
Vis	2007	Random-Accessible Compressed Triangle Meshes	10.1109/TVCG.2007.70585	http://dx.doi.org/10.1109/TVCG.2007.70585	1536	1543	J	With the exponential growth in size of geometric data, it is becoming increasingly important to make effective use of multilevel caches, limited disk storage, and bandwidth. As a result, recent work in the visualization community has focused either on designing sequential access compression schemes or on producing cache-coherent layouts of (uncompressed) meshes for random access. Unfortunately combining these two strategies is challenging as they fundamentally assume conflicting modes of data access. In this paper, we propose a novel order-preserving compression method that supports transparent random access to compressed triangle meshes. Our decompression method selectively fetches from disk, decodes, and caches in memory requested parts of a mesh. We also provide a general mesh access API for seamless mesh traversal and incidence queries. While the method imposes no particular mesh layout, it is especially suitable for cache-oblivious layouts, which minimize the number of decompression I/O requests and provide high cache utilization during access to decompressed, in-memory portions of the mesh. Moreover, the transparency of our scheme enables improved performance without the need for application code changes. We achieve compression rates on the order of 20:1 and significantly improved I/O performance due to reduced data transfer. To demonstrate the benefits of our method, we implement two common applications as benchmarks. By using cache-oblivious layouts for the input models, we observe 2-6 times overall speedup compared to using uncompressed meshes.	Sung-Eui Yoon;Peter Lindstrom	Korea Adv. Inst. of Sci. & Technol.|c|;	10.1109/VISUAL.2002.1183796;10.1109/TVCG.2006.143;10.1109/VISUAL.2005.1532800;10.1109/TVCG.2006.162;10.1109/VISUAL.2001.964532	Mesh compression, random access, cache-coherent layouts, mesh data structures, external memory algorithms	
Vis	2007	Registration Techniques for Using Imperfect and Par tially Calibrated Devices in Planar Multi-Projector Displays	10.1109/TVCG.2007.70586	http://dx.doi.org/10.1109/TVCG.2007.70586	1368	1375	J	Multi-projector displays today are automatically registered, both geometrically and photometrically, using cameras. Existing registration techniques assume pre-calibrated projectors and cameras that are devoid of imperfections such as lens distortion. In practice, however, these devices are usually imperfect and uncalibrated. Registration of each of these devices is often more challenging than the multi-projector display registration itself. To make tiled projection-based displays accessible to a layman user we should allow the use of uncalibrated inexpensive devices that are prone to imperfections. In this paper, we make two important advances in this direction. First, we present a new geometric registration technique that can achieve geometric alignment in the presence of severe projector lens distortion using a relatively inexpensive low-resolution camera. This is achieved via a closed-form model that relates the projectors to cameras, in planar multi-projector displays, using rational Bezier patches. This enables us to geometrically calibrate a 3000 times 2500 resolution planar multi-projector display made of 3 times 3 array of nine severely distorted projectors using a low resolution (640 times 480) VGA camera. Second, we present a photometric self-calibration technique for a projector-camera pair. This allows us to photometrically calibrate the same display made of nine projectors using a photometrically uncalibrated camera. To the best of our knowledge, this is the first work that allows geometrically imperfect projectors and photometrically uncalibrated cameras in calibrating multi-projector displays.	Ezekiel S. Bhasker;Ray Juang;Aditi Majumder	Univ. of California, Irvine|c|;;	10.1109/VISUAL.2001.964508;10.1109/TVCG.2006.121;10.1109/VISUAL.2000.885685;10.1109/VISUAL.2002.1183793;10.1109/VISUAL.2000.885684;10.1109/VISUAL.1999.809883	Geometric calibration, photometric calibration, tiled displays	
Vis	2007	Tile-based Level of Detail for the Parallel Age 	10.1109/TVCG.2007.70587	http://dx.doi.org/10.1109/TVCG.2007.70587	1352	1359	J	Today's PCs incorporate multiple CPUs and GPUs and are easily arranged in clusters for high-performance, interactive graphics. We present an approach based on hierarchical, screen-space tiles to parallelizing rendering with level of detail. Adapt tiles, render tiles, and machine tiles are associated with CPUs, GPUs, and PCs, respectively, to efficiently parallelize the workload with good resource utilization. Adaptive tile sizes provide load balancing while our level of detail system allows total and independent management of the load on CPUs and GPUs. We demonstrate our approach on parallel configurations consisting of both single PCs and a cluster of PCs.	Krzysztof Niski;Jonathan D. Cohen	NVIDIA Corp., Santa Clara|c|;	10.1109/VISUAL.2005.1532786	Geometric calibration, photometric calibration, tiled displays	
Vis	2007	Scalable Hybrid Unstructured and Structured Grid Raycasting	10.1109/TVCG.2007.70588	http://dx.doi.org/10.1109/TVCG.2007.70588	1592	1599	J	This paper presents a scalable framework for real-time raycasting of large unstructured volumes that employs a hybrid bricking approach. It adaptively combines original unstructured bricks in important (focus) regions, with structured bricks that are resampled on demand in less important (context) regions. The basis of this focus+context approach is interactive specification of a scalar degree of interest (DOI) function. Thus, rendering always considers two volumes simultaneously: a scalar data volume, and the current DOI volume. The crucial problem of visibility sorting is solved by raycasting individual bricks and compositing in visibility order from front to back. In order to minimize visual errors at the grid boundary, it is always rendered accurately, even for resampled bricks. A variety of different rendering modes can be combined, including contour enhancement. A very important property of our approach is that it supports a variety of cell types natively, i.e., it is not constrained to tetrahedral grids, even when interpolation within cells is used. Moreover, our framework can handle multi-variate data, e.g., multiple scalar channels such as temperature or pressure, as well as time-dependent data. The combination of unstructured and structured bricks with different quality characteristics such as the type of interpolation or resampling resolution in conjunction with custom texture memory management yields a very scalable system.	Philipp Muigg;Markus Hadwiger;Helmut Doleisch;Helwig Hauser	VRVis Res. Center|c|;;;	10.1109/TVCG.2006.171;10.1109/VISUAL.2003.1250390;10.1109/TVCG.2006.124;10.1109/VISUAL.2001.964514;10.1109/TVCG.2006.152;10.1109/TVCG.2006.110;10.1109/TVCG.2006.154;10.1109/VISUAL.2000.885683;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2001.964512;10.1109/VISUAL.1999.809908	Volume Rendering of Unstructured Grids, Focus+Context Techniques, Hardware-Assisted Volume Rendering	
Vis	2007	Segmentation of Three-dimensional Retinal Image Data	10.1109/TVCG.2007.70590	http://dx.doi.org/10.1109/TVCG.2007.70590	1719	1726	J	We have combined methods from volume visualization and data analysis to support better diagnosis and treatment of human retinal diseases. Many diseases can be identified by abnormalities in the thicknesses of various retinal layers captured using optical coherence tomography (OCT). We used a support vector machine (SVM) to perform semi-automatic segmentation of retinal layers for subsequent analysis including a comparison of layer thicknesses to known healthy parameters. We have extended and generalized an older SVM approach to support better performance in a clinical setting through performance enhancements and graceful handling of inherent noise in OCT data by considering statistical characteristics at multiple levels of resolution. The addition of the multi-resolution hierarchy extends the SVM to have "global awareness". A feature, such as a retinal layer, can therefore be modeled within the SVM as a combination of statistical characteristics across all levels; thus capturing high- and low-frequency information. We have compared our semi-automatically generated segmentations to manually segmented layers for verification purposes. Our main goals were to provide a tool that could (i) be used in a clinical setting; (ii) operate on noisy OCT data; and (iii) isolate individual or multiple retinal layers in both healthy and disease cases that contain structural deformities.	Alfred R. Fuller;Robert Zawadzki;Stacey Choi;David F. Wiley;John Werner;Bernd Hamann	Univ. of California at Davis, Davis|c|;;;;;	10.1109/VISUAL.2001.964519;10.1109/VISUAL.2003.1250413	support vector machine, segmentation, image analysis, retinal, optical coherence tomography, volume visualization, image processing	
Vis	2007	Semantic Layers for Illustrative Volume Rendering	10.1109/TVCG.2007.70591	http://dx.doi.org/10.1109/TVCG.2007.70591	1336	1343	J	Direct volume rendering techniques map volumetric attributes (e.g., density, gradient magnitude, etc.) to visual styles. Commonly this mapping is specified by a transfer function. The specification of transfer functions is a complex task and requires expert knowledge about the underlying rendering technique. In the case of multiple volumetric attributes and multiple visual styles the specification of the multi-dimensional transfer function becomes more challenging and non-intuitive. We present a novel methodology for the specification of a mapping from several volumetric attributes to multiple illustrative visual styles. We introduce semantic layers that allow a domain expert to specify the mapping in the natural language of the domain. A semantic layer defines the mapping of volumetric attributes to one visual style. Volumetric attributes and visual styles are represented as fuzzy sets. The mapping is specified by rules that are evaluated with fuzzy logic arithmetics. The user specifies the fuzzy sets and the rules without special knowledge about the underlying rendering technique. Semantic layers allow for a linguistic specification of the mapping from attributes to visual styles replacing the traditional transfer function specification.	Peter Rautek;Stefan Bruckner;Eduard Gröller	Vienna Univ. of Technol., Vienna|c|;;	10.1109/VISUAL.2004.95;10.1109/VISUAL.2005.1532792;10.1109/VISUAL.2005.1532807;10.1109/VISUAL.2003.1250414;10.1109/VISUAL.2004.64;10.1109/VISUAL.2005.1532856;10.1109/TVCG.2006.164;10.1109/TVCG.2006.148	Illustrative Visualization, Focus+Context Techniques, Volume Visualization	
Vis	2007	Shadow-Driven 4D Haptic Visualization	10.1109/TVCG.2007.70593	http://dx.doi.org/10.1109/TVCG.2007.70593	1688	1695	J	Just as we can work with two-dimensional floor plans to communicate 3D architectural design, we can exploit reduced- dimension shadows to manipulate the higher-dimensional objects generating the shadows. In particular, by taking advantage of physically reactive 3D shadow-space controllers, we can transform the task of interacting with 4D objects to a new level of physical reality. We begin with a teaching tool that uses 2D knot diagrams to manipulate the geometry of 3D mathematical knots via their projections; our unique 2D haptic interface allows the user to become familiar with sketching, editing, exploration, and manipulation of 3D knots rendered as projected images on a 2D shadow space. By combining graphics and collision-sensing haptics, we can enhance the 2D shadow-driven editing protocol to successfully leverage 2D pen-and-paper or blackboard skills. Building on the reduced-dimension 2D editing tool for manipulating 3D shapes, we develop the natural analogy to produce a reduced-dimension 3D tool for manipulating 4D shapes. By physically modeling the correct properties of 4D surfaces, their bending forces, and their collisions in the 3D haptic controller interface, we can support full-featured physical exploration of 4D mathematical objects in a manner that is otherwise far beyond the experience accessible to human beings. As far as we are aware, this paper reports the first interactive system with force-feedback that provides "4D haptic visualization" permitting the user to model and interact with 4D cloth-like objects.	Hui Zhang 0006;Andrew J. Hanson	Indiana Univ., Bloomington|c|;	10.1109/VISUAL.1996.568120;10.1109/VISUAL.2005.1532804	knot theory, haptics, visualization	
Vis	2007	Similarity-Guided Streamline Placement with Error Evaluation	10.1109/TVCG.2007.70595	http://dx.doi.org/10.1109/TVCG.2007.70595	1448	1455	J	Most streamline generation algorithms either provide a particular density of streamlines across the domain or explicitly detect features, such as critical points, and follow customized rules to emphasize those features. However, the former generally includes many redundant streamlines, and the latter requires Boolean decisions on which points are features (and may thus suffer from robustness problems for real-world data). We take a new approach to adaptive streamline placement for steady vector fields in 2D and 3D. We define a metric for local similarity among streamlines and use this metric to grow streamlines from a dense set of candidate seed points. The metric considers not only Euclidean distance, but also a simple statistical measure of shape and directional similarity. Without explicit feature detection, our method produces streamlines that naturally accentuate regions of geometric interest. In conjunction with this method, we also propose a quantitative error metric for evaluating a streamline representation based on how well it preserves the information from the original vector field. This error metric reconstructs a vector field from points on the streamline representation and computes a difference of the reconstruction from the original vector field.	Yuan Chen;Jonathan D. Cohen;Julian Krolik	Johns Hopkins Univ., Baltimore|c|;;	10.1109/VISUAL.2005.1532831;10.1109/VISUAL.2005.1532832;10.1109/VISUAL.2004.87;10.1109/VISUAL.2001.964530;10.1109/TVCG.2006.116;10.1109/VISUAL.2000.885690	Adaptive streamlines, vector field reconstruction, shape matching	
Vis	2007	Stochastic DT-MRI Connectivity Mapping on the GPU	10.1109/TVCG.2007.70597	http://dx.doi.org/10.1109/TVCG.2007.70597	1504	1511	J	We present a method for stochastic fiber tract mapping from diffusion tensor MRI (DT-MRI) implemented on graphics hardware. From the simulated fibers we compute a connectivity map that gives an indication of the probability that two points in the dataset are connected by a neuronal fiber path. A Bayesian formulation of the fiber model is given and it is shown that the inversion method can be used to construct plausible connectivity. An implementation of this fiber model on the graphics processing unit (GPU) is presented. Since the fiber paths can be stochastically generated independently of one another, the algorithm is highly parallelizable. This allows us to exploit the data-parallel nature of the GPU fragment processors. We also present a framework for the connectivity computation on the GPU. Our implementation allows the user to interactively select regions of interest and observe the evolving connectivity results during computation. Results are presented from the stochastic generation of over 250,000 fiber steps per iteration at interactive frame rates on consumer-grade graphics hardware.	Tim McGraw;Mariappan S. Nadar	West Virginia Univ, Morgantown|c|;	10.1109/VISUAL.2005.1532780;10.1109/TVCG.2006.134;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.1998.745294;10.1109/VISUAL.1999.809886;10.1109/VISUAL.2005.1532779;10.1109/VISUAL.2005.1532777;10.1109/VISUAL.1999.809904;10.1109/TVCG.2006.151	diffusion tensor, magnetic resonance imaging, stochastic tractography	
Vis	2007	Surface Extraction from Multi-Material Components for Metrology using Dual Energy CT	10.1109/TVCG.2007.70598	http://dx.doi.org/10.1109/TVCG.2007.70598	1520	1527	J	This paper describes a novel method for creating surface models of multi-material components using dual energy computed tomography (DECT). The application scenario is metrology and dimensional measurement in industrial high resolution 3D X-ray computed tomography (3DCT). Based on the dual source / dual exposure technology this method employs 3DCT scans of a high precision micro-focus and a high energy macro-focus X-ray source. The presented work makes use of the advantages of dual X-ray exposure technology in order to facilitate dimensional measurements of multi-material components with high density material within low density material. We propose a workflow which uses image fusion and local surface extraction techniques: a prefiltering step reduces noise inherent in the data. For image fusion the datasets have to be registered. In the fusion step the benefits of both scans are combined. The structure of the specimen is taken from the low precision, blurry, high energy dataset while the sharp edges are adopted and fused into the resulting image from the high precision, crisp, low energy dataset. In the final step a reliable surface model is extracted from the fused dataset using a local adaptive technique. The major contribution of this paper is the development of a specific workflow for dimensional measurements of multi-material industrial components, which takes two X-ray CT datasets with complementary strengths and weaknesses into account. The performance of the workflow is discussed using a test specimen as well as two real world industrial parts. As result, a significant improvement in overall measurement precision, surface geometry and mean deviation to reference measurement compared to single exposure scans was facilitated.	Christoph Heinzl;Johann Kastner;Eduard Gröller	Upper Austrian Univ. of Appl. Sci., Wels|c|;;	10.1109/VISUAL.2003.1250418;10.1109/VISUAL.2001.964519	DECT image fusion, local surface extraction, Dual Energy CT, metrology, dimensional measurement, variance comparison	
Vis	2007	Texture-based feature tracking for effective time-varying data visualization	10.1109/TVCG.2007.70599	http://dx.doi.org/10.1109/TVCG.2007.70599	1472	1479	J	Analyzing, visualizing, and illustrating changes within time-varying volumetric data is challenging due to the dynamic changes occurring between timesteps. The changes and variations in computational fluid dynamic volumes and atmospheric 3D datasets do not follow any particular transformation. Features within the data move at different speeds and directions making the tracking and visualization of these features a difficult task. We introduce a texture-based feature tracking technique to overcome some of the current limitations found in the illustration and visualization of dynamic changes within time-varying volumetric data. Our texture-based technique tracks various features individually and then uses the tracked objects to better visualize structural changes. We show the effectiveness of our texture-based tracking technique with both synthetic and real world time-varying data. Furthermore, we highlight the specific visualization, annotation, registration, and feature isolation benefits of our technique. For instance, we show how our texture-based tracking can lead to insightful visualizations of time-varying data. Such visualizations, more than traditional visualization techniques, can assist domain scientists to explore and understand dynamic changes.	Jesus J. Caban;Alark Joshi;Penny Rheingans	Univ. of Maryland Baltimore County, Baltimore|c|;;	10.1109/VISUAL.2003.1250374;10.1109/VISUAL.2000.885694;10.1109/VISUAL.1998.745288;10.1109/VISUAL.1996.567807	Feature tracking, texture-based analysis, flow visualization, time-varying data, visualization	
Vis	2007	Time Dependent Processing in a Parallel Pipeline Architecture	10.1109/TVCG.2007.70600	http://dx.doi.org/10.1109/TVCG.2007.70600	1376	1383	J	Pipeline architectures provide a versatile and efficient mechanism for constructing visualizations, and they have been implemented in numerous libraries and applications over the past two decades. In addition to allowing developers and users to freely combine algorithms, visualization pipelines have proven to work well when streaming data and scale well on parallel distributed- memory computers. However, current pipeline visualization frameworks have a critical flaw: they are unable to manage time varying data. As data flows through the pipeline, each algorithm has access to only a single snapshot in time of the data. This prevents the implementation of algorithms that do any temporal processing such as particle tracing; plotting over time; or interpolation, fitting, or smoothing of time series data. As data acquisition technology improves, as simulation time-integration techniques become more complex, and as simulations save less frequently and regularly, the ability to analyze the time-behavior of data becomes more important. This paper describes a modification to the traditional pipeline architecture that allows it to accommodate temporal algorithms. Furthermore, the architecture allows temporal algorithms to be used in conjunction with algorithms expecting a single time snapshot, thus simplifying software design and allowing adoption into existing pipeline frameworks. Our architecture also continues to work well in parallel distributed-memory environments. We demonstrate our architecture by modifying the popular VTK framework and exposing the functionality to the ParaView application. We use this framework to apply time-dependent algorithms on large data with a parallel cluster computer and thereby exercise a functionality that previously did not exist.	John Biddiscombe;Berk Geveci;Ken Martin;Kenneth Moreland;David S. Thompson	Swiss Nat. Supercomput. Centre, Manno|c|;;;;	10.1109/VISUAL.2005.1532793;10.1109/VISUAL.1992.235219;10.1109/VISUAL.2005.1532795;10.1109/VISUAL.1991.175794;10.1109/VISUAL.2004.55;10.1109/INFVIS.2000.885092;10.1109/VISUAL.1995.480821	data-parallel visualization pipeline, time-varying data	
Vis	2007	Topological Landscapes: A Terrain Metaphor for Scientific Data	10.1109/TVCG.2007.70601	http://dx.doi.org/10.1109/TVCG.2007.70601	1416	1423	J	Scientific visualization and illustration tools are designed to help people understand the structure and complexity of scientific data with images that are as informative and intuitive as possible. In this context the use of metaphors plays an important role since they make complex information easily accessible by using commonly known concepts. In this paper we propose a new metaphor, called "topological landscapes," which facilitates understanding the topological structure of scalar functions. The basic idea is to construct a terrain with the same topology as a given dataset and to display the terrain as an easily understood representation of the actual input data. In this projection from an n-dimensional scalar function to a two-dimensional (2D) model we preserve function values of critical points, the persistence (function span) of topological features, and one possible additional metric property (in our examples volume). By displaying this topologically equivalent landscape together with the original data we harness the natural human proficiency in understanding terrain topography and make complex topological information easily accessible.	Gunther H. Weber;Peer-Timo Bremer;Valerio Pascucci	Lawrence Berkeley Nat. Lab., Berkeley|c|;;	10.1109/VISUAL.2004.96;10.1109/VISUAL.1998.745303;10.1109/VISUAL.1992.235215;10.1109/VISUAL.1999.809932;10.1109/INFVIS.2004.57;10.1109/VISUAL.1997.663860;10.1109/VISUAL.1997.663875;10.1109/INFVIS.2002.1173159;10.1109/VISUAL.2002.1183772;10.1109/VISUAL.2005.1532839;10.1109/VISUAL.2003.1250376	Feature Detection, User Interfaces, Visual Analytics, Contour Tree, Terrain, Topology, SOAR	
Vis	2007	Topological Visualization of Brain Diffusion MRI Data	10.1109/TVCG.2007.70602	http://dx.doi.org/10.1109/TVCG.2007.70602	1496	1503	J	Topological methods give concise and expressive visual representations of flow fields. The present work suggests a comparable method for the visualization of human brain diffusion MRI data. We explore existing techniques for the topological analysis of generic tensor fields, but find them inappropriate for diffusion MRI data. Thus, we propose a novel approach that considers the asymptotic behavior of a probabilistic fiber tracking method and define analogs of the basic concepts of flow topology, like critical points, basins, and faces, with interpretations in terms of brain anatomy. The resulting features are fuzzy, reflecting the uncertainty inherent in any connectivity estimate from diffusion imaging. We describe an algorithm to extract the new type of features, demonstrate its robustness under noise, and present results for two regions in a diffusion MRI dataset to illustrate that the method allows a meaningful visual analysis of probabilistic fiber tracking results.	Thomas Schultz 0001;Holger Theisel;Hans-Peter Seidel	MPI Inf., Saarbrucken|c|;;	10.1109/VISUAL.1999.809894;10.1109/VISUAL.2005.1532777;10.1109/VISUAL.2005.1532841;10.1109/VISUAL.1994.346326;10.1109/VISUAL.2005.1532778;10.1109/VISUAL.1994.346326	Diffusion tensor, probabilistic fiber tracking, tensor topology, uncertainty visualization	
Vis	2007	Topologically Clean Distance fields	10.1109/TVCG.2007.70603	http://dx.doi.org/10.1109/TVCG.2007.70603	1432	1439	J	Analysis of the results obtained from material simulations is important in the physical sciences. Our research was motivated by the need to investigate the properties of a simulated porous solid as it is hit by a projectile. This paper describes two techniques for the generation of distance fields containing a minimal number of topological features, and we use them to identify features of the material. We focus on distance fields defined on a volumetric domain considering the distance to a given surface embedded within the domain. Topological features of the field are characterized by its critical points. Our first method begins with a distance field that is computed using a standard approach, and simplifies this field using ideas from Morse theory. We present a procedure for identifying and extracting a feature set through analysis of the MS complex, and apply it to find the invariants in the clean distance field. Our second method proceeds by advancing a front, beginning at the surface, and locally controlling the creation of new critical points. We demonstrate the value of topologically clean distance fields for the analysis of filament structures in porous solids. Our methods produce a curved skeleton representation of the filaments that helps material scientists to perform a detailed qualitative and quantitative analysis of pores, and hence infer important material properties. Furthermore, we provide a set of criteria for finding the "difference" between two skeletal structures, and use this to examine how the structure of the porous solid changes over several timesteps in the simulation of the particle impact.	Attila Gyulassy;Mark A. Duchaineau;Vijay Natarajan;Valerio Pascucci;Eduardo Bringa;Andrew Higginbotham;Bernd Hamann	Univ. of California at Davis, Davis|c|;;;;;;	10.1109/VISUAL.2005.1532839;10.1109/VISUAL.2005.1532783;10.1109/VISUAL.2003.1250356;10.1109/VISUAL.2004.96;10.1109/VISUAL.2000.885680;10.1109/VISUAL.2000.885703	Morse theory, Morse-Smale complex, distance field, topological simplification, wavefront, critical point, porous solid, material science	
Vis	2007	Topology, Accuracy, and Quality of Isosurface Meshes Using Dynamic Particles	10.1109/TVCG.2007.70604	http://dx.doi.org/10.1109/TVCG.2007.70604	1704	1711	J	This paper describes a method for constructing isosurface triangulations of sampled, volumetric, three-dimensional scalar fields. The resulting meshes consist of triangles that are of consistently high quality, making them well suited for accurate interpolation of scalar and vector-valued quantities, as required for numerous applications in visualization and numerical simulation. The proposed method does not rely on a local construction or adjustment of triangles as is done, for instance, in advancing wavefront or adaptive refinement methods. Instead, a system of dynamic particles optimally samples an implicit function such that the particles' relative positions can produce a topologically correct Delaunay triangulation. Thus, the proposed method relies on a global placement of triangle vertices. The main contributions of the paper are the integration of dynamic particles systems with surface sampling theory and PDE-based methods for controlling the local variability of particle densities, as well as detailing a practical method that accommodates Delaunay sampling requirements to generate sparse sets of points for the production of high-quality tessellations.	Miriah D. Meyer;Robert Michael Kirby;Ross T. Whitaker	Univ. of Utah, Salt Lake City|c|;;	10.1109/VISUAL.2002.1183766;10.1109/VISUAL.2003.1250414;10.1109/VISUAL.2003.1250363;10.1109/TVCG.2006.149;10.1109/VISUAL.2002.1183808;10.1109/VISUAL.2000.885705	Isosurface extraction, particle systems, Delaunay triangulation	
Vis	2007	Virtual Rheoscopic Fluids for Flow Visualization	10.1109/TVCG.2007.70610	http://dx.doi.org/10.1109/TVCG.2007.70610	1751	1758	J	Physics-based flow visualization techniques seek to mimic laboratory flow visualization methods with virtual analogues. In this work we describe the rendering of a virtual rheoscopic fluid to produce images with results strikingly similar to laboratory experiments with real-world rheoscopic fluids using products such as Kalliroscope. These fluid additives consist of microscopic, anisotropic particles which, when suspended in the flow, align with both the flow velocity and the local shear to produce high-quality depictions of complex flow structures. Our virtual rheoscopic fluid is produced by defining a closed-form formula for the orientation of shear layers in the flow and using this orientation to volume render the flow as a material with anisotropic reflectance and transparency. Examples are presented for natural convection, thermocapillary convection, and Taylor-Couette flow simulations. The latter agree well with photographs of experimental results of Taylor-Couette flows from the literature.	William L. Barth;Christopher Burns	Texas Advanced Computing Center, Austin|c|;	10.1109/VISUAL.2004.5	Flow visualization, rheoscopic fluids	
Vis	2007	Visual Verification and Analysis of Cluster Detection for Molecular Dynamics	10.1109/TVCG.2007.70614	http://dx.doi.org/10.1109/TVCG.2007.70614	1624	1631	J	A current research topic in molecular thermodynamics is the condensation of vapor to liquid and the investigation of this process at the molecular level. Condensation is found in many physical phenomena, e.g. the formation of atmospheric clouds or the processes inside steam turbines, where a detailed knowledge of the dynamics of condensation processes will help to optimize energy efficiency and avoid problems with droplets of macroscopic size. The key properties of these processes are the nucleation rate and the critical cluster size. For the calculation of these properties it is essential to make use of a meaningful definition of molecular clusters, which currently is a not completely resolved issue. In this paper a framework capable of interactively visualizing molecular datasets of such nucleation simulations is presented, with an emphasis on the detected molecular clusters. To check the quality of the results of the cluster detection, our framework introduces the concept of flow groups to highlight potential cluster evolution over time which is not detected by the employed algorithm. To confirm the findings of the visual analysis, we coupled the rendering view with a schematic view of the clusters' evolution. This allows to rapidly assess the quality of the molecular cluster detection algorithm and to identify locations in the simulation data in space as well as in time where the cluster detection fails. Thus, thermodynamics researchers can eliminate weaknesses in their cluster detection algorithms. Several examples for the effective and efficient usage of our tool are presented.	Sebastian Grottel;Guido Reina;Jadran Vrabec;Thomas Ertl	Univ. Stuttgart, Stuttgart|c|;;;	10.1109/VISUAL.2003.1250404;10.1109/VISUAL.2002.1183811;10.1109/TVCG.2006.115;10.1109/VISUAL.2004.103;10.1109/TVCG.2006.186;10.1109/VISUAL.2003.1250404	Cluster detection analysis, molecular dynamics visualization, time-dependent scattered data, glyph visualization, out-of-core techniques, evolution graph vie	
Vis	2007	Multifield Visualization Using Local Statistical Complexity	10.1109/TVCG.2007.70615	http://dx.doi.org/10.1109/TVCG.2007.70615	1384	1391	J	Modern unsteady (multi-)field visualizations require an effective reduction of the data to be displayed. From a huge amount of information the most informative parts have to be extracted. Instead of the fuzzy application dependent notion of feature, a new approach based on information theoretic concepts is introduced in this paper to detect important regions. This is accomplished by extending the concept of local statistical complexity from finite state cellular automata to discretized (multi-)fields. Thus, informative parts of the data can be highlighted in an application-independent, purely mathematical sense. The new measure can be applied to unsteady multifields on regular grids in any application domain. The ability to detect and visualize important parts is demonstrated using diffusion, flow, and weather simulations.	Heike Leitte;Alexander Wiebel;Gerik Scheuermann;Wolfgang Kollmann	Univ. of Leipzig, Leipzig|c|;;;	10.1109/VISUAL.1999.809865;10.1109/VISUAL.2003.1250372;10.1109/TVCG.2006.165;10.1109/VISUAL.1999.809905;10.1109/TVCG.2006.183;10.1109/VISUAL.2003.1250383	Local statistical complexity, multifield visualization, time-dependent, coherent structures, feature detection, information theroy, flow visualization	
InfoVis	2008	A Framework of Interaction Costs in Information Visualization	10.1109/TVCG.2008.109	http://dx.doi.org/10.1109/TVCG.2008.109	1149	1156	J	Interaction cost is an important but poorly understood factor in visualization design. We propose a framework of interaction costs inspired by Normanpsilas Seven Stages of Action to facilitate study. From 484 papers, we collected 61 interaction-related usability problems reported in 32 user studies and placed them into our framework of seven costs: (1) Decision costs to form goals; (2) system-power costs to form system operations; (3) Multiple input mode costs to form physical sequences; (4) Physical-motion costs to execute sequences; (5) Visual-cluttering costs to perceive state; (6) View-change costs to interpret perception; (7) State-change costs to evaluate interpretation. We also suggested ways to narrow the gulfs of execution (2-4) and evaluation (5-7) based on collected reports. Our framework suggests a need to consider decision costs (1) as the gulf of goal formation.	Heidi Lam	Univ. of British Columbia, Vancouver, BC|c|	10.1109/INFVIS.2001.963289;10.1109/INFVIS.2003.1249020;10.1109/INFVIS.2005.1532151;10.1109/INFVIS.2004.21;10.1109/TVCG.2006.187;10.1109/INFVIS.2004.5;10.1109/TVCG.2007.70515;10.1109/TVCG.2006.120;10.1109/INFVIS.2005.1532133;10.1109/INFVIS.2004.19;10.1109/INFVIS.2005.1532126;10.1109/VAST.2006.261426;10.1109/VISUAL.1994.346302;10.1109/TVCG.2007.70589;10.1109/INFVIS.2005.1532132;10.1109/INFVIS.1998.729560;10.1109/TVCG.2007.70583	Interaction, Information Visualization, Framework, Interface Evaluation	
InfoVis	2008	Balloon Focus: a Seamless Multi-Focus+Context Method for Treemaps	10.1109/TVCG.2008.114	http://dx.doi.org/10.1109/TVCG.2008.114	1157	1164	J	The treemap is one of the most popular methods for visualizing hierarchical data. When a treemap contains a large number of items, inspecting or comparing a few selected items in a greater level of detail becomes very challenging. In this paper, we present a seamless multi-focus and context technique, called Balloon Focus, that allows the user to smoothly enlarge multiple treemap items served as the foci, while maintaining a stable treemap layout as the context. Our method has several desirable features. First, this method is quite general and can be used with different treemap layout algorithms. Second, as the foci are enlarged, the relative positions among all items are preserved. Third, the foci are placed in a way that the remaining space is evenly distributed back to the non-focus treemap items. When Balloon Focus enlarges the focus items to a maximum degree, the above features ensure that the treemap will maintain a consistent appearance and avoid any abrupt layout changes. In our algorithm, a DAG (Directed Acyclic Graph) is used to maintain the positional constraints, and an elastic model is employed to govern the placement of the treemap items. We demonstrate a treemap visualization system that integrates data query, manual focus selection, and our novel multi-focus+context technique, Balloon Focus, together. A user study was conducted. Results show that with Balloon Focus, users can better perform the tasks of comparing the values and the distribution of the foci.	Ying Tu;Han-Wei Shen	Comput. Sci. & Eng. Dept., Ohio State Univ., Columbus, OH|c|;	10.1109/INFVIS.2000.885091;10.1109/INFVIS.2001.963278;10.1109/INFVIS.2005.1532148;10.1109/INFVIS.2002.1173156;10.1109/INFVIS.1996.559214;10.1109/INFVIS.1998.729558;10.1109/INFVIS.2005.1532132;10.1109/INFVIS.2004.66;10.1109/INFVIS.2002.1173151	Treemap, focus+context, multi-focus, fisheye, magnification, visualizing query results, multi-scale viewing	
InfoVis	2008	Cerebral: Visualizing Multiple Experimental Conditions on a Graph with Biological Context	10.1109/TVCG.2008.117	http://dx.doi.org/10.1109/TVCG.2008.117	1253	1260	J	Systems biologists use interaction graphs to model the behavior of biological systems at the molecular level. In an iterative process, such biologists observe the reactions of living cells under various experimental conditions, view the results in the context of the interaction graph, and then propose changes to the graph model. These graphs serve as a form of dynamic knowledge representation of the biological system being studied and evolve as new insight is gained from the experimental data. While numerous graph layout and drawing packages are available, these tools did not fully meet the needs of our immunologist collaborators. In this paper, we describe the data information display needs of these immunologists and translate them into design decisions. These decisions led us to create Cerebral, a system that uses a biologically guided graph layout and incorporates experimental data directly into the graph display. Small multiple views of different experimental conditions and a data-driven parallel coordinates view enable correlations between experimental conditions to be analyzed at the same time that the data is viewed in the graph context. This combination of coordinated views allows the biologist to view the data from many different perspectives simultaneously. To illustrate the typical analysis tasks performed, we analyze two datasets using Cerebral. Based on feedback from our collaborators we conclude that Cerebral is a valuable tool for analyzing experimental data in the context of an interaction graph model.	Aaron Barsky;Tamara Munzner;Jennifer L. Gardy;Robert Kincaid	Dept. of Comput. Sci., Univ. of British Columbia, Vancouver, BC|c|;;;	10.1109/INFVIS.2005.1532151;10.1109/TVCG.2006.156;10.1109/TVCG.2006.166	Graph layout, systems biology visualization, small multiples, design study	
InfoVis	2008	Distributed Cognition as a Theoretical Framework for Information Visualization	10.1109/TVCG.2008.121	http://dx.doi.org/10.1109/TVCG.2008.121	1173	1180	J	Even though information visualization (InfoVis) research has matured in recent years, it is generally acknowledged that the field still lacks supporting, encompassing theories. In this paper, we argue that the distributed cognition framework can be used to substantiate the theoretical foundation of InfoVis. We highlight fundamental assumptions and theoretical constructs of the distributed cognition approach, based on the cognitive science literature and a real life scenario. We then discuss how the distributed cognition framework can have an impact on the research directions and methodologies we take as InfoVis researchers. Our contributions are as follows. First, we highlight the view that cognition is more an emergent property of interaction than a property of the human mind. Second, we argue that a reductionist approach to study the abstract properties of isolated human minds may not be useful in informing InfoVis design. Finally we propose to make cognition an explicit research agenda, and discuss the implications on how we perform evaluation and theory building.	Zhicheng Liu;Nancy J. Nersessian;John T. Stasko	Sch. of Interactive Comput., Georgia Inst. of Technol., Atlanta, GA|c|;;	10.1109/TVCG.2007.70515;10.1109/TVCG.2007.70577;10.1109/VAST.2007.4389006;10.1109/INFVIS.2000.885092	Information visualization, distributed cognition, interaction, representation, theory and methods	
InfoVis	2008	Effectiveness of Animation in Trend Visualization	10.1109/TVCG.2008.125	http://dx.doi.org/10.1109/TVCG.2008.125	1325	1332	J	Animation has been used to show trends in multi-dimensional data. This technique has recently gained new prominence for presentations, most notably with Gapminder Trendalyzer. In Trendalyzer, animation together with interesting data and an engaging presenter helps the audience understand the results of an analysis of the data. It is less clear whether trend animation is effective for analysis. This paper proposes two alternative trend visualizations that use static depictions of trends: one which shows traces of all trends overlaid simultaneously in one display and a second that uses a small multiples display to show the trend traces side-by-side. The paper evaluates the three visualizations for both analysis and presentation. Results indicate that trend animation can be challenging to use even for presentations; while it is the fastest technique for presentation and participants find it enjoyable and exciting, it does lead to many participant errors. Animation is the least effective form for analysis; both static depictions of trends are significantly faster than animation, and the small multiples display is more accurate.	George G. Robertson;Roland Fernandez;Danyel Fisher;Bongshin Lee;John T. Stasko	Microsoft Res., Redmond, WA|c|;;;;	10.1109/INFVIS.1999.801854;10.1109/TVCG.2007.70539	Information visualization, animation, trends, design, experiment	
InfoVis	2008	EMDialog: Bringing Information Visualization into the Museum	10.1109/TVCG.2008.127	http://dx.doi.org/10.1109/TVCG.2008.127	1181	1188	J	Digital information displays are becoming more common in public spaces such as museums, galleries, and libraries. However, the public nature of these locations requires special considerations concerning the design of information visualization in terms of visual representations and interaction techniques. We discuss the potential for, and challenges of, information visualization in the museum context based on our practical experience with EMDialog, an interactive information presentation that was part of the Emily Carr exhibition at the Glenbow Museum in Calgary. EMDialog visualizes the diverse and multi-faceted discourse about this Canadian artist with the goal to both inform and provoke discussion. It provides a visual exploration environment that offers interplay between two integrated visualizations, one for information access along temporal, and the other along contextual dimensions. We describe the results of an observational study we conducted at the museum that revealed the different ways visitors approached and interacted with EMDialog, as well as how they perceived this form of information presentation in the museum context. Our results include the need to present information in a manner sufficiently attractive to draw attention and the importance of rewarding passive observation as well as both short- and longer term information exploration.	Uta Hinrichs;Holly Schmidt;M. Sheelagh T. Carpendale	Calgary Univ., Calgary, AB|c|;;	10.1109/TVCG.2007.70541;10.1109/INFVIS.2004.8;10.1109/INFVIS.2003.1249031;10.1109/INFVIS.2005.1532122;10.1109/TVCG.2007.70568	artistic information visualization, interactive information visualization, walk-up-and-use interaction, public displays	
InfoVis	2008	Evaluating the Use of Data Transformation for Information Visualization	10.1109/TVCG.2008.129	http://dx.doi.org/10.1109/TVCG.2008.129	1309	1316	J	Data transformation, the process of preparing raw data for effective visualization, is one of the key challenges in information visualization. Although researchers have developed many data transformation techniques, there is little empirical study of the general impact of data transformation on visualization. Without such study, it is difficult to systematically decide when and which data transformation techniques are needed. We thus have designed and conducted a two-part empirical study that examines how the use of common data transformation techniques impacts visualization quality, which in turn affects user task performance. Our first experiment studies the impact of data transformation on user performance in single-step, typical visual analytic tasks. The second experiment assesses the impact of data transformation in multi-step analytic tasks. Our results quantify the benefits of data transformation in both experiments. More importantly, our analyses reveal that (1) the benefits of data transformation vary significantly by task and by visualization, and (2) the use of data transformation depends on a user's interaction context. Based on our findings, we present a set of design recommendations that help guide the development and use of data transformation techniques.	Zhen Wen;Michelle X. Zhou	IBM T. J. Watson Res. Center, Hawthorne, NY|c|;	10.1109/INFVIS.2005.1532136;10.1109/INFVIS.2004.70;10.1109/TVCG.2006.161;10.1109/INFVIS.2000.885092;10.1109/INFVIS.2003.1249015;10.1109/VISUAL.1990.146375;10.1109/TVCG.2007.70577	data transformation, data cleaning, empirical evaluation, user studies	
InfoVis	2008	Exploration of Networks using overview+detail with Constraint-based cooperative layout	10.1109/TVCG.2008.130	http://dx.doi.org/10.1109/TVCG.2008.130	1293	1300	J	A standard approach to large network visualization is to provide an overview of the network and a detailed view of a small component of the graph centred around a focal node. The user explores the network by changing the focal node in the detailed view or by changing the level of detail of a node or cluster. For scalability, fast force-based layout algorithms are used for the overview and the detailed view. However, using the same layout algorithm in both views is problematic since layout for the detailed view has different requirements to that in the overview. Here we present a model in which constrained graph layout algorithms are used for layout in the detailed view. This means the detailed view has high-quality layout including sophisticated edge routing and is customisable by the user who can add placement constraints on the layout. Scalability is still ensured since the slower layout techniques are only applied to the small subgraph shown in the detailed view. The main technical innovations are techniques to ensure that the overview and detailed view remain synchronized, and modifying constrained graph layout algorithms to support smooth, stable layout. The key innovation supporting stability are new dynamic graph layout algorithms that preserve the topology or structure of the network when the user changes the focus node or the level of detail by in situ semantic zooming. We have built a prototype tool and demonstrate its use in two application domains, UML class diagrams and biological networks.	Tim Dwyer;Kim Marriott;Falk Schreiber;Peter J. Stuckey;Michael Woodward;Michael Wybrow	Microsoft Res., Redmond, WA|c|;;;;;	10.1109/INFVIS.2002.1173159;10.1109/TVCG.2006.122;10.1109/TVCG.2006.156;10.1109/INFVIS.2005.1532126;10.1109/INFVIS.2004.43;10.1109/TVCG.2006.177;10.1109/INFVIS.2002.1173148;10.1109/INFVIS.2004.66;10.1109/INFVIS.1999.801854	Graph drawing, constraints, stress majorization, force directed algorithms, multidimensional scaling	
InfoVis	2008	Geometry-Based Edge Clustering for Graph Visualization	10.1109/TVCG.2008.135	http://dx.doi.org/10.1109/TVCG.2008.135	1277	1284	J	Graphs have been widely used to model relationships among data. For large graphs, excessive edge crossings make the display visually cluttered and thus difficult to explore. In this paper, we propose a novel geometry-based edge-clustering framework that can group edges into bundles to reduce the overall edge crossings. Our method uses a control mesh to guide the edge-clustering process; edge bundles can be formed by forcing all edges to pass through some control points on the mesh. The control mesh can be generated at different levels of detail either manually or automatically based on underlying graph patterns. Users can further interact with the edge-clustering results through several advanced visualization techniques such as color and opacity enhancement. Compared with other edge-clustering methods, our approach is intuitive, flexible, and efficient. The experiments on some large graphs demonstrate the effectiveness of our method.	Weiwei Cui;Hong Zhou;Huamin Qu;Pak Chung Wong;Xiaoming Li	Hong Kong Univ. of Sci. & Technol., Kowloon|c|;;;;	10.1109/TVCG.2007.70535;10.1109/TVCG.2007.70580;10.1109/INFVIS.2004.43;10.1109/INFVIS.2003.1249008;10.1109/INFVIS.2005.1532150;10.1109/INFVIS.2004.66;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2006.147	Graph visualization, visual clutter, mesh, edge clustering	
InfoVis	2008	Graphical Histories for Visualization: Supporting Analysis, Communication, and Evaluation	10.1109/TVCG.2008.137	http://dx.doi.org/10.1109/TVCG.2008.137	1189	1196	J	Interactive history tools, ranging from basic undo and redo to branching timelines of user actions, facilitate iterative forms of interaction. In this paper, we investigate the design of history mechanisms for information visualization. We present a design space analysis of both architectural and interface issues, identifying design decisions and associated trade-offs. Based on this analysis, we contribute a design study of graphical history tools for Tableau, a database visualization system. These tools record and visualize interaction histories, support data analysis and communication of findings, and contribute novel mechanisms for presenting, managing, and exporting histories. Furthermore, we have analyzed aggregated collections of history sessions to evaluate Tableau usage. We describe additional tools for analyzing userspsila history logs and how they have been applied to study usage patterns in Tableau.	Jeffrey Heer;Jock D. Mackinlay;Chris Stolte;Maneesh Agrawala	Univ. of California at Berkeley, Berkeley, CA|c|;;;	10.1109/INFVIS.2000.885086;10.1109/VISUAL.1993.398857;10.1109/VISUAL.1999.809871;10.1109/INFVIS.2004.2;10.1109/VISUAL.1995.480801;10.1109/TVCG.2007.70594;10.1109/VAST.2007.4388992	Visualization, history, undo, analysis, presentation, evaluation	
InfoVis	2008	HiPP: A Novel Hierarchical Point Placement Strategy and its Application to the Exploration of Document Collections	10.1109/TVCG.2008.138	http://dx.doi.org/10.1109/TVCG.2008.138	1229	1236	J	Point placement strategies aim at mapping data points represented in higher dimensions to bi-dimensional spaces and are frequently used to visualize relationships amongst data instances. They have been valuable tools for analysis and exploration of data sets of various kinds. Many conventional techniques, however, do not behave well when the number of dimensions is high, such as in the case of documents collections. Later approaches handle that shortcoming, but may cause too much clutter to allow flexible exploration to take place. In this work we present a novel hierarchical point placement technique that is capable of dealing with these problems. While good grouping and separation of data with high similarity is maintained without increasing computation cost, its hierarchical structure lends itself both to exploration in various levels of detail and to handling data in subsets, improving analysis capability and also allowing manipulation of larger data sets.	Fernando Vieira Paulovich;Rosane Minghim	Inst. de Cienc. Mat. e de Comput., Sao Paulo Univ., Sao Paulo|c|;	10.1109/VISUAL.1999.809866;10.1109/VISUAL.1991.175815;10.1109/VAST.2007.4389002;10.1109/VISUAL.1996.567787	Text and document visualization, hierarchical multidimensional visualization, visual knowledge discovery, high-dimensional data	
InfoVis	2008	Improving the Readability of Clustered Social Networks using Node Duplication	10.1109/TVCG.2008.141	http://dx.doi.org/10.1109/TVCG.2008.141	1317	1324	J	Exploring communities is an important task in social network analysis. Such communities are currently identified using clustering methods to group actors. This approach often leads to actors belonging to one and only one cluster, whereas in real life a person can belong to several communities. As a solution we propose duplicating actors in social networks and discuss potential impact of such a move. Several visual duplication designs are discussed and a controlled experiment comparing network visualization with and without duplication is performed, using 6 tasks that are important for graph readability and visual interpretation of social networks. We show that in our experiment, duplications significantly improve community-related tasks but sometimes interfere with other graph readability tasks. Finally, we propose a set of guidelines for deciding when to duplicate actors and choosing candidates for duplication, and alternative ways to render them in social network representations.	Nathalie Henry Riche;Anastasia Bezerianos;Jean-Daniel Fekete	INRIA-LRI, Univ. of Sydney, Sydney, NSW|c|;;	10.1109/TVCG.2007.70582;10.1109/TVCG.2006.160;10.1109/VAST.2006.261426;10.1109/TVCG.2006.120;10.1109/INFVIS.1997.636792;10.1109/TVCG.2006.147;10.1109/INFVIS.2003.1249011	Clustering, Graph Visualization, Node Duplications, Social Networks	
InfoVis	2008	Interactive Visual Analysis of Set-Typed Data	10.1109/TVCG.2008.144	http://dx.doi.org/10.1109/TVCG.2008.144	1340	1347	J	While it is quite typical to deal with attributes of different data types in the visualization of heterogeneous and multivariate datasets, most existing techniques still focus on the most usual data types such as numerical attributes or strings. In this paper we present a new approach to the interactive visual exploration and analysis of data that contains attributes which are of set type. A set-typed attribute of a data item - like one cell in a table - has a list of nGt=0 elements as its value. We present the setpsilaopsilagram as a new visualization approach to represent data of set type and to enable interactive visual exploration and analysis. We also demonstrate how this approach is capable to help in dealing with datasets that have a larger number of dimensions (more than a dozen or more), especially also in the context of categorical data. To illustrate the effectiveness of our approach, we present the interactive visual analysis of a CRM dataset with data from a questionnaire on the education and shopping habits of about 90000 people.	Wolfgang Freiler;Kresimir Matkovic;Helwig Hauser	VRVis Res. Center, Vienna|c|;;	10.1109/INFVIS.1999.801860;10.1109/VISUAL.1990.146402;10.1109/INFVIS.2001.963288;10.1109/INFVIS.2003.1249016;10.1109/VAST.2007.4389006;10.1109/INFVIS.2005.1532139;10.1109/VISUAL.1991.175815	Interactive Visual Analysis, Multidimensional Multivariate Data Visualization, Categorical Data Visualization, Interactive Visualization, Focus+Context Visualization, Multiple Coordinated Views	
InfoVis	2008	Multi-Focused Geospatial Analysis Using Probes	10.1109/TVCG.2008.149	http://dx.doi.org/10.1109/TVCG.2008.149	1165	1172	J	Traditional geospatial information visualizations often present views that restrict the user to a single perspective. When zoomed out, local trends and anomalies become suppressed and lost; when zoomed in for local inspection, spatial awareness and comparison between regions become limited. In our model, coordinated visualizations are integrated within individual probe interfaces, which depict the local data in user-defined regions-of-interest. Our probe concept can be incorporated into a variety of geospatial visualizations to empower users with the ability to observe, coordinate, and compare data across multiple local regions. It is especially useful when dealing with complex simulations or analyses where behavior in various localities differs from other localities and from the system as a whole. We illustrate the effectiveness of our technique over traditional interfaces by incorporating it within three existing geospatial visualization systems: an agent-based social simulation, a census data exploration tool, and an 3D GIS environment for analyzing urban change over time. In each case, the probe-based interaction enhances spatial awareness, improves inspection and comparison capabilities, expands the range of scopes, and facilitates collaboration among multiple users.	Thomas Butkiewicz;Wenwen Dou;Zachary Wartell;William Ribarsky;Remco Chang	Charlotte Visualization Center, UNC Charlotte, Charlotte, NC|c|;;;;	10.1109/INFVIS.2000.885102;10.1109/TVCG.2007.70574	Multiple-view techniques, geospatial visualization, geospatial analysis, focus + context, probes	
InfoVis	2008	On the Visualization of Social and other Scale-Free Networks	10.1109/TVCG.2008.151	http://dx.doi.org/10.1109/TVCG.2008.151	1285	1292	J	This paper proposes novel methods for visualizing specifically the large power-law graphs that arise in sociology and the sciences. In such cases a large portion of edges can be shown to be less important and removed while preserving component connectedness and other features (e.g. cliques) to more clearly reveal the networkpsilas underlying connection pathways. This simplification approach deterministically filters (instead of clustering) the graph to retain important node and edge semantics, and works both automatically and interactively. The improved graph filtering and layout is combined with a novel computer graphics anisotropic shading of the dense crisscrossing array of edges to yield a full social network and scale-free graph visualization system. Both quantitative analysis and visual results demonstrate the effectiveness of this approach.	Yuntao Jia;Jared Hoberock;Michael Garland;John C. Hart	Illinois Univ., Urbana, IL|c|;;;	10.1109/VISUAL.2005.1532819;10.1109/TVCG.2006.193;10.1109/INFVIS.2003.1249011	Scale-free network, edge filtering, betweenness centrality, anisotropic shading	
InfoVis	2008	Particle-based labeling: Fast point-feature labeling without obscuring other visual features	10.1109/TVCG.2008.152	http://dx.doi.org/10.1109/TVCG.2008.152	1237	1244	J	In many information visualization techniques, labels are an essential part to communicate the visualized data. To preserve the expressiveness of the visual representation, a placed label should neither occlude other labels nor visual representatives (e.g., icons, lines) that communicate crucial information. Optimal, non-overlapping labeling is an NP-hard problem. Thus, only a few approaches achieve a fast non-overlapping labeling in highly interactive scenarios like information visualization. These approaches generally target the point-feature label placement (PFLP) problem, solving only label-label conflicts. This paper presents a new, fast, solid and flexible 2D labeling approach for the PFLP problem that additionally respects other visual elements and the visual extent of labeled features. The results (number of placed labels, processing time) of our particle-based method compare favorably to those of existing techniques. Although the esthetic quality of non-real-time approaches may not be achieved with our method, it complies with practical demands and thus supports the interactive exploration of information spaces. In contrast to the known adjacent techniques, the flexibility of our technique enables labeling of dense point clouds by the use of non-occluding distant labels. Our approach is independent of the underlying visualization technique, which enables us to demonstrate the application of our labeling method within different information visualization scenarios.	Martin Luboschik;Heidrun Schumann;Hilko Cords	Univ. of Rostock, Rostock|c|;;	10.1109/TVCG.2006.136;10.1109/TVCG.2006.136;10.1109/VISUAL.2005.1532856	Interactive labeling, dynamic labeling, automatic label placement, occlusion-free, information visualization	
InfoVis	2008	Rolling the Dice: Multidimensional Visual Exploration using Scatterplot Matrix Navigation	10.1109/TVCG.2008.153	http://dx.doi.org/10.1109/TVCG.2008.153	1141	1148	J	Scatterplots remain one of the most popular and widely-used visual representations for multidimensional data due to their simplicity, familiarity and visual clarity, even if they lack some of the flexibility and visual expressiveness of newer multidimensional visualization techniques. This paper presents new interactive methods to explore multidimensional data using scatterplots. This exploration is performed using a matrix of scatterplots that gives an overview of the possible configurations, thumbnails of the scatterplots, and support for interactive navigation in the multidimensional space. Transitions between scatterplots are performed as animated rotations in 3D space, somewhat akin to rolling dice. Users can iteratively build queries using bounding volumes in the dataset, sculpting the query from different viewpoints to become more and more refined. Furthermore, the dimensions in the navigation space can be reordered, manually or automatically, to highlight salient correlations and differences among them. An example scenario presents the interaction techniques supporting smooth and effortless visual exploration of multidimensional datasets.	Niklas Elmqvist;Pierre Dragicevic;Jean-Daniel Fekete	INRIA, Paris|c|;;	10.1109/TVCG.2007.70515;10.1109/VAST.2007.4389013;10.1109/TVCG.2007.70577;10.1109/VISUAL.1990.146386;10.1109/VAST.2006.261452;10.1109/INFVIS.2005.1532136;10.1109/VISUAL.1994.346302;10.1109/INFVIS.1998.729559;10.1109/VISUAL.1995.485139;10.1109/INFVIS.2003.1249016;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2004.3;10.1109/INFVIS.2004.64;10.1109/TVCG.2007.70539;10.1109/INFVIS.2004.15	Visual exploration, visual queries, visual analytics, navigation, multivariate data, interaction	
InfoVis	2008	Perceptual Organization in User-Generated Graph Layouts	10.1109/TVCG.2008.155	http://dx.doi.org/10.1109/TVCG.2008.155	1333	1339	J	Many graph layout algorithms optimize visual characteristics to achieve useful representations. Implicitly, their goal is to create visual representations that are more intuitive to human observers. In this paper, we asked users to explicitly manipulate nodes in a network diagram to create layouts that they felt best captured the relationships in the data. This allowed us to measure organizational behavior directly, allowing us to evaluate the perceptual importance of particular visual features, such as edge crossings and edge-lengths uniformity. We also manipulated the interior structure of the node relationships by designing data sets that contained clusters, that is, sets of nodes that are strongly interconnected. By varying the degree to which these clusters were ldquomaskedrdquo by extraneous edges we were able to measure observerspsila sensitivity to the existence of clusters and how they revealed them in the network diagram. Based on these measurements we found that observers are able to recover cluster structure, that the distance between clusters is inversely related to the strength of the clustering, and that users exhibit the tendency to use edges to visually delineate perceptual groups. These results demonstrate the role of perceptual organization in representing graph data and provide concrete recommendations for graph layout algorithms.	Frank van Ham;Bernice E. Rogowitz	IBM Res., Cambridge|c|;	10.1109/INFVIS.2004.1;10.1109/TVCG.2007.70577	Network layout visualization, perceptual organization, graph layout, user studies	
InfoVis	2008	Rapid Graph Layout Using Space filling Curves	10.1109/TVCG.2008.158	http://dx.doi.org/10.1109/TVCG.2008.158	1301	1308	J	Network data frequently arises in a wide variety of fields, and node-link diagrams are a very natural and intuitive representation of such data. In order for a node-link diagram to be effective, the nodes must be arranged well on the screen. While many graph layout algorithms exist for this purpose, they often have limitations such as high computational complexity or node colocation. This paper proposes a new approach to graph layout through the use of space filling curves which is very fast and guarantees that there will be no nodes that are colocated. The resulting layout is also aesthetic and satisfies several criteria for graph layout effectiveness.	Chris Muelder;Kwan-Liu Ma	Univ. of California, Davis, CA|c|;	10.1109/INFVIS.2002.1173159;10.1109/INFVIS.2005.1532145;10.1109/INFVIS.2005.1532126;10.1109/INFVIS.2004.66;10.1109/TVCG.2007.70580	 Information visualization, Graph layout, Space filling curves	
InfoVis	2008	Spatially Ordered Treemaps	10.1109/TVCG.2008.165	http://dx.doi.org/10.1109/TVCG.2008.165	1348	1355	J	Existing treemap layout algorithms suffer to some extent from poor or inconsistent mappings between data order and visual ordering in their representation, reducing their cognitive plausibility. While attempts have been made to quantify this mismatch, and algorithms proposed to minimize inconsistency, solutions provided tend to concentrate on one-dimensional ordering. We propose extensions to the existing squarified layout algorithm that exploit the two-dimensional arrangement of treemap nodes more effectively. Our proposed spatial squarified layout algorithm provides a more consistent arrangement of nodes while maintaining low aspect ratios. It is suitable for the arrangement of data with a geographic component and can be used to create tessellated cartograms for geovisualization. Locational consistency is measured and visualized and a number of layout algorithms are compared. CIELab color space and displacement vector overlays are used to assess and emphasize the spatial layout of treemap nodes. A case study involving locations of tagged photographs in the Flickr database is described.	Jo Wood;Jason Dykes	Sch. of Inf., City Univ. London, London|c|;	10.1109/INFVIS.2001.963283;10.1109/INFVIS.2001.963290;10.1109/TVCG.2007.70522;10.1109/TVCG.2007.70529	Geovisualization, treemaps, cartograms, CIELab, geographic information, tree structures	
InfoVis	2008	Stacked Graphs - Geometry & Aesthetics	10.1109/TVCG.2008.166	http://dx.doi.org/10.1109/TVCG.2008.166	1245	1252	J	In February 2008, the New York Times published an unusual chart of box office revenues for 7500 movies over 21 years. The chart was based on a similar visualization, developed by the first author, that displayed trends in music listening. This paper describes the design decisions and algorithms behind these graphics, and discusses the reaction on the Web. We suggest that this type of complex layered graph is effective for displaying large data sets to a mass audience. We provide a mathematical analysis of how this layered graph relates to traditional stacked graphs and to techniques such as ThemeRiver, showing how each method is optimizing a different ldquoenergy functionrdquo. Finally, we discuss techniques for coloring and ordering the layers of such graphs. Throughout the paper, we emphasize the interplay between considerations of aesthetics and legibility.	Lee Byron;Martin Wattenberg	New York Times, New York, NY|c|;	10.1109/TVCG.2006.163;10.1109/INFVIS.2005.1532122;10.1109/TVCG.2007.70577;10.1109/INFVIS.2000.885098	Streamgraph, ThemeRiver, listening history, lastfm, aesthetics, communication-minded visualization, time series	
InfoVis	2008	The Shaping of Information by Visual Metaphors	10.1109/TVCG.2008.171	http://dx.doi.org/10.1109/TVCG.2008.171	1269	1276	J	The nature of an information visualization can be considered to lie in the visual metaphors it uses to structure information. The process of understanding a visualization therefore involves an interaction between these external visual metaphors and the user's internal knowledge representations. To investigate this claim, we conducted an experiment to test the effects of visual metaphor and verbal metaphor on the understanding of tree visualizations. Participants answered simple data comprehension questions while viewing either a treemap or a node-link diagram. Questions were worded to reflect a verbal metaphor that was either compatible or incompatible with the visualization a participant was using. The results suggest that the visual metaphor indeed affects how a user derives information from a visualization. Additionally, we found that the degree to which a user is affected by the metaphor is strongly correlated with the user's ability to answer task questions correctly. These findings are a first step towards illuminating how visual metaphors shape user understanding, and have significant implications for the evaluation, application, and theory of visualization.	Caroline Ziemkiewicz;Robert Kosara	UNC, Charlotte, NC|c|;	10.1109/INFVIS.2004.70;10.1109/INFVIS.2002.1173153;10.1109/INFVIS.2004.64;10.1109/INFVIS.2001.963290	Cognition, visualization theory, metaphors, hierarchies, evaluation	
InfoVis	2008	The Word Tree, an Interactive Visual Concordance	10.1109/TVCG.2008.172	http://dx.doi.org/10.1109/TVCG.2008.172	1221	1228	J	We introduce the Word Tree, a new visualization and information-retrieval technique aimed at text documents. A Word Tree is a graphical version of the traditional "keyword-in-context" method, and enables rapid querying and exploration of bodies of text. In this paper we describe the design of the technique, along with some of the technical issues that arise in its implementation. In addition, we discuss the results of several months of public deployment of word trees on Many Eyes, which provides a window onto the ways in which users obtain value from the visualization.	Martin Wattenberg;Fernanda B. Viégas	IBM Res., Cambridge, MA|c|;	10.1109/INFVIS.2002.1173155;10.1109/VAST.2007.4389006;10.1109/TVCG.2007.70577;10.1109/INFVIS.2002.1173148	Text visualization, document visualization, Many Eyes, case study, concordance, information retrieval, search	
InfoVis	2008	VisGets: Coordinated Visualizations for Web-based Information Exploration and Discovery	10.1109/TVCG.2008.175	http://dx.doi.org/10.1109/TVCG.2008.175	1205	1212	J	In common Web-based search interfaces, it can be difficult to formulate queries that simultaneously combine temporal, spatial, and topical data filters. We investigate how coordinated visualizations can enhance search and exploration of information on the World Wide Web by easing the formulation of these types of queries. Drawing from visual information seeking and exploratory search, we introduce VisGets - interactive query visualizations of Web-based information that operate with online information within a Web browser. VisGets provide the information seeker with visual overviews of Web resources and offer a way to visually filter the data. Our goal is to facilitate the construction of dynamic search queries that combine filters from more than one data dimension. We present a prototype information exploration system featuring three linked VisGets (temporal, spatial, and topical), and used it to visually explore news items from online RSS feeds.	Marian Dörk;M. Sheelagh T. Carpendale;Christopher Collins;Carey L. Williamson	Comput. Sci. Dept., Univ. of Calgary, Calgary, AB|c|;;;	10.1109/TVCG.2007.70570;10.1109/TVCG.2007.70589;10.1109/TVCG.2007.70577;10.1109/VISUAL.1993.398863;10.1109/INFVIS.2005.1532122;10.1109/VISUAL.1996.567610	Information visualization, World Wide Web, information retrieval, exploratory search, visual information seeking	
InfoVis	2008	Vispedia: Interactive Visual Exploration of Wikipedia Data via Search-Based Integration	10.1109/TVCG.2008.178	http://dx.doi.org/10.1109/TVCG.2008.178	1213	1220	J	Wikipedia is an example of the collaborative, semi-structured data sets emerging on the Web. These data sets have large, non-uniform schema that require costly data integration into structured tables before visualization can begin. We present Vispedia, a Web-based visualization system that reduces the cost of this data integration. Users can browse Wikipedia, select an interesting data table, then use a search interface to discover, integrate, and visualize additional columns of data drawn from multiple Wikipedia articles. This interaction is supported by a fast path search algorithm over DBpedia, a semantic graph extracted from Wikipedia's hyperlink structure. Vispedia can also export the augmented data tables produced for use in traditional visualization systems. We believe that these techniques begin to address the "long tail" of visualization by allowing a wider audience to visualize a broader class of data. We evaluated this system in a first-use formative lab study. Study participants were able to quickly create effective visualizations for a diverse set of domains, performing data integration as needed.	Bryan Chan;Leslie Wu;Justin Talbot;Mike Cammarano;Pat Hanrahan	Stanford Univ., Stanford, CA|c|;;;;	10.1109/TVCG.2007.70617;10.1109/TVCG.2007.70577;10.1109/VAST.2007.4389010	Information visualization, Data integration, Wikipedia, Semantic web, Search interfaces	
InfoVis	2008	Visualizing Incomplete and Partially Ranked Data	10.1109/TVCG.2008.181	http://dx.doi.org/10.1109/TVCG.2008.181	1356	1363	J	Ranking data, which result from m raters ranking n items, are difficult to visualize due to their discrete algebraic structure, and the computational difficulties associated with them when n is large. This problem becomes worse when raters provide tied rankings or not all items are ranked. We develop an approach for the visualization of ranking data for large n which is intuitive, easy to use, and computationally efficient. The approach overcomes the structural and computational difficulties by utilizing a natural measure of dissimilarity for raters, and projecting the raters into a low dimensional vector space where they are viewed. The visualization techniques are demonstrated using voting data, jokes, and movie preferences.	Paul Kidwell;Guy Lebanon;William S. Cleveland	Dept. of Stat., Purdue Univ., West Lafayette, IN|c|;;		Partial rankings, incomplete rankings, multidimensional scaling	
InfoVis	2008	Viz-A-Vis: Toward Visualizing Video through Computer Vision	10.1109/TVCG.2008.185	http://dx.doi.org/10.1109/TVCG.2008.185	1261	1268	J	In the established procedural model of information visualization, the first operation is to transform raw data into data tables. The transforms typically include abstractions that aggregate and segment relevant data and are usually defined by a human, user or programmer. The theme of this paper is that for video, data transforms should be supported by low level computer vision. High level reasoning still resides in the human analyst, while part of the low level perception is handled by the computer. To illustrate this approach, we present Viz-A-Vis, an overhead video capture and access system for activity analysis in natural settings over variable periods of time. Overhead video provides rich opportunities for long-term behavioral and occupancy analysis, but it poses considerable challenges. We present initial steps addressing two challenges. First, overhead video generates overwhelmingly large volumes of video impractical to analyze manually. Second, automatic video analysis remains an open problem for computer vision.	Mario Romero;Jay Summet;John T. Stasko;Gregory D. Abowd	Georgia Tech, Atlanta, GA|c|;;;	10.1109/VISUAL.2003.1250401;10.1109/TVCG.2007.70621	Spatiotemporal visualization, time series data, video visualization, sensor analytics, image/video analytics	
InfoVis	2008	Who Votes For What? A Visual Query Language for Opinion Data	10.1109/TVCG.2008.187	http://dx.doi.org/10.1109/TVCG.2008.187	1197	1204	J	Surveys and opinion polls are extremely popular in the media, especially in the months preceding a general election. However, the available tools for analyzing poll results often require specialized training. Hence, data analysis remains out of reach for many casual computer users. Moreover, the visualizations used to communicate the results of surveys are typically limited to traditional statistical graphics like bar graphs and pie charts, both of which are fundamentally noninteractive. We present a simple interactive visualization that allows users to construct queries on large tabular data sets, and view the results in real time. The results of two separate user studies suggest that our interface lowers the learning curve for naive users, while still providing enough analytical power to discover interesting correlations in the data.	Geoffrey M. Draper;Richard F. Riesenfeld	Sch. of Comput., Univ. of Utah, Salt Lake City, UT|c|;	10.1109/TVCG.2007.70584;10.1109/INFVIS.1996.559210;10.1109/INFVIS.2005.1532134;10.1109/INFVIS.2001.963279;10.1109/VISUAL.1990.146402;10.1109/TVCG.2007.70617;10.1109/VAST.2006.261438;10.1109/INFVIS.1998.729570;10.1109/INFVIS.2001.963287;10.1109/INFVIS.2000.885086;10.1109/TVCG.2007.70539;10.1109/VAST.2007.4389013;10.1109/INFVIS.2000.885091;10.1109/TVCG.2007.70577;10.1109/TVCG.2006.147	Visual query languages, radial visualization, data analysis, human-computer interaction	
VAST	2008	Visual cluster analysis of trajectory data with interactive Kohonen Maps	10.1109/VAST.2008.4677350	http://dx.doi.org/10.1109/VAST.2008.4677350	3	10	C	Visual-interactive cluster analysis provides valuable tools for effectively analyzing large and complex data sets. Due to desirable properties and an inherent predisposition for visualization, the Kohonen Feature Map (or self-organizing map, or SOM) algorithm is among the most popular and widely used visual clustering techniques. However, the unsupervised nature of the algorithm may be disadvantageous in certain applications. Depending on initialization and data characteristics, cluster maps (cluster layouts) may emerge that do not comply with user preferences, expectations, or the application context. Considering SOM-based analysis of trajectory data, we propose a comprehensive visual-interactive monitoring and control framework extending the basic SOM algorithm. The framework implements the general Visual Analytics idea to effectively combine automatic data analysis with human expert supervision. It provides simple, yet effective facilities for visually monitoring and interactively controlling the trajectory clustering process at arbitrary levels of detail. The approach allows the user to leverage existing domain knowledge and user preferences, arriving at improved cluster maps. We apply the framework on a trajectory clustering problem, demonstrating its potential in combining both unsupervised (machine) and supervised (human expert) processing, in producing appropriate cluster results.	Tobias Schreck;Jürgen Bernard;Tatiana von Landesberger;Jörn Kohlhammer	Interactive Graphics Syst. Group, TU Darmstadt, Darmstadt|c|;;;	10.1109/TVCG.2007.70621		
VAST	2008	Crystal structures classifier for an evolutionary algorithm structure predictor	10.1109/VAST.2008.4677351	http://dx.doi.org/10.1109/VAST.2008.4677351	11	18	C	USPEX is a crystal structure predictor based on an evolutionary algorithm. Every USPEX run produces hundreds or thousands of crystal structures, some of which may be identical. To ease the extraction of unique and potentially interesting structures we applied usual high-dimensional classification concepts to the unusual field of crystallography. We experimented with various crystal structure descriptors, distinct distance measures and tried different clustering methods to identify groups of similar structures. These methods are already applied in combinatorial chemistry to organic molecules for a different goal and in somewhat different forms, but are not widely used for crystal structures classification. We adopted a visual design and validation method in the development of a library (CrystalFp) and an end-user application to select and validate method choices, to gain userspsila acceptance and to tap into their domain expertise. The use of the classifier has already accelerated the analysis of USPEX output by at least one order of magnitude, promoting some new crystallographic insight and discovery. Furthermore the visual display of key algorithm indicators has led to diverse, unexpected discoveries that will improve the USPEX algorithms.	Mario Valle;Artem R. Oganov	Data Anal. & Visualization Services, Swiss Nat. Supercomput. Centre (CSCS)|c|;			
VAST	2008	Model-driven Visual Analytics	10.1109/VAST.2008.4677352	http://dx.doi.org/10.1109/VAST.2008.4677352	19	26	C	We describe a visual analytics (VA) infrastructure, rooted on techniques in machine learning and logic-based deductive reasoning that will assist analysts to make sense of large, complex data sets by facilitating the generation and validation of models representing relationships in the data. We use logic programming (LP) as the underlying computing machinery to encode the relations as rules and facts and compute with them. A unique aspect of our approach is that the LP rules are automatically learned, using Inductive Logic Programming, from examples of data that the analyst deems interesting when viewing the data in the high-dimensional visualization interface. Using this system, analysts will be able to construct models of arbitrary relationships in the data, explore the data for scenarios that fit the model, refine the model if necessary, and query the model to automatically analyze incoming (future) data exhibiting the encoded relationships. In other words it will support both model-driven data exploration, as well as data-driven model evolution. More importantly, by basing the construction of models on techniques from machine learning and logic-based deduction, the VA process will be both flexible in terms of modeling arbitrary, user-driven relationships in the data as well as readily scale across different data domains.	Supriya Garg;Julia Eunju Nam;I. V. Ramakrishnan;Klaus Mueller	Comput. Sci. Dept., Stony Brook Univ., Stony Brook, NY|c|;;;	10.1109/VAST.2006.261437;10.1109/VAST.2007.4388999;10.1109/VAST.2007.4388998;10.1109/VAST.2007.4389003;10.1109/VAST.2007.4389000;10.1109/VAST.2006.261425;10.1109/VAST.2006.261436;10.1109/VAST.2007.4388992;10.1109/TVCG.2007.70581;10.1109/VISUAL.1990.146402;10.1109/VISUAL.1990.146386	Visual Analytics, Knowledge Discovery, Visual Clustering, Machine Learning, Grand Tour, High-dimensional Data, Network Security	
VAST	2008	Using visual analytics to maintain situation awareness in astrophysics	10.1109/VAST.2008.4677353	http://dx.doi.org/10.1109/VAST.2008.4677353	27	34	C	We present a novel collaborative visual analytics application for cognitively overloaded users in the astrophysics domain. The system was developed for scientists needing to analyze heterogeneous, complex data under time pressure, and then make predictions and time-critical decisions rapidly and correctly under a constant influx of changing data. The Sunfall Data Taking system utilizes several novel visualization and analysis techniques to enable a team of geographically distributed domain specialists to effectively and remotely maneuver a custom-built instrument under challenging operational conditions. Sunfall Data Taking has been in use for over eighteen months by a major international astrophysics collaboration (the largest data volume supernova search currently in operation), and has substantially improved the operational efficiency of its users. We describe the system design process by an interdisciplinary team, the system architecture, and the results of an informal usability evaluation of the production system by domain experts in the context of Endsleypsilas three levels of situation awareness.	Cecilia R. Aragon;Sarah S. Poon;Gregory S. Aldering;Rollin C. Thomas;Robert Quimby	Lawrence Berkeley Nat. Lab., Berkeley, CA|c|;;;;	10.1109/VAST.2007.4388997;10.1109/VAST.2007.4388998;10.1109/VAST.2007.4388993;10.1109/VAST.2006.261416;10.1109/VAST.2007.4388991;10.1109/VAST.2007.4388996;10.1109/VAST.2007.4388994;10.1109/VAST.2006.261434;10.1109/TVCG.2006.176;10.1109/INFVIS.2004.27	Data and knowledge visualization, scientific visualization, visual analytics, situation awareness, astrophysics	
VAST	2008	Understanding syndromic hotspots - a visual analytics approach	10.1109/VAST.2008.4677354	http://dx.doi.org/10.1109/VAST.2008.4677354	35	42	C	When analyzing syndromic surveillance data, health care officials look for areas with unusually high cases of syndromes. Unfortunately, many outbreaks are difficult to detect because their signal is obscured by the statistical noise. Consequently, many detection algorithms have a high false positive rate. While many false alerts can be easily filtered by trained epidemiologists, others require health officials to drill down into the data, analyzing specific segments of the population and historical trends over time and space. Furthermore, the ability to accurately recognize meaningful patterns in the data becomes more challenging as these data sources increase in volume and complexity. To facilitate more accurate and efficient event detection, we have created a visual analytics tool that provides analysts with linked geo-spatiotemporal and statistical analytic views. We model syndromic hotspots by applying a kernel density estimation on the population sample. When an analyst selects a syndromic hotspot, temporal statistical graphs of the hotspot are created. Similarly, regions in the statistical plots may be selected to generate geospatial features specific to the current time period. Demographic filtering can then be combined to determine if certain populations are more affected than others. These tools allow analysts to perform real-time hypothesis testing and evaluation.	Ross Maciejewski;Stephen Rudolph;Ryan Hafen;Ahmad M. Abusalah;Mohamed Yakout;Mourad Ouzzani;William S. Cleveland;Shaun J. Grannis;Michael Wade;David S. Ebert	;;;;;;;;;	10.1109/INFVIS.2001.963294;10.1109/VAST.2007.4388991;10.1109/INFVIS.1998.729563;10.1109/VISUAL.1995.485139;10.1109/VAST.2007.4388993		
VAST	2008	Configurable Spaces: Temporal analysis in diagrammatic contexts	10.1109/VAST.2008.4677355	http://dx.doi.org/10.1109/VAST.2008.4677355	43	50	C	Social network graphs, concept maps, and process charts are examples of diagrammatic representations employed by intelligence analysts to understand complex systems. Unfortunately, these 2D representations currently do not easily convey the flow, sequence, tempo and other important dynamic behaviors within these systems. In this paper we present Configurable Spaces, a novel analytical method for visualizing patterns of activity over time in complex diagrammatically- represented systems. Configurable Spaces extends GeoTime's X, Y, T coordinate workspace space for temporal analysis to any arbitrary diagrammatic work space by replacing a geographic map with a diagram. This paper traces progress from concept to prototype, and discusses how diagrams can be created, transformed and leveraged for analysis, including generating diagrams from knowledge bases, visualizing temporal concept maps, and the use of linked diagrams for exploring complex, multi-dimensional, sequences of events. An evaluation of the prototype by the National Institute of Standards and Technology showed intelligence analysts believed they were able to attain an increased level of insight, were able to explore data more efficiently, and that Configurable Spaces would help them work faster.	Thomas Kapler;Ryan Eccles;Robert Harper 0002;William Wright	;;;	10.1109/VAST.2006.261450;10.1109/INFVIS.2001.963281;10.1109/INFVIS.2004.27;10.1109/INFVIS.2002.1173160	human information interaction, visual analytics, graph visualization, geo-temporal analysis, concept maps	
VAST	2008	Spatio-temporal aggregation for visual analysis of movements	10.1109/VAST.2008.4677356	http://dx.doi.org/10.1109/VAST.2008.4677356	51	58	C	Data about movements of various objects are collected in growing amounts by means of current tracking technologies. Traditional approaches to visualization and interactive exploration of movement data cannot cope with data of such sizes. In this research paper we investigate the ways of using aggregation for visual analysis of movement data. We define aggregation methods suitable for movement data and find visualization and interaction techniques to represent results of aggregations and enable comprehensive exploration of the data. We consider two possible views of movement, traffic-oriented and trajectory-oriented. Each view requires different methods of analysis and of data aggregation. We illustrate our argument with example data resulting from tracking multiple cars in Milan and example analysis tasks from the domain of city traffic management.	Gennady L. Andrienko;Natalia V. Andrienko	Fraunhofer Inst. IAIS, Sankt Augustin|c|;		Movement data, spatio-temporal data, aggregation, scalable visualization, geovisualization	
VAST	2008	Maintaining interactivity while exploring massive time series	10.1109/VAST.2008.4677357	http://dx.doi.org/10.1109/VAST.2008.4677357	59	66	C	The speed of data retrieval qualitatively affects how analysts visually explore and analyze their data. To ensure smooth interactions in massive time series datasets, one needs to address the challenges of computing ad hoc queries, distributing query load, and hiding system latency. In this paper, we present ATLAS, a visualization tool for temporal data that addresses these issues using a combination of high performance database technology, predictive caching, and level of detail management. We demonstrate ATLAS using commodity hardware on a network traffic dataset of more than a billion records.	Sye-Min Chan;Ling Xiao;John Gerth;Pat Hanrahan	Stanford Univ., Stanford, CA|c|;;;	10.1109/VAST.2006.261437;10.1109/VAST.2007.4388998		
VAST	2008	Collaborative synthesis of visual analytic results	10.1109/VAST.2008.4677358	http://dx.doi.org/10.1109/VAST.2008.4677358	67	74	C	Visual analytic tools allow analysts to generate large collections of useful analytical results. We anticipate that analysts in most real world situations will draw from these collections when working together to solve complicated problems. This indicates a need to understand how users synthesize multiple collections of results. This paper reports the results of collaborative synthesis experiments conducted with expert geographers and disease biologists. Ten participants were worked in pairs to complete a simulated real-world synthesis task using artifacts printed on cards on a large, paper-covered workspace. Experiment results indicate that groups use a number of different approaches to collaborative synthesis, and that they employ a variety of organizational metaphors to structure their information. It is further evident that establishing common ground and role assignment are critical aspects of collaborative synthesis. We conclude with a set of general design guidelines for collaborative synthesis support tools.	Anthony C. Robinson	Dept. of Geogr., Pennsylvania State Univ., State College, PA|c|	10.1109/VAST.2007.4389011;10.1109/TVCG.2007.70594;10.1109/TVCG.2007.70568	Movement data, spatio-temporal data, aggregation, scalable visualization, geovisualization	
VAST	2008	Visual evaluation of text features for document summarization and analysis	10.1109/VAST.2008.4677359	http://dx.doi.org/10.1109/VAST.2008.4677359	75	82	C	Thanks to the Web-related and other advanced technologies, textual information is increasingly being stored in digital form and posted online. Automatic methods to analyze such textual information are becoming inevitable. Many of those methods are based on quantitative text features. Analysts face the challenge to choose the most appropriate features for their tasks. This requires effective approaches for evaluation and feature-engineering.	Daniela Oelke;Peter Bak;Daniel A. Keim;Mark Last;Guy Danon	Univ. of Konstanz, Konstanz|c|;;;;	10.1109/VISUAL.1993.398863;10.1109/INFVIS.1995.528686;10.1109/VAST.2007.4389004		
VAST	2008	Evaluating the relationship between user interaction and financial visual analysis	10.1109/VAST.2008.4677360	http://dx.doi.org/10.1109/VAST.2008.4677360	83	90	C	It has been widely accepted that interactive visualization techniques enable users to more effectively form hypotheses and identify areas for more detailed investigation. There have been numerous empirical user studies testing the effectiveness of specific visual analytical tools. However, there has been limited effort in connecting a userpsilas interaction with his reasoning for the purpose of extracting the relationship between the two. In this paper, we present an approach for capturing and analyzing user interactions in a financial visual analytical tool and describe an exploratory user study that examines these interaction strategies. To achieve this goal, we created two visual tools to analyze raw interaction data captured during the user session. The results of this study demonstrate one possible strategy for understanding the relationship between interaction and reasoning both operationally and strategically.	Dong Hyun Jeong;Wenwen Dou;Heather Lipford;Felesia Stukes;Remco Chang;William Ribarsky	;;;;;	10.1109/VAST.2007.4389009		
VAST	2008	Visual analytics for complex concepts using a human cognition model	10.1109/VAST.2008.4677361	http://dx.doi.org/10.1109/VAST.2008.4677361	91	98	C	As the information being visualized and the process of understanding that information both become increasingly complex, it is necessary to develop new visualization approaches that facilitate the flow of human reasoning. In this paper, we endeavor to push visualization design a step beyond current user models by discussing a modeling framework of human ldquohigher cognition.rdquo Based on this cognition model, we present design guidelines for the development of visual interfaces designed to maximize the complementary cognitive strengths of both human and computer. Some of these principles are already being reflected in the better visual analytics designs, while others have not yet been applied or fully applied. But none of the guidelines have explained the deeper rationale that the model provides. Lastly, we discuss and assess these visual analytics guidelines through the evaluation of several visualization examples.	Tera Marie Green;William Ribarsky;Brian D. Fisher	Charlotte Visualization Center, Univ. of North Carolina, Charlotte, NC|c|;;	10.1109/VISUAL.2005.1532781;10.1109/VAST.2006.261425;10.1109/TVCG.2007.70574;10.1109/VAST.2007.4389006;10.1109/VAST.2007.4389005;10.1109/VAST.2007.4389009;10.1109/INFVIS.1995.528686	visual analytics, cognition and perception theory, embodied cognition, visualization taxonomies and models	
VAST	2008	Entity-based collaboration tools for intelligence analysis	10.1109/VAST.2008.4677362	http://dx.doi.org/10.1109/VAST.2008.4677362	99	106	C	Software tools that make it easier for analysts to collaborate as a natural part of their work will lead to better analysis that is informed by more perspectives. We are interested to know if software tools can be designed that support collaboration even as they allow analysts to find documents and organize information (including evidence, schemas, and hypotheses). We have modified the Entity Workspace system, described previously, to test such designs. We have evaluated the resulting design in both a laboratory study and a study where it is situated with an analysis team. In both cases, effects on collaboration appear to be positive. Key aspects of the design include an evidence notebook optimized for organizing entities (rather than text characters), information structures that can be collapsed and expanded, visualization of evidence that emphasizes events and documents (rather than emphasizing the entity graph), and a notification system that finds entities of mutual interest to multiple analysts.	Eric A. Bier;Stuart K. Card;John W. Bodnar	Palo Alto Res. Center, Palo Alto, CA|c|;;	10.1109/VAST.2006.261427;10.1109/VAST.2007.4389006	sensemaking, information foraging, collective intelligence, exploratory search, information workspace, entity-based, collaboration, intelligence analysis, visualization, semantic notebook, argumentation marshalling, visual analytics	
VAST	2008	Applied visual analytics for economic decision-making	10.1109/VAST.2008.4677363	http://dx.doi.org/10.1109/VAST.2008.4677363	107	114	C	This paper introduces the application of visual analytics techniques as a novel approach for improving economic decision making. Particularly, we focus on two known problems where subjectspsila behavior consistently deviates from the optimal, the Winnerpsilas and Loserpsilas Curse. According to economists, subjects fail to recognize the profit-maximizing decision strategy in both the Winnerpsilas and Loserpsilas curse because they are unable to properly consider all the available information. As such, we have created a visual analytics tool to aid subjects in decision making under the Acquiring a Company framework common in many economic experiments. We demonstrate the added value of visual analytics in the decision making process through a series of user studies comparing standard visualization methods with interactive visual analytics techniques. Our work presents not only a basis for development and evaluation of economic visual analytic research, but also empirical evidence demonstrating the added value of applying visual analytics to general decision making tasks.	Anya Samak;Ross Maciejewski;David S. Ebert	Dept. of Econ., Purdue Univ., West Lafayette, IN|c|;;			
VAST	2008	Narratives: A visualization to track narrative events as they develop	10.1109/VAST.2008.4677364	http://dx.doi.org/10.1109/VAST.2008.4677364	115	122	C	Analyzing unstructured text streams can be challenging. One popular approach is to isolate specific themes in the text, and to visualize the connections between them. Some existing systems, like ThemeRiver, provide a temporal view of changes in themes; other systems, like In-Spire, use clustering techniques to help an analyst identify the themes at a single point in time. Narratives combines both of these techniques; it uses a temporal axis to visualize ways that concepts have changed over time, and introduces several methods to explore how those concepts relate to each other. Narratives is designed to help the user place news stories in their historical and social context by understanding how the major topics associated with them have changed over time. Users can relate articles through time by examining the topical keywords that summarize a specific news event. By tracking the attention to a news article in the form of references in social media (such as weblogs), a user discovers both important events and measures the social relevance of these stories.	Danyel Fisher;Aaron Hoff;George G. Robertson;Matthew Hurst	;;;	10.1109/INFVIS.2005.1532122;10.1109/INFVIS.1999.801851	blogs, events, trends, time series, topic detection and tracking 	
VAST	2008	Characterizing users' visual analytic activity for insight provenance	10.1109/VAST.2008.4677365	http://dx.doi.org/10.1109/VAST.2008.4677365	123	130	C	Insight provenance - a historical record of the process and rationale by which an insight is derived - is an essential requirement in many visual analytics applications. While work in this area has relied on either manually recorded provenance (e.g., user notes) or automatically recorded event-based insight provenance (e.g., clicks, drags, and key-presses), both approaches have fundamental limitations. Our aim is to develop a new approach that combines the benefits of both approaches while avoiding their deficiencies. Toward this goal, we characterize userspsila visual analytic activity at multiple levels of granularity. Moreover, we identify a critical level of abstraction, Actions, that can be used to represent visual analytic activity with a set of general but semantically meaningful behavior types. In turn, the action types can be used as the semantic building blocks for insight provenance. We present a catalog of common actions identified through observations of several different visual analytic systems. In addition, we define a taxonomy to categorize actions into three major classes based on their semantic intent. The concept of actions has been integrated into our labpsilas prototype visual analytic system, HARVEST, as the basis for its insight provenance capabilities.	David Gotz;Michelle X. Zhou	;	10.1109/INFVIS.2004.2;10.1109/INFVIS.1996.559213;10.1109/TVCG.2007.70577;10.1109/VISUAL.2005.1532788;10.1109/VAST.2007.4388992;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.1998.729560;10.1109/INFVIS.2004.10;10.1109/VAST.2006.261430;10.1109/INFVIS.2000.885092;10.1109/VISUAL.1990.146375;10.1109/VISUAL.2002.1183791	Taxonomy, Information Visualization, Analytic Activity, Visual Analytics, Insight Provenance	
VAST	2008	The Scalable Reasoning System: Lightweight visualization for distributed analytics	10.1109/VAST.2008.4677366	http://dx.doi.org/10.1109/VAST.2008.4677366	131	138	C	A central challenge in visual analytics is the creation of accessible, widely distributable analysis applications that bring the benefits of visual discovery to as broad a user base as possible. Moreover, to support the role of visualization in the knowledge creation process, it is advantageous to allow users to describe the reasoning strategies they employ while interacting with analytic environments. We introduce an application suite called the scalable reasoning system (SRS), which provides Web-based and mobile interfaces for visual analysis. The service-oriented analytic framework that underlies SRS provides a platform for deploying pervasive visual analytic environments across an enterprise. SRS represents a ldquolightweightrdquo approach to visual analytics whereby thin client analytic applications can be rapidly deployed in a platform-agnostic fashion. Client applications support multiple coordinated views while giving analysts the ability to record evidence, assumptions, hypotheses and other reasoning artifacts. We describe the capabilities of SRS in the context of a real-world deployment at a regional law enforcement organization.	William A. Pike;Joe Bruce;Bob Baddeley;Daniel M. Best;Lyndsey Franklin;Richard May;Douglas M. Rice;Roderick M. Riensche;Katarina Younkin	;;;;;;;;	10.1109/TVCG.2007.70577;10.1109/TVCG.2006.142;10.1109/VAST.2007.4388996;10.1109/INFVIS.2005.1532133;10.1109/VISUAL.1993.398874;10.1109/VAST.2007.4389006;10.1109/VAST.2007.4388991	Web visualization, mobile visualization, analytic reasoning, law enforcement, multiple views	
VAST	2008	Generating hypotheses of trends in high-dimensional data skeletons	10.1109/VAST.2008.4677367	http://dx.doi.org/10.1109/VAST.2008.4677367	139	146	C	We seek an information-revealing representation for high-dimensional data distributions that may contain local trends in certain subspaces. Examples are data that have continuous support in simple shapes with identifiable branches. Such data can be represented by a graph that consists of segments of locally fit principal curves or surfaces summarizing each identifiable branch. We describe a new algorithm to find the optimal paths through such a principal graph. The paths are optimal in the sense that they represent the longest smooth trends through the data set, and jointly they cover the data set entirely with minimum overlap. The algorithm is suitable for hypothesizing trends in high-dimensional data, and can assist exploratory data analysis and visualization.	Chandan K. Reddy;Snehal Pokharkar;Tin Kam Ho	;;	10.1109/VAST.2007.4388999		
VAST	2008	Multivariate visual explanation for high dimensional datasets	10.1109/VAST.2008.4677368	http://dx.doi.org/10.1109/VAST.2008.4677368	147	154	C	Understanding multivariate relationships is an important task in multivariate data analysis. Unfortunately, existing multivariate visualization systems lose effectiveness when analyzing relationships among variables that span more than a few dimensions. We present a novel multivariate visual explanation approach that helps users interactively discover multivariate relationships among a large number of dimensions by integrating automatic numerical differentiation techniques and multidimensional visualization techniques. The result is an efficient workflow for multivariate analysis model construction, interactive dimension reduction, and multivariate knowledge discovery leveraging both automatic multivariate analysis and interactive multivariate data visual exploration. Case studies and a formal user study with a real dataset illustrate the effectiveness of this approach.	Scott Barlowe;Tianyi Zhang;Yujie Liu;Jing Yang 0001;Donald J. Jacobs	Dept of Comput. Sci., Univ. of North Carolina, Charlotte, NC|c|;;;;	10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2004.10;10.1109/VISUAL.1995.485140;10.1109/VISUAL.1995.485139;10.1109/INFVIS.2004.3;10.1109/INFVIS.2004.71	visual analysis, multivariate analysis, dimension reduction, multivariate model construction, multivariate visualization	
VAST	2008	Visual mining of multimedia data for social and behavioral studies	10.1109/VAST.2008.4677369	http://dx.doi.org/10.1109/VAST.2008.4677369	155	162	C	With advances in computing techniques, a large amount of high-resolution high-quality multimedia data (video and audio, etc.) has been collected in research laboratories in various scientific disciplines, particularly in social and behavioral studies. How to automatically and effectively discover new knowledge from rich multimedia data poses a compelling challenge since state-of-the-art data mining techniques can most often only search and extract pre-defined patterns or knowledge from complex heterogeneous data. In light of this, our approach is to take advantages of both the power of human perception system and the power of computational algorithms. More specifically, we propose an approach that allows scientists to use data mining as a first pass, and then forms a closed loop of visual analysis of current results followed by more data mining work inspired by visualization, the results of which can be in turn visualized and lead to the next round of visual exploration and analysis. In this way, new insights and hypotheses gleaned from the raw data and the current level of analysis can contribute to further analysis. As a first step toward this goal, we implement a visualization system with three critical components: (1) A smooth interface between visualization and data mining. The new analysis results can be automatically loaded into our visualization tool. (2) A flexible tool to explore and query temporal data derived from raw multimedia data. We represent temporal data into two forms - continuous variables and event variables. We have developed various ways to visualize both temporal correlations and statistics of multiple variables with the same type, and conditional and high-order statistics between continuous and event variables. (3) A seamless interface between raw multimedia data and derived data. Our visualization tool allows users to explore, compare, and analyze multi-stream derived variables and simultaneously switch to access raw multimedia data. We de- - monstrate various functions in our visualization program using a set of multimedia data including video, audio and motion tracking data.	Chen Yu;Yiwen Zhong;Thomas G. Smith 0002;Ikhyun Park;Weixia Huang	;;;;	10.1109/INFVIS.2001.963273;10.1109/INFVIS.1999.801851	visual data mining, multimedia data 	
VAST	2008	Multidimensional visual analysis using cross-filtered views	10.1109/VAST.2008.4677370	http://dx.doi.org/10.1109/VAST.2008.4677370	163	170	C	Analysis of multidimensional data often requires careful examination of relationships across dimensions. Coordinated multiple view approaches have become commonplace in visual analysis tools because they directly support expression of complex multidimensional queries using simple interactions. However, generating such tools remains difficult because of the need to map domain-specific data structures and semantics into the idiosyncratic combinations of interdependent data and visual abstractions needed to reveal particular patterns and distributions in cross-dimensional relationships. This paper describes: (1) a method for interactively expressing sequences of multidimensional set queries by cross-filtering data values across pairs of views, and (2) design strategies for constructing coordinated multiple view interfaces for cross-filtered visual analysis of multidimensional data sets. Using examples of cross-filtered visualizations of data from several different domains, we describe how cross-filtering can be modularized and reused across designs, flexibly customized with respect to data types across multiple dimensions, and incorporated into more wide-ranging multiple view designs. The demonstrated analytic utility of these examples suggest that cross-filtering is a suitable design pattern for instantiation in a wide variety of visual analysis tools.	Chris Weaver	GeoVISTA Center & Dept. of Geogr., Pennsylvania State Univ., University Park, PA|c|	10.1109/TVCG.2006.178;10.1109/VAST.2006.261428;10.1109/INFVIS.2003.1249024;10.1109/INFVIS.2000.885086;10.1109/VISUAL.1994.346302;10.1109/INFVIS.1998.729560;10.1109/TVCG.2007.70594;10.1109/VAST.2007.4389006		
VAST	2008	Interactive poster: Visual analytic techniques for CO<inf>2</inf> emissions and concentrations in the United States	10.1109/VAST.2008.4677372	http://dx.doi.org/10.1109/VAST.2008.4677372	173	174	M	Climate change has emerged as one of the grand global challenges facing humanity. The dominant anthropogenic greenhouse gas that seems to be contributing to the climate change problem, carbon dioxide (CO2), has a complex cycle through the atmosphere, oceans and biosphere. The combustion of fossil fuels (power production, transportation, etc.) remains the largest source of anthropogenic CO2 to the Earthpsilas atmosphere. Up until very recently, the quantification of fossil fuel CO2 was understood only at coarse space and time scales. A recent research effort has greatly improved this space/time quantification resulting in source data at a resolution of less than 10 km2/hr at the surface of North America. By providing visual tools to examine this new, high resolution CO2 data, we can better understand the way that CO2 is transmitted within the atmosphere and how it is exchanged with other components of the Earth System. We have developed interactive visual analytic tools, which allows for easy data manipulation, analysis, and extraction. The visualization system is aimed for a wide range of users which include researchers and political leaders. The goal is to help assist these people in analyzing data and enabling new policy options in mitigation of fossil fuel CO2 emissions in the U.S.	Nathan Andrysco;Bedrich Benes;Kevin R. Gurney	Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN|c|;;			
VAST	2008	Envisioning user models for adaptive visualization	10.1109/VAST.2008.4677373	http://dx.doi.org/10.1109/VAST.2008.4677373	175	176	M	Adaptive search systems apply user models to provide better separation of relevant and non-relevant documents in a list of results. This paper presents our attempt to leverage this ability of user models in the context of visual information analysis. We developed an adaptive visualization approach for presentation and exploration of search results. We simulated a visual intelligence search/analysis scenario with log data extracted from an adaptive information foraging study and were able to verify that our method can improve the ability of traditional relevance visualization to separate relevant and irrelevant information.	Jae-wook Ahn;Peter Brusilovsky	Sch. of Inf. Sci., Univ. of Pittsburgh, Pittsburgh, PA|c|;			
VAST	2008	A compound approach for interactive visualization of time-oriented data	10.1109/VAST.2008.4677374	http://dx.doi.org/10.1109/VAST.2008.4677374	177	178	M	Many real-world visual analytics applications involve time-oriented data. I am working in a research project related to this challenge where I am responsible for the interactive visualization part. My goal are interactive visualizations to explore such time-oriented data according to the user tasks while considering the structure of time. Time is composed of many granularities that are likely to have crucial influence on the formation of the data. The challenge is to integrate the granularities into a detailed compound view on the data, like the compound eye of insects integrates many images into one view. Other members of our team are experts in temporal data mining and user centered design. The goal is to combine our research topics to an integrated system that helps domain experts to get more insight from their time-oriented data.	Tim Lammarsch	Dept. of Inf. & Knowledge Eng. (ike), Danube Univ. Krems, Krems|c|			
VAST	2008	Interactive poster - SocialRank: An ego- and time-centric workflow for relationship identification	10.1109/VAST.2008.4677375	http://dx.doi.org/10.1109/VAST.2008.4677375	179	180	M	From instant messaging and email to wikis and blogs, millions of individuals are generating content that reflects their relationships with others in the world, both online and offline. Since communication artifacts are recordings of life events, we can gain insights into the social attributes and structures of the people within this communication history. In this paper, we describe SocialRank, an ego- and time-centric workflow for identifying social relationships in an email corpus. This workflow includes four high-level tasks: discovery, validation, annotation and dissemination. SocialRank combines relationship ranking algorithms with timeline, social network diagram, and multidimensional scaling visualization techniques to support these tasks.	Jaime Montemayor;Christopher P. Diehl;Michael Pekala;David Patrone	Milton Eisenhower Res. Center, Johns Hopkins Univ. Appl. Phys. Lab., Laurel, MD|c|;;;			
VAST	2008	Visual analysis for mutual fund performance	10.1109/VAST.2008.4677376	http://dx.doi.org/10.1109/VAST.2008.4677376	181	182	M	Mutual funds are one of the most important investment instruments available. However, choosing among mutual funds is not an easy task because they vary in many different dimensions, such as asset size, turnover and fee structure, and these characteristics may affect fund returns. It is thus important to understand the relation between fund performance and these properties. In this work, we use a new visual analytical tool, the density-based distribution map, to assist in this task. By visualizing various important fund characteristics from a real-world database of the US stock funds, our new visual representations greatly help understand the relation between fund characteristics and returns.	Ye Zhao;Jamal Alsakran;Xinlei Zhao	Kent State Univ., Kent, OH|c|;;			
VAST	2008	An information visualisation system for the understanding of web data	10.1109/VAST.2008.4677377	http://dx.doi.org/10.1109/VAST.2008.4677377	183	184	M	Internet has become one of the best communication and marketing tools. Hence, designing well-structured Web sites with the information or products that users look for is a crucial mission. For this reason, understanding Web data is a decisive task to assure the success of a Website. In that sense, data mining techniques provide many metrics and statistics useful to automatically discover the structure, contents and usage of a site. This research aims at proving the usefulness of a set of information visualisation techniques in order to analyse Web data, using a visual Web mining tool that allows the combination, coordination and exploration of visualisations to get insight on Web data. The tool, named WET, provides a set of visual metaphors that represent the structure of the Websites where Web metrics are overlaid.	Victor Pascual-Cid	Web Res. Group, Univ. Pompeu Fabra & Fundacio Barcelona Media, Barcelona|c|			
VAST	2008	Supporting exploration awareness for visual analytics	10.1109/VAST.2008.4677378	http://dx.doi.org/10.1109/VAST.2008.4677378	185	186	M	While exploring data using information visualization, analysts try to make sense of the data, build cases, and present them to others. However, if the exploration is long or done in multiple sessions, it can be hard for analysts to remember all interesting visualizations and the relationships among them they have seen. Often, they will see the same or similar visualizations, and are unable to recall when, why and how they have seen something similar. Recalling and retrieving interesting visualizations are important tasks for the analysis processes such as problem solving, reasoning, and conceptualization. In this paper, we argue that offering support for thinking based on past analysis processes is important, and present a solution for this.	Yedendra Babu Shrinivasan;Jarke J. van Wijk	Eindhoven Univ. of Technol., Eindhoven|c|;			
VAST	2008	Interactive poster: Visual data mining of unevenly-spaced event sequences	10.1109/VAST.2008.4677379	http://dx.doi.org/10.1109/VAST.2008.4677379	187	188	M	We present a process for the exploration and analysis of large databases of events. A typical database is characterized by the sequential actions of a number of individual entities. These entities can be compared by their similarities in sequence and changes in sequence over time. The correlation of two sequences can provide important clues as to the possibility of a connection between the responsible entities, but an analyst might not be able to specify the type of connection sought prior to examination. Our process incorporates extensive automated calculation and data mining but permits diversity of analysis by providing visualization of results at multiple levels, taking advantage of human intuition and visual processing to generate avenues of inquiry.	Alex Godwin;Remco Chang;Robert Kosara;William Ribarsky	Visualization Center, Univ. of North Carolina at Charlotte, Charlotte, NC|c|;;;			
VAST	2008	A 3D treemap approach for analyzing the classificatory distribution in patent portfolios	10.1109/VAST.2008.4677380	http://dx.doi.org/10.1109/VAST.2008.4677380	189	190	M	Due to the complexity of the patent domain and the huge amount of data, advanced interactive visual techniques are needed to support the analysis of large patent collections and portfolios. In this paper we present a new approach for visualizing the classificatory distribution of patent collections among the International Patent Classification (IPC) - todaypsilas most important internationally agreed patent classification system with about 70.000 categories. Our approach is based on an interactive three-dimensional treemap overlaid with adjacency edge bundles.	Mark Giereth;Harald Bosch;Thomas Ertl	Visualization & Interactive Syst. Inst., Univ. of Stuttgart, Stuttgart|c|;;			
VAST	2008	Visual analysis of seismic simulation data	10.1109/VAST.2008.4677381	http://dx.doi.org/10.1109/VAST.2008.4677381	191	192	M	Seismic simulations use finite element methods to describe ground motion. The results of such numerical simulations are often difficult to interpret for decision makers. We describe a terrain rendering engine that uses photorealistic metaphors to represent typical terrain properties without representing an actual terrain. In the context of ground motion, a simulation of the effects of various types of earthquakes on buildings has been conducted. Usually, such structural response simulations are carried out independently and are being visualized separate from the ground motion simulation. We combine the results from both simulations in an interactive, hybrid visualization so that decision makers (first responders and emergency management agencies) are provided with a photo-realistic, simulated view of various earthquake scenarios, enabling them to study the effect of various earthquakes on buildings typical for a rural or urban area. We present a method for visually analyzing large-scale simulation data from different sources (ground motion simulation and structural response simulation) using photorealistic metaphors. We have implemented an intuitive, interactive system for visual analysis and inspection of possible effects of various types of earthquakes on an inventory of buildings typical for a particular area. The underlying rendering system can be easily adapted for other simulations, such as smoke plumes or biohazards.	Florian Jürgen Gerhardt;Joerg Meyer	Tech. Univ. of Kaiserslautern, Kaiserslautern|c|;			
VAST	2008	VAST 2008 Challenge: Introducing mini-challenges	10.1109/VAST.2008.4677383	http://dx.doi.org/10.1109/VAST.2008.4677383			M	Visual analytics experts realize that one effective way to push the field forward and to develop metrics for measuring the performance of various visual analytics components is to hold an annual competition. The VAST 2008 Challenge is the third year that such a competition was held in conjunction with the IEEE Visual Analytics Science and Technology (VAST) symposium. The authors restructured the contest format used in 2006 and 2007 to reduce the barriers to participation and offered four mini-challenges and a Grand Challenge. Mini Challenge participants were to use visual analytic tools to explore one of four heterogeneous data collections to analyze specific activities of a fictitious, controversial movement. Questions asked in the Grand Challenge required the participants to synthesize data from all four data sets. In this paper we give a brief overview of the data sets, the tasks, the participation, the judging, and the results.	Georges G. Grinstein;Catherine Plaisant;Sharon J. Laskowski;Teresa O'Connell;Jean Scholtz;Mark A. Whiting	;;;;;			
VAST	2008	Grand challenge award: Data integration visualization and collaboration in the VAST 2008 Challenge	10.1109/VAST.2008.4677384	http://dx.doi.org/10.1109/VAST.2008.4677384			M	The VAST 2008 Challenge consisted of four heterogeneous synthetic data sets each organized into separate mini-challenges. The Grand Challenge required integrating the raw data from these four data sets as well as integrating results and findings from team members working on specific mini-challenges. Modeling the problem with a semantic network provided a means for integrating both the raw data and the subjective findings.	Donald Pellegrino;Chi-Chun Pan;Anthony C. Robinson;Michael Stryker;Junyan Luo;Chris Weaver;Prasenjit Mitra;Chaomei Chen;Ian Turton;Alan M. MacEachren	;;;;;;;;;			
VAST	2008	Grand challenge award 2008: Support for diverse analytic techniques - nSpace2 and GeoTime visual analytics	10.1109/VAST.2008.4677385	http://dx.doi.org/10.1109/VAST.2008.4677385			M	GeoTime and nSpace2 are interactive visual analytics tools that were used to examine and interpret all four of the 2008 VAST Challenge datasets. GeoTime excels in visualizing event patterns in time and space, or in time and any abstract landscape, while nSpace2 is a web-based analytical tool designed to support every step of the analytical process. nSpace2 is an integrating analytic environment. This paper highlights the VAST analytical experience with these tools that contributed to the success of these tools and this team for the third consecutive year.	Lynn Chien;Annie Tat;Pascale Proulx;Adeel Khamisa;William Wright	;;;;			
VAST	2008	Grand challenge award: Interactive visual analytics palantir: The future of analysis	10.1109/VAST.2008.4677386	http://dx.doi.org/10.1109/VAST.2008.4677386			M	Palantir is a world-class analytic platform used worldwide by governmental and financial analysts. This paper provides an introduction to the platform contextualized by its application to the 2008 IEEE VAST contest. In this challenge, we explored a notional dataset about a fabricated religious movement, Catalanopsilas Paraiso Manifesto Movement.	Jason Payne;Jake Solomon;Ravi Sankar;Bob McGrew	;;;			
VAST	2008	Migrant boat mini challenge award: Simple and effective integrated display geo-temporal analysis of migrant boats	10.1109/VAST.2008.4677387	http://dx.doi.org/10.1109/VAST.2008.4677387			M	We provide a description of the tools and techniques used in our analysis of the VAST 2008 Challenge dealing with mass movement of persons departing Isla Del Sue.no on boats for the United States during 2005-2007. We used visual analytics to explore migration patterns, characterize the choice and evolution of landing sites, characterize the geographical patterns of interdictions and determine the successful landing rate. Our ComVis tool, in connection with some helper applications and Google Earth, allowed us to explore geo-temporal characteristics of the data set and answer the challenge questions. The ComVis project file captures the visual analysis context and facilitates better collaboration among team members.	Ranko Miklin;Tomislav Lipic;Zoltan Konyha;Mario Beric;Wolfgang Freiler;Kresimir Matkovic;Denis Gracanin	Dept. of Telecommun., Univ. of Zagreb, Zagreb|c|;;;;;;			
VAST	2008	Evacuation trace Mini Challenge award: Tool integration analysis of movements with Geospatial Visual Analytics Toolkit	10.1109/VAST.2008.4677388	http://dx.doi.org/10.1109/VAST.2008.4677388			M	The Geospatial Visual Analytics Toolkit intended for exploratory analysis of spatial and spatio-temporal data has been recently enriched with specific visual and computational techniques supporting analysis of data about movement. We applied these and other techniques to the data and tasks of Mini Challenge 4, where it was necessary to analyze tracks of moving people.CR Categories and Subject Descriptors: H.1.2 [User/Machine Systems]: Human information processing - Visual Analytics; 1.6.9 [Visualization]: information visualization.	Natalia V. Andrienko;Gennady L. Andrienko	Fraunhofer Inst. IAIS, Sankt Augustin|c|;			
VAST	2008	Cell phone mini challenge award: Social network accuracy - exploring temporal communication in mobile call graphs	10.1109/VAST.2008.4677389	http://dx.doi.org/10.1109/VAST.2008.4677389			M	In the mobile call mini challenge of VAST 2008 contest, we explored the temporal communication patterns of Catalano/Vidro social network which is reflected in the mobile call data. We focus on detecting the hierarchy of the social network and try to get the important actors in it. We present our tools and methods in this summary. By using the visual analytic approaches, we can find out not only the temporal communication patterns in the social network but also the hierarchy of it.	Qi Ye;Tian Zhu;Deyong Hu;Bin Wu;Nan Du;Bai Wang	Beijing Key Lab. of Intell. Telecommun. Software & Multimedia, Beijing Univ. of Posts & Telecommun., Beijing|c|;;;;;			
VAST	2008	Evacuation traces mini challenge: User testing to obtain consensus discovering the terrorist	10.1109/VAST.2008.4677390	http://dx.doi.org/10.1109/VAST.2008.4677390			M	The adoption of visual analytics methodologies in security applications is an approach that could lead to interesting results. Usually, the data that has to be analyzed finds in a graphical representation its preferred nature, such as spatial or temporal relationships. Due to the nature of these applications, it is very important that key-details are made easy to identify. In the context of the VAST 2008 Challenge, we developed a visualization tool that graphically displays the movement of 82 employees of the Miami Department of Health (USA). We also asked 13 users to identify potential suspects and observe what happened during an evacuation of the building caused by an explosion. In this paper we explain the results of the user testing we conducted and how the users interpreted the event taken into account.	Adalberto L. Simeone;Paolo Buono	Univ. of Bari, Bari|c|;			
VAST	2008	Cell phone mini challenge award: Intuitive social network graphs visual analytics of cell phone data using mobivis and ontovis	10.1109/VAST.2008.4677391	http://dx.doi.org/10.1109/VAST.2008.4677391			M	MobiVis is a visual analytics tools to aid in the process of processing and understanding complex relational data, such as social networks. At the core of these tools is the ability to filter complex networks structurally and semantically, which helps us discover clusters and patterns in the organization of social networks. Semantic filtering is obtained via an ontology graph, based on another visual analytics tool, called OntoVis. In this summary, we describe how these tools where used to analyze one of the mini-challenges of the 2008 VAST challenge.	Carlos D. Correa;Tarik Crnovrsanin;Chris Muelder;Zeqian Shen;Ryan Armstrong;James Shearer;Kwan-Liu Ma	Visualization & Interface Design Innovation Group, Univ. of California, Davis, CA|c|;;;;;;			
VAST	2008	Using SocialAction to uncover structure in social networks over time	10.1109/VAST.2008.4677392	http://dx.doi.org/10.1109/VAST.2008.4677392			M	I describe how SocialAction was used to find insights in an evolving social structure VAST Challenge 2008psilas Mini-Challenge 3. This analysis and SocialAction were given the award, ldquoCell Phone Mini Challenge Award: Time Visualizations of Cell Phone Activityrdquo.	Adam Perer	Dept. of Comput. Sci., Univ. of Maryland, College Park, MD|c|			
VAST	2008	Cell phone Mini Challenge: Node-link animation award animating multivariate dynamic social networks	10.1109/VAST.2008.4677393	http://dx.doi.org/10.1109/VAST.2008.4677393			M	This article describes the visualization tool developed for analysing a dynamic social network of phone calls, for the VAST 2008 mini challenge. The tool was designed to highlight temporal changes in the network, by animating different network visual representations. We also explain how animating these network representations, helped to identify key events in the mini challenge problem scenario. Finally, we make some suggestions for future research and development in the area.	Michael Farrugia;Aaron J. Quigley	Univ. Coll. Dublin, Dublin|c|;			
VAST	2008	Migrant boat mini challenge award: Analysis summary a geo-temporal analysis of the migrant boat dataset	10.1109/VAST.2008.4677394	http://dx.doi.org/10.1109/VAST.2008.4677394			M	The SPADAC team used various visual analytics tools and methods to find geo-temporal patterns of migration from a Caribbean island from 2005-2007. In this paper, we describe the tools and methods used in the analysis. These methods included generating temporal variograms, dendrograms, and proportionally weighted migration maps, using tools such as the R statistical software package and Signature Analysttrade. We found that there is a significant positive space-time correlation with the boat encounters (especially the landings), with a migratory shift further away from the point of departure over time.	Benjamin Holland;Lisa Kuchy;Jason Dalton	;;			
VAST	2008	Evacuation Traces Mini Challenge award: Innovative trace visualization staining for information discovery	10.1109/VAST.2008.4677395	http://dx.doi.org/10.1109/VAST.2008.4677395			M	Staining is a technique for categorizing time-varying spatial data; that is, data of things moving through space over time. In Staining, a stain is applied in either time or space, and the objects which move through the stain become marked. This technique and a research prototype demonstrating the technique were developed in response to the VAST 2008 Contest Mini-challenge: Evacuation Traces.	Dennis J. Bouvier;Britian Oates	Southern Illinois Univ. Edwardsville, Edwardsville, IL|c|;			
VAST	2008	Award: Efficient toolkit integration solving the cell phone calls challenge with the Prajna Project	10.1109/VAST.2008.4677396	http://dx.doi.org/10.1109/VAST.2008.4677396			M	The Prajna Project is a Java toolkit designed to provide various capabilities for visualization, knowledge representation, geographic displays, semantic reasoning, and data fusion. Rather than attempt to recreate the significant capabilities provided in other tools, Prajna instead provides software bridges to incorporate other toolkits where appropriate. This challenge required the development of a custom application for visual analysis. By applying the utilities within the Prajna project, I developed a robust and diverse set of capabilities to solve the analytical challenge.	Edward Swing				
Vis	2008	A Comparison of the Perceptual Benefits of Linear Perspective and Physically-Based Illumination for Display of Dense 3D Streamtubes	10.1109/TVCG.2008.108	http://dx.doi.org/10.1109/TVCG.2008.108	1723	1730	J	Large datasets typically contain coarse features comprised of finer sub-features. Even if the shapes of the small structures are evident in a 3D display, the aggregate shapes they suggest may not be easily inferred. From previous studies in shape perception, the evidence has not been clear whether physically-based illumination confers any advantage over local illumination for understanding scenes that arise in visualization of large data sets that contain features at two distinct scales. In this paper we show that physically-based illumination can improve the perception for some static scenes of complex 3D geometry from flow fields. We perform human-subjects experiments to quantify the effect of physically-based illumination on participant performance for two tasks: selecting the closer of two streamtubes from a field of tubes, and identifying the shape of the domain of a flow field over different densities of tubes. We find that physically-based illumination influences participant performance as strongly as perspective projection, suggesting that physically-based illumination is indeed a strong cue to the layout of complex scenes. We also find that increasing the density of tubes for the shape identification task improved participant performance under physically-based illumination but not under the traditional hardware-accelerated illumination model.	Chris Weigle;David C. Banks	Dept. of Electr. Eng. & Comput. Sci., Univ. of Tennessee, Knoxville, TN|c|;	10.1109/TVCG.2006.197;10.1109/VISUAL.2003.1250395	user study, volume completion, 3D shape perception, physically-based illumination, global illumination, local illumination, multi-scale visualization, flow visualization, streamtubes, DT-MRI, white matter tractography	
Vis	2008	A Practical Approach to Morse-Smale Complex Computation: Scalability and Generality	10.1109/TVCG.2008.110	http://dx.doi.org/10.1109/TVCG.2008.110	1619	1626	J	The Morse-Smale (MS) complex has proven to be a useful tool in extracting and visualizing features from scalar-valued data. However, efficient computation of the MS complex for large scale data remains a challenging problem. We describe a new algorithm and easily extensible framework for computing MS complexes for large scale data of any dimension where scalar values are given at the vertices of a closure-finite and weak topology (CW) complex, therefore enabling computation on a wide variety of meshes such as regular grids, simplicial meshes, and adaptive multiresolution (AMR) meshes. A new divide-and-conquer strategy allows for memory-efficient computation of the MS complex and simplification on-the-fly to control the size of the output. In addition to being able to handle various data formats, the framework supports implementation-specific optimizations, for example, for regular data. We present the complete characterization of critical point cancellations in all dimensions. This technique enables the topology based analysis of large data on off-the-shelf computers. In particular we demonstrate the first full computation of the MS complex for a 1 billion/10243 node grid on a laptop computer with 2 Gb memory.	Attila Gyulassy;Peer-Timo Bremer;Bernd Hamann;Valerio Pascucci	Livermore Nat. Lab., UC Davis & Lawrence, Livermore, CA|c|;;;	10.1109/VISUAL.2005.1532839;10.1109/VISUAL.1998.745329;10.1109/VISUAL.2004.96;10.1109/TVCG.2007.70552;10.1109/VISUAL.1998.745312;10.1109/VISUAL.2000.885680;10.1109/VISUAL.2000.885703;10.1109/TVCG.2006.186	Topology-based analysis, Morse-Smale complex, large scale data	
Vis	2008	AD-Frustum: Adaptive Frustum Tracing for Interactive Sound Propagation	10.1109/TVCG.2008.111	http://dx.doi.org/10.1109/TVCG.2008.111	1707	1722	J	We present an interactive algorithm to compute sound propagation paths for transmission, specular reflection and edge diffraction in complex scenes. Our formulation uses an adaptive frustum representation that is automatically sub-divided to accurately compute intersections with the scene primitives. We describe a simple and fast algorithm to approximate the visible surface for each frustum and generate new frusta based on specular reflection and edge diffraction. Our approach is applicable to all triangulated models and we demonstrate its performance on architectural and outdoor models with tens or hundreds of thousands of triangles and moving objects. In practice, our algorithm can perform geometric sound propagation in complex scenes at 4-20 frames per second on a multi-core PC.	Anish Chandak;Christian Lauterbach;Micah T. Taylor;Zhimin Ren;Dinesh Manocha	UNC-Chapel Hill, Chapel Hill, NC|c|;;;;	10.1109/TVCG.2007.70575;10.1109/TVCG.2006.125;10.1109/VISUAL.2005.1532790	Sound propagation, interactive system, auralization	
Vis	2008	An Efficient Naturalness-Preserving Image-Recoloring Method for Dichromats	10.1109/TVCG.2008.112	http://dx.doi.org/10.1109/TVCG.2008.112	1747	1754	J	We present an efficient and automatic image-recoloring technique for dichromats that highlights important visual details that would otherwise be unnoticed by these individuals. While previous techniques approach this problem by potentially changing all colors of the original image, causing their results to look unnatural to color vision deficients, our approach preserves, as much as possible, the image's original colors. Our approach is about three orders of magnitude faster than previous ones. The results of a paired-comparison evaluation carried out with fourteen color-vision deficients (CVDs) indicated the preference of our technique over the state-of-the-art automatic recoloring technique for dichromats. When considering information visualization examples, the subjects tend to prefer our results over the original images. An extension of our technique that exaggerates color contrast tends to be preferred when CVDs compared pairs of scientific visualization images. These results provide valuable information for guiding the design of visualizations for color-vision deficients.	Giovane R. Kuhn;Manuel Menezes de Oliveira Neto;Leandro A. F. Fernandes	Inst. de Inf., UFRGS, Porto Alegre|c|;;		Color-contrast enhancement, Color-vision deficiency, Recoloring algorithms, Information and Scientific Visualization	
Vis	2008	Box Spline Reconstruction On The Face-Centered Cubic Lattice	10.1109/TVCG.2008.115	http://dx.doi.org/10.1109/TVCG.2008.115	1523	1530	J	We introduce and analyze an efficient reconstruction algorithm for FCC-sampled data. The reconstruction is based on the 6-direction box spline that is naturally associated with the FCC lattice and shares the continuity and approximation order of the triquadratic B-spline. We observe less aliasing for generic level sets and derive special techniques to attain the higher evaluation efficiency promised by the lower degree and smaller stencil-size of the C1 6-direction box spline over the triquadratic B-spline.	Inho Kim;Alireza Entezari;Jörg Peters	CISE Dept., Univ. of Florida, Gainesville, FL|c|;;	10.1109/VISUAL.1994.346331;10.1109/TVCG.2007.70573;10.1109/VISUAL.2001.964498;10.1109/VISUAL.1993.398851;10.1109/VISUAL.2005.1532811;10.1109/VISUAL.2005.1532810;10.1109/VISUAL.2004.65	Volumetric data reconstruction, box spline, Face-Centered Cubic lattice	
Vis	2008	Brushing of Attribute Clouds for the Visualization of Multivariate Data	10.1109/TVCG.2008.116	http://dx.doi.org/10.1109/TVCG.2008.116	1459	1466	J	The visualization and exploration of multivariate data is still a challenging task. Methods either try to visualize all variables simultaneously at each position using glyph-based approaches or use linked views for the interaction between attribute space and physical domain such as brushing of scatterplots. Most visualizations of the attribute space are either difficult to understand or suffer from visual clutter. We propose a transformation of the high-dimensional data in attribute space to 2D that results in a point cloud, called attribute cloud, such that points with similar multivariate attributes are located close to each other. The transformation is based on ideas from multivariate density estimation and manifold learning. The resulting attribute cloud is an easy to understand visualization of multivariate data in two dimensions. We explain several techniques to incorporate additional information into the attribute cloud, that help the user get a better understanding of multivariate data. Using different examples from fluid dynamics and climate simulation, we show how brushing can be used to explore the attribute cloud and find interesting structures in physical space.	Heike Leitte;Michael Böttinger;Gerik Scheuermann	Univ. of Leipzig, Leipzig|c|;;	10.1109/INFVIS.2003.1249024;10.1109/INFVIS.2002.1173157;10.1109/VISUAL.1995.485139;10.1109/INFVIS.1999.801858;10.1109/VISUAL.1996.567800;10.1109/VISUAL.2004.113;10.1109/VISUAL.1998.745289	Multivariate data, brushing, data transformation, manifold learning, linked views	
Vis	2008	Color Design for Illustrative Visualization	10.1109/TVCG.2008.118	http://dx.doi.org/10.1109/TVCG.2008.118	1739	1754	J	Professional designers and artists are quite cognizant of the rules that guide the design of effective color palettes, from both aesthetic and attention-guiding points of view. In the field of visualization, however, the use of systematic rules embracing these aspects has received less attention. The situation is further complicated by the fact that visualization often uses semi-transparencies to reveal occluded objects, in which case the resulting color mixing effects add additional constraints to the choice of the color palette. Color design forms a crucial part in visual aesthetics. Thus, the consideration of these issues can be of great value in the emerging field of illustrative visualization. We describe a knowledge-based system that captures established color design rules into a comprehensive interactive framework, aimed to aid users in the selection of colors for scene objects and incorporating individual preferences, importance functions, and overall scene composition. Our framework also offers new knowledge and solutions for the mixing, ordering and choice of colors in the rendering of semi-transparent layers and surfaces. All design rules are evaluated via user studies, for which we extend the method of conjoint analysis to task-based testing scenarios. Our framework's use of principles rooted in color design with application for the illustration of features in pre-classified data distinguishes it from existing systems which target the exploration of continuous-range density data via perceptual color maps.	Lujin Wang;Joachim Giesen;Kevin T. McDonnell;Peter Zolliker;Klaus Mueller	Center for Visual Comput., Stony Brook Univ., Stony Brook, NY|c|;;;;	10.1109/VISUAL.1993.398874;10.1109/VISUAL.1996.568118;10.1109/TVCG.2007.70542;10.1109/TVCG.2006.174;10.1109/VISUAL.2001.964510	Color design, volume rendering, transparency, user study evaluation, conjoint analysis, illustrative visualization	
Vis	2008	Continuous Scatterplots	10.1109/TVCG.2008.119	http://dx.doi.org/10.1109/TVCG.2008.119	1428	1435	J	Scatterplots are well established means of visualizing discrete data values with two data variables as a collection of discrete points. We aim at generalizing the concept of scatterplots to the visualization of spatially continuous input data by a continuous and dense plot. An example of a continuous input field is data defined on an n-D spatial grid with respective interpolation or reconstruction of in-between values. We propose a rigorous, accurate, and generic mathematical model of continuous scatterplots that considers an arbitrary density defined on an input field on an n-D domain and that maps this density to m-D scatterplots. Special cases are derived from this generic model and discussed in detail: scatterplots where the n-D spatial domain and the m-D data attribute domain have identical dimension, 1-D scatterplots as a way to define continuous histograms, and 2-D scatterplots of data on 3-D spatial grids. We show how continuous histograms are related to traditional discrete histograms and to the histograms of isosurface statistics. Based on the mathematical model of continuous scatterplots, respective visualization algorithms are derived, in particular for 2-D scatterplots of data from 3-D tetrahedral grids. For several visualization tasks, we show the applicability of continuous scatterplots. Since continuous scatterplots do not only sample data at grid points but interpolate data values within cells, a dense and complete visualization of the data set is achieved that scales well with increasing data set size. Especially for irregular grids with varying cell size, improved results are obtained when compared to conventional scatterplots. Therefore, continuous scatterplots are a suitable extension of a statistics visualization technique to be applied to typical data from scientific computation.	Sven Bachthaler;Daniel Weiskopf	Visualization Res. Center, Univ. Stuttgart, Stuttgart|c|;	10.1109/TVCG.2006.168;10.1109/TVCG.2008.160	Scatterplot, histogram, continuous frequency plot, interpolation	
Vis	2008	Direct Volume Editing	10.1109/TVCG.2008.120	http://dx.doi.org/10.1109/TVCG.2008.120	1388	1395	J	In this work we present basic methodology for interactive volume editing on GPUs, and we demonstrate the use of these methods to achieve a number of different effects. We present fast techniques to modify the appearance and structure of volumetric scalar fields given on Cartesian grids. Similar to 2D circular brushes as used in surface painting we present 3D spherical brushes for intuitive coloring of particular structures in such fields. This paint metaphor is extended to allow the user to change the data itself, and the use of this functionality for interactive structure isolation, hole filling, and artefact removal is demonstrated. Building on previous work in the field we introduce high-resolution selection volumes, which can be seen as a resolution-based focus+context metaphor. By utilizing such volumes we present a novel approach to interactive volume editing at sub-voxel accuracy. Finally, we introduce a fast technique to paste textures onto iso-surfaces in a 3D scalar field. Since the texture resolution is independent of the volume resolution, this technique allows structure-aligned textures containing appearance properties or textual information to be used for volume augmentation and annotation.	Kai Bürger;Jens H. Krüger;Rüdiger Westermann	Tech. Univ. Munchen, Munich|c|;;	10.1109/TVCG.2006.124;10.1109/VISUAL.1996.568110;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2002.1183762;10.1109/VISUAL.2002.1183777;10.1109/TVCG.2007.70555;10.1109/VISUAL.2003.1250381;10.1109/VISUAL.2000.885694;10.1109/VISUAL.2004.48;10.1109/VISUAL.2005.1532856;10.1109/VISUAL.1996.568108	Volume editing, GPU, painting, carving, annotations	
Vis	2008	Edge Groups: An Approach to Understanding the Mesh Quality of Marching Methods	10.1109/TVCG.2008.122	http://dx.doi.org/10.1109/TVCG.2008.122	1651	1666	J	Marching cubes is the most popular isosurface extraction algorithm due to its simplicity, efficiency and robustness. It has been widely studied, improved, and extended. While much early work was concerned with efficiency and correctness issues, lately there has been a push to improve the quality of marching cubes meshes so that they can be used in computational codes. In this work we present a new classification of MC cases that we call edge groups, which helps elucidate the issues that impact the triangle quality of the meshes that the method generates. This formulation allows a more systematic way to bound the triangle quality, and is general enough to extend to other polyhedral cell shapes used in other polygonization algorithms. Using this analysis, we also discuss ways to improve the quality of the resulting triangle mesh, including some that require only minor modifications of the original algorithm.	Carlos A. Dietrich;Carlos Eduardo Scheidegger;João Luiz Dihl Comba;Luciana Porcher Nedel;Cláudio T. Silva	Inst. de Inf., Univ. Fed. do Rio Grande do Sul, Rio Grande do Sul|c|;;;;	10.1109/TVCG.2006.168;10.1109/VISUAL.2000.885704;10.1109/VISUAL.1994.346308;10.1109/VISUAL.2004.28;10.1109/VISUAL.2003.1250355;10.1109/TVCG.2006.149;10.1109/VISUAL.2002.1183808;10.1109/TVCG.2007.70604	Isosurface extraction, Marching Cubes	
Vis	2008	Effective visualization of complex vascular structures using a non-parametric vessel detection method	10.1109/TVCG.2008.123	http://dx.doi.org/10.1109/TVCG.2008.123	1603	1610	J	The effective visualization of vascular structures is critical for diagnosis, surgical planning as well as treatment evaluation. In recent work, we have developed an algorithm for vessel detection that examines the intensity profile around each voxel in an angiographic image and determines the likelihood that any given voxel belongs to a vessel; we term this the "vesselness coefficient" of the voxel. Our results show that our algorithm works particularly well for visualizing branch points in vessels. Compared to standard Hessian based techniques, which are fine-tuned to identify long cylindrical structures, our technique identifies branches and connections with other vessels. Using our computed vesselness coefficient, we explore a set of techniques for visualizing vasculature. Visualizing vessels is particularly challenging because not only is their position in space important for clinicians but it is also important to be able to resolve their spatial relationship. We applied visualization techniques that provide shape cues as well as depth cues to allow the viewer to differentiate between vessels that are closer from those that are farther. We use our computed vesselness coefficient to effectively visualize vasculature in both clinical neurovascular x-ray computed tomography based angiography images, as well as images from three different animal studies. We conducted a formal user evaluation of our visualization techniques with the help of radiologists, surgeons, and other expert users. Results indicate that experts preferred distance color blending and tone shading for conveying depth over standard visualization techniques.	Alark Joshi;Xiaoning Qian;Donald P. Dione;Ketan R. Bulsara;Christopher K. Breuer;Albert J. Sinusas;Xenophon Papademetris	Yale Univ., New Haven, CT|c|;;;;;;	10.1109/TVCG.2006.172;10.1109/VISUAL.2000.885694;10.1109/TVCG.2007.70555;10.1109/VISUAL.2003.1250353	Vessel identification, Vessel visualization, Evaluation of visualization techniques	
Vis	2008	Effective Visualization of Short Routes	10.1109/TVCG.2008.124	http://dx.doi.org/10.1109/TVCG.2008.124	1452	1458	J	In this work we develop a new alternative to conventional maps for visualization of relatively short paths as they are frequently encountered in hotels, resorts or museums. Our approach is based on a warped rendering of a 3D model of the environment such that the visualized path appears to be straight even though it may contain several junctions. This has the advantage that the beholder of the image gains a realistic impression of the surroundings along the way which makes it easy to retrace the route in practice. We give an intuitive method for generation of such images and present results from user studies undertaken to evaluate the benefit of the warped images for orientation in unknown environments.	Patrick Degener;Ruwen Schnabel;Christopher Schwartz;Reinhard Klein	Comput. Graphics Group, Univ. of Bonn, Bonn|c|;;;		Maps, Route visualization, Space deformation	
Vis	2008	Effects of Video Placement and Spatial Context Presentation on Path Reconstruction Tasks with Contextualized Videos	10.1109/TVCG.2008.126	http://dx.doi.org/10.1109/TVCG.2008.126	1755	1762	J	Many interesting and promising prototypes for visualizing video data have been proposed, including those that combine videos with their spatial context (contextualized videos). However, relatively little work has investigated the fundamental design factors behind these prototypes in order to provide general design guidance. Focusing on real-time video data visualization, we evaluated two important design factors - video placement method and spatial context presentation method - through a user study. In addition, we evaluated the effect of spatial knowledge of the environment. Participantspsila performance was measured through path reconstruction tasks, where the participants followed a target through simulated surveillance videos and marked the target paths on the environment model. We found that embedding videos inside the model enabled realtime strategies and led to faster performance. With the help of contextualized videos, participants not familiar with the real environment achieved similar task performance to participants that worked in that environment. We discuss design implications and provide general design recommendations for traffic and security surveillance system interfaces.	Yi Wang;Doug A. Bowman;David M. Krum;Enylton Machado Coelho;Tonya L. Smith-Jackson;David Bailey;Sarah Peck;Swethan Anand;Trevor Kennedy;Yernar Abdrazakov	Virginia Tech., Blacksburg, VA|c|;;;;;;;;;	10.1109/TVCG.2007.70621;10.1109/TVCG.2007.70544;10.1109/VISUAL.2003.1250400	contextualized videos, design factors, user study, video placement, spatial context, tracking, path reconstruction	
Vis	2008	Estimating Crossing fibers: A Tensor Decomposition Approach	10.1109/TVCG.2008.128	http://dx.doi.org/10.1109/TVCG.2008.128	1635	1642	J	Diffusion weighted magnetic resonance imaging is a unique tool for non-invasive investigation of major nerve fiber tracts. Since the popular diffusion tensor (DT-MRI) model is limited to voxels with a single fiber direction, a number of high angular resolution techniques have been proposed to provide information about more diverse fiber distributions. Two such approaches are Q-Ball imaging and spherical deconvolution, which produce orientation distribution functions (ODFs) on the sphere. For analysis and visualization, the maxima of these functions have been used as principal directions, even though the results are known to be biased in case of crossing fiber tracts. In this paper, we present a more reliable technique for extracting discrete orientations from continuous ODFs, which is based on decomposing their higher-order tensor representation into an isotropic component, several rank-1 terms, and a small residual. Comparing to ground truth in synthetic data shows that the novel method reduces bias and reliably reconstructs crossing fibers which are not resolved as individual maxima in the ODF We present results on both Q-Ball and spherical deconvolution data and demonstrate that the estimated directions allow for plausible fiber tracking in a real data set.	Thomas Schultz 0001;Hans-Peter Seidel	MPI Inf., Saarbrucken|c|;	10.1109/VISUAL.2005.1532773	DW-MRI, Q-Ball, spherical deconvolution, fiber tracking, higher-order tensor, tensor decomposition	
Vis	2008	Extensions of Parallel Coordinates for Interactive Exploration of Large Multi-Timepoint Data Sets	10.1109/TVCG.2008.131	http://dx.doi.org/10.1109/TVCG.2008.131	1436	1451	J	Parallel coordinate plots (PCPs) are commonly used in information visualization to provide insight into multi-variate data. These plots help to spot correlations between variables. PCPs have been successfully applied to unstructured datasets up to a few millions of points. In this paper, we present techniques to enhance the usability of PCPs for the exploration of large, multi-timepoint volumetric data sets, containing tens of millions of points per timestep. The main difficulties that arise when applying PCPs to large numbers of data points are visual clutter and slow performance, making interactive exploration infeasible. Moreover, the spatial context of the volumetric data is usually lost. We describe techniques for preprocessing using data quantization and compression, and for fast GPU-based rendering of PCPs using joint density distributions for each pair of consecutive variables, resulting in a smooth, continuous visualization. Also, fast brushing techniques are proposed for interactive data selection in multiple linked views, including a 3D spatial volume view. These techniques have been successfully applied to three large data sets: Hurricane Isabel (Vis'04 contest), the ionization front instability data set (Vis'08 design contest), and data from a large-eddy simulation of cumulus clouds. With these data, we show how PCPs can be extended to successfully visualize and interactively explore multi-timepoint volumetric datasets with an order of magnitude more data points.	Jorik Blaas;Charl P. Botha;Frits H. Post	Data Visualization Group, Delft Univ. of Technol., Delft|c|;;	10.1109/VISUAL.1999.809866;10.1109/TVCG.2006.170;10.1109/INFVIS.2005.1532138;10.1109/INFVIS.2004.68;10.1109/VISUAL.1994.346302;10.1109/VISUAL.2000.885739	Parallel coordinate plots, time-varying, multi-field, linked related views	
Vis	2008	Focus+Context Visualization with Distortion Minimization	10.1109/TVCG.2008.132	http://dx.doi.org/10.1109/TVCG.2008.132	1731	1738	J	The need to examine and manipulate large surface models is commonly found in many science, engineering, and medical applications. On a desktop monitor, however, seeing the whole model in detail is not possible. In this paper, we present a new, interactive Focus+Context method for visualizing large surface models. Our method, based on an energy optimization model, allows the user to magnify an area of interest to see it in detail while deforming the rest of the area without perceivable distortion. The rest of the surface area is essentially shrunk to use as little of the screen space as possible in order to keep the entire model displayed on screen. We demonstrate the efficacy and robustness of our method with a variety of models.	Yu-Shuen Wang;Tong-Yee Lee;Chiew-Lan Tai	Dept. of Comput. Sci. & Inf. Eng., Nat. Cheng-Kung Univ., Tainan|c|;;	10.1109/INFVIS.1997.636786;10.1109/VISUAL.2004.48;10.1109/INFVIS.1996.559215;10.1109/VISUAL.2003.1250400;10.1109/INFVIS.1996.559214;10.1109/INFVIS.1998.729558;10.1109/VISUAL.2005.1532818	Focus+Context visualization, magnification, bounding space	
Vis	2008	Generation of Accurate Integral Surfaces in Time-Dependent Vector fields	10.1109/TVCG.2008.133	http://dx.doi.org/10.1109/TVCG.2008.133	1404	1411	J	We present a novel approach for the direct computation of integral surfaces in time-dependent vector fields. As opposed to previous work, which we analyze in detail, our approach is based on a separation of integral surface computation into two stages: surface approximation and generation of a graphical representation. This allows us to overcome several limitations of existing techniques. We first describe an algorithm for surface integration that approximates a series of time lines using iterative refinement and computes a skeleton of the integral surface. In a second step, we generate a well-conditioned triangulation. Our approach allows a highly accurate treatment of very large time-varying vector fields in an efficient, streaming fashion. We examine the properties of the presented methods on several example datasets and perform a numerical study of its correctness and accuracy. Finally, we investigate some visualization aspects of integral surfaces.	Christoph Garth;Han Krishnan;Xavier Tricoche;Tom Tricoche;Kenneth I. Joy	Inst. of Data Anal. & Visualization, Univ. of California, Davis, CA|c|;;;;	10.1109/VISUAL.1993.398875;10.1109/VISUAL.2001.964506;10.1109/VISUAL.2004.28;10.1109/VISUAL.1992.235211;10.1109/VISUAL.1992.235226	3D vector field visualization, flow visualization, time-varying and time-series visualization, surface extraction	
Vis	2008	Geodesic Distance-weighted Shape Vector Image Diffusion	10.1109/TVCG.2008.134	http://dx.doi.org/10.1109/TVCG.2008.134	1643	1650	J	This paper presents a novel and efficient surface matching and visualization framework through the geodesic distance-weighted shape vector image diffusion. Based on conformal geometry, our approach can uniquely map a 3D surface to a canonical rectangular domain and encode the shape characteristics (e.g., mean curvatures and conformal factors) of the surface in the 2D domain to construct a geodesic distance-weighted shape vector image, where the distances between sampling pixels are not uniform but the actual geodesic distances on the manifold. Through the novel geodesic distance-weighted shape vector image diffusion presented in this paper, we can create a multiscale diffusion space, in which the cross-scale extrema can be detected as the robust geometric features for the matching and registration of surfaces. Therefore, statistical analysis and visualization of surface properties across subjects become readily available. The experiments on scanned surface models show that our method is very robust for feature extraction and surface matching even under noise and resolution change. We have also applied the framework on the real 3D human neocortical surfaces, and demonstrated the excellent performance of our approach in statistical analysis and integrated visualization of the multimodality volumetric data over the shape vector image.	Jing Hua;Zhaoqiang Lai;Ming Dong;Xianfeng Gu;Hong Qin	Wayne State Univ., Detroit, MI|c|;;;;		Surface Matching, Shape Vector Image, Multiscale Diffusion, Visualization	
Vis	2008	Glyph-Based SPECT Visualization for the Diagnosis of Coronary Artery Disease	10.1109/TVCG.2008.136	http://dx.doi.org/10.1109/TVCG.2008.136	1499	1506	J	Myocardial perfusion imaging with single photon emission computed tomography (SPECT) is an established method for the detection and evaluation of coronary artery disease (CAD). State-of-the-art SPECT scanners yield a large number of regional parameters of the left-ventricular myocardium (e.g., blood supply at rest and during stress, wall thickness, and wall thickening during heart contraction) that all need to be assessed by the physician. Today, the individual parameters of this multivariate data set are displayed as stacks of 2D slices, bull's eye plots, or, more recently, surfaces in 3D, which depict the left-ventricular wall. In all these visualizations, the data sets are displayed side-by-side rather than in an integrated manner, such that the multivariate data have to be examined sequentially and need to be fused mentally. This is time consuming and error-prone. In this paper we present an interactive 3D glyph visualization, which enables an effective integrated visualization of the multivariate data. Results from semiotic theory are used to optimize the mapping of different variables to glyph properties. This facilitates an improved perception of important information and thus an accelerated diagnosis. The 3D glyphs are linked to the established 2D views, which permit a more detailed inspection, and to relevant meta-information such as known stenoses of coronary vessels supplying the myocardial region. Our method has demonstrated its potential for clinical routine use in real application scenarios assessed by nuclear physicians.	Jennis Meyer-Spradow;Lars Stegger;Christian Döring;Timo Ropinski;Klaus H. Hinrichs	Visualization & Comput. Graphics Res. Group, Univ. of Munster, Munster|c|;;;;	10.1109/VISUAL.2003.1250425;10.1109/TVCG.2006.134;10.1109/TVCG.2007.70550;10.1109/VISUAL.1998.745294	Multivariate visualization, glyph techniques, SPECT, myocardial perfusion imaging	
Vis	2008	Hypothesis Generation in Climate Research with Interactive Visual Data Exploration	10.1109/TVCG.2008.139	http://dx.doi.org/10.1109/TVCG.2008.139	1579	1586	J	One of the most prominent topics in climate research is the investigation, detection, and allocation of climate change. In this paper, we aim at identifying regions in the atmosphere (e.g., certain height layers) which can act as sensitive and robust indicators for climate change. We demonstrate how interactive visual data exploration of large amounts of multi-variate and time-dependent climate data enables the steered generation of promising hypotheses for subsequent statistical evaluation. The use of new visualization and interaction technology-in the context of a coordinated multiple views framework-allows not only to identify these promising hypotheses, but also to efficiently narrow down parameters that are required in the process of computational data analysis. Two datasets, namely an ECHAM5 climate model run and the ERA-40 reanalysis incorporating observational data, are investigated. Higher-order information such as linear trends or signal-to-noise ratio is derived and interactively explored in order to detect and explore those regions which react most sensitively to climate change. As one conclusion from this study, we identify an excellent potential for usefully generalizing our approach to other, similar application cases, as well.	Johannes Kehrer;Florian Ladstädter;Philipp Muigg;Helmut Doleisch;Andrea Steiner;Helwig Hauser	Dept. of Inf., Bergen Univ., Bergen|c|;;;;;	10.1109/INFVIS.2005.1532138;10.1109/VISUAL.1994.346302;10.1109/VISUAL.2005.1532850;10.1109/TVCG.2006.170	Interactive visual hypothesis generation, interactive visual exploration and analysis, visualization for climate research	
Vis	2008	Importance-Driven Time-Varying Data Visualization	10.1109/TVCG.2008.140	http://dx.doi.org/10.1109/TVCG.2008.140	1547	1554	J	The ability to identify and present the most essential aspects of time-varying data is critically important in many areas of science and engineering. This paper introduces an importance-driven approach to time-varying volume data visualization for enhancing that ability. By conducting a block-wise analysis of the data in the joint feature-temporal space, we derive an importance curve for each data block based on the formulation of conditional entropy from information theory. Each curve characterizes the local temporal behavior of the respective block, and clustering the importance curves of all the volume blocks effectively classifies the underlying data. Based on different temporal trends exhibited by importance curves and their clustering results, we suggest several interesting and effective visualization techniques to reveal the important aspects of time-varying data.	Chaoli Wang;Hongfeng Yu;Kwan-Liu Ma	Dept. of Comput. Sci., Univ. of California, Davis, CA|c|;;	10.1109/VISUAL.1995.480809;10.1109/VISUAL.2003.1250402;10.1109/TVCG.2007.70615;10.1109/TVCG.2006.152;10.1109/VISUAL.2001.964531;10.1109/VISUAL.1994.346321;10.1109/VISUAL.1999.809910;10.1109/VISUAL.2004.48	Time-varying data, conditional entropy, joint feature-temporal space, clustering, highlighting, transfer function	
Vis	2008	Interactive Blood Damage Analysis for Ventricular Assist Devices	10.1109/TVCG.2008.142	http://dx.doi.org/10.1109/TVCG.2008.142	1515	1522	J	Ventricular Assist Devices (VADs) support the heart in its vital task of maintaining circulation in the human body when the heart alone is not able to maintain a sufficient flow rate due to illness or degenerative diseases. However, the engineering of these devices is a highly demanding task. Advanced modeling methods and computer simulations allow the investigation of the fluid flow inside such a device and in particular of potential blood damage. In this paper we present a set of visualization methods which have been designed to specifically support the analysis of a tensor-based blood damage prediction model. This model is based on the tracing of particles through the VAD, for each of which the cumulative blood damage can be computed. The model's tensor output approximates a single blood cell's deformation in the flow field. The tensor and derived scalar data are subsequently visualized using techniques based on icons, particle visualization, and function plotting. All these techniques are accessible through a Virtual Reality-based user interface, which features not only stereoscopic rendering but also natural interaction with the complex three-dimensional data. To illustrate the effectiveness of these visualization methods, we present the results of an analysis session that was performed by domain experts for a specific data set for the MicroMed DeBakey VAD.	Bernd Hentschel;Irene Tedjo;Markus Probst;Marc Wolter;Marek Behr;Christian H. Bischof;Torsten Kuhlen	Virtual Reality Group, RWTH Aachen Univ., Aachen|c|;;;;;;	10.1109/VISUAL.2004.55;10.1109/VISUAL.1991.175771;10.1109/VISUAL.2004.80;10.1109/VISUAL.2002.1183798;10.1109/VISUAL.1993.398849;10.1109/TVCG.2006.134;10.1109/TVCG.2006.181;10.1109/VISUAL.1991.175781;10.1109/VISUAL.1996.567777	Tensor visualization, time-dependent data, blood damage, ventricular assist device, virtual reality	
Vis	2008	Interactive Comparison of Scalar fields Based on Largest Contours with Applications to Flow Visualization	10.1109/TVCG.2008.143	http://dx.doi.org/10.1109/TVCG.2008.143	1475	1482	J	Understanding fluid flow data, especially vortices, is still a challenging task. Sophisticated visualization tools help to gain insight. In this paper, we present a novel approach for the interactive comparison of scalar fields using isosurfaces, and its application to fluid flow datasets. Features in two scalar fields are defined by largest contour segmentation after topological simplification. These features are matched using a volumetric similarity measure based on spatial overlap of individual features. The relationships defined by this similarity measure are ranked and presented in a thumbnail gallery of feature pairs and a graph representation showing all relationships between individual contours. Additionally, linked views of the contour trees are provided to ease navigation. The main render view shows the selected features overlapping each other. Thus, by displaying individual features and their relationships in a structured fashion, we enable exploratory visualization of correlations between similar structures in two scalar fields. We demonstrate the utility of our approach by applying it to a number of complex fluid flow datasets, where the emphasis is put on the comparison of vortex related scalar quantities.	Dominic Schneider;Alexander Wiebel;Hamish Carr;Mario Hlawitschka;Gerik Scheuermann	Leipzig Univ., Leipzig|c|;;;;	10.1109/TVCG.2006.164;10.1109/VISUAL.2001.964519;10.1109/VISUAL.2004.107;10.1109/TVCG.2007.70615;10.1109/VISUAL.2005.1532830;10.1109/TVCG.2006.165;10.1109/VISUAL.2004.96;10.1109/VISUAL.2003.1250374;10.1109/TVCG.2007.70519;10.1109/VISUAL.2005.1532848;10.1109/VISUAL.1997.663875;10.1109/VISUAL.2005.1532835	Scalar topology, comparative visualization, contour tree, largest contours, flow visualization	
Vis	2008	Interactive Visual Steering - Rapid Visual Prototyping of a Common Rail Injection System	10.1109/TVCG.2008.145	http://dx.doi.org/10.1109/TVCG.2008.145	1699	1706	J	Interactive steering with visualization has been a common goal of the visualization research community for twenty years, but it is rarely ever realized in practice. In this paper we describe a successful realization of a tightly coupled steering loop, integrating new simulation technology and interactive visual analysis in a prototyping environment for automotive industry system design. Due to increasing pressure on car manufacturers to meet new emission regulations, to improve efficiency, and to reduce noise, both simulation and visualization are pushed to their limits. Automotive system components, such as the powertrain system or the injection system have an increasing number of parameters, and new design approaches are required. It is no longer possible to optimize such a system solely based on experience or forward optimization. By coupling interactive visualization with the simulation back-end (computational steering), it is now possible to quickly prototype a new system, starting from a non-optimized initial prototype and the corresponding simulation model. The prototyping continues through the refinement of the simulation model, of the simulation parameters and through trial-and-error attempts to an optimized solution. The ability to early see the first results from a multidimensional simulation space - thousands of simulations are run for a multidimensional variety of input parameters - and to quickly go back into the simulation and request more runs in particular parameter regions of interest significantly improves the prototyping process and provides a deeper understanding of the system behavior. The excellent results which we achieved for the common rail injection system strongly suggest that our approach has a great potential of being generalized to other, similar scenarios.	Kresimir Matkovic;Denis Gracanin;Mario Jelovic;Helwig Hauser	VRVis Res. Center, Vienna|c|;;;	10.1109/INFVIS.2004.12;10.1109/VISUAL.1998.745289;10.1109/VISUAL.2005.1532821;10.1109/INFVIS.2005.1532143;10.1109/VISUAL.2003.1250417;10.1109/VISUAL.2005.1532850	Interactive computational steering, interactive visual analysis, simulation, common rail injection system	
Vis	2008	Interactive Visualization and Analysis of Transitional Flow	10.1109/TVCG.2008.146	http://dx.doi.org/10.1109/TVCG.2008.146	1420	1427	J	A stand-alone visualization application has been developed by a multi-disciplinary, collaborative team with the sole purpose of creating an interactive exploration environment allowing turbulent flow researchers to experiment and validate hypotheses using visualization. This system has specific optimizations made in data management, caching computations, and visualization allowing for the interactive exploration of datasets on the order of 1TB in size. Using this application, the user (co-author Calo) is able to interactively visualize and analyze all regions of a transitional flow volume, including the laminar, transitional and fully turbulent regions. The underlying goal of the visualizations produced from these transitional flow simulations is to localize turbulent spots in the laminar region of the boundary layer, determine under which conditions they form, and follow their evolution. The initiation of turbulent spots, which ultimately lead to full turbulence, was located via a proposed feature detection condition and verified by experimental results. The conditions under which these turbulent spots form and coalesce are validated and presented.	Gregory P. Johnson;Victor Calo;Kelly P. Gaither	Texas Adv. Comput. Center, Univ. of Texas, Austin, TX|c|;;	10.1109/VISUAL.2005.1532792;10.1109/VISUAL.1993.398850;10.1109/VISUAL.2005.1532794;10.1109/VISUAL.1991.175818;10.1109/VISUAL.2004.55	Applications of Visualization, Flow Visualization, Transitional Flow, Turbulence	
Vis	2008	Interactive Volume Exploration for Feature Detection and Quantification in Industrial CT Data	10.1109/TVCG.2008.147	http://dx.doi.org/10.1109/TVCG.2008.147	1507	1514	J	This paper presents a novel method for interactive exploration of industrial CT volumes such as cast metal parts, with the goal of interactively detecting, classifying, and quantifying features using a visualization-driven approach. The standard approach for defect detection builds on region growing, which requires manually tuning parameters such as target ranges for density and size, variance, as well as the specification of seed points. If the results are not satisfactory, region growing must be performed again with different parameters. In contrast, our method allows interactive exploration of the parameter space, completely separated from region growing in an unattended pre-processing stage. The pre-computed feature volume tracks a feature size curve for each voxel over time, which is identified with the main region growing parameter such as variance. A novel 3D transfer function domain over (density, feature.size, time) allows for interactive exploration of feature classes. Features and feature size curves can also be explored individually, which helps with transfer function specification and allows coloring individual features and disabling features resulting from CT artifacts. Based on the classification obtained through exploration, the classified features can be quantified immediately.	Markus Hadwiger;Laura Fritz;Christof Rezk-Salama;Thomas Höllt;Georg Geier;Thomas Pabel	VRVis Res. Center, Vienna|c|;;;;;	10.1109/VISUAL.2003.1250418;10.1109/VISUAL.2001.964519;10.1109/VISUAL.1997.663875;10.1109/VISUAL.2001.964516	Non-Destructive Testing, Multi-Dimensional Transfer Functions, Region Growing, Volume Rendering	
Vis	2008	Invariant Crease Lines for Topological and Structural Analysis of Tensor fields	10.1109/TVCG.2008.148	http://dx.doi.org/10.1109/TVCG.2008.148	1627	1634	J	We introduce a versatile framework for characterizing and extracting salient structures in three-dimensional symmetric second-order tensor fields. The key insight is that degenerate lines in tensor fields, as defined by the standard topological approach, are exactly crease (ridge and valley) lines of a particular tensor invariant called mode. This reformulation allows us to apply well-studied approaches from scientific visualization or computer vision to the extraction of topological lines in tensor fields. More generally, this main result suggests that other tensor invariants, such as anisotropy measures like fractional anisotropy (FA), can be used in the same framework in lieu of mode to identify important structural properties in tensor fields. Our implementation addresses the specific challenge posed by the non-linearity of the considered scalar measures and by the smoothness requirement of the crease manifold computation. We use a combination of smooth reconstruction kernels and adaptive refinement strategy that automatically adjust the resolution of the analysis to the spatial variation of the considered quantities. Together, these improvements allow for the robust application of existing ridge line extraction algorithms in the tensor context of our problem. Results are proposed for a diffusion tensor MRI dataset, and for a benchmark stress tensor field used in engineering research.	Xavier Tricoche;Gordon L. Kindlmann;Carl-Fredrik Westin	Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN|c|;;	10.1109/VISUAL.2004.105;10.1109/TVCG.2007.70602;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1991.175773;10.1109/VISUAL.1994.346326;10.1109/VISUAL.1994.346326;10.1109/VISUAL.1990.146359;10.1109/TVCG.2007.70554	Tensor fields, tensor invariants, ridge lines, crease extraction, structural analysis, topology	
Vis	2008	Novel interaction techniques for neurosurgical planning and stereotactic navigation	10.1109/TVCG.2008.150	http://dx.doi.org/10.1109/TVCG.2008.150	1587	1594	J	Neurosurgical planning and image guided neurosurgery require the visualization of multimodal data obtained from various functional and structural image modalities, such as magnetic resonance imaging (MRI), computed tomography (CT), functional MRI, Single photon emission computed tomography (SPECT) and so on. In the case of epilepsy neurosurgery for example, these images are used to identify brain regions to guide intracranial electrode implantation and resection. Generally, such data is visualized using 2D slices and in some cases using a 3D volume rendering along with the functional imaging results. Visualizing the activation region effectively by still preserving sufficient surrounding brain regions for context is exceedingly important to neurologists and surgeons. We present novel interaction techniques for visualization of multimodal data to facilitate improved exploration and planning for neurosurgery. We extended the line widget from VTK to allow surgeons to control the shape of the region of the brain that they can visually crop away during exploration and surgery. We allow simple spherical, cubical, ellipsoidal and cylindrical (probe aligned cuts) for exploration purposes. In addition we integrate the cropping tool with the image-guided navigation system used for epilepsy neurosurgery. We are currently investigating the use of these new tools in surgical planning and based on further feedback from our neurosurgeons we will integrate them into the setup used for image-guided neurosurgery.	Alark Joshi;Dustin Scheinost;Kenneth P. Vives;Dennis D. Spencer;Lawrence H. Staib;Xenophon Papademetris	Dept. of Diagnostic Radiol., Yale Sch. of Med., New Haven, CT|c|;;;;;	10.1109/VISUAL.2000.885694;10.1109/VISUAL.2002.1183762	User interaction, irregular cropping	
Vis	2008	Particle-based Sampling and Meshing of Surfaces in Multimaterial Volumes	10.1109/TVCG.2008.154	http://dx.doi.org/10.1109/TVCG.2008.154	1539	1546	J	Methods that faithfully and robustly capture the geometry of complex material interfaces in labeled volume data are important for generating realistic and accurate visualizations and simulations of real-world objects. The generation of such multimaterial models from measured data poses two unique challenges: first, the surfaces must be well-sampled with regular, efficient tessellations that are consistent across material boundaries; and second, the resulting meshes must respect the nonmanifold geometry of the multimaterial interfaces. This paper proposes a strategy for sampling and meshing multimaterial volumes using dynamic particle systems, including a novel, differentiable representation of the material junctions that allows the particle system to explicitly sample corners, edges, and surfaces of material intersections. The distributions of particles are controlled by fundamental sampling constraints, allowing Delaunay-based meshing algorithms to reliably extract watertight meshes of consistently high-quality.	Miriah D. Meyer;Ross T. Whitaker;Robert Michael Kirby;Christian Ledergerber;Hanspeter Pfister	Initiative in Innovative Comput., Harvard Univ., Cambridge, MA|c|;;;;	10.1109/VISUAL.2002.1183808;10.1109/TVCG.2007.70604;10.1109/VISUAL.1997.663930;10.1109/TVCG.2007.70572;10.1109/TVCG.2007.70543;10.1109/TVCG.2006.149;10.1109/VISUAL.1997.663887	Sampling, meshing, visualizations	
Vis	2008	Query-Driven Visualization of Time-Varying Adaptive Mesh Refinement Data	10.1109/TVCG.2008.157	http://dx.doi.org/10.1109/TVCG.2008.157	1715	1722	J	The visualization and analysis of AMR-based simulations is integral to the process of obtaining new insight in scientific research. We present a new method for performing query-driven visualization and analysis on AMR data, with specific emphasis on time-varying AMR data. Our work introduces a new method that directly addresses the dynamic spatial and temporal properties of AMR grids that challenge many existing visualization techniques. Further, we present the first implementation of query-driven visualization on the GPU that uses a GPU-based indexing structure to both answer queries and efficiently utilize GPU memory. We apply our method to two different science domains to demonstrate its broad applicability.	Luke J. Gosink;John C. Anderson;E. Wes Bethel;Kenneth I. Joy	Inst. for Data Anal. & Visualization, Univ. of California, Davis, CA|c|;;;	10.1109/VISUAL.2000.885704;10.1109/VISUAL.2005.1532792;10.1109/VAST.2006.261437;10.1109/VISUAL.2002.1183820;10.1109/VISUAL.2003.1250402;10.1109/TVCG.2007.70519;10.1109/VISUAL.1993.398869;10.1109/VISUAL.2005.1532793	AMR, Query-Driven Visualization, Multitemporal Visualization	
Vis	2008	Relation-Aware Volume Exploration Pipeline	10.1109/TVCG.2008.159	http://dx.doi.org/10.1109/TVCG.2008.159	1683	1690	J	Volume exploration is an important issue in scientific visualization. Research on volume exploration has been focused on revealing hidden structures in volumetric data. While the information of individual structures or features is useful in practice, spatial relations between structures are also important in many applications and can provide further insights into the data. In this paper, we systematically study the extraction, representation,exploration, and visualization of spatial relations in volumetric data and propose a novel relation-aware visualization pipeline for volume exploration. In our pipeline, various relations in the volume are first defined and measured using region connection calculus (RCC) and then represented using a graph interface called relation graph. With RCC and the relation graph, relation query and interactive exploration can be conducted in a comprehensive and intuitive way. The visualization process is further assisted with relation-revealing viewpoint selection and color and opacity enhancement. We also introduce a quality assessment scheme which evaluates the perception of spatial relations in the rendered images. Experiments on various datasets demonstrate the practical use of our system in exploratory visualization.	Ming-Yuen Chan;Huamin Qu;Ka-Kei Chung;Wai-Ho Mak;Yingcai Wu	Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong|c|;;;;	10.1109/TVCG.2007.70584;10.1109/TVCG.2007.70515;10.1109/TVCG.2006.144;10.1109/VISUAL.1999.809871;10.1109/TVCG.2007.70535;10.1109/TVCG.2007.70576;10.1109/VISUAL.2000.885694;10.1109/INFVIS.2003.1249009;10.1109/TVCG.2007.70555;10.1109/VISUAL.2005.1532835;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2007.70591;10.1109/VISUAL.2005.1532834;10.1109/VISUAL.2005.1532856;10.1109/TVCG.2007.70572;10.1109/VISUAL.2005.1532833	Exploratory Visualization, Relation-Based Visualization, Visualization Pipeline	
Vis	2008	Revisiting Histograms and Isosurface Statistics	10.1109/TVCG.2008.160	http://dx.doi.org/10.1109/TVCG.2008.160	1659	1666	J	Recent results have shown a link between geometric properties of isosurfaces and statistical properties of the underlying sampled data. However, this has two defects: not all of the properties described converge to the same solution, and the statistics computed are not always invariant under isosurface-preserving transformations. We apply Federer's Coarea Formula from geometric measure theory to explain these discrepancies. We describe an improved substitute for histograms based on weighting with the inverse gradient magnitude, develop a statistical model that is invariant under isosurface-preserving transformations, and argue that this provides a consistent method for algorithm evaluation across multiple datasets based on histogram equalization. We use our corrected formulation to reevaluate recent results on average isosurface complexity, and show evidence that noise is one cause of the discrepancy between the expected figure and the observed one.	Carlos Eduardo Scheidegger;John M. Schreiner;Brian Duffy;Hamish Carr;Cláudio T. Silva	Inst. of Sci. Comput. & Imaging, Utah Univ., Salt Lake City, UT|c|;;;;	10.1109/TVCG.2006.168;10.1109/TVCG.2008.119;10.1109/VISUAL.2001.964519;10.1109/VISUAL.2001.964515;10.1109/VISUAL.1997.663875;10.1109/VISUAL.2001.964516	Isosurfaces, Histograms, Coarea Formula	
Vis	2008	Sinus Endoscopy - Application of Advanced GPU Volume Rendering for Virtual Endoscopy	10.1109/TVCG.2008.161	http://dx.doi.org/10.1109/TVCG.2008.161	1491	1498	J	For difficult cases in endoscopic sinus surgery, a careful planning of the intervention is necessary. Due to the reduced field of view during the intervention, the surgeons have less information about the surrounding structures in the working area compared to open surgery. Virtual endoscopy enables the visualization of the operating field and additional information, such as risk structures (e.g., optical nerve and skull base) and target structures to be removed (e.g., mucosal swelling). The Sinus Endoscopy system provides the functional range of a virtual endoscopic system with special focus on a realistic representation. Furthermore, by using direct volume rendering, we avoid time-consuming segmentation steps for the use of individual patient datasets. However, the image quality of the endoscopic view can be adjusted in a way that a standard computer with a modern standard graphics card achieves interactive frame rates with low CPU utilization. Thereby, characteristics of the endoscopic view are systematically used for the optimization of the volume rendering speed. The system design was based on a careful analysis of the endoscopic sinus surgery and the resulting needs for computer support. As a small standalone application it can be instantly used for surgical planning and patient education. First results of a clinical evaluation with ENT surgeons were employed to fine-tune the user interface, in particular to reduce the number of controls by using appropriate default values wherever possible. The system was used for preoperative planning in 102 cases, provides useful information for intervention planning (e.g., anatomic variations of the Rec. Frontalis), and closely resembles the intraoperative situation.	Arno Krüger;Christoph Kubisch;Gero Strauß;Bernhard Preim	Dept. of Simulation & Graphics, Otto-von-Guericke-Univ. of Magdeburg, Magdeburg|c|;;;	10.1109/VISUAL.2003.1250370;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2004.98	medical visualization, sinus surgery, operation planning, virtual endoscopy, volume rendering	
Vis	2008	Size-based Transfer Functions: A New Volume Exploration Technique	10.1109/TVCG.2008.162	http://dx.doi.org/10.1109/TVCG.2008.162	1380	1387	J	The visualization of complex 3D images remains a challenge, a fact that is magnified by the difficulty to classify or segment volume data. In this paper, we introduce size-based transfer functions, which map the local scale of features to color and opacity. Features in a data set with similar or identical scalar values can be classified based on their relative size. We achieve this with the use of scale fields, which are 3D fields that represent the relative size of the local feature at each voxel. We present a mechanism for obtaining these scale fields at interactive rates, through a continuous scale-space analysis and a set of detection filters. Through a number of examples, we show that size-based transfer functions can improve classification and enhance volume rendering techniques, such as maximum intensity projection. The ability to classify objects based on local size at interactive rates proves to be a powerful method for complex data exploration.	Carlos D. Correa;Kwan-Liu Ma	Univ. of California, Davis, CA|c|;	10.1109/VISUAL.2003.1250414;10.1109/VISUAL.1999.809932;10.1109/VISUAL.2000.885694;10.1109/VISUAL.2001.964519;10.1109/VISUAL.2004.64;10.1109/VISUAL.2003.1250413;10.1109/VISUAL.1995.480812;10.1109/VISUAL.2003.1250369;10.1109/VISUAL.2005.1532817	Transfer Functions, Interactive Visualization, Volume Rendering, Scale Space, GPU Techniques	
Vis	2008	Smoke Surfaces: An Interactive Flow Visualization Technique Inspired by Real-World Flow Experiments	10.1109/TVCG.2008.163	http://dx.doi.org/10.1109/TVCG.2008.163	1396	1403	J	Smoke rendering is a standard technique for flow visualization. Most approaches are based on a volumetric, particle based, or image based representation of the smoke. This paper introduces an alternative representation of smoke structures: as semi-transparent streak surfaces. In order to make streak surface integration fast enough for interactive applications, we avoid expensive adaptive retriangulations by coupling the opacity of the triangles to their shapes. This way, the surface shows a smoke-like look even in rather turbulent areas. Furthermore, we show modifications of the approach to mimic smoke nozzles, wool tufts, and time surfaces. The technique is applied to a number of test data sets.	Wolfram von Funck;Tino Weinkauf;Holger Theisel;Hans-Peter Seidel	MPI Informatlk, Saarbrucken|c|;;;	10.1109/VISUAL.1995.485141;10.1109/VISUAL.1993.398846;10.1109/VISUAL.1992.235211;10.1109/VISUAL.2001.964506;10.1109/VISUAL.1993.398877	Unsteady flow visualization, streak surfaces, smoke visualization	
Vis	2008	Smooth Surface Extraction from Unstructured Point-based Volume Data Using PDEs	10.1109/TVCG.2008.164	http://dx.doi.org/10.1109/TVCG.2008.164	1531	1546	J	Smooth surface extraction using partial differential equations (PDEs) is a well-known and widely used technique for visualizing volume data. Existing approaches operate on gridded data and mainly on regular structured grids. When considering unstructured point-based volume data where sample points do not form regular patterns nor are they connected in any form, one would typically resample the data over a grid prior to applying the known PDE-based methods. We propose an approach that directly extracts smooth surfaces from unstructured point-based volume data without prior resampling or mesh generation. When operating on unstructured data one needs to quickly derive neighborhood information. The respective information is retrieved by partitioning the 3D domain into cells using a fed-tree and operating on its cells. We exploit neighborhood information to estimate gradients and mean curvature at every sample point using a four-dimensional least-squares fitting approach. Gradients and mean curvature are required for applying the chosen PDE-based method that combines hyperbolic advection to an isovalue of a given scalar field and mean curvature flow. Since we are using an explicit time-integration scheme, time steps and neighbor locations are bounded to ensure convergence of the process. To avoid small global time steps, one can use asynchronous local integration. We extract a smooth surface by successively fitting a smooth auxiliary function to the data set. This auxiliary function is initialized as a signed distance function. For each sample and for every time step we compute the respective gradient, the mean curvature, and a stable time step. With these informations the auxiliary function is manipulated using an explicit Euler time integration. The process successively continues with the next sample point in time. If the norm of the auxiliary function gradient in a sample exceeds a given threshold at some time, the auxiliary function is reinitialized to a signed dista- - nce function. After convergence of the evolvution, the resulting smooth surface is obtained by extracting the zero isosurface from the auxiliary function using direct isosurface extraction from unstructured point-based volume data and rendering the extracted surface using point-based rendering methods.	Paul Rosenthal;Lars Linsen	Jacobs Univ. Bremen, Bremen|c|;	10.1109/VISUAL.2002.1183773;10.1109/VISUAL.2003.1250357	PDEs, surface extraction, level sets, point-based visualization	
Vis	2008	Surface Extraction from Multi-field Particle Volume Data Using Multi-dimensional Cluster Visualization	10.1109/TVCG.2008.167	http://dx.doi.org/10.1109/TVCG.2008.167	1483	1490	J	Data sets resulting from physical simulations typically contain a multitude of physical variables. It is, therefore, desirable that visualization methods take into account the entire multi-field volume data rather than concentrating on one variable. We present a visualization approach based on surface extraction from multi-field particle volume data. The surfaces segment the data with respect to the underlying multi-variate function. Decisions on segmentation properties are based on the analysis of the multi-dimensional feature space. The feature space exploration is performed by an automated multi-dimensional hierarchical clustering method, whose resulting density clusters are shown in the form of density level sets in a 3D star coordinate layout. In the star coordinate layout, the user can select clusters of interest. A selected cluster in feature space corresponds to a segmenting surface in object space. Based on the segmentation property induced by the cluster membership, we extract a surface from the volume data. Our driving applications are smoothed particle hydrodynamics (SPH) simulations, where each particle carries multiple properties. The data sets are given in the form of unstructured point-based volume data. We directly extract our surfaces from such data without prior resampling or grid generation. The surface extraction computes individual points on the surface, which is supported by an efficient neighborhood computation. The extracted surface points are rendered using point-based rendering operations. Our approach combines methods in scientific visualization for object-space operations with methods in information visualization for feature-space operations.	Lars Linsen;Tran Van Long;Paul Rosenthal;Stephan Rosswog	Sch. of Eng. & Sci., Jacobs Univ., Bremen|c|;;;	10.1109/TVCG.2007.70615;10.1109/TVCG.2006.164;10.1109/TVCG.2007.70569;10.1109/TVCG.2006.165;10.1109/TVCG.2007.70526	Multi-field and multi-variate visualization, isosurfaces and surface extraction, point-based visualization, star coordinates, visualization in astrophysics, particle simulations	
Vis	2008	Text Scaffolds for Effective Surface Labeling	10.1109/TVCG.2008.168	http://dx.doi.org/10.1109/TVCG.2008.168	1675	1682	J	In this paper we introduce a technique for applying textual labels to 3D surfaces. An effective labeling must balance the conflicting goals of conveying the shape of the surface while being legible from a range of viewing directions. Shape can be conveyed by placing the text as a texture directly on the surface, providing shape cues, meaningful landmarks and minimally obstructing the rest of the model. But rendering such surface text is problematic both in regions of high curvature, where text would be warped, and in highly occluded regions, where it would be hidden. Our approach achieves both labeling goals by applying surface labels to a psilatext scaffoldpsila, a surface explicitly constructed to hold the labels. Text scaffolds conform to the underlying surface whenever possible, but can also float above problem regions, allowing them to be smooth while still conveying the overall shape. This paper provides methods for constructing scaffolds from a variety of input sources, including meshes, constructive solid geometry, and scalar fields. These sources are first mapped into a distance transform, which is then filtered and used to construct a new mesh on which labels are either manually or automatically placed. In the latter case, annotated regions of the input surface are associated with proximal regions on the new mesh, and labels placed using cartographic principles.	Gregory Cipriano;Michael Gleicher	Dept. of Comput. Sci., Wisconsin Univ., Madison, WI|c|;	10.1109/VISUAL.2000.885705	surface labeling, computational cartography, text authoring, annotation	
Vis	2008	Texture-based Transfer Functions for Direct Volume Rendering	10.1109/TVCG.2008.169	http://dx.doi.org/10.1109/TVCG.2008.169	1364	1371	J	Visualization of volumetric data faces the difficult task of finding effective parameters for the transfer functions. Those parameters can determine the effectiveness and accuracy of the visualization. Frequently, volumetric data includes multiple structures and features that need to be differentiated. However, if those features have the same intensity and gradient values, existing transfer functions are limited at effectively illustrating those similar features with different rendering properties. We introduce texture-based transfer functions for direct volume rendering. In our approach, the voxelpsilas resulting opacity and color are based on local textural properties rather than individual intensity values. For example, if the intensity values of the vessels are similar to those on the boundary of the lungs, our texture-based transfer function will analyze the textural properties in those regions and color them differently even though they have the same intensity values in the volume. The use of texture-based transfer functions has several benefits. First, structures and features with the same intensity and gradient values can be automatically visualized with different rendering properties. Second, segmentation or prior knowledge of the specific features within the volume is not required for classifying these features differently. Third, textural metrics can be combined and/or maximized to capture and better differentiate similar structures. We demonstrate our texture-based transfer function for direct volume rendering with synthetic and real-world medical data to show the strength of our technique.	Jesus J. Caban;Penny Rheingans	Dept. of Comput. Sci., Maryland Univ., College Park, MD|c|;	10.1109/VISUAL.2001.964519;10.1109/VISUAL.2003.1250413;10.1109/VISUAL.2003.1250414	visualization, statistical analysis, volume rendering, data variability, medical imaging	
Vis	2008	The Seismic Analyzer: Interpreting and Illustrating 2D Seismic Data	10.1109/TVCG.2008.170	http://dx.doi.org/10.1109/TVCG.2008.170	1571	1578	J	We present a toolbox for quickly interpreting and illustrating 2D slices of seismic volumetric reflection data. Searching for oil and gas involves creating a structural overview of seismic reflection data to identify hydrocarbon reservoirs. We improve the search of seismic structures by precalculating the horizon structures of the seismic data prior to interpretation. We improve the annotation of seismic structures by applying novel illustrative rendering algorithms tailored to seismic data, such as deformed texturing and line and texture transfer functions. The illustrative rendering results in multi-attribute and scale invariant visualizations where features are represented clearly in both highly zoomed in and zoomed out views. Thumbnail views in combination with interactive appearance control allows for a quick overview of the data before detailed interpretation takes place. These techniques help reduce the work of seismic illustrators and interpreters.	Daniel Patel;Christopher Giertsen;John Thurmond;John Gjelberg;Eduard Gröller	Christian Michelsen Res., Bergen|c|;;;;	10.1109/VISUAL.1999.809905;10.1109/VISUAL.2005.1532802;10.1109/VISUAL.1991.175811	Seismic interpretation, Illustrative rendering, Seismic attributes, Top-down interpretation	
Vis	2008	Vectorized Radviz and Its Application to Multiple Cluster Datasets	10.1109/TVCG.2008.173	http://dx.doi.org/10.1109/TVCG.2008.173	1444	1427	J	Radviz is a radial visualization with dimensions assigned to points called dimensional anchors (DAs) placed on the circumference of a circle. Records are assigned locations within the circle as a function of its relative attraction to each of the DAs. The DAs can be moved either interactively or algorithmically to reveal different meaningful patterns in the dataset. In this paper we describe Vectorized Radviz (VRV) which extends the number of dimensions through data flattening. We show how VRV increases the power of Radviz through these extra dimensions by enhancing the flexibility in the layout of the DAs. We apply VRV to the problem of analyzing the results of multiple clusterings of the same data set, called multiple cluster sets or cluster ensembles. We show how features of VRV help discern patterns across the multiple cluster sets. We use the Iris data set to explain VRV and a newt gene microarray data set used in studying limb regeneration to show its utility. We then discuss further applications of VRV.	John Sharko;Georges G. Grinstein;Kenneth A. Marx	Dept. of Comput. Sci., Univ. of Massachusetts - Lowell, Lowell, MA|c|;;	10.1109/INFVIS.2004.15;10.1109/VISUAL.1997.663916;10.1109/INFVIS.1998.729559	Visualization, Radviz, Vectorized Radviz, Clustering, Multiple Clustering, Cluster Ensembles, Flattening Datasets	
Vis	2008	VisComplete: Automating Suggestions for Visualization Pipelines	10.1109/TVCG.2008.174	http://dx.doi.org/10.1109/TVCG.2008.174	1691	1698	J	Building visualization and analysis pipelines is a large hurdle in the adoption of visualization and workflow systems by domain scientists. In this paper, we propose techniques to help users construct pipelines by consensus-automatically suggesting completions based on a database of previously created pipelines. In particular, we compute correspondences between existing pipeline subgraphs from the database, and use these to predict sets of likely pipeline additions to a given partial pipeline. By presenting these predictions in a carefully designed interface, users can create visualizations and other data products more efficiently because they can augment their normal work patterns with the suggested completions. We present an implementation of our technique in a publicly-available, open-source scientific workflow system and demonstrate efficiency gains in real-world situations.	David Koop;Carlos Eduardo Scheidegger;Steven P. Callahan;Juliana Freire;Cláudio T. Silva	Sch. of Comput., Univ. of Utah, Salt Lake City, UT|c|;;;;	10.1109/TVCG.2007.70584;10.1109/TVCG.2007.70577;10.1109/VISUAL.2005.1532834;10.1109/VISUAL.2005.1532833;10.1109/VISUAL.2005.1532788;10.1109/VISUAL.2005.1532795	Scientific Workflows, Scientific Visualization, Auto Completion	
Vis	2008	Visibility-driven Mesh Analysis and Visualization through Graph Cuts	10.1109/TVCG.2008.176	http://dx.doi.org/10.1109/TVCG.2008.176	1667	1674	J	In this paper we present an algorithm that operates on a triangular mesh and classifies each face of a triangle as either inside or outside. We present three example applications of this core algorithm: normal orientation, inside removal, and layer-based visualization. The distinguishing feature of our algorithm is its robustness even if a difficult input model that includes holes, coplanar triangles, intersecting triangles, and lost connectivity is given. Our algorithm works with the original triangles of the input model and uses sampling to construct a visibility graph that is then segmented using graph cut.	Kaichi Zhou;Eugene Zhang;Jirí Bittner;Peter Wonka	Arizona State Univ., Tempe, AZ|c|;;;	10.1109/VISUAL.2002.1183784	Interior/Exterior Classification, Normal Orientation, Layer Classification, Inside Removal, Graph Cut	
Vis	2008	Visiting the Gödel Universe	10.1109/TVCG.2008.177	http://dx.doi.org/10.1109/TVCG.2008.177	1563	1570	J	Visualization of general relativity illustrates aspects of Einstein's insights into the curved nature of space and time to the expert as well as the layperson. One of the most interesting models which came up with Einstein's theory was developed by Kurt Godel in 1949. The Godel universe is a valid solution of Einstein's field equations, making it a possible physical description of our universe. It offers remarkable features like the existence of an optical horizon beyond which time travel is possible. Although we know that our universe is not a Godel universe, it is interesting to visualize physical aspects of a world model resulting from a theory which is highly confirmed in scientific history. Standard techniques to adopt an egocentric point of view in a relativistic world model have shortcomings with respect to the time needed to render an image as well as difficulties in applying a direct illumination model. In this paper we want to face both issues to reduce the gap between common visualization standards and relativistic visualization. We will introduce two techniques to speed up recalculation of images by means of preprocessing and lookup tables and to increase image quality through a special optimization applicable to the Godel universe. The first technique allows the physicist to understand the different effects of general relativity faster and better by generating images from existing datasets interactively. By using the intrinsic symmetries of Godel's spacetime which are expressed by the Killing vector field, we are able to reduce the necessary calculations to simple cases using the second technique. This even makes it feasible to account for a direct illumination model during the rendering process. Although the presented methods are applied to Godel's universe, they can also be extended to other manifolds, for example light propagation in moving dielectric media. Therefore, other areas of research can benefit from these generic improvements.	Frank Grave;Michael Buser	Inst. for Theor. Phys. & VISUS, Univ. of Stuttgart, Stuttgart|c|;	10.1109/TVCG.2006.176;10.1109/VISUAL.2005.1532803;10.1109/TVCG.2007.70530	General relativity, Godel universe, nonlinear ray tracing, time travel	
Vis	2008	Visualization of Cellular and Microvascular Relationships	10.1109/TVCG.2008.179	http://dx.doi.org/10.1109/TVCG.2008.179	1611	1618	J	Understanding the structure of microvasculature structures and their relationship to cells in biological tissue is an important and complex problem. Brain microvasculature in particular is known to play an important role in chronic diseases. However, these networks are only visible at the microscopic level and can span large volumes of tissue. Due to recent advances in microscopy, large volumes of data can be imaged at the resolution necessary to reconstruct these structures. Due to the dense and complex nature of microscopy data sets, it is important to limit the amount of information displayed. In this paper, we describe methods for encoding the unique structure of microvascular data, allowing researchers to selectively explore microvascular anatomy. We also identify the queries most useful to researchers studying microvascular and cellular relationships. By associating cellular structures with our microvascular framework, we allow researchers to explore interesting anatomical relationships in dense and complex data sets.	David Mayerich;Louise C. Abbott;John Keyser	Dept. of Comput. Sci., Texas A&M Univ., College Station, TX|c|;;	10.1109/VISUAL.2005.1532859;10.1109/VISUAL.1997.663917;10.1109/TVCG.2006.197;10.1109/TVCG.2007.70532	microscopy, biomedical, medical, blood vessels, cells	
Vis	2008	Visualization of Myocardial Perfusion Derived from Coronary Anatomy	10.1109/TVCG.2008.180	http://dx.doi.org/10.1109/TVCG.2008.180	1595	1602	J	Visually assessing the effect of the coronary artery anatomy on the perfusion of the heart muscle in patients with coronary artery disease remains a challenging task. We explore the feasibility of visualizing this effect on perfusion using a numerical approach. We perform a computational simulation of the way blood is perfused throughout the myocardium purely based on information from a three-dimensional anatomical tomographic scan. The results are subsequently visualized using both three-dimensional visualizations and bullpsilas eye plots, partially inspired by approaches currently common in medical practice. Our approach results in a comprehensive visualization of the coronary anatomy that compares well to visualizations commonly used for other scanning technologies. We demonstrate techniques giving detailed insight in blood supply, coronary territories and feeding coronary arteries of a selected region. We demonstrate the advantages of our approach through visualizations that show information which commonly cannot be directly observed in scanning data, such as a separate visualization of the supply from each coronary artery. We thus show that the results of a computational simulation can be effectively visualized and facilitate visually correlating these results to for example perfusion data.	Maurice Termeer;Javier Oliván Bescós;Marcel Breeuwer;Anna Vilanova;Frans A. Gerritsen;Eduard Gröller;Eike Nagel	Vienna Univ. of Technol., Vienna|c|;;;;;;	10.1109/TVCG.2007.70550;10.1109/VISUAL.2002.1183754	Cardiac visualization, coronary artery territories, myocardial perfusion	
Vis	2008	Visualizing Multiwavelength Astrophysical Data	10.1109/TVCG.2008.182	http://dx.doi.org/10.1109/TVCG.2008.182	1555	1562	J	With recent advances in the measurement technology for allsky astrophysical imaging, our view of the sky is no longer limited to the tiny visible spectral range over the 2D Celestial sphere. We now can access a third dimension corresponding to a broad electromagnetic spectrum with a wide range of allsky surveys; these surveys span frequency bands including long long wavelength radio, microwaves, very short X-rays, and gamma rays. These advances motivate us to study and examine multiwavelength visualization techniques to maximize our capabilities to visualize and exploit these informative image data sets. In this work, we begin with the processing of the data themselves, uniformizing the representations and units of raw data obtained from varied detector sources. Then we apply tools to map, convert, color-code, and format the multiwavelength data in forms useful for applications. We explore different visual representations for displaying the data, including such methods as textured image stacks, the horseshoe representation, and GPU-based volume visualization. A family of visual tools and analysis methods are introduced to explore the data, including interactive data mapping on the graphics processing unit (GPU), the mini-map explorer, and GPU-based interactive feature analysis.	Hongwei Li;Chi-Wing Fu;Andrew J. Hanson	Hong Kong Univ. of Sci. & Technol., Hong Kong|c|;;	10.1109/VISUAL.2003.1250404;10.1109/TVCG.2006.155;10.1109/VISUAL.1995.485155;10.1109/TVCG.2006.176;10.1109/VISUAL.1992.235222;10.1109/VISUAL.2002.1183824;10.1109/TVCG.2007.70530;10.1109/VISUAL.2003.1250401;10.1109/VISUAL.2005.1532803;10.1109/VISUAL.2004.18;10.1109/TVCG.2007.70526	Astrophysical visualization, multiwavelength data, astronomy	
Vis	2008	Visualizing Particle/Flow Structure Interactions in the Small Bronchial Tubes	10.1109/TVCG.2008.183	http://dx.doi.org/10.1109/TVCG.2008.183	1412	1427	J	Particle deposition in the small bronchial tubes (generations six through twelve) is strongly influenced by the vortex-dominated secondary flows that are induced by axial curvature of the tubes. In this paper, we employ particle destination maps in conjunction with two-dimensional, finite-time Lyapunov exponent maps to illustrate how the trajectories of finite-mass particles are influenced by the presence of vortices. We consider two three-generation bronchial tube models: a planar, asymmetric geometry and a non-planar, asymmetric geometry. Our visualizations demonstrate that these techniques, coupled with judiciously seeded particle trajectories, are effective tools for studying particle/flow structure interactions.	Bela Soni;David S. Thompson;Raghu Machiraju	Mississippi State Univ., Oxford, MS|c|;;	10.1109/TVCG.2007.70551;10.1109/TVCG.2007.70554	FTLE, particle trajectory, visualization, bronchial tube	
Vis	2008	Visualizing Temporal Patterns in Large Multivariate Data using Textual Pattern Matching	10.1109/TVCG.2008.184	http://dx.doi.org/10.1109/TVCG.2008.184	1467	1474	J	Extracting and visualizing temporal patterns in large scientific data is an open problem in visualization research. First, there are few proven methods to flexibly and concisely define general temporal patterns for visualization. Second, with large time-dependent data sets, as typical with todaypsilas large-scale simulations, scalable and general solutions for handling the data are still not widely available. In this work, we have developed a textual pattern matching approach for specifying and identifying general temporal patterns. Besides defining the formalism of the language, we also provide a working implementation with sufficient efficiency and scalability to handle large data sets. Using recent large-scale simulation data from multiple application domains, we demonstrate that our visualization approach is one of the first to empower a concept driven exploration of large-scale time-varying multivariate data.	Markus Glatter;Jian Huang;Sean Ahern;Jamison Daniel;Aidong Lu	Univ. of Tennessee at Knoxville, Knoxville, TN|c|;;;;	10.1109/VISUAL.2003.1250402;10.1109/TVCG.2007.70600;10.1109/TVCG.2006.175;10.1109/VISUAL.2004.95;10.1109/TVCG.2007.70519;10.1109/VISUAL.2001.964519;10.1109/VISUAL.2005.1532792	Multivariate visualization, Time-varying, Uncertainty	
Vis	2008	Volume MLS Ray Casting	10.1109/TVCG.2008.186	http://dx.doi.org/10.1109/TVCG.2008.186	1372	1379	J	The method of Moving Least Squares (MLS) is a popular framework for reconstructing continuous functions from scattered data due to its rich mathematical properties and well-understood theoretical foundations. This paper applies MLS to volume rendering, providing a unified mathematical framework for ray casting of scalar data stored over regular as well as irregular grids. We use the MLS reconstruction to render smooth isosurfaces and to compute accurate derivatives for high-quality shading effects. We also present a novel, adaptive preintegration scheme to improve the efficiency of the ray casting algorithm by reducing the overall number of function evaluations, and an efficient implementation of our framework exploiting modern graphics hardware. The resulting system enables high-quality volume integration and shaded isosurface rendering for regular and irregular volume data.	Christian Ledergerber;Gaël Guennebaud;Miriah D. Meyer;Moritz Bächer;Hanspeter Pfister	Harvard Univ., Cambridge, MA|c|;;;;	10.1109/VISUAL.1993.398853;10.1109/VISUAL.2000.885683;10.1109/TVCG.2006.141;10.1109/VISUAL.2001.964490;10.1109/VISUAL.2003.1250414;10.1109/VISUAL.1994.346331;10.1109/VISUAL.2003.1250390	Volume Visualization, Unstructured Grids, Moving Least Squares Reconstruction, Adaptive Integration	
InfoVis	2009	"Search, Show Context, Expand on Demand": Supporting Large Graph Exploration with Degree-of-Interest	10.1109/TVCG.2009.108	http://dx.doi.org/10.1109/TVCG.2009.108	953	960	J	A common goal in graph visualization research is the design of novel techniques for displaying an overview of an entire graph. However, there are many situations where such an overview is not relevant or practical for users, as analyzing the global structure may not be related to the main task of the users that have semi-specific information needs. Furthermore, users accessing large graph databases through an online connection or users running on less powerful (mobile) hardware simply do not have the resources needed to compute these overviews. In this paper, we advocate an interaction model that allows users to remotely browse the immediate context graph around a specific node of interest. We show how Furnas' original degree of interest function can be adapted from trees to graphs and how we can use this metric to extract useful contextual subgraphs, control the complexity of the generated visualization and direct users to interesting datapoints in the context. We demonstrate the effectiveness of our approach with an exploration of a dense online database containing over 3 million legal citations.	Frank van Ham;Adam Perer	IBM-ILOG Res., Gentilly, France|c|;	10.1109/TVCG.2006.122;10.1109/INFVIS.2004.66;10.1109/INFVIS.2004.43;10.1109/TVCG.2006.166;10.1109/TVCG.2006.147	Graph visualization, network visualization, degree of interest, legal citation networks, focus+context	
InfoVis	2009	A Comparison of User-Generated and Automatic Graph Layouts	10.1109/TVCG.2009.109	http://dx.doi.org/10.1109/TVCG.2009.109	961	968	J	The research presented in this paper compares user-generated and automatic graph layouts. Following the methods suggested by van Ham et al. (2008), a group of users generated graph layouts using both multi-touch interaction on a tabletop display and mouse interaction on a desktop computer. Users were asked to optimize their layout for aesthetics and analytical tasks with a social network. We discuss characteristics of the user-generated layouts and interaction methods employed by users in this process. We then report on a web-based study to compare these layouts with the output of popular automatic layout algorithms. Our results demonstrate that the best of the user-generated layouts performed as well as or better than the physics-based layout. Orthogonal and circular automatic layouts were found to be considerably less effective than either the physics-based layout or the best of the user-generated layouts. We highlight several attributes of the various layouts that led to high accuracy and improved task completion time, as well as aspects in which traditional automatic layout methods were unsuccessful for our tasks.	Tim Dwyer;Bongshin Lee;Danyel Fisher;Kori Inkpen Quinn;Petra Isenberg;George G. Robertson;Chris North	;;;;;;	10.1109/TVCG.2008.155	Graph layout, network layout, automatic layout algorithms, user-generated layout, graph-drawing aesthetics	
InfoVis	2009	A Multi-Threading Architecture to Support Interactive Visual Exploration	10.1109/TVCG.2009.110	http://dx.doi.org/10.1109/TVCG.2009.110	1113	1120	J	During continuous user interaction, it is hard to provide rich visual feedback at interactive rates for datasets containing millions of entries. The contribution of this paper is a generic architecture that ensures responsiveness of the application even when dealing with large data and that is applicable to most types of information visualizations. Our architecture builds on the separation of the main application thread and the visualization thread, which can be cancelled early due to user interaction. In combination with a layer mechanism, our architecture facilitates generating previews incrementally to provide rich visual feedback quickly. To help avoiding common pitfalls of multi-threading, we discuss synchronization and communication in detail. We explicitly denote design choices to control trade-offs. A quantitative evaluation based on the system VI S P L ORE shows fast visual feedback during continuous interaction even for millions of entries. We describe instantiations of our architecture in additional tools.	Harald Piringer;Christian Tominski;Philipp Muigg;Wolfgang Berger	VRVis Res. Center, Vienna, Austria|c|;;;	10.1109/VISUAL.1999.809891;10.1109/TVCG.2006.138;10.1109/INFVIS.1997.636790;10.1109/TVCG.2006.171;10.1109/INFVIS.2004.12;10.1109/INFVIS.2002.1173156;10.1109/TVCG.2007.70540;10.1109/TVCG.2006.178;10.1109/TVCG.2006.170;10.1109/INFVIS.2004.64;10.1109/INFVIS.2000.885092;10.1109/VAST.2008.4677357	Information visualization architecture, continuous interaction, multi-threading, layer, preview	
InfoVis	2009	A Nested Model for Visualization Design and Validation	10.1109/TVCG.2009.111	http://dx.doi.org/10.1109/TVCG.2009.111	921	928	J	We present a nested model for the visualization design and validation with four layers: characterize the task and data in the vocabulary of the problem domain, abstract into operations and data types, design visual encoding and interaction techniques, and create algorithms to execute techniques efficiently. The output from a level above is input to the level below, bringing attention to the design challenge that an upstream error inevitably cascades to all downstream levels. This model provides prescriptive guidance for determining appropriate evaluation approaches by identifying threats to validity unique to each level. We also provide three recommendations motivated by this model: authors should distinguish between these levels when claiming contributions at more than one of them, authors should explicitly state upstream assumptions at levels above the focus of a paper, and visualization venues should accept more papers on domain characterization.	Tamara Munzner	Univ. of British Columbia, Vancouver, BC, Canada|c|	10.1109/VAST.2007.4389008;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2008.117;10.1109/TVCG.2006.160;10.1109/VISUAL.1998.745289;10.1109/TVCG.2007.70515;10.1109/TVCG.2008.109;10.1109/VISUAL.1992.235203;10.1109/INFVIS.2004.59;10.1109/INFVIS.2005.1532124;10.1109/INFVIS.1998.729560;10.1109/INFVIS.2004.10;10.1109/TVCG.2008.125;10.1109/INFVIS.1997.636792;10.1109/INFVIS.2005.1532150;10.1109/VISUAL.1990.146375	Models, frameworks, design, evaluation	
InfoVis	2009	ABySS-Explorer: Visualizing Genome Sequence Assemblies	10.1109/TVCG.2009.116	http://dx.doi.org/10.1109/TVCG.2009.116	881	888	J	One bottleneck in large-scale genome sequencing projects is reconstructing the full genome sequence from the short subsequences produced by current technologies. The final stages of the genome assembly process inevitably require manual inspection of data inconsistencies and could be greatly aided by visualization. This paper presents our design decisions in translating key data features identified through discussions with analysts into a concise visual encoding. Current visualization tools in this domain focus on local sequence errors making high-level inspection of the assembly difficult if not impossible. We present a novel interactive graph display, ABySS-Explorer, that emphasizes the global assembly structure while also integrating salient data features such as sequence length. Our tool replaces manual and in some cases pen-and-paper based analysis tasks, and we discuss how user feedback was incorporated into iterative design refinements. Finally, we touch on applications of this representation not initially considered in our design phase, suggesting the generality of this encoding for DNA sequence data.	Cydney B. Nielsen;Shaun D. Jackman;Inanç Birol;Steven J. M. Jones	Genome Sci. Centre, BC Cancer Agency, Vancouver, BC, Canada|c|;;;	10.1109/TVCG.2006.147	Bioinformatics visualization, design study, DNA sequence, genome assembly	
InfoVis	2009	ActiviTree: Interactive Visual Exploration of Sequences in Event-Based Data Using Graph Similarity	10.1109/TVCG.2009.117	http://dx.doi.org/10.1109/TVCG.2009.117	945	952	J	The identification of significant sequences in large and complex event-based temporal data is a challenging problem with applications in many areas of today's information intensive society. Pure visual representations can be used for the analysis, but are constrained to small data sets. Algorithmic search mechanisms used for larger data sets become expensive as the data size increases and typically focus on frequency of occurrence to reduce the computational complexity, often overlooking important infrequent sequences and outliers. In this paper we introduce an interactive visual data mining approach based on an adaptation of techniques developed for Web searching, combined with an intuitive visual interface, to facilitate user-centred exploration of the data and identification of sequences significant to that user. The search algorithm used in the exploration executes in negligible time, even for large data, and so no pre-processing of the selected data is required, making this a completely interactive experience for the user. Our particular application area is social science diary data but the technique is applicable across many other disciplines.	Katerina Vrotsou;Jimmy Johansson;Matthew D. Cooper	Linkoping Univ., Linkoping, Sweden|c|;;	10.1109/TVCG.2006.192;10.1109/VAST.2006.261421	Interactive visual exploration, event-based data, sequence identification, graph similarity, node similarity	
InfoVis	2009	Bubble Sets: Revealing Set Relations with Isocontours over Existing Visualizations	10.1109/TVCG.2009.122	http://dx.doi.org/10.1109/TVCG.2009.122	1009	1016	J	While many data sets contain multiple relationships, depicting more than one data relationship within a single visualization is challenging. We introduce Bubble Sets as a visualization technique for data that has both a primary data relation with a semantically significant spatial organization and a significant set membership relation in which members of the same set are not necessarily adjacent in the primary layout. In order to maintain the spatial rights of the primary data relation, we avoid layout adjustment techniques that improve set cluster continuity and density. Instead, we use a continuous, possibly concave, isocontour to delineate set membership, without disrupting the primary layout. Optimizations minimize cluster overlap and provide for calculation of the isocontours at interactive speeds. Case studies show how this technique can be used to indicate multiple sets on a variety of common visualizations.	Christopher Collins;Gerald Penn;M. Sheelagh T. Carpendale	Univ. of Toronto, Toronto, ON, Canada|c|;;	10.1109/TVCG.2006.122;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2008.130;10.1109/TVCG.2008.144;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2007.70521;10.1109/TVCG.2008.153	clustering, spatial layout, graph visualization, tree visualization	
InfoVis	2009	code_swarm: A Design Study in Organic Software Visualization	10.1109/TVCG.2009.123	http://dx.doi.org/10.1109/TVCG.2009.123	1097	1104	J	In May of 2008, we published online a series of software visualization videos using a method called code_swarm. Shortly thereafter, we made the code open source and its popularity took off. This paper is a study of our code swarm application, comprising its design, results and public response. We share our design methodology, including why we chose the organic information visualization technique, how we designed for both developers and a casual audience, and what lessons we learned from our experiment. We validate the results produced by code_swarm through a qualitative analysis and by gathering online user comments. Furthermore, we successfully released the code as open source, and the software community used it to visualize their own projects and shared their results as well. In the end, we believe code_swarm has positive implications for the future of organic information design and open source information visualization practice.	Michael Ogawa;Kwan-Liu Ma	VIDI Lab., Univ. of California, Davis, CA, USA|c|;	10.1109/TVCG.2007.70541;10.1109/TVCG.2008.172;10.1109/INFVIS.2005.1532125;10.1109/INFVIS.2004.65;10.1109/INFVIS.2005.1532122	Software visualization, organic information visualization, software development history and evolution	
InfoVis	2009	Comparing Dot and Landscape Spatializations for Visual Memory Differences	10.1109/TVCG.2009.127	http://dx.doi.org/10.1109/TVCG.2009.127	1033	1040	J	Spatialization displays use a geographic metaphor to arrange non-spatial data. For example, spatializations are commonly applied to document collections so that document themes appear as geographic features such as hills. Many common spatialization interfaces use a 3-D landscape metaphor to present data. However, it is not clear whether 3-D spatializations afford improved speed and accuracy for user tasks compared to similar 2-D spatializations. We describe a user study comparing users' ability to remember dot displays, 2-D landscapes, and 3-D landscapes for two different data densities (500 vs. 1000 points). Participants' visual memory was statistically more accurate when viewing dot displays and 3-D landscapes compared to 2-D landscapes. Furthermore, accuracy remembering a spatialization was significantly better overall for denser spatializations. Theseresults are of benefit to visualization designers who are contemplating the best ways to present data using spatialization techniques.	Melanie Tory;Colin Swindells;Rebecca Dreezer	Univ. of Victoria, Victoria, BC, Canada|c|;;	10.1109/INFVIS.2004.19;10.1109/INFVIS.2002.1173146;10.1109/TVCG.2007.70596;10.1109/INFVIS.2004.60;10.1109/INFVIS.2001.963291;10.1109/INFVIS.1995.528686;10.1109/INFVIS.2001.963291;10.1109/INFVIS.2001.963274	Information interfaces and presentation, screen design, evaluation / methodology, user / machine systems, software psychology, landscape visualization	
InfoVis	2009	Configuring Hierarchical Layouts to Address Research Questions	10.1109/TVCG.2009.128	http://dx.doi.org/10.1109/TVCG.2009.128	977	984	J	We explore the effects of selecting alternative layouts in hierarchical displays that show multiple aspects of large multivariate datasets, including spatial and temporal characteristics. Hierarchical displays of this type condition a dataset by multiple discrete variable values, creating nested graphical summaries of the resulting subsets in which size, shape and colour can be used to show subset properties. These 'small multiples' are ordered by the conditioning variable values and are laid out hierarchically using dimensional stacking. Crucially, we consider the use of different layouts at different hierarchical levels, so that the coordinates of the plane can be used more effectively to draw attention to trends and anomalies in the data. We argue that these layouts should be informed by the type of conditioning variable and by the research question being explored. We focus on space-filling rectangular layouts that provide data-dense and rich overviews of data to address research questions posed in our exploratory analysis of spatial and temporal aspects of property sales in London. We develop a notation ('HiVE') that describes visualisation and layout states and provides reconfiguration operators, demonstrate its use for reconfiguring layouts to pursue research questions and provide guidelines for this process. We demonstrate how layouts can be related through animated transitions to reduce the cognitive load associated with their reconfiguration whilst supporting the exploratory process.	Aidan Slingsby;Jason Dykes;Jo Wood	Dept. of Inf. Sci., City Univ. London, London, UK|c|;;	10.1109/TVCG.2007.70515;10.1109/INFVIS.2003.1249006;10.1109/VISUAL.1990.146386;10.1109/TVCG.2008.125;10.1109/TVCG.2007.70539;10.1109/VISUAL.2002.1183791	Geovisualization, hierarchical, layout, guidelines, exploratory, notation	
InfoVis	2009	Conjunctive Visual Forms	10.1109/TVCG.2009.129	http://dx.doi.org/10.1109/TVCG.2009.129	929	936	J	Visual exploration of multidimensional data is a process of isolating and extracting relationships within and between dimensions. Coordinated multiple view approaches are particularly effective for visual exploration because they support precise expression of heterogeneous multidimensional queries using simple interactions. Recent visual analytics research has made significant progress in identifying and understanding patterns of composed views and coordinations that support fast, flexible, and open-ended data exploration. What is missing is formalization of the space of expressible queries in terms of visual representation and interaction. This paper introduces the conjunctive visual form model in which visual exploration consists of interactively-driven sequences of transitions between visual states that correspond to conjunctive normal forms in boolean logic. The model predicts several new and useful ways to extend the space of rapidly expressible queries through addition of simple interactive capabilities to existing compositional patterns. Two recent related visual tools offer a subset of these capabilities, providing a basis for conjecturing about such extensions.	Chris Weaver	Center for Spatial Anal., Univ. of Oklahoma, Norman, OK, USA|c|	10.1109/VAST.2006.261427;10.1109/INFVIS.2001.963287;10.1109/INFVIS.2003.1249024;10.1109/TVCG.2007.70577;10.1109/VISUAL.1995.485139;10.1109/TVCG.2007.70594;10.1109/INFVIS.1996.559216;10.1109/VAST.2007.4389006;10.1109/VAST.2008.4677370;10.1109/TVCG.2008.153	Boolean query, brushing, conjunctive normal form, exploratory visualization, multiple views, visual abstraction	
InfoVis	2009	Constructing Overview + Detail Dendrogram-Matrix Views	10.1109/TVCG.2009.130	http://dx.doi.org/10.1109/TVCG.2009.130	889	896	J	A dendrogram that visualizes a clustering hierarchy is often integrated with a re-orderable matrix for pattern identification. The method is widely used in many research fields including biology, geography, statistics, and data mining. However, most dendrograms do not scale up well, particularly with respect to problems of graphical and cognitive information overload. This research proposes a strategy that links an overview dendrogram and a detail-view dendrogram, each integrated with a re-orderable matrix. The overview displays only a user-controlled, limited number of nodes that represent the ldquoskeletonrdquo of a hierarchy. The detail view displays the sub-tree represented by a selected meta-node in the overview. The research presented here focuses on constructing a concise overview dendrogram and its coordination with a detail view. The proposed method has the following benefits: dramatic alleviation of information overload, enhanced scalability and data abstraction quality on the dendrogram, and the support of data exploration at arbitrary levels of detail. The contribution of the paper includes a new metric to measure the ldquoimportancerdquo of nodes in a dendrogram; the method to construct the concise overview dendrogram from the dynamically-identified, important nodes; and measure for evaluating the data abstraction quality for dendrograms. We evaluate and compare the proposed method to some related existing methods, and demonstrating how the proposed method can help users find interesting patterns through a case study on county-level U.S. cervical cancer mortality and demographic data.	Jin Chen;Alan M. MacEachren;Donna Peuquet	Dept. of Geogr., Pennsylvania State Univ., University Park, PA, USA|c|;;	10.1109/TVCG.2006.161;10.1109/TVCG.2007.70535;10.1109/INFVIS.2004.46	Dendrogram, reorderable matrix, compound graphs, data abstraction quality metrics, hierarchical clusters	
InfoVis	2009	Document Cards: A Top Trumps Visualization for Documents	10.1109/TVCG.2009.139	http://dx.doi.org/10.1109/TVCG.2009.139	1145	1152	J	Finding suitable, less space consuming views for a document's main content is crucial to provide convenient access to large document collections on display devices of different size. We present a novel compact visualization which represents the document's key semantic as a mixture of images and important key terms, similar to cards in a top trumps game. The key terms are extracted using an advanced text mining approach based on a fully automatic document structure extraction. The images and their captions are extracted using a graphical heuristic and the captions are used for a semi-semantic image weighting. Furthermore, we use the image color histogram for classification and show at least one representative from each non-empty image class. The approach is demonstrated for the IEEE InfoVis publications of a complete year. The method can easily be applied to other publication collections and sets of documents which contain images.	Hendrik Strobelt;Daniela Oelke;Christian Rohrdantz;Andreas Stoffel;Daniel A. Keim;Oliver Deussen	Univ. of Konstanz, Konstanz, Germany|c|;;;;;		document visualization, visual summary, content extraction, document collection browsing	
InfoVis	2009	Exemplar-based Visualization of Large Document Corpus	10.1109/TVCG.2009.140	http://dx.doi.org/10.1109/TVCG.2009.140	1161	1168	J	With the rapid growth of the World Wide Web and electronic information services, text corpus is becoming available online at an incredible rate. By displaying text data in a logical layout (e.g., color graphs), text visualization presents a direct way to observe the documents as well as understand the relationship between them. In this paper, we propose a novel technique, Exemplar-based visualization (EV), to visualize an extremely large text corpus. Capitalizing on recent advances in matrix approximation and decomposition, EV presents a probabilistic multidimensional projection model in the low-rank text subspace with a sound objective function. The probability of each document proportion to the topics is obtained through iterative optimization and embedded to a low dimensional space using parameter embedding. By selecting the representative exemplars, we obtain a compact approximation of the data. This makes the visualization highly efficient and flexible. In addition, the selected exemplars neatly summarize the entire data set and greatly reduce the cognitive overload in the visualization, leading to an easier interpretation of large text corpus. Empirically, we demonstrate the superior performance of EV through extensive experiments performed on the publicly available text data sets.	Yanhua Chen;Lijun Wang;Ming Dong;Jing Hua	Dept. of Comput. Sci., Wayne State Univ., Detroit, MI, USA|c|;;;	10.1109/VISUAL.1999.809866;10.1109/TVCG.2008.138	Exemplar, large-scale document visualization, multidimensional projection	
InfoVis	2009	Flow Mapping and Multivariate Visualization of Large Spatial Interaction Data	10.1109/TVCG.2009.143	http://dx.doi.org/10.1109/TVCG.2009.143	1041	1048	J	Spatial interactions (or flows), such as population migration and disease spread, naturally form a weighted location-to-location network (graph). Such geographically embedded networks (graphs) are usually very large. For example, the county-to-county migration data in the U.S. has thousands of counties and about a million migration paths. Moreover, many variables are associated with each flow, such as the number of migrants for different age groups, income levels, and occupations. It is a challenging task to visualize such data and discover network structures, multivariate relations, and their geographic patterns simultaneously. This paper addresses these challenges by developing an integrated interactive visualization framework that consists three coupled components: (1) a spatially constrained graph partitioning method that can construct a hierarchy of geographical regions (communities), where there are more flows or connections within regions than across regions; (2) a multivariate clustering and visualization method to detect and present multivariate patterns in the aggregated region-to-region flows; and (3) a highly interactive flow mapping component to map both flow and multivariate patterns in the geographic space, at different hierarchical levels. The proposed approach can process relatively large data sets and effectively discover and visualize major flow structures and multivariate relations at the same time. User interactions are supported to facilitate the understanding of both an overview and detailed patterns.	Diansheng Guo	Dept. of Geogr., Univ. of South Carolina, Columbia, SC, USA|c|	10.1109/TVCG.2008.135;10.1109/TVCG.2006.147;10.1109/TVCG.2006.138;10.1109/INFVIS.2005.1532150	hierarchical clustering, graph partitioning, flow mapping, spatial interaction, contiguity constraints, multidimensional visualization, coordinated views, data mining	
InfoVis	2009	FromDaDy: Spreading Aircraft Trajectories Across Views to Support Iterative Queries	10.1109/TVCG.2009.145	http://dx.doi.org/10.1109/TVCG.2009.145	1017	1024	J	When displaying thousands of aircraft trajectories on a screen, the visualization is spoiled by a tangle of trails. The visual analysis is therefore difficult, especially if a specific class of trajectories in an erroneous dataset has to be studied. We designed FromDaDy, a trajectory visualization tool that tackles the difficulties of exploring the visualization of multiple trails. This multidimensional data exploration is based on scatterplots, brushing, pick and drop, juxtaposed views and rapid visual design. Users can organize the workspace composed of multiple juxtaposed views. They can define the visual configuration of the views by connecting data dimensions from the dataset to Bertin's visual variables. They can then brush trajectories, and with a pick and drop operation they can spread the brushed information across views. They can then repeat these interactions, until they extract a set of relevant data, thus formulating complex queries. Through two real-world scenarios, we show how FromDaDy supports iterative queries and the extraction of trajectories in a dataset that contains up to 5 million data.	Christophe Hurter;Benjamin Tissoires;Stéphane Conversy	DSNA, DTI R&D, ENAC, Toulouse, France|c|;;	10.1109/INFVIS.2000.885086;10.1109/VISUAL.1995.485139;10.1109/VISUAL.1994.346302;10.1109/TVCG.2008.153;10.1109/INFVIS.2004.64	visualization, iterative exploration, direct manipulation, trajectories	
InfoVis	2009	GeneShelf: A Web-based Visual Interface for Large Gene Expression Time-Series Data Repositories	10.1109/TVCG.2009.146	http://dx.doi.org/10.1109/TVCG.2009.146	905	912	J	A widespread use of high-throughput gene expression analysis techniques enabled the biomedical research community to share a huge body of gene expression datasets in many public databases on the web. However, current gene expression data repositories provide static representations of the data and support limited interactions. This hinders biologists from effectively exploring shared gene expression datasets. Responding to the growing need for better interfaces to improve the utility of the public datasets, we have designed and developed a new web-based visual interface entitled GeneShelf (http://bioinformatics.cnmcresearch.org/GeneShelf). It builds upon a zoomable grid display to represent two categorical dimensions. It also incorporates an augmented timeline with expandable time points that better shows multiple data values for the focused time point by embedding bar charts. We applied GeneShelf to one of the largest microarray datasets generated to study the progression and recovery process of injuries at the spinal cord of mice and rats. We present a case study and a preliminary qualitative user study with biologists to show the utility and usability of GeneShelf.	Bo Hyoung Kim;Bongshin Lee;Susan Knoblach;Eric P. Hoffman;Jinwook Seo	Seoul Nat. Univ., Seoul, South Korea|c|;;;;		bioinformatics visualization, augmented timeline, animation, zoomable grid, gene expression profiling	
InfoVis	2009	Harnessing the Information Ecosystem with Wiki-based Visualization Dashboards	10.1109/TVCG.2009.148	http://dx.doi.org/10.1109/TVCG.2009.148	1081	1088	J	We describe the design and deployment of Dashiki, a public Website where users may collaboratively build visualization dashboards through a combination of a wiki-like syntax and interactive editors. Our goals are to extend existing research on social data analysis into presentation and organization of data from multiple sources, explore new metaphors for these activities, and participate more fully in the Web's information ecology by providing tighter integration with real-time data. To support these goals, our design includes novel and low-barrier mechanisms for editing and layout of dashboard pages and visualizations, connection to data sources, and coordinating interaction between visualizations. In addition to describing these technologies, we provide a preliminary report on the public launch of a prototype based on this design, including a description of the activities of our users derived from observation and interviews.	Matt McKeon	IBM Research|c|	10.1109/TVCG.2007.70577;10.1109/INFVIS.1998.729560;10.1109/TVCG.2008.172;10.1109/TVCG.2006.178;10.1109/VAST.2008.4677366;10.1109/TVCG.2008.175;10.1109/VAST.2007.4389011;10.1109/VISUAL.1994.346302	visualization, web, social software, wikis, social data analysis, collaboration, dashboards, visual analytics	
InfoVis	2009	Interaction Techniques for Selecting and Manipulating Subgraphs in Network Visualizations	10.1109/TVCG.2009.151	http://dx.doi.org/10.1109/TVCG.2009.151	937	944	J	We present a novel and extensible set of interaction techniques for manipulating visualizations of networks by selecting subgraphs and then applying various commands to modify their layout or graphical properties. Our techniques integrate traditional rectangle and lasso selection, and also support selecting a node's neighbourhood by dragging out its radius (in edges) using a novel kind of radial menu. Commands for translation, rotation, scaling, or modifying graphical properties (such as opacity) and layout patterns can be performed by using a hotbox (a transiently popped-up, semi-transparent set of widgets) that has been extended in novel ways to integrate specification of commands with 1D or 2D arguments. Our techniques require only one mouse button and one keyboard key, and are designed for fast, gestural, in-place interaction. We present the design and integration of these interaction techniques, and illustrate their use in interactive graph visualization. Our techniques are implemented in NAViGaTOR, a software package for visualizing and analyzing biological networks. An initial usability study is also reported.	Michael J. McGuffin;Igor Jurisica	Ecole de Technol. Super., Montreal, QC, Canada|c|;	10.1109/INFVIS.2005.1532124;10.1109/INFVIS.1996.559216	Interactive graph drawing, network layout, radial menus, marking menus, hotbox, biological networks	
InfoVis	2009	Interactive Dimensionality Reduction Through User-defined Combinations of Quality Metrics	10.1109/TVCG.2009.153	http://dx.doi.org/10.1109/TVCG.2009.153	993	1000	J	Multivariate data sets including hundreds of variables are increasingly common in many application areas. Most multivariate visualization techniques are unable to display such data effectively, and a common approach is to employ dimensionality reduction prior to visualization. Most existing dimensionality reduction systems focus on preserving one or a few significant structures in data. For many analysis tasks, however, several types of structures can be of high significance and the importance of a certain structure compared to the importance of another is often task-dependent. This paper introduces a system for dimensionality reduction by combining user-defined quality metrics using weight functions to preserve as many important structures as possible. The system aims at effective visualization and exploration of structures within large multivariate data sets and provides enhancement of diverse structures by supplying a range of automatic variable orderings. Furthermore it enables a quality-guided reduction of variables through an interactive display facilitating investigation of trade-offs between loss of structure and the number of variables to keep. The generality and interactivity of the system is demonstrated through a case scenario.	Sara Johansson;Jimmy Johansson	Norrkoping Visualization & Interaction Studio (NVIS), Linkoping Univ., Linkoping, Sweden|c|;	10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2003.1249015;10.1109/INFVIS.1998.729559;10.1109/TVCG.2006.161;10.1109/INFVIS.2004.60;10.1109/INFVIS.2004.3;10.1109/INFVIS.2004.71;10.1109/TVCG.2008.138;10.1109/INFVIS.2004.15	dimensionality reduction, interactivity, quality metrics, variable ordering	
InfoVis	2009	Lark: Coordinating Co-located Collaboration with Information Visualization	10.1109/TVCG.2009.162	http://dx.doi.org/10.1109/TVCG.2009.162	1065	1072	J	Large multi-touch displays are expanding the possibilities of multiple-coordinated views by allowing multiple people to interact with data in concert or independently. We present Lark, a system that facilitates the coordination of interactions with information visualizations on shared digital workspaces. We focus on supporting this coordination according to four main criteria: scoped interaction, temporal flexibility, spatial flexibility, and changing collaboration styles. These are achieved by integrating a representation of the information visualization pipeline into the shared workspace, thus explicitly indicating coordination points on data, representation, presentation, and view levels. This integrated meta-visualization supports both the awareness of how views are linked and the freedom to work in concert or independently. Lark incorporates these four main criteria into a coherent visualization collaboration interaction environment by providing direct visual and algorithmic support for the coordination of data analysis actions over shared large displays.	Matthew Tobiasz;Petra Isenberg;M. Sheelagh T. Carpendale	Univ. of Calgary, Calgary, AB, Canada|c|;;	10.1109/INFVIS.2004.12;10.1109/INFVIS.1998.729560;10.1109/VAST.2006.261415;10.1109/VAST.2007.4389011;10.1109/INFVIS.2005.1532143;10.1109/VAST.2006.261439;10.1109/TVCG.2007.70568	Information visualization, Meta-visualization, Collaboration, Coordination, Co-located work, Workspace awareness	
InfoVis	2009	Mapping Text with Phrase Nets	10.1109/TVCG.2009.165	http://dx.doi.org/10.1109/TVCG.2009.165	1169	1176	J	We present a new technique, the phrase net, for generating visual overviews of unstructured text. A phrase net displays a graph whose nodes are words and whose edges indicate that two words are linked by a user-specified relation. These relations may be defined either at the syntactic or lexical level; different relations often produce very different perspectives on the same text. Taken together, these perspectives often provide an illuminating visual overview of the key concepts and relations in a document or set of documents.	Frank van Ham;Martin Wattenberg;Fernanda B. Viégas	;;	10.1109/TVCG.2008.172;10.1109/VISUAL.2005.1532781;10.1109/TVCG.2007.70577	Text visualization, tag cloud, natural language processing, semantic net	
InfoVis	2009	MizBee: A Multiscale Synteny Browser	10.1109/TVCG.2009.167	http://dx.doi.org/10.1109/TVCG.2009.167	897	904	J	In the field of comparative genomics, scientists seek to answer questions about evolution and genomic function by comparing the genomes of species to find regions of shared sequences. Conserve dsyntenic blocks are an important biological data abstraction for indicating regions of shared sequences. The goal of this work is to show multiple types of relationships at multiple scales in a way that is visually comprehensible in accordance with known perceptual principles. We present a task analysis for this domain where the fundamental questions asked by biologists can be understood by a characterization of relationships into the four types of proximity/location, size, orientation, and similarity/strength, and the four scales of genome, chromosome, block, and genomic feature. We also propose a new taxonomy of the design space for visually encoding conservation data. We present MizBee, a multiscale synteny browser with the unique property of providing interactive side-by-side views of the data across the range of scales supporting exploration of all of these relationship types. We conclude with case studies from two biologists who used MizBee to augment their previous automatic analysis work flow, providing anecdotal evidence about the efficacy of the system for the visualization of syntenic data, the analysis of conservation relationships, and the communication of scientific insights.	Miriah D. Meyer;Tamara Munzner;Hanspeter Pfister	Harvard Univ., Cambridge, MA, USA|c|;;	10.1109/INFVIS.2005.1532134;10.1109/TVCG.2006.147	Information visualization, design study, bioinformatics, synteny	
InfoVis	2009	Participatory Visualization with Wordle	10.1109/TVCG.2009.171	http://dx.doi.org/10.1109/TVCG.2009.171	1137	1144	J	We discuss the design and usage of ldquoWordle,rdquo a Web-based tool for visualizing text. Wordle creates tag-cloud-like displays that give careful attention to typography, color, and composition. We describe the algorithms used to balance various aesthetic criteria and create the distinctive Wordle layouts. We then present the results of a study of Wordle usage, based both on spontaneous behaviour observed in the wild, and on a large-scale survey of Wordle users. The results suggest that Wordles have become a kind of medium of expression, and that a ldquoparticipatory culturerdquo has arisen around them.	Fernanda B. Viégas;Martin Wattenberg;Jonathan Feinberg	IBM Res., Hawthorne, CA, USA|c|;;	10.1109/INFVIS.2005.1532122;10.1109/TVCG.2007.70577	Visualization, text, tag cloud, participatory culture, memory, educational visualization, social data analysis	
InfoVis	2009	Protovis: A Graphical Toolkit for Visualization	10.1109/TVCG.2009.174	http://dx.doi.org/10.1109/TVCG.2009.174	1121	1128	J	Despite myriad tools for visualizing data, there remains a gap between the notational efficiency of high-level visualization systems and the expressiveness and accessibility of low-level graphical systems. Powerful visualization systems may be inflexible or impose abstractions foreign to visual thinking, while graphical systems such as rendering APIs and vector-based drawing programs are tedious for complex work. We argue that an easy-to-use graphical system tailored for visualization is needed. In response, we contribute Protovis, an extensible toolkit for constructing visualizations by composing simple graphical primitives. In Protovis, designers specify visualizations as a hierarchy of marks with visual properties defined as functions of data. This representation achieves a level of expressiveness comparable to low-level graphics systems, while improving efficiency - the effort required to specify a visualization - and accessibility - the effort required to learn and modify the representation. We substantiate this claim through a diverse collection of examples and comparative analysis with popular visualization tools.	Michael Bostock;Jeffrey Heer	Comput. Sci. Dept., Stanford Univ., Stanford, CA, USA|c|;	10.1109/VISUAL.1999.809864;10.1109/INFVIS.2004.12;10.1109/TVCG.2006.178;10.1109/TVCG.2007.70577;10.1109/INFVIS.1998.729560;10.1109/VAST.2007.4389011;10.1109/TVCG.2008.166;10.1109/INFVIS.2004.64;10.1109/INFVIS.2000.885086;10.1109/VAST.2007.4388996	Information visualization, user interfaces, toolkits, 2D graphics	
InfoVis	2009	ResultMaps: Visualization for Search Interfaces	10.1109/TVCG.2009.176	http://dx.doi.org/10.1109/TVCG.2009.176	1057	1064	J	Hierarchical representations are common in digital repositories, yet are not always fully leveraged in their online search interfaces. This work describes ResultMaps, which use hierarchical treemap representations with query string-driven digital library search engines. We describe two lab experiments, which find that ResultsMap users yield significantly better results over a control condition on some subjective measures, and we find evidence that ResultMaps have ancillary benefits via increased understanding of some aspects of repository content. The ResultMap system and experiments contribute an understanding of the benefits-direct and indirect-of the ResultMap approach to repository search visualization.	Edward Clarkson;Krishna Desai;James D. Foley	Georgia Tech, Atlanta, GA, USA|c|;;	10.1109/VISUAL.1991.175815;10.1109/TVCG.2006.142;10.1109/INFVIS.1995.528686	Treemap, evaluation, user studies, digital library, digital repository, search engine, search visualization, infovis	
InfoVis	2009	Scattering Points in Parallel Coordinates	10.1109/TVCG.2009.179	http://dx.doi.org/10.1109/TVCG.2009.179	1001	1008	J	In this paper, we present a novel parallel coordinates design integrated with points (scattering points in parallel coordinates, SPPC), by taking advantage of both parallel coordinates and scatterplots. Different from most multiple views visualization frameworks involving parallel coordinates where each visualization type occupies an individual window, we convert two selected neighboring coordinate axes into a scatterplot directly. Multidimensional scaling is adopted to allow converting multiple axes into a single subplot. The transition between two visual types is designed in a seamless way. In our work, a series of interaction tools has been developed. Uniform brushing functionality is implemented to allow the user to perform data selection on both points and parallel coordinate polylines without explicitly switching tools. A GPU accelerated dimensional incremental multidimensional scaling (DIMDS) has been developed to significantly improve the system performance. Our case study shows that our scheme is more efficient than traditional multi-view methods in performing visual analysis tasks.	Xiaoru Yuan;Peihong Guo;He Xiao;Hong Zhou;Huamin Qu	Key Lab. of Machine Perception (Minist. of Educ.), Peking Univ., Beijing, China|c|;;;;	10.1109/TVCG.2008.119;10.1109/INFVIS.2005.1532139;10.1109/VISUAL.1997.663867;10.1109/VISUAL.1990.146402;10.1109/INFVIS.2005.1532141;10.1109/VISUAL.1997.663916;10.1109/TVCG.2006.138;10.1109/VISUAL.1997.663866;10.1109/VISUAL.1996.567800;10.1109/INFVIS.2005.1532138;10.1109/INFVIS.2003.1249015;10.1109/VISUAL.1996.567787;10.1109/INFVIS.1998.729559;10.1109/INFVIS.2003.1249008;10.1109/INFVIS.2002.1173157;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2003.1249023;10.1109/TVCG.2006.170;10.1109/INFVIS.2004.68;10.1109/INFVIS.2004.15;10.1109/TVCG.2008.153	Parallel Coordinates, Scatterplots, Information Visualization, Multidimensional Scaling	
InfoVis	2009	SellTrend: Inter-Attribute Visual Analysis of Temporal Transaction Data	10.1109/TVCG.2009.180	http://dx.doi.org/10.1109/TVCG.2009.180	1025	1032	J	We present a case study of our experience designing SellTrend, a visualization system for analyzing airline travel purchase requests. The relevant transaction data can be characterized as multi-variate temporal and categorical event sequences, and the chief problem addressed is how to help company analysts identify complex combinations of transaction attributes that contribute to failed purchase requests. SellTrend combines a diverse set of techniques ranging from time series visualization to faceted browsing and historical trend analysis in order to help analysts make sense of the data. We believe that the combination of views and interaction capabilities in SellTrend provides an innovative approach to this problem and to other similar types of multivariate, temporally driven transaction data analysis. Initial feedback from company analysts confirms the utility and benefits of the system.	Zhicheng Liu;John T. Stasko;Timothy Sullivan	Sch. of Interactive Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;;	10.1109/VAST.2007.4389009;10.1109/INFVIS.2005.1532139;10.1109/VISUAL.1991.175815;10.1109/VISUAL.1992.235181;10.1109/TVCG.2006.142;10.1109/INFVIS.1997.636793;10.1109/TVCG.2008.121;10.1109/VAST.2007.4389006	investigative analysis, transaction analysis, information visualization, multiple views, time series data, multiple attributes, categorical data	
InfoVis	2009	Smooth Graphs for Visual Exploration of Higher-Order State Transitions	10.1109/TVCG.2009.181	http://dx.doi.org/10.1109/TVCG.2009.181	969	976	J	In this paper, we present a new visual way of exploring state sequences in large observational time-series. A key advantage of our method is that it can directly visualize higher-order state transitions. A standard first order state transition is a sequence of two states that are linked by a transition. A higher-order state transition is a sequence of three or more states where the sequence of participating states are linked together by consecutive first order state transitions. Our method extends the current state-graph exploration methods by employing a two dimensional graph, in which higher-order state transitions are visualized as curved lines. All transitions are bundled into thick splines, so that the thickness of an edge represents the frequency of instances. The bundling between two states takes into account the state transitions before and after the transition. This is done in such a way that it forms a continuous representation in which any subsequence of the timeseries is represented by a continuous smooth line. The edge bundles in these graphs can be explored interactively through our incremental selection algorithm. We demonstrate our method with an application in exploring labeled time-series data from a biological survey, where a clustering has assigned a single label to the data at each time-point. In these sequences, a large number of cyclic patterns occur, which in turn are linked to specific activities. We demonstrate how our method helps to find these cycles, and how the interactive selection process helps to find and investigate activities.	Jorik Blaas;Charl P. Botha;Edward Grundy;Mark W. Jones;Robert S. Laramee;Frits H. Post	Visualization Group, Delft Univ. of Technol., Delft, Netherlands|c|;;;;;	10.1109/INFVIS.1995.528685;10.1109/TVCG.2008.155;10.1109/TVCG.2008.135;10.1109/TVCG.2006.192;10.1109/INFVIS.2001.963281;10.1109/INFVIS.2001.963281;10.1109/TVCG.2006.147	State transitions, Graph drawing, Time series, Biological data	
InfoVis	2009	Spatiotemporal Analysis of Sensor Logs using Growth Ring Maps	10.1109/TVCG.2009.182	http://dx.doi.org/10.1109/TVCG.2009.182	913	920	J	Spatiotemporal analysis of sensor logs is a challenging research field due to three facts: a) traditional two-dimensional maps do not support multiple events to occur at the same spatial location, b) three-dimensional solutions introduce ambiguity and are hard to navigate, and c) map distortions to solve the overlap problem are unfamiliar to most users. This paper introduces a novel approach to represent spatial data changing over time by plotting a number of non-overlapping pixels, close to the sensor positions in a map. Thereby, we encode the amount of time that a subject spent at a particular sensor to the number of plotted pixels. Color is used in a twofold manner; while distinct colors distinguish between sensor nodes in different regions, the colors' intensity is used as an indicator to the temporal property of the subjects' activity. The resulting visualization technique, called growth ring maps, enables users to find similarities and extract patterns of interest in spatiotemporal data by using humans' perceptual abilities. We demonstrate the newly introduced technique on a dataset that shows the behavior of healthy and Alzheimer transgenic, male and female mice. We motivate the new technique by showing that the temporal analysis based on hierarchical clustering and the spatial analysis based on transition matrices only reveal limited results. Results and findings are cross-validated using multidimensional scaling. While the focus of this paper is to apply our visualization for monitoring animal behavior, the technique is also applicable for analyzing data, such as packet tracing, geographic monitoring of sales development, or mobile phone capacity planning.	Peter Bak;Florian Mansmann;Halldór Janetzko;Daniel A. Keim	Univ. of Konstanz, Konstanz, Germany|c|;;;	10.1109/INFVIS.2004.27;10.1109/VISUAL.1995.485140;10.1109/INFVIS.2005.1532144;10.1109/TVCG.2006.198;10.1109/TVCG.2007.70621;10.1109/TVCG.2007.70535;10.1109/INFVIS.1999.801851;10.1109/TVCG.2006.202	spatiotemporal visualization, visual analytics, animal behavior, dense pixel displays	
InfoVis	2009	SpicyNodes: Radial Layout Authoring for the General Public	10.1109/TVCG.2009.183	http://dx.doi.org/10.1109/TVCG.2009.183	1089	1096	J	Trees and graphs are relevant to many online tasks such as visualizing social networks, product catalogs, educational portals, digital libraries, the semantic web, concept maps and personalized information management. SpicyNodes is an information-visualization technology that builds upon existing research on radial tree layouts and graph structures. Users can browse a tree, clicking from node to node, as well as successively viewing a node, immediately related nodes and the path back to the ldquohomerdquo nodes. SpicyNodes' layout algorithms maintain balanced layouts using a hybrid mixture of a geometric layout (a succession of spanning radial trees) and force-directed layouts to minimize overlapping nodes, plus several other improvements over prior art. It provides XML-based API and GUI authoring tools. The goal of the SpicyNodes project is to implement familiar principles of radial maps and focus+context with an attractive and inviting look and feel in an open system that is accessible to virtually any Internet user.	Michael Douma;Grzegorz Ligierko;Ovidiu Ancuta;Pavel Gritsai;Sean Liu	;;;;	10.1109/INFVIS.2001.963279;10.1109/TVCG.2008.171;10.1109/INFVIS.2003.1249009;10.1109/INFVIS.2004.64	Trees and network visualization, radial tree layout, information visualization, interaction, focus+context, hierarchy visualization, human-computer interaction	
InfoVis	2009	Temporal Summaries: Supporting Temporal Categorical Searching, Aggregation and Comparison	10.1109/TVCG.2009.187	http://dx.doi.org/10.1109/TVCG.2009.187	1049	1056	J	When analyzing thousands of event histories, analysts often want to see the events as an aggregate to detect insights and generate new hypotheses about the data. An analysis tool must emphasize both the prevalence and the temporal ordering of these events. Additionally, the analysis tool must also support flexible comparisons to allow analysts to gather visual evidence. In a previous work, we introduced align, rank, and filter (ARF) to accentuate temporal ordering. In this paper, we present temporal summaries, an interactive visualization technique that highlights the prevalence of event occurrences. Temporal summaries dynamically aggregate events in multiple granularities (year, month, week, day, hour, etc.) for the purpose of spotting trends over time and comparing several groups of records. They provide affordances for analysts to perform temporal range filters. We demonstrate the applicability of this approach in two extensive case studies with analysts who applied temporal summaries to search, filter, and look for patterns in electronic health records and academic records.	Taowei David Wang;Catherine Plaisant;Ben Shneiderman;Neil Spring;David Roseman;Greg Marchand;Vikramjit Mukherjee;Mark S. Smith	Dept. of Comput. Sci., Univ. of Maryland at Coll. Park, College Park, MD, USA|c|;;;;;;;	10.1109/INFVIS.2005.1532122;10.1109/VAST.2007.4389008	Information Visualization, Interaction design, Human-computer interaction, temporal categorical data visualization	
InfoVis	2009	The Benefits of Synchronous Collaborative Information Visualization: Evidence from an Experimental Evaluation	10.1109/TVCG.2009.188	http://dx.doi.org/10.1109/TVCG.2009.188	1073	1080	J	A great corpus of studies reports empirical evidence of how information visualization supports comprehension and analysis of data. The benefits of visualization for synchronous group knowledge work, however, have not been addressed extensively. Anecdotal evidence and use cases illustrate the benefits of synchronous collaborative information visualization, but very few empirical studies have rigorously examined the impact of visualization on group knowledge work. We have consequently designed and conducted an experiment in which we have analyzed the impact of visualization on knowledge sharing in situated work groups. Our experimental study consists of evaluating the performance of 131 subjects (all experienced managers) in groups of 5 (for a total of 26 groups), working together on a real-life knowledge sharing task. We compare (1) the control condition (no visualization provided), with two visualization supports: (2) optimal and (3) suboptimal visualization (based on a previous survey). The facilitator of each group was asked to populate the provided interactive visual template with insights from the group, and to organize the contributions according to the group consensus. We have evaluated the results through both objective and subjective measures. Our statistical analysis clearly shows that interactive visualization has a statistically significant, objective and positive impact on the outcomes of knowledge sharing, but that the subjects seem not to be aware of this. In particular, groups supported by visualization achieved higher productivity, higher quality of outcome and greater knowledge gains. No statistically significant results could be found between an optimal and a suboptimal visualization though (as classified by the pre-experiment survey). Subjects also did not seem to be aware of the benefits that the visualizations provided as no difference between the visualization and the control conditions was found for the self-reported measures of satisfaction a- - nd participation. An implication of our study for information visualization applications is to extend them by using real-time group annotation functionalities that aid in the group sense making process of the represented data.	Sabrina Bresciani;Martin J. Eppler	Univ. of Lugano, Lugano, Switzerland|c|;	10.1109/VAST.2008.4677358;10.1109/TVCG.2007.70568;10.1109/TVCG.2008.125;10.1109/TVCG.2008.129	Laboratory Studies, Visual Knowledge Representation, Collaborative and Distributed Visualization, synchronous situated collaboration, group work, experiment, knowledge sharing	
InfoVis	2009	Towards Utilizing GPUs in Information Visualization: A Model and Implementation of Image-Space Operations	10.1109/TVCG.2009.191	http://dx.doi.org/10.1109/TVCG.2009.191	1105	1112	J	Modern programmable GPUs represent a vast potential in terms of performance and visual flexibility for information visualization research, but surprisingly few applications even begin to utilize this potential. In this paper, we conjecture that this may be due to the mismatch between the high-level abstract data types commonly visualized in our field, and the low-level floating-point model supported by current GPU shader languages. To help remedy this situation, we present a refinement of the traditional information visualization pipeline that is amenable to implementation using GPU shaders. The refinement consists of a final image-space step in the pipeline where the multivariate data of the visualization is sampled in the resolution of the current view. To concretize the theoretical aspects of this work, we also present a visual programming environment for constructing visualization shaders using a simple drag-and-drop interface. Finally, we give some examples of the use of shaders for well-known visualization techniques.	Bryan McDonnel;Niklas Elmqvist	Purdue Univ., West Lafayette, IN, USA|c|;	10.1109/INFVIS.2004.12;10.1109/VISUAL.2004.95;10.1109/INFVIS.2002.1173156;10.1109/VAST.2007.4389013;10.1109/TVCG.2007.70580;10.1109/INFVIS.1998.729560;10.1109/INFVIS.1997.636792	GPU-acceleration, shader programming, interaction, high-performance visualization	
InfoVis	2009	Visual Analysis of Inter-Process Communication for Large-Scale Parallel Computing	10.1109/TVCG.2009.196	http://dx.doi.org/10.1109/TVCG.2009.196	1129	1136	J	In serial computation, program profiling is often helpful for optimization of key sections of code. When moving to parallel computation, not only does the code execution need to be considered but also communication between the different processes which can induce delays that are detrimental to performance. As the number of processes increases, so does the impact of the communication delays on performance. For large-scale parallel applications, it is critical to understand how the communication impacts performance in order to make the code more efficient. There are several tools available for visualizing program execution and communications on parallel systems. These tools generally provide either views which statistically summarize the entire program execution or process-centric views. However, process-centric visualizations do not scale well as the number of processes gets very large. In particular, the most common representation of parallel processes is a Gantt chart with a row for each process. As the number of processes increases, these charts can become difficult to work with and can even exceed screen resolution. We propose a new visualization approach that affords more scalability and then demonstrate it on systems running with up to 16,384 processes.	Chris Muelder;François Gygi;Kwan-Liu Ma	Univ. of California, Davis, CA, USA|c|;;	10.1109/INFVIS.2005.1532138;10.1109/INFVIS.2002.1173155;10.1109/INFVIS.2004.25	Information Visualization, MPI Profiling, Scalability	
InfoVis	2009	Visualizing Social Photos on a Hasse Diagram for Eliciting Relations and Indexing New Photos	10.1109/TVCG.2009.201	http://dx.doi.org/10.1109/TVCG.2009.201	985	992	J	Social photos, which are taken during family events or parties, represent individuals or groups of people. We show in this paper how a Hasse diagram is an efficient visualization strategy for eliciting different groups and navigating through them. However, we do not limit this strategy to these traditional uses. Instead we show how it can also be used for assisting in indexing new photos. Indexing consists of identifying the event and people in photos. It is an integral phase that takes place before searching and sharing. In our method we use existing indexed photos to index new photos. This is performed through a manual drag and drop procedure followed by a content fusion process that we call 'propagation'. At the core of this process is the necessity to organize and visualize the photos that will be used for indexing in a manner that is easily recognizable and accessible by the user. In this respect we make use of an object Galois sub-hierarchy and display it using a Hasse diagram. The need for an incremental display that maintains the user's mental map also leads us to propose a novel way of building the Hasse diagram. To validate the approach, we present some tests conducted with a sample of users that confirm the interest of this organization, visualization and indexation approach. Finally, we conclude by considering scalability, the possibility to extract social networks and automatically create personalised albums.	Michel Crampes;Jeremy de Oliveira-Kumar;Sylvie Ranwez;Jean Villerd	LGI2P/EMA Res. Center, France|c|;;;		Information visualization, Hasse Diagram, indexation, social photos, formal concept analysis, Galois sub-hierarchy	
InfoVis	2009	Visualizing the Intellectual Structure with Paper-Reference Matrices	10.1109/TVCG.2009.202	http://dx.doi.org/10.1109/TVCG.2009.202	1153	1160	J	Visualizing the intellectual structure of scientific domains using co-cited units such as references or authors has become a routine for domain analysis. In previous studies, paper-reference matrices are usually transformed into reference-reference matrices to obtain co-citation relationships, which are then visualized in different representations, typically as node-link networks, to represent the intellectual structures of scientific domains. Such network visualizations sometimes contain tightly knit components, which make visual analysis of the intellectual structure a challenging task. In this study, we propose a new approach to reveal co-citation relationships. Instead of using a reference-reference matrix, we directly use the original paper-reference matrix as the information source, and transform the paper-reference matrix into an FP-tree and visualize it in a Java-based prototype system. We demonstrate the usefulness of our approach through visual analyses of the intellectual structure of two domains: information visualization and Sloan Digital Sky Survey (SDSS). The results show that our visualization not only retains the major information of co-citation relationships, but also reveals more detailed sub-structures of tightly knit clusters than a conventional node-link network visualization.	Jian Zhang 0006;Chaomei Chen;Jiexun Li	Drexel Univ., Philadelphia, PA, USA|c|;;	10.1109/INFVIS.2000.885091;10.1109/TVCG.2008.172;10.1109/TVCG.2008.135;10.1109/TVCG.2008.121;10.1109/INFVIS.2004.43;10.1109/TVCG.2008.130;10.1109/VISUAL.1991.175815	Intellectual Structure, Paper-reference Matrix, FP-tree, Co-citation	
VAST	2009	Merging visual analysis with automated reasoning: Using Prajna to solve the traffic challenge	10.1109/VAST.2009.5332481	http://dx.doi.org/10.1109/VAST.2009.5332481			M	The Internet traffic challenge required the development of a custom application to analyze internet traffic patterns coupled with building access records. To solve this challenge, the author applied the Prajna Project, an open-source Java toolkit designed to provide various capabilities for visualization, knowledge representation, semantic reasoning, and data fusion. By applying some of the capabilities of Prajna to this challenge, the author could quickly develop a custom application for visual analysis. The author determined that he could solve some of the analytical components of this challenge using automated reasoning techniques. Prajna includes interfaces to incorporate automated reasoners into visual applications. By blending the automated reasoning processes with visual analysis, the author could design a flexible, useful application to solve this challenge.	Edward Swing	Vision Syst. & Technol., Inc., NJ, USA|c|			
VAST	2009	Professional analysts using a large, high-resolution display	10.1109/VAST.2009.5332485	http://dx.doi.org/10.1109/VAST.2009.5332485			M	Professional cyber analysts were observed as they attempted to solve the VAST 2009 Traffic Mini Challenge using basic visualization tools and a large, high-resolution display. We discuss some of the lessons we learned about how analysts actually work and potential roles for visualization and large, high-resolution displays.	Alex Endert;Christopher Andrews;Glenn A. Fink;Chris North	Virginia Polytech. Inst. & State Univ., Blacksburg, VA, USA|c|;;;			
VAST	2009	Interactive visual clustering of large collections of trajectories	10.1109/VAST.2009.5332584	http://dx.doi.org/10.1109/VAST.2009.5332584	3	10	C	One of the most common operations in exploration and analysis of various kinds of data is clustering, i.e. discovery and interpretation of groups of objects having similar properties and/or behaviors. In clustering, objects are often treated as points in multi-dimensional space of properties. However, structurally complex objects, such as trajectories of moving entities and other kinds of spatio-temporal data, cannot be adequately represented in this manner. Such data require sophisticated and computationally intensive clustering algorithms, which are very hard to scale effectively to large datasets not fitting in the computer main memory. We propose an approach to extracting meaningful clusters from large databases by combining clustering and classification, which are driven by a human analyst through an interactive visual interface.	Gennady L. Andrienko;Natalia V. Andrienko;Salvatore Rinzivillo;Mirco Nanni;Dino Pedreschi;Fosca Giannotti	Fraunhofer Inst. IAIS (Intell. Anal. & Inf. Syst.), St. Augustin, Germany|c|;;;;;	10.1109/VAST.2008.4677356;10.1109/VAST.2007.4388999	Spatio-temporal data, movement data, trajectories, clustering, classification, scalable visualization, geovisualization	
VAST	2009	Guided analysis of hurricane trends using statistical processes integrated with interactive parallel coordinates	10.1109/VAST.2009.5332586	http://dx.doi.org/10.1109/VAST.2009.5332586	19	26	C	This paper demonstrates the promise of augmenting interactive multivariate representations with information from statistical processes in the domain of weather data analysis. Statistical regression, correlation analysis, and descriptive statistical calculations are integrated via graphical indicators into an enhanced parallel coordinates system, called the Multidimensional Data eXplorer (MDX). These statistical indicators, which highlight significant associations in the data, are complemented with interactive visual analysis capabilities. The resulting system allows a smooth, interactive, and highly visual workflow. The system's utility is demonstrated with an extensive hurricane climate study that was conducted by a hurricane expert. In the study, the expert used a new data set of environmental weather data, composed of 28 independent variables, to predict annual hurricane activity. MDX shows the Atlantic Meridional Mode increases the explained variance of hurricane seasonal activity by 7-15% and removes less significant variables used in earlier studies. The findings and feedback from the expert (1) validate the utility of the data set for hurricane prediction, and (2) indicate that the integration of statistical processes with interactive parallel coordinates, as implemented in MDX, addresses both deficiencies in traditional weather data analysis and exhibits some of the expected benefits of visual data analysis.	Chad A. Steed;J. Edward Swan II;T. J. Jankun-Kelly;Patrick J. Fitzpatrick	Naval Res. Lab., Orlando, FL, USA|c|;;;	10.1109/TVCG.2007.70523;10.1109/INFVIS.2005.1532138;10.1109/VAST.2006.261452;10.1109/INFVIS.2004.68;10.1109/VISUAL.1995.485139;10.1109/INFVIS.2002.1173157;10.1109/VISUAL.1999.809866;10.1109/TVCG.2006.170	Climate study, multivariate data, correlation, regression, interaction, statistical analysis, visual analytics	
VAST	2009	Proximity-based visualization of movement trace data	10.1109/VAST.2009.5332593	http://dx.doi.org/10.1109/VAST.2009.5332593	11	18	C	The increasing availability of motion sensors and video cameras in living spaces has made possible the analysis of motion patterns and collective behavior in a number of situations. The visualization of this movement data, however, remains a challenge. Although maintaining the actual layout of the data space is often desirable, direct visualization of movement traces becomes cluttered and confusing as the spatial distribution of traces may be disparate and uneven. We present proximity-based visualization as a novel approach to the visualization of movement traces in an abstract space rather than the given spatial layout. This abstract space is obtained by considering proximity data, which is computed as the distance between entities and some number of important locations. These important locations can range from a single fixed point, to a moving point, several points, or even the proximities between the entities themselves. This creates a continuum of proximity spaces, ranging from the fixed absolute reference frame to completely relative reference frames. By combining these abstracted views with the concrete spatial views, we provide a way to mentally map the abstract spaces back to the real space. We demonstrate the effectiveness of this approach, and its applicability to visual analytics problems such as hazard prevention, migration patterns, and behavioral studies.	Tarik Crnovrsanin;Chris Muelder;Carlos D. Correa;Kwan-Liu Ma	Univ. of California, Davis, CA, USA|c|;;;	10.1109/INFVIS.2004.27;10.1109/VISUAL.1990.146402;10.1109/TVCG.2007.70621;10.1109/TVCG.2007.70558	Spatio-temporal visualization, proximity, linked views, principal component analysis, temporal trajectories, movement patterns	
VAST	2009	Finding comparable temporal categorical records: A similarity measure with an interactive visualization	10.1109/VAST.2009.5332595	http://dx.doi.org/10.1109/VAST.2009.5332595	27	34	C	An increasing number of temporal categorical databases are being collected: Electronic Health Records in healthcare organizations, traffic incident logs in transportation systems, or student records in universities. Finding similar records within these large databases requires effective similarity measures that capture the searcher's intent. Many similarity measures exist for numerical time series, but temporal categorical records are different. We propose a temporal categorical similarity measure, the M&M (Match & Mismatch) measure, which is based on the concept of aligning records by sentinel events, then matching events between the target and the compared records. The M&M measure combines the time differences between pairs of events and the number of mismatches. To accom-modate customization of parameters in the M&M measure and results interpretation, we implemented Similan, an interactive search and visualization tool for temporal categorical records. A usability study with 8 participants demonstrated that Similan was easy to learn and enabled them to find similar records, but users had difficulty understanding the M&M measure. The usability study feedback, led to an improved version with a continuous timeline, which was tested in a pilot study with 5 participants.	Krist Wongsuphasawat;Ben Shneiderman	Dept. of Comput. Sci. & Human-Comput. Interaction Lab., Univ. of Maryland, College Park, MD, USA|c|;	10.1109/VAST.2006.261421	Similan, M&M Measure, Similarity Search, Temporal Categorical Records	
VAST	2009	A visual analytics system for radio frequency fingerprinting-based localization	10.1109/VAST.2009.5332596	http://dx.doi.org/10.1109/VAST.2009.5332596	35	42	C	Radio frequency (RF) fingerprinting-based techniques for localization are a promising approach for ubiquitous positioning systems, particularly indoors. By finding unique fingerprints of RF signals received at different locations within a predefined area beforehand, whenever a similar fingerprint is subsequently seen again, the localization system will be able to infer a user's current location. However, developers of these systems face the problem of finding reliable RF fingerprints that are unique enough and adequately stable over time. We present a visual analytics system that enables developers of these localization systems to visually gain insight on whether their collected datasets and chosen fingerprint features have the necessary properties to enable a reliable RF fingerprinting-based localization system. The system was evaluated by testing and debugging an existing localization system.	Yi Han;Erich P. Stuntebeck;John T. Stasko;Gregory D. Abowd	Sch. of Interactive Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;;;	10.1109/INFVIS.1997.636793	 	
VAST	2009	Geovisual analytics for self-organizing network data	10.1109/VAST.2009.5332610	http://dx.doi.org/10.1109/VAST.2009.5332610	43	50	C	Cellular radio networks are continually growing in both node count and complexity. It therefore becomes more difficult to manage the networks and necessary to use time and cost effective automatic algorithms to organize the networks neighbor cell relations. There have been a number of attempts to develop such automatic algorithms. Network operators, however, may not trust them because they need to have an understanding of their behavior and of their reliability and performance, which is not easily perceived. This paper presents a novel Web-enabled geovisual analytics approach to exploration and understanding of self-organizing network data related to cells and neighbor cell relations. A demonstrator and case study are presented in this paper, developed in close collaboration with the Swedish telecom company Ericsson and based on large multivariate, time-varying and geospatial data provided by the company. It allows the operators to follow, interact with and analyze the evolution of a self-organizing network and enhance their understanding of how an automatic algorithm configures locally-unique physical cell identities and organizes neighbor cell relations of the network. The geovisual analytics tool is tested with a self-organizing network that is operated by the automatic neighbor relations (ANR) algorithm. The demonstrator has been tested with positive results by a group of domain experts from Ericsson and will be tested in production.	Ho Van Quan;Tobias Åström;Mikael Jern	Dept. of Sci. & Technol., Linkoping Univ., Linkoping, Sweden|c|;;	10.1109/VISUAL.1999.809930	Geovisual analytics, visualization, self-organizing network, multi-layer, multi-dimensional, time-varying, geospatial data sets	
VAST	2009	A framework for uncertainty-aware visual analytics	10.1109/VAST.2009.5332611	http://dx.doi.org/10.1109/VAST.2009.5332611	51	58	C	Visual analytics has become an important tool for gaining insight on large and complex collections of data. Numerous statistical tools and data transformations, such as projections, binning and clustering, have been coupled with visualization to help analysts understand data better and faster. However, data is inherently uncertain, due to error, noise or unreliable sources. When making decisions based on uncertain data, it is important to quantify and present to the analyst both the aggregated uncertainty of the results and the impact of the sources of that uncertainty. In this paper, we present a new framework to support uncertainty in the visual analytics process, through statistic methods such as uncertainty modeling, propagation and aggregation. We show that data transformations, such as regression, principal component analysis and k-means clustering, can be adapted to account for uncertainty. This framework leads to better visualizations that improve the decision-making process and help analysts gain insight on the analytic process itself.	Carlos D. Correa;Yu-Hsuan Chan;Kwan-Liu Ma	Univ. of California at Davis, Davis, CA, USA|c|;;	10.1109/VAST.2008.4677368;10.1109/VAST.2007.4389000	Uncertainty, Data Transformations, Principal Component Analysis, Model fitting	
VAST	2009	Combining automated analysis and visualization techniques for effective exploration of high-dimensional data	10.1109/VAST.2009.5332628	http://dx.doi.org/10.1109/VAST.2009.5332628	59	66	C	Visual exploration of multivariate data typically requires projection onto lower-dimensional representations. The number of possible representations grows rapidly with the number of dimensions, and manual exploration quickly becomes ineffective or even unfeasible. This paper proposes automatic analysis methods to extract potentially relevant visual structures from a set of candidate visualizations. Based on features, the visualizations are ranked in accordance with a specified user task. The user is provided with a manageable number of potentially useful candidate visualizations, which can be used as a starting point for interactive data analysis. This can effectively ease the task of finding truly useful visualizations and potentially speed up the data exploration task. In this paper, we present ranking measures for class-based as well as non class-based Scatterplots and Parallel Coordinates visualizations. The proposed analysis methods are evaluated on different datasets.	Andrada Tatu;Georgia Albuquerque;Martin Eisemann;Jörn Schneidewind;Holger Theisel;Marcus A. Magnor;Daniel A. Keim	Univ. of Konstanz, Konstanz, Germany|c|;;;;;;	10.1109/INFVIS.2005.1532142;10.1109/INFVIS.1998.729559;10.1109/INFVIS.2003.1249017;10.1109/VISUAL.1994.346302;10.1109/VAST.2006.261423	 	
VAST	2009	Two-stage framework for visualization of clustered high dimensional data	10.1109/VAST.2009.5332629	http://dx.doi.org/10.1109/VAST.2009.5332629	67	74	C	In this paper, we discuss dimension reduction methods for 2D visualization of high dimensional clustered data. We propose a two-stage framework for visualizing such data based on dimension reduction methods. In the first stage, we obtain the reduced dimensional data by applying a supervised dimension reduction method such as linear discriminant analysis which preserves the original cluster structure in terms of its criteria. The resulting optimal reduced dimension depends on the optimization criteria and is often larger than 2. In the second stage, the dimension is further reduced to 2 for visualization purposes by another dimension reduction method such as principal component analysis. The role of the second-stage is to minimize the loss of information due to reducing the dimension all the way to 2. Using this framework, we propose several two-stage methods, and present their theoretical characteristics as well as experimental comparisons on both artificial and real-world text data sets.	Jaegul Choo;Shawn Bohn;Haesun Park	Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;;	10.1109/INFVIS.2003.1249017	dimension reduction, linear discriminant analysis, principal component analysis, orthogonal centroid method, 2D projection, clustered data, regularization, generalized singular value decomposition	
VAST	2009	Capturing and supporting the analysis process	10.1109/VAST.2009.5333020	http://dx.doi.org/10.1109/VAST.2009.5333020	131	138	C	Visual analytics tools provide powerful visual representations in order to support the sense-making process. In this process, analysts typically iterate through sequences of steps many times, varying parameters each time. Few visual analytics tools support this process well, nor do they provide support for visualizing and understanding the analysis process itself. To help analysts understand, explore, reference, and reuse their analysis process, we present a visual analytics system named CzSaw (See-Saw) that provides an editable and re-playable history navigation channel in addition to multiple visual representations of document collections and the entities within them (in a manner inspired by Jigsaw). Conventional history navigation tools range from basic undo and redo to branching timelines of user actions. In CzSaw's approach to this, first, user interactions are translated into a script language that drives the underlying scripting-driven propagation system. The latter allows analysts to edit analysis steps, and ultimately to program them. Second, on this base, we build both a history view showing progress and alternative paths, and a dependency graph showing the underlying logic of the analysis and dependency relations among the results of each step. These tools result in a visual model of the sense-making process, providing a way for analysts to visualize their analysis process, to reinterpret the problem, explore alternative paths, extract analysis patterns from existing history, and reuse them with other related analyses.	Nazanin Kadivar;Victor Y. Chen;Dustin Dunsmuir;Eric Lee;Cheryl Z. Qian;John Dill;Chris Shaw 0002;Robert F. Woodbury	Sch. of Interactive Arts & Technol., Simon Fraser Univ., Burnaby, BC, Canada|c|;;;;;;;	10.1109/INFVIS.2005.1532136;10.1109/VAST.2008.4677362;10.1109/VAST.2007.4388992;10.1109/TVCG.2008.137;10.1109/VAST.2007.4389006;10.1109/VAST.2008.4677365;10.1109/INFVIS.2004.2;10.1109/VAST.2007.4389002;10.1109/TVCG.2007.70515;10.1109/VAST.2007.4389001	Visual Analytics, Sense-making, Analysis Process, Visual History	
VAST	2009	Connecting the dots in visual analysis	10.1109/VAST.2009.5333023	http://dx.doi.org/10.1109/VAST.2009.5333023	123	130	C	During visual analysis, users must often connect insights discovered at various points of time. This process is often called ldquoconnecting the dots.rdquo When analysts interactively explore complex datasets over multiple sessions, they may uncover a large number of findings. As a result, it is often difficult for them to recall the past insights, views and concepts that are most relevant to their current line of inquiry. This challenge is even more difficult during collaborative analysis tasks where they need to find connections between their own discoveries and insights found by others. In this paper, we describe a context-based retrieval algorithm to identify notes, views and concepts from users' past analyses that are most relevant to a view or a note based on their line of inquiry. We then describe a related notes recommendation feature that surfaces the most relevant items to the user as they work based on this algorithm. We have implemented this recommendation feature in HARVEST, a Web based visual analytic system. We evaluate the related notes recommendation feature of HARVEST through a case study and discuss the implications of our approach.	Yedendra Babu Shrinivasan;David Gotz;Jie Lu	Eindhoven Univ. of Technol., Eindhoven, Netherlands|c|;;	10.1109/VAST.2008.4677362;10.1109/VAST.2007.4389006;10.1109/VAST.2007.4389011;10.1109/VAST.2006.261432;10.1109/VAST.2008.4677365		
VAST	2009	Interactive poster: Interactive multiobjective optimization - a new application area for visual analytics	10.1109/VAST.2009.5333081	http://dx.doi.org/10.1109/VAST.2009.5333081	237	238	M	The poster introduces interactive multiobjective optimization (IMO) as a field offering new application possibilities and challenges for visual analytics (VA), and aims at inspiring collaboration between the two fields. Our aim is to collect new ideas in order to be able to utilize VA techniques more effectively in our user interface development. Simulation-based IMO methods are developed for complex problem solving, where the expert decision maker (analyst) should be supported during the iterative process of eliciting preference information and examining the resulting output data. IMO is a subfield of multiple criteria decision making (MCDM). In simulation-based IMO, the optimization task is formulated in a mathematical model containing several conflicting objectives and constraints depending on decision variables. While using IMO methods the analyst progressively provides preference information in order to find the most satisfactory compromise between the conflicting objectives. In the poster, the implementations of two new IMO methods are used as examples to demonstrate concrete challenges of interaction design. One of them is described in this summary.	Suvi Tarkkanen;Kaisa Miettinen;Jussi Hakanen	Dept. of Math. Inf. Technol., Univ. of Jyvaskyla, Jyvaskyla, Finland|c|;;			
VAST	2009	Poster: Icexplorer: Studying Great Lakes Ice cover	10.1109/VAST.2009.5333082	http://dx.doi.org/10.1109/VAST.2009.5333082	239	240	M	IceXplorer is a tool for analyzing variations in ice cover on Lake Erie. It enhances the data and pre-packaged analysis currently available in the great lakes ice atlas and serves as an example of a small, focused application where simple but carefully-chosen visualizations, interaction techniques, and automated data analysis are combined to create an effective tool for advancing scientific research.	Stina S. Bridgeman	Hobart & William Smith Colleges, Hobart, IN, USA|c|			
VAST	2009	Articulate: a conversational interface for visual analytics	10.1109/VAST.2009.5333099	http://dx.doi.org/10.1109/VAST.2009.5333099	233	234	M	While many visualization tools exist that offer sophisticated functions for charting complex data, they still expect users to possess a high degree of expertise in wielding the tools to create an effective visualization. This poster presents Articulate, an attempt at a semi-automated visual analytic model that is guided by a conversational user interface. The goal is to relieve the user of the physical burden of having to directly craft a visualization through the manipulation of a complex user-interface, by instead being able to verbally articulate what the user wants to see, and then using natural language processing and heuristics to semi-automatically create a suitable visualization.	Yiwen Sun;Jason Leigh;Andrew E. Johnson;Dennis Chau	Electron. Visualization Lab., Univ. of Illinois at Chicago, Chicago, IL, USA|c|;;;			
VAST	2009	VAST contest dataset use in education	10.1109/VAST.2009.5333245	http://dx.doi.org/10.1109/VAST.2009.5333245	115	122	C	The IEEE Visual Analytics Science and Technology (VAST) Symposium has held a contest each year since its inception in 2006. These events are designed to provide visual analytics researchers and developers with analytic challenges similar to those encountered by professional information analysts. The VAST contest has had an extended life outside of the symposium, however, as materials are being used in universities and other educational settings, either to help teachers of visual analytics-related classes or for student projects. We describe how we develop VAST contest datasets that results in products that can be used in different settings and review some specific examples of the adoption of the VAST contest materials in the classroom. The examples are drawn from graduate and undergraduate courses at Virginia Tech and from the Visual Analytics ldquoSummer Camprdquo run by the National Visualization and Analytics Center in 2008. We finish with a brief discussion on evaluation metrics for education.	Mark A. Whiting;Chris North;Alex Endert;Jean Scholtz;Jereme Haack;Carrie Varley;James J. Thomas	;;;;;;	10.1109/VAST.2006.261416	education, evaluation, synthetic data	
VAST	2009	What's being said near "Martha"? Exploring name entities in literary text collections	10.1109/VAST.2009.5333248	http://dx.doi.org/10.1109/VAST.2009.5333248	107	114	C	A common task in literary analysis is to study characters in a novel or collection. Automatic entity extraction, text analysis and effective user interfaces facilitate character analysis. Using our interface, called POSvis, the scholar uses word clouds and self-organizing graphs to review vocabulary, to filter by part of speech, and to explore the network of characters located near characters under review. Further, visualizations show word usages within an analysis window (i.e. a book chapter), which can be compared with a reference window (i.e. the whole book). We describe the interface and report on an early case study with a humanities scholar.	Romain Vuillemot;Tanya E. Clement;Catherine Plaisant;Amit Kumar	Univ. de Lyon, Lyon, France|c|;;;	10.1109/TVCG.2008.172;10.1109/TVCG.2007.70577;10.1109/VAST.2008.4677359;10.1109/VAST.2007.4389004;10.1109/VAST.2007.4389006	Visual Analytics, Design, Experimentation, Human Factors	
VAST	2009	BEADS: High dimensional data cluster visualization	10.1109/VAST.2009.5333417	http://dx.doi.org/10.1109/VAST.2009.5333417	235	236	M	In this poster paper, we present BEADS, a high dimensional data cluster visualization by having a 2-D representation of shape and spread of the cluster. The Cluster Division component, the Bead Shape Identification and Cluster Shape Composition form the core of the system. BEADS visualization consists of a 2-D plot, standard 2-D shapes which are used as metaphors to represent corresponding high-dimensional shapes of beads. The final resulting images convey the relative placement of beads with respect to the cluster center, the shape of the beads. We give a textual summary of the beads and their 2-D placement on the Beads plot in tabular format along with the image.	Soujanya Vadapalli;Kamalakar Karlapalem	Centre for Data Eng., Int. Inst. of Inf. Technol.-Hyderabad, Hyderabad, India|c|;			
VAST	2009	Poster: Visual prediction of time series	10.1109/VAST.2009.5333420	http://dx.doi.org/10.1109/VAST.2009.5333420	229	230	M	Many well-known time series prediction methods have been used daily by analysts making decisions. To reach a good prediction, we introduce several new visual analysis techniques of smoothing, multi-scaling, and weighted average with the involvement of human expert knowledge. We combine them into a well-fitted method to perform prediction. We have applied this approach to predict resource consumption in data center for next day planning.	Ming C. Hao;Halldór Janetzko;Ratnesh K. Sharma;Umeshwar Dayal;Daniel A. Keim;Malú Castellanos	Hewlett-Packard Labs., Palo Alto, CA, USA|c|;;;;;			
VAST	2009	ProcessLine: Visualizing time-series data in process industry	10.1109/VAST.2009.5333421	http://dx.doi.org/10.1109/VAST.2009.5333421	231	232	M	In modern process industry, it is often difficult to analyze a manufacture process due to its numerous time-series data. Analysts wish to not only interpret the evolution of data over time in a working procedure, but also examine the changes in the whole production process through time. To meet such analytic requirements, we have developed ProcessLine, an interactive visualization tool for a large amount of time-series data in process industry. The data are displayed in a fisheye timeline. ProcessLine provides good overviews for the whole production process and details for the focused working procedure. A preliminary user study using beer industry production data has shown that the tool is effective.	XiongFei Luo;Hongan Wang;Feng Tian;Wei Liu 0023;Dongxing Teng;Guozhong Dai	Chinese Acad. of Sci., Grad. Univ., Beijing, China|c|;;;;;			
VAST	2009	LSAView: A tool for visual exploration of latent semantic modeling	10.1109/VAST.2009.5333428	http://dx.doi.org/10.1109/VAST.2009.5333428	83	90	C	Latent Semantic Analysis (LSA) is a commonly-used method for automated processing, modeling, and analysis of unstructured text data. One of the biggest challenges in using LSA is determining the appropriate model parameters to use for different data domains and types of analyses. Although automated methods have been developed to make rank and scaling parameter choices, these approaches often make choices with respect to noise in the data, without an understanding of how those choices impact analysis and problem solving. Further, no tools currently exist to explore the relationships between an LSA model and analysis methods. Our work focuses on how parameter choices impact analysis and problem solving. In this paper, we present LSAView, a system for interactively exploring parameter choices for LSA models. We illustrate the use of LSAView's small multiple views, linked matrix-graph views, and data views to analyze parameter selection and application in the context of graph layout and clustering.	Patricia Crossno;Daniel M. Dunlavy;Timothy M. Shead	Sandia Nat. Labs., Albuquerque, NM, USA|c|;;			
VAST	2009	Model space visualization for multivariate linear trend discovery	10.1109/VAST.2009.5333431	http://dx.doi.org/10.1109/VAST.2009.5333431	75	82	C	Discovering and extracting linear trends and correlations in datasets is very important for analysts to understand multivariate phenomena. However, current widely used multivariate visualization techniques, such as parallel coordinates and scatterplot matrices, fail to reveal and illustrate such linear relationships intuitively, especially when more than 3 variables are involved or multiple trends coexist in the dataset. We present a novel multivariate model parameter space visualization system that helps analysts discover single and multiple linear patterns and extract subsets of data that fit a model well. Using this system, analysts are able to explore and navigate in model parameter space, interactively select and tune patterns, and refine the model for accuracy using computational techniques. We build connections between model space and data space visually, allowing analysts to employ their domain knowledge during exploration to better interpret the patterns they discover and their validity. Case studies with real datasets are used to investigate the effectiveness of the visualizations.	Zhenyu Guo;Matthew O. Ward;Elke A. Rundensteiner	Comput. Sci. Dept., Worcester Polytech. Inst., Worcester, MA, USA|c|;;	10.1109/VAST.2008.4677350;10.1109/VAST.2007.4389000;10.1109/VAST.2008.4677363;10.1109/VAST.2007.4388999;10.1109/VISUAL.1990.146402;10.1109/VAST.2008.4677352;10.1109/VAST.2008.4677368	Knowledge Discovery, visual analysis, multivariate linear model construction, model space visualization	
VAST	2009	Reordered tilebars for visual text exploration	10.1109/VAST.2009.5333436	http://dx.doi.org/10.1109/VAST.2009.5333436	225	226	M	The classic TileBars paradigm has been used to show distribution information of query terms in full-text documents. However, when the number of query terms becomes large, it is not an easy task for users to comprehend their distribution within certain parts of a document. In this paper, we present a novel approach to improve the visual presentation of TileBars, in which barycenter heuristic for bigraph crossing minimization is used to reorder TileBars elements. The reordered TileBars can be demonstrated to provide users with better focus and navigation while exploring text documents.	VinhTuan Thai;Siegfried Handschuh	Digital Enterprise Res. Inst., Nat. Univ. of Ireland, Galway, Ireland|c|;			
VAST	2009	Describing story evolution from dynamic information streams	10.1109/VAST.2009.5333437	http://dx.doi.org/10.1109/VAST.2009.5333437	99	106	C	Sources of streaming information, such as news syndicates, publish information continuously. Information portals and news aggregators list the latest information from around the world enabling information consumers to easily identify events in the past 24 hours. The volume and velocity of these streams causes information from prior days to quickly vanish despite its utility in providing an informative context for interpreting new information. Few capabilities exist to support an individual attempting to identify or understand trends and changes from streaming information over time. The burden of retaining prior information and integrating with the new is left to the skills, determination, and discipline of each individual. In this paper we present a visual analytics system for linking essential content from information streams over time into dynamic stories that develop and change over multiple days. We describe particular challenges to the analysis of streaming information and present a fundamental visual representation for showing story change and evolution over time.	Stuart J. Rose;Scott Butner;Wendy Cowley;Michelle L. Gregory;Julia Walker	Pacific Northwest Nat. Lab., Richland, WA, USA|c|;;;;	10.1109/INFVIS.2000.885098;10.1109/INFVIS.2005.1532133		
VAST	2009	Visual knowledge exploration and discovery from different points of view	10.1109/VAST.2009.5333438	http://dx.doi.org/10.1109/VAST.2009.5333438	227	228	M	Complex scenario analysis requires the exploration of multiple hypotheses and supporting evidence for each argument posed. Knowledge-intensive organisations typically analyse large amounts of inter-related, heterogeneous data to retrieve the knowledge this contains and use it to support effective decision-making. We demonstrate the use of interactive graph visualisation to support hierarchical, task-driven, hypothesis investigation. The visual investigative analysis is guided by task and domain ontologies used to capture the structure of the investigation process and the experience gained and knowledge created in previous, related investigations.	Aba-Sah Dadzie;Daniela Petrelli	Dept. of Inf. Studies, Univ. of Sheffield, Sheffield, UK|c|;			
VAST	2009	Parallel Tag Clouds to explore and analyze faceted text corpora	10.1109/VAST.2009.5333443	http://dx.doi.org/10.1109/VAST.2009.5333443	91	98	C	Do court cases differ from place to place? What kind of picture do we get by looking at a country's collection of law cases? We introduce parallel tag clouds: a new way to visualize differences amongst facets of very large metadata-rich text corpora. We have pointed parallel tag clouds at a collection of over 600,000 US Circuit Court decisions spanning a period of 50 years and have discovered regional as well as linguistic differences between courts. The visualization technique combines graphical elements from parallel coordinates and traditional tag clouds to provide rich overviews of a document collection while acting as an entry point for exploration of individual texts. We augment basic parallel tag clouds with a details-in-context display and an option to visualize changes over a second facet of the data, such as time. We also address text mining challenges such as selecting the best words to visualize, and how to do so in reasonable time periods to maintain interactivity.	Christopher Collins;Fernanda B. Viégas;Martin Wattenberg	Univ. of Toronto, Toronto, ON, Canada|c|;;	10.1109/INFVIS.1995.528686;10.1109/TVCG.2007.70589;10.1109/TVCG.2008.175;10.1109/TVCG.2008.172;10.1109/VAST.2007.4389006;10.1109/TVCG.2006.166	Text visualization, corpus visualization, information retrieval, text mining, tag clouds	
VAST	2009	A scalable architecture for visual data exploration	10.1109/VAST.2009.5333451	http://dx.doi.org/10.1109/VAST.2009.5333451	221	222	M	Intelligence analysts in the areas of defense and homeland security are now faced with the difficult problem of discerning the relevant details amidst massive data stores. We propose a component-based visualization architecture that is built specifically to encourage the flexible exploration of geospatial event databases. The proposed system is designed to deploy on a variety of display layouts, from a single laptop screen to a multi-monitor tiled-display. By utilizing a combination of parallel coordinates, principal components plots, and other data views, analysts may reduce the dimensionality of a data set to its most salient features. Of particular value to our target applications are understanding correlations between data layers, both within a single view and across multiple views. Our proposed system aims to address the limited scalability associated with coordinated multiple views (CMVs) through the implementation of an efficient core application which is extensible by the end-user.	Jonathan W. Decker;Alex Godwin;Mark A. Livingston;Denise Royle	;;;			
VAST	2009	Interactive visual analysis of location reporting patterns	10.1109/VAST.2009.5333453	http://dx.doi.org/10.1109/VAST.2009.5333453	223	224	M	Interactive visualization methods are often used to aid in the analysis of large datasets. We present a novel interactive visualization technique designed specifically for the analysis of location reporting patterns within large time-series datasets. We use a set of triangles with color coding to indicate the time between location reports. This allows reporting patterns (expected and unexpected) to be easily discerned during interactive analysis. We discuss the details of our method and describe evaluation both from expert opinion and from a user study.	Derek Overby;John Keyser;Jim Wall	Dept. of Comput. Sci. & Eng., Texas A&M Univ., College Station, TX, USA|c|;;			
VAST	2009	Working memory load as a novel tool for evaluating visual analytics	10.1109/VAST.2009.5333468	http://dx.doi.org/10.1109/VAST.2009.5333468	217	218	M	The current visual analytics literature highlights design and evaluation processes that are highly variable and situation dependent, which raises at least two broad challenges. First, lack of a standardized evaluation criterion leads to costly re-designs for each task and specific user community. Second, this inadequacy in criterion validation raises significant uncertainty regarding visualization outputs and their related decisions, which may be especially troubling in high consequence environments like those of the intelligence community. As an attempt to standardize the ldquoapples and orangesrdquo of the extant situation, we propose the creation of standardized evaluation tools using general principles of human cognition. Theoretically, visual analytics enables the user to see information in a way that should attenuate the user's memory load and increase the user's task-available cognitive resources. By using general cognitive abilities like available working memory resources as our dependent measures, we propose to develop standardized evaluative capabilities that can be generalized across contexts, tasks, and user communities.	Courtney C. Dornburg;Laura E. Matzen;Travis L. Bauer;Laura A. McNamara	Sandia Nat. Labs., Albuquerque, NM, USA|c|;;;			
VAST	2009	Comparing two interface tools in performing visual analytics tasks	10.1109/VAST.2009.5333469	http://dx.doi.org/10.1109/VAST.2009.5333469	219	220	M	In visual analytics, menu systems are commonly adopted as supporting tools because of the complex nature of data. However, it is still unknown how much the interaction implicit to the interface impacts the performance of visual analysis. To show the effectiveness of two interface tools, one a floating text-based menu (Floating Menu) and the other a more interactive iconic tool (Interactive-Icon), we evaluated the use and human performance of both tools within one highly interactive visual analytics system. We asked participants to answer similarly constructed, straightforward questions in a genomic visualization, first with one tool, and then the other. During task performance we tracked completion times, task errors, and captured coarse-grained interactive behaviors. Based on the participants accuracy, speed, behaviors and post-task qualitative feedback, we observed that although the Interactive-Icon tool supports continuous interactions, task-oriented user evaluation did not find a significant difference between the two tools because there is a familiarity effect on the performance of solving the task questions with using Floating-Menu interface tool.	Dong Hyun Jeong;Tera Marie Green;William Ribarsky;Remco Chang	Charlotte Visualization Center, UNC Charlotte, Charlotte, NC, USA|c|;;;			
VAST	2009	Analysis of community-contributed space- and time-referenced data (example of flickr and panoramio photos)	10.1109/VAST.2009.5333472	http://dx.doi.org/10.1109/VAST.2009.5333472	213	214	M	Space- and time-referenced data published on the Web by general people can be viewed in a dual way: as independent spatio-temporal events and as trajectories of people in the geographical space. These two views suppose different approaches to the analysis, which can yield different kinds of valuable knowledge about places and about people. We define possible types of analysis tasks related to the two views of the data and present several analysis methods appropriate for these tasks. The methods are suited to large amounts of the data.	Gennady L. Andrienko;Natalia V. Andrienko;Peter Bak;Slava Kisilevich;Daniel A. Keim	Fraunhofer Inst. IAIS, Univ. of Bonn, Bonn, Germany|c|;;;;			
VAST	2009	Interactive poster: A proposal for sharing user requirements for visual analytic tools	10.1109/VAST.2009.5333474	http://dx.doi.org/10.1109/VAST.2009.5333474	215	216	M	Although many in the community have advocated user-centered evaluations for visual analytic environments, a significant barrier exists. The users targeted by the visual analytics community (law enforcement personnel, professional information analysts, financial analysts, health care analysts, etc.) are often inaccessible to researchers. These analysts are extremely busy and their work environments and data are often classified or at least confidential. Furthermore, their tasks often last weeks or even months. It is simply not feasible to do such long-term observations to understand their jobs. How then can we hope to gather enough information about the diverse user populations to understand their needs? Some researchers, including the author, have been successful in getting access to specific end-users. A reasonable approach, therefore, would be to find a way to share user information. This work outlines a proposal for developing a handbook of user profiles for use by researchers, developers, and evaluators.	Jean Scholtz	Pacific Northwest Nat. Lab., Rockaway Beach, OR, USA|c|			
VAST	2009	Iterative integration of visual insights during patent search and analysis	10.1109/VAST.2009.5333564	http://dx.doi.org/10.1109/VAST.2009.5333564	203	210	C	Patents are an important economic factor in todays globalized markets. Therefore, the analysis of patent information has become an inevitable task for a variety of interest groups. The retrieval of relevant patent information is an integral part of almost every patent analysis scenario. Unfortunately, the complexity of patent material inhibits a straightforward retrieval of all relevant patent documents and leads to iterative, time-consuming approaches in practice. With `PatViz', a new system for interactive analysis of patent information has been developed to leverage iterative query refinement. PatViz supports users in building complex queries visually and in exploring patent result sets interactively. Thereby, the visual query module introduces an abstraction layer that provides uniform access to different retrieval systems and relieves users of the burden to learn different complex query languages. By establishing an integrated environment it allows for interactive reintegration of insights gained from visual result set exploration into the visual query representation. We expect that the approach we have taken is also suitable to improve iterative query refinement in other Visual Analytics systems.	Steffen Koch;Harald Bosch;Mark Giereth;Thomas Ertl	Visualization & Interactive Syst. Group, Univ. Stuttgart, Stuttgart, Germany|c|;;;	10.1109/INFVIS.2000.885086;10.1109/VAST.2007.4389009;10.1109/VAST.2007.4389006	Patent retrieval, information visualization, visual analytics, multiple coordinated views	
VAST	2009	Evaluating visual analytics systems for investigative analysis: Deriving design principles from a case study	10.1109/VAST.2009.5333878	http://dx.doi.org/10.1109/VAST.2009.5333878	139	146	C	Despite the growing number of systems providing visual analytic support for investigative analysis, few empirical studies of the potential benefits of such systems have been conducted, particularly controlled, comparative evaluations. Determining how such systems foster insight and sensemaking is important for their continued growth and study, however. Furthermore, studies that identify how people use such systems and why they benefit (or not) can help inform the design of new systems in this area. We conducted an evaluation of the visual analytics system Jigsaw employed in a small investigative sensemaking exercise, and we compared its use to three other more traditional methods of analysis. Sixteen participants performed a simulated intelligence analysis task under one of the four conditions. Experimental results suggest that Jigsaw assisted participants to analyze the data and identify an embedded threat. We describe different analysis strategies used by study participants and how computational support (or the lack thereof) influenced the strategies. We then illustrate several characteristics of the sensemaking process identified in the study and provide design implications for investigative analysis tools based thereon. We conclude with recommendations for metrics and techniques for evaluating other visual analytics investigative analysis tools.	Youn ah Kang;Carsten Görg;John T. Stasko	GVU Center, Georgia Inst. of Technol., Atlanta, GA, USA|c|;;	10.1109/VAST.2008.4677362;10.1109/VAST.2008.4677360;10.1109/VAST.2006.261416;10.1109/VAST.2007.4389006;10.1109/VAST.2008.4677358		
VAST	2009	A multi-level middle-out cross-zooming approach for large graph analytics	10.1109/VAST.2009.5333880	http://dx.doi.org/10.1109/VAST.2009.5333880	147	154	C	This paper presents a working graph analytics model that embraces the strengths of the traditional top-down and bottom-up approaches with a resilient crossover concept to exploit the vast middle-ground information overlooked by the two extreme analytical approaches. Our graph analytics model is co-developed by users and researchers, who carefully studied the functional requirements that reflect the critical thinking and interaction pattern of a real-life intelligence analyst. To evaluate the model, we implement a system prototype, known as GreenHornet, which allows our analysts to test the theory in practice, identify the technological and usage-related gaps in the model, and then adapt the new technology in their work space. The paper describes the implementation of GreenHornet and compares its strengths and weaknesses against the other prevailing models and tools.	Pak Chung Wong;Patrick Mackey;Kristin A. Cook;Randall M. Rohrer;Harlan Foote;Mark A. Whiting	Pacific Northwest Nat. Lab., Richland, WA, USA|c|;;;;;	10.1109/VAST.2007.4389006;10.1109/INFVIS.2004.43;10.1109/INFVIS.2004.66;10.1109/TVCG.2007.70582	Graph analytics, information visualization	
VAST	2009	Visual analysis of graphs with multiple connected components	10.1109/VAST.2009.5333893	http://dx.doi.org/10.1109/VAST.2009.5333893	155	162	C	In this paper, we present a system for the interactive visualization and exploration of graphs with many weakly connected components. The visualization of large graphs has recently received much research attention. However, specific systems for visual analysis of graph data sets consisting of many components are rare. In our approach, we rely on graph clustering using an extensive set of topology descriptors. Specifically, we use the self-organizing-map algorithm in conjunction with a user-adaptable combination of graph features for clustering of graphs. It offers insight into the overall structure of the data set. The clustering output is presented in a grid containing clusters of the connected components of the input graph. Interactive feature selection and task-tailored data views allow the exploration of the whole graph space. The system provides also tools for assessment and display of cluster quality. We demonstrate the usefulness of our system by application to a shareholder network analysis problem based on a large real-world data set. While so far our approach is applied to weighted directed graphs only, it can be used for various graph types.	Tatiana von Landesberger;Melanie Görner;Tobias Schreck	Interactive Graphics Syst. Group, Tech. Univ. Darmstadt, Darmstadt, Germany|c|;;	10.1109/TVCG.2006.193;10.1109/TVCG.2008.135;10.1109/INFVIS.2003.1249011;10.1109/TVCG.2006.147		
VAST	2009	MassVis: Visual analysis of protein complexes using mass spectrometry	10.1109/VAST.2009.5333895	http://dx.doi.org/10.1109/VAST.2009.5333895	163	170	C	Protein complexes are formed when two or more proteins non-covalently interact to form a larger three dimensional structure with specific biological function. Understanding the composition of such complexes is vital to understanding cell biology at the molecular level. MassVis is a visual analysis tool designed to assist the interpretation of data from a new workflow for detecting the composition of such protein complexes in biological samples. The data generated by the laboratory workflow naturally lends itself to a scatter plot visualization. However, characteristics of this data give rise to some unique aspects not typical of a standard scatter plot. We are able to take the output from tandem mass spectrometry and render the data in such a way that it mimics more traditional two-dimensional gel techniques and at the same time reveals the correlated behavior indicative of protein complexes. By computationally measuring these correlated patterns in the data, membership in putative complexes can be inferred. User interactions are provided to support both an interactive discovery mode as well as an unsupervised clustering of likely complexes. The specific analysis tasks led us to design a unique arrangement of item selection and coordinated detail views in order to simultaneously view different aspects of the selected item.	Robert Kincaid;Kurt Dejgaard	;	10.1109/VISUAL.2005.1532827;10.1109/VISUAL.2005.1532828;10.1109/VAST.2007.4389006	information visualization, visual analysis, correlation analysis, mass spectrometry, proteomics, interactome	
VAST	2009	SpRay: A visual analytics approach for gene expression data	10.1109/VAST.2009.5333911	http://dx.doi.org/10.1109/VAST.2009.5333911	179	186	C	We present a new application, SpRay, designed for the visual exploration of gene expression data. It is based on an extension and adaption of parallel coordinates to support the visual exploration of large and high-dimensional datasets. In particular, we investigate the visual analysis of gene expression data as generated by micro-array experiments; We combine refined visual exploration with statistical methods to a visual analytics approach that proved to be particularly successful in this application domain. We will demonstrate the usefulness on several multidimensional gene expression datasets from different bioinformatics applications.	Janko Dietzsch;Julian Heinrich;Kay Nieselt;Dirk Bartz	ZBIT, Univ. of Tubingen, Tubingen, Germany|c|;;;	10.1109/VISUAL.2005.1532828;10.1109/INFVIS.2004.68;10.1109/VISUAL.2004.82;10.1109/TVCG.2006.138;10.1109/TVCG.2006.170;10.1109/INFVIS.2005.1532138	Visual analytics, bioinformatics, gene expression experiments, microarray data, large-scale microarray	
VAST	2009	Using projection and 2D plots to visually reveal genetic mechanisms of complex human disorders	10.1109/VAST.2009.5333917	http://dx.doi.org/10.1109/VAST.2009.5333917	171	178	C	Gene mapping is a statistical method used to localize human disease genes to particular regions of the human genome. When performing such analysis, a genetic likelihood space is generated and sampled, which results in a multidimensional scalar field. Researchers are interested in exploring this likelihood space through the use of visualization. Previous efforts at visualizing this space, though, were slow and cumbersome, only showing a small portion of the space at a time, thus requiring the user to keep a mental picture of several views. We have developed a new technique that displays much more data at once by projecting the multidimensional data into several 2D plots. One plot is created for each parameter that shows the change along that parameter. A radial projection is used to create another plot that provides an overview of the high dimensional surface from the perspective of a single point. Linking and brushing between all the plots are used to determine relationships between parameters. We demonstrate our techniques on real world autism data, showing how to visually examine features of the high dimensional space.	Boonthanome Nouanesengsy;Sang-Cheol Seok;Han-Wei Shen;Veronica J. Vieland	Battelle Center for Math. Med., Ohio State Univ., Columbus, OH, USA|c|;;;	10.1109/VISUAL.1993.398859	Visualization, Multidimensional data, Linkage Analysis, Posterior Probability of Linkage, PPL, PPLD, LD analysis, Linkage disequilibrium, Autism	
VAST	2009	Visual opinion analysis of customer feedback data	10.1109/VAST.2009.5333919	http://dx.doi.org/10.1109/VAST.2009.5333919	187	194	C	Today, online stores collect a lot of customer feedback in the form of surveys, reviews, and comments. This feedback is categorized and in some cases responded to, but in general it is underutilized - even though customer satisfaction is essential to the success of their business. In this paper, we introduce several new techniques to interactively analyze customer comments and ratings to determine the positive and negative opinions expressed by the customers. First, we introduce a new discrimination-based technique to automatically extract the terms that are the subject of the positive or negative opinion (such as price or customer service) and that are frequently commented on. Second, we derive a Reverse-Distance-Weighting method to map the attributes to the related positive and negative opinions in the text. Third, the resulting high-dimensional feature vectors are visualized in a new summary representation that provides a quick overview. We also cluster the reviews according to the similarity of the comments. Special thumbnails are used to provide insight into the composition of the clusters and their relationship. In addition, an interactive circular correlation map is provided to allow analysts to detect the relationships of the comments to other important attributes and the scores. We have applied these techniques to customer comments from real-world online stores and product reviews from web sites to identify the strength and problems of different products and services, and show the potential of our technique.	Daniela Oelke;Ming C. Hao;Christian Rohrdantz;Daniel A. Keim;Umeshwar Dayal;Lars-Erik Haug;Halldór Janetzko	Univ. of Konstanz, Konstanz, Germany|c|;;;;;;		Visual Opinion Analysis, Visual Sentiment Analysis, Visual Document Analysis, Attribute Extraction	
VAST	2009	finVis: Applied visual analytics for personal financial planning	10.1109/VAST.2009.5333920	http://dx.doi.org/10.1109/VAST.2009.5333920	195	202	C	FinVis is a visual analytics tool that allows the non-expert casual user to interpret the return, risk and correlation aspects of financial data and make personal finance decisions. This interactive exploratory tool helps the casual decision-maker quickly choose between various financial portfolio options and view possible outcomes. FinVis allows for exploration of inter-temporal data to analyze outcomes of short-term or long-term investment decisions. FinVis helps the user overcome cognitive limitations and understand the impact of correlation between financial instruments in order to reap the benefits of portfolio diversification. Because this software is accessible by non-expert users, decision-makers from the general population can benefit greatly from using FinVis in practical applications. We quantify the value of FinVis using experimental economics methods and find that subjects using the FinVis software make better financial portfolio decisions as compared to subjects using a tabular version with the same information. We also find that FinVis engages the user, which results in greater exploration of the dataset and increased learning as compared to a tabular display. Further, participants using FinVis reported increased confidence in financial decision-making and noted that they were likely to use this tool in practical application.	Stephen Rudolph;Anya Samak;David S. Ebert	Purdue Univ. Regional Visualization & Analytics Center (PURVAC), West Lafayette, IN, USA|c|;;	10.1109/INFVIS.2000.885098;10.1109/INFVIS.1997.636789;10.1109/TVCG.2007.70541;10.1109/INFVIS.2001.963273;10.1109/TVCG.2007.70589;10.1109/TVCG.2007.70577;10.1109/VAST.2008.4677363;10.1109/INFVIS.2003.1249027	Casual Information Visualization, visual analytics, personal finance, visualization of risk, economic decision-making	
VAST	2009	VIScover: Visualizing, exploring, and analysing structured data	10.1109/VAST.2009.5333946	http://dx.doi.org/10.1109/VAST.2009.5333946			M	Today's challenging task in intelligent data processing is not to store large volumes of interlinked data but to visualize, explore, and understand its explicit or implicit relationships. Our solution to this is the VIScover system. VIScover combines semantic technologies with interactive exploration and visualization techniques able to analyze large volumes of structured data. We briefly describe our VIScover system and show its potential using the example of the VAST 2009 social network and geospatial data set.	Thorsten Liebig;Olaf Noppens;Friedrich W. von Henke	derivo GmbH, Ulm Univ., Ulm, Germany|c|;;			
VAST	2009	VIDI surveillance - embassy monitoring and oversight system	10.1109/VAST.2009.5333950	http://dx.doi.org/10.1109/VAST.2009.5333950			M	We hypothesized that potential spies would try to use other employees' terminals in order to not draw attention to themselves. We define one type of suspicious activity as IP use on a terminal when the owner is inside the classified area. We created a timeline visualization of IP usage, overlaid with classified area entrances and exits. The vertical axis divides the timelines into 31 rows, one for each day of the month. The horizontal axis represents the time of day from early morning to late evening. A single employee's entire month is viewed all at once using this visualization. The employee being viewed can be changed using the arrow keys. Every IP event is represented by a vertical bar positioned at the exact time of its appearance. We color the IP events by port number, which is either intranet, HTTP, tomcat, or email, and size the bar based on the outgoing data size. Whenever an employee enters the classified area, a semi-transparent yellow region is drawn until that user exits the classified area. In rare cases when the user double enters, the region is twice as opaque, and in the other rare case where a user leaves the exits without entering, a red region is drawn until the next time the employee enters. The legend key and office diagram showing the current selected employee, highlighted in red, can be seen in the top left-hand corner.	Chad Jones;Michael Ogawa;James Shearer;Anna Tikhonova;Kwan-Liu Ma	VIDI Group, Univ. of California, Davis, CA, USA|c|;;;;			
VAST	2009	Multiple step social structure analysis with Cytoscape	10.1109/VAST.2009.5333961	http://dx.doi.org/10.1109/VAST.2009.5333961			M	Cytoscape is a popular open source tool for biologists to visualize interaction networks. We find that it offers most of the desired functionality for visual analytics on graph data to guide us in the identification of the underlying social structure. We demonstrate its utility in the identification of the social structure in the VAST 2009 Flitter Mini Challenge.	Hao Zhou;Anna A. Shaverdian;H. V. Jagadish;George Michailidis	Dept. of Stat., Univ. of Michigan, Ann Arbor, MI, USA|c|;;;			
VAST	2009	Visualization of uncertainty and analysis of geographical data	10.1109/VAST.2009.5333965	http://dx.doi.org/10.1109/VAST.2009.5333965			M	A team of five worked on this challenge to identify a possible criminal structure within the Flitter social network. Initially we worked on the problem individually, deliberately not sharing any data, results or conclusions. This maximised the chances of spotting any blunders, unjustified assumptions or inferences and allowed us to triangulate any common conclusions. After an agreed period we shared our results demonstrating the visualization applications we had built and the reasoning behind our conclusions. This sharing of assumptions encouraged us to incorporate uncertainty in our visualization approaches as it became clear that there was a number of possible interpretations of the rules and assumptions governing the challenge. This summary of the work emphasises one of those applications detailing the geographic analysis and uncertainty handling of the network data.	Jo Wood;Aidan Slingsby;Naz Khalili-Shavarini;Jason Dykes;David M. Mountain	Sch. of Inf., City Univ. London, London, UK|c|;;;;			
VAST	2009	EAKOS: VAST 2009	10.1109/VAST.2009.5333967	http://dx.doi.org/10.1109/VAST.2009.5333967			M	In this article, I describe the tools and techniques used to generate competing hypotheses for the VAST 2009 Flitter mini challenge. I will describe how I approached solving the social networks and the importance of the geospatial relationships to determine that ldquoSocial Structure Form Ardquo was the best matching social network.	Lorne Leonard				
VAST	2009	Visualized subgraph search	10.1109/VAST.2009.5333968	http://dx.doi.org/10.1109/VAST.2009.5333968			M	We present a visually supported search and browsing system for network-type data, especially a novel module for subgraph search with a GUI to define subgraphs for queries. We describe how this prototype was applied for the Vast Challenge 2009, Flitter Mini Challenge.	Dóra Erdös;Zsolt Fekete;András Lukács	Data Min. & Web Search Group, Hungarian Acad. of Sci., Budapest, Hungary|c|;;			
VAST	2009	Innovative filtering techniques and customized analytics tools	10.1109/VAST.2009.5334300	http://dx.doi.org/10.1109/VAST.2009.5334300			M	The VAST 2009 Challenge consisted of three heterogeneous synthetic data sets organized into separate mini-challenges with minimal correspondence information. The challenge task was the identification of a suspected data theft from cyber and real-world traces. The grand challenge required integrating the findings from the mini challenges into a plausible, consistent scenario. A mixture of linked, customized tools based on queryable models and rapid prototyping as well as generic analysis tools (developed in-house) helped us correctly solve all of the mini challenges. A collaborative analytic process was employed to reconstruct the scenario and to propose the correct steps for the reliable identification of the criminal organization based on activity traces of its members.	Harald Bosch;Julian Heinrich;Christoph Müller 0001;Benjamin Höferlin;Guido Reina;Markus Höferlin;Michael Wörner;Steffen Koch	Visualization & Interactive Syst. Inst., Univ. Stuttgart, Stuttgart, Germany|c|;;;;;;;			
VAST	2009	VAST 2009 Traffic Mini Challenge: Intuitive analytic information presentation	10.1109/VAST.2009.5334301	http://dx.doi.org/10.1109/VAST.2009.5334301			M	As a solution to the VAST 2009 Traffic Mini Visualization Challenge, we built the Badge and Network Traffic (BNT) tool to create animations of the events taking place in the embassy. Using the embassy layout, the prox-card and web-access entries and their time-stamps, we animated color-based flagging of events. The BNT tool highlights logical anomalies occuring in the badge and network traffic data with color-coded alerts. Prior to the animated visualization, the tool analyzes data with respect to various aspects using (i) the amount of data transfers, (ii) destination IPs access patterns, (iii) employee's browsing patterns and (iv) employee's entry log into the restricted area. Any abnormality noticed is immediately reported to the user in the form of plots. In this presentation, we list out the various analyses performed and how they were utilized in the visualization. A few screenshots of the tool are provided to illustrate our analytic information presentation.	Shraddha Agrawal;Kollukuduru Sravanthi;Soujanya Vadapalli;Kamalakar Karlapalem	Centre for Data Eng., Int. Inst. of Inf. Technol., Hyderabad, India|c|;;;			
VAST	2009	Detecting and analyzing relationships among anomalies	10.1109/VAST.2009.5334426	http://dx.doi.org/10.1109/VAST.2009.5334426			M	The HRL anomaly analysis tool was developed as part of the IEEE VAST Challenge 2009. One of the tasks involved processing badge and network traffic in order to detect and identify a fictitious embassy employee suspected of leaking information. The tool is designed to assist an analyst in detecting, analyzing, and visualizing anomalies and their relationships. Two key visualizations in our submission present how we identified the suspicious traffic using network visualization and how subsequently we connected that activity to an employee using an alibi table.	David Allen;Tsai-Ching Lu;Dave Huber	;;			
VAST	2009	Integrative visual analytics for suspicious behavior detection	10.1109/VAST.2009.5334430	http://dx.doi.org/10.1109/VAST.2009.5334430			M	In the VAST Challenge 2009 suspicious behavior had to be detected applying visual analytics to heterogeneous data, such as network traffic, social network enriched with geo-spatial attributes, and finally video surveillance data. This paper describes some of the awarded parts from our solution entry.	Peter Bak;Christian Rohrdantz;Svenja Leifert;Christoph Granacher;Stefan Koch;Simon Butscher;Patrick Jungk;Daniel A. Keim	Univ. of Konstanz, Konstanz, Germany|c|;;;;;;;			
VAST	2009	VAST 2009 challenge: An insider threat	10.1109/VAST.2009.5334454	http://dx.doi.org/10.1109/VAST.2009.5334454			M	The 4th VAST Challenge centered on a cyber analytics scenario and offered three mini-challenges with datasets of badge and network traffic data, a social network including geospatial information, and security video. Teams could also enter the Grand challenge which combined all three datasets. In this paper, we summarize the dataset, the overall scenario and the questions asked in the challenges. We describe the judging process and new infrastructure developed to manage the submissions and compute accuracy measures in the social network mini challenge. We received 49 entries from 30 teams, and gave 23 different awards to a total of 16 teams.	Georges G. Grinstein;Jean Scholtz;Mark A. Whiting;Catherine Plaisant	Univ. of Massachusetts, Lowell, MA, USA|c|;;;			
VAST	2009	Solving the traffic and flitter challenges with tulip	10.1109/VAST.2009.5334456	http://dx.doi.org/10.1109/VAST.2009.5334456			M	We present our visualization systems and findings for the badge and network traffic as well as the social network and geospatial challenges of the 2009 VAST contest. The summary starts by presenting an overview of our time series encoding of badge information and network traffic. Our findings suggest that employee 30 may be of interest. In the second part of the paper, we describe our system for finding subgraphs in the social network subject to degree constraints. Subsequently, we present our most likely candidate network which is similar to scenario B.	Paolo Simonetto;Pierre-Yves Koenig;Faraz Zaidi;Daniel Archambault;Frédéric Gilbert;Trung-Tien Phan-Quang;Morgan Mathiaut;Antoine Lambert;Jonathan Dubois;Ronan Sicre;Mathieu Brulin;Rémy Vieux;Guy Melançon	LaBRI, Univ. de Bordeaux I, Bordeaux, France|c|;;;;;;;;;;;;			
VAST	2009	Timeline analysis of undercover activities VAST 2009 traffic mini challenge award: Good analytical technique	10.1109/VAST.2009.5334460	http://dx.doi.org/10.1109/VAST.2009.5334460			M	Our visualization tool for the VAST 2009 traffic mini challenge, Timeliner, visualizes badge and network traffic data together in a single timeline. The two views of per-employee and per-day with various filtering interactions enable users to analyze easily employees activities at a particular moment of interest as well as their general daily patterns. Using Timeliner, we present several hypotheses for the task at hand and their validation processes, which reveals various aspects of the data.	Jaegul Choo;Emily Fujimoto;Hanseung Lee;Pedro R. Walteros	Georgia Inst. of Technol., Atlanta, GA, USA|c|;;;			
VAST	2009	Palantir: A visualization platform for real-world analysis	10.1109/VAST.2009.5334462	http://dx.doi.org/10.1109/VAST.2009.5334462			M	Palantir is an analytic platform currently used worldwide by both governmental and financial analysts. This paper provides a brief overview of the platform, examines our 2009 IEEE VAST Challenge submission, and highlights several key analytic and visualization features we used in our analysis.	Brandon Wright;Jason Payne;Matthew Steckman;Scott Stevson	Palantir Technol., Palo Alto, CA, USA|c|;;;			
VAST	2009	Combining iterative analytical reasoning and software development using the visualization language Processing	10.1109/VAST.2009.5334463	http://dx.doi.org/10.1109/VAST.2009.5334463			M	Processing is a very powerful visualization language which combines software concepts with principles of visual form and interaction. Artists, designers and architects use it but it is also a very effective programming language in the area of visual analytics. In the following contribution Processing is utilized in order to visually analyze data provided by IEEE VAST 2009 Mini Challenge Badge and Network Traffic. The applied process is iterative and each stage of the analytical reasoning process is accompanied by customized software development. The visual model, the process and the technical solution will be briefly introduced.	Claudia Müller-Birn;Lukas Birn	;			
Vis	2009	A Novel Interface for Interactive Exploration of DTI fibers	10.1109/TVCG.2009.112	http://dx.doi.org/10.1109/TVCG.2009.112	1433	1440	J	Visual exploration is essential to the visualization and analysis of densely sampled 3D DTI fibers in biological speciments, due to the high geometric, spatial, and anatomical complexity of fiber tracts. Previous methods for DTI fiber visualization use zooming, color-mapping, selection, and abstraction to deliver the characteristics of the fibers. However, these schemes mainly focus on the optimization of visualization in the 3D space where cluttering and occlusion make grasping even a few thousand fibers difficult. This paper introduces a novel interaction method that augments the 3D visualization with a 2D representation containing a low-dimensional embedding of the DTI fibers. This embedding preserves the relationship between the fibers and removes the visual clutter that is inherent in 3D renderings of the fibers. This new interface allows the user to manipulate the DTI fibers as both 3D curves and 2D embedded points and easily compare or validate his or her results in both domains. The implementation of the framework is GPU based to achieve real-time interaction. The framework was applied to several tasks, and the results show that our method reduces the user's workload in recognizing 3D DTI fibers and permits quick and accurate DTI fiber selection.	Wei Chen;Zi'ang Ding;Song Zhang 0004;Anna MacKay-Brandt;Stephen Correia;Huamin Qu;John Allen Crow;David F. Tate;Zhicheng Yan;Qunsheng Peng	State Key Lab. of CAD & CG, Zhejiang Univ., Hangzhou, China|c|;;;;;;;;;	10.1109/TVCG.2007.70602;10.1109/TVCG.2009.141;10.1109/VISUAL.2005.1532777;10.1109/VISUAL.2003.1250413;10.1109/VISUAL.2005.1532778;10.1109/VISUAL.2005.1532779;10.1109/VISUAL.2005.1532772;10.1109/VISUAL.2003.1250379;10.1109/VISUAL.2004.30	Diffusion Tensor Imaging, fibers, fiber Clustering, Visualization Interface	
Vis	2009	A Physiologically-based Model for Simulation of Color Vision Deficiency	10.1109/TVCG.2009.113	http://dx.doi.org/10.1109/TVCG.2009.113	1291	1298	J	Color vision deficiency (CVD) affects approximately 200 million people worldwide, compromising the ability of these individuals to effectively perform color and visualization-related tasks. This has a significant impact on their private and professional lives. We present a physiologically-based model for simulating color vision. Our model is based on the stage theory of human color vision and is derived from data reported in electrophysiological studies. It is the first model to consistently handle normal color vision, anomalous trichromacy, and dichromacy in a unified way. We have validated the proposed model through an experimental evaluation involving groups of color vision deficient individuals and normal color vision ones. Our model can provide insights and feedback on how to improve visualization experiences for individuals with CVD. It also provides a framework for testing hypotheses about some aspects of the retinal photoreceptors in color vision deficient individuals.	Gustavo M. Machado;Manuel Menezes de Oliveira Neto;Leandro A. F. Fernandes	UFRGS, Porto Alegre, Brazil|c|;;	10.1109/VISUAL.1996.568118;10.1109/VISUAL.1995.480803;10.1109/TVCG.2008.112	Models of Color Vision, Color Perception, Simulation of Color Vision Deficiency, Anomalous Trichromacy, Dichromacy	
Vis	2009	A User Study to Compare Four Uncertainty Visualization Methods for 1D and 2D Datasets	10.1109/TVCG.2009.114	http://dx.doi.org/10.1109/TVCG.2009.114	1209	1218	J	Many techniques have been proposed to show uncertainty in data visualizations. However, very little is known about their effectiveness in conveying meaningful information. In this paper, we present a user study that evaluates the perception of uncertainty amongst four of the most commonly used techniques for visualizing uncertainty in one-dimensional and two-dimensional data. The techniques evaluated are traditional errorbars, scaled size of glyphs, color-mapping on glyphs, and color-mapping of uncertainty on the data surface. The study uses generated data that was designed to represent the systematic and random uncertainty components. Twenty-seven users performed two types of search tasks and two types of counting tasks on 1D and 2D datasets. The search tasks involved finding data points that were least or most uncertain. The counting tasks involved counting data features or uncertainty features. A 4 times 4 full-factorial ANOVA indicated a significant interaction between the techniques used and the type of tasks assigned for both datasets indicating that differences in performance between the four techniques depended on the type of task performed. Several one-way ANOVAs were computed to explore the simple main effects. Bonferronni's correction was used to control for the family-wise error rate for alpha-inflation. Although we did not find a consistent order among the four techniques for all the tasks, there are several findings from the study that we think are useful for uncertainty visualization design. We found a significant difference in user performance between searching for locations of high and searching for locations of low uncertainty. Errorbars consistently underperformed throughout the experiment. Scaling the size of glyphs and color-mapping of the surface performed reasonably well. The efficiency of most of these techniques were highly dependent on the tasks performed. We believe that these findings can be used in future uncertainty visualization desig- - n. In addition, the framework developed in this user study presents a structured approach to evaluate uncertainty visualization techniques, as well as provides a basis for future research in uncertainty visualization.	Jibonananda Sanyal;Song Zhang 0004;Gargi Bhattacharya;Philip Amburn;Robert J. Moorhead II	Geosystems Res. Inst., Mississippi State Univ., Starkville, MS, USA|c|;;;;	10.1109/TVCG.2007.70518;10.1109/VISUAL.1996.568105;10.1109/VISUAL.2000.885679;10.1109/INFVIS.2002.1173145;10.1109/INFVIS.2004.59;10.1109/TVCG.2007.70530	User study, uncertainty visualization	
Vis	2009	A Visual Approach to Efficient Analysis and Quantification of Ductile Iron and Reinforced Sprayed Concrete	10.1109/TVCG.2009.115	http://dx.doi.org/10.1109/TVCG.2009.115	1343	1350	J	This paper describes advanced volume visualization and quantification for applications in non-destructive testing (NDT), which results in novel and highly effective interactive workflows for NDT practitioners. We employ a visual approach to explore and quantify the features of interest, based on transfer functions in the parameter spaces of specific application scenarios. Examples are the orientations of fibres or the roundness of particles. The applicability and effectiveness of our approach is illustrated using two specific scenarios of high practical relevance. First, we discuss the analysis of Steel Fibre Reinforced Sprayed Concrete (SFRSpC). We investigate the orientations of the enclosed steel fibres and their distribution, depending on the concrete's application direction. This is a crucial step in assessing the material's behavior under mechanical stress, which is still in its infancy and therefore a hot topic in the building industry. The second application scenario is the designation of the microstructure of ductile cast irons with respect to the contained graphite. This corresponds to the requirements of the ISO standard 945-1, which deals with 2D metallographic samples. We illustrate how the necessary analysis steps can be carried out much more efficiently using our system for 3D volumes. Overall, we show that a visual approach with custom transfer functions in specific application domains offers significant benefits and has the potential of greatly improving and optimizing the workflows of domain scientists and engineers.	Laura Fritz;Markus Hadwiger;Georg Geier;Gerhard Pittino;Eduard Gröller	VRVis Res. Center, Vienna, Austria|c|;;;;	10.1109/TVCG.2008.147;10.1109/VISUAL.2003.1250418;10.1109/TVCG.2008.162;10.1109/VISUAL.2001.964519;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2007.70603	Non-Destructive Testing, Multi-Dimensional Transfer Functions, Direction Visualization, Volume Rendering	
Vis	2009	An interactive visualization tool for multi-channel confocal microscopy data in neurobiology research	10.1109/TVCG.2009.118	http://dx.doi.org/10.1109/TVCG.2009.118	1489	1496	J	Confocal microscopy is widely used in neurobiology for studying the three-dimensional structure of the nervous system. Confocal image data are often multi-channel, with each channel resulting from a different fluorescent dye or fluorescent protein; one channel may have dense data, while another has sparse; and there are often structures at several spatial scales: subneuronal domains, neurons, and large groups of neurons (brain regions). Even qualitative analysis can therefore require visualization using techniques and parameters fine-tuned to a particular dataset. Despite the plethora of volume rendering techniques that have been available for many years, the techniques standardly used in neurobiological research are somewhat rudimentary, such as looking at image slices or maximal intensity projections. Thus there is a real demand from neurobiologists, and biologists in general, for a flexible visualization tool that allows interactive visualization of multi-channel confocal data, with rapid fine-tuning of parameters to reveal the three-dimensional relationships of structures of interest. Together with neurobiologists, we have designed such a tool, choosing visualization methods to suit the characteristics of confocal data and a typical biologist's workflow. We use interactive volume rendering with intuitive settings for multidimensional transfer functions, multiple render modes and multi-views for multi-channel volume data, and embedding of polygon data into volume data for rendering and editing. As an example, we apply this tool to visualize confocal microscopy datasets of the developing zebrafish visual system.	Yong Wan;Hideo Otsuna;Chi-Bin Chien;Charles D. Hansen	Sci. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;;	10.1109/VISUAL.1999.809887;10.1109/TVCG.2006.148	Visualization, neurobiology, confocal microscopy, qualitative analysis, volume rendering	
Vis	2009	Applying Manifold Learning to Plotting Approximate Contour Trees	10.1109/TVCG.2009.119	http://dx.doi.org/10.1109/TVCG.2009.119	1185	1192	J	A contour tree is a powerful tool for delineating the topological evolution of isosurfaces of a single-valued function, and thus has been frequently used as a means of extracting features from volumes and their time-varying behaviors. Several sophisticated algorithms have been proposed for constructing contour trees while they often complicate the software implementation especially for higher-dimensional cases such as time-varying volumes. This paper presents a simple yet effective approach to plotting in 3D space, approximate contour trees from a set of scattered samples embedded in the high-dimensional space. Our main idea is to take advantage of manifold learning so that we can elongate the distribution of high-dimensional data samples to embed it into a low-dimensional space while respecting its local proximity of sample points. The contribution of this paper lies in the introduction of new distance metrics to manifold learning, which allows us to reformulate existing algorithms as a variant of currently available dimensionality reduction scheme. Efficient reduction of data sizes together with segmentation capability is also developed to equip our approach with a coarse-to-fine analysis even for large-scale datasets. Examples are provided to demonstrate that our proposed scheme can successfully traverse the features of volumes and their temporal behaviors through the constructed contour trees.	Shigeo Takahashi;Issei Fujishiro;Masato Okada	Univ. of Tokyo, Tokyo, Japan|c|;;	10.1109/VISUAL.2002.1183772;10.1109/TVCG.2007.70601;10.1109/VISUAL.2004.96;10.1109/VISUAL.2002.1183774;10.1109/VISUAL.1997.663875	Contour trees, manifold learning, time-varying volumes, high-dimensional data analysis	
Vis	2009	Automatic Transfer Function Generation Using Contour Tree Controlled Residue Flow Model and Color Harmonics	10.1109/TVCG.2009.120	http://dx.doi.org/10.1109/TVCG.2009.120	1481	1488	J	Transfer functions facilitate the volumetric data visualization by assigning optical properties to various data features and scalar values. Automation of transfer function specifications still remains a challenge in volume rendering. This paper presents an approach for automating transfer function generations by utilizing topological attributes derived from the contour tree of a volume. The contour tree acts as a visual index to volume segments, and captures associated topological attributes involved in volumetric data. A residue flow model based on Darcy's law is employed to control distributions of opacity between branches of the contour tree. Topological attributes are also used to control color selection in a perceptual color space and create harmonic color transfer functions. The generated transfer functions can depict inclusion relationship between structures and maximize opacity and color differences between them. The proposed approach allows efficient automation of transfer function generations, and exploration on the data to be carried out based on controlling of opacity residue flow rate instead of complex low-level transfer function parameter adjustments. Experiments on various data sets demonstrate the practical use of our approach in transfer function generations.	Jianlong Zhou;Masahiro Takatsuka	Sch. of Inf. Technol., Univ. of Sydney, Sydney, NSW, Australia|c|;	10.1109/VISUAL.1998.745319;10.1109/TVCG.2008.118;10.1109/VISUAL.1999.809932;10.1109/VISUAL.2003.1250414;10.1109/VISUAL.2004.96;10.1109/TVCG.2007.70591;10.1109/TVCG.2008.162;10.1109/VISUAL.2001.964519;10.1109/VISUAL.2003.1250413;10.1109/VISUAL.1997.663875;10.1109/TVCG.2006.148	Volume Rendering, Transfer Function, Contour Tree, Residue Flow, Harmonic Color	
Vis	2009	BrainGazer - Visual Queries for Neurobiology Research	10.1109/TVCG.2009.121	http://dx.doi.org/10.1109/TVCG.2009.121	1497	1504	J	Neurobiology investigates how anatomical and physiological relationships in the nervous system mediate behavior. Molecular genetic techniques, applied to species such as the common fruit fly Drosophila melanogaster, have proven to be an important tool in this research. Large databases of transgenic specimens are being built and need to be analyzed to establish models of neural information processing. In this paper we present an approach for the exploration and analysis of neural circuits based on such a database. We have designed and implemented emph{BrainGazer}, a system which integrates visualization techniques for volume data acquired through confocal microscopy as well as annotated anatomical structures with an intuitive approach for accessing the available information. We focus on the ability to visually query the data based on semantic as well as spatial relationships. Additionally, we present visualization techniques for the concurrent depiction of neurobiological volume data and geometric objects which aim to reduce visual clutter. The described system is the result of an ongoing interdisciplinary collaboration between neurobiologists and visualization researchers.	Stefan Bruckner;Veronika Soltészová;Eduard Gröller;Jirí Hladuvka;Katja Bühler;Jai Y. Yu;Barry J. Dickson	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Vienna, Austria|c|;;;;;;	10.1109/VISUAL.2004.104;10.1109/VISUAL.1990.146378;10.1109/VISUAL.2003.1250412;10.1109/TVCG.2006.197;10.1109/VISUAL.1995.485139;10.1109/VISUAL.1996.568136;10.1109/TVCG.2006.195;10.1109/VAST.2008.4677354	Biomedical visualization, neurobiology, visual queries, volume visualization	
Vis	2009	Color Seamlessness in Multi-Projector Displays Using Constrained Gamut Morphing	10.1109/TVCG.2009.124	http://dx.doi.org/10.1109/TVCG.2009.124	1317	1326	J	Multi-projector displays show significant spatial variation in 3D color gamut due to variation in the chromaticity gamuts across the projectors, vignetting effect of each projector and also overlap across adjacent projectors. In this paper we present a new constrained gamut morphing algorithm that removes all these variations and results in true color seamlessness across tiled multi-projector displays. Our color morphing algorithm adjusts the intensities of light from each pixel of each projector precisely to achieve a smooth morphing from one projector's gamut to the other's through the overlap region. This morphing is achieved by imposing precise constraints on the perceptual difference between the gamuts of two adjacent pixels. In addition, our gamut morphing assures a C1 continuity yielding visually pleasing appearance across the entire display. We demonstrate our method successfully on a planar and a curved display using both low and high-end projectors. Our approach is completely scalable, efficient and automatic. We also demonstrate the real-time performance of our image correction algorithm on GPUs for interactive applications. To the best of our knowledge, this is the first work that presents a scalable method with a strong foundation in perception and realizes, for the first time, a truly seamless display where the number of projectors cannot be deciphered.	Behzad Sajadi;Maxim Lazarov;Meenakshisundaram Gopi;Aditi Majumder	Comput. Sci. Dept., Univ. of California, Irvine, CA, USA|c|;;;	10.1109/VISUAL.2001.964508;10.1109/VISUAL.2002.1183793;10.1109/VISUAL.2000.885684;10.1109/VISUAL.1999.809883;10.1109/TVCG.2007.70586;10.1109/TVCG.2006.121	Color Calibration, Multi-Projector Displays, Tiled Displays	
Vis	2009	Coloring 3D Line fields Using Boy's Real Projective Plane Immersion	10.1109/TVCG.2009.125	http://dx.doi.org/10.1109/TVCG.2009.125	1457	1464	J	We introduce a new method for coloring 3D line fields and show results from its application in visualizing orientation in DTI brain data sets. The method uses Boy's surface, an immersion of RP2 in 3D. This coloring method is smooth and one-to-one except on a set of measure zero, the double curve of Boy's surface.	Çagatay Demiralp;John F. Hughes;David H. Laidlaw	Brown Univ., Providence, RI, USA|c|;;	10.1109/VISUAL.1994.346338;10.1109/VISUAL.1993.398867	Line field, colormapping, orientation, real projective plane, tensor field, DTI	
Vis	2009	Comparing 3D Vector field Visualization Methods: A User Study	10.1109/TVCG.2009.126	http://dx.doi.org/10.1109/TVCG.2009.126	1219	1226	J	In a user study comparing four visualization methods for three-dimensional vector data, participants used visualizations from each method to perform five simple but representative tasks: 1) determining whether a given point was a critical point, 2) determining the type of a critical point, 3) determining whether an integral curve would advect through two points, 4) determining whether swirling movement is present at a point, and 5) determining whether the vector field is moving faster at one point than another. The visualization methods were line and tube representations of integral curves with both monoscopic and stereoscopic viewing. While participants reported a preference for stereo lines, quantitative results showed performance among the tasks varied by method. Users performed all tasks better with methods that: 1) gave a clear representation with no perceived occlusion, 2) clearly visualized curve speed and direction information, and 3) provided fewer rich 3D cues (e.g., shading, polygonal arrows, overlap cues, and surface textures). These results provide quantitative support for anecdotal evidence on visualization methods. The tasks and testing framework also give a basis for comparing other visualization methods, for creating more effective methods, and for defining additional tasks to explore further the tradeoffs among the methods.	Andrew S. Forsberg;Jian Chen;David H. Laidlaw	Comput. Sci. Dept., Brown Univ., RI, USA|c|;;	10.1109/VISUAL.1996.567777;10.1109/VISUAL.2005.1532831;10.1109/VISUAL.2004.59;10.1109/VISUAL.2005.1532772	3D vector fields, visualization, user study, tubes, lines, stereoscopic and monoscopic viewing	
Vis	2009	Continuous Parallel Coordinates	10.1109/TVCG.2009.131	http://dx.doi.org/10.1109/TVCG.2009.131	1531	1538	J	Typical scientific data is represented on a grid with appropriate interpolation or approximation schemes,defined on a continuous domain. The visualization of such data in parallel coordinates may reveal patterns latently contained in the data and thus can improve the understanding of multidimensional relations. In this paper, we adopt the concept of continuous scatterplots for the visualization of spatially continuous input data to derive a density model for parallel coordinates. Based on the point-line duality between scatterplots and parallel coordinates, we propose a mathematical model that maps density from a continuous scatterplot to parallel coordinates and present different algorithms for both numerical and analytical computation of the resulting density field. In addition, we show how the 2-D model can be used to successively construct continuous parallel coordinates with an arbitrary number of dimensions. Since continuous parallel coordinates interpolate data values within grid cells, a scalable and dense visualization is achieved, which will be demonstrated for typical multi-variate scientific data.	Julian Heinrich;Daniel Weiskopf	VISUS (Visualization Res. Center), Univ. Stuttgart, Stuttgart, Germany|c|;	10.1109/TVCG.2006.168;10.1109/TVCG.2008.119;10.1109/TVCG.2008.131;10.1109/INFVIS.2005.1532139;10.1109/TVCG.2009.179;10.1109/TVCG.2006.138;10.1109/VISUAL.1990.146402;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2008.160;10.1109/INFVIS.2002.1173157;10.1109/VISUAL.1999.809866;10.1109/TVCG.2006.170;10.1109/INFVIS.2004.68	Parallel coordinates, integrating spatial and non-spatial data visualization, multi-variate visualization, interpolation	
Vis	2009	Curve-Centric Volume Reformation for Comparative Visualization	10.1109/TVCG.2009.136	http://dx.doi.org/10.1109/TVCG.2009.136	1235	1242	J	We present two visualization techniques for curve-centric volume reformation with the aim to create compelling comparative visualizations. A curve-centric volume reformation deforms a volume, with regards to a curve in space, to create a new space in which the curve evaluates to zero in two dimensions and spans its arc-length in the third. The volume surrounding the curve is deformed such that spatial neighborhood to the curve is preserved. The result of the curve-centric reformation produces images where one axis is aligned to arc-length, and thus allows researchers and practitioners to apply their arc-length parameterized data visualizations in parallel for comparison. Furthermore we show that when visualizing dense data, our technique provides an inside out projection, from the curve and out into the volume, which allows for inspection what is around the curve. Finally we demonstrate the usefulness of our techniques in the context of two application cases. We show that existing data visualizations of arc-length parameterized data can be enhanced by using our techniques, in addition to creating a new view and perspective on volumetric data around curves. Additionally we show how volumetric data can be brought into plotting environments that allow precise readouts. In the first case we inspect streamlines in a flow field around a car, and in the second we inspect seismic volumes and well logs from drilling.	Ove Daae Lampe;Carlos D. Correa;Kwan-Liu Ma;Helwig Hauser	CMR AS, Univ. of Bergen, Bergen, Norway|c|;;;	10.1109/TVCG.2006.144;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2001.964540;10.1109/VISUAL.1992.235194;10.1109/VISUAL.2003.1250353	Volume Deformation, Curve-Centric-Reformation, Comparative Visualization, Radial Ray-Casting	
Vis	2009	Decoupling Illumination from Isosurface Generation Using 4D Light Transport	10.1109/TVCG.2009.137	http://dx.doi.org/10.1109/TVCG.2009.137	1595	1602	J	One way to provide global illumination for the scientist who performs an interactive sweep through a 3D scalar dataset is to pre-compute global illumination, resample the radiance onto a 3D grid, then use it as a 3D texture. The basic approach of repeatedly extracting isosurfaces, illuminating them, and then building a 3D illumination grid suffers from the non-uniform sampling that arises from coupling the sampling of radiance with the sampling of isosurfaces. We demonstrate how the illumination step can be decoupled from the isosurface extraction step by illuminating the entire 3D scalar function as a 3-manifold in 4-dimensional space. By reformulating light transport in a higher dimension, one can sample a 3D volume without requiring the radiance samples to aggregate along individual isosurfaces in the pre-computed illumination grid.	David C. Banks;Kevin Beason	ORNL Sci. Comput. Group, Univ. of Tennessee, Knoxville, TN, USA|c|;	10.1109/TVCG.2008.108;10.1109/VISUAL.2000.885692;10.1109/VISUAL.2003.1250394	physically-based illumination, isosurface, level set, light transport	
Vis	2009	Depth-Dependent Halos: Illustrative Rendering of Dense Line Data	10.1109/TVCG.2009.138	http://dx.doi.org/10.1109/TVCG.2009.138	1299	1306	J	We present a technique for the illustrative rendering of 3D line data at interactive frame rates. We create depth-dependent halos around lines to emphasize tight line bundles while less structured lines are de-emphasized. Moreover, the depth-dependent halos combined with depth cueing via line width attenuation increase depth perception, extending techniques from sparse line rendering to the illustrative visualization of dense line data. We demonstrate how the technique can be used, in particular, for illustrating DTI fiber tracts but also show examples from gas and fluid flow simulations and mathematics as well as describe how the technique extends to point data. We report on an informal evaluation of the illustrative DTI fiber tract visualizations with domain experts in neurosurgery and tractography who commented positively about the results and suggested a number of directions for future work.	Maarten H. Everts;Henk Bekker;Jos B. T. M. Roerdink;Tobias Isenberg 0001	Univ. of Groningen, Groningen, Netherlands|c|;;;	10.1109/VISUAL.2000.885694;10.1109/TVCG.2007.70532;10.1109/TVCG.2006.172;10.1109/VISUAL.2000.885696;10.1109/VISUAL.2005.1532778;10.1109/TVCG.2006.115;10.1109/VISUAL.2005.1532859;10.1109/TVCG.2006.197;10.1109/VISUAL.2005.1532858;10.1109/TVCG.2007.70555;10.1109/VISUAL.1996.567777;10.1109/VISUAL.2004.48	Illustrative rendering and visualization, NPR, dense line data, DTI, black-and-white rendering, GPU technique	
Vis	2009	Exploring 3D DTI fiber Tracts with Linked 2D Representations	10.1109/TVCG.2009.141	http://dx.doi.org/10.1109/TVCG.2009.141	1449	1456	J	We present a visual exploration paradigm that facilitates navigation through complex fiber tracts by combining traditional 3D model viewing with lower dimensional representations. To this end, we create standard streamtube models along with two two-dimensional representations, an embedding in the plane and a hierarchical clustering tree, for a given set of fiber tracts. We then link these three representations using both interaction and color obtained by embedding fiber tracts into a perceptually uniform color space. We describe an anecdotal evaluation with neuroscientists to assess the usefulness of our method in exploring anatomical and functional structures in the brain. Expert feedback indicates that, while a standalone clinical use of the proposed method would require anatomical landmarks in the lower dimensional representations, the approach would be particularly useful in accelerating tract bundle selection. Results also suggest that combining traditional 3D model viewing with lower dimensional representations can ease navigation through the complex fiber tract models, improving exploration of the connectivity in the brain.	Radu Jianu;Çagatay Demiralp;David H. Laidlaw	Brown Univ., Providence, RI, USA|c|;;	10.1109/VISUAL.2000.885739;10.1109/VISUAL.1991.175794;10.1109/VISUAL.1996.567787;10.1109/VISUAL.2004.30;10.1109/TVCG.2009.112;10.1109/VISUAL.1994.346302;10.1109/VISUAL.2005.1532779	DTI fiber tracts, embedding, coloring, interaction	
Vis	2009	Exploring the Millennium Run - Scalable Rendering of Large-Scale Cosmological Datasets	10.1109/TVCG.2009.142	http://dx.doi.org/10.1109/TVCG.2009.142	1251	1258	J	In this paper we investigate scalability limitations in the visualization of large-scale particle-based cosmological simulations, and we present methods to reduce these limitations on current PC architectures. To minimize the amount of data to be streamed from disk to the graphics subsystem, we propose a visually continuous level-of-detail (LOD) particle representation based on a hierarchical quantization scheme for particle coordinates and rules for generating coarse particle distributions. Given the maximal world space error per level, our LOD selection technique guarantees a sub-pixel screen space error during rendering. A brick-based page-tree allows to further reduce the number of disk seek operations to be performed. Additional particle quantities like density, velocity dispersion, and radius are compressed at no visible loss using vector quantization of logarithmically encoded floating point values. By fine-grain view-frustum culling and presence acceleration in a geometry shader the required geometry throughput on the GPU can be significantly reduced. We validate the quality and scalability of our method by presenting visualizations of a particle-based cosmological dark-matter simulation exceeding 10 billion elements.	Roland Fraedrich;Jens Schneider;Rüdiger Westermann	Comput. Graphics & Visualization Group, Tech. Univ. Munchen, Munich, Germany|c|;;	10.1109/VISUAL.2003.1250404;10.1109/VISUAL.2002.1183824;10.1109/VISUAL.2003.1250404;10.1109/VISUAL.2005.1532795;10.1109/VISUAL.2003.1250385;10.1109/TVCG.2006.176;10.1109/TVCG.2007.70530;10.1109/VISUAL.1997.663888;10.1109/TVCG.2007.70526;10.1109/VISUAL.2004.112;10.1109/TVCG.2006.155	Particle Visualization, Scalability, Cosmology	
Vis	2009	Focus+Context Route Zooming and Information Overlay in 3D Urban Environments	10.1109/TVCG.2009.144	http://dx.doi.org/10.1109/TVCG.2009.144	1547	1554	J	In this paper we present a novel focus+context zooming technique, which allows users to zoom into a route and its associated landmarks in a 3D urban environment from a 45-degree bird's-eye view. Through the creative utilization of the empty space in an urban environment, our technique can informatively reveal the focus region and minimize distortions to the context buildings. We first create more empty space in the 2D map by broadening the road with an adapted seam carving algorithm. A grid-based zooming technique is then used to enlarge the landmarks to reclaim the created empty space and thus reduce distortions to the other parts. Finally,an occlusion-free route visualization scheme adaptively scales the buildings occluding the route to make the route always visible to users. Our method can be conveniently integrated into Google Earth and Virtual Earth to provide seamless route zooming and help users better explore a city and plan their tours. It can also be used in other applications such as information overlay to a virtual city.	Huamin Qu;Haomian Wang;Weiwei Cui;Yingcai Wu;Ming-Yuen Chan	Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;	10.1109/TVCG.2008.124;10.1109/TVCG.2006.163;10.1109/TVCG.2006.167;10.1109/INFVIS.1998.729558;10.1109/TVCG.2008.132	focus+context visualization, zooming, 3D virtual environment, seam carving	
Vis	2009	GL4D: A GPU-based Architecture for Interactive 4D Visualization	10.1109/TVCG.2009.147	http://dx.doi.org/10.1109/TVCG.2009.147	1587	1594	J	This paper describes GL4D, an interactive system for visualizing 2-manifolds and 3-manifolds embedded in four Euclidean dimensions and illuminated by 4D light sources. It is a tetrahedron-based rendering pipeline that projects geometry into volume images, an exact parallel to the conventional triangle-based rendering pipeline for 3D graphics. Novel features include GPU-based algorithms for real-time 4D occlusion handling and transparency compositing; we thus enable a previously impossible level of quality and interactivity for exploring lit 4D objects. The 4D tetrahedrons are stored in GPU memory as vertex buffer objects, and the vertex shader is used to perform per-vertex 4D modelview transformations and 4D-to-3D projection. The geometry shader extension is utilized to slice the projected tetrahedrons and rasterize the slices into individual 2D layers of voxel fragments. Finally, the fragment shader performs per-voxel operations such as lighting and alpha blending with previously computed layers. We account for 4D voxel occlusion along the 4D-to-3D projection ray by supporting a multi-pass back-to-front fragment composition along the projection ray; to accomplish this, we exploit a new adaptation of the dual depth peeling technique to produce correct volume image data and to simultaneously render the resulting volume data using 3D transfer functions into the final 2D image. Previous CPU implementations of the rendering of 4D-embedded 3-manifolds could not perform either the 4D depth-buffered projection or manipulation of the volume-rendered image in real-time; in particular, the dual depth peeling algorithm is a novel GPU-based solution to the real-time 4D depth-buffering problem. GL4D is implemented as an integrated OpenGL-style API library, so that the underlying shader operations are as transparent as possible to the user.	Alan Chu;Chi-Wing Fu;Andrew J. Hanson;Pheng-Ann Heng	Chinese Univ. of Hong Kong, Hong Kong, China|c|;;;	10.1109/VISUAL.1994.346318;10.1109/VISUAL.2000.885704;10.1109/VISUAL.1992.235222;10.1109/VISUAL.2005.1532804;10.1109/TVCG.2007.70593;10.1109/VISUAL.1994.346324;10.1109/VISUAL.1993.398869	Mathematical visualization, four-dimensional visualization, graphics hardware, interactive illumination	
Vis	2009	High-Quality, Semi-Analytical Volume Rendering for AMR Data	10.1109/TVCG.2009.149	http://dx.doi.org/10.1109/TVCG.2009.149	1611	1618	J	This paper presents a pipeline for high quality volume rendering of adaptive mesh refinement (AMR) datasets. We introduce a new method allowing high quality visualization of hexahedral cells in this context; this method avoids artifacts like discontinuities in the isosurfaces. To achieve this, we choose the number and placement of sampling points over the cast rays according to the analytical properties of the reconstructed signal inside each cell. We extend our method to handle volume shading of such cells. We propose an interpolation scheme that guarantees continuity between adjacent cells of different AMR levels. We introduce an efficient hybrid CPU-GPU mesh traversal technique. We present an implementation of our AMR visualization method on current graphics hardware, and show results demonstrating both the quality and performance of our method.	Stéphane Marchesin;Guillaume Colin de Verdière	DAM, CEA, Arpajon, France|c|;	10.1109/VISUAL.2000.885683;10.1109/VISUAL.2004.85;10.1109/VISUAL.2005.1532793;10.1109/TVCG.2008.157;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2008.186	Volume rendering, AMR data, Volume shading	
Vis	2009	Hue-Preserving Color Blending	10.1109/TVCG.2009.150	http://dx.doi.org/10.1109/TVCG.2009.150	1275	1282	J	We propose a new perception-guided compositing operator for color blending. The operator maintains the same rules for achromatic compositing as standard operators (such as the over operator), but it modifies the computation of the chromatic channels. Chromatic compositing aims at preserving the hue of the input colors; color continuity is achieved by reducing the saturation of colors that are to change their hue value. The main benefit of hue preservation is that color can be used for proper visual labeling, even under the constraint of transparency rendering or image overlays. Therefore, the visualization of nominal data is improved. Hue-preserving blending can be used in any existing compositing algorithm, and it is particularly useful for volume rendering. The usefulness of hue-preserving blending and its visual characteristics are shown for several examples of volume visualization.	Johnson Chuang;Daniel Weiskopf;Torsten Möller	Simon Fraser Univ., Burnaby, BC, Canada|c|;;	10.1109/VISUAL.1996.568118;10.1109/TVCG.2008.118;10.1109/TVCG.2006.183	Image compositing, perceptual transparency, color blending, volume rendering, illustrative visualization	
Vis	2009	Interactive Coordinated Multiple-View Visualization of Biomechanical Motion Data	10.1109/TVCG.2009.152	http://dx.doi.org/10.1109/TVCG.2009.152	1383	1390	J	We present an interactive framework for exploring space-time and form-function relationships in experimentally collected high-resolution biomechanical data sets. These data describe complex 3D motions (e.g. chewing, walking, flying) performed by animals and humans and captured via high-speed imaging technologies, such as biplane fluoroscopy. In analyzing these 3D biomechanical motions, interactive 3D visualizations are important, in particular, for supporting spatial analysis. However, as researchers in information visualization have pointed out, 2D visualizations can also be effective tools for multi-dimensional data analysis, especially for identifying trends over time. Our approach, therefore, combines techniques from both 3D and 2D visualizations. Specifically, it utilizes a multi-view visualization strategy including a small multiples view of motion sequences, a parallel coordinates view, and detailed 3D inspection views. The resulting framework follows an overview first, zoom and filter, then details-on-demand style of analysis, and it explicitly targets a limitation of current tools, namely, supporting analysis and comparison at the level of a collection of motions rather than sequential analysis of a single or small number of motions. Scientific motion collections appropriate for this style of analysis exist in clinical work in orthopedics and physical rehabilitation, in the study of functional morphology within evolutionary biology, and in other contexts. An application is described based on a collaboration with evolutionary biologists studying the mechanics of chewing motions in pigs. Interactive exploration of data describing a collection of more than one hundred experimentally captured pig chewing cycles is described.	Daniel F. Keefe;Marcus Ewert;William Ribarsky;Remco Chang	Dept. of Comput. Sci. & Eng., Univ. of Minnesota, Minneapolis, MN, USA|c|;;;	10.1109/TVCG.2008.125;10.1109/TVCG.2007.70569;10.1109/TVCG.2008.109	Scientific visualization, information visualization, coordinated multiple views, biomechanics	
Vis	2009	Interactive Streak Surface Visualization on the GPU	10.1109/TVCG.2009.154	http://dx.doi.org/10.1109/TVCG.2009.154	1259	1266	J	In this paper we present techniques for the visualization of unsteady flows using streak surfaces, which allow for the first time an adaptive integration and rendering of such surfaces in real-time. The techniques consist of two main components, which are both realized on the GPU to exploit computational and bandwidth capacities for numerical particle integration and to minimize bandwidth requirements in the rendering of the surface. In the construction stage, an adaptive surface representation is generated. Surface refinement and coarsening strategies are based on local surface properties like distortion and curvature. We compare two different methods to generate a streak surface: a) by computing a patch-based surface representation that avoids any interdependence between patches, and b) by computing a particle-based surface representation including particle connectivity, and by updating this connectivity during particle refinement and coarsening. In the rendering stage, the surface is either rendered as a set of quadrilateral surface patches using high-quality point-based approaches, or a surface triangulation is built in turn from the given particle connectivity and the resulting triangle mesh is rendered. We perform a comparative study of the proposed techniques with respect to surface quality, visual quality and performance by visualizing streak surfaces in real flows using different rendering options.	Kai Bürger;Florian Ferstl;Holger Theisel;Rüdiger Westermann	Comput. Graphics & Visualization group, Tech. Univ. Munchen, Munich, Germany|c|;;;	10.1109/VISUAL.1992.235211;10.1109/VISUAL.2001.964506;10.1109/TVCG.2008.133;10.1109/VISUAL.1993.398875;10.1109/TVCG.2008.163	Unsteady flow visualization, streak surface generation, GPUs	
Vis	2009	Interactive Visual Analysis of Complex Scientific Data as Families of Data Surfaces	10.1109/TVCG.2009.155	http://dx.doi.org/10.1109/TVCG.2009.155	1351	1358	J	The widespread use of computational simulation in science and engineering provides challenging research opportunities. Multiple independent variables are considered and large and complex data are computed, especially in the case of multi-run simulation. Classical visualization techniques deal well with 2D or 3D data and also with time-dependent data. Additional independent dimensions, however, provide interesting new challenges. We present an advanced visual analysis approach that enables a thorough investigation of families of data surfaces, i.e., datasets, with respect to pairs of independent dimensions. While it is almost trivial to visualize one such data surface, the visual exploration and analysis of many such data surfaces is a grand challenge, stressing the users' perception and cognition. We propose an approach that integrates projections and aggregations of the data surfaces at different levels (one scalar aggregate per surface, a 1D profile per surface, or the surface as such). We demonstrate the necessity for a flexible visual analysis system that integrates many different (linked) views for making sense of this highly complex data. To demonstrate its usefulness, we exemplify our approach in the context of a meteorological multi-run simulation data case and in the context of the engineering domain, where our collaborators are working with the simulation of elastohydrodynamic (EHD) lubrication bearing in the automotive industry.	Kresimir Matkovic;Denis Gracanin;Borislav Klarin;Helwig Hauser	VRVis Res. Center, Vienna, Austria|c|;;;	10.1109/VISUAL.1997.663867;10.1109/TVCG.2008.145;10.1109/INFVIS.2001.963273;10.1109/TVCG.2006.170	Interactive visual analysis, family of surfaces, coordinated multiple views, multidimensional multivariate data	
Vis	2009	Interactive Visual Optimization and Analysis for RfiD Benchmarking	10.1109/TVCG.2009.156	http://dx.doi.org/10.1109/TVCG.2009.156	1335	1342	J	Radiofrequency identification (RFID) is a powerful automatic remote identification technique that has wide applications. To facilitate RFID deployment, an RFID benchmarking instrument called aGate has been invented to identify the strengths and weaknesses of different RFID technologies in various environments. However, the data acquired by aGate are usually complex time varying multidimensional 3D volumetric data, which are extremely challenging for engineers to analyze. In this paper, we introduce a set of visualization techniques, namely, parallel coordinate plots, orientation plots, a visual history mechanism, and a 3D spatial viewer, to help RFID engineers analyze benchmark data visually and intuitively. With the techniques, we further introduce two workflow procedures (a visual optimization procedure for finding the optimum reader antenna configuration and a visual analysis procedure for comparing the performance and identifying the flaws of RFID devices) for the RFID benchmarking, with focus on the performance analysis of the aGate system. The usefulness and usability of the system are demonstrated in the user evaluation.	Yingcai Wu;Ka-Kei Chung;Huamin Qu;Xiaoru Yuan;Shing-Chi Cheung	Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Kowloon, China|c|;;;;	10.1109/TVCG.2008.131;10.1109/VISUAL.1990.146402;10.1109/TVCG.2007.70535;10.1109/INFVIS.2005.1532141;10.1109/VISUAL.1996.567800;10.1109/INFVIS.2004.2	RfiD Visualization, Visual analytics, Visual Optimization	
Vis	2009	Interactive Visualization of Molecular Surface Dynamics	10.1109/TVCG.2009.157	http://dx.doi.org/10.1109/TVCG.2009.157	1391	1398	J	Molecular dynamics simulations of proteins play a growing role in various fields such as pharmaceutical, biochemical and medical research. Accordingly, the need for high quality visualization of these protein systems raises. Highly interactive visualization techniques are especially needed for the analysis of time-dependent molecular simulations. Beside various other molecular representations the surface representations are of high importance for these applications. So far, users had to accept a trade-off between rendering quality and performance - particularly when visualizing trajectories of time-dependent protein data. We present a new approach for visualizing the solvent excluded surface of proteins using a GPU ray casting technique and thus achieving interactive frame rates even for long protein trajectories where conventional methods based on precomputation are not applicable. Furthermore, we propose a semantic simplification of the raw protein data to reduce the visual complexity of the surface and thereby accelerate the rendering without impeding perception of the protein's basic shape. We also demonstrate the application of our solvent excluded surface method to visualize the spatial probability density for the protein atoms over the whole period of the trajectory in one frame, providing a qualitative analysis of the protein flexibility.	Michael Krone;Katrin Bidmon;Thomas Ertl	Visualization Res. Center VISUS, Univ. Stuttgart, Stuttgart, Germany|c|;;	10.1109/VISUAL.2004.103;10.1109/TVCG.2006.115	Point-based Data, Time-varying Data, GPU, Ray Casting, Molecular Visualization, Surface Extraction, Isosurfaces	
Vis	2009	Interactive Volume Rendering of Functional Representations in Quantum Chemistry	10.1109/TVCG.2009.158	http://dx.doi.org/10.1109/TVCG.2009.158	1579	5186	J	Simulation and computation in chemistry studies have been improved as computational power has increased over decades. Many types of chemistry simulation results are available, from atomic level bonding to volumetric representations of electron density. However, tools for the visualization of the results from quantum chemistry computations are still limited to showing atomic bonds and isosurfaces or isocontours corresponding to certain isovalues. In this work, we study the volumetric representations of the results from quantum chemistry computations, and evaluate and visualize the representations directly on the GPU without resampling the result in grid structures. Our visualization tool handles the direct evaluation of the approximated wavefunctions described as a combination of Gaussian-like primitive basis functions. For visualizations, we use a slice based volume rendering technique with a 2D transfer function, volume clipping, and illustrative rendering in order to reveal and enhance the quantum chemistry structure. Since there is no need of resampling the volume from the functional representations, two issues, data transfer and resampling resolution, can be ignored, therefore, it is possible to interactively explore large amount of different information in the computation results.	Yun Jang;Ugo Varetto	ETH Zurich, Zurich, Switzerland|c|;	10.1109/TVCG.2007.70614;10.1109/TVCG.2007.70517;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2002.1183780;10.1109/TVCG.2006.133;10.1109/VISUAL.2005.1532811;10.1109/VISUAL.2000.885694;10.1109/VISUAL.2004.23;10.1109/TVCG.2007.70578;10.1109/TVCG.2006.150;10.1109/VISUAL.2004.36;10.1109/TVCG.2006.115;10.1109/VISUAL.2005.1532858;10.1109/VISUAL.2004.103	Quantum Chemistry, GTO, Volume Rendering, GPU	
Vis	2009	Intrinsic Geometric Scale Space by Shape Diffusion	10.1109/TVCG.2009.159	http://dx.doi.org/10.1109/TVCG.2009.159	1193	1200	J	This paper formalizes a novel, intrinsic geometric scale space (IGSS) of 3D surface shapes. The intrinsic geometry of a surface is diffused by means of the Ricci flow for the generation of a geometric scale space. We rigorously prove that this multiscale shape representation satisfies the axiomatic causality property. Within the theoretical framework, we further present a feature-based shape representation derived from IGSS processing, which is shown to be theoretically plausible and practically effective. By integrating the concept of scale-dependent saliency into the shape description, this representation is not only highly descriptive of the local structures, but also exhibits several desired characteristics of global shape representations, such as being compact, robust to noise and computationally efficient. We demonstrate the capabilities of our approach through salient geometric feature detection and highly discriminative matching of 3D scans.	Guangyu Zou;Jing Hua;Zhaoqiang Lai;Xianfeng Gu;Ming Dong	Wayne State Univ., Detroit, MI, USA|c|;;;;	10.1109/TVCG.2008.134	Scale space, feature extraction, geometric flow, Riemannian manifolds	
Vis	2009	Isosurface Extraction and View-Dependent filtering from Time-Varying fields Using Persistent Time-Octree (PTOT)	10.1109/TVCG.2009.160	http://dx.doi.org/10.1109/TVCG.2009.160	1367	1374	J	We develop a new algorithm for isosurface extraction and view-dependent filtering from large time-varying fields, by using a novel persistent time-octree (PTOT) indexing structure. Previously, the persistent octree (POT) was proposed to perform isosurface extraction and view-dependent filtering, which combines the advantages of the interval tree (for optimal searches of active cells) and of the branch-on-need octree (BONO, for view-dependent filtering), but it only works for steady-state(i.e., single time step) data. For time-varying fields, a 4D version of POT, 4D-POT, was proposed for 4D isocontour slicing, where slicing on the time domain gives all active cells in the queried timestep and isovalue. However, such slicing is not output sensitive and thus the searching is sub-optimal. Moreover, it was not known how to support view-dependent filtering in addition to time-domain slicing.In this paper, we develop a novel persistent time-octree (PTOT) indexing structure, which has the advantages of POT and performs 4D isocontour slicing on the time domain with an output-sensitive and optimal searching. In addition, when we query the same iso value q over m consecutive time steps, there is no additional searching overhead (except for reporting the additional active cells) compared to querying just the first time step. Such searching performance for finding active cells is asymptotically optimal, with asymptotically optimal space and preprocessing time as well. Moreover, our PTOT supports view-dependent filtering in addition to time-domain slicing. We propose a simple and effective out-of-core scheme, where we integrate our PTOT with implicit occluders, batched occlusion queries and batched CUDA computing tasks, so that we can greatly reduce the I/O cost as well as increase the amount of data being concurrently computed in GPU.This results in an efficient algorithm for isosurface extraction with view-dependent filtering utilizing a state-of-the-art programmable GPU for ti me-varying fields larger than main memory. Our experiments on datasets as large as 192 GB (with 4 GB per time step) having no more than 870 MB of memory footprint in both preprocessing and run-time phases demonstrate the efficacy of our new technique.	Cong Wang;Yi-Jen Chiang	CSE Dept, Polytech. Inst. of New York Univ., Brooklyn, NY, USA|c|;	10.1109/VISUAL.2003.1250375;10.1109/VISUAL.1998.745299;10.1109/VISUAL.1997.663895;10.1109/VISUAL.1998.745300;10.1109/VISUAL.2003.1250373	Isosurface extraction, time-varying fields, persistent data structure, view-dependent filtering, out-of-core methods	
Vis	2009	Kd-Jump: a Path-Preserving Stackless Traversal for Faster Isosurface Raytracing on GPUs	10.1109/TVCG.2009.161	http://dx.doi.org/10.1109/TVCG.2009.161	1555	1562	J	Stackless traversal techniques are often used to circumvent memory bottlenecks by avoiding a stack and replacing return traversal with extra computation. This paper addresses whether the stackless traversal approaches are useful on newer hardware and technology (such as CUDA). To this end, we present a novel stackless approach for implicit kd-trees, which exploits the benefits of index-based node traversal, without incurring extra node visitation. This approach, which we term Kd-Jump, enables the traversal to immediately return to the next valid node, like a stack, without incurring extra node visitation (kd-restart). Also, Kd-Jump does not require global memory (stack) at all and only requires a small matrix in fast constant-memory. We report that Kd-Jump outperforms a stack by 10 to 20% and kd-restar t by 100%. We also present a Hybrid Kd-Jump, which utilizes a volume stepper for leaf testing and a run-time depth threshold to define where kd-tree traversal stops and volume-stepping occurs. By using both methods, we gain the benefits of empty space removal, fast texture-caching and realtime ability to determine the best threshold for current isosurface and view direction.	David Meirion Hughes;Ik Soo Lim	Sch. of Comput. Sci., Bangor Univ., Bangor, UK|c|;	10.1109/VISUAL.2004.48	Raytracing, isosurface, GPU, parallel computing, volume visualization	
Vis	2009	Loop surgery for volumetric meshes: Reeb graphs reduced to contour trees	10.1109/TVCG.2009.163	http://dx.doi.org/10.1109/TVCG.2009.163	1177	1184	J	This paper introduces an efficient algorithm for computing the Reeb graph of a scalar function f defined on a volumetric mesh M in Ropf3. We introduce a procedure called "loop surgery" that transforms M into a mesh M' by a sequence of cuts and guarantees the Reeb graph of f(M') to be loop free. Therefore, loop surgery reduces Reeb graph computation to the simpler problem of computing a contour tree, for which well-known algorithms exist that are theoretically efficient (O(n log n)) and fast in practice. Inverse cuts reconstruct the loops removed at the beginning. The time complexity of our algorithm is that of a contour tree computation plus a loop surgery overhead, which depends on the number of handles of the mesh. Our systematic experiments confirm that for real-life data, this overhead is comparable to the computation of the contour tree, demonstrating virtually linear scalability on meshes ranging from 70 thousand to 3.5 million tetrahedra. Performance numbers show that our algorithm, although restricted to volumetric data, has an average speedup factor of 6,500 over the previous fastest techniques, handling larger and more complex data-sets. We demonstrate the verstility of our approach by extending fast topologically clean isosurface extraction to non simply-connected domains. We apply this technique in the context of pressure analysis for mechanical design. In this case, our technique produces results in matter of seconds even for the largest meshes. For the same models, previous Reeb graph techniques do not produce a result.	Julien Tierny;Attila Gyulassy;Eddie Simon;Valerio Pascucci	Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;;	10.1109/VISUAL.2004.96;10.1109/TVCG.2007.70601;10.1109/VISUAL.1997.663875	Reeb graph, scalar field topology, isosurfaces, topological simplification	
Vis	2009	Mapping High-fidelity Volume Rendering for Medical Imaging to CPU, GPU and Many-Core Architectures	10.1109/TVCG.2009.164	http://dx.doi.org/10.1109/TVCG.2009.164	1563	1570	J	Medical volumetric imaging requires high fidelity, high performance rendering algorithms. We motivate and analyze new volumetric rendering algorithms that are suited to modern parallel processing architectures. First, we describe the three major categories of volume rendering algorithms and confirm through an imaging scientist-guided evaluation that ray-casting is the most acceptable. We describe a thread- and data-parallel implementation of ray-casting that makes it amenable to key architectural trends of three modern commodity parallel architectures: multi-core, GPU, and an upcoming many-core Intelreg architecture code-named Larrabee. We achieve more than an order of magnitude performance improvement on a number of large 3D medical datasets. We further describe a data compression scheme that significantly reduces data-transfer overhead. This allows our approach to scale well to large numbers of Larrabee cores.	Mikhail Smelyanskiy;David R. Holmes III;Jatin Chhugani;Alan Larson;Doug Carmean;Dennis P. Hanson;Pradeep Dubey;Kurt Augustine;Daehyun Kim;Alan Kyker;Victor W. Lee;Anthony D. Nguyen;Larry Seiler;Richard A. Robb	Intel Corp., Santa Clara, CA, USA|c|;;;;;;;;;;;;;	10.1109/VISUAL.2003.1250384;10.1109/VISUAL.1998.745309	Volume Compositing, Parallel Processing, Many-core Computing, Medical Imaging, Graphics Architecture, GPGPU	
Vis	2009	Markerless View-Independent Registration of Multiple Distorted Projectors on Extruded Surfaces Using an Uncalibrated Camera	10.1109/TVCG.2009.166	http://dx.doi.org/10.1109/TVCG.2009.166	1307	1316	J	In this paper, we present the first algorithm to geometrically register multiple projectors in a view-independent manner (i.e. wallpapered) on a common type of curved surface, vertically extruded surface, using an uncalibrated camera without attaching any obtrusive markers to the display screen. Further, it can also tolerate large non-linear geometric distortions in the projectors as is common when mounting short throw lenses to allow a compact set-up. Our registration achieves sub-pixel accuracy on a large number of different vertically extruded surfaces and the image correction to achieve this registration can be run in real time on the GPU. This simple markerless registration has the potential to have a large impact on easy set-up and maintenance of large curved multi-projector displays, common for visualization, edutainment, training and simulation applications.	Behzad Sajadi;Aditi Majumder	Comput. Sci. Dept., Univ. of California, Irvine, Irvine, CA, USA|c|;	10.1109/VISUAL.2001.964508;10.1109/VISUAL.2002.1183793;10.1109/VISUAL.1999.809883;10.1109/TVCG.2009.124;10.1109/TVCG.2007.70586	Registration, Calibration, Multi-Projector Displays, Tiled Displays	
Vis	2009	Multi-Scale Surface Descriptors	10.1109/TVCG.2009.168	http://dx.doi.org/10.1109/TVCG.2009.168	1201	1208	J	Local shape descriptors compactly characterize regions of a surface, and have been applied to tasks in visualization, shape matching, and analysis. Classically, curvature has be used as a shape descriptor; however, this differential property characterizes only an infinitesimal neighborhood. In this paper, we provide shape descriptors for surface meshes designed to be multi-scale, that is, capable of characterizing regions of varying size. These descriptors capture statistically the shape of a neighborhood around a central point by fitting a quadratic surface. They therefore mimic differential curvature, are efficient to compute, and encode anisotropy. We show how simple variants of mesh operations can be used to compute the descriptors without resorting to expensive parameterizations, and additionally provide a statistical approximation for reduced computational cost. We show how these descriptors apply to a number of uses in visualization, analysis, and matching of surfaces, particularly to tasks in protein surface analysis.	Gregory Cipriano;George N. Phillips Jr.;Michael Gleicher	Dept. of Comput. Sci., Univ. of Wisconsin, Madison, WI, USA|c|;;	10.1109/VISUAL.2003.1250414;10.1109/VISUAL.2002.1183787;10.1109/VISUAL.2002.1183785	Curvature, descriptors, npr, stylized rendering, shape matching	
Vis	2009	Multimodal Vessel Visualization of Mouse Aorta PET/CT Scans	10.1109/TVCG.2009.169	http://dx.doi.org/10.1109/TVCG.2009.169	1515	1522	J	In this paper, we present a visualization system for the visual analysis of PET/CT scans of aortic arches of mice. The system has been designed in close collaboration between researchers from the areas of visualization and molecular imaging with the objective to get deeper insights into the structural and molecular processes which take place during plaque development. Understanding the development of plaques might lead to a better and earlier diagnosis of cardiovascular diseases, which are still the main cause of death in the western world. After motivating our approach, we will briefly describe the multimodal data acquisition process before explaining the visualization techniques used. The main goal is to develop a system which supports visual comparison of the data of different species. Therefore, we have chosen a linked multi-view approach, which amongst others integrates a specialized straightened multipath curved planar reformation and a multimodal vessel flattening technique. We have applied the visualization concepts to multiple data sets, and we will present the results of this investigation.	Timo Ropinski;Sven Hermann;Rainer Reich;Michael Schäfers 0001;Klaus H. Hinrichs	Visualization & Comput. Graphics Res. Group (VisCG), Univ. of Munster, Munster, Germany|c|;;;;	10.1109/VISUAL.2003.1250353;10.1109/VISUAL.1992.235203;10.1109/TVCG.2007.70576;10.1109/VISUAL.2004.104;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2001.964538;10.1109/TVCG.2007.70560;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2003.1250396	Vessel visualization, plaque growth, multipath CPR, vessel flattening	
Vis	2009	Parameter Sensitivity Visualization for DTI fiber Tracking	10.1109/TVCG.2009.170	http://dx.doi.org/10.1109/TVCG.2009.170	1441	1448	J	Fiber tracking of diffusion tensor imaging (DTI) data offers a unique insight into the three-dimensional organisation of white matter structures in the living brain. However, fiber tracking algorithms require a number of user-defined input parameters that strongly affect the output results. Usually the fiber tracking parameters are set once and are then re-used for several patient datasets. However, the stability of the chosen parameters is not evaluated and a small change in the parameter values can give very different results. The user remains completely unaware of such effects. Furthermore, it is difficult to reproduce output results between different users. We propose a visualization tool that allows the user to visually explore how small variations in parameter values affect the output of fiber tracking. With this knowledge the user cannot only assess the stability of commonly used parameter values but also evaluate in a more reliable way the output results between different patients. Existing tools do not provide such information. A small user evaluation of our tool has been done to show the potential of the technique.	Ralph Brecheisen;Anna Vilanova;Bram Platel;Bart M. ter Haar Romeny	Tech. Univ. Eindhoven, Eindhoven, Netherlands|c|;;;	10.1109/TVCG.2008.147;10.1109/VISUAL.2005.1532853;10.1109/TVCG.2007.70518;10.1109/VISUAL.2005.1532778;10.1109/VISUAL.2005.1532779;10.1109/VISUAL.1996.568116;10.1109/VISUAL.1999.809894;10.1109/VISUAL.2004.30;10.1109/VISUAL.2001.964552	fiber Tracking, Parameter Sensitivity, Stopping Criteria, Diffusion Tensor Imaging, Uncertainty Visualization	
Vis	2009	Perception-Based Transparency Optimization for Direct Volume Rendering	10.1109/TVCG.2009.172	http://dx.doi.org/10.1109/TVCG.2009.172	1283	1290	J	The semi-transparent nature of direct volume rendered images is useful to depict layered structures in a volume. However, obtaining a semi-transparent result with the layers clearly revealed is difficult and may involve tedious adjustment on opacity and other rendering parameters. Furthermore, the visual quality of layers also depends on various perceptual factors. In this paper, we propose an auto-correction method for enhancing the perceived quality of the semi-transparent layers in direct volume rendered images. We introduce a suite of new measures based on psychological principles to evaluate the perceptual quality of transparent structures in the rendered images. By optimizing rendering parameters within an adaptive and intuitive user interaction process, the quality of the images is enhanced such that specific user requirements can be met. Experimental results on various datasets demonstrate the effectiveness and robustness of our method.	Ming-Yuen Chan;Yingcai Wu;Wai-Ho Mak;Wei Chen;Huamin Qu	Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;	10.1109/VISUAL.1998.745319;10.1109/VISUAL.2000.885694;10.1109/TVCG.2008.118;10.1109/VISUAL.2003.1250414;10.1109/TVCG.2007.70591;10.1109/VISUAL.2004.62;10.1109/TVCG.2008.162;10.1109/TVCG.2006.183;10.1109/TVCG.2008.159;10.1109/TVCG.2006.148	Direct volume rendering, image enhancement, layer perception	
Vis	2009	Predictor-Corrector Schemes for Visualization ofSmoothed Particle Hydrodynamics Data	10.1109/TVCG.2009.173	http://dx.doi.org/10.1109/TVCG.2009.173	1243	1250	J	In this paper we present a method for vortex core line extraction which operates directly on the smoothed particle hydrodynamics (SPH) representation and, by this, generates smoother and more (spatially and temporally) coherent results in an efficient way. The underlying predictor-corrector scheme is general enough to be applied to other line-type features and it is extendable to the extraction of surfaces such as isosurfaces or Lagrangian coherent structures. The proposed method exploits temporal coherence to speed up computation for subsequent time steps. We show how the predictor-corrector formulation can be specialized for several variants of vortex core line definitions including two recent unsteady extensions, and we contribute a theoretical and practical comparison of these. In particular, we reveal a close relation between unsteady extensions of Fuchs et al. and Weinkauf et al. and we give a proof of the Galilean invariance of the latter. When visualizing SPH data, there is the possibility to use the same interpolation method for visualization as has been used for the simulation. This is different from the case of finite volume simulation results, where it is not possible to recover from the results the spatial interpolation that was used during the simulation. Such data are typically interpolated using the basic trilinear interpolant, and if smoothness is required, some artificial processing is added. In SPH data, however, the smoothing kernels are specified from the simulation, and they provide an exact and smooth interpolation of data or gradients at arbitrary points in the domain.	Benjamin Schindler;Raphael Fuchs;John Biddiscombe;Ronald Peikert	Inst. of Visual Comput., ETH Zurich, Zurich, Switzerland|c|;;;	10.1109/VISUAL.1999.809896;10.1109/TVCG.2007.70595;10.1109/VISUAL.2005.1532851;10.1109/VISUAL.1998.745296;10.1109/VISUAL.2004.59;10.1109/TVCG.2007.70545;10.1109/TVCG.2008.164	Smoothed particle hydrodynamics, flow visualization, unsteady flow, feature extraction, vortex core lines	
Vis	2009	Quantitative Texton Sequences for Legible Bivariate Maps	10.1109/TVCG.2009.175	http://dx.doi.org/10.1109/TVCG.2009.175	1523	1530	J	Representing bivariate scalar maps is a common but difficult visualization problem. One solution has been to use two dimensional color schemes, but the results are often hard to interpret and inaccurately read. An alternative is to use a color sequence for one variable and a texture sequence for another. This has been used, for example, in geology, but much less studied than the two dimensional color scheme, although theory suggests that it should lead to easier perceptual separation of information relating to the two variables. To make a texture sequence more clearly readable the concept of the quantitative texton sequence (QTonS) is introduced. A QTonS is defined a sequence of small graphical elements, called textons, where each texton represents a different numerical value and sets of textons can be densely displayed to produce visually differentiable textures. An experiment was carried out to compare two bivariate color coding schemes with two schemes using QTonS for one bivariate map component and a color sequence for the other. Two different key designs were investigated (a key being a sequence of colors or textures used in obtaining quantitative values from a map). The first design used two separate keys, one for each dimension, in order to measure how accurately subjects could independently estimate the underlying scalar variables. The second key design was two dimensional and intended to measure the overall integral accuracy that could be obtained. The results show that the accuracy is substantially higher for the QTonS/color sequence schemes. A hypothesis that texture/color sequence combinations are better for independent judgments of mapped quantities was supported. A second experiment probed the limits of spatial resolution for QTonSs.	Colin Ware	Center for Coastal & Ocean Mapping, Univ. of New Hampshire, Durham, NH, USA|c|	10.1109/VISUAL.1995.480803;10.1109/VISUAL.1998.745292;10.1109/TVCG.2007.70623;10.1109/VISUAL.2000.885679;10.1109/VISUAL.1997.663874;10.1109/VISUAL.1990.146383	Bivariate maps, texture, texton, legibility, quantitative texton sequence, QTonS	
Vis	2009	Sampling and Visualizing Creases with Scale-Space Particles	10.1109/TVCG.2009.177	http://dx.doi.org/10.1109/TVCG.2009.177	1415	1424	J	Particle systems have gained importance as a methodology for sampling implicit surfaces and segmented objects to improve mesh generation and shape analysis. We propose that particle systems have a significantly more general role in sampling structure from unsegmented data. We describe a particle system that computes samplings of crease features (i.e. ridges and valleys, as lines or surfaces) that effectively represent many anatomical structures in scanned medical data. Because structure naturally exists at a range of sizes relative to the image resolution, computer vision has developed the theory of scale-space, which considers an n-D image as an (n + 1)-D stack of images at different blurring levels. Our scale-space particles move through continuous four-dimensional scale-space according to spatial constraints imposed by the crease features, a particle-image energy that draws particles towards scales of maximal feature strength, and an inter-particle energy that controls sampling density in space and scale. To make scale-space practical for large three-dimensional data, we present a spline-based interpolation across scale from a small number of pre-computed blurrings at optimally selected scales. The configuration of the particle system is visualized with tensor glyphs that display information about the local Hessian of the image, and the scale of the particle. We use scale-space particles to sample the complex three-dimensional branching structure of airways in lung CT, and the major white matter structures in brain DTI.	Gordon L. Kindlmann;Raúl San José Estépar;Stephen M. Smith;Carl-Fredrik Westin	Dept. of Comput. Sci., Univ. of Chicago, Chicago, IL, USA|c|;;;	10.1109/TVCG.2008.154;10.1109/VISUAL.1993.398880;10.1109/TVCG.2007.70604;10.1109/TVCG.2008.148;10.1109/VISUAL.1997.663930;10.1109/TVCG.2008.167;10.1109/VISUAL.1999.809896	Particle Systems, Crease Features, Ridge and Valley Detection, Lung CT, Diffusion Tensor MRI	
Vis	2009	Scalable and Interactive Segmentation and Visualization of Neural Processes in EM Datasets	10.1109/TVCG.2009.178	http://dx.doi.org/10.1109/TVCG.2009.178	1505	1514	J	Recent advances in scanning technology provide high resolution EM (electron microscopy) datasets that allow neuro-scientists to reconstruct complex neural connections in a nervous system. However, due to the enormous size and complexity of the resulting data, segmentation and visualization of neural processes in EM data is usually a difficult and very time-consuming task. In this paper, we present NeuroTrace, a novel EM volume segmentation and visualization system that consists of two parts: a semi-automatic multiphase level set segmentation with 3D tracking for reconstruction of neural processes, and a specialized volume rendering approach for visualization of EM volumes. It employs view-dependent on-demand filtering and evaluation of a local histogram edge metric, as well as on-the-fly interpolation and ray-casting of implicit surfaces for segmented neural structures. Both methods are implemented on the GPU for interactive performance. NeuroTrace is designed to be scalable to large datasets and data-parallel hardware architectures. A comparison of NeuroTrace with a commonly used manual EM segmentation tool shows that our interactive workflow is faster and easier to use for the reconstruction of complex neural processes.	Won-Ki Jeong;Johanna Beyer;Markus Hadwiger;Amelio Vázquez Reina;Hanspeter Pfister;Ross T. Whitaker	Sch. of Eng. & Appl. Sci., Harvard Univ., Cambridge, MA, USA|c|;;;;;	10.1109/TVCG.2008.169;10.1109/VISUAL.2003.1250357;10.1109/TVCG.2008.179;10.1109/VISUAL.1999.809912;10.1109/TVCG.2007.70532	Segmentation, neuroscience, connectome, volume rendering, implicit surface rendering, graphics hardware	
Vis	2009	Stress Tensor field Visualization for Implant Planning in Orthopedics	10.1109/TVCG.2009.184	http://dx.doi.org/10.1109/TVCG.2009.184	1399	1406	J	We demonstrate the application of advanced 3D visualization techniques to determine the optimal implant design and position in hip joint replacement planning. Our methods take as input the physiological stress distribution inside a patient's bone under load and the stress distribution inside this bone under the same load after a simulated replacement surgery. The visualization aims at showing principal stress directions and magnitudes, as well as differences in both distributions. By visualizing changes of normal and shear stresses with respect to the principal stress directions of the physiological state, a comparative analysis of the physiological stress distribution and the stress distribution with implant is provided, and the implant parameters that most closely replicate the physiological stress state in order to avoid stress shielding can be determined. Our method combines volume rendering for the visualization of stress magnitudes with the tracing of short line segments for the visualization of stress directions. To improve depth perception, transparent, shaded, and antialiased lines are rendered in correct visibility order, and they are attenuated by the volume rendering. We use a focus+context approach to visually guide the user to relevant regions in the data, and to support a detailed stress analysis in these regions while preserving spatial context information. Since all of our techniques have been realized on the GPU, they can immediately react to changes in the simulated stress tensor field and thus provide an effective means for optimal implant selection and positioning in a computational steering environment.	Christian Dick;Joachim Georgii;Rainer Burgkart;Rüdiger Westermann	Comput. Graphics & Visualization Group, Tech. Univ. Munchen, Munich, Germany|c|;;;	10.1109/VISUAL.2005.1532780;10.1109/TVCG.2006.124;10.1109/VISUAL.2003.1250379;10.1109/VISUAL.2004.80;10.1109/VISUAL.1998.745294;10.1109/TVCG.2007.70532;10.1109/VISUAL.2002.1183797;10.1109/VISUAL.1994.346326;10.1109/VISUAL.2005.1532771;10.1109/VISUAL.2002.1183798;10.1109/VISUAL.1994.346326;10.1109/VISUAL.2002.1183799;10.1109/TVCG.2006.151;10.1109/VISUAL.1998.745316	Stress Tensor fields, Biomedical Visualization, Comparative Visualization, Implant Planning, GPU Techniques	
Vis	2009	Structuring Feature Space: A Non-Parametric Method for Volumetric Transfer Function Generation	10.1109/TVCG.2009.185	http://dx.doi.org/10.1109/TVCG.2009.185	1473	1480	J	The use of multi-dimensional transfer functions for direct volume rendering has been shown to be an effective means of extracting materials and their boundaries for both scalar and multivariate data. The most common multi-dimensional transfer function consists of a two-dimensional (2D) histogram with axes representing a subset of the feature space (e.g., value vs. value gradient magnitude), with each entry in the 2D histogram being the number of voxels at a given feature space pair. Users then assign color and opacity to the voxel distributions within the given feature space through the use of interactive widgets (e.g., box, circular, triangular selection). Unfortunately, such tools lead users through a trial-and-error approach as they assess which data values within the feature space map to a given area of interest within the volumetric space. In this work, we propose the addition of non-parametric clustering within the transfer function feature space in order to extract patterns and guide transfer function generation. We apply a non-parametric kernel density estimation to group voxels of similar features within the 2D histogram. These groups are then binned and colored based on their estimated density, and the user may interactively grow and shrink the binned regions to explore feature boundaries and extract regions of interest. We also extend this scheme to temporal volumetric data in which time steps of 2D histograms are composited into a histogram volume. A three-dimensional (3D) density estimation is then applied, and users can explore regions within the feature space across time without adjusting the transfer function at each time step. Our work enables users to effectively explore the structures found within a feature space of the volume and provide a context in which the user can understand how these structures relate to their volumetric data. We provide tools for enhanced exploration and manipulation of the transfer function, and we show that the initial t ransfer function generation serves as a reasonable base for volumetric rendering, reducing the trial-and-error overhead typically found in transfer function design.	Ross Maciejewski;Insoo Woo;Wei Chen;David S. Ebert	Rendering & Perceptualization Laboaratoy, Purdue Univ., Purdue, CA, USA|c|;;;	10.1109/TVCG.2008.119;10.1109/VISUAL.1998.745319;10.1109/VISUAL.2003.1250414;10.1109/VISUAL.2003.1250371;10.1109/VISUAL.2005.1532807;10.1109/TVCG.2008.162;10.1109/VISUAL.2001.964519;10.1109/VISUAL.2003.1250413;10.1109/VISUAL.2005.1532858;10.1109/TVCG.2006.148	Volume rendering, kernel density estimation, transfer function design, temporal volume rendering	
Vis	2009	Supercubes: A High-Level Primitive for Diamond Hierarchies	10.1109/TVCG.2009.186	http://dx.doi.org/10.1109/TVCG.2009.186	1603	1610	J	Volumetric datasets are often modeled using a multiresolution approach based on a nested decomposition of the domain into a polyhedral mesh. Nested tetrahedral meshes generated through the longest edge bisection rule are commonly used to decompose regular volumetric datasets since they produce highly adaptive crack-free representations. Efficient representations for such models have been achieved by clustering the set of tetrahedra sharing a common longest edge into a structure called a diamond. The alignment and orientation of the longest edge can be used to implicitly determine the geometry of a diamond and its relations to the other diamonds within the hierarchy. We introduce the supercube as a high-level primitive within such meshes that encompasses all unique types of diamonds. A supercube is a coherent set of edges corresponding to three consecutive levels of subdivision. Diamonds are uniquely characterized by the longest edge of the tetrahedra forming them and are clustered in supercubes through the association of the longest edge of a diamond with a unique edge in a supercube. Supercubes are thus a compact and highly efficient means of associating information with a subset of the vertices, edges and tetrahedra of the meshes generated through longest edge bisection. We demonstrate the effectiveness of the supercube representation when encoding multiresolution diamond hierarchies built on a subset of the points of a regular grid. We also show how supercubes can be used to efficiently extract meshes from diamond hierarchies and to reduce the storage requirements of such variable-resolution meshes.	Kenneth Weiss;Leila De Floriani	Dept. of Comput. Sci., Univ. of Maryland, College Park, MD, USA|c|;	10.1109/VISUAL.2002.1183810;10.1109/VISUAL.2000.885681;10.1109/VISUAL.2000.885703;10.1109/VISUAL.1997.663860;10.1109/VISUAL.1997.663869	Longest edge bisection, diamonds, hierarchy of diamonds, multiresolution models, selective refinement	
Vis	2009	The Occlusion Spectrum for Volume Classification and Visualization	10.1109/TVCG.2009.189	http://dx.doi.org/10.1109/TVCG.2009.189	1465	1472	J	Despite the ever-growing improvements on graphics processing units and computational power, classifying 3D volume data remains a challenge.In this paper, we present a new method for classifying volume data based on the ambient occlusion of voxels. This information stems from the observation that most volumes of a certain type, e.g., CT, MRI or flow simulation, contain occlusion patterns that reveal the spatial structure of their materials or features. Furthermore, these patterns appear to emerge consistently for different data sets of the same type. We call this collection of patterns the occlusion spectrum of a dataset. We show that using this occlusion spectrum leads to better two-dimensional transfer functions that can help classify complex data sets in terms of the spatial relationships among features. In general, the ambient occlusion of a voxel can be interpreted as a weighted average of the intensities in a spherical neighborhood around the voxel. Different weighting schemes determine the ability to separate structures of interest in the occlusion spectrum. We present a general methodology for finding such a weighting. We show results of our approach in 3D imaging for different applications, including brain and breast tumor detection and the visualization of turbulent flow.	Carlos D. Correa;Kwan-Liu Ma	Univ. of California at Davis, Davis, CA, USA|c|;	10.1109/VISUAL.2003.1250414;10.1109/VISUAL.1999.809932;10.1109/TVCG.2008.162;10.1109/VISUAL.2001.964519;10.1109/VISUAL.2004.64;10.1109/VISUAL.2003.1250413;10.1109/TVCG.2006.115;10.1109/VISUAL.1997.663875;10.1109/TVCG.2006.148	Transfer functions, Ambient Occlusion, Volume Rendering, Interactive Classification	
Vis	2009	Time and Streak Surfaces for Flow Visualization in Large Time-Varying Data Sets	10.1109/TVCG.2009.190	http://dx.doi.org/10.1109/TVCG.2009.190	1267	1274	J	Time and streak surfaces are ideal tools to illustrate time-varying vector fields since they directly appeal to the intuition about coherently moving particles. However, efficient generation of high-quality time and streak surfaces for complex, large and time-varying vector field data has been elusive due to the computational effort involved. In this work, we propose a novel algorithm for computing such surfaces. Our approach is based on a decoupling of surface advection and surface adaptation and yields improved efficiency over other surface tracking methods, and allows us to leverage inherent parallelization opportunities in the surface advection, resulting in more rapid parallel computation. Moreover, we obtain as a result of our algorithm the entire evolution of a time or streak surface in a compact representation, allowing for interactive, high-quality rendering, visualization and exploration of the evolving surface. Finally, we discuss a number of ways to improve surface depiction through advanced rendering and texturing, while preserving interactivity, and provide a number of examples for real-world datasets and analyze the behavior of our algorithm on them.	Harinarayan Krishnan;Christoph Garth;Kenneth I. Joy	Inst. of Data Anal. & Visualization, Univ. of California, Davis, CA, USA|c|;;	10.1109/TVCG.2007.70557;10.1109/VISUAL.1992.235211;10.1109/VISUAL.1993.398875;10.1109/VISUAL.2001.964506;10.1109/TVCG.2008.163;10.1109/VISUAL.2000.885688;10.1109/TVCG.2008.133	3D vector field visualization, flow visualization, time-varying, time and streak surfaces, surface extraction	
Vis	2009	Verifiable Visualization for Isosurface Extraction	10.1109/TVCG.2009.194	http://dx.doi.org/10.1109/TVCG.2009.194	1227	1234	J	Visual representations of isosurfaces are ubiquitous in the scientific and engineering literature. In this paper, we present techniques to assess the behavior of isosurface extraction codes. Where applicable, these techniques allow us to distinguish whether anomalies in isosurface features can be attributed to the underlying physical process or to artifacts from the extraction process. Such scientific scrutiny is at the heart of verifiable visualization - subjecting visualization algorithms to the same verification process that is used in other components of the scientific pipeline. More concretely, we derive formulas for the expected order of accuracy (or convergence rate) of several isosurface features, and compare them to experimentally observed results in the selected codes. This technique is practical: in two cases, it exposed actual problems in implementations. We provide the reader with the range of responses they can expect to encounter with isosurface techniques, both under ldquonormal operating conditionsrdquo and also under adverse conditions. Armed with this information - the results of the verification process - practitioners can judiciously select the isosurface extraction technique appropriate for their problem of interest, and have confidence in its behavior.	Tiago Etiene;Carlos Eduardo Scheidegger;Luis Gustavo Nonato;Robert Michael Kirby;Cláudio T. Silva	Sch. of Comput. & Sci. Comput., Univ. of Utah, Salt Lake City, UT, USA|c|;;;;	10.1109/TVCG.2006.149;10.1109/VISUAL.1994.346331	Verification, V&V, Isosurface Extraction, Marching Cubes	
Vis	2009	VisMashup: Streamlining the Creation of Custom Visualization Applications	10.1109/TVCG.2009.195	http://dx.doi.org/10.1109/TVCG.2009.195	1539	1546	J	Visualization is essential for understanding the increasing volumes of digital data. However, the process required to create insightful visualizations is involved and time consuming. Although several visualization tools are available, including tools with sophisticated visual interfaces, they are out of reach for users who have little or no knowledge of visualization techniques and/or who do not have programming expertise. In this paper, we propose VisMashup, a new framework for streamlining the creation of customized visualization applications. Because these applications can be customized for very specific tasks, they can hide much of the complexity in a visualization specification and make it easier for users to explore visualizations by manipulating a small set of parameters. We describe the framework and how it supports the various tasks a designer needs to carry out to develop an application, from mining and exploring a set of visualization specifications (pipelines), to the creation of simplified views of the pipelines, and the automatic generation of the application and its interface. We also describe the implementation of the system and demonstrate its use in two real application scenarios.	Emanuele Santos;Lauro Didier Lins;James P. Ahrens;Juliana Freire;Cláudio T. Silva	Sci. Comput. & Imaging (SCI) Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;;;	10.1109/TVCG.2007.70584;10.1109/VISUAL.2005.1532795;10.1109/TVCG.2007.70577	Scientific Visualization, Dataflow, Visualization Systems	
Vis	2009	Visual Exploration of Climate Variability Changes Using Wavelet Analysis	10.1109/TVCG.2009.197	http://dx.doi.org/10.1109/TVCG.2009.197	1375	1382	J	Due to its nonlinear nature, the climate system shows quite high natural variability on different time scales, including multiyear oscillations such as the El Nino southern oscillation phenomenon. Beside a shift of the mean states and of extreme values of climate variables, climate change may also change the frequency or the spatial patterns of these natural climate variations. Wavelet analysis is a well established tool to investigate variability in the frequency domain. However, due to the size and complexity of the analysis results, only few time series are commonly analyzed concurrently. In this paper we will explore different techniques to visually assist the user in the analysis of variability and variability changes to allow for a holistic analysis of a global climate model data set consisting of several variables and extending over 250 years. Our new framework and data from the IPCC AR4 simulations with the coupled climate model ECHAM5/MPI-OM are used to explore the temporal evolution of El Nino due to climate change.	Heike Leitte;Michael Böttinger;Uwe Mikolajewicz;Gerik Scheuermann	Univ. of Leipzig, Leipzig, Germany|c|;;;	10.1109/TVCG.2008.116;10.1109/VISUAL.2003.1250383;10.1109/VISUAL.1997.663871	Wavelet analysis, multivariate data, time-dependent data, climate variability change visualization, El Nino	
Vis	2009	Visual Exploration of Nasal Airflow	10.1109/TVCG.2009.198	http://dx.doi.org/10.1109/TVCG.2009.198	1407	1414	J	Rhinologists are often faced with the challenge of assessing nasal breathing from a functional point of view to derive effective therapeutic interventions. While the complex nasal anatomy can be revealed by visual inspection and medical imaging, only vague information is available regarding the nasal airflow itself: Rhinomanometry delivers rather unspecific integral information on the pressure gradient as well as on total flow and nasal flow resistance. In this article we demonstrate how the understanding of physiological nasal breathing can be improved by simulating and visually analyzing nasal airflow, based on an anatomically correct model of the upper human respiratory tract. In particular we demonstrate how various information visualization (InfoVis) techniques, such as a highly scalable implementation of parallel coordinates, time series visualizations, as well as unstructured grid multi-volume rendering, all integrated within a multiple linked views framework, can be utilized to gain a deeper understanding of nasal breathing. Evaluation is accomplished by visual exploration of spatio-temporal airflow characteristics that include not only information on flow features but also on accompanying quantities such as temperature and humidity. To our knowledge, this is the first in-depth visual exploration of the physiological function of the nose over several simulated breathing cycles under consideration of a complete model of the nasal airways, realistic boundary conditions, and all physically relevant time-varying quantities.	Stefan Zachow;Philipp Muigg;Thomas Hildebrandt;Helmut Doleisch;Hans-Christian Hege	Zuse Inst. Berlin (ZIB), Berlin, Germany|c|;;;;	10.1109/TVCG.2008.139;10.1109/TVCG.2007.70588;10.1109/VISUAL.2003.1250390;10.1109/VISUAL.2000.885739;10.1109/VISUAL.1990.146402;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2006.170	Flow visualization, exploratory data analysis, interactive visual analysis of scientific data, time-dependent data	
Vis	2009	Visual Human+Machine Learning	10.1109/TVCG.2009.199	http://dx.doi.org/10.1109/TVCG.2009.199	1327	1334	J	In this paper we describe a novel method to integrate interactive visual analysis and machine learning to support the insight generation of the user. The suggested approach combines the vast search and processing power of the computer with the superior reasoning and pattern recognition capabilities of the human user. An evolutionary search algorithm has been adapted to assist in the fuzzy logic formalization of hypotheses that aim at explaining features inside multivariate, volumetric data. Up to now, users solely rely on their knowledge and expertise when looking for explanatory theories. However, it often remains unclear whether the selected attribute ranges represent the real explanation for the feature of interest. Other selections hidden in the large number of data variables could potentially lead to similar features. Moreover, as simulation complexity grows, users are confronted with huge multidimensional data sets making it almost impossible to find meaningful hypotheses at all. We propose an interactive cycle of knowledge-based analysis and automatic hypothesis generation. Starting from initial hypotheses, created with linking and brushing, the user steers a heuristic search algorithm to look for alternative or related hypotheses. The results are analyzed in information visualization views that are linked to the volume rendering. Individual properties as well as global aggregates are visually presented to provide insight into the most relevant aspects of the generated hypotheses. This novel approach becomes computationally feasible due to a GPU implementation of the time-critical parts in the algorithm. A thorough evaluation of search times and noise sensitivity as well as a case study on data from the automotive domain substantiate the usefulness of the suggested approach.	Raphael Fuchs;Jürgen Waser;Eduard Gröller	ETH Zurich, Zurich, Switzerland|c|;;	10.1109/TVCG.2007.70615;10.1109/TVCG.2008.139;10.1109/VAST.2007.4389001;10.1109/VAST.2007.4389000	Interactive Visual Analysis, Volumetric Data, Multiple Competing Hypotheses, Knowledge Discovery, Computerassisted Multivariate Data Exploration, Curse of Dimensionality, Predictive Analysis, Genetic Algorithm	
Vis	2009	Visualization and Exploration of Temporal Trend Relationships in Multivariate Time-Varying Data	10.1109/TVCG.2009.200	http://dx.doi.org/10.1109/TVCG.2009.200	1359	1366	J	We present a new algorithm to explore and visualize multivariate time-varying data sets. We identify important trend relationships among the variables based on how the values of the variables change over time and how those changes are related to each other in different spatial regions and time intervals. The trend relationships can be used to describe the correlation and causal effects among the different variables. To identify the temporal trends from a local region, we design a new algorithm called SUBDTW to estimate when a trend appears and vanishes in a given time series. Based on the beginning and ending times of the trends, their temporal relationships can be modeled as a state machine representing the trend sequence. Since a scientific data set usually contains millions of data points, we propose an algorithm to extract important trend relationships in linear time complexity. We design novel user interfaces to explore the trend relationships, to visualize their temporal characteristics, and to display their spatial distributions. We use several scientific data sets to test our algorithm and demonstrate its utilities.	Teng-Yok Lee;Han-Wei Shen	Ohio State Univ., Columbus, OH, USA|c|;	10.1109/TVCG.2008.131;10.1109/VISUAL.1999.809864;10.1109/VISUAL.2004.95;10.1109/VISUAL.2003.1250402;10.1109/TVCG.2007.70519;10.1109/INFVIS.1997.636793;10.1109/TVCG.2008.140;10.1109/VAST.2006.261421	SUBDTW, trend sequence, trend sequence clustering	
Vis	2009	Volume Illustration of Muscle from Diffusion Tensor Images	10.1109/TVCG.2009.203	http://dx.doi.org/10.1109/TVCG.2009.203	1425	1432	J	Medical illustration has demonstrated its effectiveness to depict salient anatomical features while hiding the irrelevant details. Current solutions are ineffective for visualizing fibrous structures such as muscle, because typical datasets (CT or MRI) do not contain directional details. In this paper, we introduce a new muscle illustration approach that leverages diffusion tensor imaging (DTI) data and example-based texture synthesis techniques. Beginning with a volumetric diffusion tensor image, we reformulate it into a scalar field and an auxiliary guidance vector field to represent the structure and orientation of a muscle bundle. A muscle mask derived from the input diffusion tensor image is used to classify the muscle structure. The guidance vector field is further refined to remove noise and clarify structure. To simulate the internal appearance of the muscle, we propose a new two-dimensional example based solid texture synthesis algorithm that builds a solid texture constrained by the guidance vector field. Illustrating the constructed scalar field and solid texture efficiently highlights the global appearance of the muscle as well as the local shape and structure of the muscle fibers in an illustrative fashion. We have applied the proposed approach to five example datasets (four pig hearts and a pig leg), demonstrating plausible illustration and expressiveness.	Wei Chen;Zhicheng Yan;Song Zhang;John Allen Crow;David S. Ebert;Ronald M. McLaughlin;Katie B. Mullins;Robert Cooper;Zi'ang Ding;Jun Liao	State Key Lab. of CAD & CG, Zhejiang Univ., Hangzhou, China|c|;;;;;;;;;	10.1109/TVCG.2006.144;10.1109/VISUAL.2005.1532856;10.1109/TVCG.2006.134;10.1109/VISUAL.2005.1532777;10.1109/VISUAL.2003.1250425;10.1109/VISUAL.2005.1532854;10.1109/VISUAL.2000.885694	Illustrative Visualization, Diffusion Tensor Image, Muscle, Solid Texture Synthesis	
Vis	2009	Volume Ray Casting with Peak finding and Differential Sampling	10.1109/TVCG.2009.204	http://dx.doi.org/10.1109/TVCG.2009.204	1571	1578	J	Direct volume rendering and isosurfacing are ubiquitous rendering techniques in scientific visualization, commonly employed in imaging 3D data from simulation and scan sources. Conventionally, these methods have been treated as separate modalities, necessitating different sampling strategies and rendering algorithms. In reality, an isosurface is a special case of a transfer function, namely a Dirac impulse at a given isovalue. However, artifact-free rendering of discrete isosurfaces in a volume rendering framework is an elusive goal, requiring either infinite sampling or smoothing of the transfer function. While preintegration approaches solve the most obvious deficiencies in handling sharp transfer functions, artifacts can still result, limiting classification. In this paper, we introduce a method for rendering such features by explicitly solving for isovalues within the volume rendering integral. In addition, we present a sampling strategy inspired by ray differentials that automatically matches the frequency of the image plane, resulting in fewer artifacts near the eye and better overall performance. These techniques exhibit clear advantages over standard uniform ray casting with and without preintegration, and allow for high-quality interactive volume rendering with sharp C0 transfer functions.	Aaron Knoll;Younis Hijazi;Rolf Westerteiger;Mathias Schott;Charles D. Hansen;Hans Hagen	Univ. of Kaiserslautern, Kaiserslautern, Germany|c|;;;;;	10.1109/VISUAL.1994.346320;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2003.1250412;10.1109/VISUAL.1998.745713;10.1109/TVCG.2006.154;10.1109/VISUAL.2000.885683;10.1109/TVCG.2006.149;10.1109/VISUAL.2001.964490;10.1109/VISUAL.2004.52;10.1109/VISUAL.1998.745300	direct volume rendering, isosurface, ray casting, ray differentials, sampling, transfer function, preintegration, view dependent	
InfoVis	2010	behaviorism: a framework for dynamic data visualization	10.1109/TVCG.2010.126	http://dx.doi.org/10.1109/TVCG.2010.126	1164	1171	J	While a number of information visualization software frameworks exist, creating new visualizations, especially those that involve novel visualization metaphors, interaction techniques, data analysis strategies, and specialized rendering algorithms, is still often a difficult process. To facilitate the creation of novel visualizations we present a new software framework, behaviorism, which provides a wide range of flexibility when working with dynamic information on visual, temporal, and ontological levels, but at the same time providing appropriate abstractions which allow developers to create prototypes quickly which can then easily be turned into robust systems. The core of the framework is a set of three interconnected graphs, each with associated operators: a scene graph for high-performance 3D rendering, a data graph for different layers of semantically-linked heterogeneous data, and a timing graph for sophisticated control of scheduling, interaction, and animation. In particular, the timing graph provides a unified system to add behaviors to both data and visual elements, as well as to the behaviors themselves. To evaluate the framework we look briefly at three different projects all of which required novel visualizations in different domains, and all of which worked with dynamic data in different ways: an interactive ecological simulation, an information art installation, and an information visualization technique.	Angus Graeme Forbes;Tobias Höllerer;George Legrady	Media Arts & Technol. Dept., Univ. of California, Santa Barbara, CA, USA|c|;;	10.1109/INFVIS.2004.64;10.1109/VISUAL.1996.567752;10.1109/INFVIS.1997.636761;10.1109/TVCG.2009.111	Frameworks, information visualization, information art, dynamic data	
InfoVis	2010	A Visual Backchannel for Large-Scale Events	10.1109/TVCG.2010.129	http://dx.doi.org/10.1109/TVCG.2010.129	1129	1138	J	We introduce the concept of a Visual Backchannel as a novel way of following and exploring online conversations about large-scale events. Microblogging communities, such as Twitter, are increasingly used as digital backchannels for timely exchange of brief comments and impressions during political speeches, sport competitions, natural disasters, and other large events. Currently, shared updates are typically displayed in the form of a simple list, making it difficult to get an overview of the fast-paced discussions as it happens in the moment and how it evolves over time. In contrast, our Visual Backchannel design provides an evolving, interactive, and multi-faceted visual overview of large-scale ongoing conversations on Twitter. To visualize a continuously updating information stream, we include visual saliency for what is happening now and what has just happened, set in the context of the evolving conversation. As part of a fully web-based coordinated-view system we introduce Topic Streams, a temporally adjustable stacked graph visualizing topics over time, a People Spiral representing participants and their activity, and an Image Cloud encoding the popularity of event photos by size. Together with a post listing, these mutually linked views support cross-filtering along topics, participants, and time ranges. We discuss our design considerations, in particular with respect to evolving visualizations of dynamically changing data. Initial feedback indicates significant interest and suggests several unanticipated uses.	Marian Dörk;Dan Gruen;Carey L. Williamson;M. Sheelagh T. Carpendale	;;;	10.1109/VAST.2009.5333443;10.1109/TVCG.2007.70541;10.1109/TVCG.2008.166;10.1109/TVCG.2008.175;10.1109/INFVIS.2005.1532133;10.1109/INFVIS.2003.1249028;10.1109/VAST.2008.4677364;10.1109/VAST.2009.5333437	Backchannel, information visualization, events, multiple views, microblogging, information retrieval, World Wide Web	
InfoVis	2010	An Extension of Wilkinson's Algorithm for Positioning Tick Labels on Axes	10.1109/TVCG.2010.130	http://dx.doi.org/10.1109/TVCG.2010.130	1036	1043	J	The non-data components of a visualization, such as axes and legends, can often be just as important as the data itself. They provide contextual information essential to interpreting the data. In this paper, we describe an automated system for choosing positions and labels for axis tick marks. Our system extends Wilkinson's optimization-based labeling approach to create a more robust, full-featured axis labeler. We define an expanded space of axis labelings by automatically generating additional nice numbers as needed and by permitting the extreme labels to occur inside the data range. These changes provide flexibility in problematic cases, without degrading quality elsewhere. We also propose an additional optimization criterion, legibility, which allows us to simultaneously optimize over label formatting, font size, and orientation. To solve this revised optimization problem, we describe the optimization function and an efficient search algorithm. Finally, we compare our method to previous work using both quantitative and qualitative metrics. This paper is a good example of how ideas from automated graphic design can be applied to information visualization.	Justin Talbot;Sharon Lin;Pat Hanrahan	;;		Axis labeling, nice numbers	
InfoVis	2010	MulteeSum: A Tool for Comparative Spatial and Temporal Gene Expression Data	10.1109/TVCG.2010.137	http://dx.doi.org/10.1109/TVCG.2010.137	908	917	J	Cells in an organism share the same genetic information in their DNA, but have very different forms and behavior because of the selective expression of subsets of their genes. The widely used approach of measuring gene expression over time from a tissue sample using techniques such as microarrays or sequencing do not provide information about the spatial position with in the tissue where these genes are expressed. In contrast, we are working with biologists who use techniques that measure gene expression in every individual cell of entire fruitfly embryos over an hour of their development, and do so for multiple closely-related subspecies of Drosophila. These scientists are faced with the challenge of integrating temporal gene expression data with the spatial location of cells and, moreover, comparing this data across multiple related species. We have worked with these biologists over the past two years to develop MulteeSum, a visualization system that supports inspection and curation of data sets showing gene expression over time, in conjunction with the spatial location of the cells where the genes are expressed - it is the first tool to support comparisons across multiple such data sets. MulteeSum is part of a general and flexible framework we developed with our collaborators that is built around multiple summaries for each cell, allowing the biologists to explore the results of computations that mix spatial information, gene expression measurements over time, and data from multiple related species or organisms. We justify our design decisions based on specific descriptions of the analysis needs of our collaborators, and provide anecdotal evidence of the efficacy of MulteeSum through a series of case studies.	Miriah D. Meyer;Tamara Munzner;Angela H. DePace;Hanspeter Pfister	;;;	10.1109/TVCG.2006.178;10.1109/TVCG.2007.70583;10.1109/TVCG.2007.70589;10.1109/TVCG.2009.167	Spatial data, temporal data, gene expression	
InfoVis	2010	Comparative Analysis of Multidimensional; Quantitative Data	10.1109/TVCG.2010.138	http://dx.doi.org/10.1109/TVCG.2010.138	1027	1035	J	When analyzing multidimensional, quantitative data, the comparison of two or more groups of dimensions is a common task. Typical sources of such data are experiments in biology, physics or engineering, which are conducted in different configurations and use replicates to ensure statistically significant results. One common way to analyze this data is to filter it using statistical methods and then run clustering algorithms to group similar values. The clustering results can be visualized using heat maps, which show differences between groups as changes in color. However, in cases where groups of dimensions have an a priori meaning, it is not desirable to cluster all dimensions combined, since a clustering algorithm can fragment continuous blocks of records. Furthermore, identifying relevant elements in heat maps becomes more difficult as the number of dimensions increases. To aid in such situations, we have developed Matchmaker, a visualization technique that allows researchers to arbitrarily arrange and compare multiple groups of dimensions at the same time. We create separate groups of dimensions which can be clustered individually, and place them in an arrangement of heat maps reminiscent of parallel coordinates. To identify relations, we render bundled curves and ribbons between related records in different groups. We then allow interactive drill-downs using enlarged detail views of the data, which enable in-depth comparisons of clusters between groups. To reduce visual clutter, we minimize crossings between the views. This paper concludes with two case studies. The first demonstrates the value of our technique for the comparison of clustering algorithms. In the second, biologists use our system to investigate why certain strains of mice develop liver disease while others remain healthy, informally showing the efficacy of our system when analyzing multidimensional data containing distinct groups of dimensions.	Alexander Lex;Marc Streit;Christian Partl;Karl Kashofer;Dieter Schmalstieg	;;;;	10.1109/VISUAL.1996.568118;10.1109/VISUAL.1990.146402;10.1109/TVCG.2006.147;10.1109/TVCG.2007.70556;10.1109/TVCG.2007.70529;10.1109/TVCG.2009.167;10.1109/INFVIS.2000.885086	Multidimensional data, cluster comparison, bioinformatics visualization	
InfoVis	2010	Declarative Language Design for Interactive Visualization	10.1109/TVCG.2010.144	http://dx.doi.org/10.1109/TVCG.2010.144	1149	1156	J	We investigate the design of declarative, domain-specific languages for constructing interactive visualizations. By separating specification from execution, declarative languages can simplify development, enable unobtrusive optimization, and support retargeting across platforms. We describe the design of the Protovis specification language and its implementation within an object-oriented, statically-typed programming language (Java). We demonstrate how to support rich visualizations without requiring a toolkit-specific data model and extend Protovis to enable declarative specification of animated transitions. To support cross-platform deployment, we introduce rendering and event-handling infrastructures decoupled from the runtime platform, letting designers retarget visualization specifications (e.g., from desktop to mobile phone) with reduced effort. We also explore optimizations such as runtime compilation of visualization specifications, parallelized execution, and hardware-accelerated rendering. We present benchmark studies measuring the performance gains provided by these optimizations and compare performance to existing Java-based visualization tools, demonstrating scalability improvements exceeding an order of magnitude.	Jeffrey Heer;Michael Bostock	Comput. Sci. Dept., Stanford Univ., Stanford, CA, USA|c|;	10.1109/TVCG.2009.174;10.1109/TVCG.2006.178;10.1109/INFVIS.2004.12;10.1109/TVCG.2007.70577;10.1109/TVCG.2009.128;10.1109/VISUAL.1992.235219;10.1109/TVCG.2009.191;10.1109/TVCG.2009.110;10.1109/TVCG.2007.70539;10.1109/INFVIS.2004.64;10.1109/INFVIS.2000.885086	Information visualization, user interfaces, toolkits, domain specific languages, declarative languages, optimization	
InfoVis	2010	eSeeTrack&amp;#8212;Visualizing Sequential fixation Patterns	10.1109/TVCG.2010.149	http://dx.doi.org/10.1109/TVCG.2010.149	953	962	J	We introduce eSeeTrack, an eye-tracking visualization prototype that facilitates exploration and comparison of sequential gaze orderings in a static or a dynamic scene. It extends current eye-tracking data visualizations by extracting patterns of sequential gaze orderings, displaying these patterns in a way that does not depend on the number of fixations on a scene, and enabling users to compare patterns from two or more sets of eye-gaze data. Extracting such patterns was very difficult with previous visualization techniques. eSeeTrack combines a timeline and a tree-structured visual representation to embody three aspects of eye-tracking data that users are interested in: duration, frequency and orderings of fixations. We demonstrate the usefulness of eSeeTrack via two case studies on surgical simulation and retail store chain data. We found that eSeeTrack allows ordering of fixations to be rapidly queried, explored and compared. Furthermore, our tool provides an effective and efficient mechanism to determine pattern outliers. This approach can be effective for behavior analysis in a variety of domains that are described at the end of this paper.	Hoi Ying Tsang;Melanie Tory;Colin Swindells	;;	10.1109/TVCG.2009.117;10.1109/TVCG.2009.181;10.1109/TVCG.2008.172		
InfoVis	2010	Evaluating the impact of task demands and block resolution on the effectiveness of pixel-based visualization	10.1109/TVCG.2010.150	http://dx.doi.org/10.1109/TVCG.2010.150	963	972	J	Pixel-based visualization is a popular method of conveying large amounts of numerical data graphically. Application scenarios include business and finance, bioinformatics and remote sensing. In this work, we examined how the usability of such visual representations varied across different tasks and block resolutions. The main stimuli consisted of temporal pixel-based visualization with a white-red color map, simulating monthly temperature variation over a six-year period. In the first study, we included 5 separate tasks to exert different perceptual loads. We found that performance varied considerably as a function of task, ranging from 75% correct in low-load tasks to below 40% in high-load tasks. There was a small but consistent effect of resolution, with the uniform patch improving performance by around 6% relative to higher block resolution. In the second user study, we focused on a high-load task for evaluating month-to-month changes across different regions of the temperature range. We tested both CIE L*u*v* and RGB color spaces. We found that the nature of the change-evaluation errors related directly to the distance between the compared regions in the mapped color space. We were able to reduce such errors by using multiple color bands for the same data range. In a final study, we examined more fully the influence of block resolution on performance, and found block resolution had a limited impact on the effectiveness of pixel-based visualization.	Rita Borgo;Karl J. Proctor;Min Chen;Heike Leitte;Tavi Murray;Ian M. Thornton	Comput. Sci., Swansea Univ., Swansea, UK|c|;;;;;	10.1109/VISUAL.1995.480803	Pixel-based visualization, evaluation, user study, visual search, change detection	
InfoVis	2010	FacetAtlas: Multifaceted Visualization for Rich Text Corpora	10.1109/TVCG.2010.154	http://dx.doi.org/10.1109/TVCG.2010.154	1172	1181	J	Documents in rich text corpora usually contain multiple facets of information. For example, an article about a specific disease often consists of different facets such as symptom, treatment, cause, diagnosis, prognosis, and prevention. Thus, documents may have different relations based on different facets. Powerful search tools have been developed to help users locate lists of individual documents that are most related to specific keywords. However, there is a lack of effective analysis tools that reveal the multifaceted relations of documents within or cross the document clusters. In this paper, we present FacetAtlas, a multifaceted visualization technique for visually analyzing rich text corpora. FacetAtlas combines search technology with advanced visual analytical tools to convey both global and local patterns simultaneously. We describe several unique aspects of FacetAtlas, including (1) node cliques and multifaceted edges, (2) an optimized density map, and (3) automated opacity pattern enhancement for highlighting visual patterns, (4) interactive context switch between facets. In addition, we demonstrate the power of FacetAtlas through a case study that targets patient education in the health care domain. Our evaluation shows the benefits of this work, especially in support of complex multifaceted data analysis.	Nan Cao;Jimeng Sun;Yu-Ru Lin;David Gotz;Shixia Liu;Huamin Qu	Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;	10.1109/TVCG.2006.122;10.1109/VAST.2009.5333443;10.1109/INFVIS.2000.885098;10.1109/TVCG.2009.140;10.1109/TVCG.2008.135;10.1109/TVCG.2008.172;10.1109/TVCG.2009.139;10.1109/TVCG.2009.171;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2006.142;10.1109/TVCG.2006.147;10.1109/VISUAL.1998.745302;10.1109/TVCG.2009.165;10.1109/INFVIS.1995.528686;10.1109/TVCG.2006.185	Multi-facet visualization, Text visualization, Multi-relational Graph, Search UI	
InfoVis	2010	GeneaQuilts: A System for Exploring Large Genealogies	10.1109/TVCG.2010.159	http://dx.doi.org/10.1109/TVCG.2010.159	1073	1081	J	GeneaQuilts is a new visualization technique for representing large genealogies of up to several thousand individuals. The visualization takes the form of a diagonally-filled matrix, where rows are individuals and columns are nuclear families. After identifying the major tasks performed in genealogical research and the limits of current software, we present an interactive genealogy exploration system based on GeneaQuilts. The system includes an overview, a timeline, search and filtering components, and a new interaction technique called Bring & Slide that allows fluid navigation in very large genealogies. We report on preliminary feedback from domain experts and show how our system supports a number of their tasks.	Anastasia Bezerianos;Pierre Dragicevic;Jean-Daniel Fekete;Juhee Bae;Benjamin Watson	;;;;	10.1109/INFVIS.2002.1173156;10.1109/INFVIS.2005.1532124	Genealogy visualization, interaction	
InfoVis	2010	Graphical inference for infovis	10.1109/TVCG.2010.161	http://dx.doi.org/10.1109/TVCG.2010.161	973	979	J	How do we know if what we see is really there? When visualizing data, how do we avoid falling into the trap of apophenia where we see patterns in random noise? Traditionally, infovis has been concerned with discovering new relationships, and statistics with preventing spurious relationships from being reported. We pull these opposing poles closer with two new techniques for rigorous statistical inference of visual discoveries. The "Rorschach" helps the analyst calibrate their understanding of uncertainty and "line-up" provides a protocol for assessing the significance of visual discoveries, protecting against the discovery of spurious structure.	Hadley Wickham;Dianne Cook;Heike Hofmann;Andreas Buja	Rice Univ., Houston, TX, USA|c|;;;	10.1109/TVCG.2007.70577	Statistics, visual testing, permutation tests, null hypotheses, data plots	
InfoVis	2010	Graphical Perception of Multiple Time Series	10.1109/TVCG.2010.162	http://dx.doi.org/10.1109/TVCG.2010.162	927	934	J	Line graphs have been the visualization of choice for temporal data ever since the days of William Playfair (1759-1823), but realistic temporal analysis tasks often include multiple simultaneous time series. In this work, we explore user performance for comparison, slope, and discrimination tasks for different line graph techniques involving multiple time series. Our results show that techniques that create separate charts for each time series--such as small multiples and horizon graphs--are generally more efficient for comparisons across time series with a large visual span. On the other hand, shared-space techniques--like standard line graphs--are typically more efficient for comparisons over smaller visual spans where the impact of overlap and clutter is reduced.	Waqas Javed;Bryan McDonnel;Niklas Elmqvist	Purdue Univ. in West Lafayette, West Lafayette, IN, USA|c|;;	10.1109/TVCG.2008.166;10.1109/TVCG.2007.70583;10.1109/TVCG.2007.70535;10.1109/INFVIS.1999.801851;10.1109/TVCG.2008.125;10.1109/INFVIS.2005.1532144	Line graphs, braided graphs, horizon graphs, small multiples, stacked graphs, evaluation, design guidelines	
InfoVis	2010	Gremlin: An Interactive Visualization Model for Analyzing Genomic Rearrangements	10.1109/TVCG.2010.163	http://dx.doi.org/10.1109/TVCG.2010.163	918	926	J	In this work we present, apply, and evaluate a novel, interactive visualization model for comparative analysis of structural variants and rearrangements in human and cancer genomes, with emphasis on data integration and uncertainty visualization. To support both global trend analysis and local feature detection, this model enables explorations continuously scaled from the high-level, complete genome perspective, down to the low-level, structural rearrangement view, while preserving global context at all times. We have implemented these techniques in Gremlin, a genomic rearrangement explorer with multi-scale, linked interactions, which we apply to four human cancer genome data sets for evaluation. Using an insight-based evaluation methodology, we compare Gremlin to Circos, the state-of-the-art in genomic rearrangement visualization, through a small user study with computational biologists working in rearrangement analysis. Results from user study evaluations demonstrate that this visualization model enables more total insights, more insights per minute, and more complex insights than the current state-of-the-art for visual analysis and exploration of genome rearrangements.	Trevor M. O'Brien;Anna M. Ritz;Benjamin J. Raphael;David H. Laidlaw	Comput. Sci. Dept., Brown Univ., Providence, RI, USA|c|;;;	10.1109/TVCG.2009.174;10.1109/TVCG.2009.167	Information visualization, bioinformatics, insight-based evaluation	
InfoVis	2010	How Information Visualization Novices Construct Visualizations	10.1109/TVCG.2010.164	http://dx.doi.org/10.1109/TVCG.2010.164	943	952	J	It remains challenging for information visualization novices to rapidly construct visualizations during exploratory data analysis. We conducted an exploratory laboratory study in which information visualization novices explored fictitious sales data by communicating visualization specifications to a human mediator, who rapidly constructed the visualizations using commercial visualization software. We found that three activities were central to the iterative visualization construction process: data attribute selection, visual template selection, and visual mapping specification. The major barriers faced by the participants were translating questions into data attributes, designing visual mappings, and interpreting the visualizations. Partial specification was common, and the participants used simple heuristics and preferred visualizations they were already familiar with, such as bar, line and pie charts. We derived abstract models from our observations that describe barriers in the data exploration process and uncovered how information visualization novices think about visualization specifications. Our findings support the need for tools that suggest potential visualizations and support iterative refinement, that provide explanations and help with learning, and that are tightly integrated into tool support for the overall visual analytics process.	Lars Grammel;Melanie Tory;Margaret-Anne D. Storey	Univ. of Victoria, Victoria, BC, Canada|c|;;	10.1109/TVCG.2007.70515;10.1109/TVCG.2006.163;10.1109/TVCG.2007.70541;10.1109/VAST.2009.5333878;10.1109/TVCG.2008.109;10.1109/VAST.2006.261428;10.1109/TVCG.2007.70577;10.1109/VAST.2008.4677358;10.1109/VAST.2008.4677365;10.1109/TVCG.2007.70535;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.1998.729560;10.1109/TVCG.2007.70594;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2001.963289;10.1109/INFVIS.2000.885092;10.1109/TVCG.2008.137	Empirical study, visualization, visualization construction, visual analytics, visual mapping, novices	
InfoVis	2010	Laws of Attraction: From Perceptual Forces to Conceptual Similarity	10.1109/TVCG.2010.174	http://dx.doi.org/10.1109/TVCG.2010.174	1009	1016	J	Many of the pressing questions in information visualization deal with how exactly a user reads a collection of visual marks as information about relationships between entities. Previous research has suggested that people see parts of a visualization as objects, and may metaphorically interpret apparent physical relationships between these objects as suggestive of data relationships. We explored this hypothesis in detail in a series of user experiments. Inspired by the concept of implied dynamics in psychology, we first studied whether perceived gravity acting on a mark in a scatterplot can lead to errors in a participant's recall of the mark's position. The results of this study suggested that such position errors exist, but may be more strongly influenced by attraction between marks. We hypothesized that such apparent attraction may be influenced by elements used to suggest relationship between objects, such as connecting lines, grouping elements, and visual similarity. We further studied what visual elements are most likely to cause this attraction effect, and whether the elements that best predicted attraction errors were also those which suggested conceptual relationships most strongly. Our findings show a correlation between attraction errors and intuitions about relatedness, pointing towards a possible mechanism by which the perception of visual marks becomes an interpretation of data relationships.	Caroline Ziemkiewicz;Robert Kosara	;	10.1109/TVCG.2008.125	Perceptual cognition, visualization models, laboratory studies, cognition theory	
InfoVis	2010	ManiWordle: Providing Flexible Control over Wordle	10.1109/TVCG.2010.175	http://dx.doi.org/10.1109/TVCG.2010.175	1190	1197	J	Among the multifarious tag-clouding techniques, Wordle stands out to the community by providing an aesthetic layout, eliciting the emergence of the participatory culture and usage of tag-clouding in the artistic creations. In this paper, we introduce ManiWordle, a Wordle-based visualization tool that revamps interactions with the layout by supporting custom manipulations. ManiWordle allows people to manipulate typography, color, and composition not only for the layout as a whole, but also for the individual words, enabling them to have better control over the layout result. We first describe our design rationale along with the interaction techniques for tweaking the layout. We then present the results both from the preliminary usability study and from the comparative study between ManiWordle and Wordle. The results suggest that ManiWordle provides higher user satisfaction and an efficient method of creating the desired "art work," harnessing the power behind the ever-increasing popularity of Wordle.	Kyle Koh;Bongshin Lee;Bo Hyoung Kim;Jinwook Seo	Seoul Nat. Univ., Seoul, South Korea|c|;;;	10.1109/TVCG.2007.70541;10.1109/TVCG.2007.70515;10.1109/TVCG.2009.171;10.1109/VAST.2009.5333443;10.1109/INFVIS.2003.1249031	Interaction design, direct manipulation, flexibilty-usability tradeoff, tag-cloud, participatory visualization, user study 	
InfoVis	2010	Matching Visual Saliency to Confidence in Plots of Uncertain Data	10.1109/TVCG.2010.176	http://dx.doi.org/10.1109/TVCG.2010.176	980	989	J	Conveying data uncertainty in visualizations is crucial for preventing viewers from drawing conclusions based on untrustworthy data points. This paper proposes a methodology for efficiently generating density plots of uncertain multivariate data sets that draws viewers to preattentively identify values of high certainty while not calling attention to uncertain values. We demonstrate how to augment scatter plots and parallel coordinates plots to incorporate statistically modeled uncertainty and show how to integrate them with existing multivariate analysis techniques, including outlier detection and interactive brushing. Computing high quality density plots can be expensive for large data sets, so we also describe a probabilistic plotting technique that summarizes the data without requiring explicit density plot computation. These techniques have been useful for identifying brain tumors in multivariate magnetic resonance spectroscopy data and we describe how to extend them to visualize ensemble data sets.	David Feng;Lester Kwock;Yueh Lee;Russell M. Taylor II	Univ. of North Carolina at Chapel Hill, Chapel Hill, NC, USA|c|;;;	10.1109/TVCG.2008.119;10.1109/INFVIS.2001.963286;10.1109/TVCG.2008.167;10.1109/TVCG.2009.179;10.1109/INFVIS.2002.1173145;10.1109/TVCG.2009.131;10.1109/VISUAL.1999.809866;10.1109/TVCG.2009.114;10.1109/TVCG.2006.170;10.1109/INFVIS.2004.3;10.1109/VISUAL.1994.346302;10.1109/TVCG.2008.153;10.1109/TVCG.2009.118	Uncertainty visualization, brushing, scatter plots, parallel coordinates, multivariate data	
InfoVis	2010	Mental Models; Visual Reasoning and Interaction in Information Visualization: A Top-down Perspective	10.1109/TVCG.2010.177	http://dx.doi.org/10.1109/TVCG.2010.177	999	1008	J	Although previous research has suggested that examining the interplay between internal and external representations can benefit our understanding of the role of information visualization (InfoVis) in human cognitive activities, there has been little work detailing the nature of internal representations, the relationship between internal and external representations and how interaction is related to these representations. In this paper, we identify and illustrate a specific kind of internal representation, mental models, and outline the high-level relationships between mental models and external visualizations. We present a top-down perspective of reasoning as model construction and simulation, and discuss the role of visualization in model based reasoning. From this perspective, interaction can be understood as active modeling for three primary purposes: external anchoring, information foraging, and cognitive offloading. Finally we discuss the implications of our approach for design, evaluation and theory development.	Zhicheng Liu;John T. Stasko	Sch. of Interactive Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;	10.1109/TVCG.2009.187;10.1109/TVCG.2008.155;10.1109/INFVIS.2001.963289;10.1109/TVCG.2009.109;10.1109/TVCG.2007.70515;10.1109/TVCG.2009.180;10.1109/TVCG.2008.109;10.1109/TVCG.2008.171;10.1109/TVCG.2008.121;10.1109/VAST.2008.4677365	Mental model, model-based reasoning, distributed cognition, interaction, theory, information visualization	
InfoVis	2010	Narrative Visualization: Telling Stories with Data	10.1109/TVCG.2010.179	http://dx.doi.org/10.1109/TVCG.2010.179	1139	1148	J	Data visualization is regularly promoted for its ability to reveal stories within data, yet these ÔÇ£data storiesÔÇØ differ in important ways from traditional forms of storytelling. Storytellers, especially online journalists, have increasingly been integrating visualizations into their narratives, in some cases allowing the visualization to function in place of a written story. In this paper, we systematically review the design space of this emerging class of visualizations. Drawing on case studies from news media to visualization research, we identify distinct genres of narrative visualization. We characterize these design differences, together with interactivity and messaging, in terms of the balance between the narrative flow intended by the author (imposed by graphical elements and the interface) and story discovery on the part of the reader (often through interactive exploration). Our framework suggests design strategies for narrative visualization, including promising under-explored approaches to journalistic storytelling and educational media.	Edward Segel;Jeffrey Heer	Stanford Univ., Stanford, CA, USA|c|;	10.1109/TVCG.2007.70577;10.1109/TVCG.2007.70539;10.1109/TVCG.2008.137;10.1109/VAST.2007.4388992	Narrative visualization, storytelling, design methods, case study, journalism, social data analysis	
InfoVis	2010	Necklace Maps	10.1109/TVCG.2010.180	http://dx.doi.org/10.1109/TVCG.2010.180	881	889	J	Statistical data associated with geographic regions is nowadays globally available in large amounts and hence automated methods to visually display these data are in high demand. There are several well-established thematic map types for quantitative data on the ratio-scale associated with regions: choropleth maps, cartograms, and proportional symbol maps. However, all these maps suffer from limitations, especially if large data values are associated with small regions. To overcome these limitations, we propose a novel type of quantitative thematic map, the necklace map. In a necklace map, the regions of the underlying two-dimensional map are projected onto intervals on a one-dimensional curve (the necklace) that surrounds the map regions. Symbols are scaled such that their area corresponds to the data of their region and placed without overlap inside the corresponding interval on the necklace. Necklace maps appear clear and uncluttered and allow for comparatively large symbol sizes. They visualize data sets well which are not proportional to region sizes. The linear ordering of the symbols along the necklace facilitates an easy comparison of symbol sizes. One map can contain several nested or disjoint necklaces to visualize clustered data. The advantages of necklace maps come at a price: the association between a symbol and its region is weaker than with other types of maps. Interactivity can help to strengthen this association if necessary. We present an automated approach to generate necklace maps which allows the user to interactively control the final symbol placement. We validate our approach with experiments using various data sets and maps.	Bettina Speckmann;Kevin Verbeek	Tech. Univ. Eindhoven, Eindhoven, Netherlands|c|;	10.1109/INFVIS.2004.57;10.1109/TVCG.2008.165	Geographic Visualization, Automated Cartography, Proportional Symbol Maps, Necklace Maps	
InfoVis	2010	OpinionSeer: Interactive Visualization of Hotel Customer Feedback	10.1109/TVCG.2010.183	http://dx.doi.org/10.1109/TVCG.2010.183	1109	1118	J	The rapid development of Web technology has resulted in an increasing number of hotel customers sharing their opinions on the hotel services. Effective visual analysis of online customer opinions is needed, as it has a significant impact on building a successful business. In this paper, we present OpinionSeer, an interactive visualization system that could visually analyze a large collection of online hotel customer reviews. The system is built on a new visualization-centric opinion mining technique that considers uncertainty for faithfully modeling and analyzing customer opinions. A new visual representation is developed to convey customer opinions by augmenting well-established scatterplots and radial visualization. To provide multiple-level exploration, we introduce subjective logic to handle and organize subjective opinions with degrees of uncertainty. Several case studies illustrate the effectiveness and usefulness of OpinionSeer on analyzing relationships among multiple data dimensions and comparing opinions of different groups. Aside from data on hotel customer feedback, OpinionSeer could also be applied to visually analyze customer opinions on other products or services.	Yingcai Wu;Furu Wei;Shixia Liu;Norman Au;Weiwei Cui;Hong Zhou;Huamin Qu	Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Kowloon, China|c|;;;;;;	10.1109/VAST.2006.261431;10.1109/TVCG.2009.171;10.1109/VAST.2009.5332611;10.1109/TVCG.2008.187;10.1109/VAST.2009.5333919;10.1109/INFVIS.2002.1173151	opinion visualization, radial visualization, uncertainty visualization	
InfoVis	2010	Pargnostics: Screen-Space Metrics for Parallel Coordinates	10.1109/TVCG.2010.184	http://dx.doi.org/10.1109/TVCG.2010.184	1017	1026	J	Interactive visualization requires the translation of data into a screen space of limited resolution. While currently ignored by most visualization models, this translation entails a loss of information and the introduction of a number of artifacts that can be useful, (e.g., aggregation, structures) or distracting (e.g., over-plotting, clutter) for the analysis. This phenomenon is observed in parallel coordinates, where overlapping lines between adjacent axes form distinct patterns, representing the relation between variables they connect. However, even for a small number of dimensions, the challenge is to effectively convey the relationships for all combinations of dimensions. The size of the dataset and a large number of dimensions only add to the complexity of this problem. To address these issues, we propose Pargnostics, parallel coordinates diagnostics, a model based on screen-space metrics that quantify the different visual structures. Pargnostics metrics are calculated for pairs of axes and take into account the resolution of the display as well as potential axis inversions. Metrics include the number of line crossings, crossing angles, convergence, overplotting, etc. To construct a visualization view, the user can pick from a ranked display showing pairs of coordinate axes and the structures between them, or examine all possible combinations of axes at once in a matrix display. Picking the best axes layout is an NP-complete problem in general, but we provide a way of automatically optimizing the display according to the user's preferences based on our metrics and model.	Aritra Dasgupta;Robert Kosara	Univ. of North Carolina at Charlotte, Charlotte, NC, USA|c|;	10.1109/INFVIS.2005.1532142;10.1109/TVCG.2006.138;10.1109/VISUAL.1990.146402;10.1109/VAST.2006.261423;10.1109/VAST.2009.5332628;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.1998.729559;10.1109/INFVIS.1997.636793	Parallel coordinates, metrics, display optimization, visualization models	
InfoVis	2010	PedVis: A Structured; Space-Efficient Technique for Pedigree Visualization	10.1109/TVCG.2010.185	http://dx.doi.org/10.1109/TVCG.2010.185	1063	1072	J	Public genealogical databases are becoming increasingly populated with historical data and records of the current population's ancestors. As this increasing amount of available information is used to link individuals to their ancestors, the resulting trees become deeper and more dense, which justifies the need for using organized, space-efficient layouts to display the data. Existing layouts are often only able to show a small subset of the data at a time. As a result, it is easy to become lost when navigating through the data or to lose sight of the overall tree structure. On the contrary, leaving space for unknown ancestors allows one to better understand the tree's structure, but leaving this space becomes expensive and allows fewer generations to be displayed at a time. In this work, we propose that the H-tree based layout be used in genealogical software to display ancestral trees. We will show that this layout presents an increase in the number of displayable generations, provides a nicely arranged, symmetrical, intuitive and organized fractal structure, increases the user's ability to understand and navigate through the data, and accounts for the visualization requirements necessary for displaying such trees. Finally, user-study results indicate potential for user acceptance of the new layout.	Claurissa Tuttle;Luis Gustavo Nonato;Cláudio T. Silva	Univ. of Utah, Salt Lake City, UT, USA|c|;;	10.1109/TVCG.2008.158;10.1109/TVCG.2008.141;10.1109/INFVIS.2005.1532124;10.1109/INFVIS.2003.1249004;10.1109/VISUAL.1991.175815;10.1109/INFVIS.2002.1173152;10.1109/INFVIS.2002.1173148;10.1109/INFVIS.1997.636718	Genealogy, Pedigree, H-tree	
InfoVis	2010	Perceptual Guidelines for Creating Rectangular Treemaps	10.1109/TVCG.2010.186	http://dx.doi.org/10.1109/TVCG.2010.186	990	998	J	Treemaps are space-filling visualizations that make efficient use of limited display space to depict large amounts of hierarchical data. Creating perceptually effective treemaps requires carefully managing a number of design parameters including the aspect ratio and luminance of rectangles. Moreover, treemaps encode values using area, which has been found to be less accurate than judgments of other visual encodings, such as length. We conduct a series of controlled experiments aimed at producing a set of design guidelines for creating effective rectangular treemaps. We find no evidence that luminance affects area judgments, but observe that aspect ratio does have an effect. Specifically, we find that the accuracy of area comparisons suffers when the compared rectangles have extreme aspect ratios or when both are squares. Contrary to common assumptions, the optimal distribution of rectangle aspect ratios within a treemap should include non-squares, but should avoid extremes. We then compare treemaps with hierarchical bar chart displays to identify the data densities at which length-encoded bar charts become less effective than area-encoded treemaps. We report the transition points at which treemaps exhibit judgment accuracy on par with bar charts for both leaf and non-leaf tree nodes. We also find that even at relatively low data densities treemaps result in faster comparisons than bar charts. Based on these results, we present a set of guidelines for the effective use of treemaps and suggest alternate approaches for treemap layout.	Nicholas Kong;Jeffrey Heer;Maneesh Agrawala	Univ. of California, Berkeley, Berkeley, CA, USA|c|;;	10.1109/INFVIS.2000.885091;10.1109/INFVIS.2005.1532145;10.1109/INFVIS.2004.70;10.1109/INFVIS.2005.1532144;10.1109/TVCG.2007.70583;10.1109/INFVIS.2001.963283;10.1109/INFVIS.2001.963290;10.1109/TVCG.2008.171;10.1109/INFVIS.1999.801860;10.1109/INFVIS.2002.1173153	Graphical Perception, Visualization, Treemaps, Rectangular Area, Visual Encoding, Experiment, Mechanical Turk	
InfoVis	2010	Rethinking Map Legends with Visualization	10.1109/TVCG.2010.191	http://dx.doi.org/10.1109/TVCG.2010.191	890	899	J	This design paper presents new guidance for creating map legends in a dynamic environment. Our contribution is a set ofguidelines for legend design in a visualization context and a series of illustrative themes through which they may be expressed. Theseare demonstrated in an applications context through interactive software prototypes. The guidelines are derived from cartographicliterature and in liaison with EDINA who provide digital mapping services for UK tertiary education. They enhance approaches tolegend design that have evolved for static media with visualization by considering: selection, layout, symbols, position, dynamismand design and process. Broad visualization legend themes include: The Ground Truth Legend, The Legend as Statistical Graphicand The Map is the Legend. Together, these concepts enable us to augment legends with dynamic properties that address specificneeds, rethink their nature and role and contribute to a wider re-evaluation of maps as artifacts of usage rather than statements offact. EDINA has acquired funding to enhance their clients with visualization legends that use these concepts as a consequence ofthis work. The guidance applies to the design of a wide range of legends and keys used in cartography and information visualization.	Jason Dykes;Jo Wood;Aidan Slingsby	Dept. of Inf. Sci., City Univ. London, London, UK|c|;;	10.1109/TVCG.2007.70561;10.1109/TVCG.2008.165;10.1109/TVCG.2007.70539;10.1109/TVCG.2006.202;10.1109/INFVIS.2000.885095;10.1109/TVCG.2007.70589;10.1109/TVCG.2009.128	Cartography, design, Digimap service, legend, online web mapping, visualization	
InfoVis	2010	SignalLens: Focus+Context Applied to Electronic Time Series	10.1109/TVCG.2010.193	http://dx.doi.org/10.1109/TVCG.2010.193	900	907	J	Electronic test and measurement systems are becoming increasingly sophisticated in order to match the increased complexity and ultra-high speed of the devices under test. A key feature in many such instruments is a vastly increased capacity for storage of digital signals. Storage of 109 time points or more is now possible. At the same time, the typical screens on such measurement devices are relatively small. Therefore, these instruments can only render an extremely small fraction of the complete signal at any time. SignalLens uses a Focus+Context approach to provide a means of navigating to and inspecting low-level signal details in the context of the entire signal trace. This approach provides a compact visualization suitable for embedding into the small displays typically provided by electronic measurement instruments. We further augment this display with computed tracks which display time-aligned computed properties of the signal. By combining and filtering these computed tracks it is possible to easily and quickly find computationally detected features in the data which are often obscured by the visual compression required to render the large data sets on a small screen. Further, these tracks can be viewed in the context of the entire signal trace as well as visible high-level signal features. Several examples using real-world electronic measurement data are presented, which demonstrate typical use cases and the effectiveness of the design.	Robert Kincaid	Agilent Laboratories|c|	10.1109/VAST.2009.5333895	Focus+Context, Lens, Test and Measurement, Electronic Signal, Signal Processing 	
InfoVis	2010	SparkClouds: Visualizing Trends in Tag Clouds	10.1109/TVCG.2010.194	http://dx.doi.org/10.1109/TVCG.2010.194	1182	1189	J	Tag clouds have proliferated over the web over the last decade. They provide a visual summary of a collection of texts by visually depicting the tag frequency by font size. In use, tag clouds can evolve as the associated data source changes over time. Interesting discussions around tag clouds often include a series of tag clouds and consider how they evolve over time. However, since tag clouds do not explicitly represent trends or support comparisons, the cognitive demands placed on the person for perceiving trends in multiple tag clouds are high. In this paper, we introduce SparkClouds, which integrate sparklines into a tag cloud to convey trends between multiple tag clouds. We present results from a controlled study that compares SparkClouds with two traditional trend visualizations-multiple line graphs and stacked bar charts-as well as Parallel Tag Clouds. Results show that SparkClouds' ability to show trends compares favourably to the alternative visualizations.	Bongshin Lee;Nathalie Henry Riche;Amy K. Karlson;M. Sheelagh T. Carpendale	;;;	10.1109/TVCG.2009.171;10.1109/INFVIS.2005.1532122;10.1109/TVCG.2007.70589	Tag clouds, trend visualization, multiple line graphs, stacked bar charts, evaluation	
InfoVis	2010	Stacking Graphic Elements to Avoid Over-Plotting	10.1109/TVCG.2010.197	http://dx.doi.org/10.1109/TVCG.2010.197	1044	1052	J	An ongoing challenge for information visualization is how to deal with over-plotting forced by ties or the relatively limited visual field of display devices. A popular solution is to represent local data density with area (bubble plots, treemaps), color(heatmaps), or aggregation (histograms, kernel densities, pixel displays). All of these methods have at least one of three deficiencies:1) magnitude judgments are biased because area and color have convex downward perceptual functions, 2) area, hue, and brightnesshave relatively restricted ranges of perceptual intensity compared to length representations, and/or 3) it is difficult to brush or link toindividual cases when viewing aggregations. In this paper, we introduce a new technique for visualizing and interacting with datasets that preserves density information by stacking overlapping cases. The overlapping data can be points or lines or other geometric elements, depending on the type of plot. We show real-dataset applications of this stacking paradigm and compare them to other techniques that deal with over-plotting in high-dimensional displays.	Dang Tuan Nhon;Leland Wilkinson;Anushka Anand	Dept. of Comput. Sci., Univ. of Illinois at Chicago, Chicago, IL, USA|c|;;	10.1109/INFVIS.2005.1532139;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2009.131;10.1109/INFVIS.1995.528685;10.1109/VISUAL.1991.175815;10.1109/INFVIS.2005.1532122;10.1109/INFVIS.2004.68;10.1109/INFVIS.2000.885098	Dot plots, Parallel coordinate plots, Multidimensional data, Density-based visualization	
InfoVis	2010	The FlowVizMenu and Parallel Scatterplot Matrix: Hybrid Multidimensional Visualizations for Network Exploration	10.1109/TVCG.2010.205	http://dx.doi.org/10.1109/TVCG.2010.205	1100	1108	J	A standard approach for visualizing multivariate networks is to use one or more multidimensional views (for example, scatterplots) for selecting nodes by various metrics, possibly coordinated with a node-link view of the network. In this paper, we present three novel approaches for achieving a tighter integration of these views through hybrid techniques for multidimensional visualization, graph selection and layout. First, we present the FlowVizMenu, a radial menu containing a scatterplot that can be popped up transiently and manipulated with rapid, fluid gestures to select and modify the axes of its scatterplot. Second, the FlowVizMenu can be used to steer an attribute-driven layout of the network, causing certain nodes of a node-link diagram to move toward their corresponding positions in a scatterplot while others can be positioned manually or by force-directed layout. Third, we describe a novel hybrid approach that combines a scatterplot matrix (SPLOM) and parallel coordinates called the Parallel Scatterplot Matrix (P-SPLOM), which can be used to visualize and select features within the network. We also describe a novel arrangement of scatterplots called the Scatterplot Staircase (SPLOS) that requires less space than a traditional scatterplot matrix. Initial user feedback is reported.	Christophe Viau;Michael J. McGuffin;Yves Chiricota;Igor Jurisica	Ecole de Technol. Super., Montreal, QC, Canada|c|;;;	10.1109/TVCG.2009.151;10.1109/INFVIS.2005.1532142;10.1109/TVCG.2007.70523;10.1109/TVCG.2009.179;10.1109/VAST.2009.5332586;10.1109/INFVIS.2005.1532141;10.1109/TVCG.2006.187;10.1109/INFVIS.2004.47;10.1109/TVCG.2007.70521;10.1109/INFVIS.2003.1249011;10.1109/TVCG.2008.153	Interactive graph drawing, network layout, attribute-driven layout, parallel coordinates, scatterplot matrix, radial menu	
InfoVis	2010	The Streams of Our Lives: Visualizing Listening Histories in Context	10.1109/TVCG.2010.206	http://dx.doi.org/10.1109/TVCG.2010.206	1119	1128	J	The choices we take when listening to music are expressions of our personal taste and character. Storing and accessing our listening histories is trivial due to services like Last.fm, but learning from them and understanding them is not. Existing solutions operate at a very abstract level and only produce statistics. By applying techniques from information visualization to this problem, we were able to provide average people with a detailed and powerful tool for accessing their own musical past. LastHistory is an interactive visualization for displaying music listening histories, along with contextual information from personal photos and calendar entries. Its two main user tasks are (1) analysis, with an emphasis on temporal patterns and hypotheses related to musical genre and sequences, and (2) reminiscing, where listening histories and context represent part of one's past. In this design study paper we give an overview of the field of music listening histories and explain their unique characteristics as a type of personal data. We then describe the design rationale, data and view transformations of LastHistory and present the results from both a laband a large-scale online study. We also put listening histories in contrast to other lifelogging data. The resonant and enthusiastic feedback that we received from average users shows a need for making their personal data accessible. We hope to stimulate such developments through this research.	Dominikus Baur;Frederik Seiffert;Michael Sedlmair;Sebastian Boring	;;;	10.1109/TVCG.2008.166;10.1109/TVCG.2007.70541;10.1109/INFVIS.2001.963273;10.1109/INFVIS.2002.1173155;10.1109/INFVIS.1999.801851;10.1109/VAST.2006.261421	Information visualization, lifelogging, design study, music, listening history, timelines, photos, calendars	
InfoVis	2010	Uncovering Strengths and Weaknesses of Radial Visualizations---an Empirical Approach	10.1109/TVCG.2010.209	http://dx.doi.org/10.1109/TVCG.2010.209	935	942	J	Radial visualizations play an important role in the information visualization community. But the decision to choose a radial coordinate system is rather based on intuition than on scientific foundations. The empirical approach presented in this paper aims at uncovering strengths and weaknesses of radial visualizations by comparing them to equivalent ones in Cartesian coordinate systems. We identified memorizing positions of visual elements as a generic task when working with visualizations. A first study with 674 participants provides a broad data spectrum for exploring differences between the two visualization types. A second, complementing study with fewer participants focuses on further questions raised by the first study. Our findings document that Cartesian visualizations tend to outperform their radial counterparts especially with respect to answer times. Nonetheless, radial visualization seem to be more appropriate for focusing on a particular data dimension.	Stephan Diehl 0001;Fabian Beck;Michael Burch	Comput. Sci. Dept., Univ. of Trier, Trier, Germany|c|;;	10.1109/INFVIS.2004.70;10.1109/INFVIS.2001.963291;10.1109/VISUAL.1997.663916;10.1109/INFVIS.2001.963291	Radial visualization, user study, visual memory	
InfoVis	2010	Untangling Euler Diagrams	10.1109/TVCG.2010.210	http://dx.doi.org/10.1109/TVCG.2010.210	1090	1099	J	In many common data analysis scenarios the data elements are logically grouped into sets. Venn and Euler style diagrams are a common visual representation of such set membership where the data elements are represented by labels or glyphs and sets are indicated by boundaries surrounding their members. Generating such diagrams automatically such that set regions do not intersect unless the corresponding sets have a non-empty intersection is a difficult problem. Further, it may be impossible in some cases if regions are required to be continuous and convex. Several approaches exist to draw such set regions using more complex shapes, however, the resulting diagrams can be difficult to interpret. In this paper we present two novel approaches for simplifying a complex collection of intersecting sets into a strict hierarchy that can be more easily automatically arranged and drawn (Figure 1). In the first approach, we use compact rectangular shapes for drawing each set, attempting to improve the readability of the set intersections. In the second approach, we avoid drawing intersecting set regions by duplicating elements belonging to multiple sets. We compared both of our techniques to the traditional non-convex region technique using five readability tasks. Our results show that the compact rectangular shapes technique was often preferred by experimental subjects even though the use of duplications dramatically improves the accuracy and performance time for most of our tasks. In addition to general set representation our techniques are also applicable to visualization of networks with intersecting clusters of nodes.	Nathalie Henry Riche;Tim Dwyer	;	10.1109/TVCG.2008.144;10.1109/TVCG.2007.70582;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2008.141;10.1109/TVCG.2009.122;10.1109/TVCG.2006.156;10.1109/TVCG.2006.120;10.1109/TVCG.2008.130;10.1109/TVCG.2006.166;10.1109/VISUAL.1993.398863;10.1109/TVCG.2008.153	Information Visualization, Euler diagrams, Set Visualization, Graph Visualization	
InfoVis	2010	Visualization of Diversity in Large Multivariate Data Sets	10.1109/TVCG.2010.216	http://dx.doi.org/10.1109/TVCG.2010.216	1053	1062	J	Understanding the diversity of a set of multivariate objects is an important problem in many domains, including ecology, college admissions, investing, machine learning, and others. However, to date, very little work has been done to help users achieve this kind of understanding. Visual representation is especially appealing for this task because it offers the potential to allow users to efficiently observe the objects of interest in a direct and holistic way. Thus, in this paper, we attempt to formalize the problem of visualizing the diversity of a large (more than 1000 objects), multivariate (more than 5 attributes) data set as one worth deeper investigation by the information visualization community. In doing so, we contribute a precise definition of diversity, a set of requirements for diversity visualizations based on this definition, and a formal user study design intended to evaluate the capacity of a visual representation for communicating diversity information. Our primary contribution, however, is a visual representation, called the Diversity Map, for visualizing diversity. An evaluation of the Diversity Map using our study design shows that users can judge elements of diversity consistently and as or more accurately than when using the only other representation specifically designed to visualize diversity.	Tuan Pham;Rob Hess;Crystal Ju;Eugene Zhang;Ronald A. Metoyer	Sch. of Electr. Eng. & Comput. Sci., Oregon State Univ., Corvallis, OR, USA|c|;;;;	10.1109/VISUAL.1990.146402;10.1109/VISUAL.1990.146386;10.1109/INFVIS.2004.15;10.1109/INFVIS.1997.636793;10.1109/INFVIS.2002.1173157;10.1109/VISUAL.1991.175815;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2004.68	Information visualization, diversity, categorical data, multivariate data, evaluation	
InfoVis	2010	Visualization of Graph Products	10.1109/TVCG.2010.217	http://dx.doi.org/10.1109/TVCG.2010.217	1082	1089	J	Graphs are a versatile structure and abstraction for binary relationships between objects. To gain insight into such relationships, their corresponding graph can be visualized. In the past, many classes of graphs have been defined, e.g. trees, planar graphs, directed acyclic graphs, and visualization algorithms were proposed for these classes. Although many graphs may only be classified as "general" graphs, they can contain substructures that belong to a certain class. Archambault proposed the TopoLayout framework: rather than draw any arbitrary graph using one method, split the graph into components that are homogeneous with respect to one graph class and then draw each component with an algorithm best suited for this class. Graph products constitute a class that arises frequently in graph theory, but for which no visualization algorithm has been proposed until now. In this paper, we present an algorithm for drawing graph products and the aesthetic criterion graph product's drawings are subject to. We show that the popular High-Dimensional Embedder approach applied to cartesian products already respects this aestetic criterion, but has disadvantages. We also present how our method is integrated as a new component into the TopoLayout framework. Our implementation is used for further research of graph products in a biological context.	Stefan Jänicke;Christian Heine 0002;Marc Hellmuth;Peter F. Stadler;Gerik Scheuermann	Inst. for Compute r Sci., Univ. of Leipzig, Leipzig, Germany|c|;;;;	10.1109/TVCG.2007.70580	Graph drawing, graph products, TopoLayout	
InfoVis	2010	Visualizations everywhere: A Multiplatform Infrastructure for Linked Visualizations	10.1109/TVCG.2010.222	http://dx.doi.org/10.1109/TVCG.2010.222	1157	1163	J	In order to use new visualizations, most toolkits require application developers to rebuild their applications and distribute new versions to users. The WebCharts Framework take a different approach by hosting Javascript from within an application and providing a standard data and events interchange.. In this way, applications can be extended dynamically, with a wide variety of visualizations. We discuss the benefits of this architectural approach, contrast it to existing techniques, and give a variety of examples and extensions of the basic system.	Danyel Fisher;Steven M. Drucker;Roland Fernandez;Scott Ruble	;;;	10.1109/INFVIS.2004.12;10.1109/TVCG.2009.148;10.1109/TVCG.2008.175;10.1109/TVCG.2009.174;10.1109/TVCG.2007.70577;10.1109/INFVIS.2000.885086	Visualization systems, toolkit design, data transformation and representation	
VAST	2010	Adapting Daniel and Wood's modeling approach to interactive visual analytics	10.1109/VAST.2010.5649831	http://dx.doi.org/10.1109/VAST.2010.5649831	253	254	M	This poster describes our progress in developing an interactive linear modeling system that supports the modeling approach described by Daniel and Wood. Our visual interface permits analysts to build sets of possible models and then creates appropriate visualizations to permit human-in-the-loop model comparison and selection.	Justin Talbot;Pat Hanrahan	Comput. Sci. Dept., Stanford Univ., Stanford, CA, USA|c|;			
VAST	2010	Enron case study: Analysis of email behavior using EmailTime	10.1109/VAST.2010.5649905	http://dx.doi.org/10.1109/VAST.2010.5649905	235	236	M	This paper presents a case study with Enron email dataset to explore the behaviors of email users within different organizational positions. We defined email behavior as the email activity level of people regarding a series of measured metrics e.g. sent and received emails, numbers of email addresses, etc. These metrics were calculated through EmailTime, a visual analysis tool of email correspondence over the course of time. Results showed specific patterns in the email datasets of different organizational positions.	Minoo Erfani Joorabchi;Ji-Dong Yim;Mona Erfani Joorabchi;Chris Shaw 0002	Simon Fraser Univ., Burnaby, BC, Canada|c|;;;		Email, Enron, Case Study, EmailTime, Visual Analysis	
VAST	2010	A radial visualization tool for depicting hierarchically structured video content	10.1109/VAST.2010.5650177	http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5650177	251	252	M	The visual analysis of video content is an important research topic due to the huge amount of video data that is generated every day. Annotating this data will become a major problem since the amount of videos further increases. With this work we introduce a system that combines a visualization tool with automatic video segmentation techniques and a characteristic key-frame extraction. A summary of the content of a whole video in one view is realized. Furthermore, the user can interactively browse through the video via our visualization interface to get more detailed information. The system is adapted to two application scenarios and a third application is discussed for future work.	Tobias Ruppert;Jörn Kohlhammer	Fraunhofer Inst. for Comput. Graphics Res. (IGD), Darmstadt, Germany|c|;			
VAST	2010	A Visual Analytics approach to identifying protein structural constraints	10.1109/VAST.2010.5650199	http://dx.doi.org/10.1109/VAST.2010.5650199	249	250	M	Predicting protein structures has long been a grand-challenge problem. Fine-grained computational simulation of folding events from a protein's synthesis to its final stable structure remains computationally intractable. Therefore, methods which derive constraints from other sources are attractive. To date, constraints derived from known structures have proven to be highly successful. However, these cannot be applied to molecules with no identifiable neighbors having already-determined structures. For such molecules, structural constraints must be derived in other ways. One popular approach has been the statistical analysis of large families of proteins, with the hope that residues that ÔÇ£change togetherÔÇØ (co-evolve) imply that those residues are in contact. Unfortunately, despite repeated attempts to use this data to deduce structural constraints, this approach has met with minimal success. The consensus of current literature concludes that there is simply too little information contained within the correlated mutations of many protein families to reliably and generally predict structural constraints. Recent work in my laboratory challenges this conclusion. For some time we have been developing methods (MAVL/StickWRLD) to visualize the pattern of co-evolved mutations within sequence families. While our analysis of individual correlations agrees with the literature consensus, we have recently discovered that the visualized pattern of correlations is highly suggestive of structural relationships. In our preliminary test cases, human researchers can unambiguously determine many positive structural constraints by visual analysis of statistical sequence information alone, often with no training on interpretation of the visualization results. Herein we report the visualization design that supports this Visual Analytics approach to identifying high-confidence hypotheses about protein folding from protein sequence, and illustrate preliminary results from th- - is research. Our approach entails a higher-dimensional extension of parallel coordinates which illuminates distant shared sub-tuples of the vectors representing each protein sequence when these sub-tuples occur with an over abundance compared to expectations. It simultaneously eliminates all representations of tuples which occur with frequency near the expected norm. The result is a minimally-occluded representation of outlier, and only outlier co-occurrences within the sequence families.	William C. Ray	Res. Inst., Ohio State Univ. Biophys. Program, Columbus, OH, USA|c|		High-order finite elements, spectral/hp elements, cut-plane extraction, GPU-based root-finding, GPU ray-tracing, cut-surface extraction	
VAST	2010	ProDV - A case study in delivering visual analytics	10.1109/VAST.2010.5650219	http://dx.doi.org/10.1109/VAST.2010.5650219	247	248	M	We present a custom visual analytics system developed in conjunction with the test and evaluation community of the US Army. We designed and implemented a visual programming environment for configuring a variety of interactive visual analysis capabilities. Our abstraction of the visualization process is based on insights gained from interviews conducted with expert users. We show that this model allowed analysts to implement multiple visual analysis capabilities for network performance, anomalous sensor activity, and engagement results. Long-term interaction with expert users led to development of several custom visual analysis techniques. We have conducted training sessions with expert users, and are working to evaluate the success of our work based on performance metrics captured in a semi-automated fashion during these training sessions. We have also integrated collaborative analysis features such as annotations and shared content.	Derek Overby;John Keyser;Jim Wall	Dept. of Comput. Sci. & Eng., Texas A&M Univ., College Station, TX, USA|c|;;		Visualization system and toolkit design	
VAST	2010	Poster: Translating cross-filtered queries into questions	10.1109/VAST.2010.5650251	http://dx.doi.org/10.1109/VAST.2010.5650251	245	246	M	Complex combinations of coordinated multiple views are increasingly used to design tools for highly interactive visual exploration and analysis of multidimensional data. While complex coordination patterns provide substantial utility through expressive querying, they also exhibit usability problems for users when learning required interaction sequences, recalling past queries, and interpreting visual states. As visual analysis tools grow more sophisticated, there is a growing need to make them more understandable as well. Our long-term goal is to exploit natural language familiarity and literacy to directly facilitate individual and collaborative use of visual analysis tools. In this poster, we present work in progress on an automatically generated query-to-question user interface to translate interactive states during visual analysis into an accompanying visual log of formatted text. Our effort currently focuses on a symmetric and thus relatively simple coordination pattern: cross-filtered views. We describe our current thinking about query-to-question translation in a typical cross-filtered visualization of movies, people, and genres in the Internet Movie Database.	Maryam Nafari;Chris Weaver	Center for Spatial Anal., Univ. of Oklahoma, Norman, OK, USA|c|;		Coordinated multiple views, cross-filtered queries, interaction states, natural language generation, visual provenance  	
VAST	2010	Visual analysis of frequent patterns in large time series	10.1109/VAST.2010.5650766	http://dx.doi.org/10.1109/VAST.2010.5650766	227	228	M	The detection of previously unknown, frequently occurring patterns in time series, often called motifs, has been recognized as an important task. To find these motifs, we use an advanced temporal data mining algorithm. Since our algorithm usually finds hundreds of motifs, we need to analyze and access the discovered motifs. For this purpose, we introduce three novel visual analytics methods: (1) motif layout, using colored rectangles for visualizing the occurrences and hierarchical relationships of motifs in a multivariate time series, (2) motif distortion, for enlarging or shrinking motifs as appropriate for easy analysis and (3) motif merging, to combine a number of identical adjacent motif instances without cluttering the display. We have applied and evaluated our methods using two real-world data sets: data center cooling and oil well production.	Ming C. Hao;Manish Marwah;Halldór Janetzko;Daniel A. Keim;Umeshwar Dayal;Ratnesh K. Sharma;Debprakash Patnaik;Naren Ramakrishnan	;;;;;;;			
VAST	2010	Enhancing text-based chat with visuals for hazardous weather decision making	10.1109/VAST.2010.5650815	http://dx.doi.org/10.1109/VAST.2010.5650815	225	226	M	We created a visual chat application for use during hazardous weather events. The application, NWSChat2, allows National Weather Service forecasters, media members, and storm trackers to communicate with each other, basing their conversation on a common shared radar map of the storm. Users can additionally annotate the map with `pins' or draw notes with a stylus. These annotations are automatically shared with all other users. The collaborative nature of NWSChat2 makes it well-suited for disseminating information to all users during weather emergencies.	Moshe Gutman;Gina Eosco;Monica Zappa;Chris Weaver	Sch. of Comput. Sci., Univ. of Oklahoma, Norman, OK, USA|c|;;;		Collaboration, coordinated multiple views, instant messaging, emergency response, hazardous weather  	
VAST	2010	ALIDA: Using machine learning for intent discernment in visual analytics interfaces	10.1109/VAST.2010.5650854	http://dx.doi.org/10.1109/VAST.2010.5650854	223	224	M	In this paper, we introduce ALIDA, an Active Learning Intent Discerning Agent for visual analytics interfaces. As users interact with and explore data in a visual analytics environment they are each developing their own unique analytic process. The goal of ALIDA is to observe and record the human-computer interactions and utilize these observations as a means of supporting user exploration; ALIDA does this by using interaction to make decision about user interest. As such, ALIDA is designed to track the decision history (interactions) of a user. This history is then utilized to enhance the user's decision-making process by allowing the user to return to previously visited search states, as well as providing suggestions of other search states that may be of interest based on past exploration modalities. The agent passes these suggestions (or decisions) back to an interactive visualization prototype, and these suggestions are used to guide the user, either by suggesting searches or changes to the visualization view. Current work has tested ALIDA under the exploration of homonyms for users wishing to explore word linkages within a dictionary. Ongoing work includes using ALIDA to guide users in transfer function design for volume rendering within scientific gateways.	Tera Marie Green;Ross Maciejewski;Steve DiPaola	;;		artificial intelligence, cognition, intent discernment, volume rendering 	
VAST	2010	Conveying network features in geospatial battlespace displays	10.1109/VAST.2010.5651192	http://dx.doi.org/10.1109/VAST.2010.5651192	221	222	M	Advanced battlespace network visualization techniques are required within the modern Air Operations Center (AOC) to improve cross-domain situation awareness and to support planning and decision-making. We present a visualization toolkit to address this need that supports the integration of network health and status information and meta-information with other traditional AOC information resources and activities across air, space, and cyber domains. Applications include the development of battlespace visualization technologies that will improve warfighters' decision-making response time and provide enhanced flexibility for mission planning by efficiently revealing affordances for leveraging, disrupting, or enhancing network connectivity.	J. Alex Godwin;Ryan M. Kilgore	;			
VAST	2010	Visualization of temporal relationships within coordinated views	10.1109/VAST.2010.5651617	http://dx.doi.org/10.1109/VAST.2010.5651617	219	220	M	In command and control (C2) environments, decision makers must rapidly understand and address key temporal relationships that exist between critical tasks as conditions fluctuate. However, traditional temporal displays, such as mission timelines, fail to support user understanding of and reasoning about critical relationships. We have developed visualization methods to compactly and effectively convey key temporal constraints. In this paper, we present examples of our visualization approach and describe how we are exploring interaction methods within an integrated visualization workspace to support user awareness of temporal constraints.	Stephanie Dudzic;J. Alex Godwin;Ryan M. Kilgore	;;		temporal relationships, temporal visualization 	
VAST	2010	Cluster correspondence views for enhanced analysis of SOM displays	10.1109/VAST.2010.5651676	http://dx.doi.org/10.1109/VAST.2010.5651676	217	218	M	The Self-Organizing Map (SOM) algorithm is a popular and widely used cluster algorithm. Its constraint to organize clusters on a grid structure makes it very amenable to visualization. On the other hand, the grid constraint may lead to reduced cluster accuracy and reliability, compared to other clustering methods not implementing this restriction. We propose a visual cluster analysis system that allows to validate the output of the SOM algorithm by comparison with alternative clustering methods. Specifically, visual mappings overlaying alternative clustering results onto the SOM are proposed. We apply our system on an example data set, and outline main analytical use cases.	Jürgen Bernard;Tatiana von Landesberger;Sebastian Bremm;Tobias Schreck	Interactive Graphics Syst. Group, Tech. Univ. Darmstadt, Darmstadt, Germany|c|;;;			
VAST	2010	Interactive visual analysis of multiobjective optimizations	10.1109/VAST.2010.5651694	http://dx.doi.org/10.1109/VAST.2010.5651694	215	216	M	Optimization problems are typically addressed by purely automatic approaches. For multi-objective problems, however, a single best solution often does not exist. In this case, it is necessary to analyze trade-offs between many conflicting goals within a given application context. This poster describes an approach that tightly integrates automatic algorithms for multi-objective optimization and interactive multivariate visualizations. Ad-hoc selections support a flexible definition of input data for subsequent algorithms. These algorithms in turn represent their result as derived data attributes that can be assigned to visualizations or be used as a basis for further selections (e.g., to constrain the result set). This enables a guided search that still involves the knowledge of domain experts. We describe our approach in the context of multi-run simulation data from the application domain of car engine design.	Wolfgang Berger;Harald Piringer	VRVis Res. Center, Vienna, Austria|c|;			
VAST	2010	DimStiller: Workflows for dimensional analysis and reduction	10.1109/VAST.2010.5652392	http://dx.doi.org/10.1109/VAST.2010.5652392	3	10	C	DimStiller is a system for dimensionality reduction and analysis. It frames the task of understanding and transforming input dimensions as a series of analysis steps where users transform data tables by chaining together different techniques, called operators, into pipelines of expressions. The individual operators have controls and views that are linked together based on the structure of the expression. Users interact with the operator controls to tune parameter choices, with immediate visual feedback guiding the exploration of local neighborhoods of the space of possible data tables. DimStiller also provides global guidance for navigating data-table space through expression templates called workflows, which permit re-use of common patterns of analysis.	Stephen Ingram;Tamara Munzner;Veronika Irvine;Melanie Tory;Steven Bergner;Torsten Möller	Univ. of British Columbia, Vancouver, BC, Canada|c|;;;;;	10.1109/INFVIS.2003.1249013;10.1109/VISUAL.1994.346302;10.1109/TVCG.2006.178;10.1109/INFVIS.2003.1249015;10.1109/TVCG.2009.153;10.1109/INFVIS.2004.71		
VAST	2010	Visual exploration of classification models for risk assessment	10.1109/VAST.2010.5652398	http://dx.doi.org/10.1109/VAST.2010.5652398	11	18	C	In risk assessment applications well informed decisions are made based on huge amounts of multi-dimensional data. In many domains not only the risk of a wrong decision, but in particular the trade-off between the costs of possible decisions are of utmost importance. In this paper we describe a framework tightly integrating interactive visual exploration with machine learning to support the decision making process. The proposed approach uses a series of interactive 2D visualizations of numeric and ordinal data combined with visualization of classification models. These series of visual elements are further linked to the classifier's performance visualized using an interactive performance curve. An interactive decision point on the performance curve allows the decision maker to steer the classification model and instantly identify the critical, cost changing data elements, in the various linked visualizations. The critical data elements are represented as images in order to trigger associations related to the knowledge of the expert. In this context the data visualization and classification results are not only linked together, but are also linked back to the classification model. Such a visual analytics framework allows the user to interactively explore the costs of his decisions for different settings of the model and accordingly use the most suitable classification model and make more informed and reliable decisions. A case study on data from the Forensic Psychiatry domain reveals the usefulness of the suggested approach.	Malgorzata Migut;Marcel Worring	Intell. Syst. Lab. Amsterdam, Univ. of Amsterdam, Amsterdam, Netherlands|c|;	10.1109/TVCG.2007.70515;10.1109/INFVIS.2005.1532139;10.1109/VAST.2009.5332628;10.1109/INFVIS.1998.729559;10.1109/TVCG.2009.199;10.1109/INFVIS.2000.885086;10.1109/TVCG.2007.70521;10.1109/VAST.2008.4677369;10.1109/VISUAL.1994.346302;10.1109/TVCG.2008.153	Visual Analytics, Interactive Visual Exploration, Decision Boundary Visualization, Multi-dimensional Space, Classification	
VAST	2010	Improving the visual analysis of high-dimensional datasets using quality measures	10.1109/VAST.2010.5652433	http://dx.doi.org/10.1109/VAST.2010.5652433	19	26	C	Modern visualization methods are needed to cope with very high-dimensional data. Efficient visual analytical techniques are required to extract the information content in these data. The large number of possible projections for each method, which usually grow quadrat-ically or even exponentially with the number of dimensions, urges the necessity to employ automatic reduction techniques, automatic sorting or selecting the projections, based on their information-bearing content. Different quality measures have been successfully applied for several specified user tasks and established visualization techniques, like Scatterplots, Scatterplot Matrices or Parallel Coordinates. Many other popular visualization techniques exist, but due to the structural differences, the measures are not directly applicable to them and new approaches are needed. In this paper we propose new quality measures for three popular visualization methods: Radviz, Pixel-Oriented Displays and Table Lenses. Our experiments show that these measures efficiently guide the visual analysis task.	Georgia Albuquerque;Martin Eisemann;Dirk J. Lehmann;Holger Theisel;Marcus A. Magnor	Tech. Univ. Braunschweig, Braunschweig, Germany|c|;;;;	10.1109/INFVIS.2005.1532145;10.1109/INFVIS.2005.1532142;10.1109/VISUAL.1997.663916;10.1109/VAST.2006.261423;10.1109/VAST.2009.5332628;10.1109/TVCG.2008.173		
VAST	2010	iVisClassifier: An interactive visual analytics system for classification based on supervised dimension reduction	10.1109/VAST.2010.5652443	http://dx.doi.org/10.1109/VAST.2010.5652443	27	34	C	We present an interactive visual analytics system for classification, iVisClassifier, based on a supervised dimension reduction method, linear discriminant analysis (LDA). Given high-dimensional data and associated cluster labels, LDA gives their reduced dimensional representation, which provides a good overview about the cluster structure. Instead of a single two- or three-dimensional scatter plot, iVisClassifier fully interacts with all the reduced dimensions obtained by LDA through parallel coordinates and a scatter plot. Furthermore, it significantly improves the interactivity and interpretability of LDA. LDA enables users to understand each of the reduced dimensions and how they influence the data by reconstructing the basis vector into the original data domain. By using heat maps, iVisClassifier gives an overview about the cluster relationship in terms of pairwise distances between cluster centroids both in the original space and in the reduced dimensional space. Equipped with these functionalities, iVisClassifier supports users' classification tasks in an efficient way. Using several facial image data, we show how the above analysis is performed.	Jaegul Choo;Hanseung Lee;Jaeyeon Kihm;Haesun Park	Sch. of Comput. Sci. & Eng., Georgia Inst. of Technol., Atlanta, GA, USA|c|;;;	10.1109/VAST.2009.5332629;10.1109/INFVIS.2003.1249015;10.1109/INFVIS.2004.60;10.1109/TVCG.2009.153		
VAST	2010	finding and visualizing relevant subspaces for clustering high-dimensional astronomical data using connected morphological operators	10.1109/VAST.2010.5652450	http://dx.doi.org/10.1109/VAST.2010.5652450	35	42	C	Data sets in astronomy are growing to enormous sizes. Modern astronomical surveys provide not only image data but also catalogues of millions of objects (stars, galaxies), each object with hundreds of associated parameters. Exploration of this very high-dimensional data space poses a huge challenge. Subspace clustering is one among several approaches which have been proposed for this purpose in recent years. However, many clustering algorithms require the user to set a large number of parameters without any guidelines. Some methods also do not provide a concise summary of the datasets, or, if they do, they lack additional important information such as the number of clusters present or the significance of the clusters. In this paper, we propose a method for ranking subspaces for clustering which overcomes many of the above limitations. First we carry out a transformation from parametric space to discrete image space where the data are represented by a grid-based density field. Then we apply so-called connected morphological operators on this density field of astronomical objects that provides visual support for the analysis of the important subspaces. Clusters in subspaces correspond to high-intensity regions in the density image. The importance of a cluster is measured by a new quality criterion based on the dynamics of local maxima of the density. Connected operators are able to extract such regions with an indication of the number of clusters present. The subspaces are visualized during computation of the quality measure, so that the user can interact with the system to improve the results. In the result stage, we use three visualization toolkits linked within a graphical user interface so that the user can perform an in-depth exploration of the ranked subspaces. Evaluation based on synthetic as well as real astronomical datasets demonstrates the power of the new method. We recover various known astronomical relations directly from the data with little or no a pri- - ori assumptions. Hence, our method holds good prospects for discovering new relations as well.	Bilkis J. Ferdosi;Hugo Buddelmeijer;Scott C. Trager;Michael H. F. Wilkinson;Jos B. T. M. Roerdink	Johann Bernoulli Inst. for Math. & Comput. Sci., Univ. of Groningen, Groningen, Netherlands|c|;;;;		Subspace finding, clustering high-dimensional data, connected morphological operators, visual exploration, astronomical data	
VAST	2010	Flow-based scatterplots for sensitivity analysis	10.1109/VAST.2010.5652460	http://dx.doi.org/10.1109/VAST.2010.5652460	43	50	C	Visualization of multi-dimensional data is challenging due to the number of complex correlations that may be present in the data but that are difficult to be visually identified. One of the main causes for this problem is the inherent loss of information that occurs when high-dimensional data is projected into 2D or 3D. Although 2D scatterplots are ubiquitous due to their simplicity and familiarity, there are not a lot of variations on their basic metaphor. In this paper, we present a new way of visualizing multidimensional data using scatterplots. We extend 2D scatterplots using sensitivity coefficients to highlight local variation of one variable with respect to another. When applied to a scatterplot, these sensitivities can be understood as velocities, and the resulting visualization resembles a flow field. We also present a number of operations, based on flow-field analysis, that help users navigate, select and cluster points in an efficient manner. We show the flexibility and generality of this approach using a number of multidimensional data sets across different domains.	Yu-Hsuan Chan;Carlos D. Correa;Kwan-Liu Ma	Univ. of California at Davis, Davis, CA, USA|c|;;	10.1109/TVCG.2008.119;10.1109/VAST.2008.4677368;10.1109/VAST.2009.5332611;10.1109/VAST.2007.4389000;10.1109/TVCG.2006.166;10.1109/TVCG.2008.153	Uncertainty, Data Transformations, Principal Component Analysis, Model fitting  	
VAST	2010	Anomaly detection in GPS data based on visual analytics	10.1109/VAST.2010.5652467	http://dx.doi.org/10.1109/VAST.2010.5652467	51	58	C	Modern machine learning techniques provide robust approaches for data-driven modeling and critical information extraction, while human experts hold the advantage of possessing high-level intelligence and domain-specific expertise. We combine the power of the two for anomaly detection in GPS data by integrating them through a visualization and human-computer interaction interface. In this paper we introduce GPSvas (GPS Visual Analytics System), a system that detects anomalies in GPS data using the approach of visual analytics: a conditional random field (CRF) model is used as the machine learning component for anomaly detection in streaming GPS traces. A visualization component and an interactive user interface are built to visualize the data stream, display significant analysis results (i.e., anomalies or uncertain predications) and hidden information extracted by the anomaly detection model, which enable human experts to observe the real-time data behavior and gain insights into the data flow. Human experts further provide guidance to the machine learning model through the interaction tools; the learning model is then incrementally improved through an active learning procedure.	Zicheng Liao;Yizhou Yu;Baoquan Chen	Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA|c|;;	10.1109/TVCG.2009.145		
VAST	2010	Discovering bits of place histories from people's activity traces	10.1109/VAST.2010.5652478	http://dx.doi.org/10.1109/VAST.2010.5652478	59	66	C	Events that happened in the past are important for understanding the ongoing processes, predicting future developments, and making informed decisions. Significant and/or interesting events tend to attract many people. Some people leave traces of their attendance in the form of computer-processable data, such as records in the databases of mobile phone operators or photos on photo sharing web sites. We developed a suite of visual analytics methods for reconstructing past events from these activity traces. Our tools combine geocomputations, interactive geovisualizations and statistical methods to enable integrated analysis of the spatial, temporal, and thematic components of the data, including numeric attributes and texts. We demonstrate the utility of our approach on two large real data sets, mobile phone calls in Milano during 9 days and flickr photos made on British Isles during 5 years.	Gennady L. Andrienko;Natalia V. Andrienko;Martin Mladenov;Michael Mock;Christian Pölitz	Fraunhofer Inst. IAIS (Intell. Anal. & Inf. Syst.), St. Augustin, Germany|c|;;;;	10.1109/INFVIS.1999.801851;10.1109/TVCG.2007.70621	event detection, spatio-temporal data, time series analysis, scalable visualization, geovisualization  	
VAST	2010	A visual analytics approach to model learning	10.1109/VAST.2010.5652484	http://dx.doi.org/10.1109/VAST.2010.5652484	67	74	C	The process of learning models from raw data typically requires a substantial amount of user input during the model initialization phase. We present an assistive visualization system which greatly reduces the load on the users and makes the process of model initialization and refinement more efficient, problem-driven, and engaging. Utilizing a sequence segmentation task with a Hidden Markov Model as an example, we assign each token in the sequence a feature vector based on its various properties within the sequence. These vectors are then clustered according to similarity, generating a layout of the individual tokens in form of a node link diagram where the length of the links is determined by the feature vector similarity. Users may then tune the weights of the feature vector components to improve the segmentation, which is visualized as a better separation of the clusters. Also, as individual clusters represent different classes, the user can now work at the cluster level to define token classes, instead of labelling one entry at time. Inconsistent entries visually identify themselves by locating at the periphery of clusters, and the user then helps refine the model by resolving these inconsistencies. Our system therefore makes efficient use of the knowledge of its users, only requesting user assistance for non-trivial data items. It so allows users to visually analyse data at a higher, more abstract level, improving scalability.	Supriya Garg;I. V. Ramakrishnan;Klaus Mueller	Comput. Sci. Dept., Stony Brook Univ., Stony Brook, NY, USA|c|;;	10.1109/VAST.2008.4677352;10.1109/VAST.2008.4677350;10.1109/VAST.2009.5332584;10.1109/VAST.2007.4388990;10.1109/VAST.2009.5333428;10.1109/TVCG.2007.70592	Visual Knowledge Discovery, Visual Knowledge Representation, Data Clustering, Human-Computer Interaction  	
VAST	2010	Multidimensional data dissection using attribute relationship graphs	10.1109/VAST.2010.5652520	http://dx.doi.org/10.1109/VAST.2010.5652520	75	82	C	Visual exploration and analysis is a process of discovering and dissecting the abundant and complex attribute relationships that pervade multidimensional data. Recent research has identified and characterized patterns of multiple coordinated views, such as cross-filtered views, in which rapid sequences of simple interactions can be used to express queries on subsets of attribute values. In visualizations designed around these patterns, for the most part, distinct views serve to visually isolate each attribute from the others. Although the brush-and-click simplicity of visual isolation facilitates discovery of many-to-many relationships between attributes, dissecting these relationships into more fine-grained one-to-many relationships is interactively tedious and, worse, visually fragmented over prolonged sequences of queries. This paper describes: (1) a method for interactively dissecting multidimensional data by iteratively slicing and manipulating a multigraph representation of data values and value co-occurrences; and (2) design strategies for extending the construction of coordinated multiple view interfaces for dissection as well as discovery of attribute relationships in multidimensional data sets. Using examples from different domains, we describe how attribute relationship graphs can be combined with cross-filtered views, modularized for reuse across designs, and integrated into broader visual analysis tools. The exploratory and analytic utility of these examples suggests that an attribute relationship graph would be a useful addition to a wide variety of visual analysis tools.	Chris Weaver	Center for Spatial Anal., Univ. of Oklahoma, Norman, OK, USA|c|	10.1109/TVCG.2008.137;10.1109/TVCG.2006.122;10.1109/VAST.2006.261432;10.1109/INFVIS.2004.12;10.1109/TVCG.2006.178;10.1109/INFVIS.2002.1173158;10.1109/VISUAL.1994.346302;10.1109/INFVIS.1998.729560;10.1109/TVCG.2007.70582;10.1109/TVCG.2007.70594;10.1109/VAST.2007.4389006;10.1109/INFVIS.2005.1532129;10.1109/INFVIS.2004.64		
VAST	2010	Visual market sector analysis for financial time series data	10.1109/VAST.2010.5652530	http://dx.doi.org/10.1109/VAST.2010.5652530	83	90	C	The massive amount of financial time series data that originates from the stock market generates large amounts of complex data of high interest. However, adequate solutions that can effectively handle the information in order to gain insight and to understand the market mechanisms are rare. In this paper, we present two techniques and applications that enable the user to interactively analyze large amounts of time series data in real-time in order to get insight into the development of assets, market sectors, countries, and the financial market as a whole. The first technique allows users to quickly analyze combinations of single assets, market sectors as well as countries, compare them to each other, and to visually discover the periods of time where market sectors and countries get into turbulence. The second application clusters a selection of large amounts of financial time series data according to their similarity, and analyzes the distribution of the assets among market sectors. This allows users to identify the characteristic graphs which are representative for the development of a particular market sector, and also to identify the assets which behave considerably differently compared to other assets in the same sector. Both applications allow the user to perform investigative exploration techniques and interactive visual analysis in real-time.	Hartmut Ziegler;Marco Jenny;Tino Gruse;Daniel A. Keim	Univ. of Konstanz, Konstanz, Germany|c|;;;	10.1109/INFVIS.2001.963273;10.1109/INFVIS.1997.636789;10.1109/INFVIS.2001.963288;10.1109/INFVIS.1999.801851;10.1109/INFVIS.2003.1249027	Visual Analytics, financial Information Visualization, Time Series Data, Time Series Clustering, Explorative Analysis  	
VAST	2010	Large-scale neuroanatomical visualization using a manifold embedding approach	10.1109/VAST.2010.5652532	http://dx.doi.org/10.1109/VAST.2010.5652532	237	238	M	We present a unified framework for data processing, mining and interactive visualization of large-scale neuroanatomical databases. The input data is assumed to lie in a specific atlas space, or simply exist as a separate collection. Users can specify their own atlas for comparative analyses. The original data exist as MRI images in standard formats. It is uploaded to a remote server and processed offline by a parallelized pipeline workflow. This workflow transforms the data to represent it as both volumetric and triangular mesh cortical surfaces. We use multiresolution representations to scale complexity to data storage availability as well as graphical processing performance. Our workflow implements predefined metrics for clustering and classification, and data projection schemes to aid in visualization. Additionally the system provides a visual query interface for performing selection requests based on user-defined search criteria.	Shantanu H. Joshi;Ian Bowman;John D. Van Horn	Dept. of Neurology, Univ. of California, Los Angeles, CA, USA|c|;;			
VAST	2010	A closer look at note taking in the co-located collaborative visual analytics process	10.1109/VAST.2010.5652879	http://dx.doi.org/10.1109/VAST.2010.5652879	171	178	C	This paper highlights the important role that record-keeping (i.e. taking notes and saving charts) plays in collaborative data analysis within the business domain. The discussion of record-keeping is based on observations from a user study in which co-located teams worked on collaborative visual analytics tasks using large interactive wall and tabletop displays. Part of our findings is a collaborative data analysis framework that encompasses note taking as one of the main activities. We observed that record-keeping was a critical activity within the analysis process. Based on our observations, we characterize notes according to their content, scope, and usage, and describe how they fit into a process of collaborative data analysis. We then discuss suggestions for the design of collaborative visual analytics tools.	Narges Mahyar;Ali Sarvghad;Melanie Tory	Univ. of Victoria, Victoria, BC, Canada|c|;;	10.1109/TVCG.2008.137;10.1109/VAST.2008.4677358;10.1109/TVCG.2007.70568;10.1109/VAST.2009.5333020;10.1109/VAST.2008.4677365;10.1109/VAST.2009.5333023;10.1109/TVCG.2007.70577	note taking, recording, collaboration, tabletop, wall display, history, provenance  	
VAST	2010	An exploratory study of co-located collaborative visual analytics around a tabletop display	10.1109/VAST.2010.5652880	http://dx.doi.org/10.1109/VAST.2010.5652880	179	186	C	Co-located collaboration can be extremely valuable during complex visual analytics tasks. This paper presents an exploratory study of a system designed to support collaborative visual analysis tasks on a digital tabletop display. Fifteen participant pairs employed Cam-biera, a visual analytics system, to solve a problem involving 240 digital documents. Our analysis, supported by observations, system logs, questionnaires, and interview data, explores how pairs approached the problem around the table. We contribute a unique, rich understanding of how users worked together around the table and identify eight types of collaboration styles that can be used to identify how closely people work together while problem solving. We show how the closeness of teams' collaboration influenced how well they performed on the task overall. We further discuss the role of the tabletop for visual analytics tasks and derive novel design implications for future co-located collaborative tabletop problem solving systems.	Petra Isenberg;Danyel Fisher;Meredith Ringel Morris;Kori Inkpen Quinn;Mary Czerwinski	;;;;	10.1109/VAST.2006.261439;10.1109/VAST.2007.4389006;10.1109/VAST.2006.261415;10.1109/TVCG.2007.70577;10.1109/VAST.2008.4677358;10.1109/TVCG.2007.70568		
VAST	2010	Click2Annotate: Automated Insight Externalization with rich semantics	10.1109/VAST.2010.5652885	http://dx.doi.org/10.1109/VAST.2010.5652885	155	162	C	Insight Externalization (IE) refers to the process of capturing and recording the semantics of insights in decision making and problem solving. To reduce human effort, Automated Insight Externalization (AIE) is desired. Most existing IE approaches achieve automation by capturing events (e.g., clicks and key presses) or actions (e.g., panning and zooming). In this paper, we propose a novel AIE approach named Click2Annotate. It allows semi-automatic insight annotation that captures low-level analytics task results (e.g., clusters and outliers), which have higher semantic richness and abstraction levels than actions and events. Click2Annotate has two significant benefits. First, it reduces human effort required in IE and generates annotations easy to understand. Second, the rich semantic information encoded in the annotations enables various insight management activities, such as insight browsing and insight retrieval. We present a formal user study that proved this first benefit. We also illustrate the second benefit by presenting the novel insight management activities we developed based on Click2Annotate, namely scented insight browsing and faceted insight search.	Yang Chen;Scott Barlowe;Jing Yang 0001	Dept. of Comput. Sci., UNC Charlotte, Charlotte, NC, USA|c|;;	10.1109/VISUAL.1990.146375;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2007.70541;10.1109/VAST.2008.4677365;10.1109/TVCG.2007.70577;10.1109/TVCG.2009.139	Visual Analytics, Decision Making, Annotation, Insight Management, Multidimensional Visualization	
VAST	2010	Interactive querying of temporal data using a comic strip metaphor	10.1109/VAST.2010.5652890	http://dx.doi.org/10.1109/VAST.2010.5652890	163	170	C	Finding patterns in temporal data is an important data analysis task in many domains. Static visualizations can help users easily see certain instances of patterns, but are not specially designed to support systematic analysis tasks, such as finding all instances of a pattern automatically. VizPattern is an interactive visual query environment that uses a comic strip metaphor to enable users to easily and quickly define and locate complex temporal patterns. Evaluations provide evidence that VizPattern is applicable in many domains, and that it enables a wide variety of users to answer questions about temporal data faster and with fewer errors than existing state-of-the-art visual analysis systems.	Jing Jin;Pedro A. Szekely	Inf. Sci. Inst., Univ. of Southern California, Los Angeles, CA, USA|c|;	10.1109/VAST.2006.261421;10.1109/VAST.2006.261436		
VAST	2010	Geo-historical context support for information foraging and sensemaking: Conceptual model, implementation, and assessment	10.1109/VAST.2010.5652895	http://dx.doi.org/10.1109/VAST.2010.5652895	139	146	C	Information foraging and sensemaking with heterogeneous information are context-dependent activities. Thus visual analytics tools to support these activities must incorporate context. But, context is a difficult concept to define, model, and represent. Creating and representing context in support of visually-enabled reasoning about complex problems with complex information is a complementary but different challenge than that addressed in context-aware computing. In the latter, the goal is automated adaptation of the system to meet user needs for applications such as mobile location-based services where information about the location, the user, and the user goals filters what gets presented on a small mobile device. In contrast, for visual analytics-enabled information foraging and sensemaking, the user is likely to take an active role in foraging for the contextual information needed to support sensemaking in relation to some multifaceted problem. In this paper, we address the challenges of constructing and representing context within visual interfaces that support analytical reasoning in crisis management and humanitarian relief. The challenges stem from the diverse forms of information that can provide context and difficulty in defining and operationalizing context itself. Here, we pay particular attention to document foraging to support construction of the geographic and historical context within which monitoring and sensemaking can be carried out. Specifically, we present the concept of geo-historical context (GHC) and outline an empirical assessment of both the concept and its implementation in the Context Discovery Application, a web-based tool that supports document foraging and sensemaking.	Brian M. Tomaszewski;Alan M. MacEachren	Dept. of Inf. Sci. & Technol., Rochester Inst. of Technol., Rochester, NY, USA|c|;		context, foraging, sensemaking, mapping, text analysis, geographic information retrieval  	
VAST	2010	Real-time aggregation of Wikipedia data for visual analytics	10.1109/VAST.2010.5652896	http://dx.doi.org/10.1109/VAST.2010.5652896	147	154	C	Wikipedia has been built to gather encyclopedic knowledge using a collaborative social process that has proved its effectiveness. However, the workload required for raising the quality and increasing the coverage of Wikipedia is exhausting the community. Based on several participatory design sessions with active Wikipedia contributors (a.k.a. Wikipedians), we have collected a set of measures related to Wikipedia activity that, if available and visualized effectively, could spare a lot of monitoring time to these Wikipedians, allowing them to focus on quality and coverage of Wikipedia instead of spending their time navigating heavily to track vandals and copyright infringements. However, most of these measures cannot be computed on the fly using the available Wikipedia API. Therefore, we have designed an open architecture called WikiReactive to compute incrementally and maintain several aggregated measures on the French Wikipedia. This aggregated data is available as a Web Service and can be used to overlay information on Wikipedia articles through Wikipedia Skins or for new services for Wikipedians or people studying Wikipedia. This article describes the architecture, its performance and some of its uses.	Nadia Boukhelifa;Fanny Chevalier;Jean-Daniel Fekete	;;			
VAST	2010	NetClinic: Interactive visualization to enhance automated fault diagnosis in enterprise networks	10.1109/VAST.2010.5652910	http://dx.doi.org/10.1109/VAST.2010.5652910	131	138	C	Diagnosing faults in an operational computer network is a frustrating, time-consuming exercise. Despite advances, automatic diagnostic tools are far from perfect: they occasionally miss the true culprit and are mostly only good at narrowing down the search to a few potential culprits. This uncertainty and the inability to extract useful sense from tool output renders most tools not usable to administrators. To bridge this gap, we present NetClinic, a visual analytics system that couples interactive visualization with an automated diagnostic tool for enterprise networks. It enables administrators to verify the output of the automatic analysis at different levels of detail and to move seamlessly across levels while retaining appropriate context. A qualitative user study shows that NetClinic users can accurately identify the culprit, even when it is not present in the suggestions made by the automated component. We also find that supporting a variety of sensemaking strategies is a key to the success of systems that enhance automated diagnosis.	Zhicheng Liu;Bongshin Lee;Srikanth Kandula;Ratul Mahajan	;;;	10.1109/TVCG.2006.122;10.1109/TVCG.2007.70522;10.1109/VAST.2009.5333878;10.1109/VAST.2007.4389006;10.1109/VAST.2006.261429	Sensemaking, Semantic Graph Layout, Visual Analytics, Network Diagnosis, Information Visualization	
VAST	2010	Diamonds in the rough: Social media visual analytics for journalistic inquiry	10.1109/VAST.2010.5652922	http://dx.doi.org/10.1109/VAST.2010.5652922	115	122	C	Journalists increasingly turn to social media sources such as Facebook or Twitter to support their coverage of various news events. For large-scale events such as televised debates and speeches, the amount of content on social media can easily become overwhelming, yet still contain information that may aid and augment reporting via individual content items as well as via aggregate information from the crowd's response. In this work we present a visual analytic tool, Vox Civitas, designed to help journalists and media professionals extract news value from large-scale aggregations of social media content around broadcast events. We discuss the design of the tool, present the text analysis techniques used to enable the presentation, and provide details on the visual and interaction design. We provide an exploratory evaluation based on a user study in which journalists interacted with the system to explore and report on a dataset of over one hundred thousand twitter messages collected during the U.S. State of the Union presidential address in 2010.	Nicholas Diakopoulos;Mor Naaman;Funda Kivran-Swaine	;;	10.1109/VAST.2009.5333437;10.1109/VAST.2009.5333443;10.1109/VAST.2009.5333878;10.1109/VAST.2008.4677364	Computational Journalism, Computer Assisted Reporting, Social Media, Sensemaking  	
VAST	2010	Visual readability analysis: How to make your writings easier to read	10.1109/VAST.2010.5652926	http://dx.doi.org/10.1109/VAST.2010.5652926	123	130	C	We present a tool that is specifically designed to support a writer in revising a draft-version of a document. In addition to showing which paragraphs and sentences are difficult to read and understand, we assist the reader in understanding why this is the case. This requires features that are expressive predictors of readability, and are also semantically understandable. In the first part of the paper, we therefore discuss a semi-automatic feature selection approach that is used to choose appropriate measures from a collection of 141 candidate readability features. In the second part, we present the visual analysis tool VisRA, which allows the user to analyze the feature values across the text and within single sentences. The user can choose different visual representations accounting for differences in the size of the documents and the availability of information about the physical and logical layout of the documents. We put special emphasis on providing as much transparency as possible to ensure that the user can purposefully improve the readability of a sentence. Several case-studies are presented that show the wide range of applicability of our tool.	Daniela Oelke;David Spretke;Andreas Stoffel;Daniel A. Keim	Univ. of Konstanz, Konstanz, Germany|c|;;;	10.1109/VAST.2007.4389004		
VAST	2010	Understanding text corpora with multiple facets	10.1109/VAST.2010.5652931	http://dx.doi.org/10.1109/VAST.2010.5652931	99	106	C	Text visualization becomes an increasingly more important research topic as the need to understand massive-scale textual information is proven to be imperative for many people and businesses. However, it is still very challenging to design effective visual metaphors to represent large corpora of text due to the unstructured and high-dimensional nature of text. In this paper, we propose a data model that can be used to represent most of the text corpora. Such a data model contains four basic types of facets: time, category, content (unstructured), and structured facet. To understand the corpus with such a data model, we develop a hybrid visualization by combining the trend graph with tag-clouds. We encode the four types of data facets with four separate visual dimensions. To help people discover evolutionary and correlation patterns, we also develop several visual interaction methods that allow people to interactively analyze text by one or more facets. Finally, we present two case studies to demonstrate the effectiveness of our solution in support of multi-faceted visual analysis of text corpora.	Lei Shi;Furu Wei;Shixia Liu;Li Tan;Xiaoxiao Lian;Michelle X. Zhou	IBM Res. - China, Beijing, China|c|;;;;;	10.1109/VAST.2009.5333443;10.1109/VAST.2007.4389005;10.1109/TVCG.2008.172;10.1109/TVCG.2009.171;10.1109/TVCG.2008.166;10.1109/TVCG.2009.165;10.1109/INFVIS.2002.1173155;10.1109/INFVIS.1999.801866;10.1109/VAST.2007.4389006;10.1109/INFVIS.2005.1532122;10.1109/INFVIS.2000.885097	text visualization, multi-facet data visualization	
VAST	2010	VizCept: Supporting synchronous collaboration for constructing visualizations in intelligence analysis	10.1109/VAST.2010.5652932	http://dx.doi.org/10.1109/VAST.2010.5652932	107	114	C	In this paper, we present a new web-based visual analytics system, VizCept, which is designed to support fluid, collaborative analysis of large textual intelligence datasets. The main approach of the design is to combine individual workspace and shared visualization in an integrated environment. Collaborating analysts will be able to identify concepts and relationships from the dataset based on keyword searches in their own workspace and collaborate visually with other analysts using visualization tools such as a concept map view and a timeline view. The system allows analysts to parallelize the work by dividing initial sets of concepts, investigating them on their own workspace, and then integrating individual findings automatically on shared visualizations with support for interaction and personal graph layout in real time, in order to develop a unified plot. We highlight several design considerations that promote communication and analytic performance in small team synchronous collaboration. We report the result of a pair of case study applications including collaboration and communication methods, analysis strategies, and user behaviors under a competition setting in the same location at the same time. The results of these demonstrate the tool's effectiveness for synchronous collaborative construction and use of visualizations in intelligence data analysis.	Haeyong Chung;Seungwon Yang;Naveed Massjouni;Christopher Andrews;Rahul Kanna;Chris North	Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA|c|;;;;;	10.1109/TVCG.2009.148;10.1109/VAST.2007.4389006;10.1109/VAST.2009.5333245;10.1109/VAST.2008.4677362;10.1109/TVCG.2007.70577;10.1109/VAST.2008.4677366	Collaborative visualization, text and document data, intelligence analysis	
VAST	2010	Two-stage framework for a topology-based projection and visualization of classified document collections	10.1109/VAST.2010.5652940	http://dx.doi.org/10.1109/VAST.2010.5652940	91	98	C	During the last decades, electronic textual information has become the world's largest and most important information source. Daily newspapers, books, scientific and governmental publications, blogs and private messages have grown into a wellspring of endless information and knowledge. Since neither existing nor new information can be read in its entirety, we rely increasingly on computers to extract and visualize meaningful or interesting topics and documents from this huge information reservoir. In this paper, we extend, improve and combine existing individual approaches into an overall framework that supports topologi-cal analysis of high dimensional document point clouds given by the well-known tf-idf document-term weighting method. We show that traditional distance-based approaches fail in very high dimensional spaces, and we describe an improved two-stage method for topology-based projections from the original high dimensional information space to both two dimensional (2-D) and three dimensional (3-D) visualizations. To demonstrate the accuracy and usability of this framework, we compare it to methods introduced recently and apply it to complex document and patent collections.	Patrick Oesterling;Gerik Scheuermann;Sven Teresniak;Gerhard Heyer;Steffen Koch;Thomas Ertl;Gunther H. Weber	Univ. of Leipzig, Leipzig, Germany|c|;;;;;;	10.1109/VAST.2009.5333564;10.1109/TVCG.2007.70601;10.1109/VISUAL.1990.146402;10.1109/INFVIS.1995.528686;10.1109/VAST.2009.5332629;10.1109/TVCG.2009.119		
VAST	2010	Visually representing geo-temporal differences	10.1109/VAST.2010.5652951	http://dx.doi.org/10.1109/VAST.2010.5652951	229	230	M	Data sets that contain geospatial and temporal elements can be challenging to analyze. In particular, it can be difficult to determine how the data have changed over spatial and temporal ranges. In this poster, we present a visual approach for representing the pair-wise differences between geographically and temporally binned data. In addition to providing a novel method for visualizing such geo-temporal differences, GTdiff provides a high degree of interactivity that supports the exploration and analysis of the data.	Orland Hoeber;Garnett Carl Wilson;Simon Harding;René Enguehard;Rodolphe Devillers	;;;;			
VAST	2010	A continuous analysis process between desktop and collaborative visual analytics environments	10.1109/VAST.2010.5652958	http://dx.doi.org/10.1109/VAST.2010.5652958	231	232	M	Since its inception, the field of visual analytics has undergone tremendous growth in understanding how to create interactive visual tools to solve analytical problems. However, with few exceptions, most of these tools have been designed for single users in desktop environments. While often effective on their own, most single-user systems do not reflect the collaborative nature of solving real-world analytical tasks. Many intelligence analysts, for example, have been observed to switch repeatedly between working alone and collaborating with members of a small team. In this paper, we propose that a complete visual analytical system designed for solving real-world tasks ought to have two integrated components: a single-user desktop system and a mirroring system suitable for a collaborative environment.	Dong Hyun Jeong;Evan A. Suma;Thomas Butkiewicz;William Ribarsky;Remco Chang	Univ. of the District of Columbia, Washington, DC, USA|c|;;;;			
VAST	2010	EmailTime: Visual analytics of emails	10.1109/VAST.2010.5652968	http://dx.doi.org/10.1109/VAST.2010.5652968	233	234	M	Although the discovery and analysis of communication patterns in large and complex email datasets are difficult tasks, they can be a valuable source of information. This paper presents EmailTime's capabilities through several examples. EmailTime is a visual analysis of email correspondence patterns over the course of time that interactively portrays personal and interpersonal networks using the correspondence in the email dataset. We suggest that integrating both statistics and visualizations in order to display information about the email datasets may simplify its evaluation.	Minoo Erfani Joorabchi;Ji-Dong Yim;Chris Shaw 0002	;;		Email, Enron, EmailTime, Email Correspondents, Visual Analysis	
VAST	2010	Poster: Dynamic time transformation for interpreting clusters of trajectories with space-time cube	10.1109/VAST.2010.5653580	http://dx.doi.org/10.1109/VAST.2010.5653580	213	214	M	We propose a set of techniques that support visual interpretation of trajectory clusters by transforming absolute time references into relative positions within temporal cycles or with respect to the starting and/or ending times of the trajectories. We demonstrate the work of the approach on a real data set about individual movement over one year.	Gennady L. Andrienko;Natalia V. Andrienko	;			
VAST	2010	Towards the Personal Equation of Interaction: The impact of personality factors on visual analytics interface interaction	10.1109/VAST.2010.5653587	http://dx.doi.org/10.1109/VAST.2010.5653587	203	210	C	These current studies explored the impact of individual differences in personality factors on interface interaction and learning performance behaviors in both an interactive visualization and a menu-driven web table in two studies. Participants were administered 3 psychometric measures designed to assess Locus of Control, Extraversion, and Neuroticism. Participants were then asked to complete multiple procedural learning tasks in each interface. Results demonstrated that all three measures predicted completion times. Additionally, results analyses demonstrated personality factors also predicted the number of insights participants reported while completing the tasks in each interface. We discuss how these findings advance our ongoing research in the Personal Equation of Interaction.	Tera Marie Green;Brian D. Fisher	Sch. of Interactive Arts + Technol., Simon Fraser Univ., Surrey, BC, Canada|c|;		visual analytics, cognition and perception theory, embodied cognition, visualization taxonomies and models  	
VAST	2010	Helping users recall their reasoning process	10.1109/VAST.2010.5653598	http://dx.doi.org/10.1109/VAST.2010.5653598	187	194	C	The final product of an analyst's investigation using a visualization is often a report of the discovered knowledge, as well as the methods employed and reasoning behind the discovery. We believe that analysts may have difficulty keeping track of their knowledge discovery process and will require tools to assist in accurately recovering their reasoning. We first report on a study examining analysts' recall of their strategies and methods, demonstrating their lack of memory of the path of knowledge discovery. We then explore whether a tool visualizing the steps of the visual analysis can aid users in recalling their reasoning process. The results of our second study indicate that visualizations of interaction logs can serve as an effective memory aid, allowing analysts to recall additional details of their strategies and decisions.	Heather Lipford;Felesia Stukes;Wenwen Dou;Matthew E. Hawkins;Remco Chang	Univ. of North Carolina at Charlotte, Charlotte, NC, USA|c|;;;;	10.1109/TVCG.2008.137;10.1109/VAST.2007.4388992;10.1109/VAST.2008.4677365;10.1109/VAST.2008.4677360;10.1109/VAST.2007.4389009	Visual analytics, visualization, reasoning process 	
VAST	2010	Comparing different levels of interaction constraints for deriving visual problem isomorphs	10.1109/VAST.2010.5653599	http://dx.doi.org/10.1109/VAST.2010.5653599	195	202	C	Interaction and manual manipulation have been shown in the cognitive science literature to play a critical role in problem solving. Given different types of interactions or constraints on interactions, a problem can appear to have different degrees of difficulty. While this relationship between interaction and problem solving has been well studied in the cognitive science literatures, the visual analytics community has yet to exploit this understanding for analytical problem solving. In this paper, we hypothesize that constraints on interactions and constraints encoded in visual representations can lead to strategies of varying effectiveness during problem solving. To test our hypothesis, we conducted a user study in which participants were given different levels of interaction constraints when solving a simple math game called Number Scrabble. Number Scrabble is known to have an optimal visual problem isomorph, and the goal of this study is to learn if and how the participants could derive the isomorph and to analyze the strategies that the participants utilize in solving the problem. Our results indicate that constraints on interactions do affect problem solving, and that while the optimal visual isomorph is difficult to derive, certain interaction constraints can lead to a higher chance of deriving the isomorph.	Wenwen Dou;Caroline Ziemkiewicz;Lane Harrison;Dong Hyun Jeong;Roxanne Ryan;William Ribarsky;Xiaoyu Wang;Remco Chang	Univ. of North Carolina at Charlotte, Charlotte, NC, USA|c|;;;;;;;	10.1109/TVCG.2007.70515;10.1109/TVCG.2008.121	Interaction, Visual Isomorph, Problem Solving	
VAST	2010	Data representation and exploration with Geometric Wavelets	10.1109/VAST.2010.5653822	http://dx.doi.org/10.1109/VAST.2010.5653822	243	244	M	Geometric Wavelets is a new multi-scale data representation technique which is useful for a variety of applications such as data compression, interpretation and anomaly detection. We have developed an interactive visualization with multiple linked views to help users quickly explore data sets and understand this novel construction. Currently the interface is being used by applied mathematicians to view results and gain new insights, speeding methods development.	Eric E. Monson;Guangliang Chen;Rachel Brady;Mauro Maggioni	;;;			
VAST	2010	Combining statistical independence testing, visual attribute selection and automated analysis to find relevant attributes for classification	10.1109/VAST.2010.5654445	http://dx.doi.org/10.1109/VAST.2010.5654445	239	240	M	We present an iterative strategy for finding a relevant subset of attributes for the purpose of classification in high-dimensional, heterogeneous data sets. The attribute subset is used for the construction of a classifier function. In order to cope with the challenge of scalability, the analysis is split into an overview of all attributes and a detailed analysis of small groups of attributes. The overview provides generic information on statistical dependencies between attributes. With this information the user can select groups of attributes and an analytical method for their detailed analysis. The detailed analysis involves the identification of redundant attributes (via classification or regression) and the creation of summarizing attributes (via clustering or dimension reduction). Our strategy does not prescribe specific analytical methods. Instead, we recursively combine the results of different methods to find or generate a subset of attributes to use for classification.	Thorsten May;James Davey;Jörn Kohlhammer	Fraunhofer Inst. for Comput. Graphics Res., Darmstadt, Germany|c|;;			
VAST	2010	Visual tools for dynamic analysis of complex situations	10.1109/VAST.2010.5654451	http://dx.doi.org/10.1109/VAST.2010.5654451	241	242	M	This paper presents an interactive interface synchronized with a simulation framework for exploring complex scenarios. This interface exploits visual analysis for facilitating the understanding of complex situation by human users.	Marielle Mokhtari;Eric Boivin;Denis Laurendeau;Maxime Girardin	Syst. of Syst. Sect., Defence R&D Canada, Quebec City, QC, Canada|c|;;;		Information visualization, 2D1/2 animation, line & surface graph animation, interaction, synchronization  	
Vis	2010	A Curved Ray Camera for Handling Occlusions through Continuous Multiperspective Visualization	10.1109/TVCG.2010.127	http://dx.doi.org/10.1109/TVCG.2010.127	1235	1242	J	Most images used in visualization are computed with the planar pinhole camera. This classic camera model has important advantages such as simplicity, which enables efficient software and hardware implementations, and similarity to the human eye, which yields images familiar to the user. However, the planar pinhole camera has only a single viewpoint, which limits images to parts of the scene to which there is direct line of sight. In this paper we introduce the curved ray camera to address the single viewpoint limitation. Rays are C1-continuous curves that bend to circumvent occluders. Our camera is designed to provide a fast 3-D point projection operation, which enables interactive visualization. The camera supports both 3-D surface and volume datasets. The camera is a powerful tool that enables seamless integration of multiple perspectives for overcoming occlusions in visualization while minimizing distortions.	Jian Cui;Paul Rosen;Voicu Popescu;Christoph M. Hoffmann	;;;	10.1109/TVCG.2008.124;10.1109/VISUAL.2004.50;10.1109/TVCG.2006.140;10.1109/TVCG.2006.167;10.1109/INFVIS.2003.1249008;10.1109/TVCG.2006.124	Alleviating occlusions, camera model, curved rays, multiperspective visualization, interactive visualization	
Vis	2010	A Scalable Distributed Paradigm for Multi-User Interaction with Tiled Rear Projection Display Walls	10.1109/TVCG.2010.128	http://dx.doi.org/10.1109/TVCG.2010.128	1623	1632	J	We present the first distributed paradigm for multiple users to interact simultaneously with large tiled rear projection display walls. Unlike earlier works, our paradigm allows easy scalability across different applications, interaction modalities, displays and users. The novelty of the design lies in its distributed nature allowing well-compartmented, application independent, and application specific modules. This enables adapting to different 2D applications and interaction modalities easily by changing a few application specific modules. We demonstrate four challenging 2D applications on a nine projector display to demonstrate the application scalability of our method: map visualization, virtual graffiti, virtual bulletin board and an emergency management system. We demonstrate the scalability of our method to multiple interaction modalities by showing both gesture-based and laser-based user interfaces. Finally, we improve earlier distributed methods to register multiple projectors. Previous works need multiple patterns to identify the neighbors, the configuration of the display and the registration across multiple projectors in logarithmic time with respect to the number of projectors in the display. We propose a new approach that achieves this using a single pattern based on specially augmented QR codes in constant time. Further, previous distributed registration algorithms are prone to large misregistrations. We propose a novel radially cascading geometric registration technique that yields significantly better accuracy. Thus, our improvements allow a significantly more efficient and accurate technique for distributed self-registration of multi-projector display walls.	Pablo Roman;Maxim Lazarov;Aditi Majumder	Comput. Sci. Dept., Univ. of Calif ornia, Irvine, CA, USA|c|;;	10.1109/TVCG.2006.121;10.1109/TVCG.2007.70586;10.1109/VISUAL.2002.1183793;10.1109/TVCG.2009.124	Tiled Displays, Human-Computer Interaction, Gesture-Based Interaction, Multi-user interaction, Distributed algorithms	
Vis	2010	An Information-Theoretic Framework for Flow Visualization	10.1109/TVCG.2010.131	http://dx.doi.org/10.1109/TVCG.2010.131	1216	1224	J	The process of visualization can be seen as a visual communication channel where the input to the channel is the raw data, and the output is the result of a visualization algorithm. From this point of view, we can evaluate the effectiveness of visualization by measuring how much information in the original data is being communicated through the visual communication channel. In this paper, we present an information-theoretic framework for flow visualization with a special focus on streamline generation. In our framework, a vector field is modeled as a distribution of directions from which Shannon's entropy is used to measure the information content in the field. The effectiveness of the streamlines displayed in visualization can be measured by first constructing a new distribution of vectors derived from the existing streamlines, and then comparing this distribution with that of the original data set using the conditional entropy. The conditional entropy between these two distributions indicates how much information in the original data remains hidden after the selected streamlines are displayed. The quality of the visualization can be improved by progressively introducing new streamlines until the conditional entropy converges to a small value. We describe the key components of our framework with detailed analysis, and show that the framework can effectively visualize 2D and 3D flow data.	Lijie Xu;Teng-Yok Lee;Han-Wei Shen	Ohio State Univ., Columbus, OH, USA|c|;;	10.1109/TVCG.2008.119;10.1109/TVCG.2007.70595;10.1109/TVCG.2007.70615;10.1109/TVCG.2006.152;10.1109/TVCG.2006.116;10.1109/VISUAL.2005.1532832;10.1109/VISUAL.2005.1532831;10.1109/TVCG.2008.140;10.1109/VISUAL.2000.885690;10.1109/VISUAL.2005.1532833;10.1109/TVCG.2007.70579;10.1109/VISUAL.2002.1183785	Flow field visualization, information theory, streamline generation	
Vis	2010	An Information-theoretic Framework for Visualization	10.1109/TVCG.2010.132	http://dx.doi.org/10.1109/TVCG.2010.132	1206	1215	J	In this paper, we examine whether or not information theory can be one of the theoretic frameworks for visualization. We formulate concepts and measurements for qualifying visual information. We illustrate these concepts with examples that manifest the intrinsic and implicit use of information theory in many existing visualization techniques. We outline the broad correlation between visualization and the major applications of information theory, while pointing out the difference in emphasis and some technical gaps. Our study provides compelling evidence that information theory can explain a significant number of phenomena or events in visualization, while no example has been found which is fundamentally in conflict with information theory. We also notice that the emphasis of some traditional applications of information theory, such as data compression or data communication, may not always suit visualization, as the former typically focuses on the efficient throughput of a communication channel, whilst the latter focuses on the effectiveness in aiding the perceptual and cognitive process for data understanding and knowledge discovery. These findings suggest that further theoretic developments are necessary for adopting and adapting information theory for visualization.	Min Chen;Heike Leitte	;	10.1109/TVCG.2007.70615;10.1109/VISUAL.2005.1532781;10.1109/TVCG.2006.152;10.1109/INFVIS.1996.559213;10.1109/VISUAL.2005.1532834;10.1109/INFVIS.2000.885096;10.1109/TVCG.2007.70515;10.1109/TVCG.2006.159;10.1109/INFVIS.2004.59;10.1109/TVCG.2007.70535;10.1109/TVCG.2008.140;10.1109/TVCG.2008.121;10.1109/INFVIS.1997.636792;10.1109/VISUAL.2005.1532833;10.1109/INFVIS.2000.885092;10.1109/VISUAL.1990.146375;10.1109/VISUAL.2002.1183785	Information theory, theory of visualization, quantitative evaluation	
Vis	2010	Analysis of Recurrent Patterns in Toroidal Magnetic fields	10.1109/TVCG.2010.133	http://dx.doi.org/10.1109/TVCG.2010.133	1431	1440	J	In the development of magnetic confinement fusion which will potentially be a future source for low cost power, physicists must be able to analyze the magnetic field that confines the burning plasma. While the magnetic field can be described as a vector field, traditional techniques for analyzing the field's topology cannot be used because of its Hamiltonian nature. In this paper we describe a technique developed as a collaboration between physicists and computer scientists that determines the topology of a toroidal magnetic field using fieldlines with near minimal lengths. More specifically, we analyze the Poincare╠ü map of the sampled fieldlines in a Poincare╠ü section including identifying critical points and other topological features of interest to physicists. The technique has been deployed into an interactiveparallel visualization tool which physicists are using to gain new insight into simulations of magnetically confined burning plasmas.	Allen R. Sanderson;Guoning Chen;Xavier Tricoche;David Pugmire;Scott Kruger;Joshua A. Breslau	;;;;;	10.1109/VISUAL.2005.1532842;10.1109/VISUAL.2001.964507;10.1109/VISUAL.2003.1250376;10.1109/VISUAL.1997.663858	Confined magnetic fusion, magnetic field visualization, Poincare map, periodic magnetic fieldlines, recurrent patterns	
Vis	2010	Articulated Planar Reformation for Change Visualization in Small Animal Imaging	10.1109/TVCG.2010.134	http://dx.doi.org/10.1109/TVCG.2010.134	1396	1404	J	The analysis of multi-timepoint whole-body small animal CT data is greatly complicated by the varying posture of the subject at different timepoints. Due to these variations, correctly relating and comparing corresponding regions of interest is challenging.In addition, occlusion may prevent effective visualization of these regions of interest. To address these problems, we have developed a method that fully automatically maps the data to a standardized layout of sub-volumes, based on an articulated atlas registration.We have dubbed this process articulated planar reformation, or APR. A sub-volume can be interactively selected for closer inspection and can be compared with the corresponding sub-volume at the other timepoints, employing a number of different comparative visualization approaches. We provide an additional tool that highlights possibly interesting areas based on the change of bone density between timepoints. Furthermore we allow visualization of the local registration error, to give an indication of the accuracy of the registration. We have evaluated our approach on a case that exhibits cancer-induced bone resorption.	Peter Kok;Martin Baiker;Emile A. Hendriks;Frits H. Post;Jouke Dijkstra;Clemens W. G. M. Löwik;Boudewijn P. F. Lelieveldt;Charl P. Botha	;;;;;;;	10.1109/TVCG.2009.169;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2003.1250400;10.1109/TVCG.2006.140;10.1109/TVCG.2008.143	Small animal imaging, comparative visualization, multi-timepoint, molecular imaging, articulated planar reformation	
Vis	2010	Browsing Large Image Datasets through Voronoi Diagrams	10.1109/TVCG.2010.136	http://dx.doi.org/10.1109/TVCG.2010.136	1261	1270	J	Conventional browsing of image collections use mechanisms such as thumbnails arranged on a regular grid or on a line, often mounted over a scrollable panel. However, this approach does not scale well with the size of the datasets (number of images). In this paper, we propose a new thumbnail-based interface to browse large collections of images. Our approach is based on weighted centroidal anisotropic Voronoi diagrams. A dynamically changing subset of images is represented by thumbnails and shown on the screen. Thumbnails are shaped like general polygons, to better cover screen space, while still reflecting the original aspect ratios or orientation of the represented images. During the browsing process, thumbnails are dynamically rearranged, reshaped and rescaled. The objective is to devote more screen space (more numerous and larger thumbnails) to the parts of the dataset closer to the current region of interest, and progressively lesser away from it, while still making the dataset visible as a whole. During the entire process, temporal coherence is always maintained. GPU implementation easily guarantees the frame rates needed for fully smooth interactivity.	Paolo Brivio;Marco Tarini;Paolo Cignoni	Univ. of Insubria, Varese, Italy|c|;;		Visualization System and Toolkit Design, Scalability Issues, User Interfaces, Zooming and Navigation Techniques	
Vis	2010	Computing Robustness and Persistence for Images	10.1109/TVCG.2010.139	http://dx.doi.org/10.1109/TVCG.2010.139	1251	1260	J	We are interested in 3-dimensional images given as arrays of voxels with intensity values. Extending these values to a continuous function, we study the robustness of homology classes in its level and interlevel sets, that is, the amount of perturbation needed to destroy these classes. The structure of the homology classes and their robustness, over all level and interlevel sets, can be visualized by a triangular diagram of dots obtained by computing the extended persistence of the function. We give a fast hierarchical algorithm using the dual complexes of oct-tree approximations of the function. In addition, we show that for balanced oct-trees, the dual complexes are geometrically realized in R3 and can thus be used to construct level and interlevel sets. We apply these tools to study 3-dimensional images of plant root systems.	Paul Bendich;Herbert Edelsbrunner;Michael Kerber	IST Austria, Klosterneuburg, Austria|c|;;	10.1109/VISUAL.1997.663875	Voxel arrays, oct-trees, persistent homology, persistence diagrams, level sets, robustness, approximations, plant roots	
Vis	2010	Direct Interval Volume Visualization	10.1109/TVCG.2010.145	http://dx.doi.org/10.1109/TVCG.2010.145	1505	1514	J	We extend direct volume rendering with a unified model for generalized isosurfaces, also called interval volumes, allowing a wider spectrum of visual classification. We generalize the concept of scale-invariant opacity-typical for isosurface rendering-to semi-transparent interval volumes. Scale-invariant rendering is independent of physical space dimensions and therefore directly facilitates the analysis of data characteristics. Our model represents sharp isosurfaces as limits of interval volumes and combines them with features of direct volume rendering. Our objective is accurate rendering, guaranteeing that all isosurfaces and interval volumes are visualized in a crack-free way with correct spatial ordering. We achieve simultaneous direct and interval volume rendering by extending preintegration and explicit peak finding with data-driven splitting of ray integration and hybrid computation in physical and data domains. Our algorithm is suitable for efficient parallel processing for interactive applications as demonstrated by our CUDA implementation.	Marco Ament;Daniel Weiskopf;Hamish Carr	VISUS (Visualization Res. Center), Univ. Stuttgart, Stuttgart, Germany|c|;;	10.1109/VISUAL.1998.745713;10.1109/VISUAL.1997.663886;10.1109/VISUAL.2004.85;10.1109/VISUAL.1995.480789;10.1109/VISUAL.2002.1183762;10.1109/TVCG.2009.149;10.1109/TVCG.2006.113;10.1109/TVCG.2008.186;10.1109/VISUAL.2000.885683;10.1109/VISUAL.2005.1532808;10.1109/TVCG.2008.160;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2009.204;10.1109/VISUAL.1995.480807	Direct volume rendering, interval volume, isosurface, ray casting, preintegration, scale-invariant opacity	
Vis	2010	Discontinuities in Continuous Scatterplots	10.1109/TVCG.2010.146	http://dx.doi.org/10.1109/TVCG.2010.146	1291	1300	J	The concept of continuous scatterplot (CSP) is a modern visualization technique. The idea is to define a scalar density value based on the map between an n-dimensional spatial domain and an m-dimensional data domain, which describe the CSP space. Usually the data domain is two-dimensional to visually convey the underlying, density coded, data. In this paper we investigate kinds of map-based discontinuities, especially for the practical cases n = m = 2 and n = 3 | m = 2, and we depict relations between them and attributes of the resulting CSP itself. Additionally, we show that discontinuities build critical line structures, and we introduce algorithms to detect them. Further, we introduce a discontinuity-based visualization approach - called contribution map (CM) -which establishes a relationship between the CSP's data domain and the number of connected components in the spatial domain. We show that CMs enhance the CSP-based linking & brushing interaction. Finally, we apply our approaches to a number of synthetic as well as real data sets.	Dirk J. Lehmann;Holger Theisel	Dept. of Simulation & Graphics, Univ. of Magdeburg, Magdeburg, Germany|c|;	10.1109/TVCG.2006.168;10.1109/TVCG.2008.119;10.1109/VISUAL.1999.809896;10.1109/VISUAL.2005.1532851;10.1109/TVCG.2009.131	Discontinuity, Scatterplot, Topology, Data Visualization	
Vis	2010	Edge Aware Anisotropic Diffusion for 3D Scalar Data	10.1109/TVCG.2010.147	http://dx.doi.org/10.1109/TVCG.2010.147	1376	1385	J	In this paper we present a novel anisotropic diffusion model targeted for 3D scalar field data. Our model preserves material boundaries as well as fine tubular structures while noise is smoothed out. One of the major novelties is the use of the directional second derivative to define material boundaries instead of the gradient magnitude for thresholding. This results in a diffusion model that has much lower sensitivity to the diffusion parameter and smoothes material boundaries consistently compared to gradient magnitude based techniques. We empirically analyze the stability and convergence of the proposed diffusion and demonstrate its de-noising capabilities for both analytic and real data. We also discuss applications in the context of volume rendering.	Zahid Hossain 0001;Torsten Möller	Graphics, Usability, & Visualization (GrUVi) Lab., Simon Fraser Univ., Burnaby, BC, Canada|c|;	10.1109/VISUAL.2002.1183766;10.1109/VISUAL.2003.1250414;10.1109/VISUAL.2004.96;10.1109/VISUAL.2001.964516	Anisotropic diffusion, PDE, De-noising, Scale-Space, Principal Curvatures	
Vis	2010	Efficient High-Quality Volume Rendering of SPH Data	10.1109/TVCG.2010.148	http://dx.doi.org/10.1109/TVCG.2010.148	1533	1540	J	High quality volume rendering of SPH data requires a complex order-dependent resampling of particle quantities along the view rays. In this paper we present an efficient approach to perform this task using a novel view-space discretization of the simulation domain. Our method draws upon recent work on GPU-based particle voxelization for the efficient resampling of particles into uniform grids. We propose a new technique that leverages a perspective grid to adaptively discretize the view-volume, giving rise to a continuous level-of-detail sampling structure and reducing memory requirements compared to a uniform grid. In combination with a level-of-detail representation of the particle set, the perspective grid allows effectively reducing the amount of primitives to be processed at run-time. We demonstrate the quality and performance of our method for the rendering of fluid and gas dynamics SPH simulations consisting of many millions of particles.	Roland Fraedrich;Stefan Auer;Rüdiger Westermann	Comput. Graphics & Visualization Group, Tech. Univ. at Munchen, München, Germany|c|;;	10.1109/VISUAL.2003.1250404;10.1109/TVCG.2008.164;10.1109/VISUAL.1992.235223;10.1109/VISUAL.2003.1250404;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2007.70526;10.1109/TVCG.2009.142;10.1109/TVCG.2007.70600;10.1109/VISUAL.2004.55	Particle visualization, volume rendering, ray-casting, GPU resampling	
Vis	2010	Exploded View Diagrams of Mathematical Surfaces	10.1109/TVCG.2010.151	http://dx.doi.org/10.1109/TVCG.2010.151	1311	1318	J	We present a technique for visualizing complicated mathematical surfaces that is inspired by hand-designed topological illustrations. Our approach generates exploded views that expose the internal structure of such a surface by partitioning it into parallel slices, which are separated from each other along a single linear explosion axis. Our contributions include a set of simple, prescriptive design rules for choosing an explosion axis and placing cutting planes, as well as automatic algorithms for applying these rules. First we analyze the input shape to select the explosion axis based on the detected rotational and reflective symmetries of the input model. We then partition the shape into slices that are designed to help viewers better understand how the shape of the surface and its cross-sections vary along the explosion axis. Our algorithms work directly on triangle meshes, and do not depend on any specific parameterization of the surface. We generate exploded views for a variety of mathematical surfaces using our system.	Olga A. Karpenko;Wilmot Li;Niloy J. Mitra;Maneesh Agrawala	;;;	10.1109/TVCG.2006.140;10.1109/VISUAL.2003.1250400;10.1109/VISUAL.2005.1532856	Exploded view diagrams, mathematical visualization, symmetry	
Vis	2010	Exploration and Visualization of Segmentation Uncertainty using Shape and Appearance Prior Information	10.1109/TVCG.2010.152	http://dx.doi.org/10.1109/TVCG.2010.152	1366	1375	J	We develop an interactive analysis and visualization tool for probabilistic segmentation in medical imaging. The originality of our approach is that the data exploration is guided by shape and appearance knowledge learned from expert-segmented images of a training population. We introduce a set of multidimensional transfer function widgets to analyze the multivariate probabilistic field data. These widgets furnish the user with contextual information about conformance or deviation from the population statistics. We demonstrate the user's ability to identify suspicious regions (e.g. tumors) and to correct the misclassification results. We evaluate our system and demonstrate its usefulness in the context of static anatomical and time-varying functional imaging datasets.	Ahmed Saad;Ghassan Hamarneh;Torsten Möller	Med. Image Anal. Lab. (MIAL), Simon Fraser Univ., Burnaby, BC, Canada|c|;;	10.1109/TVCG.2009.189;10.1109/VISUAL.2005.1532807;10.1109/VISUAL.2003.1250414;10.1109/TVCG.2007.70518	Uncertainty visualization, Medical imaging, Probabilistic segmentation	
Vis	2010	Exploration of 4D MRI Blood Flow using Stylistic Visualization	10.1109/TVCG.2010.153	http://dx.doi.org/10.1109/TVCG.2010.153	1339	1347	J	Insight into the dynamics of blood-flow considerably improves the understanding of the complex cardiovascular system and its pathologies. Advances in MRI technology enable acquisition of 4D blood-flow data, providing quantitative blood-flow velocities over time. The currently typical slice-by-slice analysis requires a full mental reconstruction of the unsteady blood-flow field, which is a tedious and highly challenging task, even for skilled physicians. We endeavor to alleviate this task by means of comprehensive visualization and interaction techniques. In this paper we present a framework for pre-clinical cardiovascular research, providing tools to both interactively explore the 4D blood-flow data and depict the essential blood-flow characteristics. The framework encompasses a variety of visualization styles, comprising illustrative techniques as well as improved methods from the established field of flow visualization. Each of the incorporated styles, including exploded planar reformats, flow-direction highlights, and arrow-trails, locally captures the blood-flow dynamics and may be initiated by an interactively probed vessel cross-section. Additionally, we present the results of an evaluation with domain experts, measuring the value of each of the visualization styles and related rendering parameters.	Roy van Pelt;Javier Oliván Bescós;Marcel Breeuwer;Rachel E. Clough;Eduard Gröller;Bart M. ter Haar Romeny;Anna Vilanova	Dept. of Biomed. Eng., Eindhoven Univ. of Technol., Eindhoven, Netherlands|c|;;;;;;	10.1109/TVCG.2006.140;10.1109/TVCG.2009.138	4D MRI blood-flow, Probing, Flow visualization, Illustrative visualization, Phase-contrast cine MRI	
Vis	2010	Fast High-Quality Volume Ray Casting with Virtual Samplings	10.1109/TVCG.2010.155	http://dx.doi.org/10.1109/TVCG.2010.155	1525	1532	J	Volume ray-casting with a higher order reconstruction filter and/or a higher sampling rate has been adopted in direct volume rendering frameworks to provide a smooth reconstruction of the volume scalar and/or to reduce artifacts when the combined frequency of the volume and transfer function is high. While it enables high-quality volume rendering, it cannot support interactive rendering due to its high computational cost. In this paper, we propose a fast high-quality volume ray-casting algorithm which effectively increases the sampling rate. While a ray traverses the volume, intensity values are uniformly reconstructed using a high-order convolution filter. Additional samplings, referred to as virtual samplings, are carried out within a ray segment from a cubic spline curve interpolating those uniformly reconstructed intensities. These virtual samplings are performed by evaluating the polynomial function of the cubic spline curve via simple arithmetic operations. The min max blocks are refined accordingly for accurate empty space skipping in the proposed method. Experimental results demonstrate that the proposed algorithm, also exploiting fast cubic texture filtering supported by programmable GPUs, offers renderings as good as a conventional ray-casting algorithm using high-order reconstruction filtering at the same sampling rate, while delivering 2.5x to 3.3x rendering speed-up.	Byeonghun Lee;Jihye Yun;Jinwook Seo;Byonghyo Shim;Yeong-Gil Shin;Bo Hyoung Kim	Seoul Nat. Univ., Seoul, South Korea|c|;;;;;	10.1109/VISUAL.1994.346331;10.1109/VISUAL.2004.70;10.1109/VISUAL.2005.1532810;10.1109/TVCG.2009.204;10.1109/VISUAL.2003.1250384	Direct volume rendering, GPU, high quality, curve interpolation	
Vis	2010	Fast; Memory-Efficient Cell Location in Unstructured Grids for Visualization	10.1109/TVCG.2010.156	http://dx.doi.org/10.1109/TVCG.2010.156	1541	1550	J	Applying certain visualization techniques to datasets described on unstructured grids requires the interpolation of variables of interest at arbitrary locations within the dataset's domain of definition. Typical solutions to the problem of finding the grid element enclosing a given interpolation point make use of a variety of spatial subdivision schemes. However, existing solutions are memory- intensive, do not scale well to large grids, or do not work reliably on grids describing complex geometries. In this paper, we propose a data structure and associated construction algorithm for fast cell location in unstructured grids, and apply it to the interpolation problem. Based on the concept of bounding interval hierarchies, the proposed approach is memory-efficient, fast and numerically robust. We examine the performance characteristics of the proposed approach and compare it to existing approaches using a number of benchmark problems related to vector field visualization. Furthermore, we demonstrate that our approach can successfully accommodate large datasets, and discuss application to visualization on both CPUs and GPUs.	Christoph Garth;Kenneth I. Joy	Inst. of Data Anal. & Visualization, Univ. of California, Davis, CA, USA|c|;	10.1109/TVCG.2008.163;10.1109/TVCG.2008.133;10.1109/VISUAL.2005.1532795;10.1109/TVCG.2009.154	Unstructured grids, cell location, interpolation, vector field visualization	
Vis	2010	FI3D: Direct-Touch Interaction for the Exploration of 3D Scientific Visualization Spaces	10.1109/TVCG.2010.157	http://dx.doi.org/10.1109/TVCG.2010.157	1613	1622	J	We present the design and evaluation of FI3D, a direct-touch data exploration technique for 3D visualization spaces. The exploration of three-dimensional data is core to many tasks and domains involving scientific visualizations. Thus, effective data navigation techniques are essential to enable comprehension, understanding, and analysis of the information space. While evidence exists that touch can provide higher-bandwidth input, somesthetic information that is valuable when interacting with virtual worlds, and awareness when working in collaboration, scientific data exploration in 3D poses unique challenges to the development of effective data manipulations. We present a technique that provides touch interaction with 3D scientific data spaces in 7 DOF. This interaction does not require the presence of dedicated objects to constrain the mapping, a design decision important for many scientific datasets such as particle simulations in astronomy or physics. We report on an evaluation that compares the technique to conventional mouse-based interaction. Our results show that touch interaction is competitive in interaction speed for translation and integrated interaction, is easy to learn and use, and is preferred for exploration and wayfinding tasks. To further explore the applicability of our basic technique for other types of scientific visualizations we present a second case study, adjusting the interaction to the illustrative visualization of fiber tracts of the brain and the manipulation of cutting planes in this context.	Lingyun Yu;Pjotr Svetachov;Petra Isenberg;Maarten H. Everts;Tobias Isenberg 0001	Univ. of Groningen, Groningen, Netherlands|c|;;;;	10.1109/VISUAL.2005.1532778;10.1109/TVCG.2007.70515;10.1109/VISUAL.2004.30	Direct-touch interaction, wall displays, 3D navigation and exploration, evaluation, illustrative visualization	
Vis	2010	Gradient Estimation Revitalized	10.1109/TVCG.2010.160	http://dx.doi.org/10.1109/TVCG.2010.160	1495	1504	J	We investigate the use of a Fourier-domain derivative error kernel to quantify the error incurred while estimating the gradient of a function from scalar point samples on a regular lattice. We use the error kernel to show that gradient reconstruction quality is significantly enhanced merely by shifting the reconstruction kernel to the centers of the principal lattice directions. Additionally, we exploit the algebraic similarities between the scalar and derivative error kernels to design asymptotically optimal gradient estimation filters that can be factored into an infinite impulse response interpolation prefilter and a finite impulse response directional derivative filter. This leads to a significant performance gain both in terms of accuracy and computational efficiency. The interpolation prefilter provides an accurate scalar approximation and can be re-used to cheaply compute directional derivatives on-the-fly without the need to store gradients. We demonstrate the impact of our filters in the context of volume rendering of scalar data sampled on the Cartesian and Body-Centered Cubic lattices. Our results rival those obtained from other competitive gradient estimation methods while incurring no additional computational or storage overhead.	Usman R. Alim;Torsten Möller;Laurent Condat	Simon Fraser Univ., Burnaby, BC, Canada|c|;;	10.1109/VISUAL.2001.964498;10.1109/VISUAL.1994.346331;10.1109/VISUAL.1997.663848;10.1109/VISUAL.2004.65	Derivative, Gradient, Reconstruction, Sampling, Lattice, Interpolation, Approximation, Frequency Error Kernel	
Vis	2010	Illustrative Stream Surfaces	10.1109/TVCG.2010.166	http://dx.doi.org/10.1109/TVCG.2010.166	1329	1338	J	Stream surfaces are an intuitive approach to represent 3D vector fields. In many cases, however, they are challenging objects to visualize and to understand, due to a high degree of self-occlusion. Despite the need for adequate rendering methods, little work has been done so far in this important research area. In this paper, we present an illustrative rendering strategy for stream surfaces. In our approach, we apply various rendering techniques, which are inspired by the traditional flow illustrations drawn by Dallmann and Abraham & Shaw in the early 1980s. Among these techniques are contour lines and halftoning to show the overall surface shape. Flow direction as well as singularities on the stream surface are depicted by illustrative surface streamlines. ;To go beyond reproducing static text book images, we provide several interaction features, such as movable cuts and slabs allowing an interactive exploration of the flow and insights into subjacent structures, e.g., the inner windings of vortex breakdown bubbles. These methods take only the parameterized stream surface as input, require no further preprocessing, and can be freely combined by the user. We explain the design, GPU-implementation, and combination of the different illustrative rendering and interaction methods and demonstrate the potential of our approach by applying it to stream surfaces from various flow simulations.	Silvia Born;Alexander Wiebel;Jan Friedrich;Gerik Scheuermann;Dirk Bartz	Univ. Leipzig, Leipzig, Germany|c|;;;;	10.1109/VISUAL.1990.146395;10.1109/TVCG.2009.190;10.1109/TVCG.2007.70565;10.1109/VISUAL.2005.1532857;10.1109/VISUAL.1999.809905;10.1109/TVCG.2008.133;10.1109/TVCG.2009.138;10.1109/VISUAL.2001.964506;10.1109/VISUAL.2005.1532858;10.1109/VISUAL.2005.1532855;10.1109/TVCG.2008.170;10.1109/VISUAL.2004.113;10.1109/VISUAL.2003.1250376	Flow visualization, Stream surfaces, Illustrative rendering, Silhouettes, GPU technique, 3D vector field data	
Vis	2010	Interactive Histology of Large-Scale Biomedical Image Stacks	10.1109/TVCG.2010.168	http://dx.doi.org/10.1109/TVCG.2010.168	1386	1395	J	Histology is the study of the structure of biological tissue using microscopy techniques. As digital imaging technology advances, high resolution microscopy of large tissue volumes is becoming feasible; however, new interactive tools are needed to explore and analyze the enormous datasets. In this paper we present a visualization framework that specifically targets interactive examination of arbitrarily large image stacks. Our framework is built upon two core techniques: display-aware processing and GPU-accelerated texture compression. With display-aware processing, only the currently visible image tiles are fetched and aligned on-the-fly, reducing memory bandwidth and minimizing the need for time-consuming global pre-processing. Our novel texture compression scheme for GPUs is tailored for quick browsing of image stacks. We evaluate the usability of our viewer for two histology applications: digital pathology and visualization of neural structure at nanoscale-resolution in serial electron micrographs.	Won-Ki Jeong;Jens Schneider;Stephen G. Turney;Beverly E. Faulkner-Jones;Dominik Meyer;Rüdiger Westermann;R. Clay Reid;Jeff Lichtman;Hanspeter Pfister	;;;;;;;;	10.1109/VISUAL.1994.346321;10.1109/VISUAL.2002.1183757;10.1109/VISUAL.2001.964520;10.1109/TVCG.2007.70516;10.1109/VISUAL.1995.480809;10.1109/VISUAL.2001.964531;10.1109/VISUAL.1995.480812;10.1109/VISUAL.2003.1250385	Gigapixel viewer, biomedical image processing, GPU, texture compression	
Vis	2010	Interactive Separating Streak Surfaces	10.1109/TVCG.2010.169	http://dx.doi.org/10.1109/TVCG.2010.169	1569	1577	J	Streak surfaces are among the most important features to support 3D unsteady flow exploration, but they are also among the computationally most demanding. Furthermore, to enable a feature driven analysis of the flow, one is mainly interested in streak surfaces that show separation profiles and thus detect unstable manifolds in the flow. The computation of such separation surfaces requires to place seeding structures at the separation locations and to let the structures move correspondingly to these locations in the unsteady flow. Since only little knowledge exists about the time evolution of separating streak surfaces, at this time, an automated exploration of 3D unsteady flows using such surfaces is not feasible. Therefore, in this paper we present an interactive approach for the visual analysis of separating streak surfaces. Our method draws upon recent work on the extraction of Lagrangian coherent structures (LCS) and the real-time visualization of streak surfaces on the GPU. We propose an interactive technique for computing ridges in the finite time Lyapunov exponent (FTLE) field at each time step, and we use these ridges as seeding structures to track streak surfaces in the time-varying flow. By showing separation surfaces in combination with particle trajectories, and by letting the user interactively change seeding parameters such as particle density and position, visually guided exploration of separation profiles in 3D is provided. To the best of our knowledge, this is the first time that the reconstruction and display of semantic separable surfaces in 3D unsteady flows can be performed interactively, giving rise to new possibilities for gaining insight into complex flow phenomena.	Florian Ferstl;Kai Bürger;Holger Theisel;Rüdiger Westermann	Comput. Graphics & Visualization group, Tech. Univ. Munchen, München, Germany|c|;;;	10.1109/TVCG.2009.190;10.1109/TVCG.2007.70557;10.1109/VISUAL.1992.235211;10.1109/TVCG.2008.133;10.1109/VISUAL.2001.964506;10.1109/TVCG.2007.70554;10.1109/VISUAL.1993.398875;10.1109/TVCG.2009.177;10.1109/TVCG.2009.154;10.1109/TVCG.2006.151;10.1109/TVCG.2007.70551;10.1109/TVCG.2008.163;10.1109/VISUAL.2005.1532780	Unsteady flow visualization, feature extraction, streak surface generation, GPUs	
Vis	2010	Interactive Vector field Feature Identification	10.1109/TVCG.2010.170	http://dx.doi.org/10.1109/TVCG.2010.170	1560	1568	J	We introduce a flexible technique for interactive exploration of vector field data through classification derived from user-specified feature templates. Our method is founded on the observation that, while similar features within the vector field may be spatially disparate, they share similar neighborhood characteristics. Users generate feature-based visualizations by interactively highlighting well-accepted and domain specific representative feature points. Feature exploration begins with the computation of attributes that describe the neighborhood of each sample within the input vector field. Compilation of these attributes forms a representation of the vector field samples in the attribute space. We project the attribute points onto the canonical 2D plane to enable interactive exploration of the vector field using a painting interface. The projection encodes the similarities between vector field points within the distances computed between their associated attribute points. The proposed method is performed at interactive rates for enhanced user experience and is completely flexible as showcased by the simultaneous identification of diverse feature types.	Joel Daniels II;Erik W. Anderson;Luis Gustavo Nonato;Cláudio T. Silva	Sch. of Comput. & Sci. Comput., Univ. of Utah, Salt Lake City, UT, USA|c|;;;	10.1109/TVCG.2009.138;10.1109/VISUAL.1993.398846;10.1109/TVCG.2007.70579;10.1109/VISUAL.1991.175794;10.1109/VISUAL.1998.745333;10.1109/VISUAL.1992.235211;10.1109/TVCG.2008.116;10.1109/TVCG.2009.190;10.1109/VISUAL.1999.809917;10.1109/VISUAL.1997.663910;10.1109/VISUAL.1998.745296;10.1109/VISUAL.1991.175771;10.1109/VISUAL.2000.885690;10.1109/VISUAL.2000.885689	Vector field, data clustering, feature classification, high-dimensional data, user interaction	
Vis	2010	Interactive Visual Analysis of Multiple Simulation Runs Using the Simulation Model View: Understanding and Tuning of an Electronic Unit Injector	10.1109/TVCG.2010.171	http://dx.doi.org/10.1109/TVCG.2010.171	1449	1457	J	Multiple simulation runs using the same simulation model with different values of control parameters generate a large data set that captures the behavior of the modeled phenomenon. However, there is a conceptual and visual gap between the simulation model behavior and the data set that makes data analysis more difficult. We propose a simulation model view that helps to bridge that gap by visually combining the simulation model description and the generated data. The simulation model view provides a visual outline of the simulation process and the corresponding simulation model. The view is integrated in a Coordinated Multiple Views; (CMV) system. As the simulation model view provides a limited display space, we use three levels of details. We explored the use of the simulation model view, in close collaboration with a domain expert, to understand and tune an electronic unit injector (EUI). We also developed analysis procedures based on the view. The EUI is mostly used in heavy duty Diesel engines. We were mainly interested in understanding the model and how to tune it for three different operation modes: low emission, low consumption, and high power. Very positive feedback from the domain expert shows that the use of the simulation model view and the corresponding ;analysis procedures within a CMV system represents an effective technique for interactive visual analysis of multiple simulation runs.	Kresimir Matkovic;Denis Gracanin;Mario Jelovic;Andreas Ammer;Alan Lez;Helwig Hauser	VRVis Res. Center, Vienna, Austria|c|;;;;;	10.1109/TVCG.2009.155;10.1109/INFVIS.2002.1173149;10.1109/INFVIS.1995.528685;10.1109/INFVIS.2002.1173157	Visualization in physical sciences and engineering, time series data, coordinated multiple views	
Vis	2010	Interactive Visualization of Hyperspectral Images of Historical Documents	10.1109/TVCG.2010.172	http://dx.doi.org/10.1109/TVCG.2010.172	1441	1448	J	This paper presents an interactive visualization tool to study and analyze hyperspectral images (HSI) of historical documents. This work is part of a collaborative effort with the Nationaal Archief of the Netherlands (NAN) and Art Innovation, a manufacturer of hyperspectral imaging hardware designed for old and fragile documents. The NAN is actively capturing HSI of historical documents for use in a variety of tasks related to the analysis and management of archival collections, from ink and paper analysis to monitoring the effects of environmental aging. To assist their work, we have developed a comprehensive visualization tool that offers an assortment of visualization and analysis methods, including interactive spectral selection, spectral similarity analysis, time-varying data analysis and visualization, and selective spectral band fusion. This paper describes our visualization software and how it is used to facilitate the tasks needed by our collaborators. Evaluation feedback from our collaborators on how this tool benefits their work is included.	Seon Joo Kim;Shaojie Zhuo;Fanbo Deng;Chi-Wing Fu;Michael S. Brown	Nat. Univ. of Singapore, Singapore, Singapore|c|;;;;	10.1109/TVCG.2008.139;10.1109/TVCG.2008.161;10.1109/TVCG.2008.146;10.1109/TVCG.2006.155;10.1109/VISUAL.1995.485155;10.1109/TVCG.2008.182	Hyperspectral visualization, data exploration, image fusion, document processing and analysis	
Vis	2010	IRIS: Illustrative Rendering for Integral Surfaces	10.1109/TVCG.2010.173	http://dx.doi.org/10.1109/TVCG.2010.173	1319	1328	J	Integral surfaces are ideal tools to illustrate vector fields and fluid flow structures. However, these surfaces can be visually complex and exhibit difficult geometric properties, owing to strong stretching, shearing and folding of the flow from which they are derived. Many techniques for non-photorealistic rendering have been presented previously. It is, however, unclear how these techniques can be applied to integral surfaces. In this paper, we examine how transparency and texturing techniques can be used with integral surfaces to convey both shape and directional information. We present a rendering pipeline that combines these techniques aimed at faithfully and accurately representing integral surfaces while improving visualization insight. The presented pipeline is implemented directly on the GPU, providing real-time interaction for all rendering modes, and does not require expensive preprocessing of integral surfaces after computation.	Mathias Hummel;Christoph Garth;Bernd Hamann;Hans Hagen;Kenneth I. Joy	Univ. of Kaiserslautern, Kaiserslautern, Germany|c|;;;;	10.1109/TVCG.2006.124;10.1109/VISUAL.2003.1250414;10.1109/TVCG.2008.133;10.1109/VISUAL.1992.235211;10.1109/TVCG.2009.190;10.1109/VISUAL.1993.398875;10.1109/VISUAL.2001.964506;10.1109/VISUAL.2000.885694;10.1109/TVCG.2008.163;10.1109/TVCG.2009.154	Flow visualization, integral surfaces, illustrative rendering	
Vis	2010	Noodles: A Tool for Visualization of Numerical Weather Model Ensemble Uncertainty	10.1109/TVCG.2010.181	http://dx.doi.org/10.1109/TVCG.2010.181	1421	1430	J	Numerical weather prediction ensembles are routinely used for operational weather forecasting. The members of these ensembles are individual simulations with either slightly perturbed initial conditions or different model parameterizations, or occasionally both. Multi-member ensemble output is usually large, multivariate, and challenging to interpret interactively. Forecast meteorologists are interested in understanding the uncertainties associated with numerical weather prediction; specifically variability between the ensemble members. Currently, visualization of ensemble members is mostly accomplished through spaghetti plots of a single midtroposphere pressure surface height contour. In order to explore new uncertainty visualization methods, the Weather Research and Forecasting (WRF) model was used to create a 48-hour, 18 member parameterization ensemble of the 13 March 1993 "Superstorm". A tool was designed to interactively explore the ensemble uncertainty of three important weather variables: water-vapor mixing ratio, perturbation potential temperature, and perturbation pressure. Uncertainty was quantified using individual ensemble member standard deviation, inter-quartile range, and the width of the 95% confidence interval. Bootstrapping was employed to overcome the dependence on normality in the uncertainty metrics. A coordinated view of ribbon and glyph-based uncertainty visualization, spaghetti plots, iso-pressure colormaps, and data transect plots was provided to two meteorologists for expert evaluation. They found it useful in assessing uncertainty in the data, especially in finding outliers in the ensemble run and therefore avoiding the WRF parameterizations that lead to these outliers. Additionally, the meteorologists could identify spatial regions where the uncertainty was significantly high, allowing for identification of poorly simulated storm environments and physical interpretation of these model issues.	Jibonananda Sanyal;Song Zhang 0004;Jamie Dyer;Andrew Mercer 0001;Philip Amburn;Robert J. Moorhead II	;;;;;	10.1109/TVCG.2009.114;10.1109/INFVIS.2002.1173145	Uncertainty visualization, weather ensemble, geographic/geospatial visualization, glyph-based techniques, time-varying data, qualitative evaluation	
Vis	2010	On the Fractal Dimension of Isosurfaces	10.1109/TVCG.2010.182	http://dx.doi.org/10.1109/TVCG.2010.182	1198	1205	J	A (3D) scalar grid is a regular n1 × n2 × n3 grid of vertices where each vertex v is associated with some scalar value sv. Applying trilinear interpolation, the scalar grid determines a scalar function g where g(v) = sv for each grid vertex v. An isosurface with isovalue σ is a triangular mesh which approximates the level set g-1 (σ). The fractal dimension of an isosurface represents the growth in the isosurface as the number of grid cubes increases. We define and discuss the fractal isosurface dimension. Plotting the fractal dimension as a function of the isovalues in a data set provides information about the isosurfaces determined by the data set. We present statistics on the average fractal dimension of 60 publicly available benchmark data sets. We also show the fractal dimension is highly correlated with topological noise in the benchmark data sets, measuring the topological noise by the number of connected components in the isosurface. Lastly, we present a formula predicting the fractal dimension as a function of noise and validate the formula with experimental results.	Marc Khoury;Rephael Wenger	Comput. & Inf. Sci. Dept., Ohio State Univ., Columbus, OH, USA|c|;	10.1109/TVCG.2006.168;10.1109/TVCG.2008.160;10.1109/VISUAL.2004.28;10.1109/VISUAL.1996.568103;10.1109/VISUAL.2001.964515;10.1109/VISUAL.1991.175782;10.1109/VISUAL.1997.663875	Isosurfaces, scalar data, fractal dimension	
Vis	2010	Pre-Integrated Volume Rendering with Non-Linear Gradient Interpolation	10.1109/TVCG.2010.187	http://dx.doi.org/10.1109/TVCG.2010.187	1487	1494	J	Shading is an important feature for the comprehension of volume datasets, but is difficult to implement accurately. Current techniques based on pre-integrated direct volume rendering approximate the volume rendering integral by ignoring non-linear gradient variations between front and back samples, which might result in cumulated shading errors when gradient variations are important and / or when the illumination function features high frequencies. In this paper, we explore a simple approach for pre-integrated volume rendering with non-linear gradient interpolation between front and back samples. We consider that the gradient smoothly varies along a quadratic curve instead of a segment in-between consecutive samples. This not only allows us to compute more accurate shaded pre-integrated look-up tables, but also allows us to more efficiently process shading amplifying effects, based on gradient filtering. An interesting property is that the pre-integration tables we use remain two-dimensional as for usual pre-integrated classification. We conduct experiments using a full hardware approach with the Blinn-Phong illumination model as well as with a non-photorealistic illumination model.	Amel Guetat;Alexandre Ancel;Stéphane Marchesin;Jean-Michel Dischler	;;;	10.1109/VISUAL.2000.885683;10.1109/VISUAL.2000.885694;10.1109/VISUAL.1990.146391;10.1109/TVCG.2009.149	Ray casting, pre-integration, Phong shading, volume rendering	
Vis	2010	Projector Placement Planning for High Quality Visualizations on Real-World Colored Objects	10.1109/TVCG.2010.189	http://dx.doi.org/10.1109/TVCG.2010.189	1633	1641	J	Many visualization applications benefit from displaying content on real-world objects rather than on a traditional display (e.g., a monitor). This type of visualization display is achieved by projecting precisely controlled illumination from multiple projectors onto the real-world colored objects. For such a task, the placement of the projectors is critical in assuring that the desired visualization is possible. Using ad hoc projector placement may cause some appearances to suffer from color shifting due to insufficient projector light radiance being exposed onto the physical surface. This leads to an incorrect appearance and ultimately to a false and potentially misleading visualization. In this paper, we present a framework to discover the optimal position and orientation of the projectors for such projection-based visualization displays. An optimal projector placement should be able to achieve the desired visualization with minimal projector light radiance. When determining optimal projector placement, object visibility, surface reflectance properties, and projector-surface distance and orientation need to be considered. We first formalize a theory for appearance editing image formation and construct a constrained linear system of equations that express when a desired novel appearance or visualization is possible given a geometric and surface reflectance model of the physical surface. Then, we show how to apply this constrained system in an adaptive search to efficiently discover the optimal projector placement which achieves the desired appearance. Constraints can be imposed on the maximum radiance allowed by the projectors and the projectors' placement to support specific goals of various visualization applications. We perform several real-world and simulated appearance edits and visualizations to demonstrate the improvement obtained by our discovered projector placement over ad hoc projector placement.	Alvin J. Law;Daniel G. Aliaga;Aditi Majumder	Dept. of Comput. Sci., Purdue Univ., West Lafayette, IN, USA|c|;;	10.1109/TVCG.2009.124;10.1109/VISUAL.2002.1183793;10.1109/TVCG.2006.121;10.1109/TVCG.2007.70586;10.1109/VISUAL.2000.885684	Large and High-resolution Displays, Interaction Design, Mobile and Ubiquitous Visualization 	
Vis	2010	Result-Driven Exploration of Simulation Parameter Spaces for Visual Effects Design	10.1109/TVCG.2010.190	http://dx.doi.org/10.1109/TVCG.2010.190	1468	1476	J	Graphics artists commonly employ physically-based simulation for the generation of effects such as smoke, explosions, and similar phenomena. The task of finding the correct parameters for a desired result, however, is difficult and time-consuming as current tools provide little to no guidance. In this paper, we present a new approach for the visual exploration of such parameter spaces. Given a three-dimensional scene description, we utilize sampling and spatio-temporal clustering techniques to generate a concise overview of the achievable variations and their temporal evolution. Our visualization system then allows the user to explore the simulation space in a goal-oriented manner. Animation sequences with a set of desired characteristics can be composed using a novel search-by-example approach and interactive direct volume rendering is employed to provide instant visual feedback.	Stefan Bruckner;Torsten Möller	GrUVi (Graphics, Usability, & Visualization Lab.), Simon Fraser Univ., Burnaby, BC, Canada|c|;	10.1109/VISUAL.1992.235222;10.1109/VISUAL.1999.809871;10.1109/VISUAL.2003.1250401;10.1109/TVCG.2006.164;10.1109/VISUAL.2003.1250402;10.1109/INFVIS.1998.729559;10.1109/TVCG.2009.200;10.1109/VAST.2007.4389013;10.1109/VISUAL.1993.398859;10.1109/TVCG.2009.153;10.1109/TVCG.2007.70581;10.1109/VAST.2006.261421	Visual exploration, visual effects, clustering, time-dependent volume data	
Vis	2010	Scalable Multi-variate Analytics of Seismic and Satellite-based Observational Data	10.1109/TVCG.2010.192	http://dx.doi.org/10.1109/TVCG.2010.192	1413	1420	J	Over the past few years, large human populations around the world have been affected by an increase in significant seismic activities. For both conducting basic scientific research and for setting critical government policies, it is crucial to be able to explore and understand seismic and geographical information obtained through all scientific instruments. In this work, we present a visual analytics system that enables explorative visualization of seismic data together with satellite-based observational data, and introduce a suite of visual analytical tools. Seismic and satellite data are integrated temporally and spatially. Users can select temporal ;and spatial ranges to zoom in on specific seismic events, as well as to inspect changes both during and after the events. Tools for designing high dimensional transfer functions have been developed to enable efficient and intuitive comprehension of the multi-modal data. Spread-sheet style comparisons are used for data drill-down as well as presentation. Comparisons between distinct seismic events are also provided for characterizing event-wise differences. Our system has been designed for scalability in terms of data size, complexity (i.e. number of modalities), and varying form factors of display environments.	Xiaoru Yuan;He Xiao;Hanqi Guo;Peihong Guo;Wesley Kendall;Jian Huang;Yongxian Zhang	Key Lab. of Machine Perception, Peking Univ., Beijing, China|c|;;;;;;	10.1109/TVCG.2009.179;10.1109/VISUAL.2003.1250412;10.1109/VISUAL.1990.146402;10.1109/VISUAL.2002.1183814;10.1109/TVCG.2008.170;10.1109/TVCG.2008.184	Earth Science Visualization, Multivariate Visualization, Seismic Data, Scalable Visualization	
Vis	2010	Spatial Conditioning of Transfer Functions Using Local Material Distributions	10.1109/TVCG.2010.195	http://dx.doi.org/10.1109/TVCG.2010.195	1301	1310	J	In many applications of Direct Volume Rendering (DVR) the importance of a certain material or feature is highly dependent on its relative spatial location. For instance, in the medical diagnostic procedure, the patient's symptoms often lead to specification of features, tissues and organs of particular interest. One such example is pockets of gas which, if found inside the body at abnormal locations, are a crucial part of a diagnostic visualization. This paper presents an approach that enhances DVR transfer function design with spatial localization based on user specified material dependencies. Semantic expressions are used to define conditions based on relations between different materials, such as only render iodine uptake when close to liver. The underlying methods rely on estimations of material distributions which are acquired by weighing local neighborhoods of the data against approximations of material likelihood functions. This information is encoded and used to influence rendering according to the user's specifications. The result is improved focus on important features by allowing the user to suppress spatially less-important data. In line with requirements from actual clinical DVR practice, the methods do not require explicit material segmentation that would be impossible or prohibitively time-consuming to achieve in most real cases. The scheme scales well to higher dimensions which accounts for multi-dimensional transfer functions and multivariate data. Dual-Energy Computed Tomography, an important new modality in radiology, is used to demonstrate this scalability. In several examples we show significantly improved focus on clinically important aspects in the rendered images.	Stefan Lindholm;Patric Ljung;Claes Lundström;Anders Persson;Anders Ynnerman	;;;;	10.1109/TVCG.2009.185;10.1109/TVCG.2009.120;10.1109/TVCG.2008.147;10.1109/VISUAL.2003.1250412;10.1109/TVCG.2007.70591;10.1109/VISUAL.2001.964516;10.1109/TVCG.2009.189;10.1109/TVCG.2008.162;10.1109/VISUAL.2003.1250413;10.1109/VISUAL.1999.809932;10.1109/TVCG.2006.148	Direct Volume Rendering, Transfer Function, Spatial Conditioning, Neighborhood Meta-Data	
Vis	2010	Special Relativistic Visualization by Local Ray Tracing	10.1109/TVCG.2010.196	http://dx.doi.org/10.1109/TVCG.2010.196	1243	1250	J	Special relativistic visualization offers the possibility of experiencing the optical effects of traveling near the speed of light, including apparent geometric distortions as well as Doppler and searchlight effects. Early high-quality computer graphics images of relativistic scenes were created using offline, computationally expensive CPU-side 4D ray tracing. Alternate approaches such as image-based rendering and polygon-distortion methods are able to achieve interactivity, but exhibit inferior visual quality due to sampling artifacts. In this paper, we introduce a hybrid rendering technique based on polygon distortion and local ray tracing that facilitates interactive high-quality visualization of multiple objects moving at relativistic speeds in arbitrary directions. The method starts by calculating tight image-space footprints for the apparent triangles of the 3D scene objects. The final image is generated using a single image-space ray tracing step incorporating Doppler and searchlight effects. Our implementation uses GPU shader programming and hardware texture filtering to achieve high rendering speed.	Thomas Müller 0005;Sebastian Grottel;Daniel Weiskopf	Visualization Res. Center (VISUS), Univ. of Stuttgart, Stuttgart, Germany|c|;;	10.1109/VISUAL.2000.885709	Poincare transformation, aberration of light, Doppler effect, illumination, searchlight effect, special relativity, GPU ray tracing	
Vis	2010	Streak Lines as Tangent Curves of a Derived Vector field	10.1109/TVCG.2010.198	http://dx.doi.org/10.1109/TVCG.2010.198	1225	1234	J	Characteristic curves of vector fields include stream, path, and streak lines. Stream and path lines can be obtained by a simple vector field integration of an autonomous ODE system, i.e., they can be described as tangent curves of a vector field. This facilitates their mathematical analysis including the extraction of core lines around which stream or path lines exhibit swirling motion, or the computation of their curvature for every point in the domain without actually integrating them. Such a description of streak lines is not yet available, which excludes them from most of the feature extraction and analysis tools that have been developed in our community. In this paper, we develop the first description of streak lines as tangent curves of a derived vector field - the streak line vector field - and show how it can be computed from the spatial and temporal gradients of the flow map, i.e., a dense path line integration is required. We demonstrate the high accuracy of our approach by comparing it to solutions where the ground truth is analytically known and to solutions where the ground truth has been obtained using the classic streak line computation. Furthermore, we apply a number of feature extraction and analysis tools to the new streak line vector field including the extraction of cores of swirling streak lines and the computation of streak line curvature fields. These first applications foreshadow the large variety of possible future research directions based on our new mathematical description of streak lines.	Tino Weinkauf;Holger Theisel	Courant Inst. of Math. Sci., New York Univ., New York, NY, USA|c|;	10.1109/TVCG.2007.70557;10.1109/VISUAL.2005.1532851;10.1109/TVCG.2007.70545;10.1109/TVCG.2009.154;10.1109/TVCG.2007.70554;10.1109/VISUAL.2004.99;10.1109/TVCG.2008.133;10.1109/TVCG.2009.190;10.1109/VISUAL.2005.1532832;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1992.235211;10.1109/TVCG.2008.163;10.1109/TVCG.2007.70551	Unsteady flow visualization, streak lines, streak surfaces, feature extraction	
Vis	2010	Superquadric Glyphs for Symmetric Second-Order Tensors	10.1109/TVCG.2010.199	http://dx.doi.org/10.1109/TVCG.2010.199	1595	1604	J	Symmetric second-order tensor fields play a central role in scientific and biomedical studies as well as in image analysis and feature-extraction methods. The utility of displaying tensor field samples has driven the development of visualization techniques that encode the tensor shape and orientation into the geometry of a tensor glyph. With some exceptions, these methods work only for positive-definite tensors (i.e. having positive eigenvalues, such as diffusion tensors). We expand the scope of tensor glyphs to all symmetric second-order tensors in two and three dimensions, gracefully and unambiguously depicting any combination of positive and negative eigenvalues. We generalize a previous method of superquadric glyphs for positive-definite tensors by drawing upon a larger portion of the superquadric shape space, supplemented with a coloring that indicates the tensor's quadratic form. We show that encoding arbitrary eigenvalue sign combinations requires design choices that differ fundamentally from those in previous work on traceless tensors (arising in the study of liquid crystals). Our method starts with a design of 2-D tensor glyphs guided by principles of symmetry and continuity, and creates 3-D glyphs that include the 2-D glyphs in their axis-aligned cross-sections. A key ingredient of our method is a novel way of mapping from the shape space of three-dimensional symmetric second-order tensors to the unit square. We apply our new glyphs to stress tensors from mechanics, geometry tensors and Hessians from image analysis, and rate-of-deformation tensors in computational fluid dynamics.	Thomas Schultz 0001;Gordon L. Kindlmann	Comput. Sci. Dept., Univ. of Chicago, Chicago, IL, USA|c|;	10.1109/VISUAL.1999.809905;10.1109/TVCG.2006.134;10.1109/VISUAL.1998.745294;10.1109/TVCG.2006.181;10.1109/VISUAL.1991.175773;10.1109/TVCG.2009.184;10.1109/TVCG.2006.182;10.1109/TVCG.2009.177;10.1109/TVCG.2010.166;10.1109/VISUAL.1993.398849;10.1109/VISUAL.2003.1250414;10.1109/VISUAL.1994.346326;10.1109/VISUAL.1997.663929;10.1109/VISUAL.2002.1183797;10.1109/VISUAL.2003.1250376;10.1109/VISUAL.2005.1532774;10.1109/VISUAL.2004.80;10.1109/TVCG.2006.115	Tensor Glyphs, Stress Tensors, Rate-of-Deformation Tensors, Geometry Tensors, Glyph Design	
Vis	2010	Supine and Prone Colon Registration Using Quasi-Conformal Mapping	10.1109/TVCG.2010.200	http://dx.doi.org/10.1109/TVCG.2010.200	1348	1357	J	In virtual colonoscopy, CT scans are typically acquired with the patient in both supine (facing up) and prone (facing down) positions. The registration of these two scans is desirable so that the user can clarify situations or confirm polyp findings at a location in one scan with the same location in the other, thereby improving polyp detection rates and reducing false positives. However, this supine-prone registration is challenging because of the substantial distortions in the colon shape due to the patient's change in position. We present an efficient algorithm and framework for performing this registration through the use of conformal geometry to guarantee that the registration is a diffeomorphism (a one-to-one and onto mapping). The taeniae coli and colon flexures are automatically extracted for each supine and prone surface, employing the colon geometry. The two colon surfaces are then divided into several segments using the flexures, and each segment is cut along a taenia coli and conformally flattened to the rectangular domain using holomorphic differentials. The mean curvature is color encoded as texture images, from which feature points are automatically detected using graph cut segmentation, mathematic morphological operations, and principal component analysis. Corresponding feature points are found between supine and prone and are used to adjust the conformal flattening to be quasi-conformal, such that the features become aligned. We present multiple methods of visualizing our results, including 2D flattened rendering, corresponding 3D endoluminal views, and rendering of distortion measurements. We demonstrate the efficiency and efficacy of our registration method by illustrating matched views on both the 2D flattened colon images and in the 3D volume rendered colon endoluminal view. We analytically evaluate the correctness of the results by measuring the distance between features on the registered colons.	Wei Zeng;Joseph Marino;Krishna Chaitanya Gurijala;Xianfeng Gu;Arie E. Kaufman	Comput. Sci. Dept. at, Stony Brook Univ., Stony Brook, NY, USA|c|;;;;	10.1109/VISUAL.2005.1532806;10.1109/TVCG.2006.112;10.1109/VISUAL.2004.75;10.1109/TVCG.2006.158	Data registration, geometry-based techniques, medical visualization, mathematical foundations for visualization	
Vis	2010	TanGeoMS: Tangible Geospatial Modeling System	10.1109/TVCG.2010.202	http://dx.doi.org/10.1109/TVCG.2010.202	1605	1612	J	We present TanGeoMS, a tangible geospatial modeling visualization system that couples a laser scanner, projector, and a flexible physical three-dimensional model with a standard geospatial information system (GIS) to create a tangible user interface for terrain data. TanGeoMS projects an image of real-world data onto a physical terrain model. Users can alter the topography of the model by modifying the clay surface or placing additional objects on the surface. The modified model is captured by an overhead laser scanner then imported into a GIS for analysis and simulation of real-world processes. The results are projected back onto the surface of the model providing feedback on the impact of the modifications on terrain parameters and simulated processes. Interaction with a physical model is highly intuitive, allowing users to base initial design decisions on geospatial data, test the impact of these decisions in GIS simulations, and use the feedback to improve their design. We demonstrate the system on three applications: investigating runoff management within a watershed, assessing the impact of storm surge on barrier islands, and exploring landscape rehabilitation in military training areas.	Laura Tateosian;Helena Mitásová;Brendan Harmon;Brent Fogleman;Katherine Weaver;Russell S. Harmon	North Carolina State Univ., Raleigh, NC, USA|c|;;;;;	10.1109/VISUAL.1999.809890	Visualization system, geographic/geospatial visualization, terrain visualization, tangible user interface, collaborative visualization, human-computer interaction	
Vis	2010	Two-Phase Mapping for Projecting Massive Data Sets	10.1109/TVCG.2010.207	http://dx.doi.org/10.1109/TVCG.2010.207	1281	1290	J	Most multidimensional projection techniques rely on distance (dissimilarity) information between data instances to embed high-dimensional data into a visual space. When data are endowed with Cartesian coordinates, an extra computational effort is necessary to compute the needed distances, making multidimensional projection prohibitive in applications dealing with interactivity and massive data. The novel multidimensional projection technique proposed in this work, called Part-Linear Multidimensional Projection (PLMP), has been tailored to handle multivariate data represented in Cartesian high-dimensional spaces, requiring only distance information between pairs of representative samples. This characteristic renders PLMP faster than previous methods when processing large data sets while still being competitive in terms of precision. Moreover, knowing the range of variation for data instances in the high-dimensional space, we can make PLMP a truly streaming data projection technique, a trait absent in previous methods.	Fernando Vieira Paulovich;Cláudio T. Silva;Luis Gustavo Nonato	Univ. de Sao Paulo, Sa&#x0303;o Carlos, Brazil|c|;;	10.1109/INFVIS.2002.1173159;10.1109/VISUAL.1996.567787;10.1109/TVCG.2008.138;10.1109/TVCG.2009.131;10.1109/INFVIS.2004.60;10.1109/TVCG.2007.70580;10.1109/TVCG.2008.153;10.1109/INFVIS.2002.1173161	Dimensionality Reduction,Projection Methods,Visual Data Mining,Streaming Technique	
Vis	2010	Uncertainty-Aware Guided Volume Segmentation	10.1109/TVCG.2010.208	http://dx.doi.org/10.1109/TVCG.2010.208	1358	1365	J	Although direct volume rendering is established as a powerful tool for the visualization of volumetric data, efficient and reliable feature detection is still an open topic. Usually, a tradeoff between fast but imprecise classification schemes and accurate but time-consuming segmentation techniques has to be made. Furthermore, the issue of uncertainty introduced with the feature detection process is completely neglected by the majority of existing approaches.In this paper we propose a guided probabilistic volume segmentation approach that focuses on the minimization of uncertainty. In an iterative process, our system continuously assesses uncertainty of a random walker-based segmentation in order to detect regions with high ambiguity, to which the user's attention is directed to support the correction of potential misclassifications. This reduces the risk of critical segmentation errors and ensures that information about the segmentation's reliability is conveyed to the user in a dependable way. In order to improve the efficiency of the segmentation process, our technique does not only take into account the volume data to be segmented, but also enables the user to incorporate classification information. An interactive workflow has been achieved by implementing the presented system on the GPU using the OpenCL API. Our results obtained for several medical data sets of different modalities, including brain MRI and abdominal CT, demonstrate the reliability and efficiency of our approach.	Jörg-Stefan Praßni;Timo Ropinski;Klaus H. Hinrichs	Visualization & Comput. Graphics Res. Group (VisCG), Univ. of Munster, Munster, Germany|c|;;	10.1109/VISUAL.2005.1532855;10.1109/VISUAL.2003.1250370;10.1109/TVCG.2009.189;10.1109/TVCG.2007.70518;10.1109/VISUAL.2005.1532807;10.1109/VISUAL.2003.1250369	Volume segmentation, uncertainty, classification, random walker	
Vis	2010	VDVR: Verifiable Volume Visualization of Projection-Based Data	10.1109/TVCG.2010.211	http://dx.doi.org/10.1109/TVCG.2010.211	1515	1524	J	Practical volume visualization pipelines are never without compromises and errors. A delicate and often-studied component is the interpolation of off-grid samples, where aliasing can lead to misleading artifacts and blurring, potentially hiding fine details of critical importance. The verifiable visualization framework we describe aims to account for these errors directly in the volume generation stage, and we specifically target volumetric data obtained via computed tomography (CT) reconstruction. In this case the raw data are the X-ray projections obtained from the scanner and the volume data generation process is the CT algorithm. Our framework informs the CT reconstruction process of the specific filter intended for interpolation in the subsequent visualization process, and this in turn ensures an accurate interpolation there at a set tolerance. Here, we focus on fast trilinear interpolation in conjunction with an octree-type mixed resolution volume representation without T-junctions. Efficient rendering is achieved by a space-efficient and locality-optimized representation, which can straightforwardly exploit fast fixed-function pipelines on GPUs.	Ziyi Zheng;Wei Xu;Klaus Mueller	Center of Visual Comput., Stony Brook Univ., Stony Brook, NY, USA|c|;;	10.1109/VISUAL.1999.809908;10.1109/VISUAL.1991.175805;10.1109/TVCG.2009.194;10.1109/TVCG.2006.141;10.1109/VISUAL.1994.346331;10.1109/VISUAL.2004.70;10.1109/TVCG.2009.149	Direct volume rendering, computed tomography, filtered back-projection, verifiable visualization 	
Vis	2010	View-Dependent Streamlines for 3D Vector fields	10.1109/TVCG.2010.212	http://dx.doi.org/10.1109/TVCG.2010.212	1578	1586	J	This paper introduces a new streamline placement and selection algorithm for 3D vector fields. Instead of considering the problem as a simple feature search in data space, we base our work on the observation that most streamline fields generate a lot of self-occlusion which prevents proper visualization. In order to avoid this issue, we approach the problem in a view-dependent fashion and dynamically determine a set of streamlines which contributes to data understanding without cluttering the view. Since our technique couples flow characteristic criteria and view-dependent streamline selection we are able achieve the best of both worlds: relevant flow description and intelligible, uncluttered pictures. We detail an efficient GPU implementation of our algorithm, show comprehensive visual results on multiple datasets and compare our method with existing flow depiction techniques. Our results show that our technique greatly improves the readability of streamline visualizations on different datasets without requiring user intervention.	Stéphane Marchesin;Cheng-Kai Chen;Chris Ho;Kwan-Liu Ma	Univ. of California, Davis, CA, USA|c|;;;	10.1109/VISUAL.2005.1532831;10.1109/TVCG.2007.70595;10.1109/VISUAL.1994.346312;10.1109/VISUAL.2002.1183789;10.1109/TVCG.2006.116;10.1109/VISUAL.2000.885690;10.1109/VISUAL.1998.745295;10.1109/VISUAL.2005.1532832;10.1109/VISUAL.2005.1532834;10.1109/TVCG.2009.125	Streamlines, Vector fields, View-dependent	
Vis	2010	Visual Exploration of High Dimensional Scalar Functions	10.1109/TVCG.2010.213	http://dx.doi.org/10.1109/TVCG.2010.213	1271	1280	J	An important goal of scientific data analysis is to understand the behavior of a system or process based on a sample of the system. In many instances it is possible to observe both input parameters and system outputs, and characterize the system as a high-dimensional function. Such data sets arise, for instance, in large numerical simulations, as energy landscapes in optimization problems, or in the analysis of image data relating to biological or medical parameters. This paper proposes an approach to analyze and visualizing such data sets. The proposed method combines topological and geometric techniques to provide interactive visualizations of discretely sampled high-dimensional scalar fields. The method relies on a segmentation of the parameter space using an approximate Morse-Smale complex on the cloud of point samples. For each crystal of the Morse-Smale complex, a regression of the system parameters with respect to the output yields a curve in the parameter space. The result is a simplified geometric representation of the Morse-Smale complex in the high dimensional input domain. Finally, the geometric representation is embedded in 2D, using dimension reduction, to provide a visualization platform. The geometric properties of the regression curves enable the visualization of additional information about each crystal such as local and global shape, width, length, and sampling densities. The method is illustrated on several synthetic examples of two dimensional functions. Two use cases, using data sets from the UCI machine learning repository, demonstrate the utility of the proposed approach on real data. Finally, in collaboration with domain experts the proposed method is applied to two scientific challenges. The analysis of parameters of climate simulations and their relationship to predicted global energy flux and the concentrations of chemical species in a combustion simulation and their integration with temperature.	Samuel Gerber;Peer-Timo Bremer;Valerio Pascucci;Ross T. Whitaker	Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;;	10.1109/VISUAL.2004.96;10.1109/TVCG.2007.70603;10.1109/TVCG.2006.186;10.1109/TVCG.2007.70552;10.1109/TVCG.2007.70601;10.1109/VISUAL.2005.1532839	Morse theory, High-dimensional visualization, Morse-Smale complex	
Vis	2010	Visual Optimality and Stability Analysis of 3DCT Scan Positions	10.1109/TVCG.2010.214	http://dx.doi.org/10.1109/TVCG.2010.214	1477	1486	J	Industrial cone-beam X-Ray computed tomography (CT) systems often face problems due to artifacts caused by a bad placement of the specimen on the rotary plate. This paper presents a visual-analysis tool for CT systems, which provides a simulation-based preview and estimates artifacts and deviations of a specimen's placement using the corresponding 3D geometrical surface model as input. The presented tool identifies potentially good or bad placements of a specimen and regions of a specimen, which cause the major portion of artefacts. The tool can be used for a preliminary analysis of the specimen before CT scanning, in order to determine the optimal way of placing the object. The analysis includes: penetration lengths, placement stability and an investigation in Radon space. Novel visualization techniques are applied to the simulation data. A stability widget is presented for determining the placement parameters' robustness. The performance and the comparison of results provided by the tool compared with real world data is demonstrated using two specimens.	Artem Amirkhanov;Christoph Heinzl;Michael Reiter;Eduard Gröller	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Vienna, Austria|c|;;;	10.1109/TVCG.2006.152;10.1109/VISUAL.2005.1532834;10.1109/VISUAL.2005.1532833		
Vis	2010	Visualization by Proxy: A Novel Framework for Deferred Interaction with Volume Data	10.1109/TVCG.2010.215	http://dx.doi.org/10.1109/TVCG.2010.215	1551	1559	J	Interactivity is key to exploration of volume data. Interactivity may be hindered due to many factors, e.g. large data size,high resolution or complexity of a data set, or an expensive rendering algorithm. We present a novel framework for visualizing volumedata that enables interactive exploration using proxy images, without accessing the original 3D data. Data exploration using directvolume rendering requires multiple (often redundant) accesses to possibly large amounts of data. The notion of visualization by proxyrelies on the ability to defer operations traditionally used for exploring 3D data to a more suitable intermediate representation forinteraction - proxy images. Such operations include view changes, transfer function exploration, and relighting. While previous workhas addressed specific interaction needs, we provide a complete solution that enables real-time interaction with large data sets andhas low hardware and storage requirements.	Anna Tikhonova;Carlos D. Correa;Kwan-Liu Ma	Univ. of California, Davis, CA, USA|c|;;	10.1109/TVCG.2007.70591;10.1109/VISUAL.1996.568113;10.1109/VISUAL.2002.1183758	Volume visualization, deferred interaction, image-based rendering, volume distortion camera	
Vis	2010	Visualizing Flow Trajectories Using Locality-based Rendering and Warped Curve Plots	10.1109/TVCG.2010.218	http://dx.doi.org/10.1109/TVCG.2010.218	1587	1594	J	In flow simulations the behavior and properties of particle trajectories often depend on the physical geometry contained in the simulated environment. Understanding the flow in and around the geometry itself is an important part of analyzing the data. Previous work has often utilized focus+context rendering techniques, with an emphasis on showing trajectories while simplifying or illustratively rendering the physical areas. Our research instead emphasizes the local relationship between particle paths and geometry by using a projected multi-field visualization technique. The correlation between a particle path and its surrounding area is calculated on-the-fly and displayed in a non-intrusive manner. In addition, we support visual exploration and comparative analysis through the use of linked information visualization, such as manipulatable curve plots and one-on-one similarity plots. Our technique is demonstrated on particle trajectories from a groundwater simulation and a computer room airflow simulation, where the flow of particles is highly influenced by the dense geometry.	Chad Jones;Kwan-Liu Ma	Univ. of California, Davis, CA, USA|c|;	10.1109/TVCG.2009.136;10.1109/VISUAL.2005.1532850;10.1109/TVCG.2009.145;10.1109/TVCG.2008.186	Flow visualization, Multi-field visualization, Focus+context visualization, Coordinated linked views	
Vis	2010	Volumetric Modeling in Laser BPH Therapy Simulation	10.1109/TVCG.2010.221	http://dx.doi.org/10.1109/TVCG.2010.221	1405	1412	J	In this paper, we introduce a novel application of volume modeling techniques on laser Benign Prostatic Hyperplasia (BPH) therapy simulation. The core technique in our system is an algorithm for simulating the tissue vaporization process by laser heating. Different from classical volume CSG operations, our technique takes experimental data as the guidance to determine the vaporization amount so that only a specified amount of tissue is vaporized in each time. Our algorithm uses a predictor-corrector strategy. First, we apply the classical CSG algorithm on a tetrahedral grid based distance field to estimate the vaporized tissue amount. Then, a volume-correction phase is applied on the distance field. To improve the performance, we further propose optimization approaches for efficient implementation.	Nan Zhang;Xiangmin Zhou;Yunhe Shen;Robert M. Sweet	Univ. of Minnesota, Duluth, MN, USA|c|;;;	10.1109/VISUAL.2003.1250358;10.1109/VISUAL.2003.1250360	Volume modeling, volume CSG, controlled-volume vaporization, medical simulation, laser BPH simulator	
Vis	2010	World Lines	10.1109/TVCG.2010.223	http://dx.doi.org/10.1109/TVCG.2010.223	1458	1467	J	In this paper we present World Lines as a novel interactive visualization that provides complete control over multiple heterogeneous simulation runs. In many application areas, decisions can only be made by exploring alternative scenarios. The goal of the suggested approach is to support users in this decision making process. In this setting, the data domain is extended to a set of alternative worlds where only one outcome will actually happen. World Lines integrate simulation, visualization and computational steering into a single unified system that is capable of dealing with the extended solution space. World Lines represent simulation runs as causally connected tracks that share a common time axis. This setup enables users to interfere and add new information quickly. A World Line is introduced as a visual combination of user events and their effects in order to present a possible future. To quickly find the most attractive outcome, we suggest World Lines as the governing component in a system of multiple linked views and a simulation component. World Lines employ linking and brushing to enable comparative visual analysis of multiple simulations in linked views. Analysis results can be mapped to various visual variables that World Lines provide in order to highlight the most compelling solutions. To demonstrate this technique we present a flooding scenario and show the usefulness of the integrated approach to support informed decision making.	Jürgen Waser;Raphael Fuchs;Hrvoje Ribicic;Benjamin Schindler;Günter Blöschl;Eduard Gröller	VRVis Vienna, Vienna, Austria|c|;;;;;	10.1109/INFVIS.2002.1173149;10.1109/INFVIS.2004.12;10.1109/VISUAL.1999.809871;10.1109/INFVIS.2005.1532143;10.1109/TVCG.2009.199;10.1109/VISUAL.1993.398857;10.1109/TVCG.2008.145;10.1109/TVCG.2007.70539;10.1109/VISUAL.1998.745289	Problem solving environment, decision making, simulation steering, parallel worlds, CFD, smoothed particle hydrodynamics	
InfoVis	2011	A Study on Dual-Scale Data Charts	10.1109/TVCG.2011.160	http://dx.doi.org/10.1109/TVCG.2011.160	2469	2478	J	We present the results of a user study that compares different ways of representing Dual-Scale data charts. Dual-Scale charts incorporate two different data resolutions into one chart in order to emphasize data in regions of interest or to enable the comparison of data from distant regions. While some design guidelines exist for these types of charts, there is currently little empirical evidence on which to base their design. We fill this gap by discussing the design space of Dual-Scale cartesian-coordinate charts and by experimentally comparing the performance of different chart types with respect to elementary graphical perception tasks such as comparing lengths and distances. Our study suggests that cut-out charts which include collocated full context and focus are the best alternative, and that superimposed charts in which focus and context overlap on top of each other should be avoided.	Petra Isenberg;Anastasia Bezerianos;Pierre Dragicevic;Jean-Daniel Fekete	Inria, France;;;	10.1109/INFVIS.1998.729558;10.1109/TVCG.2009.174;10.1109/TVCG.2007.70577	Focus+Context, Quantitative Experiment, Dual-Scale Charts	
InfoVis	2011	Adaptive Privacy-Preserving Visualization Using Parallel Coordinates	10.1109/TVCG.2011.163	http://dx.doi.org/10.1109/TVCG.2011.163	2241	2248	J	Current information visualization techniques assume unrestricted access to data. However, privacy protection is a key issue for a lot of real-world data analyses. Corporate data, medical records, etc. are rich in analytical value but cannot be shared without first going through a transformation step where explicit identifiers are removed and the data is sanitized. Researchers in the field of data mining have proposed different techniques over the years for privacy-preserving data publishing and subsequent mining techniques on such sanitized data. A well-known drawback in these methods is that for even a small guarantee of privacy, the utility of the datasets is greatly reduced. In this paper, we propose an adaptive technique for privacy preser vation in parallel coordinates. Based on knowledge about the sensitivity of the data, we compute a clustered representation on the fly, which allows the user to explore the data without breaching privacy. Through the use of screen-space privacy metrics, the technique adapts to the user's screen parameters and interaction. We demonstrate our method in a case study and discuss potential attack scenarios.	Aritra Dasgupta;Robert Kosara	;	10.1109/VISUAL.1990.146402;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2010.184;10.1109/VISUAL.1999.809866;10.1109/TVCG.2006.170	Parallel coordinates, privacy, clustering	
InfoVis	2011	Angular Histograms: Frequency-Based Visualizations for Large, High Dimensional Data	10.1109/TVCG.2011.166	http://dx.doi.org/10.1109/TVCG.2011.166	2572	2580	J	Parallel coordinates is a popular and well-known multivariate data visualization technique. However, one of their inherent limitations has to do with the rendering of very large data sets. This often causes an overplotting problem and the goal of the visual information seeking mantra is hampered because of a cluttered overview and non-interactive update rates. In this paper, we propose two novel solutions, namely, angular histograms and attribute curves. These techniques are frequency-based approaches to large, high-dimensional data visualization. They are able to convey both the density of underlying polylines and their slopes. Angular histogram and attribute curves offer an intuitive way for the user to explore the clustering, linear correlations and outliers in large data sets without the over-plotting and clutter problems associated with traditional parallel coordinates. We demonstrate the results on a wide variety of data sets including real-world, high-dimensional biological data. Finally, we compare our methods with the other popular frequency-based algorithms.	Zhao Geng;Zhenmin Peng;Robert S. Laramee;Jonathan C. Roberts;Rick Walker	Visual Comput. Group, Swansea Univ., Swansea, UK|c|;;;;	10.1109/INFVIS.2002.1173157;10.1109/INFVIS.2004.68;10.1109/TVCG.2006.138;10.1109/TVCG.2007.70535;10.1109/VISUAL.1999.809866;10.1109/INFVIS.1996.559216;10.1109/VISUAL.1990.146402;10.1109/TVCG.2010.184;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2006.170;10.1109/TVCG.2008.131	Parallel Coordinates, Angular Histogram, Attribute Curves	
InfoVis	2011	Arc Length-Based Aspect Ratio Selection	10.1109/TVCG.2011.167	http://dx.doi.org/10.1109/TVCG.2011.167	2276	2282	J	The aspect ratio of a plot has a dramatic impact on our ability to perceive trends and patterns in the data. Previous approaches for automatically selecting the aspect ratio have been based on adjusting the orientations or angles of the line segments in the plot. In contrast, we recommend a simple, effective method for selecting the aspect ratio: minimize the arc length of the data curve while keeping the area of the plot constant. The approach is parameterization invariant, robust to a wide range of inputs, preserves visual symmetries in the data, and is a compromise between previously proposed techniques. Further, we demonstrate that it can be effectively used to select the aspect ratio of contour plots. We believe arc length should become the default aspect ratio selection method.	Justin Talbot;John Gerth;Pat Hanrahan	;;	10.1109/TVCG.2006.163	Aspect ratio selection, Banking to 45 degrees, Orientation resolution	
InfoVis	2011	Asymmetric Relations in Longitudinal Social Networks	10.1109/TVCG.2011.169	http://dx.doi.org/10.1109/TVCG.2011.169	2283	2290	J	In modeling and analysis of longitudinal social networks, visual exploration is used in particular to complement and inform other methods. The most common graphical representations for this purpose appear to be animations and small multiples of intermediate states, depending on the type of media available. We present an alternative approach based on matrix representation of gestaltlines (a combination of Tufte's sparklines with glyphs based on gestalt theory). As a result, we obtain static, compact, yet data-rich diagrams that support specifically the exploration of evolving dyadic relations and persistent group structure, although at the expense of cross-sectional network views and indirect linkages.	Ulrik Brandes;Bobo Nick	Dept. of Comput. & Inf. Sci., Univ. of Konstanz, Konstanz, Germany|c|;	10.1109/TVCG.2006.163;10.1109/TVCG.2007.70582;10.1109/TVCG.2009.116;10.1109/TVCG.2006.122;10.1109/TVCG.2010.215	Network visualization, Social networks, Time series data, visual knolwedge discovery and representation, glyph-based techniques	
InfoVis	2011	BallotMaps: Detecting Name Bias in Alphabetically Ordered Ballot Papers	10.1109/TVCG.2011.174	http://dx.doi.org/10.1109/TVCG.2011.174	2384	2391	J	The relationship between candidates' position on a ballot paper and vote rank is explored in the case of 5000 candidates for the UK 2010 local government elections in the Greater London area. This design study uses hierarchical spatially arranged graphics to represent two locations that affect candidates at very different scales: the geographical areas for which they seek election and the spatial location of their names on the ballot paper. This approach allows the effect of position bias to be assessed; that is, the degree to which the position of a candidate's name on the ballot paper influences the number of votes received by the candidate, and whether this varies geographically. Results show that position bias was significant enough to influence rank order of candidates, and in the case of many marginal electoral wards, to influence who was elected to government. Position bias was observed most strongly for Liberal Democrat candidates but present for all major political parties. Visual analysis of classification of candidate names by ethnicity suggests that this too had an effect on votes received by candidates, in some cases overcoming alphabetic name bias. The results found contradict some earlier research suggesting that alphabetic name bias was not sufficiently significant to affect electoral outcome and add new evidence for the geographic and ethnicity influences on voting behaviour. The visual approach proposed here can be applied to a wider range of electoral data and the patterns identified and hypotheses derived from them could have significant implications for the design of ballot papers and the conduct of fair elections.	Jo Wood;Donia Badawood;Jason Dykes;Aidan Slingsby	;;;	10.1109/TVCG.2009.128;10.1109/TVCG.2008.165;10.1109/TVCG.2010.161	Voting, election, bias, democracy, governance, treemaps, geovisualization, hierarchy, governance	
InfoVis	2011	Benefitting InfoVis with Visual Difficulties	10.1109/TVCG.2011.175	http://dx.doi.org/10.1109/TVCG.2011.175	2213	2222	J	Many well-cited theories for visualization design state that a visual representation should be optimized for quick and immediate interpretation by a user. Distracting elements like decorative "chartjunk" or extraneous information are avoided so as not to slow comprehension. Yet several recent studies in visualization research provide evidence that non-efficient visual elements may benefit comprehension and recall on the part of users. Similarly, findings from studies related to learning from visual displays in various subfields of psychology suggest that introducing cognitive difficulties to visualization interaction can improve a user's understanding of important information. In this paper, we synthesize empirical results from cross-disciplinary research on visual information representations, providing a counterpoint to efficiency-based design theory with guidelines that describe how visual difficulties can be introduced to benefit comprehension and recall. We identify conditions under which the application of visual difficulties is appropriate based on underlying factors in visualization interaction like active processing and engagement. We characterize effective graph design as a trade-off between efficiency and learning difficulties in order to provide Information Visualization (InfoVis) researchers and practitioners with a framework for organizing explorations of graphs for which comprehension and recall are crucial. We identify implications of this view for the design and evaluation of information visualizations.	Jessica Hullman;Eytan Adar;Priti Shah	;;	10.1109/INFVIS.1995.528688;10.1109/TVCG.2008.125;10.1109/TVCG.2007.70539;10.1109/TVCG.2010.177;10.1109/INFVIS.2001.963279;10.1109/TVCG.2009.111	Desirable difficulites, cognitive efficiency, active processing, engagement, individual differences 	
InfoVis	2011	BirdVis: Visualizing and Understanding Bird Populations	10.1109/TVCG.2011.176	http://dx.doi.org/10.1109/TVCG.2011.176	2374	2383	J	Birds are unrivaled windows into biotic processes at all levels and are proven indicators of ecological well-being. Understanding the determinants of species distributions and their dynamics is an important aspect of ecology and is critical for conservation and management. Through crowdsourcing, since 2002, the eBird project has been collecting bird observation records. These observations, together with local-scale environmental covariates such as climate, habitat, and vegetation phenology have been a valuable resource for a global community of educators, land managers, ornithologists, and conservation biologists. By associating environmental inputs with observed patterns of bird occurrence, predictive models have been developed that provide a statistical framework to harness available data for predicting species distributions and making inferences about species-habitat associations. Understanding these models, however, is challenging because they require scientists to quantify and compare multiscale spatialtemporal patterns. A large series of coordinated or sequential plots must be generated, individually programmed, and manually composed for analysis. This hampers the exploration and is a barrier to making the cross-species comparisons that are essential for coordinating conservation and extracting important ecological information. To address these limitations, as part of a collaboration among computer scientists, statisticians, biologists and ornithologists, we have developed BirdVis, an interactive visualization system that supports the analysis of spatio-temporal bird distribution models. BirdVis leverages visualization techniques and uses them in a novel way to better assist users in the exploration of interdependencies among model parameters. Furthermore, the system allows for comparative visualization through coordinated views, providing an intuitive interface to identify relevant correlations and patterns. We justify our design decisions and present case s- udies that show how BirdVis has helped scientists obtain new evidence for existing hypotheses, as well as formulate new hypotheses in their domain.	Nivan Ferreira;Lauro Didier Lins;Daniel Fink;Steve Kelling;Christopher Wood;Juliana Freire;Cláudio T. Silva	;;;;;;	10.1109/VISUAL.2001.964510;10.1109/VISUAL.1990.146361;10.1109/TVCG.2010.194;10.1109/TVCG.2010.130;10.1109/TVCG.2007.70570;10.1109/TVCG.2008.153	Ornithology, species distribution models, multiscale analysis, spatial data, temporal data	
InfoVis	2011	Brushing Dimensions - A Dual Visual Analysis Model for High-Dimensional Data	10.1109/TVCG.2011.178	http://dx.doi.org/10.1109/TVCG.2011.178	2591	2599	J	In many application fields, data analysts have to deal with datasets that contain many expressions per item. The effective analysis of such multivariate datasets is dependent on the user's ability to understand both the intrinsic dimensionality of the dataset as well as the distribution of the dependent values with respect to the dimensions. In this paper, we propose a visualization model that enables the joint interactive visual analysis of multivariate datasets with respect to their dimensions as well as with respect to the actual data values. We describe a dual setting of visualization and interaction in items space and in dimensions space. The visualization of items is linked to the visualization of dimensions with brushing and focus+context visualization. With this approach, the user is able to jointly study the structure of the dimensions space as well as the distribution of data items with respect to the dimensions. Even though the proposed visualization model is general, we demonstrate its application in the context of a DNA microarray data analysis.	Cagatay Turkay;Peter Filzmoser;Helwig Hauser	Dept. of Inf., Univ. of Bergen, Bergen, Norway	10.1109/INFVIS.2000.885086;10.1109/VISUAL.1994.346302;10.1109/TVCG.2008.116;10.1109/TVCG.2009.199;10.1109/VISUAL.1995.485139;10.1109/VAST.2009.5332611;10.1109/INFVIS.2004.60;10.1109/INFVIS.2004.3;10.1109/VAST.2009.5333431	Interactive visual analysis, High-dimensional data analysis	
InfoVis	2011	CloudLines: Compact Display of Event Episodes in Multiple Time-Series	10.1109/TVCG.2011.179	http://dx.doi.org/10.1109/TVCG.2011.179	2432	2439	J	We propose incremental logarithmic time-series technique as a way to deal with time-based representations of large and dynamic event data sets in limited space. Modern data visualization problems in the domains of news analysis, network security and financial applications, require visual analysis of incremental data, which poses specific challenges that are normally not solved by static visualizations. The incremental nature of the data implies that visualizations have to necessarily change their content and still provide comprehensible representations. In particular, in this paper we deal with the need to keep an eye on recent events together with providing a context on the past and to make relevant patterns accessible at any scale. Our technique adapts to the incoming data by taking care of the rate at which data items occur and by using a decay function to let the items fade away according to their relevance. Since access to details is also important, we also provide a novel distortion magnifying lens technique which takes into account the distortions introduced by the logarithmic time scale to augment readability in selected areas of interest. We demonstrate the validity of our techniques by applying them on incremental data coming from online news streams in different time frames.	Milos Krstajic;Enrico Bertini;Daniel A. Keim	Univ. of Konstanz, Konstanz, Germany|c|;;	10.1109/TVCG.2010.193;10.1109/VAST.2006.261431;10.1109/INFVIS.2005.1532133;10.1109/INFVIS.2003.1249028;10.1109/TVCG.2007.70539	Incremental Visualization, Event-based Data, Lens Distortion	
InfoVis	2011	Composite Density Maps for Multivariate Trajectories	10.1109/TVCG.2011.181	http://dx.doi.org/10.1109/TVCG.2011.181	2518	2527	J	We consider moving objects as multivariate time-series. By visually analyzing the attributes, patterns may appear that explain why certain movements have occurred. Density maps as proposed by Scheepens et al. [25] are a way to reveal these patterns by means of aggregations of filtered subsets of trajectories. Since filtering is often not sufficient for analysts to express their domain knowledge, we propose to use expressions instead. We present a flexible architecture for density maps to enable custom, versatile exploration using multiple density fields. The flexibility comes from a script, depicted in this paper as a block diagram, which defines an advanced computation of a density field. We define six different types of blocks to create, compose, and enhance trajectories or density fields. Blocks are customized by means of expressions that allow the analyst to model domain knowledge. The versatility of our architecture is demonstrated with several maritime use cases developed with domain experts. Our approach is expected to be useful for the analysis of objects in other domains.	Roeland Scheepens;Niels Willems;Huub van de Wetering;Gennady L. Andrienko;Natalia V. Andrienko;Jarke J. van Wijk	Eindhoven Univ. of Technol., Eindhoven, Netherlands|c|;;;;;	10.1109/TVCG.2006.178;10.1109/VAST.2008.4677356;10.1109/TVCG.2007.70570;10.1109/VAST.2010.5652478;10.1109/VAST.2007.4388992;10.1109/VAST.2010.5652467;10.1109/VAST.2009.5332593	Trajectories, Kernel Density Estimation, Multivariate Data, Geographical Information Systems, Raster Maps	
InfoVis	2011	Context-Preserving Visual Links	10.1109/TVCG.2011.183	http://dx.doi.org/10.1109/TVCG.2011.183	2249	2258	J	Evaluating, comparing, and interpreting related pieces of information are tasks that are commonly performed during visual data analysis and in many kinds of information-intensive work. Synchronized visual highlighting of related elements is a well-known technique used to assist this task. An alternative approach, which is more invasive but also more expressive is visual linking in which line connections are rendered between related elements. In this work, we present context-preserving visual links as a new method for generating visual links. The method specifically aims to fulfill the following two goals: first, visual links should minimize the occlusion of important information; second, links should visually stand out from surrounding information by minimizing visual interference. We employ an image-based analysis of visual saliency to determine the important regions in the original representation. A consequence of the image-based approach is that our technique is application-independent and can be employed in a large number of visual data analysis scenarios in which the underlying content cannot or should not be altered. We conducted a controlled experiment that indicates that users can find linked elements in complex visualizations more quickly and with greater subjective satisfaction than in complex visualizations in which plain highlighting is used. Context-preserving visual links were perceived as visually more attractive than traditional visual links that do not account for the context information.	Markus Steinberger;Manuela Waldner;Marc Streit;Alexander Lex;Dieter Schmalstieg	;;;;	10.1109/TVCG.2010.138;10.1109/INFVIS.2001.963286;10.1109/TVCG.2006.147;10.1109/TVCG.2009.122;10.1109/VISUAL.1995.485139;10.1109/TVCG.2010.174;10.1109/TVCG.2006.166;10.1109/TVCG.2007.70521	Visual links, highlighting, connectedness, routing, image-based, saliency	
InfoVis	2011	D3 Data-Driven Documents	10.1109/TVCG.2011.185	http://dx.doi.org/10.1109/TVCG.2011.185	2301	2309	J	Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations.	Michael Bostock;Vadim Ogievetsky;Jeffrey Heer	Comput. Sci. Dept., Stanford Univ., Stanford, CA, USA|c|;;	10.1109/INFVIS.2000.885091;10.1109/INFVIS.2000.885098;10.1109/TVCG.2010.144;10.1109/TVCG.2009.174;10.1109/INFVIS.2004.12;10.1109/TVCG.2006.178;10.1109/INFVIS.2005.1532122;10.1109/TVCG.2008.166;10.1109/INFVIS.2004.64;10.1109/TVCG.2007.70539	Information visualization, user interfaces, toolkits, 2D graphics	
InfoVis	2011	Design Study of LineSets, a Novel Set Visualization Technique	10.1109/TVCG.2011.186	http://dx.doi.org/10.1109/TVCG.2011.186	2259	2267	J	Computing and visualizing sets of elements and their relationships is one of the most common tasks one performs when analyzing and organizing large amounts of data. Common representations of sets such as convex or concave geometries can become cluttered and difficult to parse when these sets overlap in multiple or complex ways, e.g., when multiple elements belong to multiple sets. In this paper, we present a design study of a novel set visual representation, LineSets, consisting of a curve connecting all of the set's elements. Our approach to design the visualization differs from traditional methodology used by the InfoVis community. We first explored the potential of the visualization concept by running a controlled experiment comparing our design sketches to results from the state-of-the-art technique. Our results demonstrated that LineSets are advantageous for certain tasks when compared to concave shapes. We discuss an implementation of LineSets based on simple heuristics and present a study demonstrating that our generated curves do as well as human-drawn ones. Finally, we present two applications of our technique in the context of search tasks on a map and community analysis tasks in social networks.	Basak Alper;Nathalie Henry Riche;Gonzalo Ramos;Mary Czerwinski	;;;	10.1109/TVCG.2008.144;10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/INFVIS.2005.1532126	Set visualization, clustering, faceted data visualization, graph visualization   	
InfoVis	2011	Developing and Evaluating Quilts for the Depiction of Large Layered Graphs	10.1109/TVCG.2011.187	http://dx.doi.org/10.1109/TVCG.2011.187	2268	2275	J	Traditional layered graph depictions such as flow charts are in wide use. Yet as graphs grow more complex, these depictions can become difficult to understand. Quilts are matrix-based depictions for layered graphs designed to address this problem. In this research, we first improve Quilts by developing three design alternatives, and then compare the best of these alternatives to better-known node-link and matrix depictions. A primary weakness in Quilts is their depiction of skip links, links that do not simply connect to a succeeding layer. Therefore in our first study, we compare Quilts using color-only, text-only, and mixed (color and text) skip link depictions, finding that path finding with the color-only depiction is significantly slower and less accurate, and that in certain cases, the mixed depiction offers an advantage over the text-only depiction. In our second study, we compare Quilts using the mixed depiction to node-link diagrams and centered matrices. Overall results show that users can find paths through graphs significantly faster with Quilts (46.6 secs) than with node-link (58.3 secs) or matrix (71.2 secs) diagrams. This speed advantage is still greater in large graphs (e.g. in 200 node graphs, 55.4 secs vs. 71.1 secs for node-link and 84.2 secs for matrix depictions).	Juhee Bae;Benjamin Watson	;	10.1109/TVCG.2010.159;10.1109/INFVIS.2004.1;10.1109/TVCG.2007.70582	Graph drawing, layered graphs, matrix based depiction, node-link diagram	
InfoVis	2011	DICON: Interactive Visual Analysis of Multidimensional Clusters	10.1109/TVCG.2011.188	http://dx.doi.org/10.1109/TVCG.2011.188	2581	2590	J	Clustering as a fundamental data analysis technique has been widely used in many analytic applications. However, it is often difficult for users to understand and evaluate multidimensional clustering results, especially the quality of clusters and their semantics. For large and complex data, high-level statistical information about the clusters is often needed for users to evaluate cluster quality while a detailed display of multidimensional attributes of the data is necessary to understand the meaning of clusters. In this paper, we introduce DICON, an icon-based cluster visualization that embeds statistical information into a multi-attribute display to facilitate cluster interpretation, evaluation, and comparison. We design a treemap-like icon to represent a multidimensional cluster, and the quality of the cluster can be conveniently evaluated with the embedded statistical information. We further develop a novel layout algorithm which can generate similar icons for similar clusters, making comparisons of clusters easier. User interaction and clutter reduction are integrated into the system to help users more effectively analyze and refine clustering results for large datasets. We demonstrate the power of DICON through a user study and a case study in the healthcare domain. Our evaluation shows the benefits of the technique, especially in support of complex multidimensional cluster analysis.	Nan Cao;David Gotz;Jimeng Sun;Huamin Qu	Dept. of Comput. Sci. & Eng., Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;	10.1109/INFVIS.2005.1532128;10.1109/TVCG.2006.147;10.1109/TVCG.2009.179;10.1109/VISUAL.1995.485141;10.1109/TVCG.2007.70582;10.1109/VISUAL.1990.146402;10.1109/VAST.2009.5332628;10.1109/INFVIS.2001.963283;10.1109/INFVIS.1998.729559;10.1109/TVCG.2010.216;10.1109/VISUAL.1999.809866;10.1109/TVCG.2008.153;10.1109/TVCG.2008.165;10.1109/TVCG.2009.153	Visual Analysis, Clustering, Information Visualization	
InfoVis	2011	Divided Edge Bundling for Directional Network Data	10.1109/TVCG.2011.190	http://dx.doi.org/10.1109/TVCG.2011.190	2354	2363	J	The node-link diagram is an intuitive and venerable way to depict a graph. To reduce clutter and improve the readability of node-link views, Holten & van Wijk's force-directed edge bundling employs a physical simulation to spatially group graph edges. While both useful and aesthetic, this technique has shortcomings: it bundles spatially proximal edges regardless of direction, weight, or graph connectivity. As a result, high-level directional edge patterns are obscured. We present divided edge bundling to tackle these shortcomings. By modifying the forces in the physical simulation, directional lanes appear as an emergent property of edge direction. By considering graph topology, we only bundle edges related by graph structure. Finally, we aggregate edge weights in bundles to enable more accurate visualization of total bundle weights. We compare visualizations created using our technique to standard force-directed edge bundling, matrix diagrams, and clustered graphs; we find that divided edge bundling leads to visualizations that are easier to interpret and reveal both familiar and previously obscured patterns.	David Selassie;Brandon Heller;Jeffrey Heer	Comput. Sci. Dept., Stanford Univ., Stanford, CA, USA|c|;;	10.1109/INFVIS.2003.1249008;10.1109/TVCG.2008.135;10.1109/TVCG.2007.70582;10.1109/TVCG.2007.70535;10.1109/TVCG.2006.147	Graph visualization, aggregation, node-link diagrams, edge bundling, physical simulation	
InfoVis	2011	Drawing Road Networks with Focus Regions	10.1109/TVCG.2011.191	http://dx.doi.org/10.1109/TVCG.2011.191	2555	2562	J	Mobile users of maps typically need detailed information about their surroundings plus some context information about remote places. In order to avoid that the map partly gets too dense, cartographers have designed mapping functions that enlarge a user-defined focus region - such functions are sometimes called fish-eye projections. The extra map space occupied by the enlarged focus region is compensated by distorting other parts of the map. We argue that, in a map showing a network of roads relevant to the user, distortion should preferably take place in those areas where the network is sparse. Therefore, we do not apply a predefined mapping function. Instead, we consider the road network as a graph whose edges are the road segments. We compute a new spatial mapping with a graph-based optimization approach, minimizing the square sum of distortions at edges. Our optimization method is based on a convex quadratic program (CQP); CQPs can be solved in polynomial time. Important requirements on the output map are expressed as linear inequalities. In particular, we show how to forbid edge crossings. We have implemented our method in a prototype tool. For instances of different sizes, our method generated output maps that were far less distorted than those generated with a predefined fish-eye projection. Future work is needed to automate the selection of roads relevant to the user. Furthermore, we aim at fast heuristics for application in real-time systems.	Jan-Henrik Haunert;Leon Sering	Univ. of Würzburg, Würzburg, Germany|c|;	10.1109/TVCG.2008.132;10.1109/INFVIS.2004.66	cartography, schematic maps, fish-eye view, graph drawing, optimization, quadratic programming	
InfoVis	2011	Evaluation of Artery Visualizations for Heart Disease Diagnosis	10.1109/TVCG.2011.192	http://dx.doi.org/10.1109/TVCG.2011.192	2479	2488	J	Heart disease is the number one killer in the United States, and finding indicators of the disease at an early stage is critical for treatment and prevention. In this paper we evaluate visualization techniques that enable the diagnosis of coronary artery disease. A key physical quantity of medical interest is endothelial shear stress (ESS). Low ESS has been associated with sites of lesion formation and rapid progression of disease in the coronary arteries. Having effective visualizations of a patient's ESS data is vital for the quick and thorough non-invasive evaluation by a cardiologist. We present a task taxonomy for hemodynamics based on a formative user study with domain experts. Based on the results of this study we developed HemoVis, an interactive visualization application for heart disease diagnosis that uses a novel 2D tree diagram representation of coronary artery trees. We present the results of a formal quantitative user study with domain experts that evaluates the effect of 2D versus 3D artery representations and of color maps on identifying regions of low ESS. We show statistically significant results demonstrating that our 2D visualizations are more accurate and efficient than 3D representations, and that a perceptually appropriate color map leads to fewer diagnostic mistakes than a rainbow color map.	Michelle Borkin;Krzysztof Z. Gajos;Amanda Peters Randles;Dimitris Mitsouras;Simone Melchionna;Frank J. Rybicki;Charles L. Feldman;Hanspeter Pfister	;;;;;;;	10.1109/TVCG.2009.169;10.1109/VISUAL.2002.1183788;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2001.964510;10.1109/VISUAL.2004.104;10.1109/TVCG.2006.172;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2009.126;10.1109/VISUAL.2001.964538;10.1109/TVCG.2009.126;10.1109/VISUAL.1992.235201;10.1109/VISUAL.1996.568118;10.1109/VISUAL.2000.885731;10.1109/TVCG.2007.70550;10.1109/TVCG.2007.70596	Quantitative evaluation, qualitative evaluation, biomedical and medical visualization	
InfoVis	2011	Evaluation of Traditional, Orthogonal, and Radial Tree Diagrams by an Eye Tracking Study	10.1109/TVCG.2011.193	http://dx.doi.org/10.1109/TVCG.2011.193	2440	2448	J	Node-link diagrams are an effective and popular visualization approach for depicting hierarchical structures and for showing parent-child relationships. In this paper, we present the results of an eye tracking experiment investigating traditional, orthogonal, and radial node-link tree layouts as a piece of empirical basis for choosing between those layouts. Eye tracking was used to identify visual exploration behaviors of participants that were asked to solve a typical hierarchy exploration task by inspecting a static tree diagram: finding the least common ancestor of a given set of marked leaf nodes. To uncover exploration strategies, we examined fixation points, duration, and saccades of participants' gaze trajectories. For the non-radial diagrams, we additionally investigated the effect of diagram orientation by switching the position of the root node to each of the four main orientations. We also recorded and analyzed correctness of answers as well as completion times in addition to the eye movement data. We found out that traditional and orthogonal tree layouts significantly outperform radial tree layouts for the given task. Furthermore, by applying trajectory analysis techniques we uncovered that participants cross-checked their task solution more often in the radial than in the non-radial layouts.	Michael Burch;Natalia Konevtsova;Julian Heinrich;Markus Höferlin;Daniel Weiskopf	VISUS, Univ. of Stuttgart, Germany|c|;;;;	10.1109/TVCG.2010.209;10.1109/INFVIS.2004.70	Hierarchy visualization, node-link layout, eye tracking, user study	
InfoVis	2011	Exploratory Analysis of Time-Series with ChronoLenses	10.1109/TVCG.2011.195	http://dx.doi.org/10.1109/TVCG.2011.195	2422	2431	J	Visual representations of time-series are useful for tasks such as identifying trends, patterns and anomalies in the data. Many techniques have been devised to make these visual representations more scalable, enabling the simultaneous display of multiple variables, as well as the multi-scale display of time-series of very high resolution or that span long time periods. There has been comparatively little research on how to support the more elaborate tasks associated with the exploratory visual analysis of timeseries, e.g., visualizing derived values, identifying correlations, or discovering anomalies beyond obvious outliers. Such tasks typically require deriving new time-series from the original data, trying different functions and parameters in an iterative manner. We introduce a novel visualization technique called ChronoLenses, aimed at supporting users in such exploratory tasks. ChronoLenses perform on-the-fly transformation of the data points in their focus area, tightly integrating visual analysis with user actions, and enabling the progressive construction of advanced visual analysis pipelines.	Jian Zhao;Fanny Chevalier;Emmanuel Pietriga;Ravin Balakrishnan	DGP, Univ. of Toronto, Toronto, ON, Canada|c|;;;	10.1109/TVCG.2010.162;10.1109/INFVIS.1999.801851;10.1109/VAST.2007.4389007;10.1109/INFVIS.2001.963273;10.1109/INFVIS.2005.1532148;10.1109/TVCG.2007.70583;10.1109/TVCG.2010.193	Time-series Data, Exploratory Visualization, Focus+Context, Lens, Interaction Techniques	
InfoVis	2011	Exploring Ambient and Artistic Visualization for Residential Energy Use Feedback	10.1109/TVCG.2011.196	http://dx.doi.org/10.1109/TVCG.2011.196	2489	2497	J	Providing effective feedback on resource consumption in the home is a key challenge of environmental conservation efforts. One promising approach for providing feedback about residential energy consumption is the use of ambient and artistic visualizations. Pervasive computing technologies enable the integration of such feedback into the home in the form of distributed point-of-consumption feedback devices to support decision-making in everyday activities. However, introducing these devices into the home requires sensitivity to the domestic context. In this paper we describe three abstract visualizations and suggest four design requirements that this type of device must meet to be effective: pragmatic, aesthetic, ambient, and ecological. We report on the findings from a mixed methods user study that explores the viability of using ambient and artistic feedback in the home based on these requirements. Our findings suggest that this approach is a viable way to provide resource use feedback and that both the aesthetics of the representation and the context of use are important elements that must be considered in this design space.	Johnny Rodgers;Lyn Bartram	;	10.1109/TVCG.2007.70541;10.1109/INFVIS.2003.1249031	Ambient visualization, informative art, casual infovis, sustainability, distributed visualization	
InfoVis	2011	Exploring Uncertainty in Geodemographics with Interactive Graphics	10.1109/TVCG.2011.197	http://dx.doi.org/10.1109/TVCG.2011.197	2545	2554	J	Geodemographic classifiers characterise populations by categorising geographical areas according to the demographic and lifestyle characteristics of those who live within them. The dimension-reducing quality of such classifiers provides a simple and effective means of characterising population through a manageable set of categories, but inevitably hides heterogeneity, which varies within and between the demographic categories and geographical areas, sometimes systematically. This may have implications for their use, which is widespread in government and commerce for planning, marketing and related activities. We use novel interactive graphics to delve into OAC - a free and open geodemographic classifier that classifies the UK population in over 200,000 small geographical areas into 7 super-groups, 21 groups and 52 sub-groups. Our graphics provide access to the original 41 demographic variables used in the classification and the uncertainty associated with the classification of each geographical area on-demand. It also supports comparison geographically and by category. This serves the dual purpose of helping understand the classifier itself leading to its more informed use and providing a more comprehensive view of population in a comprehensible manner. We assess the impact of these interactive graphics on experienced OAC users who explored the details of the classification, its uncertainty and the nature of between - and within - class variation and then reflect on their experiences. Visualization of the complexities and subtleties of the classification proved to be a thought-provoking exercise both confirming and challenging users' understanding of population, the OAC classifier and the way it is used in their organisations. Users identified three contexts for which the techniques were deemed useful in the context of local government, confirming the validity of the proposed methods.	Aidan Slingsby;Jason Dykes;Jo Wood	;;	10.1109/INFVIS.1996.559216;10.1109/TVCG.2010.191;10.1109/TVCG.2007.70574;10.1109/TVCG.2010.186;10.1109/VISUAL.1999.809866;10.1109/TVCG.2008.165;10.1109/TVCG.2006.202;10.1109/TVCG.2007.70515;10.1109/INFVIS.2004.12	Geodemographics, OAC, classification, cartography, uncertainty	
InfoVis	2011	Flexible Linked Axes for Multivariate Data Visualization	10.1109/TVCG.2011.201	http://dx.doi.org/10.1109/TVCG.2011.201	2310	2316	J	Multivariate data visualization is a classic topic, for which many solutions have been proposed, each with its own strengths and weaknesses. In standard solutions the structure of the visualization is fixed, we explore how to give the user more freedom to define visualizations. Our new approach is based on the usage of Flexible Linked Axes: The user is enabled to define a visualization by drawing and linking axes on a canvas. Each axis has an associated attribute and range, which can be adapted. Links between pairs of axes are used to show data in either scatter plot- or Parallel Coordinates Plot-style. Flexible Linked Axes enable users to define a wide variety of different visualizations. These include standard methods, such as scatter plot matrices, radar charts, and PCPs [11]; less well known approaches, such as Hyperboxes [1], TimeWheels [17], and many-to-many relational parallel coordinate displays [14]; and also custom visualizations, consisting of combinations of scatter plots and PCPs. Furthermore, our method allows users to define composite visualizations that automatically support brushing and linking. We have discussed our approach with ten prospective users, who found the concept easy to understand and highly promising.	Jarry H. T. Claessen;Jarke J. van Wijk	Eindhoven Univ. of Technol., Eindhoven, Netherlands|c|;	10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.2002.1173157;10.1109/TVCG.2006.138;10.1109/TVCG.2010.205;10.1109/TVCG.2006.170;10.1109/TVCG.2007.70521;10.1109/VISUAL.1991.175790;10.1109/TVCG.2008.153	Multivariate data, visualization, scatterplot, Parallel Coordinates Plot	
InfoVis	2011	Flow Map Layout via Spiral Trees	10.1109/TVCG.2011.202	http://dx.doi.org/10.1109/TVCG.2011.202	2536	2544	J	Flow maps are thematic maps that visualize the movement of objects, such as people or goods, between geographic regions. One or more sources are connected to several targets by lines whose thickness corresponds to the amount of flow between a source and a target. Good flow maps reduce visual clutter by merging (bundling) lines smoothly and by avoiding self-intersections. Most flow maps are still drawn by hand and only few automated methods exist. Some of the known algorithms do not support edge-bundling and those that do, cannot guarantee crossing-free flows. We present a new algorithmic method that uses edge-bundling and computes crossing-free flows of high visual quality. Our method is based on so-called spiral trees, a novel type of Steiner tree which uses logarithmic spirals. Spiral trees naturally induce a clustering on the targets and smoothly bundle lines. Our flows can also avoid obstacles, such as map features, region outlines, or even the targets. We demonstrate our approach with extensive experiments.	Kevin Buchin;Bettina Speckmann;Kevin Verbeek	Tech. Univ. Eindhoven, Eindhoven, Netherlands|c|;;	10.1109/TVCG.2009.143;10.1109/TVCG.2008.135;10.1109/INFVIS.2005.1532150;10.1109/INFVIS.1996.559226;10.1109/TVCG.2006.147	Flow maps, Automated Cartography, Spiral Trees	
InfoVis	2011	Focus+Context Metro Maps	10.1109/TVCG.2011.205	http://dx.doi.org/10.1109/TVCG.2011.205	2528	2535	J	We introduce a focus+context method to visualize a complicated metro map of a modern city on a small displaying area. The context of our work is with regard the popularity of mobile devices. The best route to the destination, which can be obtained from the arrival time of trains, is highlighted. The stations on the route enjoy larger spaces, whereas the other stations are rendered smaller and closer to fit the whole map into a screen. To simplify the navigation and route planning for visitors, we formulate various map characteristics such as octilinear transportation lines and regular station distances into energy terms. We then solve for the optimal layout in a least squares sense. In addition, we label the names of stations that are on the route of a passenger according to human preferences, occlusions, and consistencies of label positions using the graph cuts method. Our system achieves real-time performance by being able to report instant information because of the carefully designed energy terms. We apply our method to layout a number of metro maps and show the results and timing statistics to demonstrate the feasibility of our technique.	Yu-Shuen Wang;Ming-Te Chi	;	10.1109/INFVIS.1997.636786;10.1109/INFVIS.1996.559214;10.1109/TVCG.2008.132;10.1109/INFVIS.1998.729558;10.1109/VISUAL.2005.1532818	Focus+context visualization, metro map, octilinear layout, graph labeling, optimization	
InfoVis	2011	Human-Centered Approaches in Geovisualization Design: Investigating Multiple Methods Through a Long-Term Case Study	10.1109/TVCG.2011.209	http://dx.doi.org/10.1109/TVCG.2011.209	2498	2507	J	Working with three domain specialists we investigate human-centered approaches to geovisualization following an ISO13407 taxonomy covering context of use, requirements and early stages of design. Our case study, undertaken over three years, draws attention to repeating trends: that generic approaches fail to elicit adequate requirements for geovis application design; that the use of real data is key to understanding needs and possibilities; that trust and knowledge must be built and developed with collaborators. These processes take time but modified human-centred approaches can be effective. A scenario developed through contextual inquiry but supplemented with domain data and graphics is useful to geovis designers. Wireframe, paper and digital prototypes enable successful communication between specialist and geovis domains when incorporating real and interesting data, prompting exploratory behaviour and eliciting previously unconsidered requirements. Paper prototypes are particularly successful at eliciting suggestions, especially for novel visualization. Enabling specialists to explore their data freely with a digital prototype is as effective as using a structured task protocol and is easier to administer. Autoethnography has potential for framing the design process. We conclude that a common understanding of context of use, domain data and visualization possibilities are essential to successful geovis design and develop as this progresses. HC approaches can make a significant contribution here. However, modified approaches, applied with flexibility, are most promising. We advise early, collaborative engagement with data - through simple, transient visual artefacts supported by data sketches and existing designs - before moving to successively more sophisticated data wireframes and data prototypes.	David Lloyd;Jason Dykes	giCentre, City Univ. London, London, UK|c|;	10.1109/TVCG.2010.191;10.1109/TVCG.2009.174	Evaluation, geovisualization, context of use, requirements, field study, prototypes, sketching, design	
InfoVis	2011	Improved Similarity Trees and their Application to Visual Data Classification	10.1109/TVCG.2011.212	http://dx.doi.org/10.1109/TVCG.2011.212	2459	2468	J	An alternative form to multidimensional projections for the visual analysis of data represented in multidimensional spaces is the deployment of similarity trees, such as Neighbor Joining trees. They organize data objects on the visual plane emphasizing their levels of similarity with high capability of detecting and separating groups and subgroups of objects. Besides this similarity-based hierarchical data organization, some of their advantages include the ability to decrease point clutter; high precision; and a consistent view of the data set during focusing, offering a very intuitive way to view the general structure of the data set as well as to drill down to groups and subgroups of interest. Disadvantages of similarity trees based on neighbor joining strategies include their computational cost and the presence of virtual nodes that utilize too much of the visual space. This paper presents a highly improved version of the similarity tree technique. The improvements in the technique are given by two procedures. The first is a strategy that replaces virtual nodes by promoting real leaf nodes to their place, saving large portions of space in the display and maintaining the expressiveness and precision of the technique. The second improvement is an implementation that significantly accelerates the algorithm, impacting its use for larger data sets. We also illustrate the applicability of the technique in visual data mining, showing its advantages to support visual classification of data sets, with special attention to the case of image classification. We demonstrate the capabilities of the tree for analysis and iterative manipulation and employ those capabilities to support evolving to a satisfactory data organization and classification.	Jose Gustavo Paiva;Laura Florian;Hélio Pedrini;Guilherme P. Telles;Rosane Minghim	Univ. of Sao Paulo, Sao Paulo, Brazil|c|;;;;	10.1109/INFVIS.1999.801855;10.1109/TVCG.2009.140;10.1109/VAST.2007.4389002;10.1109/TVCG.2008.138;10.1109/VISUAL.1996.567787;10.1109/TVCG.2010.207;10.1109/TVCG.2010.170;10.1109/INFVIS.2002.1173148	Similarity Trees, Multidimensional Projections, Image Classification	
InfoVis	2011	In Situ Exploration of Large Dynamic Networks	10.1109/TVCG.2011.213	http://dx.doi.org/10.1109/TVCG.2011.213	2334	2343	J	The analysis of large dynamic networks poses a challenge in many fields, ranging from large bot-nets to social networks. As dynamic networks exhibit different characteristics, e.g., being of sparse or dense structure, or having a continuous or discrete time line, a variety of visualization techniques have been specifically designed to handle these different aspects of network structure and time. This wide range of existing techniques is well justified, as rarely a single visualization is suitable to cover the entire visual analysis. Instead, visual representations are often switched in the course of the exploration of dynamic graphs as the focus of analysis shifts between the temporal and the structural aspects of the data. To support such a switching in a seamless and intuitive manner, we introduce the concept of in situ visualization- a novel strategy that tightly integrates existing visualization techniques for dynamic networks. It does so by allowing the user to interactively select in a base visualization a region for which a different visualization technique is then applied and embedded in the selection made. This permits to change the way a locally selected group of data items, such as nodes or time points, are shown - right in the place where they are positioned, thus supporting the user's overall mental map. Using this approach, a user can switch seamlessly between different visual representations to adapt a region of a base visualization to the specifics of the data within it or to the current analysis focus. This paper presents and discusses the in situ visualization strategy and its implications for dynamic graph visualization. Furthermore, it illustrates its usefulness by employing it for the visual exploration of dynamic networks from two different fields: model versioning and wireless mesh networks.	Steffen Hadlak;Hans-Jörg Schulz;Heidrun Schumann	;;	10.1109/TVCG.2009.151;10.1109/TVCG.2008.114;10.1109/INFVIS.2004.18;10.1109/TVCG.2007.70582;10.1109/INFVIS.2000.885087;10.1109/INFVIS.2004.66;10.1109/INFVIS.2002.1173153;10.1109/INFVIS.2002.1173160;10.1109/INFVIS.2005.1532151;10.1109/INFVIS.2003.1249006;10.1109/TVCG.2007.70529;10.1109/TVCG.2006.166	Dynamic graph data, multiform visualization, multi-focus+context	
InfoVis	2011	Local Affine Multidimensional Projection	10.1109/TVCG.2011.220	http://dx.doi.org/10.1109/TVCG.2011.220	2563	2571	J	Multidimensional projection techniques have experienced many improvements lately, mainly regarding computational times and accuracy. However, existing methods do not yet provide flexible enough mechanisms for visualization-oriented fully interactive applications. This work presents a new multidimensional projection technique designed to be more flexible and versatile than other methods. This novel approach, called Local Affine Multidimensional Projection (LAMP), relies on orthogonal mapping theory to build accurate local transformations that can be dynamically modified according to user knowledge. The accuracy, flexibility and computational efficiency of LAMP is confirmed by a comprehensive set of comparisons. LAMP's versatility is exploited in an application which seeks to correlate data that, in principle, has no connection as well as in visual exploration of textual documents.	Paulo Joia;Danilo Barbosa Coimbra;José Alberto Cuminato;Fernando Vieira Paulovich;Luis Gustavo Nonato	Univ. de Sao Paulo, Sao Paulo, Brazil|c|;;;;	10.1109/VISUAL.1996.567787;10.1109/TVCG.2009.140;10.1109/TVCG.2007.70580;10.1109/INFVIS.2002.1173159;10.1109/TVCG.2010.207;10.1109/TVCG.2010.170;10.1109/INFVIS.2002.1173161	Multidimensional Projection, High Dimensional Data, Visual Data Mining	
InfoVis	2011	MoleView: An Attribute and Structure-Based Semantic Lens for Large Element-Based Plots	10.1109/TVCG.2011.223	http://dx.doi.org/10.1109/TVCG.2011.223	2600	2609	J	We present MoleView, a novel technique for interactive exploration of multivariate relational data. Given a spatial embedding of the data, in terms of a scatter plot or graph layout, we propose a semantic lens which selects a specific spatial and attribute-related data range. The lens keeps the selected data in focus unchanged and continuously deforms the data out of the selection range in order to maintain the context around the focus. Specific deformations include distance-based repulsion of scatter plot points, deforming straight-line node-link graph drawings, and as varying the simplification degree of bundled edge graph layouts. Using a brushing-based technique, we further show the applicability of our semantic lens for scenarios requiring a complex selection of the zones of interest. Our technique is simple to implement and provides real-time performance on large datasets. We demonstrate our technique with actual data from air and road traffic control, medical imaging, and software comprehension applications.	Christophe Hurter;Alexandru Telea;Ozan Ersoy	DGAC, Univ. of Toulouse, Toulouse, France	10.1109/TVCG.2011.233;10.1109/TVCG.2008.135;10.1109/TVCG.2006.147;10.1109/INFVIS.2005.1532150;10.1109/INFVIS.2004.66;10.1109/INFVIS.2003.1249008	Semantic lenses, magic lenses, graph bundling, attribute filtering	
InfoVis	2011	Parallel Edge Splatting for Scalable Dynamic Graph Visualization	10.1109/TVCG.2011.226	http://dx.doi.org/10.1109/TVCG.2011.226	2344	2353	J	We present a novel dynamic graph visualization technique based on node-link diagrams. The graphs are drawn side-byside from left to right as a sequence of narrow stripes that are placed perpendicular to the horizontal time line. The hierarchically organized vertices of the graphs are arranged on vertical, parallel lines that bound the stripes; directed edges connect these vertices from left to right. To address massive overplotting of edges in huge graphs, we employ a splatting approach that transforms the edges to a pixel-based scalar field. This field represents the edge densities in a scalable way and is depicted by non-linear color mapping. The visualization method is complemented by interaction techniques that support data exploration by aggregation, filtering, brushing, and selective data zooming. Furthermore, we formalize graph patterns so that they can be interactively highlighted on demand. A case study on software releases explores the evolution of call graphs extracted from the JUnit open source software project. In a second application, we demonstrate the scalability of our approach by applying it to a bibliography dataset containing more than 1.5 million paper titles from 60 years of research history producing a vast amount of relations between title words.	Michael Burch;Corinna Vehlow;Fabian Beck;Stephan Diehl 0001;Daniel Weiskopf	VISUS, Univ. of Stuttgart, Stuttgart, Germany|c|;;;;	10.1109/TVCG.2009.123;10.1109/TVCG.2008.131;10.1109/VISUAL.1990.146402;10.1109/TVCG.2010.176;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2006.147;10.1109/TVCG.2009.131;10.1109/INFVIS.1999.801866;10.1109/INFVIS.2002.1173160;10.1109/INFVIS.2004.68	Dynamic graph visualization, graph splatting, software visualization, software evolution	
InfoVis	2011	Product Plots	10.1109/TVCG.2011.227	http://dx.doi.org/10.1109/TVCG.2011.227	2223	2230	J	We propose a new framework for visualising tables of counts, proportions and probabilities. We call our framework product plots, alluding to the computation of area as a product of height and width, and the statistical concept of generating a joint distribution from the product of conditional and marginal distributions. The framework, with extensions, is sufficient to encompass over 20 visualisations previously described in fields of statistical graphics and infovis, including bar charts, mosaic plots, treemaps, equal area plots and fluctuation diagrams.	Hadley Wickham;Heike Hofmann	;	10.1109/TVCG.2007.70594;10.1109/TVCG.2006.200;10.1109/INFVIS.2002.1173141;10.1109/INFVIS.2000.885091;10.1109/VISUAL.1990.146386;10.1109/TVCG.2010.186;10.1109/INFVIS.2005.1532128;10.1109/INFVIS.2005.1532142;10.1109/TVCG.2010.209;10.1109/TVCG.2009.128;10.1109/INFVIS.2005.1532145	Statistics, joint distribution, conditional distribution, treemap, bar chart, mosaic plot	
InfoVis	2011	Quality Metrics in High-Dimensional Data Visualization: An Overview and Systematization	10.1109/TVCG.2011.229	http://dx.doi.org/10.1109/TVCG.2011.229	2203	2212	J	In this paper, we present a systematization of techniques that use quality metrics to help in the visual exploration of meaningful patterns in high-dimensional data. In a number of recent papers, different quality metrics are proposed to automate the demanding search through large spaces of alternative visualizations (e.g., alternative projections or ordering), allowing the user to concentrate on the most promising visualizations suggested by the quality metrics. Over the last decade, this approach has witnessed a remarkable development but few reflections exist on how these methods are related to each other and how the approach can be developed further. For this purpose, we provide an overview of approaches that use quality metrics in high-dimensional data visualization and propose a systematization based on a thorough literature review. We carefully analyze the papers and derive a set of factors for discriminating the quality metrics, visualization techniques, and the process itself. The process is described through a reworked version of the well-known information visualization pipeline. We demonstrate the usefulness of our model by applying it to several existing approaches that use quality metrics, and we provide reflections on implications of our model for future research.	Enrico Bertini	Univ. of Konstanz, Konstanz, Germany|c|;;	10.1109/INFVIS.2005.1532145;10.1109/VAST.2010.5652433;10.1109/VAST.2006.261423;10.1109/TVCG.2010.184;10.1109/TVCG.2010.179;10.1109/INFVIS.2004.15;10.1109/TVCG.2006.161;10.1109/TVCG.2007.70515;10.1109/INFVIS.2005.1532142;10.1109/VISUAL.1990.146402;10.1109/INFVIS.2003.1249006;10.1109/VISUAL.1990.146386;10.1109/TVCG.2006.138;10.1109/INFVIS.2004.59;10.1109/VAST.2009.5332628;10.1109/INFVIS.2003.1249015;10.1109/VAST.2010.5652450;10.1109/TVCG.2007.70535;10.1109/INFVIS.1998.729559;10.1109/INFVIS.2000.885092;10.1109/INFVIS.2004.3;10.1109/TVCG.2009.153;10.1109/INFVIS.1997.636794	Quality Metrics, High-Dimensional Data Visualization	
InfoVis	2011	Sequence Surveyor: Leveraging Overview for Scalable Genomic Alignment Visualization	10.1109/TVCG.2011.232	http://dx.doi.org/10.1109/TVCG.2011.232	2392	2401	J	In this paper, we introduce overview visualization tools for large-scale multiple genome alignment data. Genome alignment visualization and, more generally, sequence alignment visualization are an important tool for understanding genomic sequence data. As sequencing techniques improve and more data become available, greater demand is being placed on visualization tools to scale to the size of these new datasets. When viewing such large data, we necessarily cannot convey details, rather we specifically design overview tools to help elucidate large-scale patterns. Perceptual science, signal processing theory, and generality provide a framework for the design of such visualizations that can scale well beyond current approaches. We present Sequence Surveyor, a prototype that embodies these ideas for scalable multiple whole-genome alignment overview visualization. Sequence Surveyor visualizes sequences in parallel, displaying data using variable color, position, and aggregation encodings. We demonstrate how perceptual science can inform the design of visualization techniques that remain visually manageable at scale and how signal processing concepts can inform aggregation schemes that highlight global trends, outliers, and overall data distributions as the problem scales. These techniques allow us to visualize alignments with over 100 whole bacterial-sized genomes.	Danielle Albers Szafir;Colin N. Dewey;Michael Gleicher	Univ. of Wisconsin-Madison, Madison, WI, USA|c|;;	10.1109/TVCG.2007.70623;10.1109/INFVIS.2002.1173156;10.1109/TVCG.2009.128;10.1109/TVCG.2009.167	Bioinformatics Visualization, Perception Theory, Scalability Issues, Visual Design	
InfoVis	2011	Skeleton-Based Edge Bundling for Graph Visualization	10.1109/TVCG.2011.233	http://dx.doi.org/10.1109/TVCG.2011.233	2364	2373	J	In this paper, we present a novel approach for constructing bundled layouts of general graphs. As layout cues for bundles, we use medial axes, or skeletons, of edges which are similar in terms of position information. We combine edge clustering, distance fields, and 2D skeletonization to construct progressively bundled layouts for general graphs by iteratively attracting edges towards the centerlines of level sets of their distance fields. Apart from clustering, our entire pipeline is image-based with an efficient implementation in graphics hardware. Besides speed and implementation simplicity, our method allows explicit control of the emphasis on structure of the bundled layout, i.e. the creation of strongly branching (organic-like) or smooth bundles. We demonstrate our method on several large real-world graphs.	Ozan Ersoy;Christophe Hurter;Fernando Vieira Paulovich;Gabriel Cantareiro;Alexandru Telea	Univ. of Groningen, Groningen, Netherlands|c|;;;;	10.1109/TVCG.2008.135;10.1109/TVCG.2006.147;10.1109/TVCG.2007.70535;10.1109/TVCG.2006.120;10.1109/INFVIS.2005.1532150;10.1109/INFVIS.2003.1249030	Graph layouts, edge bundles, image-based information visualization	
InfoVis	2011	Stereoscopic Highlighting: 2D Graph Visualization on Stereo Displays	10.1109/TVCG.2011.234	http://dx.doi.org/10.1109/TVCG.2011.234	2325	2333	J	In this paper we present a new technique and prototype graph visualization system, stereoscopic highlighting, to help answer accessibility and adjacency queries when interacting with a node-link diagram. Our technique utilizes stereoscopic depth to highlight regions of interest in a 2D graph by projecting these parts onto a plane closer to the viewpoint of the user. This technique aims to isolate and magnify specific portions of the graph that need to be explored in detail without resorting to other highlighting techniques like color or motion, which can then be reserved to encode other data attributes. This mechanism of stereoscopic highlighting also enables focus+context views by juxtaposing a detailed image of a region of interest with the overall graph, which is visualized at a further depth with correspondingly less detail. In order to validate our technique, we ran a controlled experiment with 16 subjects comparing static visual highlighting to stereoscopic highlighting on 2D and 3D graph layouts for a range of tasks. Our results show that while for most tasks the difference in performance between stereoscopic highlighting alone and static visual highlighting is not statistically significant, users performed better when both highlighting methods were used concurrently. In more complicated tasks, 3D layout with static visual highlighting outperformed 2D layouts with a single highlighting method. However, it did not outperform the 2D layout utilizing both highlighting techniques simultaneously. Based on these results, we conclude that stereoscopic highlighting is a promising technique that can significantly enhance graph visualizations for certain use cases.	Basak Alper;Tobias Höllerer;JoAnn Kuchera-Morin;Angus Graeme Forbes	Media Arts & Technol. Program, Univ. of California, Santa Barbara, CA, USA|c|;;;	10.1109/INFVIS.1999.801869;10.1109/TVCG.2007.70521;10.1109/INFVIS.2002.1173160	Graph visualization, stereo displays, virtual reality	
InfoVis	2011	Synthetic Generation of High-Dimensional Datasets	10.1109/TVCG.2011.237	http://dx.doi.org/10.1109/TVCG.2011.237	2317	2324	J	Generation of synthetic datasets is a common practice in many research areas. Such data is often generated to meet specific needs or certain conditions that may not be easily found in the original, real data. The nature of the data varies according to the application area and includes text, graphs, social or weather data, among many others. The common process to create such synthetic datasets is to implement small scripts or programs, restricted to small problems or to a specific application. In this paper we propose a framework designed to generate high dimensional datasets. Users can interactively create and navigate through multi dimensional datasets using a suitable graphical user-interface. The data creation is driven by statistical distributions based on a few user-defined parameters. First, a grounding dataset is created according to given inputs, and then structures and trends are included in selected dimensions and orthogonal projection planes. Furthermore, our framework supports the creation of complex non-orthogonal trends and classified datasets. It can successfully be used to create synthetic datasets simulating important trends as multidimensional clusters, correlations and outliers.	Georgia Albuquerque;Thomas Löwe;Marcus A. Magnor	Comput. Graphics Lab., TU, Braunschweig, Germany|c|;;	10.1109/INFVIS.2005.1532142;10.1109/VISUAL.1994.346302;10.1109/VAST.2010.5652433;10.1109/VAST.2009.5332628;10.1109/INFVIS.2004.15;10.1109/TVCG.2008.153	Synthetic data generation, multivariate data, high-dimensional data, interaction	
InfoVis	2011	TextFlow: Towards Better Understanding of Evolving Topics in Text	10.1109/TVCG.2011.239	http://dx.doi.org/10.1109/TVCG.2011.239	2412	2421	J	Understanding how topics evolve in text data is an important and challenging task. Although much work has been devoted to topic analysis, the study of topic evolution has largely been limited to individual topics. In this paper, we introduce TextFlow, a seamless integration of visualization and topic mining techniques, for analyzing various evolution patterns that emerge from multiple topics. We first extend an existing analysis technique to extract three-level features: the topic evolution trend, the critical event, and the keyword correlation. Then a coherent visualization that consists of three new visual components is designed to convey complex relationships between them. Through interaction, the topic mining model and visualization can communicate with each other to help users refine the analysis result and gain insights into the data progressively. Finally, two case studies are conducted to demonstrate the effectiveness and usefulness of TextFlow in helping users understand the major topic evolution patterns in time-varying text data.	Weiwei Cui;Shixia Liu;Li Tan;Conglei Shi;Yangqiu Song;Zekai Gao;Huamin Qu;Xin Tong	Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;;;	10.1109/VAST.2010.5652931;10.1109/VAST.2009.5333443;10.1109/TVCG.2006.156;10.1109/TVCG.2009.171;10.1109/TVCG.2008.166;10.1109/TVCG.2010.129;10.1109/VAST.2008.4677364;10.1109/INFVIS.2005.1532122;10.1109/VAST.2009.5333437;10.1109/INFVIS.2005.1532152	Text visualization, Topic evolution, Hierarchical Dirichlet process, Critical event	
InfoVis	2011	TreeNetViz: Revealing Patterns of Networks over Tree Structures	10.1109/TVCG.2011.247	http://dx.doi.org/10.1109/TVCG.2011.247	2449	2458	J	Network data often contain important attributes from various dimensions such as social affiliations and areas of expertise in a social network. If such attributes exhibit a tree structure, visualizing a compound graph consisting of tree and network structures becomes complicated. How to visually reveal patterns of a network over a tree has not been fully studied. In this paper, we propose a compound graph model, TreeNet, to support visualization and analysis of a network at multiple levels of aggregation over a tree. We also present a visualization design, TreeNetViz, to offer the multiscale and cross-scale exploration and interaction of a TreeNet graph. TreeNetViz uses a Radial, Space-Filling (RSF) visualization to represent the tree structure, a circle layout with novel optimization to show aggregated networks derived from TreeNet, and an edge bundling technique to reduce visual complexity. Our circular layout algorithm reduces both total edge-crossings and edge length and also considers hierarchical structure constraints and edge weight in a TreeNet graph. These experiments illustrate that the algorithm can reduce visual cluttering in TreeNet graphs. Our case study also shows that TreeNetViz has the potential to support the analysis of a compound graph by revealing multiscale and cross-scale network patterns.	Liang Gou;Xiaolong Zhang	Coll. of Inf. Sci. & Technol., Pennsylvania State Univ., University Park, PA, USA|c|;	10.1109/INFVIS.2004.1;10.1109/INFVIS.2003.1249011;10.1109/INFVIS.2003.1249030;10.1109/INFVIS.2002.1173151;10.1109/TVCG.2009.167;10.1109/TVCG.2006.192;10.1109/TVCG.2008.135;10.1109/TVCG.2006.120;10.1109/INFVIS.2000.885091;10.1109/TVCG.2006.166;10.1109/TVCG.2007.70521;10.1109/TVCG.2006.147	Compound graph, network and tree, TreeNetViz, visualization, multiscale and cross-scale	
InfoVis	2011	VisBricks: Multiform Visualization of Large, Inhomogeneous Data	10.1109/TVCG.2011.250	http://dx.doi.org/10.1109/TVCG.2011.250	2291	2300	J	Large volumes of real-world data often exhibit inhomogeneities: vertically in the form of correlated or independent dimensions and horizontally in the form of clustered or scattered data items. In essence, these inhomogeneities form the patterns in the data that researchers are trying to find and understand. Sophisticated statistical methods are available to reveal these patterns, however, the visualization of their outcomes is mostly still performed in a one-view-fits-all manner, In contrast, our novel visualization approach, VisBricks, acknowledges the inhomogeneity of the data and the need for different visualizations that suit the individual characteristics of the different data subsets. The overall visualization of the entire data set is patched together from smaller visualizations, there is one VisBrick for each cluster in each group of interdependent dimensions. Whereas the total impression of all VisBricks together gives a comprehensive high-level overview of the different groups of data, each VisBrick independently shows the details of the group of data it represents, State-of-the-art brushing and visual linking between all VisBricks furthermore allows the comparison of the groupings and the distribution of data items among them. In this paper, we introduce the VisBricks visualization concept, discuss its design rationale and implementation, and demonstrate its usefulness by applying it to a use case from the field of biomedicine.	Alexander Lex;Hans-Jörg Schulz;Marc Streit;Christian Partl;Dieter Schmalstieg	Graz Univ. of Technol., Graz, Austria|c|;;;;	10.1109/INFVIS.2005.1532129;10.1109/TVCG.2010.138;10.1109/TVCG.2006.120;10.1109/TVCG.2007.70582;10.1109/INFVIS.2003.1249006;10.1109/TVCG.2006.147;10.1109/TVCG.2009.167;10.1109/TVCG.2010.216;10.1109/TVCG.2006.166	Inhomogeneous data, multiple coordinated views, multiform visualization	
InfoVis	2011	Visual Thinking In Action: Visualizations As Used On Whiteboards	10.1109/TVCG.2011.251	http://dx.doi.org/10.1109/TVCG.2011.251	2508	2517	J	While it is still most common for information visualization researchers to develop new visualizations from a data-or taskdriven perspective, there is growing interest in understanding the types of visualizations people create by themselves for personal use. As part of this recent direction, we have studied a large collection of whiteboards in a research institution, where people make active use of combinations of words, diagrams and various types of visuals to help them further their thought processes. Our goal is to arrive at a better understanding of the nature of visuals that are created spontaneously during brainstorming, thinking, communicating, and general problem solving on whiteboards. We use the qualitative approaches of open coding, interviewing, and affinity diagramming to explore the use of recognizable and novel visuals, and the interplay between visualization and diagrammatic elements with words, numbers and labels. We discuss the potential implications of our findings on information visualization design.	Jagoda Walny;M. Sheelagh T. Carpendale;Nathalie Henry Riche;Gina Venolia;Philip Fawcett	Univ. of Calgary, Calgary, AB, Canada|c|;;;;	10.1109/TVCG.2010.144;10.1109/TVCG.2010.179;10.1109/TVCG.2006.156;10.1109/TVCG.2007.70535;10.1109/TVCG.2008.155;10.1109/INFVIS.2004.10;10.1109/INFVIS.2002.1173148;10.1109/VISUAL.1991.175815;10.1109/TVCG.2010.164	Visualization, diagrams, whiteboards, observational study	
InfoVis	2011	Visualization of Parameter Space for Image Analysis	10.1109/TVCG.2011.253	http://dx.doi.org/10.1109/TVCG.2011.253	2402	2411	J	Image analysis algorithms are often highly parameterized and much human input is needed to optimize parameter settings. This incurs a time cost of up to several days. We analyze and characterize the conventional parameter optimization process for image analysis and formulate user requirements. With this as input, we propose a change in paradigm by optimizing parameters based on parameter sampling and interactive visual exploration. To save time and reduce memory load, users are only involved in the first step - initialization of sampling - and the last step - visual analysis of output. This helps users to more thoroughly explore the parameter space and produce higher quality results. We describe a custom sampling plug-in we developed for CellProfiler - a popular biomedical image analysis framework. Our main focus is the development of an interactive visualization technique that enables users to analyze the relationships between sampled input parameters and corresponding output. We implemented this in a prototype called Paramorama. It provides users with a visual overview of parameters and their sampled values. User-defined areas of interest are presented in a structured way that includes image-based output and a novel layout algorithm. To find optimal parameter settings, users can tag high- and low-quality results to refine their search. We include two case studies to illustrate the utility of this approach.	A. Johannes Pretorius;Mark-Anthony Bray;Anne E. Carpenter;Roy A. Ruddle	Sch. of Comput., Univ. of Leeds, Leeds, UK|c|;;;	10.1109/INFVIS.2004.70;10.1109/VISUAL.2005.1532788;10.1109/VISUAL.1991.175815;10.1109/VISUAL.1999.809871;10.1109/VISUAL.2000.885678;10.1109/INFVIS.2001.963290	Information visualization, visual analytics, parameter space, image analysis, sampling	
InfoVis	2011	Visualization Rhetoric: Framing Effects in Narrative Visualization	10.1109/TVCG.2011.255	http://dx.doi.org/10.1109/TVCG.2011.255	2231	2240	J	Narrative visualizations combine conventions of communicative and exploratory information visualization to convey an intended story. We demonstrate visualization rhetoric as an analytical framework for understanding how design techniques that prioritize particular interpretations in visualizations that "tell a story" can significantly affect end-user interpretation. We draw a parallel between narrative visualization interpretation and evidence from framing studies in political messaging, decision-making, and literary studies. Devices for understanding the rhetorical nature of narrative information visualizations are presented, informed by the rigorous application of concepts from critical theory, semiotics, journalism, and political theory. We draw attention to how design tactics represent additions or omissions of information at various levels-the data, visual representation, textual annotations, and interactivity-and how visualizations denote and connote phenomena with reference to unstated viewing conventions and codes. Classes of rhetorical techniques identified via a systematic analysis of recent narrative visualizations are presented, and characterized according to their rhetorical contribution to the visualization. We describe how designers and researchers can benefit from the potentially positive aspects of visualization rhetoric in designing engaging, layered narrative visualizations and how our framework can shed light on how a visualization design prioritizes specific interpretations. We identify areas where future inquiry into visualization rhetoric can improve understanding of visualization interpretation.	Jessica Hullman;Nicholas Diakopoulos	;	10.1109/TVCG.2010.179;10.1109/TVCG.2007.70577;10.1109/TVCG.2010.177;10.1109/TVCG.2009.111	Rhetoric, narrative visualization, framing effects, semiotics, denotation, connotation 	
VAST	2011	Visual analytic roadblocks for novice investigators	10.1109/VAST.2011.6102435	http://dx.doi.org/10.1109/VAST.2011.6102435	3	11	C	We have observed increasing interest in visual analytics tools and their applications in investigative analysis. Despite the growing interest and substantial studies regarding the topic, understanding the major roadblocks of using such tools from novice users' perspectives is still limited. Therefore, we attempted to identify such â€œvisual analytic roadblocksâ€ for novice users in an investigative analysis scenario. To achieve this goal, we reviewed the existing models, theories, and frameworks that could explain the cognitive processes of human-visualization interaction in investigative analysis. Then, we conducted a qualitative experiment with six novice participants, using a slightly modified version of pair analytics, and analyzed the results through the open-coding method. As a result, we came up with four visual analytic roadblocks and explained these roadblocks using existing cognitive models and theories. We also provided design suggestions to overcome these roadblocks.	Bum Chul Kwon;Brian D. Fisher;Ji Soo Yi	Purdue Univ., West Lafayette, IN, USA|c|;;	10.1109/INFVIS.2004.10;10.1109/VAST.2007.4389006;10.1109/TVCG.2010.164;10.1109/VAST.2009.5333878;10.1109/TVCG.2010.179;10.1109/TVCG.2008.121;10.1109/INFVIS.2004.5;10.1109/TVCG.2007.70515;10.1109/TVCG.2010.177;10.1109/VAST.2006.261416;10.1109/TVCG.2008.171;10.1109/TVCG.2008.109;10.1109/TVCG.2007.70535;10.1109/VAST.2008.4677361;10.1109/TVCG.2007.70589;10.1109/TVCG.2007.70594	Visual analytics, investigative analysis, cognitive  model, framework, roadblock, qualitative experiment   	
VAST	2011	Perception-based visual quality measures	10.1109/VAST.2011.6102437	http://dx.doi.org/10.1109/VAST.2011.6102437	13	20	C	In recent years diverse quality measures to support the exploration of high-dimensional data sets have been proposed. Such measures can be very useful to rank and select information-bearing projections of very high dimensional data, when the visual exploration of all possible projections becomes unfeasible. But even though a ranking of the low dimensional projections may support the user in the visual exploration task, different measures deliver different distances between the views that do not necessarily match the expectations of human perception. As an alternative solution, we propose a perception-based approach that, similar to the existing measures, can be used to select information bearing projections of the data. Specifically, we construct a perceptual embedding for the different projections based on the data from a psychophysics study and multi-dimensional scaling. This embedding together with a ranking function is then used to estimate the value of the projections for a specific user task in a perceptual sense.	Georgia Albuquerque;Martin Eisemann;Marcus A. Magnor	Tech. Univ. Braunschweig, Braunschweig, Germany|c|;;	10.1109/INFVIS.2005.1532142;10.1109/VAST.2010.5652433;10.1109/VAST.2006.261423;10.1109/VAST.2009.5332628;10.1109/TVCG.2010.184;10.1109/TVCG.2009.153		
VAST	2011	Characterizing the intelligence analysis process: Informing visual analytics design through a longitudinal field study	10.1109/VAST.2011.6102438	http://dx.doi.org/10.1109/VAST.2011.6102438	21	30	C	While intelligence analysis has been a primary target domain for visual analytics system development, relatively little user and task analysis has been conducted within this area. Our research community's understanding of the work processes and practices of intelligence analysts is not deep enough to adequately address their needs. Without a better understanding of the analysts and their problems, we cannot build visual analytics systems that integrate well with their work processes and truly provide benefit to them. In order to close this knowledge gap, we conducted a longitudinal, observational field study of intelligence analysts in training within the intelligence program at Mercyhurst College. We observed three teams of analysts, each working on an intelligence problem for a ten-week period. Based upon study findings, we describe and characterize processes and methods of intelligence analysis that we observed, make clarifications regarding the processes and practices, and suggest design implications for visual analytics systems for intelligence analysis.	Youn ah Kang;John T. Stasko	Georgia Inst. of Technol., Atlanta, GA, USA|c|;	10.1109/VAST.2008.4677362;10.1109/VISUAL.1992.235203;10.1109/VAST.2008.4677358;10.1109/TVCG.2009.111;10.1109/VAST.2007.4389006	 Intelligence analysis, qualitatvie user study 	
VAST	2011	Interactive visual comparison of multiple trees	10.1109/VAST.2011.6102439	http://dx.doi.org/10.1109/VAST.2011.6102439	31	40	C	Traditionally, the visual analysis of hierarchies, respectively, trees, is conducted by focusing on one given hierarchy. However, in many research areas multiple, differing hierarchies need to be analyzed simultaneously in a comparative way - in particular to highlight differences between them, which sometimes can be subtle. A prominent example is the analysis of so-called phylogenetic trees in biology, reflecting hierarchical evolutionary relationships among a set of organisms. Typically, the analysis considers multiple phylogenetic trees, either to account for statistical significance or for differences in derivation of such evolutionary hierarchies; for example, based on different input data, such as the 16S ribosomal RNA and protein sequences of highly conserved enzymes. The simultaneous analysis of a collection of such trees leads to more insight into the evolutionary process. We introduce a novel visual analytics approach for the comparison of multiple hierarchies focusing on both global and local structures. A new tree comparison score has been elaborated for the identification of interesting patterns. We developed a set of linked hierarchy views showing the results of automatic tree comparison on various levels of details. This combined approach offers detailed assessment of local and global tree similarities. The approach was developed in close cooperation with experts from the evolutionary biology domain. We apply it to a phylogenetic data set on bacterial ancestry, demonstrating its application benefit.	Sebastian Bremm;Tatiana von Landesberger;Martin Hess;Tobias Schreck;Philipp Weil;Kay Hamacher	Interactive-Graphics Syst., Tech. Univ. Darmstadt, Darmstadt, Germany|c|;;;;;	10.1109/TVCG.2008.114;10.1109/TVCG.2009.130;10.1109/VAST.2009.5333893;10.1109/TVCG.2007.70529		
VAST	2011	Network-based visual analysis of tabular data	10.1109/VAST.2011.6102440	http://dx.doi.org/10.1109/VAST.2011.6102440	41	50	C	Tabular data are pervasive. Although tables often describe multivariate data without explicit network semantics, it may be advantageous to explore the data modeled as a graph or network for analysis. Even when a given table design conveys some static network semantics, analysts may want to look at multiple networks from different perspectives, at different levels of abstraction, and with different edge semantics. We present a system called Ploceus that offers a general approach for performing multi-dimensional and multi-level network-based visual analysis on multivariate tabular data. Powered by an underlying relational algebraic framework, Ploceus supports flexible construction and transformation of networks through a direct manipulation interface, and integrates dynamic network manipulation with visual exploration for a seamless analytic experience.	Zhicheng Liu;Shamkant B. Navathe;John T. Stasko	Georgia Inst. of Technol., Atlanta, GA, USA|c|;;	10.1109/TVCG.2006.122;10.1109/TVCG.2010.177;10.1109/TVCG.2007.70582;10.1109/TVCG.2006.166;10.1109/VAST.2010.5652520;10.1109/INFVIS.2000.885086;10.1109/VAST.2007.4389006		
VAST	2011	Orion: A system for modeling, transformation and visualization of multidimensional heterogeneous networks	10.1109/VAST.2011.6102441	http://dx.doi.org/10.1109/VAST.2011.6102441	51	60	C	The study of complex activities such as scientific production and software development often require modeling connections among heterogeneous entities including people, institutions and artifacts. Despite numerous advances in algorithms and visualization techniques for understanding such social networks, the process of constructing network models and performing exploratory analysis remains difficult and time-consuming. In this paper we present Orion, a system for interactive modeling, transformation and visualization of network data. Orion's interface enables the rapid manipulation of large graphs-including the specification of complex linking relationships-using simple drag-and-drop operations with desired node types. Orion maps these user interactions to statements in a declarative workflow language that incorporates both relational operators (e.g., selection, aggregation and joins) and network analytics (e.g., centrality measures). We demonstrate how these features enable analysts to flexibly construct and compare networks in domains such as online health communities, academic collaboration and distributed software development.	Jeffrey Heer;Adam Perer	Stanford Univ., Stanford, CA, USA|c|;	10.1109/TVCG.2010.144;10.1109/TVCG.2009.174;10.1109/TVCG.2006.178;10.1109/TVCG.2007.70582;10.1109/TVCG.2006.166;10.1109/VAST.2006.261426;10.1109/INFVIS.2000.885086	Social network analysis, data management, data transformation, graphs, visualization, end-user programming 	
VAST	2011	G-PARE: A visual analytic tool for comparative analysis of uncertain graphs	10.1109/VAST.2011.6102442	http://dx.doi.org/10.1109/VAST.2011.6102442	61	70	C	There are a growing number of machine learning algorithms which operate on graphs. Example applications for these algorithms include predicting which customers will recommend products to their friends in a viral marketing campaign using a customer network, predicting the topics of publications in a citation network, or predicting the political affiliations of people in a social network. It is important for an analyst to have tools to help compare the output of these machine learning algorithms. In this work, we present G-PARE, a visual analytic tool for comparing two uncertain graphs, where each uncertain graph is produced by a machine learning algorithm which outputs probabilities over node labels. G-PARE provides several different views which allow users to obtain a global overview of the algorithms output, as well as focused views that show subsets of nodes of interest. By providing an adaptive exploration environment, G-PARE guides the users to places in the graph where two algorithms predictions agree and places where they disagree. This enables the user to follow cascades of misclassifications by comparing the algorithms outcome with the ground truth. After describing the features of G-PARE, we illustrate its utility through several use cases based on networks from different domains.	Hossam Sharara;Awalin Sopan;Galileo Namata;Lise Getoor;Lisa Singh	Comput. Sci. Dept., Univ. of Maryland, College Park, MD, USA|c|;;;;	10.1109/TVCG.2006.122;10.1109/VAST.2010.5652398;10.1109/VAST.2010.5652910;10.1109/VAST.2006.261429;10.1109/VAST.2010.5652443;10.1109/TVCG.2007.70582	Uncertain Graphs, Comparative Analysis, Model Comparison, Visualizing Uncertainty	
VAST	2011	Visual social network analytics for relationship discovery in the enterprise	10.1109/VAST.2011.6102443	http://dx.doi.org/10.1109/VAST.2011.6102443	71	79	C	As people continue to author and share increasing amounts of information in social media, the opportunity to leverage such information for relationship discovery tasks increases. In this paper, we describe a set of systems that mine, aggregate, and infer a social graph from social media inside an enterprise, resulting in over 73 million relationships between 450,000 people. We then describe SaNDVis, a novel visual analytics tool that supports people-centric tasks like expertise location, team building, and team coordination in the enterprise. We also provide details of a 12-month-long, large-scale deployment to almost 1,800 users from which we extract dominant use cases from log and interview data. By integrating social position, evidence, and facets into SaNDVis, we demonstrate how users can use a visual analytics tool to reflect on existing relationships as well as build new relationships in an enterprise setting.	Adam Perer;Ido Guy;Erel Uziel;Inbal Ronen;Michal Jacovi	IBM Res., Yorktown Heights, NY, USA|c|;;;;	10.1109/TVCG.2006.122;10.1109/TVCG.2007.70582;10.1109/VAST.2006.261426;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2006.166	 information discovery, social networks, social data mining, social visualization	
VAST	2011	How locus of control influences compatibility with visualization style	10.1109/VAST.2011.6102445	http://dx.doi.org/10.1109/VAST.2011.6102445	81	90	C	Existing research suggests that individual personality differences are correlated with a user's speed and accuracy in solving problems with different types of complex visualization systems. In this paper, we extend this research by isolating factors in personality traits as well as in the visualizations that could have contributed to the observed correlation. We focus on a personality trait known as â€œlocus of control,â€ which represents a person's tendency to see themselves as controlled by or in control of external events. To isolate variables of the visualization design, we control extraneous factors such as color, interaction, and labeling, and specifically focus on the overall layout style of the visualizations. We conduct a user study with four visualizations that gradually shift from an indentation metaphor to a containment metaphor and compare the participants' speed, accuracy, and preference with their locus of control. Our findings demonstrate that there is indeed a correlation between the two: participants with an internal locus of control perform more poorly with visualizations that employ a containment metaphor, while those with an external locus of control perform well with such visualizations. We discuss a possible explanation for this relationship based in cognitive psychology and propose that these results can be used to better understand how people use visualizations and how to adapt visual analytics design to an individual user's needs.	Caroline Ziemkiewicz;R. Jordan Crouser;Ashley Rye Yauilla;Sara L. Su;William Ribarsky;Remco Chang	Brown Univ., Providence, RI, USA|c|;;;;;	10.1109/VAST.2010.5653587;10.1109/TVCG.2008.171;10.1109/TVCG.2008.121		
VAST	2011	Obvious: A meta-toolkit to encapsulate information visualization toolkits - One toolkit to bind them all	10.1109/VAST.2011.6102446	http://dx.doi.org/10.1109/VAST.2011.6102446	91	100	C	This article describes â€œObviousâ€: a meta-toolkit that abstracts and encapsulates information visualization toolkits implemented in the Java language. It intends to unify their use and postpone the choice of which concrete toolkit(s) to use later-on in the development of visual analytics applications. We also report on the lessons we have learned when wrapping popular toolkits with Obvious, namely Prefuse, the InfoVis Toolkit, partly Improvise, JUNG and other data management libraries. We show several examples on the uses of Obvious, how the different toolkits can be combined, for instance sharing their data models. We also show how Weka and Rapid-Miner, two popular machine-learning toolkits, have been wrapped with Obvious and can be used directly with all the other wrapped toolkits. We expect Obvious to start a co-evolution process: Obvious is meant to evolve when more components of Information Visualization systems will become consensual. It is also designed to help information visualization systems adhere to the best practices to provide a higher level of interoperability and leverage the domain of visual analytics.	Jean-Daniel Fekete;Pierre-Luc Hemery;Thomas Baudel;Jo Wood	INRIA, Sophia Antipolis, France|c|;;;	10.1109/INFVIS.2004.12;10.1109/TVCG.2009.152;10.1109/TVCG.2009.174;10.1109/TVCG.2006.178;10.1109/TVCG.2010.159;10.1109/INFVIS.2004.64;10.1109/INFVIS.1998.729560;10.1109/INFVIS.2002.1173148		
VAST	2011	Supporting effective common ground construction in Asynchronous Collaborative Visual Analytics	10.1109/VAST.2011.6102447	http://dx.doi.org/10.1109/VAST.2011.6102447	101	110	C	Asynchronous Collaborative Visual Analytics (ACVA) leverages group sensemaking by releasing the constraints on when, where, and who works collaboratively. A significant task to be addressed before ACVA can reach its full potential is effective common ground construction, namely the process in which users evaluate insights from individual work to develop a shared understanding of insights and collectively pool them. This is challenging due to the lack of instant communication and scale of collaboration in ACVA. We propose a novel visual analytics approach that automatically gathers, organizes, and summarizes insights to form common ground with reduced human effort. The rich set of visualization and interaction techniques provided in our approach allows users to effectively and flexibly control the common ground construction and review, explore, and compare insights in detail. A working prototype of the approach has been implemented. We have conducted a case study and a user study to demonstrate its effectiveness.	Yang Chen;Jamal Alsakran;Scott Barlowe;Jing Yang 0001;Ye Zhao	Univ. of North Carolina at Charlotte, Charlotte, NC, USA|c|;;;;	10.1109/TVCG.2007.70541;10.1109/VAST.2009.5333023;10.1109/TVCG.2007.70577;10.1109/VAST.2010.5652879;10.1109/VAST.2008.4677358;10.1109/VAST.2010.5652932;10.1109/VAST.2007.4389011;10.1109/VAST.2008.4677365;10.1109/TVCG.2006.166;10.1109/VAST.2010.5652885	Visual analytics, asynchronous collaboration, insight, multidimensional visualization	
VAST	2011	Guiding feature subset selection with an interactive visualization	10.1109/VAST.2011.6102448	http://dx.doi.org/10.1109/VAST.2011.6102448	111	120	C	We propose a method for the semi-automated refinement of the results of feature subset selection algorithms. Feature subset selection is a preliminary step in data analysis which identifies the most useful subset of features (columns) in a data table. So-called filter techniques use statistical ranking measures for the correlation of features. Usually a measure is applied to all entities (rows) of a data table. However, the differing contributions of subsets of data entities are masked by statistical aggregation. Feature and entity subset selection are, thus, highly interdependent. Due to the difficulty in visualizing a high-dimensional data table, most feature subset selection algorithms are applied as a black box at the outset of an analysis. Our visualization technique, SmartStripes, allows users to step into the feature subset selection process. It enables the investigation of dependencies and interdependencies between different feature and entity subsets. A user may even choose to control the iterations manually, taking into account the ranking measures, the contributions of different entity subsets, as well as the semantics of the features.	Thorsten May;Andreas Bannach;James Davey;Tobias Ruppert;Jörn Kohlhammer	Fraunhofer Inst. for Comput. Graphics Res., Darmstadt, Germany|c|;;;;	10.1109/VAST.2010.5652392;10.1109/INFVIS.2003.1249006;10.1109/TVCG.2009.153;10.1109/TVCG.2008.153		
VAST	2011	Observation-level interaction with statistical models for visual analytics	10.1109/VAST.2011.6102449	http://dx.doi.org/10.1109/VAST.2011.6102449	121	130	C	In visual analytics, sensemaking is facilitated through interactive visual exploration of data. Throughout this dynamic process, users combine their domain knowledge with the dataset to create insight. Therefore, visual analytic tools exist that aid sensemaking by providing various interaction techniques that focus on allowing users to change the visual representation through adjusting parameters of the underlying statistical model. However, we postulate that the process of sensemaking is not focused on a series of parameter adjustments, but instead, a series of perceived connections and patterns within the data. Thus, how can models for visual analytic tools be designed, so that users can express their reasoning on observations (the data), instead of directly on the model or tunable parameters? Observation level (and thus â€œobservationâ€) in this paper refers to the data points within a visualization. In this paper, we explore two possible observation-level interactions, namely exploratory and expressive, within the context of three statistical methods, Probabilistic Principal Component Analysis (PPCA), Multidimensional Scaling (MDS), and Generative Topographic Mapping (GTM). We discuss the importance of these two types of observation level interactions, in terms of how they occur within the sensemaking process. Further, we present use cases for GTM, MDS, and PPCA, illustrating how observation level interaction can be incorporated into visual analytic tools.	Alex Endert;Chao Han;Dipayan Maiti;Leanna House;Scotland Leman;Chris North	Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA|c|;;;;;		observation-level interaction, visual analytics, statistical models	
VAST	2011	Pointwise local pattern exploration for sensitivity analysis	10.1109/VAST.2011.6102450	http://dx.doi.org/10.1109/VAST.2011.6102450	131	140	C	Sensitivity analysis is a powerful method for discovering the significant factors that contribute to targets and understanding the interaction between variables in multivariate datasets. A number of sensitivity analysis methods fall into the class of local analysis, in which the sensitivity is defined as the partial derivatives of a target variable with respect to a group of independent variables. Incorporating sensitivity analysis in visual analytic tools is essential for multivariate phenomena analysis. However, most current multivariate visualization techniques do not allow users to explore local patterns individually for understanding the sensitivity from a pointwise view. In this paper, we present a novel pointwise local pattern exploration system for visual sensitivity analysis. Using this system, analysts are able to explore local patterns and the sensitivity at individual data points, which reveals the relationships between a focal point and its neighbors. During exploration, users are able to interactively change the derivative coefficients to perform sensitivity analysis based on different requirements as well as their domain knowledge. Each local pattern is assigned an outlier factor, so that users can quickly identify anomalous local patterns that do not conform with the global pattern. Users can also compare the local pattern with the global pattern both visually and statistically. Finally, the local pattern is integrated into the original attribute space using color mapping and jittering, which reveals the distribution of the partial derivatives. Case studies with real datasets are used to investigate the effectiveness of the visualizations and interactions.	Zhenyu Guo;Matthew O. Ward;Elke A. Rundensteiner;Carolina Ruiz	Comput. Sci. Dept., Worcester Polytech. Inst., Worcester, MA, USA|c|;;;	10.1109/VISUAL.2005.1532821;10.1109/VAST.2008.4677368;10.1109/VAST.2010.5652460;10.1109/VAST.2009.5332611;10.1109/INFVIS.2004.71;10.1109/VAST.2009.5333431	Knowledge discovery, sensitivity analysis, local pattern visualizations	
VAST	2011	Interactive decision making using dissimilarity to visually represented prototypes	10.1109/VAST.2011.6102451	http://dx.doi.org/10.1109/VAST.2011.6102451	141	149	C	To make informed decisions, an expert has to reason with multi-dimensional, heterogeneous data and analysis results of these. Items in such datasets are typically represented by features. However, as argued in cognitive science, features do not yield an optimal space for human reasoning. In fact, humans tend to organize complex information in terms of prototypes or known cases rather than in absolute terms. When confronted with unknown data items, humans assess them in terms of similarity to these prototypical elements. Interestingly, an analogues similarity-to-prototype approach, where prototypes are taken from the data, has been successfully applied in machine learning. Combining such a machine learning approach with human prototypical reasoning in a Visual Analytics context requires to integrate similarity-based classification with interactive visualizations. To that end, the data prototypes should be visually represented to trigger direct associations to cases familiar to the domain experts. In this paper, we propose a set of highly interactive visualizations to explore data and classification results in terms of dissimilarities to visually represented prototypes. We argue that this approach not only supports human reasoning processes, but is also suitable to enhance understanding of heterogeneous data. The proposed framework is applied to a risk assessment case study in Forensic Psychiatry.	Malgorzata Migut;Jan C. van Gemert;Marcel Worring	Intell. Syst. Lab. Amsterdam, Univ. of Amsterdam, Amsterdam, Netherlands|c|;;	10.1109/TVCG.2007.70515;10.1109/TVCG.2009.174;10.1109/TVCG.2009.199;10.1109/VAST.2010.5652398;10.1109/VISUAL.1994.346302;10.1109/INFVIS.1998.729559;10.1109/INFVIS.2000.885086	dissimilarity based classication, dissimilarity based visualization, prototypes, interactive visualization, visual analytics	
VAST	2011	BaobabView: Interactive construction and analysis of decision trees	10.1109/VAST.2011.6102453	http://dx.doi.org/10.1109/VAST.2011.6102453	151	160	C	We present a system for the interactive construction and analysis of decision trees that enables domain experts to bring in domain specific knowledge. We identify different user tasks and corresponding requirements, and develop a system incorporating a tight integration of visualization, interaction and algorithmic support. Domain experts are supported in growing, pruning, optimizing and analysing decision trees. Furthermore, we present a scalable decision tree visualization optimized for exploration. We show the effectiveness of our approach by applying the methods to two use cases. The first case illustrates the advantages of interactive construction, the second case demonstrates the effectiveness of analysis of decision trees and exploration of the structure of the data.	Stef van den Elzen;Jarke J. van Wijk	Eindhoven Univ. of Technol., Eindhoven, Netherlands|c|;	10.1109/TVCG.2008.166;10.1109/INFVIS.2001.963292;10.1109/INFVIS.2001.963290		
VAST	2011	From movement tracks through events to places: Extracting and characterizing significant places from mobility data	10.1109/VAST.2011.6102454	http://dx.doi.org/10.1109/VAST.2011.6102454	161	170	C	We propose a visual analytics procedure for analyzing movement data, i.e., recorded tracks of moving objects. It is oriented to a class of problems where it is required to determine significant places on the basis of certain types of events occurring repeatedly in movement data. The procedure consists of four major steps: (1) event extraction from trajectories; (2) event clustering and extraction of relevant places; (3) spatio-temporal aggregation of events or trajectories; (4) analysis of the aggregated data. All steps are scalable with respect to the amount of the data under analysis. We demonstrate the use of the procedure by example of two real-world problems requiring analysis at different spatial scales.	Gennady L. Andrienko;Natalia V. Andrienko;Christophe Hurter;Salvatore Rinzivillo;Stefan Wrobel	Fraunhofer Inst., Univ. of Bonn, Bonn, Germany|c|;;;;	10.1109/VAST.2009.5332593;10.1109/TVCG.2009.145	movement, trajectories, spatio-temporal data, spatial  events, spatial clustering, spatio-temporal clustering 	
VAST	2011	Visual analysis of route diversity	10.1109/VAST.2011.6102455	http://dx.doi.org/10.1109/VAST.2011.6102455	171	180	C	Route suggestion is an important feature of GPS navigation systems. Recently, Microsoft T-drive has been enabled to suggest routes chosen by experienced taxi drivers for given source/destination pairs in given time periods, which often take less time than the routes calculated according to distance. However, in real environments, taxi drivers may use different routes to reach the same destination, which we call route diversity. In this paper we first propose a trajectory visualization method that examines the regions where the diversity exists and then develop several novel visualization techniques to display the high dimensional attributes and statistics associated with different routes to help users analyze diversity patterns. Our techniques have been applied to the real trajectory data of thousands of taxis and some interesting findings about route diversity have been obtained. We further demonstrate that our system can be used not only to suggest better routes for drivers but also to analyze traffic bottlenecks for transportation management.	He Liu;Yuan Gao;Lu Lu;Siyuan Liu;Huamin Qu;Lionel M. Ni	Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;	10.1109/INFVIS.2004.27;10.1109/VAST.2008.4677356;10.1109/TVCG.2008.149;10.1109/TVCG.2007.70570;10.1109/TVCG.2007.70574;10.1109/TVCG.2006.202;10.1109/VAST.2009.5332593;10.1109/TVCG.2007.70561;10.1109/TVCG.2009.145;10.1109/TVCG.2010.180		
VAST	2011	SensePlace2: GeoTwitter analytics support for situational awareness	10.1109/VAST.2011.6102456	http://dx.doi.org/10.1109/VAST.2011.6102456	181	190	C	Geographically-grounded situational awareness (SA) is critical to crisis management and is essential in many other decision making domains that range from infectious disease monitoring, through regional planning, to political campaigning. Social media are becoming an important information input to support situational assessment (to produce awareness) in all domains. Here, we present a geovisual analytics approach to supporting SA for crisis events using one source of social media, Twitter. Specifically, we focus on leveraging explicit and implicit geographic information for tweets, on developing place-time-theme indexing schemes that support overview+detail methods and that scale analytical capabilities to relatively large tweet volumes, and on providing visual interface methods to enable understanding of place, time, and theme components of evolving situations. Our approach is user-centered, using scenario-based design methods that include formal scenarios to guide design and validate implementation as well as a systematic claims analysis to justify design choices and provide a framework for future testing. The work is informed by a structured survey of practitioners and the end product of Phase-I development is demonstrated / validated through implementation in SensePlace2, a map-based, web application initially focused on tweets but extensible to other media.	Alan M. MacEachren;Anuj R. Jaiswal;Anthony C. Robinson;Scott Pezanowski;Alexander Savelyev;Prasenjit Mitra;Xiao Zhang;Justine I. Blanford	GeoVISTA Center, Pennsylvania State Univ., University Park, PA, USA|c|;;;;;;;	10.1109/VAST.2010.5652478;10.1109/VAST.2007.4388994;10.1109/TVCG.2010.129;10.1109/INFVIS.2005.1532134;10.1109/VAST.2010.5652922	social media analytics, scenario-based design, geovisualization, situational awareness, text analytics, crisis management, spatio-temporal analysis 	
VAST	2011	Visual analytics decision support environment for epidemic modeling and response evaluation	10.1109/VAST.2011.6102457	http://dx.doi.org/10.1109/VAST.2011.6102457	191	200	C	In modeling infectious diseases, scientists are studying the mechanisms by which diseases spread, predicting the future course of the outbreak, and evaluating strategies applied to control an epidemic. While recent work has focused on accurately modeling disease spread, less work has been performed in developing interactive decision support tools for analyzing the future course of the outbreak and evaluating potential disease mitigation strategies. The absence of such tools makes it difficult for researchers, analysts and public health officials to evaluate response measures within outbreak scenarios. As such, our research focuses on the development of an interactive decision support environment in which users can explore epidemic models and their impact. This environment provides a spatiotemporal view where users can interactively utilize mitigative response measures and observe the impact of their decision over time. Our system also provides users with a linked decision history visualization and navigation tool that support the simultaneous comparison of mortality and infection rates corresponding to different response measures at different points in time.	Shehzad Afzal;Ross Maciejewski;David S. Ebert	Visualization & Analytics Center, Purdue Univ., West Lafayette, IN, USA|c|;;	10.1109/TVCG.2008.137;10.1109/TVCG.2007.70594;10.1109/VISUAL.1993.398857;10.1109/VAST.2009.5333020;10.1109/TVCG.2010.223;10.1109/TVCG.2010.190;10.1109/TVCG.2010.206;10.1109/TVCG.2009.187;10.1109/TVCG.2010.171;10.1109/VAST.2006.261450;10.1109/INFVIS.2000.885086		
VAST	2011	SAVE: Sensor anomaly visualization engine	10.1109/VAST.2011.6102458	http://dx.doi.org/10.1109/VAST.2011.6102458	201	210	C	Diagnosing a large-scale sensor network is a crucial but challenging task. Particular challenges include the resource and bandwidth constraints on sensor nodes, the spatiotemporally dynamic network behaviors, and the lack of accurate models to understand such behaviors in a hostile environment. In this paper, we present the Sensor Anomaly Visualization Engine (SAVE), a system that fully leverages the power of both visualization and anomaly detection analytics to guide the user to quickly and accurately diagnose sensor network failures and faults. SAVE combines customized visualizations over separate sensor data facets as multiple coordinated views. Temporal expansion model, correlation graph and dynamic projection views are proposed to effectively interpret the topological, correlational and dimensional sensor data dynamics and their anomalies. Through a case study with real-world sensor network system and administrators, we demonstrate that SAVE is able to help better locate the system problem and further identify the root cause of major sensor network failure scenarios.	Lei Shi;Qi Liao;Yuan He;Rui Li;Aaron Striegel;Zhong Su	IBM Res., Beijing, China|c|;;;;;	10.1109/TVCG.2009.182;10.1109/VAST.2009.5333880;10.1109/INFVIS.2005.1532126;10.1109/INFVIS.2004.1;10.1109/VAST.2010.5652910		
VAST	2011	A visual navigation system for querying neural stem cell imaging data	10.1109/VAST.2011.6102459	http://dx.doi.org/10.1109/VAST.2011.6102459	211	220	C	Cellular biology deals with studying the behavior of cells. Current time-lapse imaging microscopes help us capture the progress of experiments at intervals that allow for understanding of the dynamic and kinematic behavior of the cells. On the other hand, these devices generate such massive amounts of data (250GB of data per experiment) that manual sieving of data to identify interesting patterns becomes virtually impossible. In this paper we propose an end-to-end system to analyze time-lapse images of the cultures of human neural stem cells (hNSC), that includes an image processing system to analyze the images to extract all the relevant geometric and statistical features within and between images, a database management system to manage and handle queries on the data, a visual analytic system to navigate through the data, and a visual query system to explore different relationships and correlations between the parameters. In each stage of the pipeline we make novel algorithmic and conceptual contributions, and the entire system design is motivated by many different yet unanswered exploratory questions pursued by our neurobiologist collaborators. With a few examples we show how such abstract biological queries can be analyzed and answered by our system.	Ishwar Kulkarni;Shanaz Y. Mistry;Brian Cummings;Meenakshisundaram Gopi	Dept. of Comput. Sci., Univ. of California, Irvine, CA, USA|c|;;;	10.1109/TVCG.2009.121;10.1109/VAST.2009.5333895	Neuroscience, stem cell segmentation, tracking, cell imaging, data management, visual analytics, navigation, exploration, query processing	
VAST	2011	A visual analytics process for maritime resource allocation and risk assessment	10.1109/VAST.2011.6102460	http://dx.doi.org/10.1109/VAST.2011.6102460	221	230	C	In this paper, we present our collaborative work with the U.S. Coast Guard's Ninth District and Atlantic Area Commands where we developed a visual analytics system to analyze historic response operations and assess the potential risks in the maritime environment associated with the hypothetical allocation of Coast Guard resources. The system includes linked views and interactive displays that enable the analysis of trends, patterns and anomalies among the U.S. Coast Guard search and rescue (SAR) operations and their associated sorties. Our system allows users to determine the potential change in risks associated with closing certain stations in terms of response time, potential lives and property lost and provides optimal direction as to the nearest available station. We provide maritime risk assessment tools that allow analysts to explore Coast Guard coverage for SAR operations and identify regions of high risk. The system also enables a thorough assessment of all SAR operations conducted by each Coast Guard station in the Great Lakes region. Our system demonstrates the effectiveness of visual analytics in analyzing risk within the maritime domain and is currently being used by analysts at the Coast Guard Atlantic Area.	Abish Malik;Ross Maciejewski;Ben Maule;David S. Ebert	Purdue Univ. Visualization & Analytics Center (PURVAC), IN, USA|c|;;;	10.1109/VISUAL.1993.398870;10.1109/VAST.2010.5652398;10.1109/VAST.2009.5333920;10.1109/VAST.2008.4677363;10.1109/INFVIS.1999.801851;10.1109/VAST.2007.4389006;10.1109/VAST.2009.5332611	Visual analytics, risk assessment, Coast Guard	
VAST	2011	ParallelTopics: A probabilistic approach to exploring document collections	10.1109/VAST.2011.6102461	http://dx.doi.org/10.1109/VAST.2011.6102461	231	240	C	Scalable and effective analysis of large text corpora remains a challenging problem as our ability to collect textual data continues to increase at an exponential rate. To help users make sense of large text corpora, we present a novel visual analytics system, Parallel-Topics, which integrates a state-of-the-art probabilistic topic model Latent Dirichlet Allocation (LDA) with interactive visualization. To describe a corpus of documents, ParallelTopics first extracts a set of semantically meaningful topics using LDA. Unlike most traditional clustering techniques in which a document is assigned to a specific cluster, the LDA model accounts for different topical aspects of each individual document. This permits effective full text analysis of larger documents that may contain multiple topics. To highlight this property of the model, ParallelTopics utilizes the parallel coordinate metaphor to present the probabilistic distribution of a document across topics. Such representation allows the users to discover single-topic vs. multi-topic documents and the relative importance of each topic to a document of interest. In addition, since most text corpora are inherently temporal, ParallelTopics also depicts the topic evolution over time. We have applied ParallelTopics to exploring and analyzing several text corpora, including the scientific proposals awarded by the National Science Foundation and the publications in the VAST community over the years. To demonstrate the efficacy of ParallelTopics, we conducted several expert evaluations, the results of which are reported in this paper.	Wenwen Dou;Xiaoyu Wang;Remco Chang;William Ribarsky	UNC Charlotte, Charlotte, NC, USA|c|;;;	10.1109/VAST.2010.5652931;10.1109/VAST.2009.5333428;10.1109/TVCG.2010.184;10.1109/VAST.2010.5652940;10.1109/TVCG.2009.140;10.1109/INFVIS.2000.885098		
VAST	2011	Analysis of large digital collections with interactive visualization	10.1109/VAST.2011.6102462	http://dx.doi.org/10.1109/VAST.2011.6102462	241	250	C	To make decisions about the long-term preservation and access of large digital collections, archivists gather information such as the collections' contents, their organizational structure, and their file format composition. To date, the process of analyzing a collection - from data gathering to exploratory analysis and final conclusions - has largely been conducted using pen and paper methods. To help archivists analyze large-scale digital collections for archival purposes, we developed an interactive visual analytics application. The application narrows down different kinds of information about the collection, and presents them as meaningful data views. Multiple views and analysis features can be linked or unlinked on demand to enable researchers to compare and contrast different analyses, and to identify trends. We describe and present two user scenarios to show how the application allowed archivists to learn about a collection with accuracy, facilitated decision-making, and helped them arrive at conclusions.	Weijia Xu;Maria Esteva;Suyog Dott Jain;Varun Jain	Univ. of Texas at Austin, Austin, TX, USA|c|;;;	10.1109/INFVIS.2000.885091;10.1109/TVCG.2008.172;10.1109/TVCG.2009.176;10.1109/VAST.2007.4389006;10.1109/INFVIS.2004.64;10.1109/VAST.2010.5652931;10.1109/INFVIS.1999.801860	Digital collections, archival analysis, visual anaytics, data curation	
VAST	2011	A two-stage framework for designing visual analytics system in organizational environments	10.1109/VAST.2011.6102463	http://dx.doi.org/10.1109/VAST.2011.6102463	251	260	C	A perennially interesting research topic in the field of visual analytics is how to effectively develop systems that support organizational users' decision-making and reasoning processes. The problem is, however, most domain analytical practices generally vary from organization to organization. This leads to diverse designs of visual analytics systems in incorporating domain analytical processes, making it difficult to generalize the success from one domain to another. Exacerbating this problem is the dearth of general models of analytical workflows available to enable such timely and effective designs. To alleviate these problems, we present a two-stage framework for informing the design of a visual analytics system. This design framework builds upon and extends current practices pertaining to analytical workflow and focuses, in particular, on incorporating both general domain analysis processes as well as individual's analytical activities. We illustrate both stages and their design components through examples, and hope this framework will be useful for designing future visual analytics systems. We validate the soundness of our framework with two visual analytics systems, namely Entity Workspace [8] and PatViz [37].	Xiaoyu Wang;Wenwen Dou;Thomas Butkiewicz;Eric A. Bier;William Ribarsky	UNC Charlotte, Charlotte, NC, USA|c|;;;;	10.1109/VAST.2008.4677362;10.1109/VAST.2009.5333020;10.1109/TVCG.2008.137;10.1109/VAST.2006.261416;10.1109/VAST.2007.4389009;10.1109/TVCG.2009.139;10.1109/VAST.2008.4677361;10.1109/TVCG.2009.111;10.1109/VISUAL.2005.1532781;10.1109/VAST.2008.4677352;10.1109/TVCG.2008.109;10.1109/TVCG.2007.70515;10.1109/VAST.2008.4677360;10.1109/VAST.2008.4677365;10.1109/VAST.2009.5333564	Design Theory, Visual Analytics, HCI	
VAST	2011	Using random projections to identify class-separating variables in high-dimensional spaces	10.1109/VAST.2011.6102465	http://dx.doi.org/10.1109/VAST.2011.6102465	263	264	M	Projection Pursuit has been an effective method for finding interesting low-dimensional (usually 2D) projections in multidimensional spaces. Unfortunately, projection pursuit is not scalable to high-dimensional spaces. We introduce a novel method for approximating the results of projection pursuit to find class-separating views by using random projections. We build an analytic visualization platform based on this algorithm that is scalable to extremely large problems. Then, we discuss its extension to the recognition of other noteworthy configurations in high-dimensional spaces.	Anushka Anand;Leland Wilkinson;Dang Tuan Nhon	Dept. of Comput. Sci., Univ. of Illinois at Chicago, Chicago, IL, USA|c|;;			
VAST	2011	Evaluation of large display interaction using smart phones	10.1109/VAST.2011.6102466	http://dx.doi.org/10.1109/VAST.2011.6102466	265	266	M	Visual analytics, â€œthe science of analytical reasoning facilitated by visual interactive interfacesâ€ [5], puts high demands on the applications visualization as well as interaction capabilities. Due to their size large high-resolution screens have become popular display devices, especially when used in collaborative data analysis scenarios. However, traditional interaction methods based on combinations of computer mice and keyboards often do not scale to the number of users or the size of the display. Modern smart phones featuring multi-modal input/output and considerable memory offer a way to address these issues. In the last couple of years they have become common everyday life gadgets. In this paper we conduct an extensive user study comparing the experience of test candidates when using traditional input devices and metaphors with the one when using new smart phone based techniques, like multi-modal drag and tilt. Candidates were asked to complete various interaction tasks relevant for most applications on a large, monitor-based, high-resolution tiled wall system. Our study evaluates both user performance and satisfaction, identifying strengths and weaknesses of the researched interaction methods in specific tasks. Results reveal good performance of users in certain tasks when using the new interaction techniques. Even first-time users were able to complete a task faster with the smart phone than with traditional devices.	Jens Bauer;Sebastian Thelen;Achim Ebert	Comput. Graphics & HCI Lab., Univ. of Kaiserslautern, Kaiserslautern, Germany|c|;;			
VAST	2011	Query-based coordinated multiple views with Feature Similarity Space for visual analysis of MRI repositories	10.1109/VAST.2011.6102467	http://dx.doi.org/10.1109/VAST.2011.6102467	267	268	M	It is a laborious process to quantify relationship patterns within a feature-rich archive. For example, understanding the degree of neuroanatomical similarity between the scanned subjects of a Magnetic Resonance Imaging (MRI) repository is a nontrivial task. In this work we present a Coordinated Multiple View (CMV) system for visually analyzing collections of feature-rich datasets. A query-based user interface operates on a feature-respective data scheme, and is geared towards domain experts that are non-specialists in informatics and analytics. We employ multi-dimensional scaling (MDS) to project feature surface representations into three-dimensions, where proximity in location is proportional to the feature similarity. Through query feedback and environment navigation, the user groups clusters that exhibit probable trends across feature and attribute. The system provides supervised classification methods for determining attribute classes within the user selected groups. Finally, using visual or analytical feature-wise exploration the user determines intra-group feature commonality.	Ian Bowman;Shantanu H. Joshi;John D. Van Horn	Lab. of Neuro Imaging, Univ. of California Los Angeles, Los Angeles, CA, USA|c|;;			
VAST	2011	Reasonable abstractions: Semantics for dynamic data visualization	10.1109/VAST.2011.6102468	http://dx.doi.org/10.1109/VAST.2011.6102468	269	270	M	Chi showed how to treat visualization programing models abstractly. This provided a firm theoretical basis for the data-state model of visualization. However, Chi's models did not look deeper into fine-grained program properties, such as execution semantics. We present conditionally deterministic and resource bounded semantics for the data flow model of visualization based on E-FRP. These semantics are used in the Stencil system to move between data state and data flow execution, build task-based parallelism, and build complex analysis chains for dynamic data. This initial work also shows promise for other complex operators, compilation techniques to enable efficient use of time and space, and mixing task and data parallelism.	Joseph A. Cottam;Andrew Lumsdaine	;			
VAST	2011	Exploring agent-based simulations using temporal graphs	10.1109/VAST.2011.6102469	http://dx.doi.org/10.1109/VAST.2011.6102469	271	272	M	Agent-based simulation has become a key technique for modeling and simulating dynamic, complicated behaviors in social and behavioral sciences. Lacking the appropriate tools and support, it is difficult for social scientists to thoroughly analyze the results of these simulations. In this work, we capture the complex relationships between discrete simulation states by visualizing the data as a temporal graph. In collaboration with expert analysts, we identify two graph structures which capture important relationships between pivotal states in the simulation and their inevitable outcomes. Finally, we demonstrate the utility of these structures in the interactive analysis of a large-scale social science simulation of political power in present-day Thailand.	R. Jordan Crouser;Jeremy G. Freeman;Remco Chang	Tufts Univ., Medford, MA, USA|c|;;			
VAST	2011	Visual analytical approaches to evaluating uncertainty and bias in crowd sourced crisis information	10.1109/VAST.2011.6102470	http://dx.doi.org/10.1109/VAST.2011.6102470	273	274	M	Concerns about verification mean the humanitarian community are reluctant to use information collected during crisis events, even though such information could potentially enhance the response effort. Consequently, a program of research is presented that aims to evaluate the degree to which uncertainty and bias are found in public collections of incident reports gathered during crisis events. These datasets exemplify a class whose members have spatial and temporal attributes, are gathered from heterogeneous sources, and do not have readily available attribution information. An interactive software prototype, and existing software, are applied to a dataset related to the current armed conflict in Libya to identify `intrinsic' characteristics against which uncertainty and bias can be evaluated. Requirements on the prototype are identified, which in time will be expanded into full research objectives.	Iain Dillingham;Jason Dykes;Jo Wood	giCentre, City Univ. London, London, UK|c|;;			
VAST	2011	TreeVersity: Comparing tree structures by topology and node's attributes differences	10.1109/VAST.2011.6102471	http://dx.doi.org/10.1109/VAST.2011.6102471	275	276	M	It is common to classify data in hierarchies, they provide a comprehensible way of understanding big amounts of data. From budgets to organizational charts or even the stock market, trees are everywhere and people find them easy to use. However when analysts need to compare two versions of the same tree structure, or two related taxonomies, the task is not so easy. Much work has been done on this topic, but almost all of it has been restricted to either compare the trees by topology, or by the node attribute values. With this project we are proposing TreeVersity, a framework for comparing tree structures, both by structural changes and by differences in the node attributes. This paper is based on our previous work on comparing traffic agencies using LifeFlow [1, 2] and on a first prototype of TreeVersity.	John Alexis Guerra Gómez;Audra Buck-Coleman;Catherine Plaisant;Ben Shneiderman	HCIL & Dept. of Comput. Sci., Univ. of Maryland, College Park, MD, USA|c|;;;			
VAST	2011	Visual sentiment analysis on twitter data streams	10.1109/VAST.2011.6102472	http://dx.doi.org/10.1109/VAST.2011.6102472	277	278	M	Twitter currently receives about 190 million tweets (small text-based Web posts) a day, in which people share their comments regarding a wide range of topics. A large number of tweets include opinions about products and services. However, with Twitter being a relatively new phenomenon, these tweets are underutilized as a source for evaluating customer sentiment. To explore high-volume twitter data, we introduce three novel time-based visual sentiment analysis techniques: (1) topic-based sentiment analysis that extracts, maps, and measures customer opinions; (2) stream analysis that identifies interesting tweets based on their density, negativity, and influence characteristics; and (3) pixel cell-based sentiment calendars and high density geo maps that visualize large volumes of data in a single view. We applied these techniques to a variety of twitter data, (e.g., movies, amusement parks, and hotels) to show their distribution and patterns, and to identify influential opinions.	Ming C. Hao;Christian Rohrdantz;Halldór Janetzko;Umeshwar Dayal;Daniel A. Keim;Lars-Erik Haug;Meichun Hsu	Hewlett-Packard Labs., Palo Alto, CA, USA|c|;;;;;;			
VAST	2011	Analysts aren't machines: Inferring frustration through visualization interaction	10.1109/VAST.2011.6102473	http://dx.doi.org/10.1109/VAST.2011.6102473	279	280	M	Recent work in visual analytics has explored the extent to which information regarding analyst action and reasoning can be inferred from interaction. However, these methods typically rely on humans instead of automatic extraction techniques. Furthermore, there is little discussion regarding the role of user frustration when interacting with a visual interface. We demonstrate that automatic extraction of user frustration is possible given action-level visualization interaction logs. An experiment is described which collects data that accurately reflects user emotion transitions and corresponding interaction sequences. This data is then used in building HiddenMarkov Models (HMMs) which statistically connect interaction events with frustration. The capabilities of HMMs in predicting user frustration are tested using standard machine learning evaluation methods. The resulting classifier serves as a suitable predictor of user frustration that performs similarly across different users and datasets.	Lane Harrison;Wenwen Dou;Aidong Lu;William Ribarsky;Xiaoyu Wang	Comput. Sci., UNC - Charlotte, Charlotte, NC, USA|c|;;;;			
VAST	2011	Automated measures for interpretable dimensionality reduction for visual classification: A user study	10.1109/VAST.2011.6102474	http://dx.doi.org/10.1109/VAST.2011.6102474	281	282	M	This paper studies the interpretability of transformations of labeled higher dimensional data into a 2D representation (scatterplots) for visual classification.1In this context, the term interpretability has two components: the interpretability of the visualization (the image itself) and the interpretability of the visualization axes (the data transformation functions). We define a data transformation function as any linear or non-linear function of the original variables mapping the data into 1D. Even for a small dataset, the space of possible data transformations is beyond the limit of manual exploration, therefore it is important to develop automated techniques that capture both aspects of interpretability so that they can be used to guide the search process without human intervention. The goal of the search process is to find a smaller number of interpretable data transformations for the users to explore. We briefly discuss how we used such automated measures in an evolutionary computing based data dimensionality reduction application for visual analytics. In this paper, we present a two-part user study in which we separately investigated how humans rated the visualizations of labeled data and comprehensibility of mathematical expressions that could be used as data transformation functions. In the first part, we compared human perception with a number of automated measures from the machine learning and visual analytics literature. In the second part, we studied how various structural properties of an expression related to its interpretability.	Ilknur Icke;Andrew Rosenberg	Grad. Center, City Univ. of New York, New York, NY, USA|c|;			
VAST	2011	3D Visualization of temporal changes in bloggers' activities and interests	10.1109/VAST.2011.6102475	http://dx.doi.org/10.1109/VAST.2011.6102475	283	284	M	This paper presents a novel system for analyzing temporal changes in bloggers' activities and interests on a topic through a 3D visualization of dependency structures related to the topic. Having a dependency database built from a blog archive, our 3D visualization framework helps users to interactively exploring temporal changes in bloggers' activities and interests related to the topic.	Masahiko Itoh;Naoki Yoshinaga 0001;Masashi Toyoda;Masaru Kitsuregawa	Inst. of Ind. Sci., Univ. of Tokyo, Tokyo, Japan|c|;;;			
VAST	2011	A state transition approach to understanding users' interactions	10.1109/VAST.2011.6102476	http://dx.doi.org/10.1109/VAST.2011.6102476	285	286	M	Understanding users' interactions is considered as one of the important research topics in visual analytics. Although numerous empirical user studies have been performed to understand a user's interaction, a limited study has been successful in connecting the user's interaction to his/her reasoning. In this paper, we present an approach of understanding experts' interactive analysis by connecting their interactions to conclusions (i.e. findings) through a state transition approach.	Dong Hyun Jeong;Soo-Yeon Ji;William Ribarsky;Remco Chang	Univ. of the District of Columbia, Washington, DC, USA|c|;;;			
VAST	2011	Visualizing an information assurance risk taxonomy	10.1109/VAST.2011.6102477	http://dx.doi.org/10.1109/VAST.2011.6102477	287	288	M	The researchers explore the intersections between Information Assurance and Risk using visual analysis of text mining operations. The methodological approach involves searching for and extracting for analysis those abstracts and keywords groupings that relate to risk within a defined subset of scientific research journals. This analysis is conducted through a triangulated study incorporating visualizations produced using both Starlight and In-Spire visual analysis software. The results are definitional, showing current attitudes within the Information Assurance research community towards risk management strategies, while simultaneously demonstrating the value of visual analysis processes when engaging in sense making of a large body of knowledge.	Victoria Lemieux;Barbara Endicott-Popovsky;Karl Eckler;Thomas Dang;Adam Jansen	;;;;			
VAST	2011	Find distance function, hide model inference	10.1109/VAST.2011.6102478	http://dx.doi.org/10.1109/VAST.2011.6102478	289	290	M	Faced with a large, high-dimensional dataset, many turn to data analysis approaches that they understand less well than the domain of their data. An expert's knowledge can be leveraged into many types of analysis via a domain-specific distance function, but creating such a function is not intuitive to do by hand. We have created a system that shows an initial visualization, adapts to user feedback, and produces a distance function as a result. Specifically, we present a multidimensional scaling (MDS) visualization and an iterative feedback mechanism for a user to affect the distance function that informs the visualization without having to adjust the parameters of the visualization directly. An encouraging experimental result suggests that using this tool, data attributes with useless data are given low importance in the distance function.	Jingjing Liu;Eli T. Brown;Remco Chang	Tufts Univ., Medford, MA, USA|c|;;			
VAST	2011	KD-photomap: Exploring photographs in space and time	10.1109/VAST.2011.6102479	http://dx.doi.org/10.1109/VAST.2011.6102479	291	292	M	KD-photomap is a web-based visual analytics system for browsing collections of geotagged Flickr photographs in search of interesting pictures, places, and events. Spatial filtering of the data is performed through zooming, moving or searching along the map. Temporal filtering is possible through defining time windows using interactive histograms and calendar controls. Information about the number and spatiotemporal distribution of photos captured in an explored area is continuously provided using various visual cues.	Iulian Peca;Haolin Zhi;Katerina Vrotsou;Natalia V. Andrienko;Gennady L. Andrienko	Fraunhofer Inst. for Intell. Anal. & Inf. Syst. (IAIS), Univ. of Bonn, Bonn, Germany|c|;;;;			
VAST	2011	PORGY: Interactive and visual reasoning with graph rewriting systems	10.1109/VAST.2011.6102480	http://dx.doi.org/10.1109/VAST.2011.6102480	293	294	M	Graph rewriting systems are easily described and explained. They can be seen as a game where one iterates transformation rules on an initial graph, until some condition is met. A rule describes a local pattern (i.e. a subgraph) that must be identified in a graph and specifies how to transform this subgraph. The graph rewriting formalism is at the same time extremely rich and complex, making the study of a model expressed in terms of graph rewriting quite challenging. For instance, predicting whether rules can be applied in any order is often difficult. When modelling complex systems, graphical formalisms have clear advantages: they are more intuitive and make it easier to visualize a system and convey intuitions about it. This work focuses on the design of an interactive visual graph rewriting system which supports graphical manipulations and computation to reason and simulate on a system. PORGY has been designed based on regular exchanges with graph rewriting systems experts and users over the past three years. The design choices relied on a careful methodology inspired from Munzner's nested process model for visualization design and validation [4].	Bruno Pinaud;Jonathan Dubois;Guy Melançon	Univ. of Bordeaux, Bordeaux, France|c|;;			
VAST	2011	Exploring proportions: Comparative visualization of categorical data	10.1109/VAST.2011.6102481	http://dx.doi.org/10.1109/VAST.2011.6102481	295	296	M	This poster describes an approach to facilitate comparisons in multi-dimensional categorical data. The key idea is to represent over- or under-proportional relationships explicitly. On an overview level, the visualization of various measures conveys pair-wise relationships between categorical dimensions. For more details, interaction supports to relate a single category to all categories of multiple dimensions. We discuss methods for representing relationships and visualization-driven strategies for ordering dimensions and categories, and we illustrate the approach by means of data from a social survey.	Harald Piringer;Matthias Buchetics	VRVis Res. Center, Vienna, Austria|c|;			
VAST	2011	Pexel and heatmap visual analysis of multidimensional gun/homicide data	10.1109/VAST.2011.6102482	http://dx.doi.org/10.1109/VAST.2011.6102482	297	298	M	We present a visual analysis tool for mining correlations in county-level, multidimensional gun/homicide data. The tool uses 2D pexels, heatmaps, linked-views, dynamic queries and details-on-demand to analyze annual county-level data on firearm homicide rates and gun availability, as well as various socio-demographic measures. A statistical significance filter was implemented as a visual means to validate exploratory hypotheses. Results from expert evaluations indicate that our methods outperform typical graphical techniques used by statisticians, such as bar graphs, scatterplots and residual plots, to show spatial and temporal relationships. Our visualization has the potential to convey the impact of gun availability on firearm homicides to the public health arena and the general public.	Scott D. Rothenberger;John E. Wenskovitch;G. Elisabeta Marai	Dept. of Stat., Univ. of Pittsburgh, Pittsburgh, PA, USA|c|;;			
VAST	2011	City sentinel - VAST 2011 mini challenge 1 award: "Outstanding integration of computational and visual methods"	10.1109/VAST.2011.6102485	http://dx.doi.org/10.1109/VAST.2011.6102485	305	306	M	We present City Sentinel, an in-house built visual analytic software capable of handling a large collection of textual documents by combining diverse text mining and visualization tools. We applied this tool for the Vast Challenge 2011, Mini Challenge 1 over millions of tweet messages. We demonstrate how City Sentinel aided the analyst in retrieving the hidden information from the tweet messages to analyze and locate a hypothetical epidemic outbreak.	N. Banfi;L. Dudas;Zsolt Fekete;J. Gobolos-Szabo;András Lukács;A. Nagy;A. Szabo;Z. Szabo;G. Szucs	Comput. & Autom. Res. Inst. (MTA SZTAKI), Hungary|c|;;;;;;;;			
VAST	2011	Mapping an epidemic outbreak: Effective analysis and presentation	10.1109/VAST.2011.6102486	http://dx.doi.org/10.1109/VAST.2011.6102486	307	308	M	The microblog challenge presented an opportunity to use commercial software for visual analysis. An epidemic outbreak occurred in the city of Vastopolis, requiring visualizations of symptoms and their spread over time. Using these tools, analysts could successfully identify the outbreak's origin and pattern of dispersion. The maps used to analyze the data and present the results provided clear, easily understood representations, and presented a logical explanation of a complex progression of events.	Kevin Boone;Edward Swing	;			
VAST	2011	ScatterBlogs: Geo-spatial document analysis	10.1109/VAST.2011.6102488	http://dx.doi.org/10.1109/VAST.2011.6102488	309	310	M	We presented Scatterblogs, a system for microblog analysis that seamlessly integrates search backend and visual frontend. It provides powerful, automatic algorithms for detecting spatio-temporal `anomalies' within blog entries as well as corresponding visual representations and interaction facilities for inspecting anomalies or exploiting them in further analytic steps. Apart from that, we consider the system's combinatoric facilities for building complex hypotheses from temporal, spatial, and content-related aspects an important feature. This was the key for creating a cross-checked analysis for MC1.	Harald Bosch;Dennis Thom;Michael Wörner;Steffen Koch;Edwin Puttmann;Dominik Jäckle;Thomas Ertl	Inst. for Visualization & Interactive Syst., Univ. Stuttgart, Stuttgart, Germany|c|;;;;;;			
VAST	2011	epSpread - Storyboarding for visual analytics	10.1109/VAST.2011.6102489	http://dx.doi.org/10.1109/VAST.2011.6102489	311	312	M	We present epSpread, an analysis and storyboarding tool for geolocated microblogging data. Individual time points and ranges are analysed through queries, heatmaps, word clouds and streamgraphs. The underlying narrative is shown on a storyboard-style timeline for discussion, refinement and presentation. The tool was used to analyse data from the VAST Challenge 2011 Mini-Challenge 1, tracking the spread of an epidemic using microblogging data. In this article we describe how the tool was used to identify the origin and track the spread of the epidemic.	Llyr ap Cenydd;Rick Walker;Serban Pop;Helen C. Miles;Chris J. Hughes;William John Teahan;Jonathan C. Roberts	Sch. of Comput. Sci., Bangor Univ., Bangor, UK|c|;;;;;;			
VAST	2011	MobileAnalymator: Animating data changes on mobile devices	10.1109/VAST.2011.6102490	http://dx.doi.org/10.1109/VAST.2011.6102490	313	314	M	MobileAnalymator (Mobile Analysis Animator) is a visual analytic system designed to analyze geospatial-temporal data on mobile devices. The system is an Internet based application that allows analysts to work in flexile enviornments at anytime. Its client side is developed by Adobe Flash to animate and interact with data. The server side uses Java and MySQL to query, compute, and serve data. The analyst can run the analytical task from a tablet (or computer) with Internet connection. MobileAnalymator adopted spatial and temporal autocorrelations in the interface design and integrated tangible interaction in the navigation to support analysis process.	Victor Y. Chen;Cheryl Z. Qian;Li Zhang	Interaction Design, Purdue Univ., West Lafayette, IN, USA|c|;;			
VAST	2011	Geovisual analytics for cyber security: Adopting the GeoViz Toolkit	10.1109/VAST.2011.6102491	http://dx.doi.org/10.1109/VAST.2011.6102491	315	316	M	For the VAST 2011 Network Security Mini-Challenge, we adopted geovisual analytic methods and applied them in the field of network security. We used the GeoViz Toolkit [1] to represent cyber security events, by fabricating a simple â€œgeographyâ€ of several sets of blocks (one for the workstations, one for the servers, and one for the Internet) using ArcGIS 10 (by ESRI - Environmental System Research Institute). Security data was tabulated using Perl scripts to parse the logs in order to create representations of event frequency and where they occurred on the network. The tabulated security data was then added as attributes of the geography. Exploration of the data and subsequent analysis of the meaning and impact of the cyber security events was made possible using the GeoViz Toolkit.	Nicklaus A. Giacobe;Sen Xu	Coll. of Inf. Sci. & Technol., Pennsylvania State Univ., University Park, PA, USA|c|;			
VAST	2011	Guiding security analysis through visualization	10.1109/VAST.2011.6102492	http://dx.doi.org/10.1109/VAST.2011.6102492	317	318	M	We present a multiple views visualization for the security data in the VAST 2010 Mini Challenge 2. The visualization is used to monitor log event activity on the network log data included in the challenge. Interactions are provided that allow analysts to investigate suspicious activity and escalate events as needed. Additionally, a database application is used to allow SQL queries for more detailed investigation.	Lane Harrison;Wenwen Dou;Aidong Lu;William Ribarsky;Xiaoyu Wang	Comput. Sci., UNC - Charlotte, Charlotte, NC, USA|c|;;;;			
VAST	2011	An integrated visualization on network events VAST 2011 mini challenge #2 award: "Outstanding integrated overview display"	10.1109/VAST.2011.6102493	http://dx.doi.org/10.1109/VAST.2011.6102493	319	321	M	To visualize security trends for the data set provided by the VAST 2011 Mini Challenge #2 a custom tool has been developed. Open source tools [1,2], web programming languages [4,7] and an open source database [3] has been used to work with the data and create a visualization for security log files containing network security trends. In this paper, the tools and methods used for the analysis are described. The methods include the log synchronization with different timezone and the development of heat maps and parallel coordinates charts. To develop the visualization, Processing and Canvas [4,7] was used.	Walter Marcelo Lamagna	Master on Datamining & Knowledge Discovery, Univ. de Buenos Aires, Buenos Aires, Argentina|c|			
VAST	2011	Analyst's workspace: Protecting vastopolis	10.1109/VAST.2011.6102495	http://dx.doi.org/10.1109/VAST.2011.6102495	323	324	M	Analyst's Workspace is a sensemaking environment designed specifically for use of large, high-resolution displays. It employs a spatial workspace to integrate foraging and synthesis activities into a unified process. In this paper we describe how Analyst's Workspace solved the VAST 2011 mini-challenge #3 and discuss some of the unique features of the environment.	Christopher Andrews;M. Shahriar Hossain;Samah Gad;Naren Ramakrishnan;Chris North	;;;;			
VAST	2011	Jigsaw to save vastopolis	10.1109/VAST.2011.6102496	http://dx.doi.org/10.1109/VAST.2011.6102496	325	326	M	This article describes our analytic process and experience of using the Jigsaw system in working on the VAST 2011 Mini Challenge 3. We describe how we extracted and worked with entities from the documents, and how Jigsaw's computational analysis capabilities and visualizations scaffolded the investigation. Based on our experiences, we discuss desirable features that would enhance the analytic power of Jigsaw.	Elizabeth Braunstein;Carsten Görg;Zhicheng Liu;John T. Stasko	Mercyhurst Coll., USA|c|;;;			
VAST	2011	Interactive data analysis with nSpace2(c)	10.1109/VAST.2011.6102497	http://dx.doi.org/10.1109/VAST.2011.6102497	327	328	M	nSpace2 is an innovative visual analytics tool that was the primary platform used to search, evaluate, and organize the data in the VAST 2011 Mini Challenge #3 dataset. nSpace2 is a web-based tool that is designed to facilitate the back-and-forth flow of the multiple steps of an analysis process, including search, data triage, organization, sense-making, and reporting. This paper describes how nSpace2 was used to assist every step of the analysis process for this VAST challenge.	Casey M. Canfield;David Sheffield	;			
VAST	2011	Visual analytics of terrorist activities related to epidemics	10.1109/VAST.2011.6102498	http://dx.doi.org/10.1109/VAST.2011.6102498	329	330	M	The task of the VAST 2011 Grand Challenge was to investigate potential terrorist activities and their relation to the spread of an epidemic. Three different data sets were provided as part of three Mini Challenges (MCs). MC 1 was about analyzing geo-tagged microblogging (Twitter) messages to characterize the spread of an epidemic. MC 2 required analyzing threats to a computer network using a situational awareness approach. In MC 3 possible criminal and terrorist activities were to be analyzed based on a collection of news articles. To solve the Grand Challenge, insight from each of the individual MCs had to be integrated appropriately.	Enrico Bertini;Juri Buchmüller;Fabian Fischer;Stephan Huber;Thomas Lindemeier;Fabian Maass;Florian Mansmann;Thomas Ramm;Michael Regenscheit;Christian Rohrdantz;Christian Scheible;Tobias Schreck;Stephan Sellien;Florian Stoffel;Mark Tautzenberger;Matthias Zieker;Daniel A. Keim	Data Anal. & Visualization Group, Univ. of Konstanz, Konstanz, Germany|c|;;;;;;;;;;;;;;;;			
Vis	2011	A Scale Space Based Persistence Measure for Critical Points in 2D Scalar fields	10.1109/TVCG.2011.159	http://dx.doi.org/10.1109/TVCG.2011.159	2045	2052	J	This paper introduces a novel importance measure for critical points in 2D scalar fields. This measure is based on a combination of the deep structure of the scale space with the well-known concept of homological persistence. We enhance the noise robust persistence measure by implicitly taking the hill-, ridge- and outlier-like spatial extent of maxima and minima into account. This allows for the distinction between different types of extrema based on their persistence at multiple scales. Our importance measure can be computed efficiently in an out-of-core setting. To demonstrate the practical relevance of our method we apply it to a synthetic and a real-world data set and evaluate its performance and scalability.	Jan Reininghaus;Natallia Kotava;David Günther;Jens Kasten;Hans Hagen;Ingrid Hotz	Zuse Inst. Berlin, Berlin, Germany|c|;;;;;	10.1109/TVCG.2008.110;10.1109/TVCG.2008.162;10.1109/TVCG.2007.70603;10.1109/TVCG.2009.177;10.1109/TVCG.2006.186	Scale space, persistence, discrete Morse theory	
Vis	2011	About the Influence of Illumination Models on Image Comprehension in Direct Volume Rendering	10.1109/TVCG.2011.161	http://dx.doi.org/10.1109/TVCG.2011.161	1922	1931	J	In this paper, we present a user study in which we have investigated the influence of seven state-of-the-art volumetric illumination models on the spatial perception of volume rendered images. Within the study, we have compared gradient-based shading with half angle slicing, directional occlusion shading, multidirectional occlusion shading, shadow volume propagation, spherical harmonic lighting as well as dynamic ambient occlusion. To evaluate these models, users had to solve three tasks relying on correct depth as well as size perception. Our motivation for these three tasks was to find relations between the used illumination model, user accuracy and the elapsed time. In an additional task, users had to subjectively judge the output of the tested models. After first reviewing the models and their features, we will introduce the individual tasks and discuss their results. We discovered statistically significant differences in the testing performance of the techniques. Based on these findings, we have analyzed the models and extracted those features which are possibly relevant for the improved spatial comprehension in a relational task. We believe that a combination of these distinctive features could pave the way for a novel illumination model, which would be optimized based on our findings.	Florian Lindemann;Timo Ropinski	Visualization & Comput. Graphics Res. Group, Univ. of Munster, Munster, Germany|c|;	10.1109/TVCG.2008.108;10.1109/VISUAL.2002.1183761;10.1109/TVCG.2009.172;10.1109/TVCG.2011.211;10.1109/VISUAL.2003.1250394;10.1109/VISUAL.2002.1183764	Volumetric illumination, volume rendering, spatial comprehension	
Vis	2011	Adaptive Extraction and Quantification of Geophysical Vortices	10.1109/TVCG.2011.162	http://dx.doi.org/10.1109/TVCG.2011.162	2088	2095	J	We consider the problem of extracting discrete two-dimensional vortices from a turbulent flow. In our approach we use a reference model describing the expected physics and geometry of an idealized vortex. The model allows us to derive a novel correlation between the size of the vortex and its strength, measured as the square of its strain minus the square of its vorticity. For vortex detection in real models we use the strength parameter to locate potential vortex cores, then measure the similarity of our ideal analytical vortex and the real vortex core for different strength thresholds. This approach provides a metric for how well a vortex core is modeled by an ideal vortex. Moreover, this provides insight into the problem of choosing the thresholds that identify a vortex. By selecting a target coefficient of determination (i.e., statistical confidence), we determine on a per-vortex basis what threshold of the strength parameter would be required to extract that vortex at the chosen confidence. We validate our approach on real data from a global ocean simulation and derive from it a map of expected vortex strengths over the global ocean.	Sean Williams;Mark Petersen;Peer-Timo Bremer;Matthew Hecht;Valerio Pascucci;James P. Ahrens;Mario Hlawitschka;Bernd Hamann	Inst. for Data Anal. & Visualization, Univ. of California, Davis, CA, USA|c|;;;;;;;	10.1109/VISUAL.1994.346327;10.1109/TVCG.2008.143;10.1109/VISUAL.1993.398877	Vortex extraction, feature extraction, statistical data analysis	
Vis	2011	An Efficient Direct Volume Rendering Approach for Dichromats	10.1109/TVCG.2011.164	http://dx.doi.org/10.1109/TVCG.2011.164	2144	2152	J	Color vision deficiency (CVD) affects a high percentage of the population worldwide. When seeing a volume visualization result, persons with CVD may be incapable of discriminating the classification information expressed in the image if the color transfer function or the color blending used in the direct volume rendering is not appropriate. Conventional methods used to address this problem adopt advanced image recoloring techniques to enhance the rendering results frame-by-frame; unfortunately, problematic perceptual results may still be generated. This paper proposes an alternative solution that complements the image recoloring scheme by reconfiguring the components of the direct volume rendering (DVR) pipeline. Our approach optimizes the mapped colors of a transfer function to simulate CVD-friendly effect that is generated by applying the image recoloring to the results with the initial transfer function. The optimization process has a low computational complexity, and only needs to be performed once for a given transfer function. To achieve detail-preserving and perceptually natural semi-transparent effects, we introduce a new color composition mode that works in the color space of dichromats. Experimental results and a pilot study demonstrates that our approach can yield dichromats-friendly and consistent volume visualization in real-time.	Weifeng Chen;Wei Chen;Hujun Bao	State Key Lab. of CAD&CG, Zhejiang Univ., Hangzhou, China|c|;;	10.1109/TVCG.2008.118;10.1109/TVCG.2009.172;10.1109/TVCG.2008.112;10.1109/TVCG.2009.150;10.1109/VISUAL.2005.1532833;10.1109/TVCG.2009.113	Dichromacy, direct volume rendering, volume classification, image recoloring	
Vis	2011	An Interactive Local Flattening Operator to Support Digital Investigations on Artwork Surfaces	10.1109/TVCG.2011.165	http://dx.doi.org/10.1109/TVCG.2011.165	1989	1996	J	Analyzing either high-frequency shape detail or any other 2D fields (scalar or vector) embedded over a 3D geometry is a complex task, since detaching the detail from the overall shape can be tricky. An alternative approach is to move to the 2D space, resolving shape reasoning to easier image processing techniques. In this paper we propose a novel framework for the analysis of 2D information distributed over 3D geometry, based on a locally smooth parametrization technique that allows us to treat local 3D data in terms of image content. The proposed approach has been implemented as a sketch-based system that allows to design with a few gestures a set of (possibly overlapping) parameterizations of rectangular portions of the surface. We demonstrate that, due to the locality of the parametrization, the distortion is under an acceptable threshold, while discontinuities can be avoided since the parametrized geometry is always homeomorphic to a disk. We show the effectiveness of the proposed technique to solve specific Cultural Heritage (CH) tasks: the analysis of chisel marks over the surface of a unfinished sculpture and the local comparison of multiple photographs mapped over the surface of an artwork. For this very difficult task, we believe that our framework and the corresponding tool are the first steps toward a computer-based shape reasoning system, able to support CH scholars with a medium they are more used to.	Nico Pietroni;Massimiliano Corsini;Paolo Cignoni;Roberto Scopigno	ISTI, CNR, Pisa, Italy|c|;;;	10.1109/VISUAL.2004.75	Surface Characterization, Interactive Inspection, Cultural Heritage, Mesh Parameterization, Image Processing	
Vis	2011	Artificial Defocus for Displaying Markers in Microscopy Z-Stacks	10.1109/TVCG.2011.168	http://dx.doi.org/10.1109/TVCG.2011.168	1757	1764	J	As microscopes have a very shallow depth of field, Z-stacks (i.e. sets of images shot at different focal planes) are often acquired to fully capture a thick sample. Such stacks are viewed by users by navigating them through the mouse wheel. We propose a new technique of visualizing 3D point, line or area markers in such focus stacks, by displaying them with a depth-dependent defocus, simulating the microscope's optics; this leverages on the microscopists' ability to continuously twiddle focus, while implicitly performing a shape-from-focus reconstruction of the 3D structure of the sample. User studies confirm that the approach is effective, and can complement more traditional techniques such as color-based cues. We provide two implementations, one of which computes defocus in real time on the GPU, and examples of their application.	Alessandro Giusti;Pierluigi Taddei;Giorgio Corani;Luca Maria Gambardella;Cristina Magli;Luca Gianaroli	Dalle Molle Inst. for Artificial Intell., Lugano, Switzerland|c|;;;;;	10.1109/VISUAL.1990.146378;10.1109/VISUAL.1996.568136	Depth of field, Microscopy, Focus stacks	
Vis	2011	Asymmetric Tensor field Visualization for Surfaces	10.1109/TVCG.2011.170	http://dx.doi.org/10.1109/TVCG.2011.170	1979	1988	J	Asymmetric tensor field visualization can provide important insight into fluid flows and solid deformations. Existing techniques for asymmetric tensor fields focus on the analysis, and simply use evenly-spaced hyperstreamlines on surfaces following eigenvectors and dual-eigenvectors in the tensor field. In this paper, we describe a hybrid visualization technique in which hyperstreamlines and elliptical glyphs are used in real and complex domains, respectively. This enables a more faithful representation of flow behaviors inside complex domains. In addition, we encode tensor magnitude, an important quantity in tensor field analysis, using the density of hyperstreamlines and sizes of glyphs. This allows colors to be used to encode other important tensor quantities. To facilitate quick visual exploration of the data from different viewpoints and at different resolutions, we employ an efficient image-space approach in which hyperstreamlines and glyphs are generated quickly in the image plane. The combination of these techniques leads to an efficient tensor field visualization system for domain scientists. We demonstrate the effectiveness of our visualization technique through applications to complex simulated engine fluid flow and earthquake deformation data. Feedback from domain expert scientists, who are also co-authors, is provided.	Darrel Palke;Zhongzang Lin;Guoning Chen;Harry Yeh;Paul Vincent;Robert S. Laramee;Eugene Zhang	SCI, Univ. of Utah, Salt Lake City, UT, USA|c|;;;;;;	10.1109/VISUAL.2003.1250379;10.1109/TVCG.2010.199;10.1109/VISUAL.2004.105;10.1109/VISUAL.1993.398849;10.1109/VISUAL.2005.1532773;10.1109/VISUAL.2005.1532770;10.1109/TVCG.2006.134;10.1109/VISUAL.2005.1532850;10.1109/TVCG.2006.116;10.1109/VISUAL.2005.1532841;10.1109/VISUAL.2003.1250363;10.1109/VISUAL.1998.745295;10.1109/VISUAL.2004.80;10.1109/VISUAL.1998.745294;10.1109/VISUAL.2005.1532832;10.1109/VISUAL.1999.809905;10.1109/VISUAL.2000.885690;10.1109/VISUAL.1994.346326	Aasymmetric tensor fields, vector fields, glyph packing, hyperstreamline placement, view-dependent	
Vis	2011	Authalic Parameterization of General Surfaces Using Lie Advection	10.1109/TVCG.2011.171	http://dx.doi.org/10.1109/TVCG.2011.171	2005	2014	J	Parameterization of complex surfaces constitutes a major means of visualizing highly convoluted geometric structures as well as other properties associated with the surface. It also enables users with the ability to navigate, orient, and focus on regions of interest within a global view and overcome the occlusions to inner concavities. In this paper, we propose a novel area-preserving surface parameterization method which is rigorous in theory, moderate in computation, yet easily extendable to surfaces of non-disc and closed-boundary topologies. Starting from the distortion induced by an initial parameterization, an area restoring diffeomorphic flow is constructed as a Lie advection of differential 2-forms along the manifold, which yields equality of the area elements between the domain and the original surface at its final state. Existence and uniqueness of result are assured through an analytical derivation. Based upon a triangulated surface representation, we also present an efficient algorithm in line with discrete differential modeling. As an exemplar application, the utilization of this method for the effective visualization of brain cortical imaging modalities is presented. Compared with conformal methods, our method can reveal more subtle surface patterns in a quantitative manner. It, therefore, provides a competitive alternative to the existing parameterization techniques for better surface-based analysis in various scenarios.	Guangyu Zou;Jiaxi Hu;Xianfeng Gu;Jing Hua	Wayne State Univ., Detroit, MI, USA|c|;;;	10.1109/TVCG.2008.134;10.1109/TVCG.2009.159;10.1109/TVCG.2006.134;10.1109/VISUAL.2004.75;10.1109/VISUAL.2002.1183795;10.1109/VISUAL.2001.964553	Area-preserving surface parameterization, differential forms, Lie advection, surface visualization	
Vis	2011	Automatic Transfer Functions Based on Informational Divergence	10.1109/TVCG.2011.173	http://dx.doi.org/10.1109/TVCG.2011.173	1932	1941	J	In this paper we present a framework to define transfer functions from a target distribution provided by the user. A target distribution can reflect the data importance, or highly relevant data value interval, or spatial segmentation. Our approach is based on a communication channel between a set of viewpoints and a set of bins of a volume data set, and it supports 1D as well as 2D transfer functions including the gradient information. The transfer functions are obtained by minimizing the informational divergence or Kullback-Leibler distance between the visibility distribution captured by the viewpoints and a target distribution selected by the user. The use of the derivative of the informational divergence allows for a fast optimization process. Different target distributions for 1D and 2D transfer functions are analyzed together with importance-driven and view-based techniques.	Marc Ruiz;Anton Bardera;Imma Boada;Ivan Viola	;;;;;	10.1109/TVCG.2010.132;10.1109/TVCG.2006.137;10.1109/TVCG.2006.159;10.1109/TVCG.2010.131;10.1109/TVCG.2006.152;10.1109/VISUAL.2003.1250414;10.1109/TVCG.2007.70576;10.1109/TVCG.2009.120;10.1109/VISUAL.1996.568113;10.1109/TVCG.2008.140;10.1109/VISUAL.2005.1532834;10.1109/VISUAL.2002.1183785;10.1109/TVCG.2006.148	Transfer function, Information theory, Informational divergence, Kullback-Leibler distance	
Vis	2011	Branching and Circular Features in High Dimensional Data	10.1109/TVCG.2011.177	http://dx.doi.org/10.1109/TVCG.2011.177	1902	1911	J	Large observations and simulations in scientific research give rise to high-dimensional data sets that present many challenges and opportunities in data analysis and visualization. Researchers in application domains such as engineering, computational biology, climate study, imaging and motion capture are faced with the problem of how to discover compact representations of highdimensional data while preserving their intrinsic structure. In many applications, the original data is projected onto low-dimensional space via dimensionality reduction techniques prior to modeling. One problem with this approach is that the projection step in the process can fail to preserve structure in the data that is only apparent in high dimensions. Conversely, such techniques may create structural illusions in the projection, implying structure not present in the original high-dimensional data. Our solution is to utilize topological techniques to recover important structures in high-dimensional data that contains non-trivial topology. Specifically, we are interested in high-dimensional branching structures. We construct local circle-valued coordinate functions to represent such features. Subsequently, we perform dimensionality reduction on the data while ensuring such structures are visually preserved. Additionally, we study the effects of global circular structures on visualizations. Our results reveal never-before-seen structures on real-world data sets from a variety of applications.	Bei Wang;Brian Summa;Valerio Pascucci;Mikael Vejdemo-Johansson	SCI Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;;	10.1109/TVCG.2010.213;10.1109/TVCG.2009.119;10.1109/TVCG.2007.70601;10.1109/TVCG.2010.139;10.1109/VAST.2010.5652940	Dimensionality reduction, circular coordinates, visualization, topological analysis	
Vis	2011	Context Preserving Maps of Tubular Structures	10.1109/TVCG.2011.182	http://dx.doi.org/10.1109/TVCG.2011.182	1997	2004	J	When visualizing tubular 3D structures, external representations are often used for guidance and display, and such views in 2D can often contain occlusions. Virtual dissection methods have been proposed where the entire 3D structure can be mapped to the 2D plane, though these will lose context by straightening curved sections. We present a new method of creating maps of 3D tubular structures that yield a succinct view while preserving the overall geometric structure. Given a dominant view plane for the structure, its curve skeleton is first projected to a 2D skeleton. This 2D skeleton is adjusted to account for distortions in length, modified to remove intersections, and optimized to preserve the shape of the original 3D skeleton. Based on this shaped 2D skeleton, a boundary for the map of the object is obtained based on a slicing path through the structure and the radius around the skeleton. The sliced structure is conformally mapped to a rectangle and then deformed via harmonic mapping to match the boundary placement. This flattened map preserves the general geometric context of a 3D object in a 2D display, and rendering of this flattened map can be accomplished using volumetric ray casting. We have evaluated our method on real datasets of human colon models.	Joseph Marino	Comput. Sci. Dept., Stony Brook Univ., Stony Brook, NY, USA|c|;;;	10.1109/TVCG.2006.112;10.1109/TVCG.2010.200;10.1109/VISUAL.2001.964540	Geometry-based technique, volume rendering, biomedical visualization, medical visualization, conformal mapping	
Vis	2011	Crepuscular Rays for Tumor Accessibility Planning	10.1109/TVCG.2011.184	http://dx.doi.org/10.1109/TVCG.2011.184	2163	2172	J	In modern clinical practice, planning access paths to volumetric target structures remains one of the most important and most complex tasks, and a physician's insufficient experience in this can lead to severe complications or even the death of the patient. In this paper, we present a method for safety evaluation and the visualization of access paths to assist physicians during preoperative planning. As a metaphor for our method, we employ a well-known, and thus intuitively perceivable, natural phenomenon that is usually called crepuscular rays. Using this metaphor, we propose several ways to compute the safety of paths from the region of interest to all tumor voxels and show how this information can be visualized in real-time using a multi-volume rendering system. Furthermore, we show how to estimate the extent of connected safe areas to improve common medical 2D multi-planar reconstruction (MPR) views. We evaluate our method by means of expert interviews, an online survey, and a retrospective evaluation of 19 real abdominal radio-frequency ablation (RFA) interventions, with expert decisions serving as a gold standard. The evaluation results show clear evidence that our method can be successfully applied in clinical practice without introducing substantial overhead work for the acting personnel. Finally, we show that our method is not limited to medical applications and that it can also be useful in other fields.	Rostislav Khlebnikov;Bernhard Kainz;Judith Muehl;Dieter Schmalstieg	Graz Univ. of Technol., Graz, Austria|c|;;;	10.1109/TVCG.2007.70560	Accessibility, ray casting, medical visualization	
Vis	2011	Distance Visualization for Interactive 3D Implant Planning	10.1109/TVCG.2011.189	http://dx.doi.org/10.1109/TVCG.2011.189	2173	2182	J	An instant and quantitative assessment of spatial distances between two objects plays an important role in interactive applications such as virtual model assembly, medical operation planning, or computational steering. While some research has been done on the development of distance-based measures between two objects, only very few attempts have been reported to visualize such measures in interactive scenarios. In this paper we present two different approaches for this purpose, and we investigate the effectiveness of these approaches for intuitive 3D implant positioning in a medical operation planning system. The first approach uses cylindrical glyphs to depict distances, which smoothly adapt their shape and color to changing distances when the objects are moved. This approach computes distances directly on the polygonal object representations by means of ray/triangle mesh intersection. The second approach introduces a set of slices as additional geometric structures, and uses color coding on surfaces to indicate distances. This approach obtains distances from a precomputed distance field of each object. The major findings of the performed user study indicate that a visualization that can facilitate an instant and quantitative analysis of distances between two objects in interactive 3D scenarios is demanding, yet can be achieved by including additional monocular cues into the visualization.	Christian Dick;Rainer Burgkart;Rüdiger Westermann	Comput. Graphics & Visualization Group, Tech. Univ. Munchen, Munich, Germany|c|;;	10.1109/VISUAL.2002.1183752;10.1109/TVCG.2009.184	Distance visualization, biomedical visualization, implant planning, glyphs, distance fields	
Vis	2011	Evaluation of Trend Localization with Multi-Variate Visualizations	10.1109/TVCG.2011.194	http://dx.doi.org/10.1109/TVCG.2011.194	2053	2062	J	Multi-valued data sets are increasingly common, with the number of dimensions growing. A number of multi-variate visualization techniques have been presented to display such data. However, evaluating the utility of such techniques for general data sets remains difficult. Thus most techniques are studied on only one data set. Another criticism that could be levied against previous evaluations of multi-variate visualizations is that the task doesn't require the presence of multiple variables. At the same time, the taxonomy of tasks that users may perform visually is extensive. We designed a task, trend localization, that required comparison of multiple data values in a multi-variate visualization. We then conducted a user study with this task, evaluating five multivariate visualization techniques from the literature (Brush Strokes, Data-Driven Spots, Oriented Slivers, Color Blending, Dimensional Stacking) and juxtaposed grayscale maps. We report the results and discuss the implications for both the techniques and the task.	Mark A. Livingston;Jonathan W. Decker	;	10.1109/TVCG.2009.126;10.1109/VISUAL.1998.745292;10.1109/VISUAL.1990.146387;10.1109/VISUAL.1990.146386;10.1109/TVCG.2007.70623;10.1109/VISUAL.1991.175795;10.1109/VISUAL.1999.809905;10.1109/VISUAL.2003.1250362;10.1109/VISUAL.1998.745294;10.1109/VISUAL.2003.1250362	User study, multi-variate visualization, visual task design, visual analytics	
Vis	2011	Extinction-Based Shading and Illumination in GPU Volume Ray-Casting	10.1109/TVCG.2011.198	http://dx.doi.org/10.1109/TVCG.2011.198	1795	1802	J	Direct volume rendering has become a popular method for visualizing volumetric datasets. Even though computers are continually getting faster, it remains a challenge to incorporate sophisticated illumination models into direct volume rendering while maintaining interactive frame rates. In this paper, we present a novel approach for advanced illumination in direct volume rendering based on GPU ray-casting. Our approach features directional soft shadows taking scattering into account, ambient occlusion and color bleeding effects while achieving very competitive frame rates. In particular, multiple dynamic lights and interactive transfer function changes are fully supported. Commonly, direct volume rendering is based on a very simplified discrete version of the original volume rendering integral, including the development of the original exponential extinction into a-blending. In contrast to a-blending forming a product when sampling along a ray, the original exponential extinction coefficient is an integral and its discretization a Riemann sum. The fact that it is a sum can cleverly be exploited to implement volume lighting effects, i.e. soft directional shadows, ambient occlusion and color bleeding. We will show how this can be achieved and how it can be implemented on the GPU.	Philipp Schlegel;Maxim Makhinya;Renato Pajarola	Dept. of Inf., Univ. of Zurich, Zurich, Switzerland|c|;;	10.1109/TVCG.2007.70555;10.1109/VISUAL.2002.1183764;10.1109/VISUAL.2003.1250384	Volume Rendering, Shadows, Ambient Occlusion, GPU Ray-Casting, Exponential Extinction	
Vis	2011	Feature-Based Statistical Analysis of Combustion Simulation Data	10.1109/TVCG.2011.199	http://dx.doi.org/10.1109/TVCG.2011.199	1822	1831	J	We present a new framework for feature-based statistical analysis of large-scale scientific data and demonstrate its effectiveness by analyzing features from Direct Numerical Simulations (DNS) of turbulent combustion. Turbulent flows are ubiquitous and account for transport and mixing processes in combustion, astrophysics, fusion, and climate modeling among other disciplines. They are also characterized by coherent structure or organized motion, i.e. nonlocal entities whose geometrical features can directly impact molecular mixing and reactive processes. While traditional multi-point statistics provide correlative information, they lack nonlocal structural information, and hence, fail to provide mechanistic causality information between organized fluid motion and mixing and reactive processes. Hence, it is of great interest to capture and track flow features and their statistics together with their correlation with relevant scalar quantities, e.g. temperature or species concentrations. In our approach we encode the set of all possible flow features by pre-computing merge trees augmented with attributes, such as statistical moments of various scalar fields, e.g. temperature, as well as length-scales computed via spectral analysis. The computation is performed in an efficient streaming manner in a pre-processing step and results in a collection of meta-data that is orders of magnitude smaller than the original simulation data. This meta-data is sufficient to support a fully flexible and interactive analysis of the features, allowing for arbitrary thresholds, providing per-feature statistics, and creating various global diagnostics such as Cumulative Density Functions (CDFs), histograms, or time-series. We combine the analysis with a rendering of the features in a linked-view browser that enables scientists to interactively explore, visualize, and analyze the equivalent of one terabyte of simulation data. We highlight the utility of this new framework for combustion s- ience; however, it is applicable to many other science domains.	Janine Bennett;Vaidyanathan Krishnamoorthy;Shusen Liu;Ray W. Grout;Evatt R. Hawkes;Jacqueline Chen;Jason F. Shepherd;Valerio Pascucci;Peer-Timo Bremer	Sandia Nat. Labs., Albuquerque, NM, USA|c|;;;;;;;;	10.1109/VISUAL.2004.96;10.1109/VISUAL.2003.1250386;10.1109/TVCG.2007.70603;10.1109/TVCG.2006.186;10.1109/VISUAL.1997.663875	Topology, Statistics, Data analysis, Data exploration, Visualization in Physical Sciences and Engineering, Multi-variate Data	
Vis	2011	Features in Continuous Parallel Coordinates	10.1109/TVCG.2011.200	http://dx.doi.org/10.1109/TVCG.2011.200	1912	1921	J	Continuous Parallel Coordinates (CPC) are a contemporary visualization technique in order to combine several scalar fields, given over a common domain. They facilitate a continuous view for parallel coordinates by considering a smooth scalar field instead of a finite number of straight lines. We show that there are feature curves in CPC which appear to be the dominant structures of a CPC. We present methods to extract and classify them and demonstrate their usefulness to enhance the visualization of CPCs. In particular, we show that these feature curves are related to discontinuities in Continuous Scatterplots (CSP). We show this by exploiting a curve-curve duality between parallel and Cartesian coordinates, which is a generalization of the well-known point-line duality. Furthermore, we illustrate the theoretical considerations. Concluding, we discuss relations and aspects of the CPC's/CSP's features concerning the data analysis.	Dirk J. Lehmann;Holger Theisel	Dept. of Simulation & Graphics, Univ. of Magdeburg, Magdeburg, Germany|c|;	10.1109/TVCG.2008.119;10.1109/TVCG.2010.146;10.1109/VISUAL.1998.745284;10.1109/TVCG.2009.131;10.1109/VISUAL.1999.809896	Features, Parallel Coordinates, Topology, Visualization	
Vis	2011	Flow Radar Glyphs&amp;#8212;Static Visualization of Unsteady Flow with Uncertainty	10.1109/TVCG.2011.203	http://dx.doi.org/10.1109/TVCG.2011.203	1949	1958	J	A new type of glyph is introduced to visualize unsteady flow with static images, allowing easier analysis of time-dependent phenomena compared to animated visualization. Adopting the visual metaphor of radar displays, this glyph represents flow directions by angles and time by radius in spherical coordinates. Dense seeding of flow radar glyphs on the flow domain naturally lends itself to multi-scale visualization: zoomed-out views show aggregated overviews, zooming-in enables detailed analysis of spatial and temporal characteristics. Uncertainty visualization is supported by extending the glyph to display possible ranges of flow directions. The paper focuses on 2D flow, but includes a discussion of 3D flow as well. Examples from CFD and the field of stochastic hydrogeology show that it is easy to discriminate regions of different spatiotemporal flow behavior and regions of different uncertainty variations in space and time. The examples also demonstrate that parameter studies can be analyzed because the glyph design facilitates comparative visualization. Finally, different variants of interactive GPU-accelerated implementations are discussed.	Marcel Hlawatsch;Philipp C. Leube;Wolfgang Nowak;Daniel Weiskopf	Visualization Res. Center (VISUS), Univ. of Stuttgart, Stuttgart, Germany|c|;;;	10.1109/VISUAL.2005.1532853;10.1109/VISUAL.1993.398849;10.1109/INFVIS.2001.963273;10.1109/VISUAL.2003.1250402;10.1109/VISUAL.1996.568139;10.1109/VISUAL.2005.1532857;10.1109/VISUAL.1991.175792;10.1109/VISUAL.1995.480819;10.1109/VISUAL.1996.568116;10.1109/TVCG.2009.182	Visualization, glyph, uncertainty, unsteady flow	
Vis	2011	FoamVis: Visualization of 2D Foam Simulation Data	10.1109/TVCG.2011.204	http://dx.doi.org/10.1109/TVCG.2011.204	2096	2105	J	Research in the field of complex fluids such as polymer solutions, particulate suspensions and foams studies how the flow of fluids with different material parameters changes as a result of various constraints. Surface Evolver, the standard solver software used to generate foam simulations, provides large, complex, time-dependent data sets with hundreds or thousands of individual bubbles and thousands of time steps. However this software has limited visualization capabilities, and no foam specific visualization software exists. We describe the foam research application area where, we believe, visualization has an important role to play. We present a novel application that provides various techniques for visualization, exploration and analysis of time-dependent 2D foam simulation data. We show new features in foam simulation data and new insights into foam behavior discovered using our application.	Dan R. Lipsa;Robert S. Laramee;Simon J. Cox;Tudur Davies	Swansea Univ., Swansea, UK|c|;;;	10.1109/TVCG.2008.147;10.1109/TVCG.2008.139	Surface Evolver, bubble-scale simulation, time-dependent visualizations	
Vis	2011	GPU-Based Interactive Cut-Surface Extraction From High-Order finite Element fields	10.1109/TVCG.2011.206	http://dx.doi.org/10.1109/TVCG.2011.206	1803	1811	J	We present a GPU-based ray-tracing system for the accurate and interactive visualization of cut-surfaces through 3D simulations of physical processes created from spectral/hp high-order finite element methods. When used by the numerical analyst to debug the solver, the ability for the imagery to precisely reflect the data is critical. In practice, the investigator interactively selects from a palette of visualization tools to construct a scene that can answer a query of the data. This is effective as long as the implicit contract of image quality between the individual and the visualization system is upheld. OpenGL rendering of scientific visualizations has worked remarkably well for exploratory visualization for most solver results. This is due to the consistency between the use of first-order representations in the simulation and the linear assumptions inherent in OpenGL (planar fragments and color-space interpolation). Unfortunately, the contract is broken when the solver discretization is of higher-order. There have been attempts to mitigate this through the use of spatial adaptation and/or texture mapping. These methods do a better job of approximating what the imagery should be but are not exact and tend to be view-dependent. This paper introduces new rendering mechanisms that specifically deal with the kinds of native data generated by high-order finite element solvers. The exploratory visualization tools are reassessed and cast in this system with the focus on image accuracy. This is accomplished in a GPU setting to ensure interactivity.	Blake Nelson;Robert Michael Kirby;Robert Haimes	Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;	10.1109/VISUAL.2005.1532776;10.1109/VISUAL.2004.91;10.1109/TVCG.2006.154	High-order finite elements, spectral/hp elements, cut-plane extraction, GPU-based root-finding, GPU ray-tracing, cut-surface extraction	
Vis	2011	GPU-based Real-Time Approximation of the Ablation Zone for Radiofrequency Ablation	10.1109/TVCG.2011.207	http://dx.doi.org/10.1109/TVCG.2011.207	1812	1821	J	Percutaneous radiofrequency ablation (RFA) is becoming a standard minimally invasive clinical procedure for the treatment of liver tumors. However, planning the applicator placement such that the malignant tissue is completely destroyed, is a demanding task that requires considerable experience. In this work, we present a fast GPU-based real-time approximation of the ablation zone incorporating the cooling effect of liver vessels. Weighted distance fields of varying RF applicator types are derived from complex numerical simulations to allow a fast estimation of the ablation zone. Furthermore, the heat-sink effect of the cooling blood flow close to the applicator's electrode is estimated by means of a preprocessed thermal equilibrium representation of the liver parenchyma and blood vessels. Utilizing the graphics card, the weighted distance field incorporating the cooling blood flow is calculated using a modular shader framework, which facilitates the real-time visualization of the ablation zone in projected slice views and in volume rendering. The proposed methods are integrated in our software assistant prototype for planning RFA therapy. The software allows the physician to interactively place virtual RF applicator models. The real-time visualization of the corresponding approximated ablation zone facilitates interactive evaluation of the tumor coverage in order to optimize the applicator's placement such that all cancer cells are destroyed by the ablation.	Christian Rieder;Tim Kröger;Christian Schumann;Horst K. Hahn	;;;	10.1109/TVCG.2010.208;10.1109/VISUAL.1998.745311;10.1109/VISUAL.2000.885694	Radiofrequency ablation, ablation zone visualization, distance field, volume rendering, GPU, interaction	
Vis	2011	Hierarchical Event Selection for Video Storyboards with a Case Study on Snooker Video Visualization	10.1109/TVCG.2011.208	http://dx.doi.org/10.1109/TVCG.2011.208	1747	1756	J	Video storyboard, which is a form of video visualization, summarizes the major events in a video using illustrative visualization. There are three main technical challenges in creating a video storyboard, (a) event classification, (b) event selection and (c) event illustration. Among these challenges, (a) is highly application-dependent and requires a significant amount of application specific semantics to be encoded in a system or manually specified by users. This paper focuses on challenges (b) and (c). In particular, we present a framework for hierarchical event representation, and an importance-based selection algorithm for supporting the creation of a video storyboard from a video. We consider the storyboard to be an event summarization for the whole video, whilst each individual illustration on the board is also an event summarization but for a smaller time window. We utilized a 3D visualization template for depicting and annotating events in illustrations. To demonstrate the concepts and algorithms developed, we use Snooker video visualization as a case study, because it has a concrete and agreeable set of semantic definitions for events and can make use of existing techniques of event detection and 3D reconstruction in a reliable manner. Nevertheless, most of our concepts and algorithms developed for challenges (b) and (c) can be applied to other application areas.	Matthew L. Parry;Philip A. Legg;David H. S. Chung;Iwan W. Griffiths;Min Chen	Dept. of Comput. Sci., Swansea Univ., Swansea, UK|c|;;;;	10.1109/TVCG.2008.185;10.1109/INFVIS.2004.27;10.1109/VISUAL.2003.1250401;10.1109/TVCG.2007.70544;10.1109/TVCG.2006.194	Multimedia visualization, Time series data, Illustrative visualization	
Vis	2011	Image Plane Sweep Volume Illumination	10.1109/TVCG.2011.211	http://dx.doi.org/10.1109/TVCG.2011.211	2125	2134	J	In recent years, many volumetric illumination models have been proposed, which have the potential to simulate advanced lighting effects and thus support improved image comprehension. Although volume ray-casting is widely accepted as the volume rendering technique which achieves the highest image quality, so far no volumetric illumination algorithm has been designed to be directly incorporated into the ray-casting process. In this paper we propose image plane sweep volume illumination (IPSVI), which allows the integration of advanced illumination effects into a GPU-based volume ray-caster by exploiting the plane sweep paradigm. Thus, we are able to reduce the problem complexity and achieve interactive frame rates, while supporting scattering as well as shadowing. Since all illumination computations are performed directly within a single rendering pass, IPSVI does not require any preprocessing nor does it need to store intermediate results within an illumination volume. It therefore has a significantly lower memory footprint than other techniques. This makes IPSVI directly applicable to large data sets. Furthermore, the integration into a GPU-based ray-caster allows for high image quality as well as improved rendering performance by exploiting early ray termination. This paper discusses the theory behind IPSVI, describes its implementation, demonstrates its visual results and provides performance measurements.	Erik Sundén;Anders Ynnerman;Timo Ropinski	Sci. Visualization Group, Linkoping Univ., Linkoping, Sweden|c|;;	10.1109/TVCG.2011.161;10.1109/VISUAL.2002.1183761;10.1109/VISUAL.2003.1250394;10.1109/VISUAL.2002.1183764;10.1109/TVCG.2007.70573;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2009.164	Interactive volume rendering, GPU-based ray-casting, Advanced illumination	
Vis	2011	Interactive Multiscale Tensor Reconstruction for Multiresolution Volume Visualization	10.1109/TVCG.2011.214	http://dx.doi.org/10.1109/TVCG.2011.214	2135	2143	J	Large scale and structurally complex volume datasets from high-resolution 3D imaging devices or computational simulations pose a number of technical challenges for interactive visual analysis. In this paper, we present the first integration of a multiscale volume representation based on tensor approximation within a GPU-accelerated out-of-core multiresolution rendering framework. Specific contributions include (a) a hierarchical brick-tensor decomposition approach for pre-processing large volume data, (b) a GPU accelerated tensor reconstruction implementation exploiting CUDA capabilities, and (c) an effective tensor-specific quantization strategy for reducing data transfer bandwidth and out-of-core memory footprint. Our multiscale representation allows for the extraction, analysis and display of structural features at variable spatial scales, while adaptive level-of-detail rendering methods make it possible to interactively explore large datasets within a constrained memory footprint. The quality and performance of our prototype system is evaluated on large structurally complex datasets, including gigabyte-sized micro-tomographic volumes.	Susanne K. Suter;José Antonio Iglesias Guitián;Fabio Marton;Marco Agus;Andreas Elsener;Christoph P. E. Zollikofer;Meenakshisundaram Gopi;Enrico Gobbetti;Renato Pajarola	Univ. of Zurich, Zurich, Switzerland|c|;;;;;;;;	10.1109/VISUAL.2002.1183757;10.1109/VISUAL.1997.663900;10.1109/TVCG.2007.70516;10.1109/VISUAL.1998.745311;10.1109/TVCG.2006.146;10.1109/VISUAL.2003.1250385	GPU/CUDA, multiscale, tensor reconstruction, interactive volume visualization, multiresolution rendering	
Vis	2011	Interactive Virtual Probing of 4D MRI Blood-Flow	10.1109/TVCG.2011.215	http://dx.doi.org/10.1109/TVCG.2011.215	2153	2162	J	Better understanding of hemodynamics conceivably leads to improved diagnosis and prognosis of cardiovascular diseases. Therefore, an elaborate analysis of the blood-flow in heart and thoracic arteries is essential. Contemporary MRI techniques enable acquisition of quantitative time-resolved flow information, resulting in 4D velocity fields that capture the blood-flow behavior. Visual exploration of these fields provides comprehensive insight into the unsteady blood-flow behavior, and precedes a quantitative analysis of additional blood-flow parameters. The complete inspection requires accurate segmentation of anatomical structures, encompassing a time-consuming and hard-to-automate process, especially for malformed morphologies. We present a way to avoid the laborious segmentation process in case of qualitative inspection, by introducing an interactive virtual probe. This probe is positioned semi-automatically within the blood-flow field, and serves as a navigational object for visual exploration. The difficult task of determining position and orientation along the view-direction is automated by a fitting approach, aligning the probe with the orientations of the velocity field. The aligned probe provides an interactive seeding basis for various flow visualization approaches. We demonstrate illustration-inspired particles, integral lines and integral surfaces, conveying distinct characteristics of the unsteady blood-flow. Lastly, we present the results of an evaluation with domain experts, valuing the practical use of our probe and flow visualization techniques.	Roy van Pelt;Javier Oliván Bescós;Marcel Breeuwer;Rachel E. Clough;Eduard Gröller;Bart M. ter Haar Romeny;Anna Vilanova	Dept. of Biomed. Eng., Eindhoven Univ. of Technol., Eindhoven, Netherlands|c|;;;;;;	10.1109/VISUAL.1993.398849;10.1109/TVCG.2009.154;10.1109/TVCG.2010.173;10.1109/TVCG.2010.153;10.1109/TVCG.2007.70576;10.1109/TVCG.2008.133;10.1109/TVCG.2009.138;10.1109/VISUAL.2005.1532847;10.1109/TVCG.2010.166;10.1109/VISUAL.2005.1532857	Probing, Flow visualization, Illustrative visualization, Multivalued images, Phase-contrast cine MRI	
Vis	2011	Interactive Volume Visualization of General Polyhedral Grids	10.1109/TVCG.2011.216	http://dx.doi.org/10.1109/TVCG.2011.216	2115	2124	J	This paper presents a novel framework for visualizing volumetric data specified on complex polyhedral grids, without the need to perform any kind of a priori tetrahedralization. These grids are composed of polyhedra that often are non-convex and have an arbitrary number of faces, where the faces can be non-planar with an arbitrary number of vertices. The importance of such grids in state-of-the-art simulation packages is increasing rapidly. We propose a very compact, face-based data structure for representing such meshes for visualization, called two-sided face sequence lists (TSFSL), as well as an algorithm for direct GPU-based ray-casting using this representation. The TSFSL data structure is able to represent the entire mesh topology in a 1D TSFSL data array of face records, which facilitates the use of efficient 1D texture accesses for visualization. In order to scale to large data sizes, we employ a mesh decomposition into bricks that can be handled independently, where each brick is then composed of its own TSFSL array. This bricking enables memory savings and performance improvements for large meshes. We illustrate the feasibility of our approach with real-world application results, by visualizing highly complex polyhedral data from commercial state-of-the-art simulation packages.	Philipp Muigg;Markus Hadwiger;Helmut Doleisch;Eduard Gröller	Vienna Univ. of Technol., Vienna, Austria|c|;;;	10.1109/VISUAL.2005.1532796;10.1109/TVCG.2006.171;10.1109/TVCG.2007.70588;10.1109/VISUAL.2003.1250390;10.1109/VISUAL.2001.964514;10.1109/TVCG.2006.154;10.1109/VISUAL.2005.1532850;10.1109/VISUAL.2001.964511;10.1109/VISUAL.1999.809908	Volume rendering, unstructured grids, polyhedral grids, GPU-based visualization	
Vis	2011	Interactive, Graph-based Visual Analysis of High-dimensional, Multi-parameter Fluorescence Microscopy Data in Toponomics	10.1109/TVCG.2011.217	http://dx.doi.org/10.1109/TVCG.2011.217	1882	1891	J	In Toponomics, the function protein pattern in cells or tissue (the toponome) is imaged and analyzed for applications in toxicology, new drug development and patient-drug-interaction. The most advanced imaging technique is robot-driven multi-parameter fluorescence microscopy. This technique is capable of co-mapping hundreds of proteins and their distribution and assembly in protein clusters across a cell or tissue sample by running cycles of fluorescence tagging with monoclonal antibodies or other affinity reagents, imaging, and bleaching in situ. The imaging results in complex multi-parameter data composed of one slice or a 3D volume per affinity reagent. Biologists are particularly interested in the localization of co-occurring proteins, the frequency of co-occurrence and the distribution of co-occurring proteins across the cell. We present an interactive visual analysis approach for the evaluation of multi-parameter fluorescence microscopy data in toponomics. Multiple, linked views facilitate the definition of features by brushing multiple dimensions. The feature specification result is linked to all views establishing a focus+context visualization in 3D. In a new attribute view, we integrate techniques from graph visualization. Each node in the graph represents an affinity reagent while each edge represents two co-occurring affinity reagent bindings. The graph visualization is enhanced by glyphs which encode specific properties of the binding. The graph view is equipped with brushing facilities. By brushing in the spatial and attribute domain, the biologist achieves a better understanding of the function protein patterns of a cell. Furthermore, an interactive table view is integrated which summarizes unique fluorescence patterns. We discuss our approach with respect to a cell probe containing lymphocytes and a prostate tissue section.	Steffen Oeltze-Jafra;Wolfgang Freiler	Univ. of Magdeburg, Magdeburg, Germany|c|;;;;;	10.1109/VAST.2009.5333911;10.1109/TVCG.2006.195;10.1109/TVCG.2006.147;10.1109/TVCG.2007.70569;10.1109/TVCG.2009.167	Visual Analytics, Fluorescence Microscopy, Toponomics, Protein Interaction, Graph Visualization	
Vis	2011	iView: A Feature Clustering Framework for Suggesting Informative Views in Volume Visualization	10.1109/TVCG.2011.218	http://dx.doi.org/10.1109/TVCG.2011.218	1959	1968	J	The unguided visual exploration of volumetric data can be both a challenging and a time-consuming undertaking. Identifying a set of favorable vantage points at which to start exploratory expeditions can greatly reduce this effort and can also ensure that no important structures are being missed. Recent research efforts have focused on entropy-based viewpoint selection criteria that depend on scalar values describing the structures of interest. In contrast, we propose a viewpoint suggestion pipeline that is based on feature-clustering in high-dimensional space. We use gradient/normal variation as a metric to identify interesting local events and then cluster these via k-means to detect important salient composite features. Next, we compute the maximum possible exposure of these composite feature for different viewpoints and calculate a 2D entropy map parameterized in longitude and latitude to point out promising view orientations. Superimposed onto an interactive track-ball interface, users can then directly use this entropy map to quickly navigate to potentially interesting viewpoints where visibility-based transfer functions can be employed to generate volume renderings that minimize occlusions. To give full exploration freedom to the user, the entropy map is updated on the fly whenever a view has been selected, pointing to new and promising but so far unseen view directions. Alternatively, our system can also use a set-cover optimization algorithm to provide a minimal set of views needed to observe all features. The views so generated could then be saved into a list for further inspection or into a gallery for a summary presentation.	Ziyi Zheng;Nafees Ahmed;Klaus Mueller	Comput. Sci. Dept., Stony Brook Univ., Stony Brook, NY, USA|c|;;	10.1109/TVCG.2009.156;10.1109/TVCG.2007.70576;10.1109/TVCG.2008.162;10.1109/TVCG.2008.159;10.1109/TVCG.2010.214;10.1109/TVCG.2009.172;10.1109/VISUAL.2005.1532833;10.1109/VISUAL.2005.1532818;10.1109/TVCG.2006.124;10.1109/TVCG.2009.185;10.1109/TVCG.2009.189;10.1109/VISUAL.2003.1250414;10.1109/VISUAL.2005.1532834	Direct volume rendering, k-means, entropy, view suggestion, set-cover problem, ant colony optimization	
Vis	2011	Load-Balanced Parallel Streamline Generation on Large Scale Vector fields	10.1109/TVCG.2011.219	http://dx.doi.org/10.1109/TVCG.2011.219	1785	1794	J	Because of the ever increasing size of output data from scientific simulations, supercomputers are increasingly relied upon to generate visualizations. One use of supercomputers is to generate field lines from large scale flow fields. When generating field lines in parallel, the vector field is generally decomposed into blocks, which are then assigned to processors. Since various regions of the vector field can have different flow complexity, processors will require varying amounts of computation time to trace their particles, causing load imbalance, and thus limiting the performance speedup. To achieve load-balanced streamline generation, we propose a workload-aware partitioning algorithm to decompose the vector field into partitions with near equal workloads. Since actual workloads are unknown beforehand, we propose a workload estimation algorithm to predict the workload in the local vector field. A graph-based representation of the vector field is employed to generate these estimates. Once the workloads have been estimated, our partitioning algorithm is hierarchically applied to distribute the workload to all partitions. We examine the performance of our workload estimation and workload-aware partitioning algorithm in several timings studies, which demonstrates that by employing these methods, better scalability can be achieved with little overhead.	Boonthanome Nouanesengsy;Teng-Yok Lee;Han-Wei Shen	Ohio State Univ., Columbus, OH, USA|c|;;		Flow visualization, Parallel processing, 3D vector field visualization, Streamlines	
Vis	2011	Multi-Touch Table System for Medical Visualization: Application to Orthopedic Surgery Planning	10.1109/TVCG.2011.224	http://dx.doi.org/10.1109/TVCG.2011.224	1775	1784	J	Medical imaging plays a central role in a vast range of healthcare practices. The usefulness of 3D visualizations has been demonstrated for many types of treatment planning. Nevertheless, full access to 3D renderings outside of the radiology department is still scarce even for many image-centric specialties. Our work stems from the hypothesis that this under-utilization is partly due to existing visualization systems not taking the prerequisites of this application domain fully into account. We have developed a medical visualization table intended to better fit the clinical reality. The overall design goals were two-fold: similarity to a real physical situation and a very low learning threshold. This paper describes the development of the visualization table with focus on key design decisions. The developed features include two novel interaction components for touch tables. A user study including five orthopedic surgeons demonstrates that the system is appropriate and useful for this application domain.	Claes Lundström;Thomas Rydell;Camilla Forsell;Anders Persson;Anders Ynnerman	Center for Med. Image Sci. & Visualization, Linkoping Univ., Linkoping, Sweden|c|;;;;	10.1109/TVCG.2010.157;10.1109/VAST.2010.5652880;10.1109/TVCG.2006.146	Medical visualization, multi-touch, tabletop display, treatment planning	
Vis	2011	Nodes on Ropes: A Comprehensive Data and Control Flow for Steering Ensemble Simulations	10.1109/TVCG.2011.225	http://dx.doi.org/10.1109/TVCG.2011.225	1872	1881	J	Flood disasters are the most common natural risk and tremendous efforts are spent to improve their simulation and management. However, simulation-based investigation of actions that can be taken in case of flood emergencies is rarely done. This is in part due to the lack of a comprehensive framework which integrates and facilitates these efforts. In this paper, we tackle several problems which are related to steering a flood simulation. One issue is related to uncertainty. We need to account for uncertain knowledge about the environment, such as levee-breach locations. Furthermore, the steering process has to reveal how these uncertainties in the boundary conditions affect the confidence in the simulation outcome. Another important problem is that the simulation setup is often hidden in a black-box. We expose system internals and show that simulation steering can be comprehensible at the same time. This is important because the domain expert needs to be able to modify the simulation setup in order to include local knowledge and experience. In the proposed solution, users steer parameter studies through the World Lines interface to account for input uncertainties. The transport of steering information to the underlying data-flow components is handled by a novel meta-flow. The meta-flow is an extension to a standard data-flow network, comprising additional nodes and ropes to abstract parameter control. The meta-flow has a visual representation to inform the user about which control operations happen. Finally, we present the idea to use the data-flow diagram itself for visualizing steering information and simulation results. We discuss a case-study in collaboration with a domain expert who proposes different actions to protect a virtual city from imminent flooding. The key to choosing the best response strategy is the ability to compare different regions of the parameter space while retaining an understanding of what is happening inside the data-flow system.	Jürgen Waser;Hrvoje Ribicic;Raphael Fuchs;Christian Hirsch;Benjamin Schindler;Günter Blöschl;Eduard Gröller	VRVis Vienna, Vienna, Austria|c|;;;;;;	10.1109/TVCG.2010.223;10.1109/TVCG.2007.70584;10.1109/INFVIS.2002.1173149;10.1109/TVCG.2010.214;10.1109/INFVIS.2004.12;10.1109/VISUAL.2005.1532795;10.1109/TVCG.2009.195;10.1109/INFVIS.2005.1532143;10.1109/TVCG.2010.190;10.1109/TVCG.2010.223	Emergency/Disaster Management, Visual Knowledge Discovery, Visualization System and Toolkit Design, Data-Flow, Meta-Flow, Parameter Study, Uncertainty, Visualization of Control	
Vis	2011	Projection-Based Metal-Artifact Reduction for Industrial 3D X-ray Computed Tomography	10.1109/TVCG.2011.228	http://dx.doi.org/10.1109/TVCG.2011.228	2193	2202	J	Multi-material components, which contain metal parts surrounded by plastic materials, are highly interesting for inspection using industrial 3D X-ray computed tomography (3DXCT). Examples of this application scenario are connectors or housings with metal inlays in the electronic or automotive industry. A major problem of this type of components is the presence of metal, which causes streaking artifacts and distorts the surrounding media in the reconstructed volume. Streaking artifacts and dark-band artifacts around metal components significantly influence the material characterization (especially for the plastic components). In specific cases these artifacts even prevent a further analysis. Due to the nature and the different characteristics of artifacts, the development of an efficient artifact-reduction technique in reconstruction-space is rather complicated. In this paper we present a projection-space pipeline for metal-artifacts reduction. The proposed technique first segments the metal in the spatial domain of the reconstructed volume in order to separate it from the other materials. Then metal parts are forward-projected on the set of projections in a way that metal-projection regions are treated as voids. Subsequently the voids, which are left by the removed metal, are interpolated in the 2D projections. Finally, the metal is inserted back into the reconstructed 3D volume during the fusion stage. We present a visual analysis tool, allowing for interactive parameter estimation of the metal segmentation. The results of the proposed artifact-reduction technique are demonstrated on a test part as well as on real world components. For these specimens we achieve a significant reduction of metal artifacts, allowing an enhanced material characterization.	Artem Amirkhanov;Christoph Heinzl;Michael Reiter;Johann Kastner;Eduard Gröller	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Vienna, Austria|c|;;;;	10.1109/TVCG.2008.147;10.1109/VISUAL.2003.1250418	Metal-artifact reduction, multi-material components, visual analysis, 3D X-ray computed tomography	
Vis	2011	Quasi Interpolation With Voronoi Splines	10.1109/TVCG.2011.230	http://dx.doi.org/10.1109/TVCG.2011.230	1832	1841	J	We present a quasi interpolation framework that attains the optimal approximation-order of Voronoi splines for reconstruction of volumetric data sampled on general lattices. The quasi interpolation framework of Voronoi splines provides an unbiased reconstruction method across various lattices. Therefore this framework allows us to analyze and contrast the sampling-theoretic performance of general lattices, using signal reconstruction, in an unbiased manner. Our quasi interpolation methodology is implemented as an efficient FIR filter that can be applied online or as a preprocessing step. We present visual and numerical experiments that demonstrate the improved accuracy of reconstruction across lattices, using the quasi interpolation framework.	Mahsa Mirzargar;Alireza Entezari	;	10.1109/TVCG.2008.115;10.1109/VISUAL.2004.65;10.1109/TVCG.2007.70573;10.1109/VISUAL.2001.964498;10.1109/VISUAL.2005.1532810;10.1109/VISUAL.1997.663848;10.1109/VISUAL.1994.346331	Voronoi Spline, Quasi Interpolation, Volume Visualization, Box spline	
Vis	2011	Saliency-Assisted Navigation of Very Large Landscape Images	10.1109/TVCG.2011.231	http://dx.doi.org/10.1109/TVCG.2011.231	1737	1746	J	The field of visualization has addressed navigation of very large datasets, usually meshes and volumes. Significantly less attention has been devoted to the issues surrounding navigation of very large images. In the last few years the explosive growth in the resolution of camera sensors and robotic image acquisition techniques has widened the gap between the display and image resolutions to three orders of magnitude or more. This paper presents the first steps towards navigation of very large images, particularly landscape images, from an interactive visualization perspective. The grand challenge in navigation of very large images is identifying regions of potential interest. In this paper we outline a three-step approach. In the first step we use multi-scale saliency to narrow down the potential areas of interest. In the second step we outline a method based on statistical signatures to further cull out regions of high conformity. In the final step we allow a user to interactively identify the exceptional regions of high interest that merit further attention. We show that our approach of progressive elicitation is fast and allows rapid identification of regions of interest. Unlike previous work in this area, our approach is scalable and computationally reasonable on very large images. We validate the results of our approach by comparing them to user-tagged regions of interest on several very large landscape images from the Internet.	Cheuk Yiu Ip;Amitabh Varshney	Dept. of Comput. Sci., Univ. of Maryland, College Park, MD, USA|c|;	10.1109/TVCG.2010.132;10.1109/TVCG.2007.70557;10.1109/TVCG.2007.70615;10.1109/TVCG.2006.152;10.1109/VISUAL.2003.1250401;10.1109/TVCG.2006.174;10.1109/VISUAL.2005.1532833	Image Saliency, Very Large Scale Images, Scene Perception, Interactive Visualization, Anomaly Detection, Guided Interaction	
Vis	2011	Straightening Tubular Flow for Side-by-Side Visualization	10.1109/TVCG.2011.235	http://dx.doi.org/10.1109/TVCG.2011.235	2063	2070	J	Flows through tubular structures are common in many fields, including blood flow in medicine and tubular fluid flows in engineering. The analysis of such flows is often done with a strong reference to the main flow direction along the tubular boundary. In this paper we present an approach for straightening the visualization of tubular flow. By aligning the main reference direction of the flow, i.e., the center line of the bounding tubular structure, with one axis of the screen, we are able to natively juxtapose (1.) different visualizations of the same flow, either utilizing different flow visualization techniques, or by varying parameters of a chosen approach such as the choice of seeding locations for integration-based flow visualization, (2.) the different time steps of a time-dependent flow, (3.) different projections around the center line , and (4.) quantitative flow visualizations in immediate spatial relation to the more qualitative classical flow visualization. We describe how to utilize this approach for an informative interactive visual analysis. We demonstrate the potential of our approach by visualizing two datasets from two different fields: an arterial blood flow measurement and a tubular gas flow simulation from the automotive industry.	Paolo Angelelli;Helwig Hauser	;	10.1109/TVCG.2009.169;10.1109/TVCG.2010.218;10.1109/VISUAL.1996.568137;10.1109/VISUAL.2003.1250353;10.1109/TVCG.2010.153;10.1109/VISUAL.2001.964540;10.1109/TVCG.2009.136	Flow Visualization, Data Reformation, Comparative Visualization	
Vis	2011	Symmetry in Scalar field Topology	10.1109/TVCG.2011.236	http://dx.doi.org/10.1109/TVCG.2011.236	2035	2044	J	Study of symmetric or repeating patterns in scalar fields is important in scientific data analysis because it gives deep insights into the properties of the underlying phenomenon. Though geometric symmetry has been well studied within areas like shape processing, identifying symmetry in scalar fields has remained largely unexplored due to the high computational cost of the associated algorithms. We propose a computationally efficient algorithm for detecting symmetric patterns in a scalar field distribution by analysing the topology of level sets of the scalar field. Our algorithm computes the contour tree of a given scalar field and identifies subtrees that are similar. We define a robust similarity measure for comparing subtrees of the contour tree and use it to group similar subtrees together. Regions of the domain corresponding to subtrees that belong to a common group are extracted and reported to be symmetric. Identifying symmetry in scalar fields finds applications in visualization, data exploration, and feature detection. We describe two applications in detail: symmetry-aware transfer function design and symmetry-aware isosurface extraction.	Dilip Mathew Thomas;Vijay Natarajan	Dept. of Comput. Sci. & Autom., Indian Inst. of Sci., Bangalore, India|c|;	10.1109/TVCG.2008.143;10.1109/TVCG.2009.120;10.1109/TVCG.2007.70601	Scalar field symmetry, contour tree, similarity measure, persistence, isosurface extraction, transfer function design	
Vis	2011	The Effect of Colour and Transparency on the Perception of Overlaid Grids	10.1109/TVCG.2011.242	http://dx.doi.org/10.1109/TVCG.2011.242	1942	1948	J	Overlaid reference elements need to be sufficiently visible to effectively relate to the underlying information, but not so obtrusive that they clutter the presentation. We seek to create guidelines for presenting such structures through experimental studies to define boundary conditions for visual intrusiveness. We base our work on the practice of designers, who use transparency to integrate overlaid grids with their underlying imagery. Previous work discovered a useful range of alpha values for black or white grids overlayed on scatterplot images rendered in shades of gray over gray backgrounds of different lightness values. This work compares black grids to blue and red ones on different image types of scatterplots and maps. We expected that the coloured grids over grayscale images would be more visually salient than black ones, resulting in lower alpha values. Instead, we found that there was no significant difference between the boundaries set for red and black grids, but that the boundaries for blue grids were set consistently higher (more opaque). As in our previous study, alpha values are affected by image density rather than image type, and are consistently lower than many default settings. These results have implications for the design of subtle reference structures.	Lyn Bartram;Billy Cheung;Maureen C. Stone	;;	10.1109/TVCG.2007.70559;10.1109/TVCG.2006.180	Information visualization, automated presentation, applied perception, visual design, computational aesthetics	
Vis	2011	The FLOWLENS: A Focus-and-Context Visualization Approach for Exploration of Blood Flow in Cerebral Aneurysms	10.1109/TVCG.2011.243	http://dx.doi.org/10.1109/TVCG.2011.243	2183	2192	J	Blood flow and derived data are essential to investigate the initiation and progression of cerebral aneurysms as well as their risk of rupture. An effective visual exploration of several hemodynamic attributes like the wall shear stress (WSS) and the inflow jet is necessary to understand the hemodynamics. Moreover, the correlation between focus-and-context attributes is of particular interest. An expressive visualization of these attributes and anatomic information requires appropriate visualization techniques to minimize visual clutter and occlusions. We present the FLOWLENS as a focus-and-context approach that addresses these requirements. We group relevant hemodynamic attributes to pairs of focus-and-context attributes and assign them to different anatomic scopes. For each scope, we propose several FLOWLENS visualization templates to provide a flexible visual filtering of the involved hemodynamic pairs. A template consists of the visualization of the focus attribute and the additional depiction of the context attribute inside the lens. Furthermore, the FLOWLENS supports local probing and the exploration of attribute changes over time. The FLOWLENS minimizes visual cluttering, occlusions, and provides a flexible exploration of a region of interest. We have applied our approach to seven representative datasets, including steady and unsteady flow data from CFD simulations and 4D PC-MRI measurements. Informal user interviews with three domain experts confirm the usefulness of our approach.	Rocco Gasteiger;Mathias Neugebauer;Oliver Beuing;Bernhard Preim	Dept. of Simulation & Graphics, Univ. of Magdeburg, Magdeburg, Germany|c|;;;	10.1109/TVCG.2010.166;10.1109/TVCG.2009.138;10.1109/TVCG.2010.153;10.1109/TVCG.2006.124;10.1109/TVCG.2009.126;10.1109/VISUAL.2005.1532818	Flow Visualization, Focus-and-Context, Illustrative Rendering, Aneurysm	
Vis	2011	Topological Spines: A Structure-preserving Visual Representation of Scalar fields	10.1109/TVCG.2011.244	http://dx.doi.org/10.1109/TVCG.2011.244	1842	1851	J	We present topological spines-a new visual representation that preserves the topological and geometric structure of a scalar field. This representation encodes the spatial relationships of the extrema of a scalar field together with the local volume and nesting structure of the surrounding contours. Unlike other topological representations, such as contour trees, our approach preserves the local geometric structure of the scalar field, including structural cycles that are useful for exposing symmetries in the data. To obtain this representation, we describe a novel mechanism based on the extraction of extremum graphs-sparse subsets of the Morse-Smale complex that retain the important structural information without the clutter and occlusion problems that arise from visualizing the entire complex directly. Extremum graphs form a natural multiresolution structure that allows the user to suppress noise and enhance topological features via the specification of a persistence range. Applications of our approach include the visualization of 3D scalar fields without occlusion artifacts, and the exploratory analysis of high-dimensional functions.	Carlos D. Correa;Peter Lindstrom;Peer-Timo Bremer	Center for Appl. Sci. Comput. (CASC), Lawrence Livermore Nat. Lab., Livermore, CA, USA|c|;;	10.1109/VISUAL.2002.1183772;10.1109/TVCG.2007.70552;10.1109/TVCG.2007.70601;10.1109/VISUAL.2003.1250376;10.1109/TVCG.2009.163;10.1109/TVCG.2008.110;10.1109/TVCG.2010.213;10.1109/VISUAL.2005.1532839;10.1109/TVCG.2006.186	Scalar field topology, topological spine, extremum graph, Morse-Smale complex	
Vis	2011	Towards Robust Topology of Sparsely Sampled Data	10.1109/TVCG.2011.245	http://dx.doi.org/10.1109/TVCG.2011.245	1852	1861	J	Sparse, irregular sampling is becoming a necessity for reconstructing large and high-dimensional signals. However, the analysis of this type of data remains a challenge. One issue is the robust selection of neighborhoods - a crucial part of analytic tools such as topological decomposition, clustering and gradient estimation. When extracting the topology of sparsely sampled data, common neighborhood strategies such as k-nearest neighbors may lead to inaccurate results, either due to missing neighborhood connections, which introduce false extrema, or due to spurious connections, which conceal true extrema. Other neighborhoods, such as the Delaunay triangulation, are costly to compute and store even in relatively low dimensions. In this paper, we address these issues. We present two new types of neighborhood graphs: a variation on and a generalization of empty region graphs, which considerably improve the robustness of neighborhood-based analysis tools, such as topological decomposition. Our findings suggest that these neighborhood graphs lead to more accurate topological representations of low- and high- dimensional data sets at relatively low cost, both in terms of storage and computation time. We describe the implications of our work in the analysis and visualization of scalar functions, and provide general strategies for computing and applying our neighborhood graphs towards robust data analysis.	Carlos D. Correa;Peter Lindstrom	Center for Appl. Sci. Comput. (CASC), Lawrence Livermore Nat. Lab., Livermore, CA, USA|c|;	10.1109/VISUAL.2005.1532839;10.1109/TVCG.2010.213;10.1109/TVCG.2011.244;10.1109/VAST.2010.5652940;10.1109/VISUAL.1999.809932	Neighborhood graphs, topology, sparsely sampled data	
Vis	2011	TransGraph: Hierarchical Exploration of Transition Relationships in Time-Varying Volumetric Data	10.1109/TVCG.2011.246	http://dx.doi.org/10.1109/TVCG.2011.246	2015	2024	J	A fundamental challenge for time-varying volume data analysis and visualization is the lack of capability to observe and track data change or evolution in an occlusion-free, controllable, and adaptive fashion. In this paper, we propose to organize a timevarying data set into a hierarchy of states. By deriving transition probabilities among states, we construct a global map that captures the essential transition relationships in the time-varying data. We introduce the TransGraph, a graph-based representation to visualize hierarchical state transition relationships. The TransGraph not only provides a visual mapping that abstracts data evolution over time in different levels of detail, but also serves as a navigation tool that guides data exploration and tracking. The user interacts with the TransGraph and makes connection to the volumetric data through brushing and linking. A set of intuitive queries is provided to enable knowledge extraction from time-varying data. We test our approach with time-varying data sets of different characteristics and the results show that the TransGraph can effectively augment our ability in understanding time-varying data.	Yi Gu;Chaoli Wang	Dept. of Comput. Sci., Michigan Technol. Univ., Houghton, MA, USA|c|;	10.1109/TVCG.2008.119;10.1109/VISUAL.1994.346321;10.1109/VAST.2006.261451;10.1109/VISUAL.1999.809871;10.1109/TVCG.2006.165;10.1109/VISUAL.2003.1250401;10.1109/TVCG.2008.116;10.1109/TVCG.2010.190;10.1109/VISUAL.2003.1250402;10.1109/VISUAL.1995.480809;10.1109/TVCG.2008.140;10.1109/VISUAL.2001.964531;10.1109/TVCG.2009.200	Time-varying data visualization, hierarchical representation, states, transition relationship, user interface	
Vis	2011	Tuner: Principled Parameter finding for Image Segmentation Algorithms Using Visual Response Surface Exploration	10.1109/TVCG.2011.248	http://dx.doi.org/10.1109/TVCG.2011.248	1892	1901	J	In this paper we address the difficult problem of parameter-finding in image segmentation. We replace a tedious manual process that is often based on guess-work and luck by a principled approach that systematically explores the parameter space. Our core idea is the following two-stage technique: We start with a sparse sampling of the parameter space and apply a statistical model to estimate the response of the segmentation algorithm. The statistical model incorporates a model of uncertainty of the estimation which we use in conjunction with the actual estimate in (visually) guiding the user towards areas that need refinement by placing additional sample points. In the second stage the user navigates through the parameter space in order to determine areas where the response value (goodness of segmentation) is high. In our exploration we rely on existing ground-truth images in order to evaluate the "goodness" of an image segmentation technique. We evaluate its usefulness by demonstrating this technique on two image segmentation algorithms: a three parameter model to detect microtubules in electron tomograms and an eight parameter model to identify functional regions in dynamic Positron Emission Tomography scans.	Thomas Torsney-Weir;Ahmed Saad;Torsten Möller;Hans-Christian Hege;Britta Weber;Jean-Marc Verbavatz	Graphics, Usability, & Visualization Lab., Simon Fraser Univ., Burnaby, BC, Canada|c|;;;;;;	10.1109/TVCG.2007.70584;10.1109/TVCG.2008.119;10.1109/TVCG.2010.223;10.1109/TVCG.2010.190;10.1109/VISUAL.1994.346302;10.1109/TVCG.2010.130;10.1109/VISUAL.1993.398859;10.1109/VISUAL.1999.809871;10.1109/TVCG.2011.253;10.1109/VISUAL.2000.885678	Parameter exploration, Image segmentation, Gaussian Process Model	
Vis	2011	Two-Dimensional Time-Dependent Vortex Regions Based on the Acceleration Magnitude	10.1109/TVCG.2011.249	http://dx.doi.org/10.1109/TVCG.2011.249	2080	2087	J	Acceleration is a fundamental quantity of flow fields that captures Galilean invariant properties of particle motion. Considering the magnitude of this field, minima represent characteristic structures of the flow that can be classified as saddle- or vortex-like. We made the interesting observation that vortex-like minima are enclosed by particularly pronounced ridges. This makes it possible to define boundaries of vortex regions in a parameter-free way. Utilizing scalar field topology, a robust algorithm can be designed to extract such boundaries. They can be arbitrarily shaped. An efficient tracking algorithm allows us to display the temporal evolution of vortices. Various vortex models are used to evaluate the method. We apply our method to two-dimensional model systems from computational fluid dynamics and compare the results to those arising from existing definitions.	Jens Kasten;Jan Reininghaus;Ingrid Hotz;Hans-Christian Hege	Zuse Inst. Berlin, Berlin, Germany|c|;;;	10.1109/VISUAL.2005.1532830;10.1109/VISUAL.2004.107;10.1109/TVCG.2008.143;10.1109/VISUAL.2002.1183821;10.1109/TVCG.2006.201	Vortex regions, time-dependent flow fields, feature extraction	
Vis	2011	Visualization of AMR Data With Multi-Level Dual-Mesh Interpolation	10.1109/TVCG.2011.252	http://dx.doi.org/10.1109/TVCG.2011.252	1862	1871	J	We present a new technique for providing interpolation within cell-centered Adaptive Mesh Refinement (AMR) data that achieves C0 continuity throughout the 3D domain. Our technique improves on earlier work in that it does not require that adjacent patches differ by at most one refinement level. Our approach takes the dual of each mesh patch and generates "stitching cells" on the fly to fill the gaps between dual meshes. We demonstrate applications of our technique with data from Enzo, an AMR cosmological structure formation simulation code. We show ray-cast visualizations that include contributions from particle data (dark matter and stars, also output by Enzo) and gridded hydrodynamic data. We also show results from isosurface studies, including surfaces in regions where adjacent patches differ by more than one refinement level.	Patrick J. Moran;David Ellsworth	Ames Res. Center, NASA, Moffett Field, CA, USA|c|;	10.1109/VISUAL.1991.175782;10.1109/TVCG.2009.149;10.1109/VISUAL.2002.1183820	Adaptive mesh refinement, AMR, Enzo, interpolation, ray casting, isosurfaces, dual meshes, stitching cells	
Vis	2011	Visualization of Topological Structures in Area-Preserving Maps	10.1109/TVCG.2011.254	http://dx.doi.org/10.1109/TVCG.2011.254	1765	1774	J	Area-preserving maps are found across a wide range of scientific and engineering problems. Their study is made challenging by the significant computational effort typically required for their inspection but more fundamentally by the fractal complexity of salient structures. The visual inspection of these maps reveals a remarkable topological picture consisting of fixed (or periodic) points embedded in so-called island chains, invariant manifolds, and regions of ergodic behavior. This paper is concerned with the effective visualization and precise topological analysis of area-preserving maps with two degrees of freedom from numerical or analytical data. Specifically, a method is presented for the automatic extraction and characterization of fixed points and the computation of their invariant manifolds, also known as separatrices, to yield a complete picture of the structures present within the scale and complexity bounds selected by the user. This general approach offers a significant improvement over the visual representations that are so far available for area-preserving maps. The technique is demonstrated on a numerical simulation of magnetic confinement in a fusion reactor.	Xavier Tricoche;Christoph Garth;Allen R. Sanderson	Purdue Univ., West Lafayette, IN, USA|c|;;	10.1109/VISUAL.2005.1532839;10.1109/VISUAL.2003.1250376;10.1109/VISUAL.2004.107;10.1109/VISUAL.2000.885716;10.1109/TVCG.2007.70601;10.1109/TVCG.2010.133;10.1109/VISUAL.2005.1532770;10.1109/VISUAL.2002.1183786;10.1109/VISUAL.1994.346326	Poincare map, dynamical systems, topology, chaos, area-preserving maps, invariant manifolds	
Vis	2011	Volume Analysis Using Multimodal Surface Similarity	10.1109/TVCG.2011.258	http://dx.doi.org/10.1109/TVCG.2011.258	1969	1978	J	The combination of volume data acquired by multiple modalities has been recognized as an important but challenging task. Modalities often differ in the structures they can delineate and their joint information can be used to extend the classification space. However, they frequently exhibit differing types of artifacts which makes the process of exploiting the additional information non-trivial. In this paper, we present a framework based on an information-theoretic measure of isosurface similarity between different modalities to overcome these problems. The resulting similarity space provides a concise overview of the differences between the two modalities, and also serves as the basis for an improved selection of features. Multimodal classification is expressed in terms of similarities and dissimilarities between the isosurfaces of individual modalities, instead of data value combinations. We demonstrate that our approach can be used to robustly extract features in applications such as dual energy computed tomography of parts in industrial manufacturing.	Martin Haidacher;Stefan Bruckner;Eduard Gröller	Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Vienna, Austria|c|;;	10.1109/TVCG.2010.132;10.1109/TVCG.2006.168;10.1109/TVCG.2010.131;10.1109/TVCG.2006.152;10.1109/TVCG.2007.70598;10.1109/TVCG.2008.160;10.1109/TVCG.2010.182	Multimodal data, volume visualization, surface similarity	
Vis	2011	Voronoi-Based Extraction and Visualization of Molecular Paths	10.1109/TVCG.2011.259	http://dx.doi.org/10.1109/TVCG.2011.259	2025	2034	J	Visual analysis is widely used to study the behavior of molecules. Of particular interest are the analysis of molecular interactions and the investigation of binding sites. For large molecules, however, it is difficult to detect possible binding sites and paths leading to these sites by pure visual inspection. In this paper, we present new methods for the computation and visualization of potential molecular paths. Using a novel filtering method, we extract the significant paths from the Voronoi diagram of spheres. For the interactive visualization of molecules and their paths, we present several methods using deferred shading and other state-of-theart techniques. To allow for a fast overview of reachable regions of the molecule, we illuminate the molecular surface using a large number of light sources placed on the extracted paths. We also provide a method to compute the extension surface of selected paths and visualize it using the skin surface. Furthermore, we use the extension surface to clip the molecule to allow easy visual tracking of even deeply buried paths. The methods are applied to several proteins to demonstrate their usefulness.	Norbert Lindow;Daniel Baum;Hans-Christian Hege	Zuse Inst. Berlin, Berlin, Germany|c|;;	10.1109/TVCG.2010.218;10.1109/TVCG.2006.115;10.1109/TVCG.2009.157	Molecular visualization, data filtering, geometry-based techniques, view-dependent visualization	
Vis	2011	Vortex Visualization in Ultra Low Reynolds Number Insect Flight	10.1109/TVCG.2011.260	http://dx.doi.org/10.1109/TVCG.2011.260	2071	2079	J	We present the visual analysis of a biologically inspired CFD simulation of the deformable flapping wings of a dragonfly as it takes off and begins to maneuver, using vortex detection and integration-based flow lines. The additional seed placement and perceptual challenges introduced by having multiple dynamically deforming objects in the highly unsteady 3D flow domain are addressed. A brief overview of the high speed photogrammetry setup used to capture the dragonfly takeoff, parametric surfaces used for wing reconstruction, CFD solver and underlying flapping flight theory is presented to clarify the importance of several unsteady flight mechanisms, such as the leading edge vortex, that are captured visually. A novel interactive seed placement method is used to simplify the generation of seed curves that stay in the vicinity of relevant flow phenomena as they move with the flapping wings. This method allows a user to define and evaluate the quality of a seed's trajectory over time while working with a single time step. The seed curves are then used to place particles, streamlines and generalized streak lines. The novel concept of flowing seeds is also introduced in order to add visual context about the instantaneous vector fields surrounding smoothly animate streak lines. Tests show this method to be particularly effective at visually capturing vortices that move quickly or that exist for a very brief period of time. In addition, an automatic camera animation method is used to address occlusion issues caused when animating the immersed wing boundaries alongside many geometric flow lines. Each visualization method is presented at multiple time steps during the up-stroke and down-stroke to highlight the formation, attachment and shedding of the leading edge vortices in pairs of wings. Also, the visualizations show evidence of wake capture at stroke reversal which suggests the existence of previously unknown unsteady lift generation mechanisms that are unique to qua- wing insects.	Christopher Koehler;Thomas Wischgoll;Haibo Dong;Zachary Gaston	Eng. & Comput. Sci., Wright State Univ. Coll., Dayton, OH, USA|c|;;;	10.1109/VISUAL.2002.1183789;10.1109/VISUAL.2005.1532830;10.1109/TVCG.2007.70557;10.1109/VISUAL.2005.1532831;10.1109/TVCG.2008.163;10.1109/TVCG.2010.169;10.1109/VISUAL.2005.1532848;10.1109/VISUAL.2005.1532850;10.1109/TVCG.2010.212;10.1109/VISUAL.2000.885690;10.1109/TVCG.2010.198;10.1109/VISUAL.2004.113;10.1109/VISUAL.1998.745296;10.1109/TVCG.2007.70595;10.1109/TVCG.2009.190;10.1109/TVCG.2008.133;10.1109/TVCG.2006.199;10.1109/VISUAL.2002.1183821;10.1109/TVCG.2007.70545;10.1109/TVCG.2010.166;10.1109/TVCG.2006.201	Flow visualization, flowing seed points, streak lines, streamlines, insect flight, vortex visualization, unsteady flow	
Vis	2011	WYSIWYG (What You See is What You Get) Volume Visualization	10.1109/TVCG.2011.261	http://dx.doi.org/10.1109/TVCG.2011.261	2106	2114	J	In this paper, we propose a volume visualization system that accepts direct manipulation through a sketch-based What You See Is What You Get (WYSIWYG) approach. Similar to the operations in painting applications for 2D images, in our system, a full set of tools have been developed to enable direct volume rendering manipulation of color, transparency, contrast, brightness, and other optical properties by brushing a few strokes on top of the rendered volume image. To be able to smartly identify the targeted features of the volume, our system matches the sparse sketching input with the clustered features both in image space and volume space. To achieve interactivity, both special algorithms to accelerate the input identification and feature matching have been developed and implemented in our system. Without resorting to tuning transfer function parameters, our proposed system accepts sparse stroke inputs and provides users with intuitive, flexible and effective interaction during volume data exploration and visualization.	Hanqi Guo;Ningyu Mao;Xiaoru Yuan	Key Lab. of Machine Perception (Minist. of Educ.), Peking Univ., Beijing, China|c|;;	10.1109/TVCG.2010.145;10.1109/VISUAL.1998.745319;10.1109/TVCG.2008.120;10.1109/VISUAL.2003.1250414;10.1109/TVCG.2007.70591;10.1109/VISUAL.1996.568113;10.1109/TVCG.2009.189;10.1109/TVCG.2008.162;10.1109/VISUAL.2003.1250386;10.1109/VISUAL.2003.1250413;10.1109/VISUAL.2000.885694;10.1109/VISUAL.2005.1532856;10.1109/VISUAL.1997.663875;10.1109/TVCG.2006.148	Volume rendering, Sketching input, Human-computer interaction, Transfer functions, Feature space	
InfoVis	2012	A User Study on Curved Edges in Graph Visualization	10.1109/TVCG.2012.189	http://dx.doi.org/10.1109/TVCG.2012.189	2449	2456	J	Recently there has been increasing research interest in displaying graphs with curved edges to produce more readable visualizations. While there are several automatic techniques, little has been done to evaluate their effectiveness empirically. In this paper we present two experiments studying the impact of edge curvature on graph readability. The goal is to understand the advantages and disadvantages of using curved edges for common graph tasks compared to straight line segments, which are the conventional choice for showing edges in node-link diagrams. We included several edge variations: straight edges, edges with different curvature levels, and mixed straight and curved edges. During the experiments, participants were asked to complete network tasks including determination of connectivity, shortest path, node degree, and common neighbors. We also asked the participants to provide subjective ratings of the aesthetics of different edge types. The results show significant performance differences between the straight and curved edges and clear distinctions between variations of curved edges.	Kai Xu 0003;Chris Rooney;Peter J. Passmore;Dong-Han Ham;Phong H. Nguyen	Middlesex Univ., London, UK|c|;;;;	10.1109/TVCG.2011.233;10.1109/INFVIS.2002.1173155;10.1109/TVCG.2006.147;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.2005.1532131;10.1109/INFVIS.2003.1249008;10.1109/TVCG.2006.166	Graph, visualization, curved edges, evaluation	
InfoVis	2012	Adaptive Composite Map Projections	10.1109/TVCG.2012.192	http://dx.doi.org/10.1109/TVCG.2012.192	2575	2582	J	All major web mapping services use the web Mercator projection. This is a poor choice for maps of the entire globe or areas of the size of continents or larger countries because the Mercator projection shows medium and higher latitudes with extreme areal distortion and provides an erroneous impression of distances and relative areas. The web Mercator projection is also not able to show the entire globe, as polar latitudes cannot be mapped. When selecting an alternative projection for information visualization, rivaling factors have to be taken into account, such as map scale, the geographic area shown, the map's height-to-width ratio, and the type of cartographic visualization. It is impossible for a single map projection to meet the requirements for all these factors. The proposed composite map projection combines several projections that are recommended in cartographic literature and seamlessly morphs map space as the user changes map scale or the geographic region displayed. The composite projection adapts the map's geometry to scale, to the map's height-to-width ratio, and to the central latitude of the displayed area by replacing projections and adjusting their parameters. The composite projection shows the entire globe including poles; it portrays continents or larger countries with less distortion (optionally without areal distortion); and it can morph to the web Mercator projection for maps showing small regions.	Bernhard Jenny	Oregon State Univ., Corvallis, OR, USA|c|	10.1109/TVCG.2011.191;10.1109/TVCG.2010.191;10.1109/INFVIS.2000.885095	Multi-scale map, web mapping, web cartography, web map projection, web Mercator, HTML5 Canvas	
InfoVis	2012	Algorithms for Labeling Focus Regions	10.1109/TVCG.2012.193	http://dx.doi.org/10.1109/TVCG.2012.193	2583	2592	J	In this paper, we investigate the problem of labeling point sites in focus regions of maps or diagrams. This problem occurs, for example, when the user of a mapping service wants to see the names of restaurants or other POIs in a crowded downtown area but keep the overview over a larger area. Our approach is to place the labels at the boundary of the focus region and connect each site with its label by a linear connection, which is called a leader. In this way, we move labels from the focus region to the less valuable context region surrounding it. In order to make the leader layout well readable, we present algorithms that rule out crossings between leaders and optimize other characteristics such as total leader length and distance between labels. This yields a new variant of the boundary labeling problem, which has been studied in the literature. Other than in traditional boundary labeling, where leaders are usually schematized polylines, we focus on leaders that are either straight-line segments or Bezier curves. Further, we present algorithms that, given the sites, find a position of the focus region that optimizes the above characteristics. We also consider a variant of the problem where we have more sites than space for labels. In this situation, we assume that the sites are prioritized by the user. Alternatively, we take a new facility-location perspective which yields a clustering of the sites. We label one representative of each cluster. If the user wishes, we apply our approach to the sites within a cluster, giving details on demand.	Martin Fink 0001;Jan-Henrik Haunert;André Schulz 0001;Joachim Spoerhase;Alexander Wolff	Inst. fur Inf., Univ. Wurzburg, Wurzburg, Germany|c|;;;;	10.1109/TVCG.2011.191;10.1109/TVCG.2010.180;10.1109/TVCG.2011.183;10.1109/INFVIS.2000.885087	Focus+context techniques, data clustering, mobile and ubiquitous visualization, geographic/geospatial visualization	
InfoVis	2012	An Empirical Model of Slope Ratio Comparisons	10.1109/TVCG.2012.196	http://dx.doi.org/10.1109/TVCG.2012.196	2613	2620	J	Comparing slopes is a fundamental graph reading task and the aspect ratio chosen for a plot influences how easy these comparisons are to make. According to Banking to 45Â°, a classic design guideline first proposed and studied by Cleveland et al., aspect ratios that center slopes around 45Â° minimize errors in visual judgments of slope ratios. This paper revisits this earlier work. Through exploratory pilot studies that expand Cleveland et al.'s experimental design, we develop an empirical model of slope ratio estimation that fits more extreme slope ratio judgments and two common slope ratio estimation strategies. We then run two experiments to validate our model. In the first, we show that our model fits more generally than the one proposed by Cleveland et al. and we find that, in general, slope ratio errors are not minimized around 45Â°. In the second experiment, we explore a novel hypothesis raised by our model: that visible baselines can substantially mitigate errors made in slope judgments. We conclude with an application of our model to aspect ratio selection.	Justin Talbot;John Gerth;Pat Hanrahan	;;	10.1109/TVCG.2006.163;10.1109/TVCG.2011.167	Banking to 45 degrees, slope perception, orientation resolution, aspect ratio selection	
InfoVis	2012	An Empirical Study on Using Visual Embellishments in Visualization	10.1109/TVCG.2012.197	http://dx.doi.org/10.1109/TVCG.2012.197	2759	2768	J	In written and spoken communications, figures of speech (e.g., metaphors and synecdoche) are often used as an aid to help convey abstract or less tangible concepts. However, the benefits of using rhetorical illustrations or embellishments in visualization have so far been inconclusive. In this work, we report an empirical study to evaluate hypotheses that visual embellishments may aid memorization, visual search and concept comprehension. One major departure from related experiments in the literature is that we make use of a dual-task methodology in our experiment. This design offers an abstraction of typical situations where viewers do not have their full attention focused on visualization (e.g., in meetings and lectures). The secondary task introduces â€œdivided attentionâ€, and makes the effects of visual embellishments more observable. In addition, it also serves as additional masking in memory-based trials. The results of this study show that visual embellishments can help participants better remember the information depicted in visualization. On the other hand, visual embellishments can have a negative impact on the speed of visual search. The results show a complex pattern as to the benefits of visual embellishments in helping participants grasp key concepts from visualization.	Rita Borgo;Alfie Abdul-Rahman;Farhan Mohamed;Phil W. Grant;Irene Reppa;Luciano Floridi;Min Chen	Comput. Sci., Swansea Univ., Swansea, UK|c|;;;;;;	10.1109/TVCG.2010.132;10.1109/VISUAL.1996.568118;10.1109/TVCG.2008.171;10.1109/TVCG.2011.175	Visual embellishments, metaphors, icons, cognition, working memory, long-term memory, visual search, evaluation	
InfoVis	2012	Assessing the Effect of Visualizations on Bayesian Reasoning through Crowdsourcing	10.1109/TVCG.2012.199	http://dx.doi.org/10.1109/TVCG.2012.199	2536	2545	J	People have difficulty understanding statistical information and are unaware of their wrong judgments, particularly in Bayesian reasoning. Psychology studies suggest that the way Bayesian problems are represented can impact comprehension, but few visual designs have been evaluated and only populations with a specific background have been involved. In this study, a textual and six visual representations for three classic problems were compared using a diverse subject pool through crowdsourcing. Visualizations included area-proportional Euler diagrams, glyph representations, and hybrid diagrams combining both. Our study failed to replicate previous findings in that subjects' accuracy was remarkably lower and visualizations exhibited no measurable benefit. A second experiment confirmed that simply adding a visualization to a textual Bayesian problem is of little help, even when the text refers to the visualization, but suggests that visualizations are more effective when the text is given without numerical values. We discuss our findings and the need for more such experiments to be carried out on heterogeneous populations of non-experts.	Luana Micallef;Pierre Dragicevic;Jean-Daniel Fekete	INRIA, Sophia Antipolis, France|c|;;	10.1109/TVCG.2010.210;10.1109/TVCG.2009.122	Bayesian reasoning, base rate fallacy, probabilistic judgment, Euler diagrams, glyphs, crowdsourcing	
InfoVis	2012	Beyond Mouse and Keyboard: Expanding Design Considerations for Information Visualization Interactions	10.1109/TVCG.2012.204	http://dx.doi.org/10.1109/TVCG.2012.204	2689	2698	J	The importance of interaction to Information Visualization (InfoVis) and, in particular, of the interplay between interactivity and cognition is widely recognized [12, 15, 32, 55, 70]. This interplay, combined with the demands from increasingly large and complex datasets, is driving the increased significance of interaction in InfoVis. In parallel, there have been rapid advances in many facets of interaction technologies. However, InfoVis interactions have yet to take full advantage of these new possibilities in interaction technologies, as they largely still employ the traditional desktop, mouse, and keyboard setup of WIMP (Windows, Icons, Menus, and a Pointer) interfaces. In this paper, we reflect more broadly about the role of more â€œnaturalâ€ interactions for InfoVis and provide opportunities for future research. We discuss and relate general HCI interaction models to existing InfoVis interaction classifications by looking at interactions from a novel angle, taking into account the entire spectrum of interactions. Our discussion of InfoVis-specific interaction design considerations helps us identify a series of underexplored attributes of interaction that can lead to new, more â€œnatural,â€ interaction techniques for InfoVis.	Bongshin Lee;Petra Isenberg;Nathalie Henry Riche;M. Sheelagh T. Carpendale	;;;	10.1109/TVCG.2010.164;10.1109/TVCG.2007.70515;10.1109/TVCG.2008.121;10.1109/TVCG.2009.162;10.1109/TVCG.2010.206;10.1109/TVCG.2007.70582;10.1109/INFVIS.2005.1532122;10.1109/INFVIS.1998.729560;10.1109/TVCG.2007.70568	Design considerations, interaction, post-WIMP, NUI (Natural User Interface)	
InfoVis	2012	Capturing the Design Space of Sequential Space-filling Layouts	10.1109/TVCG.2012.205	http://dx.doi.org/10.1109/TVCG.2012.205	2593	2602	J	We characterize the design space of the algorithms that sequentially tile a rectangular area with smaller, fixed-surface, rectangles. This space consist of five independent dimensions: Order, Size, Score, Recurse and Phrase. Each of these dimensions describe a particular aspect of such layout tasks. This class of layouts is interesting, because, beyond encompassing simple grids, tables and trees, it also includes all kinds of treemaps involving the placement of rectangles. For instance, Slice and dice, Squarified, Strip and Pivot layouts are various points in this five dimensional space. Many classic statistics visualizations, such as 100% stacked bar charts, mosaic plots and dimensional stacking, are also instances of this class. A few new and potentially interesting points in this space are introduced, such as spiral treemaps and variations on the strip layout. The core algorithm is implemented as a JavaScript prototype that can be used as a layout component in a variety of InfoViz toolkits.	Thomas Baudel;Bertjan Broeksema	;	10.1109/VISUAL.1991.175815;10.1109/TVCG.2006.178;10.1109/VISUAL.1990.146386;10.1109/TVCG.2006.200;10.1109/TVCG.2011.227;10.1109/INFVIS.1998.729560;10.1109/TVCG.2010.186;10.1109/TVCG.2008.165;10.1109/TVCG.2009.128	Layout, visualization models, tables & tree layouts, grids, treemaps, mosaic plots, dimensional stacking	
InfoVis	2012	Comparing Clusterings Using Bertin's Idea	10.1109/TVCG.2012.207	http://dx.doi.org/10.1109/TVCG.2012.207	2506	2515	J	Classifying a set of objects into clusters can be done in numerous ways, producing different results. They can be visually compared using contingency tables [27], mosaicplots [13], fluctuation diagrams [15], tableplots [20] , (modified) parallel coordinates plots [28], Parallel Sets plots [18] or circos diagrams [19]. Unfortunately the interpretability of all these graphical displays decreases rapidly with the numbers of categories and clusterings. In his famous book A Semiology of Graphics [5] Bertin writes â€œthe discovery of an ordered concept appears as the ultimate point in logical simplification since it permits reducing to a single instant the assimilation of series which previously required many instants of studyâ€. Or in more everyday language, if you use good orderings you can see results immediately that with other orderings might take a lot of effort. This is also related to the idea of effect ordering [12], that data should be organised to reflect the effect you want to observe. This paper presents an efficient algorithm based on Bertin's idea and concepts related to Kendall's t [17], which finds informative joint orders for two or more nominal classification variables. We also show how these orderings improve the various displays and how groups of corresponding categories can be detected using a top-down partitioning algorithm. Different clusterings based on data on the environmental performance of cars sold in Germany are used for illustration. All presented methods are available in the R package extracat which is used to compute the optimized orderings for the example dataset.	Alexander Pilhofer;Alexander Gribov;Antony Unwin	Univ. of Augsburg, Augsburg, Germany|c|;;	10.1109/TVCG.2010.184;10.1109/TVCG.2010.138	Order optimization, fluctuation diagrams, classification, seriation	
InfoVis	2012	Compressed Adjacency Matrices: Untangling Gene Regulatory Networks	10.1109/TVCG.2012.208	http://dx.doi.org/10.1109/TVCG.2012.208	2457	2466	J	We present a novel technique-Compressed Adjacency Matrices-for visualizing gene regulatory networks. These directed networks have strong structural characteristics: out-degrees with a scale-free distribution, in-degrees bound by a low maximum, and few and small cycles. Standard visualization techniques, such as node-link diagrams and adjacency matrices, are impeded by these network characteristics. The scale-free distribution of out-degrees causes a high number of intersecting edges in node-link diagrams. Adjacency matrices become space-inefficient due to the low in-degrees and the resulting sparse network. Compressed adjacency matrices, however, exploit these structural characteristics. By cutting open and rearranging an adjacency matrix, we achieve a compact and neatly-arranged visualization. Compressed adjacency matrices allow for easy detection of subnetworks with a specific structure, so-called motifs, which provide important knowledge about gene regulatory networks to domain experts. We summarize motifs commonly referred to in the literature, and relate them to network analysis tasks common to the visualization domain. We show that a user can easily find the important motifs in compressed adjacency matrices, and that this is hard in standard adjacency matrix and node-link diagrams. We also demonstrate that interaction techniques for standard adjacency matrices can be used for our compressed variant. These techniques include rearrangement clustering, highlighting, and filtering.	Kasper Dinkla;Michel A. Westenberg;Jarke J. van Wijk	;;	10.1109/TVCG.2011.187;10.1109/TVCG.2006.160;10.1109/TVCG.2007.70582;10.1109/INFVIS.2004.1;10.1109/INFVIS.2005.1532126;10.1109/INFVIS.2004.46;10.1109/TVCG.2006.147;10.1109/TVCG.2008.141;10.1109/TVCG.2007.70556;10.1109/INFVIS.2004.5;10.1109/TVCG.2006.156;10.1109/TVCG.2010.159;10.1109/INFVIS.2003.1249030	Network, gene regulation, scale-free, adjacency matrix	
InfoVis	2012	Design Considerations for Optimizing Storyline Visualizations	10.1109/TVCG.2012.212	http://dx.doi.org/10.1109/TVCG.2012.212	2679	2688	J	Storyline visualization is a technique used to depict the temporal dynamics of social interactions. This visualization technique was first introduced as a hand-drawn illustration in XKCD's â€œMovie Narrative Chartsâ€ [21]. If properly constructed, the visualization can convey both global trends and local interactions in the data. However, previous methods for automating storyline visualizations are overly simple, failing to achieve some of the essential principles practiced by professional illustrators. This paper presents a set of design considerations for generating aesthetically pleasing and legible storyline visualizations. Our layout algorithm is based on evolutionary computation, allowing us to effectively incorporate multiple objective functions. We show that the resulting visualizations have significantly improved aesthetics and legibility compared to existing techniques.	Yuzuru Tanahashi;Kwan-Liu Ma	ViDi Res. Group, Univ. of California, Davis, CA, USA|c|;	10.1109/TVCG.2008.166;10.1109/TVCG.2008.135;10.1109/TVCG.2011.190;10.1109/TVCG.2011.239;10.1109/TVCG.2006.193;10.1109/TVCG.2007.70535;10.1109/INFVIS.2003.1249008;10.1109/TVCG.2008.125;10.1109/INFVIS.2002.1173160	Layout algorithm, timeline visualization, storyline visualization, design study	
InfoVis	2012	Design Study Methodology: Reflections from the Trenches and the Stacks	10.1109/TVCG.2012.213	http://dx.doi.org/10.1109/TVCG.2012.213	2431	2440	J	Design studies are an increasingly popular form of problem-driven visualization research, yet there is little guidance available about how to do them effectively. In this paper we reflect on our combined experience of conducting twenty-one design studies, as well as reading and reviewing many more, and on an extensive literature review of other field work methods and methodologies. Based on this foundation we provide definitions, propose a methodological framework, and provide practical guidance for conducting design studies. We define a design study as a project in which visualization researchers analyze a specific real-world problem faced by domain experts, design a visualization system that supports solving this problem, validate the design, and reflect about lessons learned in order to refine visualization design guidelines. We characterize two axes - a task clarity axis from fuzzy to crisp and an information location axis from the domain expert's head to the computer - and use these axes to reason about design study contributions, their suitability, and uniqueness from other approaches. The proposed methodological framework consists of 9 stages: learn, winnow, cast, discover, design, implement, deploy, reflect, and write. For each stage we provide practical guidance and outline potential pitfalls. We also conducted an extensive literature survey of related methodological approaches that involve a significant amount of qualitative field work, and compare design study methodology to that of ethnography, grounded theory, and action research.	Michael Sedlmair;Miriah D. Meyer;Tamara Munzner	;;	10.1109/INFVIS.1999.801869;10.1109/INFVIS.1996.559226;10.1109/TVCG.2008.117;10.1109/TVCG.2009.152;10.1109/TVCG.2010.206;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2010.193;10.1109/VAST.2011.6102443;10.1109/TVCG.2011.174;10.1109/VAST.2007.4389008;10.1109/TVCG.2009.116;10.1109/TVCG.2011.192;10.1109/TVCG.2009.128;10.1109/INFVIS.2003.1249023;10.1109/TVCG.2009.167;10.1109/TVCG.2009.111;10.1109/TVCG.2011.209	Design study, methodology, visualization, framework	
InfoVis	2012	Different Strokes for Different Folks: Visual Presentation Design between Disciplines	10.1109/TVCG.2012.214	http://dx.doi.org/10.1109/TVCG.2012.214	2411	2420	J	We present an ethnographic study of design differences in visual presentations between academic disciplines. Characterizing design conventions between users and data domains is an important step in developing hypotheses, tools, and design guidelines for information visualization. In this paper, disciplines are compared at a coarse scale between four groups of fields: social, natural, and formal sciences; and the humanities. Two commonplace presentation types were analyzed: electronic slideshows and whiteboard â€œchalk talksâ€. We found design differences in slideshows using two methods - coding and comparing manually-selected features, like charts and diagrams, and an image-based analysis using PCA called eigenslides. In whiteboard talks with controlled topics, we observed design behaviors, including using representations and formalisms from a participant's own discipline, that suggest authors might benefit from novel assistive tools for designing presentations. Based on these findings, we discuss opportunities for visualization ethnography and human-centered authoring tools for visual information.	Steven R. Gomez;Radu Jianu;Caroline Ziemkiewicz;Hua Guo;David H. Laidlaw	Brown Univ., Providence, RI, USA|c|;;;;	10.1109/TVCG.2011.251;10.1109/TVCG.2010.177;10.1109/TVCG.2010.179;10.1109/TVCG.2011.255	Presentations, information visualization, design, visual analysis	
InfoVis	2012	Does an Eye Tracker Tell the Truth about Visualizations?: findings while Investigating Visualizations for Decision Making	10.1109/TVCG.2012.215	http://dx.doi.org/10.1109/TVCG.2012.215	2421	2430	J	For information visualization researchers, eye tracking has been a useful tool to investigate research participants' underlying cognitive processes by tracking their eye movements while they interact with visual techniques. We used an eye tracker to better understand why participants with a variant of a tabular visualization called `SimulSort' outperformed ones with a conventional table and typical one-column sorting feature (i.e., Typical Sorting). The collected eye-tracking data certainly shed light on the detailed cognitive processes of the participants; SimulSort helped with decision-making tasks by promoting efficient browsing behavior and compensatory decision-making strategies. However, more interestingly, we also found unexpected eye-tracking patterns with Simul- Sort. We investigated the cause of the unexpected patterns through a crowdsourcing-based study (i.e., Experiment 2), which elicited an important limitation of the eye tracking method: incapability of capturing peripheral vision. This particular result would be a caveat for other visualization researchers who plan to use an eye tracker in their studies. In addition, the method to use a testing stimulus (i.e., influential column) in Experiment 2 to verify the existence of such limitations would be useful for researchers who would like to verify their eye tracking results.	Sung-Hee Kim;Zhihua Dong;Hanjun Xian;Benjavan Upatising;Ji Soo Yi	Sch. ofIndustrial Eng., Purdue Univ., West Lafayette, IN, USA|c|;;;;	10.1109/VISUAL.1990.146402;10.1109/TVCG.2011.193;10.1109/VAST.2008.4677363;10.1109/TVCG.2010.149;10.1109/TVCG.2011.183;10.1109/VAST.2009.5333920	Visualized decision making, eye tracking, crowdsourcing, quantitative empirical study, limitations, peripheral vision	
InfoVis	2012	Evaluating Sketchiness as a Visual Variable for the Depiction of Qualitative Uncertainty	10.1109/TVCG.2012.220	http://dx.doi.org/10.1109/TVCG.2012.220	2769	2778	J	We report on results of a series of user studies on the perception of four visual variables that are commonly used in the literature to depict uncertainty. To the best of our knowledge, we provide the first formal evaluation of the use of these variables to facilitate an easier reading of uncertainty in visualizations that rely on line graphical primitives. In addition to blur, dashing and grayscale, we investigate the use of `sketchiness' as a visual variable because it conveys visual impreciseness that may be associated with data quality. Inspired by work in non-photorealistic rendering and by the features of hand-drawn lines, we generate line trajectories that resemble hand-drawn strokes of various levels of proficiency-ranging from child to adult strokes-where the amount of perturbations in the line corresponds to the level of uncertainty in the data. Our results show that sketchiness is a viable alternative for the visualization of uncertainty in lines and is as intuitive as blur; although people subjectively prefer dashing style over blur, grayscale and sketchiness. We discuss advantages and limitations of each technique and conclude with design considerations on how to deploy these visual variables to effectively depict various levels of uncertainty for line marks.	Nadia Boukhelifa;Anastasia Bezerianos;Tobias Isenberg 0001;Jean-Daniel Fekete	INRIA, Sophia Antipolis, France|c|;;;	10.1109/VISUAL.2005.1532853;10.1109/VISUAL.1992.235199;10.1109/TVCG.2007.70530;10.1109/TVCG.2009.114;10.1109/VAST.2009.5332611;10.1109/VAST.2006.261424;10.1109/TVCG.2012.262;10.1109/TVCG.2007.70589;10.1109/VISUAL.2000.885679	Uncertainty visualization, qualitative evaluation, quantitative evaluation, perception	
InfoVis	2012	Evaluating the Effect of Style in Information Visualization	10.1109/TVCG.2012.221	http://dx.doi.org/10.1109/TVCG.2012.221	2739	2748	J	This paper reports on a between-subject, comparative online study of three information visualization demonstrators that each displayed the same dataset by way of an identical scatterplot technique, yet were different in style in terms of visual and interactive embellishment. We validated stylistic adherence and integrity through a separate experiment in which a small cohort of participants assigned our three demonstrators to predefined groups of stylistic examples, after which they described the styles with their own words. From the online study, we discovered significant differences in how participants execute specific interaction operations, and the types of insights that followed from them. However, in spite of significant differences in apparent usability, enjoyability and usefulness between the style demonstrators, no variation was found on the self-reported depth, expert-rated depth, confidence or difficulty of the resulting insights. Three different methods of insight analysis have been applied, revealing how style impacts the creation of insights, ranging from higher-level pattern seeking to a more reflective and interpretative engagement with content, which is what underlies the patterns. As this study only forms the first step in determining how the impact of style in information visualization could be best evaluated, we propose several guidelines and tips on how to gather, compare and categorize insights through an online evaluation study, particularly in terms of analyzing the concise, yet wide variety of insights and observations in a trustworthy and reproducable manner.	Andrew Vande Moere;Martin Tomitsch;Christoph Wimmer;Christoph Bösch;Thomas Grechenig	;;;;	10.1109/TVCG.2007.70541;10.1109/TVCG.2007.70577;10.1109/TVCG.2009.122	Visualization, design, style, aesthetics, evaluation, online study, user experience	
InfoVis	2012	Exploring Flow, Factors, and Outcomes of Temporal Event Sequences with the Outflow Visualization	10.1109/TVCG.2012.225	http://dx.doi.org/10.1109/TVCG.2012.225	2659	2668	J	Event sequence data is common in many domains, ranging from electronic medical records (EMRs) to sports events. Moreover, such sequences often result in measurable outcomes (e.g., life or death, win or loss). Collections of event sequences can be aggregated together to form event progression pathways. These pathways can then be connected with outcomes to model how alternative chains of events may lead to different results. This paper describes the Outflow visualization technique, designed to (1) aggregate multiple event sequences, (2) display the aggregate pathways through different event states with timing and cardinality, (3) summarize the pathways' corresponding outcomes, and (4) allow users to explore external factors that correlate with specific pathway state transitions. Results from a user study with twelve participants show that users were able to learn how to use Outflow easily with limited training and perform a range of tasks both accurately and rapidly.	Krist Wongsuphasawat;David Gotz	Univ. of Maryland, College Park, MD, USA|c|;	10.1109/TVCG.2009.181;10.1109/VAST.2011.6102453;10.1109/TVCG.2006.192;10.1109/INFVIS.2005.1532150;10.1109/VAST.2009.5332595;10.1109/TVCG.2009.117;10.1109/INFVIS.2005.1532152;10.1109/VAST.2006.261421	Outflow, information visualization, temporal event sequences, state diagram, state transition	
InfoVis	2012	Facilitating Discourse Analysis with Interactive Visualization	10.1109/TVCG.2012.226	http://dx.doi.org/10.1109/TVCG.2012.226	2639	2648	J	A discourse parser is a natural language processing system which can represent the organization of a document based on a rhetorical structure tree-one of the key data structures enabling applications such as text summarization, question answering and dialogue generation. Computational linguistics researchers currently rely on manually exploring and comparing the discourse structures to get intuitions for improving parsing algorithms. In this paper, we present DAViewer, an interactive visualization system for assisting computational linguistics researchers to explore, compare, evaluate and annotate the results of discourse parsers. An iterative user-centered design process with domain experts was conducted in the development of DAViewer. We report the results of an informal formative study of the system to better understand how the proposed visualization and interaction techniques are used in the real research environment.	Jian Zhao;Fanny Chevalier;Christopher Collins;Ravin Balakrishnan	Univ. of Toronto, Toronto, ON, Canada|c|;;;	10.1109/VAST.2011.6102439;10.1109/TVCG.2007.70529;10.1109/TVCG.2009.122;10.1109/INFVIS.1999.801869;10.1109/INFVIS.2003.1249030	Discourse structure, tree comparison, computational linguisitics, visual analytics, interaction techniques	
InfoVis	2012	Graphical Overlays: Using Layered Elements to Aid Chart Reading	10.1109/TVCG.2012.229	http://dx.doi.org/10.1109/TVCG.2012.229	2631	2638	J	Reading a visualization can involve a number of tasks such as extracting, comparing or aggregating numerical values. Yet, most of the charts that are published in newspapers, reports, books, and on the Web only support a subset of these tasks. In this paper we introduce graphical overlays-visual elements that are layered onto charts to facilitate a larger set of chart reading tasks. These overlays directly support the lower-level perceptual and cognitive processes that viewers must perform to read a chart. We identify five main types of overlays that support these processes; the overlays can provide (1) reference structures such as gridlines, (2) highlights such as outlines around important marks, (3) redundant encodings such as numerical data labels, (4) summary statistics such as the mean or max and (5) annotations such as descriptive text for context. We then present an automated system that applies user-chosen graphical overlays to existing chart bitmaps. Our approach is based on the insight that generating most of these graphical overlays only requires knowing the properties of the visual marks and axes that encode the data, but does not require access to the underlying data values. Thus, our system analyzes the chart bitmap to extract only the properties necessary to generate the desired overlay. We also discuss techniques for generating interactive overlays that provide additional controls to viewers. We demonstrate several examples of each overlay type for bar, pie and line charts.	Nicholas Kong;Maneesh Agrawala	Comput. Sci. Div., UC Berkeley, Berkeley, CO, USA|c|;	10.1109/TVCG.2011.242;10.1109/VISUAL.1991.175820;10.1109/TVCG.2009.122;10.1109/TVCG.2011.183	Visualization, overlays, graphical perception, graph comprehension	
InfoVis	2012	Graphical Tests for Power Comparison of Competing Designs	10.1109/TVCG.2012.230	http://dx.doi.org/10.1109/TVCG.2012.230	2441	2448	J	Lineups [4, 28] have been established as tools for visual testing similar to standard statistical inference tests, allowing us to evaluate the validity of graphical findings in an objective manner. In simulation studies [12] lineups have been shown as being efficient: the power of visual tests is comparable to classical tests while being much less stringent in terms of distributional assumptions made. This makes lineups versatile, yet powerful, tools in situations where conditions for regular statistical tests are not or cannot be met. In this paper we introduce lineups as a tool for evaluating the power of competing graphical designs. We highlight some of the theoretical properties and then show results from two studies evaluating competing designs: both studies are designed to go to the limits of our perceptual abilities to highlight differences between designs. We use both accuracy and speed of evaluation as measures of a successful design. The first study compares the choice of coordinate system: polar versus cartesian coordinates. The results show strong support in favor of cartesian coordinates in finding fast and accurate answers to spotting patterns. The second study is aimed at finding shift differences between distributions. Both studies are motivated by data problems that we have recently encountered, and explore using simulated data to evaluate the plot designs under controlled conditions. Amazon Mechanical Turk (MTurk) is used to conduct the studies. The lineups provide an effective mechanism for objectively evaluating plot designs.	Heike Hofmann;Lendie Follett;Mahbubul Majumder;Dianne Cook	Stat., Iowa State Univ., Ames, IA, USA|c|;;;	10.1109/TVCG.2009.111;10.1109/TVCG.2010.161	Lineups, Visual inference, Power comparison, Efficiency of displays	
InfoVis	2012	How Capacity Limits of Attention Influence Information Visualization Effectiveness	10.1109/TVCG.2012.233	http://dx.doi.org/10.1109/TVCG.2012.233	2402	2410	J	In this paper, we explore how the capacity limits of attention influence the effectiveness of information visualizations. We conducted a series of experiments to test how visual feature type (color vs. motion), layout, and variety of visual elements impacted user performance. The experiments tested users' abilities to (1) determine if a specified target is on the screen, (2) detect an odd-ball, deviant target, different from the other visible objects, and (3) gain a qualitative overview by judging the number of unique categories on the screen. Our results show that the severe capacity limits of attention strongly modulate the effectiveness of information visualizations, particularly the ability to detect unexpected information. Keeping in mind these capacity limits, we conclude with a set of design guidelines which depend on a visualization's intended use.	Steve Haroz;David Whitney	Univ. of California, Davis, CA, USA|c|;	10.1109/INFVIS.2001.963274;10.1109/VISUAL.1996.568118;10.1109/TVCG.2010.186;10.1109/VISUAL.2005.1532838	Perception, attention, color, motion, user study, nominal axis, layout, goal-oriented design	
InfoVis	2012	Intelligent Graph Layout Using Many Users' Input	10.1109/TVCG.2012.236	http://dx.doi.org/10.1109/TVCG.2012.236	2699	2708	J	In this paper, we propose a new strategy for graph drawing utilizing layouts of many sub-graphs supplied by a large group of people in a crowd sourcing manner. We developed an algorithm based on Laplacian constrained distance embedding to merge subgraphs submitted by different users, while attempting to maintain the topological information of the individual input layouts. To facilitate collection of layouts from many people, a light-weight interactive system has been designed to enable convenient dynamic viewing, modification and traversing between layouts. Compared with other existing graph layout algorithms, our approach can achieve more aesthetic and meaningful layouts with high user preference.	Xiaoru Yuan;Limei Che;Yifan Hu;Xin Zhang	Key Lab. of Machine Perception (Minist. of Educ.), Peking Univ., Beijing, China|c|;;;	10.1109/TVCG.2008.155;10.1109/INFVIS.2005.1532130;10.1109/TVCG.2009.109;10.1109/TVCG.2007.70580	Graph layout, Laplacian matrix, force directed layout, stress model, merging, editing, crowd sourcing	
InfoVis	2012	Interaction Support for Visual Comparison Inspired by Natural Behavior	10.1109/TVCG.2012.237	http://dx.doi.org/10.1109/TVCG.2012.237	2719	2728	J	Visual comparison is an intrinsic part of interactive data exploration and analysis. The literature provides a large body of existing solutions that help users accomplish comparison tasks. These solutions are mostly of visual nature and custom-made for specific data. We ask the question if a more general support is possible by focusing on the interaction aspect of comparison tasks. As an answer to this question, we propose a novel interaction concept that is inspired by real-world behavior of people comparing information printed on paper. In line with real-world interaction, our approach supports users (1) in interactively specifying pieces of graphical information to be compared, (2) in flexibly arranging these pieces on the screen, and (3) in performing the actual comparison of side-by-side and overlapping arrangements of the graphical information. Complementary visual cues and add-ons further assist users in carrying out comparison tasks. Our concept and the integrated interaction techniques are generally applicable and can be coupled with different visualization techniques. We implemented an interactive prototype and conducted a qualitative user study to assess the concept's usefulness in the context of three different visualization techniques. The obtained feedback indicates that our interaction techniques mimic the natural behavior quite well, can be learned quickly, and are easy to apply to visual comparison tasks.	Christian Tominski;Camilla Forsell;Jimmy Johansson	Univ. of Rostock, Rostock, Germany|c|;;	10.1109/TVCG.2008.109;10.1109/TVCG.2007.70568;10.1109/TVCG.2011.201;10.1109/TVCG.2007.70515;10.1109/TVCG.2007.70623;10.1109/TVCG.2009.151;10.1109/INFVIS.2002.1173157;10.1109/TVCG.2011.223;10.1109/TVCG.2007.70582;10.1109/TVCG.2008.153	Interaction techniques, visual comparison, visualization, human-computer interaction, natural interaction	
InfoVis	2012	Interactive Level-of-Detail Rendering of Large Graphs	10.1109/TVCG.2012.238	http://dx.doi.org/10.1109/TVCG.2012.238	2486	2495	J	We propose a technique that allows straight-line graph drawings to be rendered interactively with adjustable level of detail. The approach consists of a novel combination of edge cumulation with density-based node aggregation and is designed to exploit common graphics hardware for speed. It operates directly on graph data and does not require precomputed hierarchies or meshes. As proof of concept, we present an implementation that scales to graphs with millions of nodes and edges, and discuss several example applications.	Michael Zinsmaier;Ulrik Brandes;Oliver Deussen;Hendrik Strobelt	;;;	10.1109/INFVIS.2005.1532150;10.1109/TVCG.2006.120;10.1109/TVCG.2011.233;10.1109/TVCG.2008.135;10.1109/TVCG.2006.187;10.1109/TVCG.2006.147;10.1109/TVCG.2010.154;10.1109/INFVIS.2004.66	Graph visualization, OpenGL, edge aggregation	
InfoVis	2012	Living Liquid: Design and Evaluation of an Exploratory Visualization Tool for Museum Visitors	10.1109/TVCG.2012.244	http://dx.doi.org/10.1109/TVCG.2012.244	2799	2808	J	Interactive visualizations can allow science museum visitors to explore new worlds by seeing and interacting with scientific data. However, designing interactive visualizations for informal learning environments, such as museums, presents several challenges. First, visualizations must engage visitors on a personal level. Second, visitors often lack the background to interpret visualizations of scientific data. Third, visitors have very limited time at individual exhibits in museums. This paper examines these design considerations through the iterative development and evaluation of an interactive exhibit as a visualization tool that gives museumgoers access to scientific data generated and used by researchers. The exhibit prototype, Living Liquid, encourages visitors to ask and answer their own questions while exploring the time-varying global distribution of simulated marine microbes using a touchscreen interface. Iterative development proceeded through three rounds of formative evaluations using think-aloud protocols and interviews, each round informing a key visualization design decision: (1) what to visualize to initiate inquiry, (2) how to link data at the microscopic scale to global patterns, and (3) how to include additional data that allows visitors to pursue their own questions. Data from visitor evaluations suggests that, when designing visualizations for public audiences, one should (1) avoid distracting visitors from data that they should explore, (2) incorporate background information into the visualization, (3) favor understandability over scientific accuracy, and (4) layer data accessibility to structure inquiry. Lessons learned from this case study add to our growing understanding of how to use visualizations to actively engage learners with scientific data.	Joyce Ma;Isaac Liao;Kwan-Liu Ma;Jennifer Frazier	Exploratorium, San Francisco, CA, USA|c|;;;	10.1109/TVCG.2008.127;10.1109/TVCG.2011.175;10.1109/INFVIS.2004.8	Information visualization, user interaction, evaluation, user studies, science museums, informal learning environments	
InfoVis	2012	Memorability of Visual Features in Network Diagrams	10.1109/TVCG.2012.245	http://dx.doi.org/10.1109/TVCG.2012.245	2477	2485	J	We investigate the cognitive impact of various layout features-symmetry, alignment, collinearity, axis alignment and orthogonality - on the recall of network diagrams (graphs). This provides insight into how people internalize these diagrams and what features should or shouldn't be utilised when designing static and interactive network-based visualisations. Participants were asked to study, remember, and draw a series of small network diagrams, each drawn to emphasise a particular visual feature. The visual features were based on existing theories of perception, and the task enabled visual processing at the visceral level only. Our results strongly support the importance of visual features such as symmetry, collinearity and orthogonality, while not showing any significant impact for node-alignment or parallel edges.	Kim Marriott;Helen C. Purchase;Michael Wybrow;Cagatay Goncu	Monash Univ., Melbourne, VIC, Australia|c|;;;	10.1109/TVCG.2008.155;10.1109/TVCG.2009.109	Network diagrams, graph layout, perceptual theories, visual features, diagram recall, experiment	
InfoVis	2012	Organizing Search Results with a Reference Map	10.1109/TVCG.2012.250	http://dx.doi.org/10.1109/TVCG.2012.250	2546	2555	J	We propose a method to highlight query hits in hierarchically clustered collections of interrelated items such as digital libraries or knowledge bases. The method is based on the idea that organizing search results similarly to their arrangement on a fixed reference map facilitates orientation and assessment by preserving a user's mental map. Here, the reference map is built from an MDS layout of the items in a Voronoi treemap representing their hierarchical clustering, and we use techniques from dynamic graph layout to align query results with the map. The approach is illustrated on an archive of newspaper articles.	Arlind Nocaj;Ulrik Brandes	;	10.1109/INFVIS.2005.1532128;10.1109/INFVIS.1997.636718;10.1109/TVCG.2006.147;10.1109/TVCG.2010.154;10.1109/TVCG.2009.176	Search results, mental map, voronoi treemaps, dynamic graph layout, multidimensional scaling, edge bundling	
InfoVis	2012	Perception of Visual Variables on Tiled Wall-Sized Displays for Information Visualization Applications	10.1109/TVCG.2012.251	http://dx.doi.org/10.1109/TVCG.2012.251	2516	2525	J	We present the results of two user studies on the perception of visual variables on tiled high-resolution wall-sized displays. We contribute an understanding of, and indicators predicting how, large variations in viewing distances and viewing angles affect the accurate perception of angles, areas, and lengths. Our work, thus, helps visualization researchers with design considerations on how to create effective visualizations for these spaces. The first study showed that perception accuracy was impacted most when viewers were close to the wall but differently for each variable (Angle, Area, Length). Our second study examined the effect of perception when participants could move freely compared to when they had a static viewpoint. We found that a far but static viewpoint was as accurate but less time consuming than one that included free motion. Based on our findings, we recommend encouraging viewers to stand further back from the display when conducting perception estimation tasks. If tasks need to be conducted close to the wall display, important information should be placed directly in front of the viewer or above, and viewers should be provided with an estimation of the distortion effects predicted by our work-or encouraged to physically navigate the wall in specific ways to reduce judgement error.	Anastasia Bezerianos;Petra Isenberg	;	10.1109/TVCG.2011.160;10.1109/TVCG.2006.184	Information visualization, perception, wall-displays	
InfoVis	2012	PivotPaths: Strolling through Faceted Information Spaces	10.1109/TVCG.2012.252	http://dx.doi.org/10.1109/TVCG.2012.252	2709	2718	J	We present PivotPaths, an interactive visualization for exploring faceted information resources. During both work and leisure, we increasingly interact with information spaces that contain multiple facets and relations, such as authors, keywords, and citations of academic publications, or actors and genres of movies. To navigate these interlinked resources today, one typically selects items from facet lists resulting in abrupt changes from one subset of data to another. While filtering is useful to retrieve results matching specific criteria, it can be difficult to see how facets and items relate and to comprehend the effect of filter operations. In contrast, the PivotPaths interface exposes faceted relations as visual paths in arrangements that invite the viewer to `take a stroll' through an information space. PivotPaths supports pivot operations as lightweight interaction techniques that trigger gradual transitions between views. We designed the interface to allow for casual traversal of large collections in an aesthetically pleasing manner that encourages exploration and serendipitous discoveries. This paper shares the findings from our iterative design-and-evaluation process that included semi-structured interviews and a two-week deployment of PivotPaths applied to a large database of academic publications.	Marian Dörk;Nathalie Henry Riche;Gonzalo Ramos;Susan T. Dumais	;;;	10.1109/VAST.2009.5333443;10.1109/TVCG.2010.154;10.1109/VAST.2006.261426;10.1109/VAST.2007.4389006;10.1109/VAST.2008.4677370;10.1109/TVCG.2007.70539;10.1109/TVCG.2008.175	Information visualization, interactivity, node-link diagrams, animation, information seeking, exploratory search	
InfoVis	2012	RankExplorer: Visualization of Ranking Changes in Large Time Series Data	10.1109/TVCG.2012.253	http://dx.doi.org/10.1109/TVCG.2012.253	2669	2678	J	For many applications involving time series data, people are often interested in the changes of item values over time as well as their ranking changes. For example, people search many words via search engines like Google and Bing every day. Analysts are interested in both the absolute searching number for each word as well as their relative rankings. Both sets of statistics may change over time. For very large time series data with thousands of items, how to visually present ranking changes is an interesting challenge. In this paper, we propose RankExplorer, a novel visualization method based on ThemeRiver to reveal the ranking changes. Our method consists of four major components: 1) a segmentation method which partitions a large set of time series curves into a manageable number of ranking categories; 2) an extended ThemeRiver view with embedded color bars and changing glyphs to show the evolution of aggregation values related to each ranking category over time as well as the content changes in each ranking category; 3) a trend curve to show the degree of ranking changes over time; 4) rich user interactions to support interactive exploration of ranking changes. We have applied our method to some real time series data and the case studies demonstrate that our method can reveal the underlying patterns related to ranking changes which might otherwise be obscured in traditional visualizations.	Conglei Shi;Weiwei Cui;Shixia Liu;Panpan Xu;Wei Chen;Huamin Qu	Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;	10.1109/TVCG.2008.166;10.1109/VAST.2010.5652931;10.1109/TVCG.2010.193;10.1109/VAST.2010.5652530;10.1109/INFVIS.2000.885098;10.1109/INFVIS.2005.1532148;10.1109/TVCG.2011.179;10.1109/TVCG.2007.70535;10.1109/TVCG.2008.140;10.1109/TVCG.2010.129;10.1109/TVCG.2008.181;10.1109/TVCG.2009.187;10.1109/INFVIS.1999.801851;10.1109/INFVIS.2005.1532122;10.1109/VISUAL.1995.485140;10.1109/TVCG.2010.194;10.1109/TVCG.2011.239;10.1109/TVCG.2010.162;10.1109/TVCG.2011.195;10.1109/TVCG.2009.180	Time-series data, ranking change, Themeriver, interaction techniques	
InfoVis	2012	RelEx: Visualization for Actively Changing Overlay Network Specifications	10.1109/TVCG.2012.255	http://dx.doi.org/10.1109/TVCG.2012.255	2729	2738	J	We present a network visualization design study focused on supporting automotive engineers who need to specify and optimize traffic patterns for in-car communication networks. The task and data abstractions that we derived support actively making changes to an overlay network, where logical communication specifications must be mapped to an underlying physical network. These abstractions are very different from the dominant use case in visual network analysis, namely identifying clusters and central nodes, that stems from the domain of social network analysis. Our visualization tool RelEx was created and iteratively refined through a full user-centered design process that included a full problem characterization phase before tool design began, paper prototyping, iterative refinement in close collaboration with expert users for formative evaluation, deployment in the field with real analysts using their own data, usability testing with non-expert users, and summative evaluation at the end of the deployment. In the summative post-deployment study, which entailed domain experts using the tool over several weeks in their daily practice, we documented many examples where the use of RelEx simplified or sped up their work compared to previous practices.	Michael Sedlmair;Annika Frank;Tamara Munzner;Andreas Butz	Univ. of British Columbia, Vancouver, BC, Canada|c|;;;	10.1109/TVCG.2006.160;10.1109/INFVIS.2004.12;10.1109/VAST.2011.6102443;10.1109/TVCG.2007.70582;10.1109/TVCG.2009.111;10.1109/TVCG.2009.116;10.1109/INFVIS.1999.801869;10.1109/TVCG.2008.141;10.1109/TVCG.2008.117;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2012.213;10.1109/INFVIS.2003.1249030;10.1109/VAST.2006.261426	Network visualization, change management, traffic routing, traffic optimization, automotive, design study	
InfoVis	2012	Representative Factor Generation for the Interactive Visual Analysis of High-Dimensional Data	10.1109/TVCG.2012.256	http://dx.doi.org/10.1109/TVCG.2012.256	2621	2630	J	Datasets with a large number of dimensions per data item (hundreds or more) are challenging both for computational and visual analysis. Moreover, these dimensions have different characteristics and relations that result in sub-groups and/or hierarchies over the set of dimensions. Such structures lead to heterogeneity within the dimensions. Although the consideration of these structures is crucial for the analysis, most of the available analysis methods discard the heterogeneous relations among the dimensions. In this paper, we introduce the construction and utilization of representative factors for the interactive visual analysis of structures in high-dimensional datasets. First, we present a selection of methods to investigate the sub-groups in the dimension set and associate representative factors with those groups of dimensions. Second, we introduce how these factors are included in the interactive visual analysis cycle together with the original dimensions. We then provide the steps of an analytical procedure that iteratively analyzes the datasets through the use of representative factors. We discuss how our methods improve the reliability and interpretability of the analysis process by enabling more informed selections of computational tools. Finally, we demonstrate our techniques on the analysis of brain imaging study results that are performed over a large group of subjects.	Cagatay Turkay;Arvid Lundervold;Astri J. Lundervold;Helwig Hauser	Dept. of Inf., Univ. of Bergen, Bergen, Norway|c|;;;	10.1109/TVCG.2009.199;10.1109/INFVIS.2005.1532142;10.1109/VAST.2011.6102449;10.1109/INFVIS.2000.885086;10.1109/VISUAL.1994.346302;10.1109/TVCG.2008.116;10.1109/TVCG.2011.178;10.1109/TVCG.2007.70569;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2004.60;10.1109/INFVIS.2004.3;10.1109/TVCG.2009.153	Interactive visual analysis, high-dimensional data analysis	
InfoVis	2012	Sketchy Rendering for Information Visualization	10.1109/TVCG.2012.262	http://dx.doi.org/10.1109/TVCG.2012.262	2749	2758	J	We present and evaluate a framework for constructing sketchy style information visualizations that mimic data graphics drawn by hand. We provide an alternative renderer for the Processing graphics environment that redefines core drawing primitives including line, polygon and ellipse rendering. These primitives allow higher-level graphical features such as bar charts, line charts, treemaps and node-link diagrams to be drawn in a sketchy style with a specified degree of sketchiness. The framework is designed to be easily integrated into existing visualization implementations with minimal programming modification or design effort. We show examples of use for statistical graphics, conveying spatial imprecision and for enhancing aesthetic and narrative qualities of visualization. We evaluate user perception of sketchiness of areal features through a series of stimulus-response tests in order to assess users' ability to place sketchiness on a ratio scale, and to estimate area. Results suggest relative area judgment is compromised by sketchy rendering and that its influence is dependent on the shape being rendered. They show that degree of sketchiness may be judged on an ordinal scale but that its judgement varies strongly between individuals. We evaluate higher-level impacts of sketchiness through user testing of scenarios that encourage user engagement with data visualization and willingness to critique visualization design. Results suggest that where a visualization is clearly sketchy, engagement may be increased and that attitudes to participating in visualization annotation are more positive. The results of our work have implications for effective information visualization design that go beyond the traditional role of sketching as a tool for prototyping or its use for an indication of general uncertainty.	Jo Wood;Petra Isenberg;Tobias Isenberg 0001;Jason Dykes;Nadia Boukhelifa;Aidan Slingsby	giCentre, City Univ. London, London, UK|c|;;;;;	10.1109/TVCG.2010.186;10.1109/TVCG.2011.175;10.1109/TVCG.2012.220;10.1109/TVCG.2011.251;10.1109/TVCG.2011.209;10.1109/TVCG.2011.255	NPR, non-photorealistic rendering, sketch, hand-drawn, uncertainty, visualization	
InfoVis	2012	SnapShot: Visualization to Propel Ice Hockey Analytics	10.1109/TVCG.2012.263	http://dx.doi.org/10.1109/TVCG.2012.263	2819	2828	J	Sports analysts live in a world of dynamic games flattened into tables of numbers, divorced from the rinks, pitches, and courts where they were generated. Currently, these professional analysts use R, Stata, SAS, and other statistical software packages for uncovering insights from game data. Quantitative sports consultants seek a competitive advantage both for their clients and for themselves as analytics becomes increasingly valued by teams, clubs, and squads. In order for the information visualization community to support the members of this blossoming industry, it must recognize where and how visualization can enhance the existing analytical workflow. In this paper, we identify three primary stages of today's sports analyst's routine where visualization can be beneficially integrated: 1) exploring a dataspace; 2) sharing hypotheses with internal colleagues; and 3) communicating findings to stakeholders.Working closely with professional ice hockey analysts, we designed and built SnapShot, a system to integrate visualization into the hockey intelligence gathering process. SnapShot employs a variety of information visualization techniques to display shot data, yet given the importance of a specific hockey statistic, shot length, we introduce a technique, the radial heat map. Through a user study, we received encouraging feedback from several professional analysts, both independent consultants and professional team personnel.	Hannah Pileggi;Charles D. Stolper;J. Michael Boyle;John T. Stasko	;;;	10.1109/TVCG.2010.179;10.1109/TVCG.2007.70537;10.1109/INFVIS.1997.636793;10.1109/TVCG.2011.185;10.1109/TVCG.2007.70577;10.1109/INFVIS.1996.559229	Visual knowledge discovery, visual knowledge representation, hypothesis testing, visual evidence, human computer interaction	
InfoVis	2012	Spatial Text Visualization Using Automatic Typographic Maps	10.1109/TVCG.2012.264	http://dx.doi.org/10.1109/TVCG.2012.264	2556	2564	J	We present a method for automatically building typographic maps that merge text and spatial data into a visual representation where text alone forms the graphical features. We further show how to use this approach to visualize spatial data such as traffic density, crime rate, or demographic data. The technique accepts a vector representation of a geographic map and spatializes the textual labels in the space onto polylines and polygons based on user-defined visual attributes and constraints. Our sample implementation runs as a Web service, spatializing shape files from the OpenStreetMap project into typographic maps for any region.	Shehzad Afzal;Ross Maciejewski;Yun Jang;Niklas Elmqvist;David S. Ebert	Purdue Univ. in West Lafayette, West Lafayette, IN, USA|c|;;;;	10.1109/VAST.2010.5652931;10.1109/TVCG.2010.191;10.1109/TVCG.2010.175;10.1109/INFVIS.1995.528686;10.1109/VISUAL.1997.663912;10.1109/VISUAL.2000.885694;10.1109/INFVIS.2005.1532131;10.1109/INFVIS.2002.1173144;10.1109/TVCG.2008.165;10.1109/TVCG.2010.194;10.1109/TVCG.2009.171;10.1109/INFVIS.2000.885095	Geovisualization, spatial data, text visualization, label placement	
InfoVis	2012	Stacking-Based Visualization of Trajectory Attribute Data	10.1109/TVCG.2012.265	http://dx.doi.org/10.1109/TVCG.2012.265	2565	2574	J	Visualizing trajectory attribute data is challenging because it involves showing the trajectories in their spatio-temporal context as well as the attribute values associated with the individual points of trajectories. Previous work on trajectory visualization addresses selected aspects of this problem, but not all of them. We present a novel approach to visualizing trajectory attribute data. Our solution covers space, time, and attribute values. Based on an analysis of relevant visualization tasks, we designed the visualization solution around the principle of stacking trajectory bands. The core of our approach is a hybrid 2D/3D display. A 2D map serves as a reference for the spatial context, and the trajectories are visualized as stacked 3D trajectory bands along which attribute values are encoded by color. Time is integrated through appropriate ordering of bands and through a dynamic query mechanism that feeds temporally aggregated information to a circular time display. An additional 2D time graph shows temporal information in full detail by stacking 2D trajectory bands. Our solution is equipped with analytical and interactive mechanisms for selecting and ordering of trajectories, and adjusting the color mapping, as well as coordinated highlighting and dedicated 3D navigation. We demonstrate the usefulness of our novel visualization by three examples related to radiation surveillance, traffic analysis, and maritime navigation. User feedback obtained in a small experiment indicates that our hybrid 2D/3D solution can be operated quite well.	Christian Tominski;Heidrun Schumann;Gennady L. Andrienko;Natalia V. Andrienko	;;;	10.1109/TVCG.2010.197;10.1109/VAST.2011.6102455;10.1109/VAST.2009.5332593;10.1109/VISUAL.1995.480803;10.1109/INFVIS.2004.27;10.1109/INFVIS.2005.1532144;10.1109/VAST.2011.6102454	Visualization, interaction, exploratory analysis, trajectory attribute data, spatio-temporal data	
InfoVis	2012	Taxonomy-Based Glyph Design---with a Case Study on Visualizing Workflows of Biological Experiments	10.1109/TVCG.2012.271	http://dx.doi.org/10.1109/TVCG.2012.271	2603	2612	J	Glyph-based visualization can offer elegant and concise presentation of multivariate information while enhancing speed and ease in visual search experienced by users. As with icon designs, glyphs are usually created based on the designers' experience and intuition, often in a spontaneous manner. Such a process does not scale well with the requirements of applications where a large number of concepts are to be encoded using glyphs. To alleviate such limitations, we propose a new systematic process for glyph design by exploring the parallel between the hierarchy of concept categorization and the ordering of discriminative capacity of visual channels. We examine the feasibility of this approach in an application where there is a pressing need for an efficient and effective means to visualize workflows of biological experiments. By processing thousands of workflow records in a public archive of biological experiments, we demonstrate that a cost-effective glyph design can be obtained by following a process of formulating a taxonomy with the aid of computation, identifying visual channels hierarchically, and defining application-specific abstraction and metaphors.	Eamonn Maguire;Philippe Rocca-Serra;Susanna-Assunta Sansone;Jim Davies;Min Chen	Dept. of Comput. Sci., Univ. of Oxford, Oxford, UK|c|;;;;	10.1109/TVCG.2006.134;10.1109/TVCG.2012.197;10.1109/TVCG.2010.132;10.1109/VISUAL.1995.485141;10.1109/INFVIS.1998.729568	Glyph-based techniques, taxonomies, design methodologies, bioinformatics visualization	
InfoVis	2012	The DeepTree Exhibit: Visualizing the Tree of Life to Facilitate Informal Learning	10.1109/TVCG.2012.272	http://dx.doi.org/10.1109/TVCG.2012.272	2789	2798	J	In this paper, we present the DeepTree exhibit, a multi-user, multi-touch interactive visualization of the Tree of Life. We developed DeepTree to facilitate collaborative learning of evolutionary concepts. We will describe an iterative process in which a team of computer scientists, learning scientists, biologists, and museum curators worked together throughout design, development, and evaluation. We present the importance of designing the interactions and the visualization hand-in-hand in order to facilitate active learning. The outcome of this process is a fractal-based tree layout that reduces visual complexity while being able to capture all life on earth; a custom rendering and navigation engine that prioritizes visual appeal and smooth fly-through; and a multi-user interface that encourages collaborative exploration while offering guided discovery. We present an evaluation showing that the large dataset encouraged free exploration, triggers emotional responses, and facilitates visitor engagement and informal learning.	Florian Block;Michael S. Horn;Brenda Caldwell Phillips;Judy Diamond;E. Margaret Evans;Chia Shen	;;;;;	10.1109/INFVIS.2001.963285;10.1109/INFVIS.1997.636718;10.1109/TVCG.2009.111;10.1109/TVCG.2007.70539;10.1109/INFVIS.2002.1173153;10.1109/TVCG.2008.127;10.1109/INFVIS.2002.1173148;10.1109/TVCG.2007.70541	Informal science education, collaborative learning, large tree visualizations, multi-touch interaction	
InfoVis	2012	Understanding Pen and Touch Interaction for Data Exploration on Interactive Whiteboards	10.1109/TVCG.2012.275	http://dx.doi.org/10.1109/TVCG.2012.275	2779	2788	J	Current interfaces for common information visualizations such as bar graphs, line graphs, and scatterplots usually make use of the WIMP (Windows, Icons, Menus and a Pointer) interface paradigm with its frequently discussed problems of multiple levels of indirection via cascading menus, dialog boxes, and control panels. Recent advances in interface capabilities such as the availability of pen and touch interaction challenge us to re-think this and investigate more direct access to both the visualizations and the data they portray. We conducted a Wizard of Oz study to explore applying pen and touch interaction to the creation of information visualization interfaces on interactive whiteboards without implementing a plethora of recognizers. Our wizard acted as a robust and flexible pen and touch recognizer, giving participants maximum freedom in how they interacted with the system. Based on our qualitative analysis of the interactions our participants used, we discuss our insights about pen and touch interactions in the context of learnability and the interplay between pen and touch gestures. We conclude with suggestions for designing pen and touch enabled interactive visualization interfaces.	Jagoda Walny;Bongshin Lee;Paul Johns;Nathalie Henry Riche;M. Sheelagh T. Carpendale	;;;;	10.1109/TVCG.2012.262;10.1109/TVCG.2009.174;10.1109/TVCG.2011.251;10.1109/TVCG.2007.70568;10.1109/TVCG.2010.164	Pen and touch, interaction, Wizard of Oz, whiteboard, data exploration	
InfoVis	2012	Visual Semiotics & Uncertainty Visualization: An Empirical Study	10.1109/TVCG.2012.279	http://dx.doi.org/10.1109/TVCG.2012.279	2496	2505	J	This paper presents two linked empirical studies focused on uncertainty visualization. The experiments are framed from two conceptual perspectives. First, a typology of uncertainty is used to delineate kinds of uncertainty matched with space, time, and attribute components of data. Second, concepts from visual semiotics are applied to characterize the kind of visual signification that is appropriate for representing those different categories of uncertainty. This framework guided the two experiments reported here. The first addresses representation intuitiveness, considering both visual variables and iconicity of representation. The second addresses relative performance of the most intuitive abstract and iconic representations of uncertainty on a map reading task. Combined results suggest initial guidelines for representing uncertainty and discussion focuses on practical applicability of results.	Alan M. MacEachren;Robert E. Roth;James O'Brien;Bonan Li;Derek Swingley;Mark Gahegan	;;;;;	10.1109/VISUAL.1992.235199;10.1109/TVCG.2011.197;10.1109/TVCG.2009.114	Uncertainty visualization, uncertainty categories, visual variables, semiotics	
InfoVis	2012	Visualizing Flow of Uncertainty through Analytical Processes	10.1109/TVCG.2012.285	http://dx.doi.org/10.1109/TVCG.2012.285	2526	2535	J	Uncertainty can arise in any stage of a visual analytics process, especially in data-intensive applications with a sequence of data transformations. Additionally, throughout the process of multidimensional, multivariate data analysis, uncertainty due to data transformation and integration may split, merge, increase, or decrease. This dynamic characteristic along with other features of uncertainty pose a great challenge to effective uncertainty-aware visualization. This paper presents a new framework for modeling uncertainty and characterizing the evolution of the uncertainty information through analytical processes. Based on the framework, we have designed a visual metaphor called uncertainty flow to visually and intuitively summarize how uncertainty information propagates over the whole analysis pipeline. Our system allows analysts to interact with and analyze the uncertainty information at different levels of detail. Three experiments were conducted to demonstrate the effectiveness and intuitiveness of our design.	Yingcai Wu;Guo-Xun Yuan;Kwan-Liu Ma	Univ. of California, Davis, CA, USA|c|;;	10.1109/TVCG.2008.137;10.1109/TVCG.2011.178;10.1109/INFVIS.2004.2;10.1109/INFVIS.2002.1173145;10.1109/VISUAL.1993.398857;10.1109/VAST.2009.5332611;10.1109/TVCG.2010.183;10.1109/TVCG.2009.114;10.1109/TVCG.2011.197;10.1109/TVCG.2010.176	Uncertainty visualization, uncertainty quantification, uncertainty propagation, error ellipsoids, uncertainty fusion	
InfoVis	2012	Visualizing Network Traffic to Understand the Performance of Massively Parallel Simulations	10.1109/TVCG.2012.286	http://dx.doi.org/10.1109/TVCG.2012.286	2467	2476	J	The performance of massively parallel applications is often heavily impacted by the cost of communication among compute nodes. However, determining how to best use the network is a formidable task, made challenging by the ever increasing size and complexity of modern supercomputers. This paper applies visualization techniques to aid parallel application developers in understanding the network activity by enabling a detailed exploration of the flow of packets through the hardware interconnect. In order to visualize this large and complex data, we employ two linked views of the hardware network. The first is a 2D view, that represents the network structure as one of several simplified planar projections. This view is designed to allow a user to easily identify trends and patterns in the network traffic. The second is a 3D view that augments the 2D view by preserving the physical network topology and providing a context that is familiar to the application developers. Using the massively parallel multi-physics code pF3D as a case study, we demonstrate that our tool provides valuable insight that we use to explain and optimize pF3D's performance on an IBM Blue Gene/P system.	Aaditya G. Landge;Joshua A. Levine;Abhinav Bhatele;Katherine E. Isaacs;Todd Gamblin;Martin Schulz 0001;Steve H. Langer;Peer-Timo Bremer;Valerio Pascucci	;;;;;;;;	10.1109/TVCG.2009.196;10.1109/INFVIS.2004.66	Performance analysis, network traffic visualization, projected graph layouts	
InfoVis	2012	Visualizing Student Histories Using Clustering and Composition	10.1109/TVCG.2012.288	http://dx.doi.org/10.1109/TVCG.2012.288	2809	2818	J	While intuitive time-series visualizations exist for common datasets, student course history data is difficult to represent using traditional visualization techniques due its concurrent nature. A visual composition process is developed and applied to reveal trends across various groupings. By working closely with educators, analytic strategies and techniques are developed to leverage the visualization composition to reveal unknown trends in the data. Furthermore, clustering algorithms are developed to group common course-grade histories for further analysis. Lastly, variations of the composition process are implemented to reveal subtle differences in the underlying data. These analytic tools and techniques enabled educators to confirm expected trends and to discover new ones.	David Trimm;Penny Rheingans;Marie desJardins	Univ. of Maryland, Baltimore County (UMBC), Baltimore, MD, USA|c|;;	10.1109/INFVIS.2005.1532140;10.1109/TVCG.2007.70623;10.1109/TVCG.2009.131	Clustering, aggregate visualization, student performance analysis, visualization composition	
InfoVis	2012	Whisper: Tracing the Spatiotemporal Process of Information Diffusion in Real Time	10.1109/TVCG.2012.291	http://dx.doi.org/10.1109/TVCG.2012.291	2649	2658	J	When and where is an idea dispersed? Social media, like Twitter, has been increasingly used for exchanging information, opinions and emotions about events that are happening across the world. Here we propose a novel visualization design, â€œWhisperâ€, for tracing the process of information diffusion in social media in real time. Our design highlights three major characteristics of diffusion processes in social media: the temporal trend, social-spatial extent, and community response of a topic of interest. Such social, spatiotemporal processes are conveyed based on a sunflower metaphor whose seeds are often dispersed far away. In Whisper, we summarize the collective responses of communities on a given topic based on how tweets were retweeted by groups of users, through representing the sentiments extracted from the tweets, and tracing the pathways of retweets on a spatial hierarchical layout. We use an efficient flux line-drawing algorithm to trace multiple pathways so the temporal and spatial patterns can be identified even for a bursty event. A focused diffusion series highlights key roles such as opinion leaders in the diffusion process. We demonstrate how our design facilitates the understanding of when and where a piece of information is dispersed and what are the social responses of the crowd, for large-scale events including political campaigns and natural disasters. Initial feedback from domain experts suggests promising use for today's information consumption and dispersion in the wild.	Nan Cao;Yu-Ru Lin;Xiaohua Sun;David Lazer;Shixia Liu;Huamin Qu	Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;	10.1109/TVCG.2009.171;10.1109/TVCG.2006.147;10.1109/INFVIS.2000.885098;10.1109/TVCG.2006.202;10.1109/TVCG.2007.70535;10.1109/TVCG.2010.129;10.1109/TVCG.2008.125;10.1109/TVCG.2011.188	Information visualization, Information diffusion, Contagion, Social media, Microblogging, Spatiotemporal patterns	
VAST	2012	A Visual Analytics Approach to Multiscale Exploration of Environmental Time Series	10.1109/TVCG.2012.191	http://dx.doi.org/10.1109/TVCG.2012.191	2899	2907	J	We present a Visual Analytics approach that addresses the detection of interesting patterns in numerical time series, specifically from environmental sciences. Crucial for the detection of interesting temporal patterns are the time scale and the starting points one is looking at. Our approach makes no assumption about time scale and starting position of temporal patterns and consists of three main steps: an algorithm to compute statistical values for all possible time scales and starting positions of intervals, visual identification of potentially interesting patterns in a matrix visualization, and interactive exploration of detected patterns. We demonstrate the utility of this approach in two scientific scenarios and explain how it allowed scientists to gain new insight into the dynamics of environmental systems.	Mike Sips;Patrick Köthur;Andrea Unger;Hans-Christian Hege;Doris Dransch	German Res. Center for Geosci. GFZ, Germany|c|;;;;	10.1109/INFVIS.2001.963273;10.1109/INFVIS.1995.528685	Time series analysis, multiscale visualization, visual analytics	
VAST	2012	An Affordance-Based Framework for Human Computation and Human-Computer Collaboration	10.1109/TVCG.2012.195	http://dx.doi.org/10.1109/TVCG.2012.195	2859	2868	J	Visual Analytics is â€œthe science of analytical reasoning facilitated by visual interactive interfacesâ€ [70]. The goal of this field is to develop tools and methodologies for approaching problems whose size and complexity render them intractable without the close coupling of both human and machine analysis. Researchers have explored this coupling in many venues: VAST, Vis, InfoVis, CHI, KDD, IUI, and more. While there have been myriad promising examples of human-computer collaboration, there exists no common language for comparing systems or describing the benefits afforded by designing for such collaboration. We argue that this area would benefit significantly from consensus about the design attributes that define and distinguish existing techniques. In this work, we have reviewed 1,271 papers from many of the top-ranking conferences in visual analytics, human-computer interaction, and visualization. From these, we have identified 49 papers that are representative of the study of human-computer collaborative problem-solving, and provide a thorough overview of the current state-of-the-art. Our analysis has uncovered key patterns of design hinging on humanand machine-intelligence affordances, and also indicates unexplored avenues in the study of this area. The results of this analysis provide a common framework for understanding these seemingly disparate branches of inquiry, which we hope will motivate future work in the field.	R. Jordan Crouser;Remco Chang	;	10.1109/VAST.2010.5652398;10.1109/VAST.2011.6102461;10.1109/TVCG.2009.199;10.1109/VAST.2010.5652910;10.1109/VAST.2010.5652484;10.1109/VAST.2009.5332584;10.1109/VAST.2010.5652885;10.1109/VAST.2009.5333564;10.1109/VAST.2010.5652392;10.1109/VAST.2009.5332586;10.1109/VAST.2011.6102451;10.1109/VAST.2009.5333023;10.1109/VAST.2009.5333020;10.1109/VAST.2009.5332628;10.1109/TVCG.2011.173;10.1109/TVCG.2011.218;10.1109/TVCG.2011.231;10.1109/VAST.2010.5652443;10.1109/VAST.2010.5653598;10.1109/VAST.2011.6102447	Human computation, human complexity, theory, framework	
VAST	2012	Enterprise Data Analysis and Visualization: An Interview Study	10.1109/TVCG.2012.219	http://dx.doi.org/10.1109/TVCG.2012.219	2917	2926	J	Organizations rely on data analysts to model customer engagement, streamline operations, improve production, inform business decisions, and combat fraud. Though numerous analysis and visualization tools have been built to improve the scale and efficiency at which analysts can work, there has been little research on how analysis takes place within the social and organizational context of companies. To better understand the enterprise analysts' ecosystem, we conducted semi-structured interviews with 35 data analysts from 25 organizations across a variety of sectors, including healthcare, retail, marketing and finance. Based on our interview data, we characterize the process of industrial data analysis and document how organizational features of an enterprise impact it. We describe recurring pain points, outstanding challenges, and barriers to adoption for visual analytic tools. Finally, we discuss design implications and opportunities for visual analysis research.	Sean Kandel;Andreas Paepcke;Joseph M. Hellerstein;Jeffrey Heer	Stanford Univ., Stanford, CA, USA|c|;;;	10.1109/TVCG.2008.137;10.1109/VAST.2008.4677365;10.1109/VAST.2011.6102438;10.1109/INFVIS.2005.1532136;10.1109/VAST.2010.5652880;10.1109/VAST.2009.5333878;10.1109/VAST.2007.4389011;10.1109/VAST.2011.6102435	Data, analysis, visualization, enterprise	
VAST	2012	Examining the Use of a Visual Analytics System for Sensemaking Tasks: Case Studies with Domain Experts	10.1109/TVCG.2012.224	http://dx.doi.org/10.1109/TVCG.2012.224	2869	2878	J	While the formal evaluation of systems in visual analytics is still relatively uncommon, particularly rare are case studies of prolonged system use by domain analysts working with their own data. Conducting case studies can be challenging, but it can be a particularly effective way to examine whether visual analytics systems are truly helping expert users to accomplish their goals. We studied the use of a visual analytics system for sensemaking tasks on documents by six analysts from a variety of domains. We describe their application of the system along with the benefits, issues, and problems that we uncovered. Findings from the studies identify features that visual analytics systems should emphasize as well as missing capabilities that should be addressed. These findings inform design implications for future systems.	Youn ah Kang;John T. Stasko	;	10.1109/VAST.2008.4677362;10.1109/VAST.2006.261416;10.1109/INFVIS.2004.5;10.1109/VAST.2011.6102438;10.1109/VAST.2012.6400559;10.1109/VAST.2007.4389006;10.1109/VAST.2009.5333878	Visual analytics, case study, qualitative evaluation	
VAST	2012	Reinventing the Contingency Wheel: Scalable Visual Analytics of Large Categorical Data	10.1109/TVCG.2012.254	http://dx.doi.org/10.1109/TVCG.2012.254	2849	2858	J	Contingency tables summarize the relations between categorical variables and arise in both scientific and business domains. Asymmetrically large two-way contingency tables pose a problem for common visualization methods. The Contingency Wheel has been recently proposed as an interactive visual method to explore and analyze such tables. However, the scalability and readability of this method are limited when dealing with large and dense tables. In this paper we present Contingency Wheel++, new visual analytics methods that overcome these major shortcomings: (1) regarding automated methods, a measure of association based on Pearson's residuals alleviates the bias of the raw residuals originally used, (2) regarding visualization methods, a frequency-based abstraction of the visual elements eliminates overlapping and makes analyzing both positive and negative associations possible, and (3) regarding the interactive exploration environment, a multi-level overview+detail interface enables exploring individual data items that are aggregated in the visualization or in the table using coordinated views. We illustrate the applicability of these new methods with a use case and show how they enable discovering and analyzing nontrivial patterns and associations in large categorical data.	Bilal Alsallakh;Wolfgang Aigner;Silvia Miksch;Eduard Gröller	;;;	10.1109/INFVIS.2005.1532139;10.1109/VISUAL.2005.1532819;10.1109/INFVIS.2002.1173156;10.1109/INFVIS.2003.1249016;10.1109/INFVIS.2002.1173157	Large categorical data, contingency table analysis, information interfaces and representation, visual analytics	
VAST	2012	Scatter/Gather Clustering: Flexibly Incorporating User Feedback to Steer Clustering Results	10.1109/TVCG.2012.258	http://dx.doi.org/10.1109/TVCG.2012.258	2829	2838	J	Significant effort has been devoted to designing clustering algorithms that are responsive to user feedback or that incorporate prior domain knowledge in the form of constraints. However, users desire more expressive forms of interaction to influence clustering outcomes. In our experiences working with diverse application scientists, we have identified an interaction style scatter/gather clustering that helps users iteratively restructure clustering results to meet their expectations. As the names indicate, scatter and gather are dual primitives that describe whether clusters in a current segmentation should be broken up further or, alternatively, brought back together. By combining scatter and gather operations in a single step, we support very expressive dynamic restructurings of data. Scatter/gather clustering is implemented using a nonlinear optimization framework that achieves both locality of clusters and satisfaction of user-supplied constraints. We illustrate the use of our scatter/gather clustering approach in a visual analytic application to study baffle shapes in the bat biosonar (ears and nose) system. We demonstrate how domain experts are adept at supplying scatter/gather constraints, and how our framework incorporates these constraints effectively without requiring numerous instance-level constraints.	M. Shahriar Hossain;Praveen Kumar Reddy Ojili;Cindy Grimm;Rolf Mueller;Layne T. Watson;Naren Ramakrishnan	Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA|c|;;;;;	10.1109/VAST.2009.5332584;10.1109/VAST.2007.4388999;10.1109/VAST.2008.4677350;10.1109/INFVIS.1998.729559;10.1109/VAST.2009.5332629	Scatter/gather clustering, alternative clustering, constrained clustering	
VAST	2012	Semantic Interaction for Sensemaking: Inferring Analytical Reasoning for Model Steering	10.1109/TVCG.2012.260	http://dx.doi.org/10.1109/TVCG.2012.260	2879	2888	J	Visual analytic tools aim to support the cognitively demanding task of sensemaking. Their success often depends on the ability to leverage capabilities of mathematical models, visualization, and human intuition through flexible, usable, and expressive interactions. Spatially clustering data is one effective metaphor for users to explore similarity and relationships between information, adjusting the weighting of dimensions or characteristics of the dataset to observe the change in the spatial layout. Semantic interaction is an approach to user interaction in such spatializations that couples these parametric modifications of the clustering model with users' analytic operations on the data (e.g., direct document movement in the spatialization, highlighting text, search, etc.). In this paper, we present results of a user study exploring the ability of semantic interaction in a visual analytic prototype, ForceSPIRE, to support sensemaking. We found that semantic interaction captures the analytical reasoning of the user through keyword weighting, and aids the user in co-creating a spatialization based on the user's reasoning and intuition.	Alex Endert;Patrick Fiaux;Chris North	;;	10.1109/INFVIS.1995.528686;10.1109/VAST.2012.6400559;10.1109/VAST.2011.6102449;10.1109/VAST.2011.6102438;10.1109/VAST.2007.4389006	User Interaction, visualization, sensemaking, analytic reasoning, visual analytics	
VAST	2012	The User Puzzle---Explaining the Interaction with Visual Analytics Systems	10.1109/TVCG.2012.273	http://dx.doi.org/10.1109/TVCG.2012.273	2908	2916	J	Visual analytics emphasizes the interplay between visualization, analytical procedures performed by computers and human perceptual and cognitive activities. Human reasoning is an important element in this context. There are several theories in psychology and HCI explaining open-ended and exploratory reasoning. Five of these theories (sensemaking theories, gestalt theories, distributed cognition, graph comprehension theories and skill-rule-knowledge models) are described in this paper. We discuss their relevance for visual analytics. In order to do this more systematically, we developed a schema of categories relevant for visual analytics research and evaluation. All these theories have strengths but also weaknesses in explaining interaction with visual analytics systems. A possibility to overcome the weaknesses would be to combine two or more of these theories.	Margit Pohl;Michael Smuc;Eva Mayr	Vienna Univ. of Technol., Vienna, Austria|c|;;	10.1109/TVCG.2008.121;10.1109/TVCG.2007.70515;10.1109/VAST.2010.5653598;10.1109/VAST.2008.4677361;10.1109/VAST.2011.6102445	Cognitive theory, visual knowledge discovery, interaction design, reasoning, problem solving	
VAST	2012	Visual Analytics Methodology for Eye Movement Studies	10.1109/TVCG.2012.276	http://dx.doi.org/10.1109/TVCG.2012.276	2889	2898	J	Eye movement analysis is gaining popularity as a tool for evaluation of visual displays and interfaces. However, the existing methods and tools for analyzing eye movements and scanpaths are limited in terms of the tasks they can support and effectiveness for large data and data with high variation. We have performed an extensive empirical evaluation of a broad range of visual analytics methods used in analysis of geographic movement data. The methods have been tested for the applicability to eye tracking data and the capability to extract useful knowledge about users' viewing behaviors. This allowed us to select the suitable methods and match them to possible analysis tasks they can support. The paper describes how the methods work in application to eye tracking data and provides guidelines for method selection depending on the analysis tasks.	Gennady L. Andrienko;Natalia V. Andrienko;Michael Burch;Daniel Weiskopf	;;;	10.1109/VAST.2009.5332593;10.1109/TVCG.2011.193;10.1109/INFVIS.2005.1532150	Visual analytics, eye tracking, movement data, trajectory analysis	
VAST	2012	Visual Classifier Training for Text Document Retrieval	10.1109/TVCG.2012.277	http://dx.doi.org/10.1109/TVCG.2012.277	2839	2848	J	Performing exhaustive searches over a large number of text documents can be tedious, since it is very hard to formulate search queries or define filter criteria that capture an analyst's information need adequately. Classification through machine learning has the potential to improve search and filter tasks encompassing either complex or very specific information needs, individually. Unfortunately, analysts who are knowledgeable in their field are typically not machine learning specialists. Most classification methods, however, require a certain expertise regarding their parametrization to achieve good results. Supervised machine learning algorithms, in contrast, rely on labeled data, which can be provided by analysts. However, the effort for labeling can be very high, which shifts the problem from composing complex queries or defining accurate filters to another laborious task, in addition to the need for judging the trained classifier's quality. We therefore compare three approaches for interactive classifier training in a user study. All of the approaches are potential candidates for the integration into a larger retrieval system. They incorporate active learning to various degrees in order to reduce the labeling effort as well as to increase effectiveness. Two of them encompass interactive visualization for letting users explore the status of the classifier in context of the labeled documents, as well as for judging the quality of the classifier in iterative feedback loops. We see our work as a step towards introducing user controlled classification methods in addition to text search and filtering for increasing recall in analytics scenarios involving large corpora.	Florian Heimerl;Steffen Koch;Harald Bosch;Thomas Ertl	Inst. for Visualization & Interactive Syst., Univ. Stuttgart, Stuttgart, Germany|c|;;;	10.1109/VAST.2011.6102449;10.1109/VAST.2011.6102453;10.1109/VAST.2007.4389006;10.1109/VAST.2012.6400492	Visual analytics, human computer interaction, information retrieval, active learning, classification, user evaluation	
VAST	2012	Relative N-gram signatures: Document visualization at the level of character N-grams	10.1109/VAST.2012.6400484	http://dx.doi.org/10.1109/VAST.2012.6400484	103	112	C	The Common N-Gram (CNG) classifier is a text classification algorithm based on the comparison of frequencies of character n-grams (strings of characters of length n) that are the most common in the considered documents and classes of documents. We present a text analytic visualization system that employs the CNG approach for text classification and uses the differences in frequency values of common n-grams in order to visually compare documents at the sub-word level. The visualization method provides both an insight into n-gram characteristics of documents or classes of documents and a visual interpretation of the workings of the CNG classifier.	Magdalena Jankowska;Vlado Keselj;Evangelos E. Milios	;;	10.1109/VAST.2009.5333443;10.1109/VAST.2007.4389004	Visual analytics, visual text analysis, text classification	
VAST	2012	LeadLine: Interactive visual analysis of text data through event identification and exploration	10.1109/VAST.2012.6400485	http://dx.doi.org/10.1109/VAST.2012.6400485	93	102	C	Text data such as online news and microblogs bear valuable insights regarding important events and responses to such events. Events are inherently temporal, evolving over time. Existing visual text analysis systems have provided temporal views of changes based on topical themes extracted from text data. But few have associated topical themes with events that cause the changes. In this paper, we propose an interactive visual analytics system, LeadLine, to automatically identify meaningful events in news and social media data and support exploration of the events. To characterize events, LeadLine integrates topic modeling, event detection, and named entity recognition techniques to automatically extract information regarding the investigative 4 Ws: who, what, when, and where for each event. To further support analysis of the text corpora through events, LeadLine allows users to interactively examine meaningful events using the 4 Ws to develop an understanding of how and why. Through representing large-scale text corpora in the form of meaningful events, LeadLine provides a concise summary of the corpora. LeadLine also supports the construction of simple narratives through the exploration of events. To demonstrate the efficacy of LeadLine in identifying events and supporting exploration, two case studies were conducted using news and social media data.	Wenwen Dou;Xiaoyu Wang;Drew Skau;William Ribarsky;Michelle X. Zhou	Univ. of North Carolina at Charlotte, Charlotte, NC, USA|c|;;;;	10.1109/VAST.2011.6102456;10.1109/VAST.2010.5652931;10.1109/TVCG.2011.179;10.1109/TVCG.2011.239;10.1109/VAST.2011.6102461;10.1109/TVCG.2011.185;10.1109/TVCG.2010.179;10.1109/VAST.2007.4389006;10.1109/INFVIS.2000.885098		
VAST	2012	Dis-function: Learning distance functions interactively	10.1109/VAST.2012.6400486	http://dx.doi.org/10.1109/VAST.2012.6400486	83	92	C	The world's corpora of data grow in size and complexity every day, making it increasingly difficult for experts to make sense out of their data. Although machine learning offers algorithms for finding patterns in data automatically, they often require algorithm-specific parameters, such as an appropriate distance function, which are outside the purview of a domain expert. We present a system that allows an expert to interact directly with a visual representation of the data to define an appropriate distance function, thus avoiding direct manipulation of obtuse model parameters. Adopting an iterative approach, our system first assumes a uniformly weighted Euclidean distance function and projects the data into a two-dimensional scatterplot view. The user can then move incorrectly-positioned data points to locations that reflect his or her understanding of the similarity of those data points relative to the other data points. Based on this input, the system performs an optimization to learn a new distance function and then re-projects the data to redraw the scatter-plot. We illustrate empirically that with only a few iterations of interaction and optimization, a user can achieve a scatterplot view and its corresponding distance function that reflect the user's knowledge of the data. In addition, we evaluate our system to assess scalability in data size and data dimension, and show that our system is computationally efficient and can provide an interactive or near-interactive user experience.	Eli T. Brown;Jingjing Liu;Carla E. Brodley;Remco Chang	Dept. of Comput. Sci., Tufts Univ., Medford, MA, USA|c|;;;	10.1109/VISUAL.1990.146402;10.1109/VAST.2011.6102449;10.1109/VAST.2007.4388999;10.1109/VAST.2009.5332584;10.1109/VAST.2011.6102448;10.1109/VAST.2008.4677352;10.1109/VAST.2010.5652443		
VAST	2012	Just-in-time annotation of clusters, outliers, and trends in point-based data visualizations	10.1109/VAST.2012.6400487	http://dx.doi.org/10.1109/VAST.2012.6400487	73	82	C	We introduce the concept of just-in-time descriptive analytics as a novel application of computational and statistical techniques performed at interaction-time to help users easily understand the structure of data as seen in visualizations. Fundamental to just-intime descriptive analytics is (a) identifying visual features, such as clusters, outliers, and trends, user might observe in visualizations automatically, (b) determining the semantics of such features by performing statistical analysis as the user is interacting, and (c) enriching visualizations with annotations that not only describe semantics of visual features but also facilitate interaction to support high-level understanding of data. In this paper, we demonstrate just-in-time descriptive analytics applied to a point-based multi-dimensional visualization technique to identify and describe clusters, outliers, and trends. We argue that it provides a novel user experience of computational techniques working alongside of users allowing them to build faster qualitative mental models of data by demonstrating its application on a few use-cases. Techniques used to facilitate just-in-time descriptive analytics are described in detail along with their runtime performance characteristics. We believe this is just a starting point and much remains to be researched, as we discuss open issues and opportunities in improving accessibility and collaboration.	Eser Kandogan		10.1109/INFVIS.2003.1249015;10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2004.3;10.1109/TVCG.2011.220;10.1109/INFVIS.2004.15;10.1109/INFVIS.1998.729559;10.1109/VAST.2006.261423;10.1109/TVCG.2009.153;10.1109/VAST.2010.5652885;10.1109/VAST.2009.5332628;10.1109/TVCG.2011.229	Just-in-time descriptive analytics, feature identification and characterization, point-based visualizations	
VAST	2012	Subspace search and visualization to make sense of alternative clusterings in high-dimensional data	10.1109/VAST.2012.6400488	http://dx.doi.org/10.1109/VAST.2012.6400488	63	72	C	In explorative data analysis, the data under consideration often resides in a high-dimensional (HD) data space. Currently many methods are available to analyze this type of data. So far, proposed automatic approaches include dimensionality reduction and cluster analysis, whereby visual-interactive methods aim to provide effective visual mappings to show, relate, and navigate HD data. Furthermore, almost all of these methods conduct the analysis from a singular perspective, meaning that they consider the data in either the original HD data space, or a reduced version thereof. Additionally, HD data spaces often consist of combined features that measure different properties, in which case the particular relationships between the various properties may not be clear to the analysts a priori since it can only be revealed if appropriate feature combinations (subspaces) of the data are taken into consideration. Considering just a single subspace is, however, often not sufficient since different subspaces may show complementary, conjointly, or contradicting relations between data items. Useful information may consequently remain embedded in sets of subspaces of a given HD input data space. Relying on the notion of subspaces, we propose a novel method for the visual analysis of HD data in which we employ an interestingness-guided subspace search algorithm to detect a candidate set of subspaces. Based on appropriately defined subspace similarity functions, we visualize the subspaces and provide navigation facilities to interactively explore large sets of subspaces. Our approach allows users to effectively compare and relate subspaces with respect to involved dimensions and clusters of objects. We apply our approach to synthetic and real data sets. We thereby demonstrate its support for understanding HD data from different perspectives, effectively yielding a more complete view on HD data.	Andrada Tatu;Fabian Maass;Ines Färber;Enrico Bertini;Tobias Schreck;Thomas Seidl 0001;Daniel A. Keim	Univ. of Konstanz, Konstanz, Germany|c|;;;;;;	10.1109/INFVIS.2005.1532142;10.1109/TVCG.2010.138;10.1109/VAST.2010.5652392;10.1109/INFVIS.2004.71;10.1109/VAST.2010.5652450;10.1109/VAST.2011.6102439;10.1109/TVCG.2011.188;10.1109/INFVIS.2004.3;10.1109/TVCG.2009.153		
VAST	2012	iLAMP: Exploring high-dimensional spacing through backward multidimensional projection	10.1109/VAST.2012.6400489	http://dx.doi.org/10.1109/VAST.2012.6400489	53	62	C	Ever improving computing power and technological advances are greatly augmenting data collection and scientific observation. This has directly contributed to increased data complexity and dimensionality, motivating research of exploration techniques for multidimensional data. Consequently, a recent influx of work dedicated to techniques and tools that aid in understanding multidimensional datasets can be observed in many research fields, including biology, engineering, physics and scientific computing. While the effectiveness of existing techniques to analyze the structure and relationships of multidimensional data varies greatly, few techniques provide flexible mechanisms to simultaneously visualize and actively explore high-dimensional spaces. In this paper, we present an inverse linear affine multidimensional projection, coined iLAMP, that enables a novel interactive exploration technique for multidimensional data. iLAMP operates in reverse to traditional projection methods by mapping low-dimensional information into a high-dimensional space. This allows users to extrapolate instances of a multidimensional dataset while exploring a projection of the data to the planar domain. We present experimental results that validate iLAMP, measuring the quality and coherence of the extrapolated data; as well as demonstrate the utility of iLAMP to hypothesize the unexplored regions of a high-dimensional space.	Elisa Portes dos Santos;Emilio Vital Brazil;Joel Daniels II;Paulo Joia;Luis Gustavo Nonato;Mario Costa Sousa	;;;;;	10.1109/INFVIS.2005.1532138;10.1109/TVCG.2008.116;10.1109/TVCG.2010.213;10.1109/TVCG.2009.140;10.1109/TVCG.2011.220;10.1109/VISUAL.1999.809866;10.1109/TVCG.2006.170;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2004.15;10.1109/TVCG.2008.153;10.1109/INFVIS.2002.1173159;10.1109/INFVIS.2003.1249015;10.1109/VISUAL.1990.146402;10.1109/VISUAL.1996.567787;10.1109/TVCG.2010.170;10.1109/TVCG.2007.70580;10.1109/TVCG.2010.207;10.1109/INFVIS.2002.1173161		
VAST	2012	Visual pattern discovery using random projections	10.1109/VAST.2012.6400490	http://dx.doi.org/10.1109/VAST.2012.6400490	43	52	C	An essential element of exploratory data analysis is the use of revealing low-dimensional projections of high-dimensional data. Projection Pursuit has been an effective method for finding interesting low-dimensional projections of multidimensional spaces by optimizing a score function called a projection pursuit index. However, the technique is not scalable to high-dimensional spaces. Here, we introduce a novel method for discovering noteworthy views of high-dimensional data spaces by using binning and random projections. We define score functions, akin to projection pursuit indices, that characterize visual patterns of the low-dimensional projections that constitute feature subspaces. We also describe an analytic, multivariate visualization platform based on this algorithm that is scalable to extremely large problems.	Anushka Anand;Leland Wilkinson;Dang Tuan Nhon	Dept. of Comput. Sci., Univ. of Illinois at Chicago, Chicago, IL, USA|c|;;	10.1109/VAST.2010.5652433;10.1109/TVCG.2011.178;10.1109/VAST.2011.6102437;10.1109/VAST.2007.4389006;10.1109/VAST.2010.5652392;10.1109/INFVIS.2005.1532142;10.1109/VAST.2009.5332629	Random Projections, High-dimensional Data	
VAST	2012	A correlative analysis process in a visual analytics environment	10.1109/VAST.2012.6400491	http://dx.doi.org/10.1109/VAST.2012.6400491	33	42	C	Finding patterns and trends in spatial and temporal datasets has been a long studied problem in statistics and different domains of science. This paper presents a visual analytics approach for the interactive exploration and analysis of spatiotemporal correlations among multivariate datasets. Our approach enables users to discover correlations and explore potentially causal or predictive links at different spatiotemporal aggregation levels among the datasets, and allows them to understand the underlying statistical foundations that precede the analysis. Our technique utilizes the Pearson's product-moment correlation coefficient and factors in the lead or lag between different datasets to detect trends and periodic patterns amongst them.	Abish Malik;Ross Maciejewski;Niklas Elmqvist;Yun Jang;David S. Ebert;Whitney Huang	Purdue Univ., West Lafayette, IN, USA|c|;;;;;	10.1109/INFVIS.2005.1532148;10.1109/TVCG.2011.179;10.1109/TVCG.2010.193;10.1109/INFVIS.1999.801851;10.1109/INFVIS.1999.801851;10.1109/VAST.2007.4389006;10.1109/TVCG.2007.70539;10.1109/TVCG.2010.162;10.1109/TVCG.2011.195	Visual analytics, correlative analysis	
VAST	2012	Inter-active learning of ad-hoc classifiers for video visual analytics	10.1109/VAST.2012.6400492	http://dx.doi.org/10.1109/VAST.2012.6400492	23	32	C	Learning of classifiers to be used as filters within the analytical reasoning process leads to new and aggravates existing challenges. Such classifiers are typically trained ad-hoc, with tight time constraints that affect the amount and the quality of annotation data and, thus, also the users' trust in the classifier trained. We approach the challenges of ad-hoc training by inter-active learning, which extends active learning by integrating human experts' background knowledge to greater extent. In contrast to active learning, not only does inter-active learning include the users' expertise by posing queries of data instances for labeling, but it also supports the users in comprehending the classifier model by visualization. Besides the annotation of manually or automatically selected data instances, users are empowered to directly adjust complex classifier models. Therefore, our model visualization facilitates the detection and correction of inconsistencies between the classifier model trained by examples and the user's mental model of the class definition. Visual feedback of the training process helps the users assess the performance of the classifier and, thus, build up trust in the filter created. We demonstrate the capabilities of inter-active learning in the domain of video visual analytics and compare its performance with the results of random sampling and uncertainty sampling of training sets.	Benjamin Höferlin;Rudolf Netzel;Markus Höferlin;Daniel Weiskopf;Gunther Heidemann	;;;;	10.1109/VAST.2010.5652398;10.1109/TVCG.2012.277		
VAST	2012	An adaptive parameter space-filling algorithm for highly interactive cluster exploration	10.1109/VAST.2012.6400493	http://dx.doi.org/10.1109/VAST.2012.6400493	13	22	C	For a user to perceive continuous interactive response time in a visualization tool, the rule of thumb is that it must process, deliver, and display rendered results for any given interaction in under 100 milliseconds. In many visualization systems, successive interactions trigger independent queries and caching of results. Consequently, computationally expensive queries like multidimensional clustering cannot keep up with rapid sequences of interactions, precluding visual benefits such as motion parallax. In this paper, we describe a heuristic prefetching technique to improve the interactive response time of KMeans clustering in dynamic query visualizations of multidimensional data. We address the tradeoff between high interaction and intense query computation by observing how related interactions on overlapping data subsets produce similar clustering results, and characterizing these similarities within a parameter space of interaction. We focus on the two-dimensional parameter space defined by the minimum and maximum values of a time range manipulated by dragging and stretching a one-dimensional filtering lens over a plot of time series data. Using calculation of nearest neighbors of interaction points in parameter space, we reuse partial query results from prior interaction sequences to calculate both an immediate best-effort clustering result and to schedule calculation of an exact result. The method adapts to user interaction patterns in the parameter space by reprioritizing the interaction neighbors of visited points in the parameter space. A performance study on Mesonet meteorological data demonstrates that the method is a significant improvement over the baseline scheme in which interaction triggers on-demand, exact-range clustering with LRU caching. We also present initial evidence that approximate, temporary clustering results are sufficiently accurate (compared to exact results) to convey useful cluster structure during rapid and protracted interaction.	Zafar Ahmed;Chris Weaver	Sch. of Comput. Sci. &amp; Center for Spatial Anal., Univ. of Oklahoma, Norman, OK, USA|c|;	10.1109/TVCG.2007.70515;10.1109/INFVIS.2004.12;10.1109/VAST.2009.5332629;10.1109/VAST.2008.4677357;10.1109/TVCG.2011.188;10.1109/VISUAL.1994.346302;10.1109/INFVIS.1998.729559;10.1109/VAST.2007.4388999		
VAST	2012	Visual cluster exploration of web clickstream data	10.1109/VAST.2012.6400494	http://dx.doi.org/10.1109/VAST.2012.6400494	3	12	C	Web clickstream data are routinely collected to study how users browse the web or use a service. It is clear that the ability to recognize and summarize user behavior patterns from such data is valuable to e-commerce companies. In this paper, we introduce a visual analytics system to explore the various user behavior patterns reflected by distinct clickstream clusters. In a practical analysis scenario, the system first presents an overview of clickstream clusters using a Self-Organizing Map with Markov chain models. Then the analyst can interactively explore the clusters through an intuitive user interface. He can either obtain summarization of a selected group of data or further refine the clustering result. We evaluated our system using two different datasets from eBay. Analysts who were working on the same data have confirmed the system's effectiveness in extracting user behavior patterns from complex datasets and enhancing their ability to reason.	Jishang Wei;Zeqian Shen;Neel Sundaresan;Kwan-Liu Ma	;;;	10.1109/INFVIS.2005.1532145;10.1109/VAST.2007.4389008;10.1109/VAST.2011.6102462;10.1109/VISUAL.1991.175815		
VAST	2012	LensingWikipedia: Parsing text for the interactive visualization of human history	10.1109/VAST.2012.6400530	http://dx.doi.org/10.1109/VAST.2012.6400530	247	248	M	Extracting information from text is challenging. Most current practices treat text as a bag of words or word clusters, ignoring valuable linguistic information. Leveraging this linguistic information, we propose a novel approach to visualize textual information. The novelty lies in using state-of-the-art Natural Language Processing (NLP) tools to automatically annotate text which provides a basis for new and powerful interactive visualizations. Using NLP tools, we built a web-based interactive visual browser for human history articles from Wikipedia.	Ravikiran Vadlapudi;Maryam Siahbani;Anoop Sarkar;John Dill	;;;			
VAST	2012	VDQAM: A toolkit for database quality evaluation based on visual morphology	10.1109/VAST.2012.6400531	http://dx.doi.org/10.1109/VAST.2012.6400531	245	246	M	Data quality evaluation is one of the most critical steps during the data mining processes. Data with poor quality often leads to poor performance in data mining, low efficiency in data analysis, wrong decision which bring great economic loss to users and organizations further. Although many researches have been carried out from various aspects of the extracting, transforming, and loading processes in data mining, most researches pay more attention to analysis automation than to data quality evaluation. To address the data quality evaluation issues, we propose an approach to combine human beings' powerful cognitive abilities in data quality evaluation with the high efficiency ability of computer, and develop a visual analysis method for data quality evaluation based on visual morphology.	Dongxing Teng;Haiyan Yang;CuiXia Ma;Hongan Wang	Inst. of Software, Beijing, China|c|;;;			
VAST	2012	A case study: Tracking and visualizing the evolution of dark matter halos and groups of satellite halos in cosmology simulations	10.1109/VAST.2012.6400532	http://dx.doi.org/10.1109/VAST.2012.6400532	243	244	M	In this poster, we track the evolution of cosmic structures and higher level host structures in cosmological simulation as they interact with each other. The structures found in these simulations are made up of groups of dark matter tracer particles called satellite halos and groups of satellite halos called host halos. We implement a multilevel tracking model to track dark matter tracer particles, satellite halos and host halos to understand their behaviour and show how the different structures are formed over time. We also represent the evolution of halos in the form of merger trees for detailed analysis by cosmologists.	Jay Takle;Deborah Silver;Katrin Heitmann	Dept. of Electr. &amp; Comput. Eng., Rutgers Univ., Piscataway, NJ, USA|c|;;			
VAST	2012	Infographics at the Congressional Budget Office	10.1109/VAST.2012.6400533	http://dx.doi.org/10.1109/VAST.2012.6400533	241	242	M	The Congressional Budget Office (CBO) is an agency of the federal government with about 240 employees that provides the U.S. Congress with timely, nonpartisan analysis of important budgetary and economic issues. Recently, CBO began producing static infographics to present its headline stories and to provide information to the Congress in different ways.	Jonathan A. Schwabish				
VAST	2012	Visual exploration of local interest points in sets of time series	10.1109/VAST.2012.6400534	http://dx.doi.org/10.1109/VAST.2012.6400534	239	240	M	Visual analysis of time series data is an important, yet challenging task with many application examples in fields such as financial or news stream data analysis. Many visual time series analysis approaches consider a global perspective on the time series. Fewer approaches consider visual analysis of local patterns in time series, and often rely on interactive specification of the local area of interest. We present initial results of an approach that is based on automatic detection of local interest points. We follow an overview-first approach to find useful parameters for the interest point detection, and details-on-demand to relate the found patterns. We present initial results and detail possible extensions of the approach.	Tobias Schreck;Lyubka Sharalieva;Franz Wanner;Jürgen Bernard;Tobias Ruppert;Tatiana von Landesberger;Benjamin Bustos	Univ. of Konstanz, Konstanz, Germany|c|;;;;;;			
VAST	2012	Priming Locus of Control to affect performance	10.1109/VAST.2012.6400535	http://dx.doi.org/10.1109/VAST.2012.6400535	237	238	M	Recent research suggests that the personality trait Locus of Control (LOC) can be a reliable predictor of performance when learning a new visualization tool. While these results are compelling and have direct implications to visualization design, the relationship between a user's LOC measure and their performance is not well understood. We hypothesize that there is a dependent relationship between LOC and performance; specifically, a person's orientation on the LOC scale directly influences their performance when learning new visualizations. To test this hypothesis, we conduct an experiment with 300 subjects using Amazon's Mechanical Turk. We adapt techniques from personality psychology to manipulate a user's LOC so that users are either primed to be more internally or externally oriented on the LOC scale. Replicating previous studies investigating the effect of LOC on performance, we measure users' speed and accuracy as they use visualizations with varying visual metaphors. Our findings demonstrate that changing a user's LOC impacts their performance. We find that a change in users' LOC results in performance changes.	Alvitta Ottley;R. Jordan Crouser;Caroline Ziemkiewicz;Remco Chang	;;;			
VAST	2012	The spatiotemporal multivariate hypercube for discovery of patterns in event data	10.1109/VAST.2012.6400536	http://dx.doi.org/10.1109/VAST.2012.6400536	235	236	M	Event data can hold valuable decision making information, yet detecting interesting patterns in this type of data is not an easy task because the data is usually rich and contains spatial, temporal as well as multivariate dimensions. Research into visual analytics tools to support the discovery of patterns in event data often focuses on the spatiotemporal or spatiomultivariate dimension of the data only. Few research efforts focus on all three dimensions in one framework. An integral view on all three dimensions is, however, required to unlock the full potential of event datasets. In this poster, we present an event visualization, transition, and interaction framework that enables an integral view on all dimensions of spatiotemporal multivariate event data. The framework is built around the notion that the event data space can be considered a spatiotemporal multivariate hypercube. Results of a case study we performed suggest that a visual analytics tool based on the proposed framework is indeed capable to support users in the discovery of multidimensional spatiotemporal multivariate patterns in event data.	Fred Olislagers;Marcel Worring	Intell. Syst. Lab. Amsterdam, Univ. of Amsterdam, Amsterdam, Netherlands|c|;			
VAST	2012	A generic model for the integration of interactive visualization and statistical computing using R	10.1109/VAST.2012.6400537	http://dx.doi.org/10.1109/VAST.2012.6400537	233	234	M	This poster describes general concepts of integrating the statistical computation package R into a coordinated multiple views framework. The integration is based on a cyclic analysis workflow. In this model, interactive selections are a key aspect to trigger and control computations in R. Dynamic updates of data columns are a generic mechanism to transfer computational results back to the interactive visualization. Further aspects include the integration of the R console and an R object browser as views in our system. We illustrate our approach by means of an interactive modeling process.	Johannes Kehrer;Roland N. Boubela;Peter Filzmoser;Harald Piringer	VRVis Res. Center, Vienna, Austria|c|;;;			
VAST	2012	Using visual analytics to detect problems in datasets collected from photo-sharing services	10.1109/VAST.2012.6400538	http://dx.doi.org/10.1109/VAST.2012.6400538	231	232	M	Datasets that are collected for research often contain millions of records and may carry hidden pitfalls that are hard to detect. This work demonstrates how visual analytics can be used for identifying problems in the spatial distribution of crawled photographic data in different datasets: Picasa Web Albums, Panoramio, Flickr and Geograph, chosen to be potential data sources for ongoing doctoral research. This poster summary describes a number of problems found in the datasets using visual analytics and suggests that greater attention should be paid to assessing the quality of data gathered from user-generated photographic content. This work is the first part of a three-year PhD project aimed at producing a pedestrian-routing system that can suggest attractive pathways extracted from user-generated photographic content.	Alexander Kachkaev;Jo Wood	giCentre, City Univ. London, London, UK|c|;			
VAST	2012	Visualizing flows of images in social media	10.1109/VAST.2012.6400539	http://dx.doi.org/10.1109/VAST.2012.6400539	229	230	M	Mass and social media provide flows of images for real world events. It is sometimes difficult to represent realities and impressions of events using only text. However, even a single photo might remind us complex events. Along with events in the real world, there are representative images, such as design of products and commercial pictures. We can therefore recognize changes in trends of people's ideas, experiences, and interests through observing the flows of such representative images. This paper presents a novel 3D visualization system to explore temporal changes in trends using images associating with different topics, called Image Bricks. We show case studies using images extracted from our six-year blog archive. We first extract clusters of images as topics related to given keywords. We then visualize them on multiple timelines in a 3D space. Users can visually read stories of topics through exploring visualized images.	Masahiko Itoh;Masashi Toyoda;Tetsuya Kamijo;Masaru Kitsuregawa	;;;			
VAST	2012	Exploring the impact of emotion on visual judgement	10.1109/VAST.2012.6400540	http://dx.doi.org/10.1109/VAST.2012.6400540	227	228	M	Existing research suggests that individual personality differences can influence performance with visualizations. In addition to stable traits such as locus of control, research in psychology has found that temporary changes in affect (emotion) can significantly impact individual performance on cognitive tasks. We examine the relationship between fundamental visual judgement tasks and affect through a crowdsourced user study that combines affective-priming techniques from psychology with longstanding graphical perception experiments. Our results suggest that affective-priming can significantly influence accuracy in visual judgements, and that some chart types may be more affected than others.	Lane Harrison;Remco Chang;Aidong Lu	UNC-Charlotte, Charlotte, NC, USA|c|;;			
VAST	2012	Exploring cyber physical data streams using Radial Pixel Visualizations	10.1109/VAST.2012.6400541	http://dx.doi.org/10.1109/VAST.2012.6400541	225	226	M	Cyber physical systems (CPS), such as smart buildings and data centers, are richly instrumented systems composed of tightly coupled computational and physical elements that generate large amounts of data. To explore CPS data and obtain actionable insights, we construct a Radial Pixel Visualization (RPV) system, which uses multiple concentric rings to show the data in a compact circular layout of small polygons (pixel cells), each of which represents an individual data value. RPV provides an effective visual representation of locality and periodicity of the high volume, multivariate data streams, and seamlessly combines them with the results of an automated analysis. In the outermost ring the results of correlation analysis and peak point detection are highlighted. Our explorations demonstrates how RPV can help administrators to identify periodic thermal hot spots, understand data center energy consumption, and optimize IT workload.	Ming C. Hao;Manish Marwah;Sebastian Mittelstädt;Halldór Janetzko;Daniel A. Keim;Umeshwar Dayal;Cullen Bash;Carlos J. Felix;Chandrakant D. Patel;Meichun Hsu;Yuan Chen	Hewlett-Packard Labs., Palo Alto, CA, USA|c|;;;;;;;;;;			
VAST	2012	Incorporating GOMS analysis into the design of an EEG data visual analysis tool	10.1109/VAST.2012.6400542	http://dx.doi.org/10.1109/VAST.2012.6400542	223	224	M	In this paper, we present a case study where we incorporate GOMS (Goals, Operators, Methods, and Selectors) [2] task analysis into the design process of a visual analysis tool. We performed GOMS analysis on an Electroencephalography (EEG) analyst's current data analysis strategy to identify important user tasks and unnecessary user actions in his current workflow. We then designed an EEG data visual analysis tool based on the GOMS analysis result. Evaluation results show that the tool we have developed, EEGVis, allows the user to analyze EEG data with reduced subjective cognitive load, faster speed and increased confidence in the analysis quality. The positive evaluation results suggest that our design process demonstrates an effective application of GOMS analysis to discover opportunities for designing better tools to support the user's visual analysis process.	Hua Guo;Diem Tran;David H. Laidlaw	Dept. of Comput. Sci., Brown Univ., Providence, RI, USA|c|;;			
VAST	2012	Using translational science in visual analytics	10.1109/VAST.2012.6400543	http://dx.doi.org/10.1109/VAST.2012.6400543	221	222	M	We introduce translational science, a research discipline from medicine, and show how adapting it for visual analytics can improve the design and evaluation of visual analytics interfaces. Translational science â€œtranslatesâ€ knowledge from the lab to the real-world to â€œground truthâ€ by incorporating a 3 phase program of research. Phase 1 & 2 include protocols for research in the lab and field and Phase 3 focuses on dissemination and documentation. We discuss these phases and how they may be applied to visual analytics research.	Tera Marie Green;Brian D. Fisher	Sch. of Interactive Arts + Sci., Simon Fraser Univ., Surrey, BC, Canada|c|;			
VAST	2012	Optimizing an SPT-tree for visual analytics	10.1109/VAST.2012.6400544	http://dx.doi.org/10.1109/VAST.2012.6400544	219	220	M	Despite the extensive work done in the scientific visualization community on the creation and optimization of spatial data structures, there has been little adaptation of these structures in visual analytics and information visualization. In this work we present how we modify a space-partioning time (SPT) tree - a structure normally used in direct-volume rendering - for geospatial-temporal visualizations. We also present optimization techniques to improve the traversal speed of our structure through locational codes and bitwise comparisons. Finally, we present the results of an experiment that quantitatively evaluates our modified SPT tree with and without our optimizations. Our results indicate that retrieval was nearly three times faster when using our optimizations, and are consistent across multiple trials. Our finding could have implications for performance in using our modified SPT tree in large-scale geospatial temporal visual analytics software.	Connor Gramazio;Remco Chang	;			
VAST	2012	Visualising variations in household energy consumption	10.1109/VAST.2012.6400545	http://dx.doi.org/10.1109/VAST.2012.6400545	217	218	M	There is limited understanding of the relationship between neighbourhoods, demographic characteristics and domestic energy consumption habits. We report upon research that combines datasets relating to household energy use with geodemographics to enable better understanding of UK energy user types. A novel interactive interface is planned to evaluate the performance of specifically created energy-based data classifications. The research aims to help local governments and the energy industry in targeting households and populations for new energy saving schemes and in improving efforts to promote sustainable energy consumption. The new classifications may also stimulate consumption awareness amongst domestic users. This poster reports on initial visual findings and describes the research methodology, data sources and future visualisation requirements.	Sarah Goodwin;Jason Dykes	giCentre, City Univ. London, London, UK|c|;			
VAST	2012	Time-oriented visualization and anticipation	10.1109/VAST.2012.6400546	http://dx.doi.org/10.1109/VAST.2012.6400546	215	216	M	Temporal awareness is pivotal to successful real-time dynamic decision making in a wide range of command and control situations; particularly in safety-critical environments. However, little explicit support for operators' temporal awareness is provided by decision support systems (DSS) for time-critical decisions. In the context of functional simulations of naval anti-air warfare and emergency response management, the present study compares operator support provided by two display formats. In both environments, we contrast a baseline condition to a condition in which a temporal display was integrated to the original interface to support operators' temporal awareness. We also wish to establish whether the implementation of time-based DSSs may also come with drawbacks on cognitive functioning and performance.	Cindy Chamberland;François Vachon;Jean-François Gagnon;Simon P. Banbury;Sébastien Tremblay	Univ. Laval, Quebec City, QC, Canada|c|;;;;			
VAST	2012	Augmenting visual representation of affectively charged information using sound graphs	10.1109/VAST.2012.6400547	http://dx.doi.org/10.1109/VAST.2012.6400547	213	214	M	Within the Visual Analytics research agenda there is an interest on studying the applicability of multimodal information representation and interaction techniques for the analytical reasoning process. The present study summarizes a pilot experiment conducted to understand the effects of augmenting visualizations of affectively-charged information using auditory graphs. We designed an audiovisual representation of social comments made to different news posted on a popular website, and their affective dimension using a sentiment analysis tool for short texts. Participants of the study were asked to create an assessment of the affective valence trend (positive or negative) of the news articles using for it, the visualizations and sonifications. The conditions were tested looking for speed/accuracy trade off comparing the visual representation with an audiovisual one. We discuss our preliminary findings regarding the design of augmented information-representation.	Nadya A. Calderón;Bernhard E. Riecke;Brian D. Fisher	;;			
VAST	2012	Feature-similarity visualization of MRI cortical surface data	10.1109/VAST.2012.6400548	http://dx.doi.org/10.1109/VAST.2012.6400548	211	212	M	We present an analytics-based framework for simultaneous visualization of large surface data collections arising in clinical neuroimaging studies. Termed Informatics Visualization for Neuroimaging (INVIZIAN), this framework allows the visualization of both cortical surfaces characteristics and feature relatedness in unison. It also uses dimension reduction methods to derive new coordinate systems using a Jensen-Shannon divergence metric for positioning cortical surfaces in a metric space such that the proximity in location is proportional to neuroanatomical similarity. Feature data such as thickness and volume are colored on the cortical surfaces and used to display both subject-specific feature values and global trends within the population. Additionally, a query-based framework allows the neuroscience researcher to investigate probable correlations between neuroanatomical and subject patient attribute values such as age and diagnosis.	Ian Bowman;Shantanu H. Joshi;Vaughan Greer;John D. Van Horn	Sch. of Med., Lab. of Neuro Imaging, UCLA, Los Angeles, CA, USA|c|;;;			
VAST	2012	Matrix-based visual correlation analysis on large timeseries data	10.1109/VAST.2012.6400549	http://dx.doi.org/10.1109/VAST.2012.6400549	209	210	M	In recent years, the quantity of time series data generated in a wide variety of domains grown consistently. Thus, it is difficult for analysts to process and understand this overwhelming amount of data. In the specific case of time series data another problem arises: time series can be highly interrelated. This problem becomes even more challenging when a set of parameters influences the progression of a time series. However, while most visual analysis techniques support the analysis of short time periods, e.g. one day or one week, they fail to visualize large-scale time series, ranging over one year or more. In our approach we present a time series matrix visualization that tackles this problem. Its primary advantages are that it scales to a large number of time series with different start and end points and allows for the visual comparison / correlation analysis of a set of influencing factors. To evaluate our approach, we applied our technique to a real-world data set, showing the impact of local weather conditions on the efficiency of photovoltaic power plants.	Michael Behrisch;James Davey;Tobias Schreck;Daniel A. Keim;Jörn Kohlhammer	;;;;			
VAST	2012	A visual analytics approach to understanding cycling behaviour	10.1109/VAST.2012.6400550	http://dx.doi.org/10.1109/VAST.2012.6400550	207	208	M	Existing research into cycling behaviours has either relied on detailed ethnographic studies or larger public attitude surveys [1] [9]. Instead, following recent contributions from information visualization [13] and data mining [5] [7], this design study uses visual analytics techniques to identify, describe and explain cycling behaviours within a large and attribute rich transactional dataset. Using data from London's bike share scheme1, customer level classifications will be created, which consider the regularity of scheme use, journey length and travel times. Monitoring customer usage over time, user classifications will attend to the dynamics of cycling behaviour, asking substantive questions about how behaviours change under varying conditions. The 3-year PhD project will contribute to academic and strategic discussions around sustainable travel policy. A programme of research is outlined, along with an early visual analytics prototype for rapidly querying customer journeys.	Roger Beecham;Jo Wood;Audrey Bowerman	City Univ. London, London, UK|c|;;			
VAST	2012	Information retrieval failure analysis: Visual analytics as a support for interactive "what-if" investigation	10.1109/VAST.2012.6400551	http://dx.doi.org/10.1109/VAST.2012.6400551	204	206	M	This poster provides an analytical model for examining performances of IR systems, based on the discounted cumulative gain family of metrics, and visualization for interacting and exploring the performances of the system under examination. Moreover, we propose machine learning approach to learn the ranking model of the examined system in order to be able to conduct a â€œwhat-ifâ€ analysis and visually explore what can happen if you adopt a given solution before having to actually implement it.	Marco Angelini;Nicola Ferro;Guido Granato;Giuseppe Santucci;Gianmaria Silvello	Sapienza Univ. of Roma, Rome, Italy|c|;;;;			
VAST	2012	Watch this: A taxonomy for dynamic data visualization	10.1109/VAST.2012.6400552	http://dx.doi.org/10.1109/VAST.2012.6400552	193	202	C	Visualizations embody design choices about data access, data transformation, visual representation, and interaction. To interpret a static visualization, a person must identify the correspondences between the visual representation and the underlying data. These correspondences become moving targets when a visualization is dynamic. Dynamics may be introduced in a visualization at any point in the analysis and visualization process. For example, the data itself may be streaming, shifting subsets may be selected, visual representations may be animated, and interaction may modify presentation. In this paper, we focus on the impact of dynamic data. We present a taxonomy and conceptual framework for understanding how data changes influence the interpretability of visual representations. Visualization techniques are organized into categories at various levels of abstraction. The salient characteristics of each category and task suitability are discussed through examples from the scientific literature and popular practices. Examining the implications of dynamically updating visualizations warrants attention because it directly impacts the interpretability (and thus utility) of visualizations. The taxonomy presented provides a reference point for further exploration of dynamic data visualization techniques.	Joseph A. Cottam;Andrew Lumsdaine;Chris Weaver	Indiana Univ., Bloomington, IN, USA|c|;;	10.1109/TVCG.2009.123;10.1109/INFVIS.2004.65;10.1109/TVCG.2007.70539;10.1109/TVCG.2008.125;10.1109/INFVIS.2000.885092	Dynamic Data, Interpretation	
VAST	2012	Visual analytics methods for categoric spatio-temporal data	10.1109/VAST.2012.6400553	http://dx.doi.org/10.1109/VAST.2012.6400553	183	192	C	We focus on visual analysis of space- and time-referenced categorical data, which describe possible states of spatial (geographical) objects or locations and their changes over time. The analysis of these data is difficult as there are only limited possibilities to analyze the three aspects (location, time and category) simultaneously. We present a new approach which interactively combines (a) visualization of categorical changes over time; (b) various spatial data displays; (c) computational techniques for task-oriented selection of time steps. They provide an expressive visualization with regard to either the overall evolution over time or unusual changes. We apply our approach on two use cases demonstrating its usefulness for a wide variety of tasks. We analyze data from movement tracking and meteorologic areas. Using our approach, expected events could be detected and new insights were gained.	Tatiana von Landesberger;Sebastian Bremm;Natalia V. Andrienko;Gennady L. Andrienko;Maria Tekusova	Tech. Univ. Darmstadt, Darmstadt, Germany|c|;;;;	10.1109/TVCG.2011.174;10.1109/TVCG.2009.117;10.1109/TVCG.2009.181;10.1109/INFVIS.2000.885098;10.1109/TVCG.2010.138;10.1109/VAST.2010.5652530;10.1109/INFVIS.2004.27;10.1109/INFVIS.2005.1532152;10.1109/INFVIS.2001.963281;10.1109/TVCG.2008.165;10.1109/TVCG.2009.153		
VAST	2012	Visual analytics for the big data era---A comparative review of state-of-the-art commercial systems	10.1109/VAST.2012.6400554	http://dx.doi.org/10.1109/VAST.2012.6400554	173	182	C	Visual analytics (VA) system development started in academic research institutions where novel visualization techniques and open source toolkits were developed. Simultaneously, small software companies, sometimes spin-offs from academic research institutions, built solutions for specific application domains. In recent years we observed the following trend: some small VA companies grew exponentially; at the same time some big software vendors such as IBM and SAP started to acquire successful VA companies and integrated the acquired VA components into their existing frameworks. Generally the application domains of VA systems have broadened substantially. This phenomenon is driven by the generation of more and more data of high volume and complexity, which leads to an increasing demand for VA solutions from many application domains. In this paper we survey a selection of state-of-the-art commercial VA frameworks, complementary to an existing survey on open source VA tools. From the survey results we identify several improvement opportunities as future research directions.	Leishi Zhang;Andreas Stoffel;Michael Behrisch;Sebastian Mittelstädt;Tobias Schreck;René Pompl;Stefan Weber 0004;Holger Last;Daniel A. Keim	Univ. of Konstanz, Konstanz, Germany|c|;;;;;;;;	10.1109/INFVIS.2004.12;10.1109/INFVIS.2004.64;10.1109/INFVIS.2000.885098		
VAST	2012	Smart super views---A knowledge-assisted interface for medical visualization	10.1109/VAST.2012.6400555	http://dx.doi.org/10.1109/VAST.2012.6400555	163	172	C	Due to the ever growing volume of acquired data and information, users have to be constantly aware of the methods for their exploration and for interaction. Of these, not each might be applicable to the data at hand or might reveal the desired result. Owing to this, innovations may be used inappropriately and users may become skeptical. In this paper we propose a knowledge-assisted interface for medical visualization, which reduces the necessary effort to use new visualization methods, by providing only the most relevant ones in a smart way. Consequently, we are able to expand such a system with innovations without the users to worry about when, where, and especially how they may or should use them. We present an application of our system in the medical domain and give qualitative feedback from domain experts.	Gabriel Mistelbauer;Hamed Bouzari;Rüdiger Schernthaner;Ivan Baclija;Arnold Köchl;Stefan Bruckner;Milos Srámek;Eduard Gröller	Vienna Univ. of Technol., Vienna, Austria|c|;;;;;;;	10.1109/VISUAL.2003.1250400;10.1109/TVCG.2006.152;10.1109/TVCG.2007.70576;10.1109/TVCG.2007.70591;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2005.1532856;10.1109/TVCG.2011.183;10.1109/VISUAL.2005.1532818;10.1109/TVCG.2006.148	Visualization, Fuzzy Logic, Interaction	
VAST	2012	AlVis: Situation awareness in the surveillance of road tunnels	10.1109/VAST.2012.6400556	http://dx.doi.org/10.1109/VAST.2012.6400556	153	162	C	In the surveillance of road tunnels, video data plays an important role for a detailed inspection and as an input to systems for an automated detection of incidents. In disaster scenarios like major accidents, however, the increased amount of detected incidents may lead to situations where human operators lose a sense of the overall meaning of that data, a problem commonly known as a lack of situation awareness. The primary contribution of this paper is a design study of AlVis, a system designed to increase situation awareness in the surveillance of road tunnels. The design of AlVis is based on a simplified tunnel model which enables an overview of the spatiotemporal development of scenarios in real-time. The visualization explicitly represents the present state, the history, and predictions of potential future developments. Concepts for situation-sensitive prioritization of information ensure scalability from normal operation to major disaster scenarios. The visualization enables an intuitive access to live and historic video for any point in time and space. We illustrate AlVis by means of a scenario and report qualitative feedback by tunnel experts and operators. This feedback suggests that AlVis is suitable to save time in recognizing dangerous situations and helps to maintain an overview in complex disaster scenarios.	Harald Piringer;Matthias Buchetics;Rudolf Benedik	;;	10.1109/INFVIS.2002.1173149;10.1109/INFVIS.2005.1532134;10.1109/VAST.2011.6102456;10.1109/TVCG.2007.70544;10.1109/TVCG.2007.70521;10.1109/TVCG.2007.70621;10.1109/INFVIS.2004.27;10.1109/INFVIS.1995.528685;10.1109/TVCG.2008.185;10.1109/VAST.2007.4388994;10.1109/VAST.2007.4388998;10.1109/VAST.2008.4677353		
VAST	2012	Spatiotemporal social media analytics for abnormal event detection and examination using seasonal-trend decomposition	10.1109/VAST.2012.6400557	http://dx.doi.org/10.1109/VAST.2012.6400557	143	152	C	Recent advances in technology have enabled social media services to support space-time indexed data, and internet users from all over the world have created a large volume of time-stamped, geo-located data. Such spatiotemporal data has immense value for increasing situational awareness of local events, providing insights for investigations and understanding the extent of incidents, their severity, and consequences, as well as their time-evolving nature. In analyzing social media data, researchers have mainly focused on finding temporal trends according to volume-based importance. Hence, a relatively small volume of relevant messages may easily be obscured by a huge data set indicating normal situations. In this paper, we present a visual analytics approach that provides users with scalable and interactive social media data analysis and visualization including the exploration and examination of abnormal topics and events within various social media data sources, such as Twitter, Flickr and YouTube. In order to find and understand abnormal events, the analyst can first extract major topics from a set of selected messages and rank them probabilistically using Latent Dirichlet Allocation. He can then apply seasonal trend decomposition together with traditional control chart methods to find unusual peaks and outliers within topic time series. Our case studies show that situational awareness can be improved by incorporating the anomaly and trend examination techniques into a highly interactive visual analysis process.	Junghoon Chae;Dennis Thom;Harald Bosch;Yun Jang;Ross Maciejewski;David S. Ebert;Thomas Ertl	;;;;;;	10.1109/VAST.2011.6102456;10.1109/VAST.2011.6102461;10.1109/TVCG.2008.175		
VAST	2012	SocialNetSense: Supporting sensemaking of social and structural features in networks with interactive visualization	10.1109/VAST.2012.6400558	http://dx.doi.org/10.1109/VAST.2012.6400558	133	142	C	Increasingly, social network datasets contain social attribute information about actors and their relationship. Analyzing such network with social attributes requires making sense of not only its structural features, but also the relationship between social features in attributes and network structures. Existing social network analysis tools are usually weak in supporting complex analytical tasks involving both structural and social features, and often overlook users' needs for sensemaking tools that help to gather, synthesize, and organize information of these features. To address these challenges, we propose a sensemaking framework of social-network visual analytics in this paper. This framework considers both bottom-up processes, which are about constructing new understandings based on collected information, and top-down processes, which concern using prior knowledge to guide information collection, in analyzing social networks from both social and structural perspectives. The framework also emphasizes the externalization of sensemaking processes through interactive visualization. Guided by the framework, we develop a system, SocialNetSense, to support the sensemaking in visual analytics of social networks with social attributes. The example of using our system to analyze a scholar collaboration network shows that our approach can help users gain insight into social networks both structurally and socially, and enhance their process awareness in visual analytics.	Liang Gou;Xiaolong Zhang;Airong Luo;Patricia F. Anderson	Pennsylvania State Univ., University Park, PA, USA|c|;;;	10.1109/INFVIS.1999.801853;10.1109/TVCG.2011.247;10.1109/INFVIS.2005.1532126;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2007.70582;10.1109/TVCG.2006.192;10.1109/VAST.2009.5333020;10.1109/VAST.2011.6102440;10.1109/VAST.2006.261426;10.1109/INFVIS.2004.2;10.1109/TVCG.2008.137;10.1109/TVCG.2006.166;10.1109/TVCG.2006.160;10.1109/VAST.2008.4677365;10.1109/TVCG.2006.147;10.1109/VAST.2007.4389006	Social network, visualization, sensemaking, visual analytics, SocialNetSense	
VAST	2012	Analyst's Workspace: An embodied sensemaking environment for large, high-resolution displays	10.1109/VAST.2012.6400559	http://dx.doi.org/10.1109/VAST.2012.6400559	123	131	C	Distributed cognition and embodiment provide compelling models for how humans think and interact with the environment. Our examination of the use of large, high-resolution displays from an embodied perspective has lead directly to the development of a new sensemaking environment called Analyst's Workspace (AW). AW leverages the embodied resources made more accessible through the physical nature of the display to create a spatial workspace. By combining spatial layout of documents and other artifacts with an entity-centric, explorative investigative approach, AW aims to allow the analyst to externalize elements of the sensemaking process as a part of the investigation, integrated into the visual representations of the data itself. In this paper, we describe the various capabilities of AW and discuss the key principles and concepts underlying its design, emphasizing unique design principles for designing visual analytic tools for large, high-resolution displays.	Christopher Andrews;Chris North	Virginia Tech, Blacksburg, VA, USA|c|;	10.1109/TVCG.2008.121;10.1109/VAST.2008.4677362;10.1109/INFVIS.2004.27;10.1109/VAST.2008.4677358;10.1109/TVCG.2006.184;10.1109/VAST.2007.4388992;10.1109/VAST.2010.5652880;10.1109/VAST.2011.6102449;10.1109/VAST.2007.4389006;10.1109/VAST.2011.6102438;10.1109/VAST.2009.5333878	Embodiment, distributed cognition, large and high-resolution display, sensemaking, space	
VAST	2012	The Deshredder: A visual analytic approach to reconstructing shredded documents	10.1109/VAST.2012.6400560	http://dx.doi.org/10.1109/VAST.2012.6400560	113	122	C	Reconstruction of shredded documents remains a significant challenge. Creating a better document reconstruction system enables not just recovery of information accidentally lost but also understanding our limitations against adversaries' attempts to gain access to information. Existing approaches to reconstructing shredded documents adopt either a predominantly manual (e.g., crowd-sourcing) or a near automatic approach. We describe Deshredder, a visual analytic approach that scales well and effectively incorporates user input to direct the reconstruction process. Deshredder represents shredded pieces as time series and uses nearest neighbor matching techniques that enable matching both the contours of shredded pieces as well as the content of shreds themselves. More importantly, Deshred-der's interface support visual analytics through user interaction with similarity matrices as well as higher level assembly through more complex stitching functions. We identify a functional task taxonomy leading to design considerations for constructing deshredding solutions, and describe how Deshredder applies to problems from the DARPA Shredder Challenge through expert evaluations.	Patrick Butler;Prithwish Chakraborty;Naren Ramakrishnan	Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA|c|;;			
SciVis	2012	A Data-Driven Approach to Hue-Preserving Color-Blending	10.1109/TVCG.2012.186	http://dx.doi.org/10.1109/TVCG.2012.186	2122	2129	J	Color mapping and semitransparent layering play an important role in many visualization scenarios, such as information visualization and volume rendering. The combination of color and transparency is still dominated by standard alpha-compositing using the Porter-Duff over operator which can result in false colors with deceiving impact on the visualization. Other more advanced methods have also been proposed, but the problem is still far from being solved. Here we present an alternative to these existing methods specifically devised to avoid false colors and preserve visual depth ordering. Our approach is data driven and follows the recently formulated knowledge-assisted visualization (KAV) paradigm. Preference data, that have been gathered in web-based user surveys, are used to train a support-vector machine model for automatically predicting an optimized hue-preserving blending. We have applied the resulting model to both volume rendering and a specific information visualization technique, illustrative parallel coordinate plots. Comparative renderings show a significant improvement over previous approaches in the sense that false colors are completely removed and important properties such as depth ordering and blending vividness are better preserved. Due to the generality of the defined data-driven blending operator, it can be easily integrated also into other visualization frameworks.	Lars Kuehne;Joachim Giesen;Zhiyuan Zhang;Sungsoo Ha;Klaus Mueller	;;;;	10.1109/TVCG.2009.150;10.1109/TVCG.2008.118;10.1109/TVCG.2007.70623;10.1109/TVCG.2012.234;10.1109/VISUAL.2003.1250362	Color blending, hue preservation, knowledge-assisted visualization, volume rendering, parallel coordinates	
SciVis	2012	A Novel Approach to Visualizing Dark Matter Simulations	10.1109/TVCG.2012.187	http://dx.doi.org/10.1109/TVCG.2012.187	2078	2087	J	In the last decades cosmological N-body dark matter simulations have enabled ab initio studies of the formation of structure in the Universe. Gravity amplified small density fluctuations generated shortly after the Big Bang, leading to the formation of galaxies in the cosmic web. These calculations have led to a growing demand for methods to analyze time-dependent particle based simulations. Rendering methods for such N-body simulation data usually employ some kind of splatting approach via point based rendering primitives and approximate the spatial distributions of physical quantities using kernel interpolation techniques, common in SPH (Smoothed Particle Hydrodynamics)-codes. This paper proposes three GPU-assisted rendering approaches, based on a new, more accurate method to compute the physical densities of dark matter simulation data. It uses full phase-space information to generate a tetrahedral tessellation of the computational domain, with mesh vertices defined by the simulation's dark matter particle positions. Over time the mesh is deformed by gravitational forces, causing the tetrahedral cells to warp and overlap. The new methods are well suited to visualize the cosmic web. In particular they preserve caustics, regions of high density that emerge, when several streams of dark matter particles share the same location in space, indicating the formation of structures like sheets, filaments and halos. We demonstrate the superior image quality of the new approaches in a comparison with three standard rendering techniques for N-body simulation data.	Ralf Kähler;Oliver Hahn;Tom Abel	;;	10.1109/TVCG.2010.148;10.1109/VISUAL.2003.1250390;10.1109/VISUAL.2004.85;10.1109/TVCG.2006.154;10.1109/VISUAL.2003.1250404;10.1109/TVCG.2011.216;10.1109/TVCG.2009.142;10.1109/VISUAL.2001.964512;10.1109/VISUAL.2003.1250404	Astrophysics, dark matter, n-body simulations, tetrahedral grids	
SciVis	2012	A Perceptual-Statistics Shading Model	10.1109/TVCG.2012.188	http://dx.doi.org/10.1109/TVCG.2012.188	2265	2274	J	The process of surface perception is complex and based on several influencing factors, e.g., shading, silhouettes, occluding contours, and top down cognition. The accuracy of surface perception can be measured and the influencing factors can be modified in order to decrease the error in perception. This paper presents a novel concept of how a perceptual evaluation of a visualization technique can contribute to its redesign with the aim of improving the match between the distal and the proximal stimulus. During analysis of data from previous perceptual studies, we observed that the slant of 3D surfaces visualized on 2D screens is systematically underestimated. The visible trends in the error allowed us to create a statistical model of the perceived surface slant. Based on this statistical model we obtained from user experiments, we derived a new shading model that uses adjusted surface normals and aims to reduce the error in slant perception. The result is a shape-enhancement of visualization which is driven by an experimentally-founded statistical model. To assess the efficiency of the statistical shading model, we repeated the evaluation experiment and confirmed that the error in perception was decreased. Results of both user experiments are publicly-available datasets.	Veronika Soltészová;Cagatay Turkay;Mark C. Price;Ivan Viola	Dept. of Inf., Univ. of Bergen, Bergen, Norway|c|;;;	10.1109/TVCG.2011.161	Shading, perception, evaluation, surface slant, statistical analysis	
SciVis	2012	A Visual Analysis Concept for the Validation of Geoscientific Simulation Models	10.1109/TVCG.2012.190	http://dx.doi.org/10.1109/TVCG.2012.190	2216	2225	J	Geoscientific modeling and simulation helps to improve our understanding of the complex Earth system. During the modeling process, validation of the geoscientific model is an essential step. In validation, it is determined whether the model output shows sufficient agreement with observation data. Measures for this agreement are called goodness of fit. In the geosciences, analyzing the goodness of fit is challenging due to its manifold dependencies: 1) The goodness of fit depends on the model parameterization, whose precise values are not known. 2) The goodness of fit varies in space and time due to the spatio-temporal dimension of geoscientific models. 3) The significance of the goodness of fit is affected by resolution and preciseness of available observational data. 4) The correlation between goodness of fit and underlying modeled and observed values is ambiguous. In this paper, we introduce a visual analysis concept that targets these challenges in the validation of geoscientific models - specifically focusing on applications where observation data is sparse, unevenly distributed in space and time, and imprecise, which hinders a rigorous analytical approach. Our concept, developed in close cooperation with Earth system modelers, addresses the four challenges by four tailored visualization components. The tight linking of these components supports a twofold interactive drill-down in model parameter space and in the set of data samples, which facilitates the exploration of the numerous dependencies of the goodness of fit. We exemplify our visualization concept for geoscientific modeling of glacial isostatic adjustments in the last 100,000 years, validated against sea levels indicators - a prominent example for sparse and imprecise observation data. An initial use case and feedback from Earth system modelers indicate that our visualization concept is a valuable complement to the range of validation methods.	Andrea Unger;Sven Schulte;Volker Klemann;Doris Dransch	GFZ German Reserach Center For Geosci., Potsdam, Germany|c|;;;	10.1109/TVCG.2010.192;10.1109/VAST.2010.5652895;10.1109/TVCG.2011.248;10.1109/TVCG.2008.145;10.1109/TVCG.2011.225;10.1109/TVCG.2010.223;10.1109/TVCG.2010.171;10.1109/TVCG.2010.190;10.1109/VISUAL.1993.398859;10.1109/TVCG.2010.181;10.1109/TVCG.2008.139	Earth science visualization, model validation, coordinated multiple views, spatio-temporal visualization, sea level indicators	
SciVis	2012	An Adaptive Prediction-Based Approach to Lossless Compression of Floating-Point Volume Data	10.1109/TVCG.2012.194	http://dx.doi.org/10.1109/TVCG.2012.194	2295	2304	J	In this work, we address the problem of lossless compression of scientific and medical floating-point volume data. We propose two prediction-based compression methods that share a common framework, which consists of a switched prediction scheme wherein the best predictor out of a preset group of linear predictors is selected. Such a scheme is able to adapt to different datasets as well as to varying statistics within the data. The first method, called APE (Adaptive Polynomial Encoder), uses a family of structured interpolating polynomials for prediction, while the second method, which we refer to as ACE (Adaptive Combined Encoder), combines predictors from previous work with the polynomial predictors to yield a more flexible, powerful encoder that is able to effectively decorrelate a wide range of data. In addition, in order to facilitate efficient visualization of compressed data, our scheme provides an option to partition floating-point values in such a way as to provide a progressive representation. We compare our two compressors to existing state-of-the-art lossless floating-point compressors for scientific data, with our data suite including both computer simulations and observational measurements. The results demonstrate that our polynomial predictor, APE, is comparable to previous approaches in terms of speed but achieves better compression rates on average. ACE, our combined predictor, while somewhat slower, is able to achieve the best compression rate on all datasets, with significantly better rates on most of the datasets.	Nathaniel Fout;Kwan-Liu Ma	UC Davis, Davis, CA, USA|c|;	10.1109/VISUAL.1996.568138;10.1109/TVCG.2006.143;10.1109/VISUAL.1994.346332	Volume compression, lossless compression, floating-point compression	
SciVis	2012	Analysis of Streamline Separation at Infinity Using Time-Discrete Markov Chains	10.1109/TVCG.2012.198	http://dx.doi.org/10.1109/TVCG.2012.198	2140	2148	J	Existing methods for analyzing separation of streamlines are often restricted to a finite time or a local area. In our paper we introduce a new method that complements them by allowing an infinite-time-evaluation of steady planar vector fields. Our algorithm unifies combinatorial and probabilistic methods and introduces the concept of separation in time-discrete Markov-Chains. We compute particle distributions instead of the streamlines of single particles. We encode the flow into a map and then into a transition matrix for each time direction. Finally, we compare the results of our grid-independent algorithm to the popular Finite-Time-Lyapunov-Exponents and discuss the discrepancies.	Wieland Reich;Gerik Scheuermann	Univ. of Leipzig, Leipzig, Germany|c|;	10.1109/VISUAL.1999.809896	Vector field topology, flow visualization, feature extraction, uncertainty	
SciVis	2012	Augmented Topological Descriptors of Pore Networks for Material Science	10.1109/TVCG.2012.200	http://dx.doi.org/10.1109/TVCG.2012.200	2041	2050	J	One potential solution to reduce the concentration of carbon dioxide in the atmosphere is the geologic storage of captured CO2 in underground rock formations, also known as carbon sequestration. There is ongoing research to guarantee that this process is both efficient and safe. We describe tools that provide measurements of media porosity, and permeability estimates, including visualization of pore structures. Existing standard algorithms make limited use of geometric information in calculating permeability of complex microstructures. This quantity is important for the analysis of biomineralization, a subsurface process that can affect physical properties of porous media. This paper introduces geometric and topological descriptors that enhance the estimation of material permeability. Our analysis framework includes the processing of experimental data, segmentation, and feature extraction and making novel use of multiscale topological analysis to quantify maximum flow through porous networks. We illustrate our results using synchrotron-based X-ray computed microtomography of glass beads during biomineralization. We also benchmark the proposed algorithms using simulated data sets modeling jammed packed bead beds of a monodispersive material.	Daniela Ushizima;Dmitriy Morozov;Gunther H. Weber;Andrea Gomes Campos Bianchi;James A. Sethian;E. Wes Bethel	Comput. Res. Div., Lawrence Berkeley Nat. Lab., Berkeley, CA, USA|c|;;;;;	10.1109/TVCG.2010.218;10.1109/TVCG.2007.70603;10.1109/VISUAL.2005.1532795	Reeb graph, persistent homology, topological data analysis, geometric algorithms, segmentation, microscopy	
SciVis	2012	Automatic Detection and Visualization of Qualitative Hemodynamic Characteristics in Cerebral Aneurysms	10.1109/TVCG.2012.202	http://dx.doi.org/10.1109/TVCG.2012.202	2178	2187	J	Cerebral aneurysms are a pathological vessel dilatation that bear a high risk of rupture. For the understanding and evaluation of the risk of rupture, the analysis of hemodynamic information plays an important role. Besides quantitative hemodynamic information, also qualitative flow characteristics, e.g., the inflow jet and impingement zone are correlated with the risk of rupture. However, the assessment of these two characteristics is currently based on an interactive visual investigation of the flow field, obtained by computational fluid dynamics (CFD) or blood flow measurements. We present an automatic and robust detection as well as an expressive visualization of these characteristics. The detection can be used to support a comparison, e.g., of simulation results reflecting different treatment options. Our approach utilizes local streamline properties to formalize the inflow jet and impingement zone. We extract a characteristic seeding curve on the ostium, on which an inflow jet boundary contour is constructed. Based on this boundary contour we identify the impingement zone. Furthermore, we present several visualization techniques to depict both characteristics expressively. Thereby, we consider accuracy and robustness of the extracted characteristics, minimal visual clutter and occlusions. An evaluation with six domain experts confirms that our approach detects both hemodynamic characteristics reasonably.	Rocco Gasteiger;Dirk J. Lehmann;Roy van Pelt;Gábor Janiga;Oliver Beuing;Anna Vilanova;Holger Theisel;Bernhard Preim	Dept. of Simulation & Graphics, Univ. of Magdeburg, Magdeburg, Germany|c|;;;;;;;	10.1109/TVCG.2011.215;10.1109/TVCG.2011.159;10.1109/TVCG.2011.243;10.1109/TVCG.2009.138;10.1109/TVCG.2010.153;10.1109/TVCG.2010.173	Cerebral aneurysm, Hemodynamic, Inflow jet, Impingement zone, Visualization, Glyph	
SciVis	2012	Automatic Tuning of Spatially Varying Transfer Functions for Blood Vessel Visualization	10.1109/TVCG.2012.203	http://dx.doi.org/10.1109/TVCG.2012.203	2345	2354	J	Computed Tomography Angiography (CTA) is commonly used in clinical routine for diagnosing vascular diseases. The procedure involves the injection of a contrast agent into the blood stream to increase the contrast between the blood vessels and the surrounding tissue in the image data. CTA is often visualized with Direct Volume Rendering (DVR) where the enhanced image contrast is important for the construction of Transfer Functions (TFs). For increased efficiency, clinical routine heavily relies on preset TFs to simplify the creation of such visualizations for a physician. In practice, however, TF presets often do not yield optimal images due to variations in mixture concentration of contrast agent in the blood stream. In this paper we propose an automatic, optimization-based method that shifts TF presets to account for general deviations and local variations of the intensity of contrast enhanced blood vessels. Some of the advantages of this method are the following. It computationally automates large parts of a process that is currently performed manually. It performs the TF shift locally and can thus optimize larger portions of the image than is possible with manual interaction. The method is based on a well known vesselness descriptor in the definition of the optimization criterion. The performance of the method is illustrated by clinically relevant CT angiography datasets displaying both improved structural overviews of vessel trees and improved adaption to local variations of contrast concentration.	Gunnar Läthén;Stefan Lindholm;Reiner Lenz;Anders Persson;Magnus Borga	Center for Med. Image Sci. & Visualization (CMIV), Linkoping Univ., Linkoping, Sweden|c|;;;;	10.1109/VISUAL.2003.1250414;10.1109/TVCG.2009.120;10.1109/VISUAL.2001.964516;10.1109/VISUAL.1996.568113;10.1109/TVCG.2008.162;10.1109/TVCG.2010.195;10.1109/TVCG.2008.123	Direct volume rendering, transfer functions, vessel visualization	
SciVis	2012	Coherency-Based Curve Compression for High-Order finite Element Model Visualization	10.1109/TVCG.2012.206	http://dx.doi.org/10.1109/TVCG.2012.206	2315	2324	J	Finite element (FE) models are frequently used in engineering and life sciences within time-consuming simulations. In contrast with the regular grid structure facilitated by volumetric data sets, as used in medicine or geosciences, FE models are defined over a non-uniform grid. Elements can have curved faces and their interior can be defined through high-order basis functions, which pose additional challenges when visualizing these models. During ray-casting, the uniformly distributed sample points along each viewing ray must be transformed into the material space defined within each element. The computational complexity of this transformation makes a straightforward approach inadequate for interactive data exploration. In this paper, we introduce a novel coherency-based method which supports the interactive exploration of FE models by decoupling the expensive world-to-material space transformation from the rendering stage, thereby allowing it to be performed within a precomputation stage. Therefore, our approach computes view-independent proxy rays in material space, which are clustered to facilitate data reduction. During rendering, these proxy rays are accessed, and it becomes possible to visually analyze high-order FE models at interactive frame rates, even when they are time-varying or consist of multiple modalities. Within this paper, we provide the necessary background about the FE data, describe our decoupling method, and introduce our interactive rendering algorithm. Furthermore, we provide visual results and analyze the error introduced by the presented approach.	Alexander Bock;Erik Sundén;Bingchen Liu;Burkhard Wünsche;Timo Ropinski	Sci. Visualization Group, Linkoping Univ., Linkoping, Sweden|c|;;;;	10.1109/VISUAL.1998.745310;10.1109/VISUAL.2004.91;10.1109/TVCG.2011.206;10.1109/TVCG.2006.110	finite element visualization, GPU-based ray-casting	
SciVis	2012	Computing Morse-Smale Complexes with Accurate Geometry	10.1109/TVCG.2012.209	http://dx.doi.org/10.1109/TVCG.2012.209	2014	2022	J	Topological techniques have proven highly successful in analyzing and visualizing scientific data. As a result, significant efforts have been made to compute structures like the Morse-Smale complex as robustly and efficiently as possible. However, the resulting algorithms, while topologically consistent, often produce incorrect connectivity as well as poor geometry. These problems may compromise or even invalidate any subsequent analysis. Moreover, such techniques may fail to improve even when the resolution of the domain mesh is increased, thus producing potentially incorrect results even for highly resolved functions. To address these problems we introduce two new algorithms: (i) a randomized algorithm to compute the discrete gradient of a scalar field that converges under refinement; and (ii) a deterministic variant which directly computes accurate geometry and thus correct connectivity of the MS complex. The first algorithm converges in the sense that on average it produces the correct result and its standard deviation approaches zero with increasing mesh resolution. The second algorithm uses two ordered traversals of the function to integrate the probabilities of the first to extract correct (near optimal) geometry and connectivity. We present an extensive empirical study using both synthetic and real-world data and demonstrates the advantages of our algorithms in comparison with several popular approaches.	Attila Gyulassy;Peer-Timo Bremer;Valerio Pascucci	SCI Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;	10.1109/TVCG.2011.249;10.1109/TVCG.2008.110;10.1109/TVCG.2007.70603;10.1109/TVCG.2011.199;10.1109/VISUAL.2005.1532839;10.1109/TVCG.2006.186	Topology, topological methods, Morse-Smale complex	
SciVis	2012	Cumulative Heat Diffusion Using Volume Gradient Operator for Volume Analysis	10.1109/TVCG.2012.210	http://dx.doi.org/10.1109/TVCG.2012.210	2069	2077	J	We introduce a simple, yet powerful method called the Cumulative Heat Diffusion for shape-based volume analysis, while drastically reducing the computational cost compared to conventional heat diffusion. Unlike the conventional heat diffusion process, where the diffusion is carried out by considering each node separately as the source, we simultaneously consider all the voxels as sources and carry out the diffusion, hence the term cumulative heat diffusion. In addition, we introduce a new operator that is used in the evaluation of cumulative heat diffusion called the Volume Gradient Operator (VGO). VGO is a combination of the LBO and a data-driven operator which is a function of the half gradient. The half gradient is the absolute value of the difference between the voxel intensities. The VGO by its definition captures the local shape information and is used to assign the initial heat values. Furthermore, VGO is also used as the weighting parameter for the heat diffusion process. We demonstrate that our approach can robustly extract shape-based features and thus forms the basis for an improved classification and exploration of features based on shape.	Krishna Chaitanya Gurijala;Lei Wang 0024;Arie E. Kaufman	Stony Brook Univ., Stony Brook, NY, USA|c|;;	10.1109/TVCG.2011.258;10.1109/VISUAL.2005.1532817	Heat diffusion, volume gradient operator, shape-based volume analysis, classification, transfer function	
SciVis	2012	Derived Metric Tensors for Flow Surface Visualization	10.1109/TVCG.2012.211	http://dx.doi.org/10.1109/TVCG.2012.211	2149	2158	J	Integral flow surfaces constitute a widely used flow visualization tool due to their capability to convey important flow information such as fluid transport, mixing, and domain segmentation. Current flow surface rendering techniques limit their expressiveness, however, by focusing virtually exclusively on displacement visualization, visually neglecting the more complex notion of deformation such as shearing and stretching that is central to the field of continuum mechanics. To incorporate this information into the flow surface visualization and analysis process, we derive a metric tensor field that encodes local surface deformations as induced by the velocity gradient of the underlying flow field. We demonstrate how properties of the resulting metric tensor field are capable of enhancing present surface visualization and generation methods and develop novel surface querying, sampling, and visualization techniques. The provided results show how this step towards unifying classic flow visualization and more advanced concepts from continuum mechanics enables more detailed and improved flow analysis.	Harald Obermaier;Kenneth I. Joy	Inst. for Data Anal. & Visualization (IDAV), Univ. of California, Davis, CA, USA|c|;	10.1109/TVCG.2008.163;10.1109/TVCG.2010.173;10.1109/TVCG.2011.170;10.1109/TVCG.2006.134;10.1109/TVCG.2008.133;10.1109/VISUAL.1992.235211;10.1109/TVCG.2007.70551;10.1109/VISUAL.2004.80;10.1109/TVCG.2009.190;10.1109/TVCG.2010.166;10.1109/TVCG.2009.154;10.1109/TVCG.2007.70554	Vector field, integral surfaces, metric tensor, deformation, velocity gradient, continuum mechanics	
SciVis	2012	Effects of Stereo and Screen Size on the Legibility of Three-Dimensional Streamtube Visualization	10.1109/TVCG.2012.216	http://dx.doi.org/10.1109/TVCG.2012.216	2130	2139	J	We report the impact of display characteristics (stereo and size) on task performance in diffusion magnetic resonance imaging (DMRI) in a user study with 12 participants. The hypotheses were that (1) adding stereo and increasing display size would improve task accuracy and reduce completion time, and (2) the greater the complexity of a spatial task, the greater the benefits of an improved display. Thus we expected to see greater performance gains when detailed visual reasoning was required. Participants used dense streamtube visualizations to perform five representative tasks: (1) determine the higher average fractional anisotropy (FA) values between two regions, (2) find the endpoints of fiber tracts, (3) name a bundle, (4) mark a brain lesion, and (5) judge if tracts belong to the same bundle. Contrary to our hypotheses, we found the task completion time was not improved by the use of the larger display and that performance accuracy was hurt rather than helped by the introduction of stereo in our study with dense DMRI data. Bigger was not always better. Thus cautious should be taken when selecting displays for scientific visualization applications. We explored the results further using the body-scale unit and subjective size and stereo experiences.	Jian Chen;Haipeng Cai;Alexander P. Auchus;David H. Laidlaw	;;;	10.1109/TVCG.2009.126;10.1109/VISUAL.2000.885694;10.1109/VISUAL.2003.1250414;10.1109/TVCG.2009.111;10.1109/TVCG.2009.138;10.1109/TVCG.2006.183	Display characteristics, diffusion tensor MRI, virtual environment	
SciVis	2012	Efficient Structure-Aware Selection Techniques for 3D Point Cloud Visualizations with 2DOF Input	10.1109/TVCG.2012.217	http://dx.doi.org/10.1109/TVCG.2012.217	2245	2254	J	Data selection is a fundamental task in visualization because it serves as a pre-requisite to many follow-up interactions. Efficient spatial selection in 3D point cloud datasets consisting of thousands or millions of particles can be particularly challenging. We present two new techniques, TeddySelection and CloudLasso, that support the selection of subsets in large particle 3D datasets in an interactive and visually intuitive manner. Specifically, we describe how to spatially select a subset of a 3D particle cloud by simply encircling the target particles on screen using either the mouse or direct-touch input. Based on the drawn lasso, our techniques automatically determine a bounding selection surface around the encircled particles based on their density. This kind of selection technique can be applied to particle datasets in several application domains. TeddySelection and CloudLasso reduce, and in some cases even eliminate, the need for complex multi-step selection processes involving Boolean operations. This was confirmed in a formal, controlled user study in which we compared the more flexible CloudLasso technique to the standard cylinder-based selection technique. This study showed that the former is consistently more efficient than the latter - in several cases the CloudLasso selection time was half that of the corresponding cylinder-based selection.	Lingyun Yu;Konstantinos Efstathiou 0001;Petra Isenberg;Tobias Isenberg 0001	Univ. of Groningen, Groningen, Netherlands|c|;;;	10.1109/TVCG.2010.157;10.1109/TVCG.2012.292;10.1109/TVCG.2008.153	3D interaction, spatial selection, direct-touch interaction	
SciVis	2012	ElVis: A System for the Accurate and Interactive Visualization of High-Order finite Element Solutions	10.1109/TVCG.2012.218	http://dx.doi.org/10.1109/TVCG.2012.218	2325	2334	J	This paper presents the Element Visualizer (ElVis), a new, open-source scientific visualization system for use with high-order finite element solutions to PDEs in three dimensions. This system is designed to minimize visualization errors of these types of fields by querying the underlying finite element basis functions (e.g., high-order polynomials) directly, leading to pixel-exact representations of solutions and geometry. The system interacts with simulation data through runtime plugins, which only require users to implement a handful of operations fundamental to finite element solvers. The data in turn can be visualized through the use of cut surfaces, contours, isosurfaces, and volume rendering. These visualization algorithms are implemented using NVIDIA's OptiX GPU-based ray-tracing engine, which provides accelerated ray traversal of the high-order geometry, and CUDA, which allows for effective parallel evaluation of the visualization algorithms. The direct interface between ElVis and the underlying data differentiates it from existing visualization tools. Current tools assume the underlying data is composed of linear primitives; high-order data must be interpolated with linear functions as a result. In this work, examples drawn from aerodynamic simulations-high-order discontinuous Galerkin finite element solutions of aerodynamic flows in particular-will demonstrate the superiority of ElVis' pixel-exact approach when compared with traditional linear-interpolation methods. Such methods can introduce a number of inaccuracies in the resulting visualization, making it unclear if visual artifacts are genuine to the solution data or if these artifacts are the result of interpolation errors. Linear methods additionally cannot properly visualize curved geometries (elements or boundaries) which can greatly inhibit developers' debugging efforts. As we will show, pixel-exact visualization exhibits none of these issues, removing the visualization scheme as a source of - ncertainty for engineers using ElVis.	Blake Nelson;Eric Liu;Robert Michael Kirby;Robert Haimes	Sch. of Comput., Univ. of Utah, Salt Lake City, UT, USA|c|;;;	10.1109/VISUAL.2005.1532776;10.1109/VISUAL.1991.175837;10.1109/VISUAL.2004.91;10.1109/TVCG.2006.154;10.1109/TVCG.2011.206	High-order finite elements, spectral/hp elements, discontinuous Galerkin, fluid flow simulation, cut surface extraction, contours, isosurfaces	
SciVis	2012	Evaluation of Fast-Forward Video Visualization	10.1109/TVCG.2012.222	http://dx.doi.org/10.1109/TVCG.2012.222	2095	2103	J	We evaluate and compare video visualization techniques based on fast-forward. A controlled laboratory user study (n = 24) was conducted to determine the trade-off between support of object identification and motion perception, two properties that have to be considered when choosing a particular fast-forward visualization. We compare four different visualizations: two representing the state-of-the-art and two new variants of visualization introduced in this paper. The two state-of-the-art methods we consider are frame-skipping and temporal blending of successive frames. Our object trail visualization leverages a combination of frame-skipping and temporal blending, whereas predictive trajectory visualization supports motion perception by augmenting the video frames with an arrow that indicates the future object trajectory. Our hypothesis was that each of the state-of-the-art methods satisfies just one of the goals: support of object identification or motion perception. Thus, they represent both ends of the visualization design. The key findings of the evaluation are that object trail visualization supports object identification, whereas predictive trajectory visualization is most useful for motion perception. However, frame-skipping surprisingly exhibits reasonable performance for both tasks. Furthermore, we evaluate the subjective performance of three different playback speed visualizations for adaptive fast-forward, a subdomain of video fast-forward.	Markus Höferlin;Kuno Kurzhals;Benjamin Höferlin;Gunther Heidemann;Daniel Weiskopf	;;;;	10.1109/TVCG.2007.70542;10.1109/TVCG.2007.70617;10.1109/TVCG.2008.125;10.1109/TVCG.2007.70539;10.1109/TVCG.2006.194	Video visualization, adaptive fast-forward, controlled laboratory user study	
SciVis	2012	Evaluation of Multivariate Visualization on a Multivariate Task	10.1109/TVCG.2012.223	http://dx.doi.org/10.1109/TVCG.2012.223	2114	2121	J	Multivariate visualization techniques have attracted great interest as the dimensionality of data sets grows. One premise of such techniques is that simultaneous visual representation of multiple variables will enable the data analyst to detect patterns amongst multiple variables. Such insights could lead to development of new techniques for rigorous (numerical) analysis of complex relationships hidden within the data. Two natural questions arise from this premise: Which multivariate visualization techniques are the most effective for high-dimensional data sets? How does the analysis task change this utility ranking? We present a user study with a new task to answer the first question. We provide some insights to the second question based on the results of our study and results available in the literature. Our task led to significant differences in error, response time, and subjective workload ratings amongst four visualization techniques. We implemented three integrated techniques (Data-driven Spots, Oriented Slivers, and Attribute Blocks), as well as a baseline case of separate grayscale images. The baseline case fared poorly on all three measures, whereas Datadriven Spots yielded the best accuracy and was among the best in response time. These results differ from comparisons of similar techniques with other tasks, and we review all the techniques, tasks, and results (from our work and previous work) to understand the reasons for this discrepancy.	Mark A. Livingston;Jonathan W. Decker;Zhuming Ai	;;	10.1109/TVCG.2011.194;10.1109/TVCG.2009.126;10.1109/VISUAL.1998.745292;10.1109/VISUAL.1990.146387;10.1109/TVCG.2007.70623;10.1109/VISUAL.1990.146386;10.1109/VISUAL.1991.175795;10.1109/VISUAL.1998.745294;10.1109/VISUAL.2003.1250362	Quantitative evaluation, multivariate visualization, visual task design, texture perception	
SciVis	2012	Fuzzy Volume Rendering	10.1109/TVCG.2012.227	http://dx.doi.org/10.1109/TVCG.2012.227	2335	2344	J	In order to assess the reliability of volume rendering, it is necessary to consider the uncertainty associated with the volume data and how it is propagated through the volume rendering algorithm, as well as the contribution to uncertainty from the rendering algorithm itself. In this work, we show how to apply concepts from the field of reliable computing in order to build a framework for management of uncertainty in volume rendering, with the result being a self-validating computational model to compute a posteriori uncertainty bounds. We begin by adopting a coherent, unifying possibility-based representation of uncertainty that is able to capture the various forms of uncertainty that appear in visualization, including variability, imprecision, and fuzziness. Next, we extend the concept of the fuzzy transform in order to derive rules for accumulation and propagation of uncertainty. This representation and propagation of uncertainty together constitute an automated framework for management of uncertainty in visualization, which we then apply to volume rendering. The result, which we call fuzzy volume rendering, is an uncertainty-aware rendering algorithm able to produce more complete depictions of the volume data, thereby allowing more reliable conclusions and informed decisions. Finally, we compare approaches for self-validated computation in volume rendering, demonstrating that our chosen method has the ability to handle complex uncertainty while maintaining efficiency.	Nathaniel Fout;Kwan-Liu Ma	;	10.1109/TVCG.2007.70518;10.1109/TVCG.2010.211;10.1109/VISUAL.2005.1532807;10.1109/VAST.2009.5332611	Uncertainty visualization, verifiable visualization, volume rendering	
SciVis	2012	Generalized Topological Simplification of Scalar fields on Surfaces	10.1109/TVCG.2012.228	http://dx.doi.org/10.1109/TVCG.2012.228	2005	2013	J	We present a combinatorial algorithm for the general topological simplification of scalar fields on surfaces. Given a scalar field f, our algorithm generates a simplified field g that provably admits only critical points from a constrained subset of the singularities of f, while guaranteeing a small distance ||f - g||∞ for data-fitting purpose. In contrast to previous algorithms, our approach is oblivious to the strategy used for selecting features of interest and allows critical points to be removed arbitrarily. When topological persistence is used to select the features of interest, our algorithm produces a standard ϵ-simplification. Our approach is based on a new iterative algorithm for the constrained reconstruction of sub- and sur-level sets. Extensive experiments show that the number of iterations required for our algorithm to converge is rarely greater than 2 and never greater than 5, yielding O(n log(n)) practical time performances. The algorithm handles triangulated surfaces with or without boundary and is robust to the presence of multi-saddles in the input. It is simple to implement, fast in practice and more general than previous techniques. Practically, our approach allows a user to arbitrarily simplify the topology of an input function and robustly generate the corresponding simplified function. An appealing application area of our algorithm is in scalar field design since it enables, without any threshold parameter, the robust pruning of topological noise as selected by the user. This is needed for example to get rid of inaccuracies introduced by numerical solvers, thereby providing topological guarantees needed for certified geometry processing. Experiments show this ability to eliminate numerical noise as well as validate the time efficiency and accuracy of our algorithm. We provide a lightweight C++ implementation as supplemental material that can be used for topological cleaning on surface meshes.	Julien Tierny;Valerio Pascucci	Telecom ParisTech, Paris, France|c|;	10.1109/TVCG.2008.110;10.1109/TVCG.2009.163;10.1109/VISUAL.2004.96;10.1109/TVCG.2011.244	Scalar field visualization, scalar field design, topological simplification	
SciVis	2012	Hierarchical Exploration of Volumes Using Multilevel Segmentation of the Intensity-Gradient Histograms	10.1109/TVCG.2012.231	http://dx.doi.org/10.1109/TVCG.2012.231	2355	2363	J	Visual exploration of volumetric datasets to discover the embedded features and spatial structures is a challenging and tedious task. In this paper we present a semi-automatic approach to this problem that works by visually segmenting the intensity-gradient 2D histogram of a volumetric dataset into an exploration hierarchy. Our approach mimics user exploration behavior by analyzing the histogram with the normalized-cut multilevel segmentation technique. Unlike previous work in this area, our technique segments the histogram into a reasonable set of intuitive components that are mutually exclusive and collectively exhaustive. We use information-theoretic measures of the volumetric data segments to guide the exploration. This provides a data-driven coarse-to-fine hierarchy for a user to interactively navigate the volume in a meaningful manner.	Cheuk Yiu Ip;Amitabh Varshney;Joseph JáJá	Inst. for Adv. Comput. Studies, Univ. of Maryland, College Park, MD, USA|c|;;	10.1109/TVCG.2010.132;10.1109/TVCG.2009.185;10.1109/VISUAL.1999.809932;10.1109/VISUAL.2005.1532795;10.1109/VISUAL.2003.1250370;10.1109/TVCG.2010.208;10.1109/TVCG.2008.162;10.1109/TVCG.2011.248;10.1109/TVCG.2011.173;10.1109/TVCG.2006.174;10.1109/TVCG.2011.231;10.1109/TVCG.2007.70590;10.1109/TVCG.2009.197;10.1109/TVCG.2006.148	Volume exploration, volume classification, normalized cut, Information-guided exploration	
SciVis	2012	Historygrams: Enabling Interactive Global Illumination in Direct Volume Rendering using Photon Mapping	10.1109/TVCG.2012.232	http://dx.doi.org/10.1109/TVCG.2012.232	2364	2371	J	In this paper, we enable interactive volumetric global illumination by extending photon mapping techniques to handle interactive transfer function (TF) and material editing in the context of volume rendering. We propose novel algorithms and data structures for finding and evaluating parts of a scene affected by these parameter changes, and thus support efficient updates of the photon map. In direct volume rendering (DVR) the ability to explore volume data using parameter changes, such as editable TFs, is of key importance. Advanced global illumination techniques are in most cases computationally too expensive, as they prevent the desired interactivity. Our technique decreases the amount of computation caused by parameter changes, by introducing Historygrams which allow us to efficiently reuse previously computed photon media interactions. Along the viewing rays, we utilize properties of the light transport equations to subdivide a view-ray into segments and independently update them when invalid. Unlike segments of a view-ray, photon scattering events within the volumetric medium needs to be sequentially updated. Using our Historygram approach, we can identify the first invalid photon interaction caused by a property change, and thus reuse all valid photon interactions. Combining these two novel concepts, supports interactive editing of parameters when using volumetric photon mapping in the context of DVR. As a consequence, we can handle arbitrarily shaped and positioned light sources, arbitrary phase functions, bidirectional reflectance distribution functions and multiple scattering which has previously not been possible in interactive DVR.	Daniel Jönsson;Joel Kronander;Timo Ropinski;Anders Ynnerman	Linkoping Univ., Linkoping, Sweden|c|;;;	10.1109/TVCG.2011.211	Volume rendering, photon mapping, global illumination, participating media	
SciVis	2012	Human Computation in Visualization: Using Purpose Driven Games for Robust Evaluation of Visualization Algorithms	10.1109/TVCG.2012.234	http://dx.doi.org/10.1109/TVCG.2012.234	2104	2113	J	Due to the inherent characteristics of the visualization process, most of the problems in this field have strong ties with human cognition and perception. This makes the human brain and sensory system the only truly appropriate evaluation platform for evaluating and fine-tuning a new visualization method or paradigm. However, getting humans to volunteer for these purposes has always been a significant obstacle, and thus this phase of the development process has traditionally formed a bottleneck, slowing down progress in visualization research. We propose to take advantage of the newly emerging field of Human Computation (HC) to overcome these challenges. HC promotes the idea that rather than considering humans as users of the computational system, they can be made part of a hybrid computational loop consisting of traditional computation resources and the human brain and sensory system. This approach is particularly successful in cases where part of the computational problem is considered intractable using known computer algorithms but is trivial to common sense human knowledge. In this paper, we focus on HC from the perspective of solving visualization problems and also outline a framework by which humans can be easily seduced to volunteer their HC resources. We introduce a purpose-driven game titled â€œDisguiseâ€ which serves as a prototypical example for how the evaluation of visualization algorithms can be mapped into a fun and addicting activity, allowing this task to be accomplished in an extensive yet cost effective way. Finally, we sketch out a framework that transcends from the pure evaluation of existing visualization methods to the design of a new one.	Nafees Ahmed;Ziyi Zheng;Klaus Mueller	Comput. Sci. Dept., Stony Brook Univ., Stony Brook, NY, USA|c|;;	10.1109/TVCG.2009.172;10.1109/TVCG.2011.218;10.1109/TVCG.2009.189;10.1109/VISUAL.2005.1532781;10.1109/TVCG.2012.186;10.1109/TVCG.2008.118;10.1109/TVCG.2009.150	Human computation, perception, evaluation, color blending	
SciVis	2012	Interactive Retro-Deformation of Terrain for Reconstructing 3D Fault Displacements	10.1109/TVCG.2012.239	http://dx.doi.org/10.1109/TVCG.2012.239	2208	2215	J	Planetary topography is the result of complex interactions between geological processes, of which faulting is a prominent component. Surface-rupturing earthquakes cut and move landforms which develop across active faults, producing characteristic surface displacements across the fault. Geometric models of faults and their associated surface displacements are commonly applied to reconstruct these offsets to enable interpretation of the observed topography. However, current 2D techniques are limited in their capability to convey both the three-dimensional kinematics of faulting and the incremental sequence of events required by a given reconstruction. Here we present a real-time system for interactive retro-deformation of faulted topography to enable reconstruction of fault displacement within a high-resolution (sub 1m/pixel) 3D terrain visualization. We employ geometry shaders on the GPU to intersect the surface mesh with fault-segments interactively specified by the user and transform the resulting surface blocks in realtime according to a kinematic model of fault motion. Our method facilitates a human-in-the-loop approach to reconstruction of fault displacements by providing instant visual feedback while exploring the parameter space. Thus, scientists can evaluate the validity of traditional point-to-point reconstructions by visually examining a smooth interpolation of the displacement in 3D. We show the efficacy of our approach by using it to reconstruct segments of the San Andreas fault, California as well as a graben structure in the Noctis Labyrinthus region on Mars.	Rolf Westerteiger;Tracy Compton;Tony Bernardin;Eric S. Cowgill;Klaus Gwinner;Bernd Hamann;Andreas Gerndt;Hans Hagen	German Aerosp. Center, Univ. of Kaiserslautern, Kaiserslautern, Germany|c|;;;;;;;		Terrain rendering, interactive, fault simulation, mesh deformation	
SciVis	2012	Interactive Volume Exploration of Petascale Microscopy Data Streams Using a Visualization-Driven Virtual Memory Approach	10.1109/TVCG.2012.240	http://dx.doi.org/10.1109/TVCG.2012.240	2285	2294	J	This paper presents the first volume visualization system that scales to petascale volumes imaged as a continuous stream of high-resolution electron microscopy images. Our architecture scales to dense, anisotropic petascale volumes because it: (1) decouples construction of the 3D multi-resolution representation required for visualization from data acquisition, and (2) decouples sample access time during ray-casting from the size of the multi-resolution hierarchy. Our system is designed around a scalable multi-resolution virtual memory architecture that handles missing data naturally, does not pre-compute any 3D multi-resolution representation such as an octree, and can accept a constant stream of 2D image tiles from the microscopes. A novelty of our system design is that it is visualization-driven: we restrict most computations to the visible volume data. Leveraging the virtual memory architecture, missing data are detected during volume ray-casting as cache misses, which are propagated backwards for on-demand out-of-core processing. 3D blocks of volume data are only constructed from 2D microscope image tiles when they have actually been accessed during ray-casting. We extensively evaluate our system design choices with respect to scalability and performance, compare to previous best-of-breed systems, and illustrate the effectiveness of our system for real microscopy data from neuroscience.	Markus Hadwiger;Johanna Beyer;Won-Ki Jeong;Hanspeter Pfister	;;;	10.1109/VISUAL.1999.809908;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2009.161	Petascale volume exploration, high-resolution microscopy, high-throughput imaging, neuroscience	
SciVis	2012	KnotPad: Visualizing and Exploring Knot Theory with Fluid Reidemeister Moves	10.1109/TVCG.2012.242	http://dx.doi.org/10.1109/TVCG.2012.242	2051	2060	J	We present KnotPad, an interactive paper-like system for visualizing and exploring mathematical knots; we exploit topological drawing and math-aware deformation methods in particular to enable and enrich our interactions with knot diagrams. Whereas most previous efforts typically employ physically based modeling to simulate the 3D dynamics of knots and ropes, our tool offers a Reidemeister move based interactive environment that is much closer to the topological problems being solved in knot theory, yet without interfering with the traditional advantages of paper-based analysis and manipulation of knot diagrams. Drawing knot diagrams with many crossings and producing their equivalent is quite challenging and error-prone. KnotPad can restrict user manipulations to the three types of Reidemeister moves, resulting in a more fluid yet mathematically correct user experience with knots. For our principal test case of mathematical knots, KnotPad permits us to draw and edit their diagrams empowered by a family of interactive techniques. Furthermore, we exploit supplementary interface elements to enrich the user experiences. For example, KnotPad allows one to pull and drag on knot diagrams to produce mathematically valid moves. Navigation enhancements in KnotPad provide still further improvement: by remembering and displaying the sequence of valid moves applied during the entire interaction, KnotPad allows a much cleaner exploratory interface for the user to analyze and study knot equivalence. All these methods combine to reveal the complex spatial relationships of knot diagrams with a mathematically true and rich user experience.	Hui Zhang 0006;Jianguang Weng;Lin Jing;Yiwen Zhong	Pervasive Technol. Inst., Indiana Univ., Bloomington, IN, USA|c|;;;	10.1109/VISUAL.2005.1532804;10.1109/VISUAL.2005.1532843;10.1109/TVCG.2007.70593	Knot Theory, Math Visualization	
SciVis	2012	Lagrangian Coherent Structures for Design Analysis of Revolving Doors	10.1109/TVCG.2012.243	http://dx.doi.org/10.1109/TVCG.2012.243	2159	2168	J	Room air flow and air exchange are important aspects for the design of energy-efficient buildings. As a result, simulations are increasingly used prior to construction to achieve an energy-efficient design. We present a visual analysis of air flow generated at building entrances, which uses a combination of revolving doors and air curtains. The resulting flow pattern is challenging because of two interacting flow patterns: On the one hand, the revolving door acts as a pump, on the other hand, the air curtain creates a layer of uniformly moving warm air between the interior of the building and the revolving door. Lagrangian coherent structures (LCS), which by definition are flow barriers, are the method of choice for visualizing the separation and recirculation behavior of warm and cold air flow. The extraction of LCS is based on the finite-time Lyapunov exponent (FTLE) and makes use of a ridge definition which is consistent with the concept of weak LCS. Both FTLE computation and ridge extraction are done in a robust and efficient way by making use of the fast Fourier transform for computing scale-space derivatives.	Benjamin Schindler;Raphael Fuchs;Stefan Barp;Jürgen Waser;Armin Pobitzer;Robert Carnecky;Kresimir Matkovic;Ronald Peikert	ETH Zurich, Zurich, Switzerland|c|;;;;;;;	10.1109/TVCG.2007.70551;10.1109/TVCG.2010.223;10.1109/TVCG.2007.70554;10.1109/TVCG.2010.156;10.1109/VISUAL.2005.1532813	Visualization in physical sciences and engineering, topology-based techniques, vector field data	
SciVis	2012	Multivariate Data Analysis Using Persistence-Based filtering and Topological Signatures	10.1109/TVCG.2012.248	http://dx.doi.org/10.1109/TVCG.2012.248	2382	2391	J	The extraction of significant structures in arbitrary high-dimensional data sets is a challenging task. Moreover, classifying data points as noise in order to reduce a data set bears special relevance for many application domains. Standard methods such as clustering serve to reduce problem complexity by providing the user with classes of similar entities. However, they usually do not highlight relations between different entities and require a stopping criterion, e.g. the number of clusters to be detected. In this paper, we present a visualization pipeline based on recent advancements in algebraic topology. More precisely, we employ methods from persistent homology that enable topological data analysis on high-dimensional data sets. Our pipeline inherently copes with noisy data and data sets of arbitrary dimensions. It extracts central structures of a data set in a hierarchical manner by using a persistence-based filtering algorithm that is theoretically well-founded. We furthermore introduce persistence rings, a novel visualization technique for a class of topological features-the persistence intervals-of large data sets. Persistence rings provide a unique topological signature of a data set, which helps in recognizing similarities. In addition, we provide interactive visualization techniques that assist the user in evaluating the parameter space of our method in order to extract relevant structures. We describe and evaluate our analysis pipeline by means of two very distinct classes of data sets: First, a class of synthetic data sets containing topological objects is employed to highlight the interaction capabilities of our method. Second, in order to affirm the utility of our technique, we analyse a class of high-dimensional real-world data sets arising from current research in cultural heritage.	Bastian Rieck;Hubert Mara;Heike Leitte	Interdiscipl. Center for Sci. Comput. (IWR), Heidelberg Univ., Heidelberg, Germany|c|;;	10.1109/VISUAL.1990.146373;10.1109/VISUAL.2005.1532839;10.1109/TVCG.2007.70601;10.1109/VISUAL.2002.1183774	Topological persistence, multivariate data, clustering	
SciVis	2012	On the Interpolation of Data with Normally Distributed Uncertainty for Visualization	10.1109/TVCG.2012.249	http://dx.doi.org/10.1109/TVCG.2012.249	2305	2314	J	In many fields of science or engineering, we are confronted with uncertain data. For that reason, the visualization of uncertainty received a lot of attention, especially in recent years. In the majority of cases, Gaussian distributions are used to describe uncertain behavior, because they are able to model many phenomena encountered in science. Therefore, in most applications uncertain data is (or is assumed to be) Gaussian distributed. If such uncertain data is given on fixed positions, the question of interpolation arises for many visualization approaches. In this paper, we analyze the effects of the usual linear interpolation schemes for visualization of Gaussian distributed data. In addition, we demonstrate that methods known in geostatistics and machine learning have favorable properties for visualization purposes in this case.	Steven Schlegel;Nico Korn;Gerik Scheuermann	Univ. of Leipzig, Leipzig, Germany|c|;;	10.1109/TVCG.2007.70530;10.1109/TVCG.2011.203;10.1109/VISUAL.2005.1532807	Gaussian process, uncertainty, interpolation	
SciVis	2012	SeiVis: An Interactive Visual Subsurface Modeling Application	10.1109/TVCG.2012.259	http://dx.doi.org/10.1109/TVCG.2012.259	2226	2235	J	The most important resources to fulfill today's energy demands are fossil fuels, such as oil and natural gas. When exploiting hydrocarbon reservoirs, a detailed and credible model of the subsurface structures is crucial in order to minimize economic and ecological risks. Creating such a model is an inverse problem: reconstructing structures from measured reflection seismics. The major challenge here is twofold: First, the structures in highly ambiguous seismic data are interpreted in the time domain. Second, a velocity model has to be built from this interpretation to match the model to depth measurements from wells. If it is not possible to obtain a match at all positions, the interpretation has to be updated, going back to the first step. This results in a lengthy back and forth between the different steps, or in an unphysical velocity model in many cases. This paper presents a novel, integrated approach to interactively creating subsurface models from reflection seismics. It integrates the interpretation of the seismic data using an interactive horizon extraction technique based on piecewise global optimization with velocity modeling. Computing and visualizing the effects of changes to the interpretation and velocity model on the depth-converted model on the fly enables an integrated feedback loop that enables a completely new connection of the seismic data in time domain and well data in depth domain. Using a novel joint time/depth visualization, depicting side-by-side views of the original and the resulting depth-converted data, domain experts can directly fit their interpretation in time domain to spatial ground truth data. We have conducted a domain expert evaluation, which illustrates that the presented workflow enables the creation of exact subsurface models much more rapidly than previous approaches.	Thomas Höllt;Wolfgang Freiler;Fritz Gschwantner;Helmut Doleisch;Gabor Heinemann;Markus Hadwiger	King Adbullah Univ. of Sci. & Technol., Thuwal, Saudi Arabia|c|;;;;;	10.1109/TVCG.2009.136;10.1109/TVCG.2006.140;10.1109/VISUAL.2005.1532802;10.1109/VISUAL.2003.1250400	Seismic visualization, volume deformation, exploded views, seismic interpretation	
SciVis	2012	Sketching Uncertainty into Simulations	10.1109/TVCG.2012.261	http://dx.doi.org/10.1109/TVCG.2012.261	2255	2264	J	In a variety of application areas, the use of simulation steering in decision making is limited at best. Research focusing on this problem suggests that most user interfaces are too complex for the end user. Our goal is to let users create and investigate multiple, alternative scenarios without the need for special simulation expertise. To simplify the specification of parameters, we move from a traditional manipulation of numbers to a sketch-based input approach. Users steer both numeric parameters and parameters with a spatial correspondence by sketching a change onto the rendering. Special visualizations provide immediate visual feedback on how the sketches are transformed into boundary conditions of the simulation models. Since uncertainty with respect to many intertwined parameters plays an important role in planning, we also allow the user to intuitively setup complete value ranges, which are then automatically transformed into ensemble simulations. The interface and the underlying system were developed in collaboration with experts in the field of flood management. The real-world data they have provided has allowed us to construct scenarios used to evaluate the system. These were presented to a variety of flood response personnel, and their feedback is discussed in detail in the paper. The interface was found to be intuitive and relevant, although a certain amount of training might be necessary.	Hrvoje Ribicic;Jürgen Waser;Roman Gurbat;Bernhard Sadransky;Eduard Gröller	VRVis Vienna, Vienna, Austria|c|;;;;	10.1109/TVCG.2010.223;10.1109/TVCG.2011.225;10.1109/TVCG.2010.223;10.1109/TVCG.2010.202;10.1109/VAST.2011.6102457	Emergency/disaster management, interaction design, uncertainty visualization, sketch-based steering, ensemble simulation steering, integrated visualization system, flood management	
SciVis	2012	Structure-Aware Lighting Design for Volume Visualization	10.1109/TVCG.2012.267	http://dx.doi.org/10.1109/TVCG.2012.267	2372	2381	J	Lighting design is a complex, but fundamental, problem in many fields. In volume visualization, direct volume rendering generates an informative image without external lighting, as each voxel itself emits radiance. However, external lighting further improves the shape and detail perception of features, and it also determines the effectiveness of the communication of feature information. The human visual system is highly effective in extracting structural information from images, and to assist it further, this paper presents an approach to structure-aware automatic lighting design by measuring the structural changes between the images with and without external lighting. Given a transfer function and a viewpoint, the optimal lighting parameters are those that provide the greatest enhancement to structural information - the shape and detail information of features are conveyed most clearly by the optimal lighting parameters. Besides lighting goodness, the proposed metric can also be used to evaluate lighting similarity and stability between two sets of lighting parameters. Lighting similarity can be used to optimize the selection of multiple light sources so that different light sources can reveal distinct structural information. Our experiments with several volume data sets demonstrate the effectiveness of the structure-aware lighting design approach. It is well suited to use by novices as it requires little technical understanding of the rendering parameters associated with direct volume rendering.	Yubo Tao;Hai Lin 0003;Feng Dong;Chao Wang;Gordon Clapworthy;Hujun Bao	State Key Lab. of CAD&amp;CG, Zhejiang Univ., Hangzhou, China|c|;;;;;	10.1109/TVCG.2006.137;10.1109/TVCG.2011.218;10.1109/VISUAL.2004.62;10.1109/VISUAL.2005.1532834;10.1109/VISUAL.2005.1532833;10.1109/VISUAL.2003.1250395;10.1109/VISUAL.2002.1183785	Automatic lighting design, structural dissimilarity, lighting similarity, lighting stability, volume rendering	
SciVis	2012	Surface-Based Structure Analysis and Visualization for Multifield Time-Varying Datasets	10.1109/TVCG.2012.269	http://dx.doi.org/10.1109/TVCG.2012.269	2392	2401	J	This paper introduces a new feature analysis and visualization method for multifield datasets. Our approach applies a surface-centric model to characterize salient features and form an effective, schematic representation of the data. We propose a simple, geometrically motivated, multifield feature definition. This definition relies on an iterative algorithm that applies existing theory of skeleton derivation to fuse the structures from the constitutive fields into a coherent data description, while addressing noise and spurious details. This paper also presents a new method for non-rigid surface registration between the surfaces of consecutive time steps. This matching is used in conjunction with clustering to discover the interaction patterns between the different fields and their evolution over time. We document the unified visual analysis achieved by our method in the context of several multifield problems from large-scale time-varying simulations.	Samer S. Barakat;Markus Rütten;Xavier Tricoche	;;	10.1109/TVCG.2007.70615;10.1109/TVCG.2007.70523;10.1109/TVCG.2006.165;10.1109/TVCG.2007.70519;10.1109/TVCG.2008.116;10.1109/TVCG.2007.70519;10.1109/TVCG.2008.140;10.1109/VISUAL.1995.485139;10.1109/TVCG.2009.177;10.1109/TVCG.2008.148	Multifield, time-varying, surface structures	
SciVis	2012	Turbulence Visualization at the Terascale on Desktop PCs	10.1109/TVCG.2012.274	http://dx.doi.org/10.1109/TVCG.2012.274	2169	2177	J	Despite the ongoing efforts in turbulence research, the universal properties of the turbulence small-scale structure and the relationships between small- and large-scale turbulent motions are not yet fully understood. The visually guided exploration of turbulence features, including the interactive selection and simultaneous visualization of multiple features, can further progress our understanding of turbulence. Accomplishing this task for flow fields in which the full turbulence spectrum is well resolved is challenging on desktop computers. This is due to the extreme resolution of such fields, requiring memory and bandwidth capacities going beyond what is currently available. To overcome these limitations, we present a GPU system for feature-based turbulence visualization that works on a compressed flow field representation. We use a wavelet-based compression scheme including run-length and entropy encoding, which can be decoded on the GPU and embedded into brick-based volume ray-casting. This enables a drastic reduction of the data to be streamed from disk to GPU memory. Our system derives turbulence properties directly from the velocity gradient tensor, and it either renders these properties in turn or generates and renders scalar feature volumes. The quality and efficiency of the system is demonstrated in the visualization of two unsteady turbulence simulations, each comprising a spatio-temporal resolution of 10244. On a desktop computer, the system can visualize each time step in 5 seconds, and it achieves about three times this rate for the visualization of a scalar feature volume.	Marc Treib;Kai Bürger;Florian Reichl;Charles Meneveau;Alexander S. Szalay;Rüdiger Westermann	Tech. Univ. Munchen, Munich, Germany|c|;;;;;	10.1109/VISUAL.2002.1183757;10.1109/VISUAL.2001.964520;10.1109/TVCG.2006.143;10.1109/VISUAL.2005.1532808;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.2001.964531;10.1109/VISUAL.2004.55;10.1109/VISUAL.2003.1250385	Visualization system and toolkit design, vector fields, volume rendering, data streaming, data compression	
SciVis	2012	Visual Data Analysis as an Integral Part of Environmental Management	10.1109/TVCG.2012.278	http://dx.doi.org/10.1109/TVCG.2012.278	2088	2094	J	The U.S. Department of Energy's (DOE) Office of Environmental Management (DOE/EM) currently supports an effort to understand and predict the fate of nuclear contaminants and their transport in natural and engineered systems. Geologists, hydrologists, physicists and computer scientists are working together to create models of existing nuclear waste sites, to simulate their behavior and to extrapolate it into the future. We use visualization as an integral part in each step of this process. In the first step, visualization is used to verify model setup and to estimate critical parameters. High-performance computing simulations of contaminant transport produces massive amounts of data, which is then analyzed using visualization software specifically designed for parallel processing of large amounts of structured and unstructured data. Finally, simulation results are validated by comparing simulation results to measured current and historical field data. We describe in this article how visual analysis is used as an integral part of the decision-making process in the planning of ongoing and future treatment options for the contaminated nuclear waste sites. Lessons learned from visually analyzing our large-scale simulation runs will also have an impact on deciding on treatment measures for other contaminated sites.	Joerg Meyer;E. Wes Bethel;Jennifer L. Horsman;Susan S. Hubbard;Harinarayan Krishnan;Alexandru Romosan;Elizabeth H. Keating;Laura Monroe;Richard Strelitz;Phil Moore;Glenn Taylor;Ben Torkian;Timothy C. Johnson;Ian Gorton	Lawrence Berkeley Nat. Lab., Berkeley, CA, USA|c|;;;;;;;;;;;;;		Visual analytics, high-performance computing, data management, parallel rendering, environmental management	
SciVis	2012	Visual Steering and Verification of Mass Spectrometry Data Factorization in Air Quality Research	10.1109/TVCG.2012.280	http://dx.doi.org/10.1109/TVCG.2012.280	2275	2284	J	The study of aerosol composition for air quality research involves the analysis of high-dimensional single particle mass spectrometry data. We describe, apply, and evaluate a novel interactive visual framework for dimensionality reduction of such data. Our framework is based on non-negative matrix factorization with specifically defined regularization terms that aid in resolving mass spectrum ambiguity. Thereby, visualization assumes a key role in providing insight into and allowing to actively control a heretofore elusive data processing step, and thus enabling rapid analysis meaningful to domain scientists. In extending existing black box schemes, we explore design choices for visualizing, interacting with, and steering the factorization process to produce physically meaningful results. A domain-expert evaluation of our system performed by the air quality research experts involved in this effort has shown that our method and prototype admits the finding of unambiguous and physically correct lower-dimensional basis transformations of mass spectrometry data at significantly increased speed and a higher degree of ease.	Daniel Engel;Klaus Greff;Christoph Garth;Keith Bein;Anthony S. Wexler;Bernd Hamann;Hans Hagen	Univ. of Kaiserslautern, Kaiserslautern, Germany|c|;;;;;;	10.1109/INFVIS.2004.68;10.1109/INFVIS.2004.15;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2008.116;10.1109/VISUAL.2000.885734;10.1109/INFVIS.2003.1249015;10.1109/TVCG.2010.223;10.1109/VISUAL.2005.1532850;10.1109/INFVIS.2002.1173157;10.1109/TVCG.2008.153	Dimension reduction, mass spectrometry data, matrix factorization, visual encodings of numerical error metrics, multi-dimensional data visualization	
SciVis	2012	Visualization of Astronomical Nebulae via Distributed Multi-GPU Compressed Sensing Tomography	10.1109/TVCG.2012.281	http://dx.doi.org/10.1109/TVCG.2012.281	2188	2197	J	The 3D visualization of astronomical nebulae is a challenging problem since only a single 2D projection is observable from our fixed vantage point on Earth. We attempt to generate plausible and realistic looking volumetric visualizations via a tomographic approach that exploits the spherical or axial symmetry prevalent in some relevant types of nebulae. Different types of symmetry can be implemented by using different randomized distributions of virtual cameras. Our approach is based on an iterative compressed sensing reconstruction algorithm that we extend with support for position-dependent volumetric regularization and linear equality constraints. We present a distributed multi-GPU implementation that is capable of reconstructing high-resolution datasets from arbitrary projections. Its robustness and scalability are demonstrated for astronomical imagery from the Hubble Space Telescope. The resulting volumetric data is visualized using direct volume rendering. Compared to previous approaches, our method preserves a much higher amount of detail and visual variety in the 3D visualization, especially for objects with only approximate symmetry.	Stephan Wenger;Marco Ament;Stefan Guthe;Dirk A. Lorenz;Andreas M. Tillmann;Daniel Weiskopf;Marcus A. Magnor	Inst. fur Computergraphik, Tech. Univ. Braunschweig, Braunschweig, Germany|c|;;;;;;	10.1109/VISUAL.2005.1532803;10.1109/VISUAL.2004.18;10.1109/VISUAL.1994.346331	Astronomical visualization, distributed volume reconstruction, direct volume rendering	
SciVis	2012	Visualization of Electrostatic Dipoles in Molecular Dynamics of Metal Oxides	10.1109/TVCG.2012.282	http://dx.doi.org/10.1109/TVCG.2012.282	2061	2068	J	Metal oxides are important for many technical applications. For example alumina (aluminum oxide) is the most commonly-used ceramic in microelectronic devices thanks to its excellent properties. Experimental studies of these materials are increasingly supplemented with computer simulations. Molecular dynamics (MD) simulations can reproduce the material behavior very well and are now reaching time scales relevant for interesting processes like crack propagation. In this work we focus on the visualization of induced electric dipole moments on oxygen atoms in crack propagation simulations. The straightforward visualization using glyphs for the individual atoms, simple shapes like spheres or arrows, is insufficient for providing information about the data set as a whole. As our contribution we show for the first time that fractional anisotropy values computed from the local neighborhood of individual atoms of MD simulation data depict important information about relevant properties of the field of induced electric dipole moments. Iso surfaces in the field of fractional anisotropy as well as adjustments of the glyph representation allow the user to identify regions of correlated orientation. We present novel and relevant findings for the application domain resulting from these visualizations, like the influence of mechanical forces on the electrostatic properties.	Sebastian Grottel;Philipp Beck;Christoph Müller 0001;Guido Reina;Johannes Roth;Hans-Rainer Trebin;Thomas Ertl	;;;;;;	10.1109/TVCG.2006.186;10.1109/VISUAL.2005.1532781;10.1109/VISUAL.1999.809886	Visualization in physical sciences and engineering, glyph-based techniques, time-varying data, point-based data	
SciVis	2012	Visualization of Flow Behavior in Earth Mantle Convection	10.1109/TVCG.2012.283	http://dx.doi.org/10.1109/TVCG.2012.283	2198	2207	J	A fundamental characteristic of fluid flow is that it causes mixing: introduce a dye into a flow, and it will disperse. Mixing can be used as a method to visualize and characterize flow. Because mixing is a process that occurs over time, it is a 4D problem that presents a challenge for computation, visualization, and analysis. Motivated by a mixing problem in geophysics, we introduce a combination of methods to analyze, transform, and finally visualize mixing in simulations of convection in a self-gravitating 3D spherical shell representing convection in the Earth's mantle. Geophysicists use tools such as the finite element model CitcomS to simulate convection, and introduce massless, passive tracers to model mixing. The output of geophysical flow simulation is hard to analyze for domain experts because of overall data size and complexity. In addition, information overload and occlusion are problems when visualizing a whole-earth model. To address the large size of the data, we rearrange the simulation data using intelligent indexing for fast file access and efficient caching. To address information overload and interpret mixing, we compute tracer concentration statistics, which are used to characterize mixing in mantle convection models. Our visualization uses a specially tailored version of Direct Volume Rendering. The most important adjustment is the use of constant opacity. Because of this special area of application, i. e. the rendering of a spherical shell, many computations for volume rendering can be optimized. These optimizations are essential to a smooth animation of the time-dependent simulation data. Our results show how our system can be used to quickly assess the simulation output and test hypotheses regarding Earth's mantle convection. The integrated processing pipeline helps geoscientists to focus on their main task of analyzing mantle homogenization.	Simon Schröder;John A. Peterson;Harald Obermaier;Louise H. Kellogg;Kenneth I. Joy;Hans Hagen	Comput. Graphics & HCI Group, Univ. of Kaiserslautern, Kaiserslautern, Germany|c|;;;;;	10.1109/TVCG.2010.156	Geophysics, flow visualization, tracer concentration, Earth mantle, convection, large data system	
SciVis	2012	Visualization of Temporal Similarity in field Data	10.1109/TVCG.2012.284	http://dx.doi.org/10.1109/TVCG.2012.284	2023	2032	J	This paper presents a visualization approach for detecting and exploring similarity in the temporal variation of field data. We provide an interactive technique for extracting correlations from similarity matrices which capture temporal similarity of univariate functions. We make use of the concept to extract periodic and quasiperiodic behavior at single (spatial) points as well as similarity between different locations within a field and also between different data sets. The obtained correlations are utilized for visual exploration of both temporal and spatial relationships in terms of temporal similarity. Our entire pipeline offers visual interaction and inspection, allowing for the flexibility that in particular time-dependent data analysis techniques require. We demonstrate the utility and versatility of our approach by applying our implementation to data from both simulation and measurement.	Steffen Frey;Filip Sadlo;Thomas Ertl	Visualization Res. Center (VISUS), Univ. of Stuttgart, Stuttgart, Germany|c|;;	10.1109/TVCG.2008.139;10.1109/TVCG.2006.199;10.1109/TVCG.2006.165;10.1109/TVCG.2010.213;10.1109/TVCG.2010.133;10.1109/TVCG.2010.223;10.1109/TVCG.2009.199;10.1109/TVCG.2008.140;10.1109/TVCG.2010.216;10.1109/TVCG.2009.200;10.1109/TVCG.2011.159;10.1109/TVCG.2009.197	Time-dependent fields, similarity analysis, interactive recurrence analysis, comparative visualization	
SciVis	2012	Visualizing Nuclear Scission through a Multifield Extension of Topological Analysis	10.1109/TVCG.2012.287	http://dx.doi.org/10.1109/TVCG.2012.287	2033	2040	J	In nuclear science, density functional theory (DFT) is a powerful tool to model the complex interactions within the atomic nucleus, and is the primary theoretical approach used by physicists seeking a better understanding of fission. However DFT simulations result in complex multivariate datasets in which it is difficult to locate the crucial `scission' point at which one nucleus fragments into two, and to identify the precursors to scission. The Joint Contour Net (JCN) has recently been proposed as a new data structure for the topological analysis of multivariate scalar fields, analogous to the contour tree for univariate fields. This paper reports the analysis of DFT simulations using the JCN, the first application of the JCN technique to real data. It makes three contributions to visualization: (i) a set of practical methods for visualizing the JCN, (ii) new insight into the detection of nuclear scission, and (iii) an analysis of aesthetic criteria to drive further work on representing the JCN.	David J. Duke;Hamish Carr;Aaron Knoll;Nicolas Schunck;Hai Ah Nam;Andrzej Staszczak	Sch. of Comput., Univ. of Leeds, Leeds, UK|c|;;;;;	10.1109/TVCG.2008.143	Topology, scalar fields, multifields	
SciVis	2012	WYSIWYP: What You See Is What You Pick	10.1109/TVCG.2012.292	http://dx.doi.org/10.1109/TVCG.2012.292	2236	2244	J	Scientists, engineers and physicians are used to analyze 3D data with slice-based visualizations. Radiologists for example are trained to read slices of medical imaging data. Despite the numerous examples of sophisticated 3D rendering techniques, domain experts, who still prefer slice-based visualization do not consider these to be very useful. Since 3D renderings have the advantage of providing an overview at a glance, while 2D depictions better serve detailed analyses, it is of general interest to better combine these methods. Recently there have been attempts to bridge this gap between 2D and 3D renderings. These attempts include specialized techniques for volume picking in medical imaging data that result in repositioning slices. In this paper, we present a new volume picking technique called WYSIWYP (â€œwhat you see is what you pickâ€) that, in contrast to previous work, does not require pre-segmented data or metadata and thus is more generally applicable. The positions picked by our method are solely based on the data itself, the transfer function, and the way the volumetric rendering is perceived by the user. To demonstrate the utility of the proposed method, we apply it to automated positioning of slices in volumetric scalar fields from various application areas. Finally, we present results of a user study in which 3D locations selected by users are compared to those resulting from WYSIWYP. The user study confirms our claim that the resulting positions correlate well with those perceived by the user.	Alexander Wiebel;Frans Vos;David Foerster;Hans-Christian Hege	Zuse Inst. Berlin (ZIB), Berlin, Germany|c|;;;	10.1109/TVCG.2012.217;10.1109/VISUAL.1998.745337;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2007.70576;10.1109/VISUAL.2005.1532833;10.1109/TVCG.2009.121	Picking, volume rendering, WYSIWYG	
InfoVis	2013	A Deeper Understanding of Sequence in Narrative Visualization	10.1109/TVCG.2013.119	http://dx.doi.org/10.1109/TVCG.2013.119	2406	2415	J	Conveying a narrative with visualizations often requires choosing an order in which to present visualizations. While evidence exists that narrative sequencing in traditional stories can affect comprehension and memory, little is known about how sequencing choices affect narrative visualization. We consider the forms and reactions to sequencing in narrative visualization presentations to provide a deeper understanding with a focus on linear, 'slideshow-style' presentations. We conduct a qualitative analysis of 42 professional narrative visualizations to gain empirical knowledge on the forms that structure and sequence take. Based on the results of this study we propose a graph-driven approach for automatically identifying effective sequences in a set of visualizations to be presented linearly. Our approach identifies possible transitions in a visualization set and prioritizes local (visualization-to-visualization) transitions based on an objective function that minimizes the cost of transitions from the audience perspective. We conduct two studies to validate this function. We also expand the approach with additional knowledge of user preferences for different types of local transitions and the effects of global sequencing strategies on memory, preference, and comprehension. Our results include a relative ranking of types of visualization transitions by the audience perspective and support for memory and subjective rating benefits of visualization sequences that use parallelism as a structural device. We discuss how these insights can guide the design of narrative visualization and systems that support optimization of visualization sequence.	Jessica Hullman;Steven M. Drucker;Nathalie Henry Riche;Bongshin Lee;Danyel Fisher;Eytan Adar	;;;;;	10.1109/VISUAL.2005.1532788;10.1109/TVCG.2007.70577;10.1109/TVCG.2007.70594;10.1109/TVCG.2010.179;10.1109/TVCG.2008.137;10.1109/TVCG.2011.255;10.1109/TVCG.2007.70584;10.1109/TVCG.2007.70539;10.1109/INFVIS.2000.885086	Data storytelling, narrative visualization, narrative structure	
InfoVis	2013	A Design Space of Visualization Tasks	10.1109/TVCG.2013.120	http://dx.doi.org/10.1109/TVCG.2013.120	2366	2375	J	Knowledge about visualization tasks plays an important role in choosing or building suitable visual representations to pursue them. Yet, tasks are a multi-faceted concept and it is thus not surprising that the many existing task taxonomies and models all describe different aspects of tasks, depending on what these task descriptions aim to capture. This results in a clear need to bring these different aspects together under the common hood of a general design space of visualization tasks, which we propose in this paper. Our design space consists of five design dimensions that characterize the main aspects of tasks and that have so far been distributed across different task descriptions. We exemplify its concrete use by applying our design space in the domain of climate impact research. To this end, we propose interfaces to our design space for different user roles (developers, authors, and end users) that allow users of different levels of expertise to work with it.	Hans-Jörg Schulz;Thomas Nocke;Magnus Heitzler;Heidrun Schumann	Univ. of Rostock, Rostock, Germany|c|;;;	10.1109/INFVIS.1996.559213;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2007.70515;10.1109/VISUAL.1990.146372;10.1109/TVCG.2012.205;10.1109/VISUAL.1992.235203;10.1109/INFVIS.2004.59;10.1109/VAST.2008.4677365;10.1109/INFVIS.1996.559211;10.1109/INFVIS.2004.10;10.1109/INFVIS.1997.636792;10.1109/INFVIS.2000.885093;10.1109/INFVIS.2000.885092;10.1109/VISUAL.1990.146375	Task taxonomy, design space, climate impact research, visualization recommendation	
InfoVis	2013	A Model for Structure-Based Comparison of Many Categories in Small-Multiple Displays	10.1109/TVCG.2013.122	http://dx.doi.org/10.1109/TVCG.2013.122	2287	2296	J	Many application domains deal with multi-variate data that consist of both categorical and numerical information. Small-multiple displays are a powerful concept for comparing such data by juxtaposition. For comparison by overlay or by explicit encoding of computed differences, however, a specification of references is necessary. In this paper, we present a formal model for defining semantically meaningful comparisons between many categories in a small-multiple display. Based on pivotized data that are hierarchically partitioned by the categories assigned to the x and y axis of the display, we propose two alternatives for structure-based comparison within this hierarchy. With an absolute reference specification, categories are compared to a fixed reference category. With a relative reference specification, in contrast, a semantic ordering of the categories is considered when comparing them either to the previous or subsequent category each. Both reference specifications can be defined at multiple levels of the hierarchy (including aggregated summaries), enabling a multitude of useful comparisons. We demonstrate the general applicability of our model in several application examples using different visualizations that compare data by overlay or explicit encoding of differences.	Johannes Kehrer;Harald Piringer;Wolfgang Berger;Eduard Gröller	VRVis Res. Center, Vienna, Austria|c|;;;	10.1109/TVCG.2010.138;10.1109/TVCG.2007.70594;10.1109/VISUAL.2005.1532821;10.1109/TVCG.2013.125;10.1109/TVCG.2011.178;10.1109/VAST.2011.6102439;10.1109/TVCG.2008.125;10.1109/INFVIS.2000.885086;10.1109/TVCG.2012.237;10.1109/TVCG.2007.70521	Comparative visualization, small-multiple displays, trellis displays, categorical data	
InfoVis	2013	A Multi-Level Typology of Abstract Visualization Tasks	10.1109/TVCG.2013.124	http://dx.doi.org/10.1109/TVCG.2013.124	2376	2385	J	The considerable previous work characterizing visualization usage has focused on low-level tasks or interactions and high-level tasks, leaving a gap between them that is not addressed. This gap leads to a lack of distinction between the ends and means of a task, limiting the potential for rigorous analysis. We contribute a multi-level typology of visualization tasks to address this gap, distinguishing why and how a visualization task is performed, as well as what the task inputs and outputs are. Our typology allows complex tasks to be expressed as sequences of interdependent simpler tasks, resulting in concise and flexible descriptions for tasks of varying complexity and scope. It provides abstract rather than domain-specific descriptions of tasks, so that useful comparisons can be made between visualization systems targeted at different application domains. This descriptive power supports a level of analysis required for the generation of new designs, by guiding the translation of domain-specific problems into abstract tasks, and for the qualitative evaluation of visualization usage. We demonstrate the benefits of our approach in a detailed case study, comparing task descriptions from our typology to those derived from related work. We also discuss the similarities and differences between our typology and over two dozen extant classification systems and theoretical frameworks from the literatures of visualization, human-computer interaction, information retrieval, communications, and cartography.	Matthew Brehmer;Tamara Munzner	;	10.1109/TVCG.2007.70541;10.1109/TVCG.2012.219;10.1109/INFVIS.1996.559213;10.1109/TVCG.2012.213;10.1109/TVCG.2012.273;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2010.177;10.1109/TVCG.2007.70539;10.1109/INFVIS.2002.1173148;10.1109/TVCG.2007.70515;10.1109/TVCG.2012.204;10.1109/TVCG.2009.111;10.1109/TVCG.2008.109;10.1109/VISUAL.1992.235203;10.1109/INFVIS.2004.59;10.1109/VAST.2008.4677365;10.1109/VAST.2011.6102438;10.1109/TVCG.2008.121;10.1109/TVCG.2008.137;10.1109/INFVIS.1998.729560;10.1109/INFVIS.2004.10;10.1109/TVCG.2012.252;10.1109/VISUAL.1990.146375	Typology, visualization models, task and requirements analysis, qualitative evaluation	
InfoVis	2013	An Empirically-Derived Taxonomy of Interaction Primitives for Interactive Cartography and Geovisualization	10.1109/TVCG.2013.130	http://dx.doi.org/10.1109/TVCG.2013.130	2356	2365	J	Proposals to establish a 'science of interaction' have been forwarded from Information Visualization and Visual Analytics, as well as Cartography, Geovisualization, and GIScience. This paper reports on two studies to contribute to this call for an interaction science, with the goal of developing a functional taxonomy of interaction primitives for map-based visualization. A semi-structured interview study first was conducted with 21 expert interactive map users to understand the way in which map-based visualizations currently are employed. The interviews were transcribed and coded to identify statements representative of either the task the user wished to accomplish (i.e., objective primitives) or the interactive functionality included in the visualization to achieve this task (i.e., operator primitives). A card sorting study then was conducted with 15 expert interactive map designers to organize these example statements into logical structures based on their experience translating client requests into interaction designs. Example statements were supplemented with primitive definitions in the literature and were separated into two sorting exercises: objectives and operators. The objective sort suggested five objectives that increase in cognitive sophistication (identify, compare, rank, associate, & delineate), but exhibited a large amount of variation across participants due to consideration of broader user goals (procure, predict, & prescribe) and interaction operands (space-alone, attributes-in-space, & space-in-time; elementary & general). The operator sort suggested five enabling operators (import, export, save, edit, & annotate) and twelve work operators (reexpress, arrange, sequence, resymbolize, overlay, pan, zoom, reproject, search, filter, retrieve, & calculate). This taxonomy offers an empirically-derived and ecologically-valid structure to inform future research and design on interaction.	Robert E. Roth	Univ. of Wisconsin-Madison, Madison, WI, USA|c|	10.1109/INFVIS.1996.559213;10.1109/TVCG.2007.70515;10.1109/VISUAL.1990.146375;10.1109/INFVIS.1998.729560;10.1109/INFVIS.2005.1532136;10.1109/VAST.2010.5653599;10.1109/INFVIS.2000.885092	Science of interaction, interaction primitives, interactive maps, geovisualization, interaction techniques	
InfoVis	2013	An Interaction Model for Visualizations Beyond The Desktop	10.1109/TVCG.2013.134	http://dx.doi.org/10.1109/TVCG.2013.134	2396	2405	J	We present an interaction model for beyond-desktop visualizations that combines the visualization reference model with the instrumental interaction paradigm. Beyond-desktop visualizations involve a wide range of emerging technologies such as wall-sized displays, 3D and shape-changing displays, touch and tangible input, and physical information visualizations. While these technologies allow for new forms of interaction, they are often studied in isolation. New conceptual models are needed to build a coherent picture of what has been done and what is possible. We describe a modified pipeline model where raw data is processed into a visualization and then rendered into the physical world. Users can explore or change data by directly manipulating visualizations or through the use of instruments. Interactions can also take place in the physical world outside the visualization system, such as when using locomotion to inspect a large scale visualization. Through case studies we illustrate how this model can be used to describe both conventional and unconventional interactive visualization systems, and compare different design alternatives.	Yvonne Jansen;Pierre Dragicevic	Inria & Univ. Paris Sud, Paris, France|c|;	10.1109/TVCG.2010.177;10.1109/VISUAL.2005.1532781;10.1109/TVCG.2007.70577;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2012.251;10.1109/TVCG.2007.70515;10.1109/TVCG.2012.204;10.1109/TVCG.2006.178;10.1109/TVCG.2009.162;10.1109/INFVIS.2003.1249008;10.1109/INFVIS.1998.729560;10.1109/VISUAL.1990.146375	Information visualization, interaction model, notational system, physical visualization	
InfoVis	2013	Automatic Layout of Structured Hierarchical Reports	10.1109/TVCG.2013.137	http://dx.doi.org/10.1109/TVCG.2013.137	2586	2595	J	Domain-specific database applications tend to contain a sizable number of table-, form-, and report-style views that must each be designed and maintained by a software developer. A significant part of this job is the necessary tweaking of low-level presentation details such as label placements, text field dimensions, list or table styles, and so on. In this paper, we present a horizontally constrained layout management algorithm that automates the display of structured hierarchical data using the traditional visual idioms of hand-designed database UIs: tables, multi-column forms, and outline-style indented lists. We compare our system with pure outline and nested table layouts with respect to space efficiency and readability, the latter with an online user study on 27 subjects. Our layouts are 3.9 and 1.6 times more compact on average than outline layouts and horizontally unconstrained table layouts, respectively, and are as readable as table layouts even for large datasets.	Eirik Bakke;David R. Karger;Rob Miller	Comput. Sci. & Artificial Intell. Lab. (CSAIL), MIT, Cambridge, MA, USA|c|;;	10.1109/VAST.2011.6102445;10.1109/INFVIS.2004.1;10.1109/INFVIS.1995.528693;10.1109/TVCG.2007.70594;10.1109/VISUAL.1991.175815;10.1109/INFVIS.2005.1532129;10.1109/INFVIS.1997.636761	Hierarchy data, tabular data, nested relations, layout management	
InfoVis	2013	Common Angle Plots as Perception-True Visualizations of Categorical Associations	10.1109/TVCG.2013.140	http://dx.doi.org/10.1109/TVCG.2013.140	2297	2305	J	Visualizations are great tools of communications-they summarize findings and quickly convey main messages to our audience. As designers of charts we have to make sure that information is shown with a minimum of distortion. We have to also consider illusions and other perceptual limitations of our audience. In this paper we discuss the effect and strength of the line width illusion, a Muller-Lyer type illusion, on designs related to displaying associations between categorical variables. Parallel sets and hammock plots are both affected by line width illusions. We introduce the common-angle plot as an alternative method for displaying categorical data in a manner that minimizes the effect from perceptual illusions. Results from user studies both highlight the need for addressing line-width illusions in displays and provide evidence that common angle charts successfully resolve this issue.	Heike Hofmann;Marie Vendettuoli	;	10.1109/INFVIS.2000.885091;10.1109/INFVIS.2005.1532128;10.1109/TVCG.2010.186;10.1109/TVCG.2011.185;10.1109/TVCG.2009.128	Linewidth illusion, data visualization, high-dimensional displays, parallel sets, hammock plots, Muller-Lyer illusion	
InfoVis	2013	Creative User-Centered Visualization Design for Energy Analysts and Modelers	10.1109/TVCG.2013.145	http://dx.doi.org/10.1109/TVCG.2013.145	2516	2525	J	We enhance a user-centered design process with techniques that deliberately promote creativity to identify opportunities for the visualization of data generated by a major energy supplier. Visualization prototypes developed in this way prove effective in a situation whereby data sets are largely unknown and requirements open - enabling successful exploration of possibilities for visualization in Smart Home data analysis. The process gives rise to novel designs and design metaphors including data sculpting. It suggests: that the deliberate use of creativity techniques with data stakeholders is likely to contribute to successful, novel and effective solutions; that being explicit about creativity may contribute to designers developing creative solutions; that using creativity techniques early in the design process may result in a creative approach persisting throughout the process. The work constitutes the first systematic visualization design for a data rich source that will be increasingly important to energy suppliers and consumers as Smart Meter technology is widely deployed. It is novel in explicitly employing creativity techniques at the requirements stage of visualization design and development, paving the way for further use and study of creativity methods in visualization design.	Sarah Goodwin;Jason Dykes;Sara Jones;Iain Dillingham;Graham Dove;Alison Duffy;Alexander Kachkaev;Aidan Slingsby;Jo Wood	giCentre, City Univ. London, London, UK|c|;;;;;;;;	10.1109/TVCG.2010.191;10.1109/TVCG.2012.213;10.1109/TVCG.2011.196;10.1109/TVCG.2007.70539;10.1109/INFVIS.1999.801851;10.1109/TVCG.2011.209	Creativity techniques, user-centered design, data visualization, smart home, energy consumption	
InfoVis	2013	DiffAni: Visualizing Dynamic Graphs with a Hybrid of Difference Maps and Animation	10.1109/TVCG.2013.149	http://dx.doi.org/10.1109/TVCG.2013.149	2556	2565	J	Visualization of dynamically changing networks (graphs) is a significant challenge for researchers. Previous work has experimentally compared animation, small multiples, and other techniques, and found trade-offs between these. One potential way to avoid such trade-offs is to combine previous techniques in a hybrid visualization. We present two taxonomies of visualizations of dynamic graphs: one of non-hybrid techniques, and one of hybrid techniques. We also describe a prototype, called DiffAni, that allows a graph to be visualized as a sequence of three kinds of tiles: diff tiles that show difference maps over some time interval, animation tiles that show the evolution of the graph over some time interval, and small multiple tiles that show the graph state at an individual time slice. This sequence of tiles is ordered by time and covers all time slices in the data. An experimental evaluation of DiffAni shows that our hybrid approach has advantages over non-hybrid techniques in certain cases.	Sébastien Rufiange;Michael J. McGuffin	Ecole de Technol. Super., Montreal, QC, Canada|c|;	10.1109/VAST.2012.6400552;10.1109/TVCG.2011.169;10.1109/INFVIS.2005.1532151;10.1109/TVCG.2011.226;10.1109/INFVIS.2002.1173155;10.1109/TVCG.2011.213;10.1109/TVCG.2008.141;10.1109/TVCG.2007.70582;10.1109/INFVIS.2002.1173148;10.1109/INFVIS.2005.1532129;10.1109/INFVIS.2002.1173160;10.1109/TVCG.2007.70539	Dynamic networks, hybrid visualization, taxonomy, evolution, animation, difference map	
InfoVis	2013	Dimension Projection Matrix/Tree: Interactive Subspace Visual Exploration and Analysis of High Dimensional Data	10.1109/TVCG.2013.150	http://dx.doi.org/10.1109/TVCG.2013.150	2625	2633	J	For high-dimensional data, this work proposes two novel visual exploration methods to gain insights into the data aspect and the dimension aspect of the data. The first is a Dimension Projection Matrix, as an extension of a scatterplot matrix. In the matrix, each row or column represents a group of dimensions, and each cell shows a dimension projection (such as MDS) of the data with the corresponding dimensions. The second is a Dimension Projection Tree, where every node is either a dimension projection plot or a Dimension Projection Matrix. Nodes are connected with links and each child node in the tree covers a subset of the parent node's dimensions or a subset of the parent node's data items. While the tree nodes visualize the subspaces of dimensions or subsets of the data items under exploration, the matrix nodes enable cross-comparison between different combinations of subspaces. Both Dimension Projection Matrix and Dimension Project Tree can be constructed algorithmically through automation, or manually through user interaction. Our implementation enables interactions such as drilling down to explore different levels of the data, merging or splitting the subspaces to adjust the matrix, and applying brushing to select data clusters. Our method enables simultaneously exploring data correlation and dimension correlation for data with high dimensions.	Xiaoru Yuan;Donghao Ren;Zuchao Wang;Cong Guo	Key Lab. of Machine Perception (Minist. of Educ.) & Sch. of EECS, Peking Univ., Beijing, China|c|;;;	10.1109/INFVIS.2005.1532142;10.1109/TVCG.2009.179;10.1109/TVCG.2010.138;10.1109/INFVIS.2003.1249015;10.1109/VISUAL.1990.146402;10.1109/VAST.2012.6400488;10.1109/VISUAL.1997.663866;10.1109/VISUAL.1995.485140;10.1109/TVCG.2010.184;10.1109/TVCG.2009.128;10.1109/VAST.2006.261422;10.1109/VISUAL.1999.809866;10.1109/INFVIS.2004.60;10.1109/INFVIS.2004.3;10.1109/INFVIS.2004.71;10.1109/TVCG.2009.153;10.1109/TVCG.2008.153;10.1109/INFVIS.2002.1173151	High dimensional data, hierarchical visualization, sub-dimensional space, user interaction, subspace, tree, matrix	
InfoVis	2013	Edge Compression Techniques for Visualization of Dense Directed Graphs	10.1109/TVCG.2013.151	http://dx.doi.org/10.1109/TVCG.2013.151	2596	2605	J	We explore the effectiveness of visualizing dense directed graphs by replacing individual edges with edges connected to 'modules'-or groups of nodes-such that the new edges imply aggregate connectivity. We only consider techniques that offer a lossless compression: that is, where the entire graph can still be read from the compressed version. The techniques considered are: a simple grouping of nodes with identical neighbor sets; Modular Decomposition which permits internal structure in modules and allows them to be nested; and Power Graph Analysis which further allows edges to cross module boundaries. These techniques all have the same goal-to compress the set of edges that need to be rendered to fully convey connectivity-but each successive relaxation of the module definition permits fewer edges to be drawn in the rendered graph. Each successive technique also, we hypothesize, requires a higher degree of mental effort to interpret. We test this hypothetical trade-off with two studies involving human participants. For Power Graph Analysis we propose a novel optimal technique based on constraint programming. This enables us to explore the parameter space for the technique more precisely than could be achieved with a heuristic. Although applicable to many domains, we are motivated by-and discuss in particular-the application to software dependency analysis.	Tim Dwyer;Nathalie Henry Riche;Kim Marriott;Christopher Mears	;;;	10.1109/TVCG.2009.165;10.1109/TVCG.2011.233;10.1109/TVCG.2006.120;10.1109/INFVIS.2004.66	Directed graphs, networks, modular decomposition, power graph analysis	
InfoVis	2013	Empirical Guidance on Scatterplot and Dimension Reduction Technique Choices	10.1109/TVCG.2013.153	http://dx.doi.org/10.1109/TVCG.2013.153	2634	2643	J	To verify cluster separation in high-dimensional data, analysts often reduce the data with a dimension reduction (DR) technique, and then visualize it with 2D Scatterplots, interactive 3D Scatterplots, or Scatterplot Matrices (SPLOMs). With the goal of providing guidance between these visual encoding choices, we conducted an empirical data study in which two human coders manually inspected a broad set of 816 scatterplots derived from 75 datasets, 4 DR techniques, and the 3 previously mentioned scatterplot techniques. Each coder scored all color-coded classes in each scatterplot in terms of their separability from other classes. We analyze the resulting quantitative data with a heatmap approach, and qualitatively discuss interesting scatterplot examples. Our findings reveal that 2D scatterplots are often 'good enough', that is, neither SPLOM nor interactive 3D adds notably more cluster separability with the chosen DR technique. If 2D is not good enough, the most promising approach is to use an alternative DR technique in 2D. Beyond that, SPLOM occasionally adds additional value, and interactive 3D rarely helps but often hurts in terms of poorer class separation and usability. We summarize these results as a workflow model and implications for design. Our results offer guidance to analysts during the DR exploration process.	Michael Sedlmair;Tamara Munzner;Melanie Tory	Univ. of Vienna, Vienna, Austria|c|;;	10.1109/TVCG.2009.127;10.1109/TVCG.2011.229;10.1109/TVCG.2007.70596;10.1109/INFVIS.2005.1532142;10.1109/INFVIS.1997.636793;10.1109/VAST.2010.5652392;10.1109/VAST.2012.6400490;10.1109/TVCG.2008.109;10.1109/VAST.2009.5332628	Dimensionality reduction, scatterplots, quantitative study	
InfoVis	2013	Entourage: Visualizing Relationships between Biological Pathways using Contextual Subsets	10.1109/TVCG.2013.154	http://dx.doi.org/10.1109/TVCG.2013.154	2536	2545	J	Biological pathway maps are highly relevant tools for many tasks in molecular biology. They reduce the complexity of the overall biological network by partitioning it into smaller manageable parts. While this reduction of complexity is their biggest strength, it is, at the same time, their biggest weakness. By removing what is deemed not important for the primary function of the pathway, biologists lose the ability to follow and understand cross-talks between pathways. Considering these cross-talks is, however, critical in many analysis scenarios, such as judging effects of drugs. In this paper we introduce Entourage, a novel visualization technique that provides contextual information lost due to the artificial partitioning of the biological network, but at the same time limits the presented information to what is relevant to the analyst's task. We use one pathway map as the focus of an analysis and allow a larger set of contextual pathways. For these context pathways we only show the contextual subsets, i.e., the parts of the graph that are relevant to a selection. Entourage suggests related pathways based on similarities and highlights parts of a pathway that are interesting in terms of mapped experimental data. We visualize interdependencies between pathways using stubs of visual links, which we found effective yet not obtrusive. By combining this approach with visualization of experimental data, we can provide domain experts with a highly valuable tool. We demonstrate the utility of Entourage with case studies conducted with a biochemist who researches the effects of drugs on pathways. We show that the technique is well suited to investigate interdependencies between pathways and to analyze, understand, and predict the effect that drugs have on different cell types.	Alexander Lex;Christian Partl;Denis Kalkofen;Marc Streit;Samuel Gratzl;Anne Mai Wassermann;Dieter Schmalstieg;Hanspeter Pfister	Harvard Univ., Cambridge, MA, USA|c|;;;;;;;	10.1109/VAST.2009.5333443;10.1109/TVCG.2011.250;10.1109/TVCG.2011.213;10.1109/TVCG.2009.122;10.1109/TVCG.2011.183;10.1109/INFVIS.2000.885087	Pathway visualization, biological networks, subsets, graphs, biomolecular data	
InfoVis	2013	Evaluation of filesystem Provenance Visualization Tools	10.1109/TVCG.2013.155	http://dx.doi.org/10.1109/TVCG.2013.155	2476	2485	J	Having effective visualizations of filesystem provenance data is valuable for understanding its complex hierarchical structure. The most common visual representation of provenance data is the node-link diagram. While effective for understanding local activity, the node-link diagram fails to offer a high-level summary of activity and inter-relationships within the data. We present a new tool, InProv, which displays filesystem provenance with an interactive radial-based tree layout. The tool also utilizes a new time-based hierarchical node grouping method for filesystem provenance data we developed to match the user's mental model and make data exploration more intuitive. We compared InProv to a conventional node-link based tool, Orbiter, in a quantitative evaluation with real users of filesystem provenance data including provenance data experts, IT professionals, and computational scientists. We also compared in the evaluation our new node grouping method to a conventional method. The results demonstrate that InProv results in higher accuracy in identifying system activity than Orbiter with large complex data sets. The results also show that our new time-based hierarchical node grouping method improves performance in both tools, and participants found both tools significantly easier to use with the new time-based node grouping method. Subjective measures show that participants found InProv to require less mental activity, less physical activity, less work, and is less stressful to use. Our study also reveals one of the first cases of gender differences in visualization; both genders had comparable performance with InProv, but women had a significantly lower average accuracy (56%) compared to men (70%) with Orbiter.	Michelle Borkin;Chelsea S. Yeh;Madelaine Boyd;Peter Macko;Krzysztof Z. Gajos;Margo I. Seltzer;Hanspeter Pfister	Sch. of Eng. & Appl. Sci., Harvard Univ., Cambridge, MA, USA|c|;;;;;;	10.1109/TVCG.2006.193;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2006.120;10.1109/TVCG.2009.167;10.1109/INFVIS.2004.66;10.1109/INFVIS.2004.1;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2011.247;10.1109/INFVIS.2005.1532134	Provenance data, graph/network data, hierarchy data, quantitative evaluation, gender differences	
InfoVis	2013	GPLOM: The Generalized Plot Matrix for Visualizing Multidimensional Multivariate Data	10.1109/TVCG.2013.160	http://dx.doi.org/10.1109/TVCG.2013.160	2606	2614	J	Scatterplot matrices (SPLOMs), parallel coordinates, and glyphs can all be used to visualize the multiple continuous variables (i.e., dependent variables or measures) in multidimensional multivariate data. However, these techniques are not well suited to visualizing many categorical variables (i.e., independent variables or dimensions). To visualize multiple categorical variables, 'hierarchical axes' that 'stack dimensions' have been used in systems like Polaris and Tableau. However, this approach does not scale well beyond a small number of categorical variables. Emerson et al. [8] extend the matrix paradigm of the SPLOM to simultaneously visualize several categorical and continuous variables, displaying many kinds of charts in the matrix depending on the kinds of variables involved. We propose a variant of their technique, called the Generalized Plot Matrix (GPLOM). The GPLOM restricts Emerson et al.'s technique to only three kinds of charts (scatterplots for pairs of continuous variables, heatmaps for pairs of categorical variables, and barcharts for pairings of categorical and continuous variable), in an effort to make it easier to understand. At the same time, the GPLOM extends Emerson et al.'s work by demonstrating interactive techniques suited to the matrix of charts. We discuss the visual design and interactive features of our GPLOM prototype, including a textual search feature allowing users to quickly locate values or variables by name. We also present a user study that compared performance with Tableau and our GPLOM prototype, that found that GPLOM is significantly faster in certain cases, and not significantly slower in other cases.	Jean-Francois Im;Michael J. McGuffin;Rock Leung	Ecole de Technol. Super., Montreal, QC, Canada|c|;;	10.1109/INFVIS.2005.1532142;10.1109/TVCG.2007.70523;10.1109/TVCG.2009.179;10.1109/VAST.2009.5332586;10.1109/TVCG.2007.70594;10.1109/VISUAL.1990.146386;10.1109/TVCG.2011.185;10.1109/TVCG.2010.205;10.1109/TVCG.2011.183;10.1109/VISUAL.1993.398859;10.1109/TVCG.2011.201;10.1109/TVCG.2010.164;10.1109/INFVIS.2000.885086;10.1109/TVCG.2007.70521;10.1109/INFVIS.2004.15;10.1109/TVCG.2008.153;10.1109/VISUAL.1991.175796	Multidimensional data, tabular data, relational data, mdmv, high-dimensional data, database visualization, database overview, parallel coordinates, scatterplot matrix, user interfaces, business intelligence	
InfoVis	2013	Hybrid-Image Visualization for Large Viewing Environments	10.1109/TVCG.2013.163	http://dx.doi.org/10.1109/TVCG.2013.163	2346	2355	J	We present a first investigation into hybrid-image visualization for data analysis in large-scale viewing environments. Hybrid-image visualizations blend two different visual representations into a single static view, such that each representation can be perceived at a different viewing distance. Our work is motivated by data analysis scenarios that incorporate one or more displays with sufficiently large size and resolution to be comfortably viewed by different people from various distances. Hybrid-image visualizations can be used, in particular, to enhance overview tasks from a distance and detail-in-context tasks when standing close to the display. By using a perception-based blending approach, hybrid-image visualizations make two full-screen visualizations accessible without tracking viewers in front of a display. We contribute a design space, discuss the perceptual rationale for our work, provide examples, and introduce a set of techniques and tools to aid the design of hybrid-image visualizations.	Petra Isenberg;Pierre Dragicevic;Wesley Willett;Anastasia Bezerianos;Jean-Daniel Fekete	Inria, France;;;;	10.1109/TVCG.2012.251;10.1109/TVCG.2012.264;10.1109/TVCG.2006.184;10.1109/TVCG.2007.70582;10.1109/INFVIS.2001.963288;10.1109/TVCG.2007.70583;10.1109/INFVIS.2005.1532131	Multi-scale, large displays, hybrid images, collaboration, visualization	
InfoVis	2013	Information Visualization and Proxemics: Design Opportunities and Empirical findings	10.1109/TVCG.2013.166	http://dx.doi.org/10.1109/TVCG.2013.166	2386	2395	J	People typically interact with information visualizations using a mouse. Their physical movement, orientation, and distance to visualizations are rarely used as input. We explore how to use such spatial relations among people and visualizations (i.e., proxemics) to drive interaction with visualizations, focusing here on the spatial relations between a single user and visualizations on a large display. We implement interaction techniques that zoom and pan, query and relate, and adapt visualizations based on tracking of users' position in relation to a large high-resolution display. Alternative prototypes are tested in three user studies and compared with baseline conditions that use a mouse. Our aim is to gain empirical data on the usefulness of a range of design possibilities and to generate more ideas. Among other things, the results show promise for changing zoom level or visual representation with the user's physical distance to a large display. We discuss possible benefits and potential issues to avoid when designing information visualizations that use proxemics.	Mikkel Rønne Jakobsen;Yonas Sahlemariam Haile;Søren Knudsen;Kasper Hornbæk	Univ. of Copenhagen, Copenhagen, Denmark|c|;;;	10.1109/TVCG.2006.184;10.1109/TVCG.2012.204;10.1109/TVCG.2012.251;10.1109/TVCG.2007.70577;10.1109/INFVIS.2005.1532136	Proxemics, information visualization, user study, large displays, user tracking, movement, orientation, distance	
InfoVis	2013	Interactive Visualizations on Large and Small Displays: The Interrelation of Display Size, Information Space, and Scale	10.1109/TVCG.2013.170	http://dx.doi.org/10.1109/TVCG.2013.170	2336	2345	J	In controlled experiments on the relation of display size (i.e., the number of pixels) and the usability of visualizations, the size of the information space can either be kept constant or varied relative to display size. Both experimental approaches have limitations. If the information space is kept constant then the scale ratio between an overview of the entire information space and the lowest zoom level varies, which can impact performance; if the information space is varied then the scale ratio is kept constant, but performance cannot be directly compared. In other words, display size, information space, and scale ratio are interrelated variables. We investigate this relation in two experiments with interfaces that implement classic information visualization techniques-focus+context, overview+detail, and zooming-for multi-scale navigation in maps. Display size varied between 0.17, 1.5, and 13.8 megapixels. Information space varied relative to display size in one experiment and was constant in the other. Results suggest that for tasks where users navigate targets that are visible at all map scales the interfaces do not benefit from a large display: With a constant map size, a larger display does not improve performance with the interfaces; with map size varied relative to display size, participants found interfaces harder to use with a larger display and task completion times decrease only when they are normalized to compensate for the increase in map size. The two experimental approaches show different interaction effects between display size and interface. In particular, focus+context performs relatively worse at a large display size with variable map size, and relatively worse at a small display size with a fixed map size. Based on a theoretical analysis of the interaction with the visualization techniques, we examine individual task actions empirically so as to understand the relative impact of display size and scale ratio on the visualization techniques' p- rformance and to discuss differences between the two experimental approaches.	Mikkel Rønne Jakobsen;Kasper Hornbæk	Univ. of Copenhagen, Copenhagen, Denmark|c|;	10.1109/TVCG.2006.184;10.1109/TVCG.2006.187	Information visualization, multi-scale navigation, interaction techniques, experimental method, user studies	
InfoVis	2013	LineUp: Visual Analysis of Multi-Attribute Rankings	10.1109/TVCG.2013.173	http://dx.doi.org/10.1109/TVCG.2013.173	2277	2286	J	Rankings are a popular and universal approach to structuring otherwise unorganized collections of items by computing a rank for each item based on the value of one or more of its attributes. This allows us, for example, to prioritize tasks or to evaluate the performance of products relative to each other. While the visualization of a ranking itself is straightforward, its interpretation is not, because the rank of an item represents only a summary of a potentially complicated relationship between its attributes and those of the other items. It is also common that alternative rankings exist which need to be compared and analyzed to gain insight into how multiple heterogeneous attributes affect the rankings. Advanced visual exploration tools are needed to make this process efficient. In this paper we present a comprehensive analysis of requirements for the visualization of multi-attribute rankings. Based on these considerations, we propose LineUp - a novel and scalable visualization technique that uses bar charts. This interactive technique supports the ranking of items based on multiple heterogeneous attributes with different scales and semantics. It enables users to interactively combine attributes and flexibly refine parameters to explore the effect of changes in the attribute combination. This process can be employed to derive actionable insights as to which attributes of an item need to be modified in order for its rank to change. Additionally, through integration of slope graphs, LineUp can also be used to compare multiple alternative rankings on the same set of items, for example, over time or across different attribute combinations. We evaluate the effectiveness of the proposed multi-attribute visualization technique in a qualitative study. The study shows that users are able to successfully solve complex ranking tasks in a short period of time.	Samuel Gratzl;Alexander Lex;Nils Gehlenborg;Hanspeter Pfister;Marc Streit	Johannes Kepler Univ. Linz, Linz, Austria|c|;;;;	10.1109/TVCG.2012.253;10.1109/TVCG.2008.166;10.1109/VISUAL.1996.568118;10.1109/TVCG.2008.181;10.1109/TVCG.2007.70539	Ranking visualization, ranking, scoring, multi-attribute, multifactorial, multi-faceted, stacked bar charts	
InfoVis	2013	Nanocubes for Real-Time Exploration of Spatiotemporal Datasets	10.1109/TVCG.2013.179	http://dx.doi.org/10.1109/TVCG.2013.179	2456	2465	J	Consider real-time exploration of large multidimensional spatiotemporal datasets with billions of entries, each defined by a location, a time, and other attributes. Are certain attributes correlated spatially or temporally? Are there trends or outliers in the data? Answering these questions requires aggregation over arbitrary regions of the domain and attributes of the data. Many relational databases implement the well-known data cube aggregation operation, which in a sense precomputes every possible aggregate query over the database. Data cubes are sometimes assumed to take a prohibitively large amount of space, and to consequently require disk storage. In contrast, we show how to construct a data cube that fits in a modern laptop's main memory, even for billions of entries; we call this data structure a nanocube. We present algorithms to compute and query a nanocube, and show how it can be used to generate well-known visual encodings such as heatmaps, histograms, and parallel coordinate plots. When compared to exact visualizations created by scanning an entire dataset, nanocube plots have bounded screen error across a variety of scales, thanks to a hierarchical structure in space and time. We demonstrate the effectiveness of our technique on a variety of real-world datasets, and present memory, timing, and network bandwidth measurements. We find that the timings for the queries in our examples are dominated by network and user-interaction latencies.	Lauro Didier Lins;James T. Klosowski;Carlos Eduardo Scheidegger	;;	10.1109/TVCG.2006.161;10.1109/INFVIS.2002.1173141;10.1109/TVCG.2009.191;10.1109/VAST.2008.4677357;10.1109/TVCG.2007.70594;10.1109/INFVIS.2002.1173156;10.1109/VISUAL.1990.146386;10.1109/TVCG.2011.185	Data cube, Data structures, Interactive exploration	
InfoVis	2013	Orthographic Star Coordinates	10.1109/TVCG.2013.182	http://dx.doi.org/10.1109/TVCG.2013.182	2615	2624	J	Star coordinates is a popular projection technique from an nD data space to a 2D/3D visualization domain. It is defined by setting n coordinate axes in the visualization domain. Since it generally defines an affine projection, strong distortions can occur: an nD sphere can be mapped to an ellipse of arbitrary size and aspect ratio. We propose to restrict star coordinates to orthographic projections which map an nD sphere of radius r to a 2D circle of radius r. We achieve this by formulating conditions for the coordinate axes to define orthographic projections, and by running a repeated non-linear optimization in the background of every modification of the coordinate axes. This way, we define a number of orthographic interaction concepts as well as orthographic data tour sequences: a scatterplot tour, a principle component tour, and a grand tour. All concepts are illustrated and evaluated with synthetic and real data.	Dirk J. Lehmann;Holger Theisel	Dept. of Simulation & Graphics, Univ. of Magdeburg, Magdeburg, Germany|c|;	10.1109/VISUAL.1997.663916	Start plot, multivariate visualization, visual analytics	
InfoVis	2013	Perception of Average Value in Multiclass Scatterplots	10.1109/TVCG.2013.183	http://dx.doi.org/10.1109/TVCG.2013.183	2316	2325	J	The visual system can make highly efficient aggregate judgements about a set of objects, with speed roughly independent of the number of objects considered. While there is a rich literature on these mechanisms and their ramifications for visual summarization tasks, this prior work rarely considers more complex tasks requiring multiple judgements over long periods of time, and has not considered certain critical aggregation types, such as the localization of the mean value of a set of points. In this paper, we explore these questions using a common visualization task as a case study: relative mean value judgements within multi-class scatterplots. We describe how the perception literature provides a set of expected constraints on the task, and evaluate these predictions with a large-scale perceptual study with crowd-sourced participants. Judgements are no harder when each set contains more points, redundant and conflicting encodings, as well as additional sets, do not strongly affect performance, and judgements are harder when using less salient encodings. These results have concrete ramifications for the design of scatterplots.	Michael Gleicher;Michael Correll;Christine Nothelfer;Steven Franconeri	Dept. of Comput. Sci., Univ. of Wisconsin - Madison, Madison, WI, USA|c|;;;	10.1109/TVCG.2012.233	Psychophysics, Information Visualization, Perceptual Study	
InfoVis	2013	Radial Sets: Interactive Visual Analysis of Large Overlapping Sets	10.1109/TVCG.2013.184	http://dx.doi.org/10.1109/TVCG.2013.184	2496	2505	J	In many applications, data tables contain multi-valued attributes that often store the memberships of the table entities to multiple sets such as which languages a person masters, which skills an applicant documents, or which features a product comes with. With a growing number of entities, the resulting element-set membership matrix becomes very rich of information about how these sets overlap. Many analysis tasks targeted at set-typed data are concerned with these overlaps as salient features of such data. This paper presents Radial Sets, a novel visual technique to analyze set memberships for a large number of elements. Our technique uses frequency-based representations to enable quickly finding and analyzing different kinds of overlaps between the sets, and relating these overlaps to other attributes of the table entities. Furthermore, it enables various interactions to select elements of interest, find out if they are over-represented in specific sets or overlaps, and if they exhibit a different distribution for a specific attribute compared to the rest of the elements. These interactions allow formulating highly-expressive visual queries on the elements in terms of their set memberships and attribute values. As we demonstrate via two usage scenarios, Radial Sets enable revealing and analyzing a multitude of overlapping patterns between large sets, beyond the limits of state-of-the-art techniques.	Bilal Alsallakh;Wolfgang Aigner;Silvia Miksch;Helwig Hauser	Vienna Univ. of Technol., Vienna, Austria|c|;;;	10.1109/TVCG.2006.160;10.1109/TVCG.2009.122;10.1109/TVCG.2008.144;10.1109/TVCG.2011.186;10.1109/INFVIS.2004.1;10.1109/TVCG.2010.210;10.1109/TVCG.2012.254;10.1109/INFVIS.2002.1173157	Multi-valued attributes, set-typed data, overlapping sets, visualization technique, scalability	
InfoVis	2013	Selecting the Aspect Ratio of a Scatter Plot Based on Its Delaunay Triangulation	10.1109/TVCG.2013.187	http://dx.doi.org/10.1109/TVCG.2013.187	2326	2335	J	Scatter plots are diagrams that visualize two-dimensional data as sets of points in the plane. They allow users to detect correlations and clusters in the data. Whether or not a user can accomplish these tasks highly depends on the aspect ratio selected for the plot, i.e., the ratio between the horizontal and the vertical extent of the diagram. We argue that an aspect ratio is good if the Delaunay triangulation of the scatter plot at this aspect ratio has some nice geometric property, e.g., a large minimum angle or a small total edge length. More precisely, we consider the following optimization problem. Given a set Q of points in the plane, find a scale factor s such that scaling the x-coordinates of the points in Q by s and the y-coordinates by 1=s yields a point set P(s) that optimizes a property of the Delaunay triangulation of P(s), over all choices of s. We present an algorithm that solves this problem efficiently and demonstrate its usefulness on real-world instances. Moreover, we discuss an empirical test in which we asked 64 participants to choose the aspect ratios of 18 scatter plots. We tested six different quality measures that our algorithm can optimize. In conclusion, minimizing the total edge length and minimizing what we call the 'uncompactness' of the triangles of the Delaunay triangulation yielded the aspect ratios that were most similar to those chosen by the participants in the test.	Martin Fink 0001;Jan-Henrik Haunert;Joachim Spoerhase;Alexander Wolff	Inst. fur Inf., Univ. Wurzburg, Wurzburg, Germany|c|;;;	10.1109/TVCG.2006.163;10.1109/TVCG.2012.196;10.1109/TVCG.2011.167	Scatter plot, aspect ratio, Delaunay triangulation	
InfoVis	2013	SketchStory: Telling More Engaging Stories with Data through Freeform Sketching	10.1109/TVCG.2013.191	http://dx.doi.org/10.1109/TVCG.2013.191	2416	2425	J	Presenting and communicating insights to an audience-telling a story-is one of the main goals of data exploration. Even though visualization as a storytelling medium has recently begun to gain attention, storytelling is still underexplored in information visualization and little research has been done to help people tell their stories with data. To create a new, more engaging form of storytelling with data, we leverage and extend the narrative storytelling attributes of whiteboard animation with pen and touch interactions. We present SketchStory, a data-enabled digital whiteboard that facilitates the creation of personalized and expressive data charts quickly and easily. SketchStory recognizes a small set of sketch gestures for chart invocation, and automatically completes charts by synthesizing the visuals from the presenter-provided example icon and binding them to the underlying data. Furthermore, SketchStory allows the presenter to move and resize the completed data charts with touch, and filter the underlying data to facilitate interactive exploration. We conducted a controlled experiment for both audiences and presenters to compare SketchStory with a traditional presentation system, Microsoft PowerPoint. Results show that the audience is more engaged by presentations done with SketchStory than PowerPoint. Eighteen out of 24 audience participants preferred SketchStory to PowerPoint. Four out of five presenter participants also favored SketchStory despite the extra effort required for presentation.	Bongshin Lee;Rubaiat Habib Kazi;Greg Smith	;;	10.1109/TVCG.2007.70577;10.1109/TVCG.2012.262;10.1109/TVCG.2010.179;10.1109/TVCG.2012.275;10.1109/TVCG.2008.137;10.1109/VAST.2007.4388992	Storytelling, data presentation, sketch, pen and touch, interaction, visualization	
InfoVis	2013	SoccerStories: A Kick-off for Visual Soccer Analysis	10.1109/TVCG.2013.192	http://dx.doi.org/10.1109/TVCG.2013.192	2506	2515	J	This article presents SoccerStories, a visualization interface to support analysts in exploring soccer data and communicating interesting insights. Currently, most analyses on such data relate to statistics on individual players or teams. However, soccer analysts we collaborated with consider that quantitative analysis alone does not convey the right picture of the game, as context, player positions and phases of player actions are the most relevant aspects. We designed SoccerStories to support the current practice of soccer analysts and to enrich it, both in the analysis and communication stages. Our system provides an overview+detail interface of game phases, and their aggregation into a series of connected visualizations, each visualization being tailored for actions such as a series of passes or a goal attempt. To evaluate our tool, we ran two qualitative user studies on recent games using SoccerStories with data from one of the world's leading live sports data providers. The first study resulted in a series of four articles on soccer tactics, by a tactics analyst, who said he would not have been able to write these otherwise. The second study consisted in an exploratory follow-up to investigate design alternatives for embedding soccer phases into word-sized graphics. For both experiments, we received a very enthusiastic feedback and participants consider further use of SoccerStories to enhance their current workflow.	Charles Perin;Romain Vuillemot;Jean-Daniel Fekete	INRIA, Univ. Paris-Sud, Paris, France|c|;;	10.1109/TVCG.2007.70582;10.1109/TVCG.2011.169;10.1109/TVCG.2011.185;10.1109/TVCG.2012.263	Visual knowledge discovery, visual knowledge representation, sport analytics, visual aggregation	
InfoVis	2013	StoryFlow: Tracking the Evolution of Stories	10.1109/TVCG.2013.196	http://dx.doi.org/10.1109/TVCG.2013.196	2436	2445	J	Storyline visualizations, which are useful in many applications, aim to illustrate the dynamic relationships between entities in a story. However, the growing complexity and scalability of stories pose great challenges for existing approaches. In this paper, we propose an efficient optimization approach to generating an aesthetically appealing storyline visualization, which effectively handles the hierarchical relationships between entities over time. The approach formulates the storyline layout as a novel hybrid optimization approach that combines discrete and continuous optimization. The discrete method generates an initial layout through the ordering and alignment of entities, and the continuous method optimizes the initial layout to produce the optimal one. The efficient approach makes real-time interactions (e.g., bundling and straightening) possible, thus enabling users to better understand and track how the story evolves. Experiments and case studies are conducted to demonstrate the effectiveness and usefulness of the optimization approach.	Shixia Liu;Yingcai Wu;Enxun Wei;Mengchen Liu;Yang Liu 0014	;;;;	10.1109/TVCG.2012.253;10.1109/TVCG.2011.255;10.1109/TVCG.2010.179;10.1109/TVCG.2011.226;10.1109/VAST.2008.4677364;10.1109/TVCG.2012.212;10.1109/TVCG.2013.221;10.1109/TVCG.2012.225;10.1109/VAST.2006.261421;10.1109/VAST.2009.5333437;10.1109/TVCG.2011.239	Storylines, story-telling visualization, user interactions, level-of-detail, optimization	
InfoVis	2013	Understanding Interfirm Relationships in Business Ecosystems with Interactive Visualization	10.1109/TVCG.2013.209	http://dx.doi.org/10.1109/TVCG.2013.209	2526	2535	J	Business ecosystems are characterized by large, complex, and global networks of firms, often from many different market segments, all collaborating, partnering, and competing to create and deliver new products and services. Given the rapidly increasing scale, complexity, and rate of change of business ecosystems, as well as economic and competitive pressures, analysts are faced with the formidable task of quickly understanding the fundamental characteristics of these interfirm networks. Existing tools, however, are predominantly query- or list-centric with limited interactive, exploratory capabilities. Guided by a field study of corporate analysts, we have designed and implemented dotlink360, an interactive visualization system that provides capabilities to gain systemic insight into the compositional, temporal, and connective characteristics of business ecosystems. dotlink360 consists of novel, multiple connected views enabling the analyst to explore, discover, and understand interfirm networks for a focal firm, specific market segments or countries, and the entire business ecosystem. System evaluation by a small group of prototypical users shows supporting evidence of the benefits of our approach. This design study contributes to the relatively unexplored, but promising area of exploratory information visualization in market research and business strategy.	Rahul C. Basole;Trustin Clear;Mengdie Hu;Harshit Mehrotra;John T. Stasko	;;;;	10.1109/TVCG.2006.160;10.1109/INFVIS.2005.1532134;10.1109/INFVIS.2003.1249027;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2012.213;10.1109/TVCG.2006.122;10.1109/VAST.2010.5652530;10.1109/TVCG.2006.166	Business ecosystems, market research, strategic analysis, design study, interaction, network visualization	
InfoVis	2013	Using Concrete Scales: A Practical Framework for Effective Visual Depiction of Complex Measures	10.1109/TVCG.2013.210	http://dx.doi.org/10.1109/TVCG.2013.210	2426	2435	J	From financial statistics to nutritional values, we are frequently exposed to quantitative information expressed in measures of either extreme magnitudes or unfamiliar units, or both. A common practice used to comprehend such complex measures is to relate, re-express, and compare them through visual depictions using magnitudes and units that are easier to grasp. Through this practice, we create a new graphic composition that we refer to as a concrete scale. To the best of our knowledge, there are no design guidelines that exist for concrete scales despite their common use in communication, educational, and decision-making settings. We attempt to fill this void by introducing a novel framework that would serve as a practical guide for their analysis and design. Informed by a thorough analysis of graphic compositions involving complex measures and an extensive literature review of scale cognition mechanisms, our framework outlines the design space of various measure relations-specifically relations involving the re-expression of complex measures to more familiar concepts-and their visual representations as graphic compositions.	Fanny Chevalier;Romain Vuillemot;Guia Gali	Univ. of Toronto & OCAD Univ., Toronto, ON, Canada|c|;;	10.1109/TVCG.2012.199	Concrete scale, scale cognition, visual comparison, graphic composition, visual notation	
InfoVis	2013	Variant View: Visualizing Sequence Variants in their Gene Context	10.1109/TVCG.2013.214	http://dx.doi.org/10.1109/TVCG.2013.214	2546	2555	J	Scientists use DNA sequence differences between an individual's genome and a standard reference genome to study the genetic basis of disease. Such differences are called sequence variants, and determining their impact in the cell is difficult because it requires reasoning about both the type and location of the variant across several levels of biological context. In this design study, we worked with four analysts to design a visualization tool supporting variant impact assessment for three different tasks. We contribute data and task abstractions for the problem of variant impact assessment, and the carefully justified design and implementation of the Variant View tool. Variant View features an information-dense visual encoding that provides maximal information at the overview level, in contrast to the extensive navigation required by currently-prevalent genome browsers. We provide initial evidence that the tool simplified and accelerated workflows for these three tasks through three case studies. Finally, we reflect on the lessons learned in creating and refining data and task abstractions that allow for concise overviews of sprawling information spaces that can reduce or remove the need for the memory-intensive use of navigation.	Joel A. Ferstay;Cydney B. Nielsen;Tamara Munzner	;;	10.1109/TVCG.2009.111;10.1109/TVCG.2008.109;10.1109/TVCG.2012.213;10.1109/TVCG.2011.185;10.1109/INFVIS.2003.1249023;10.1109/TVCG.2009.116;10.1109/TVCG.2009.167;10.1109/TVCG.2011.209	Information visualization, design study, bioinformatics, genetic variants	
InfoVis	2013	Visual Compression of Workflow Visualizations with Automated Detection of Macro Motifs	10.1109/TVCG.2013.225	http://dx.doi.org/10.1109/TVCG.2013.225	2576	2585	J	This paper is concerned with the creation of 'macros' in workflow visualization as a support tool to increase the efficiency of data curation tasks. We propose computation of candidate macros based on their usage in large collections of workflows in data repositories. We describe an efficient algorithm for extracting macro motifs from workflow graphs. We discovered that the state transition information, used to identify macro candidates, characterizes the structural pattern of the macro and can be harnessed as part of the visual design of the corresponding macro glyph. This facilitates partial automation and consistency in glyph design applicable to a large set of macro glyphs. We tested this approach against a repository of biological data holding some 9,670 workflows and found that the algorithmically generated candidate macros are in keeping with domain expert expectations.	Eamonn Maguire;Philippe Rocca-Serra;Susanna-Assunta Sansone;Jim Davies;Min Chen	Dept. of Comput. Sci., Univ. of Oxford, Oxford, UK|c|;;;;	10.1109/TVCG.2007.70584;10.1109/INFVIS.2004.12;10.1109/TVCG.2006.147;10.1109/TVCG.2009.195;10.1109/TVCG.2012.271;10.1109/VISUAL.1996.567752;10.1109/TVCG.2008.174;10.1109/TVCG.2006.166	Workflow visualization, motif detection, glyph-based visualization, glyph generation, state-transition-based algorithm	
InfoVis	2013	Visual Sedimentation	10.1109/TVCG.2013.227	http://dx.doi.org/10.1109/TVCG.2013.227	2446	2455	J	We introduce Visual Sedimentation, a novel design metaphor for visualizing data streams directly inspired by the physical process of sedimentation. Visualizing data streams (e. g., Tweets, RSS, Emails) is challenging as incoming data arrive at unpredictable rates and have to remain readable. For data streams, clearly expressing chronological order while avoiding clutter, and keeping aging data visible, are important. The metaphor is drawn from the real-world sedimentation processes: objects fall due to gravity, and aggregate into strata over time. Inspired by this metaphor, data is visually depicted as falling objects using a force model to land on a surface, aggregating into strata over time. In this paper, we discuss how this metaphor addresses the specific challenge of smoothing the transition between incoming and aging data. We describe the metaphor's design space, a toolkit developed to facilitate its implementation, and example applications to a range of case studies. We then explore the generative capabilities of the design space through our toolkit. We finally illustrate creative extensions of the metaphor when applied to real streams of data.	Samuel Huron;Romain Vuillemot;Jean-Daniel Fekete	;;	10.1109/VAST.2012.6400552;10.1109/TVCG.2012.291;10.1109/TVCG.2011.179;10.1109/INFVIS.2003.1249014;10.1109/TVCG.2011.185;10.1109/TVCG.2008.166;10.1109/TVCG.2008.171;10.1109/INFVIS.2004.65;10.1109/TVCG.2007.70539	Design, Information Visualization, Dynamic visualization, Dynamic data, Data stream, Real time, Metaphor	
InfoVis	2013	Visualization of Shape Motions in Shape Space	10.1109/TVCG.2013.230	http://dx.doi.org/10.1109/TVCG.2013.230	2644	2652	J	Analysis of dynamic object deformations such as cardiac motion is of great importance, especially when there is a necessity to visualize and compare the deformation behavior across subjects. However, there is a lack of effective techniques for comparative visualization and assessment of a collection of motion data due to its 4-dimensional nature, i.e., timely varying three-dimensional shapes. From the geometric point of view, the motion change can be considered as a function defined on the 2D manifold of the surface. This paper presents a novel classification and visualization method based on a medial surface shape space, in which two novel shape descriptors are defined, for discriminating normal and abnormal human heart deformations as well as localizing the abnormal motion regions. In our medial surface shape space, the geodesic distance connecting two points in the space measures the similarity between their corresponding medial surfaces, which can quantify the similarity and disparity of the 3D heart motions. Furthermore, the novel descriptors can effectively localize the inconsistently deforming myopathic regions on the left ventricle. An easy visualization of heart motion sequences on the projected space allows users to distinguish the deformation differences. Our experimental results on both synthetic and real imaging data show that this method can automatically classify the healthy and myopathic subjects and accurately detect myopathic regions on the left ventricle, which outperforms other conventional cardiac diagnostic methods.	Vahid Taimouri;Jing Hua	Dept. of Comput. Sci., Wayne State Univ., Detroit, MI, USA|c|;	10.1109/TVCG.2006.137;10.1109/INFVIS.2003.1249025;10.1109/TVCG.2009.159;10.1109/INFVIS.2004.65	Medial surface, shape space, comparative visualization, left ventricle diagnosis	
InfoVis	2013	Visualizing Change over Time Using Dynamic Hierarchies: TreeVersity2 and the StemView	10.1109/TVCG.2013.231	http://dx.doi.org/10.1109/TVCG.2013.231	2566	2575	J	To analyze data such as the US Federal Budget or characteristics of the student population of a University it is common to look for changes over time. This task can be made easier and more fruitful if the analysis is performed by grouping by attributes, such as by Agencies, Bureaus and Accounts for the Budget, or Ethnicity, Gender and Major in a University. We present TreeVersity2, a web based interactive data visualization tool that allows users to analyze change in datasets by creating dynamic hierarchies based on the data attributes. TreeVersity2 introduces a novel space filling visualization (StemView) to represent change in trees at multiple levels - not just at the leaf level. With this visualization users can explore absolute and relative changes, created and removed nodes, and each node's actual values, while maintaining the context of the tree. In addition, TreeVersity2 provides overviews of change over the entire time period, and a reporting tool that lists outliers in textual form, which helps users identify the major changes in the data without having to manually setup filters. We validated TreeVersity2 with 12 case studies with organizations as diverse as the National Cancer Institute, Federal Drug Administration, Department of Transportation, Office of the Bursar of the University of Maryland, or eBay. Our case studies demonstrated that TreeVersity2 is flexible enough to be used in different domains and provide useful insights for the data owners. A TreeVersity2 demo can be found at https://treeversity.cattlab.umd.edu.	John Alexis Guerra Gómez;Michael L. Pack;Catherine Plaisant;Ben Shneiderman	Dept. of Comput. Sci., Univ. of Maryland, College Park, MD, USA|c|;;;	10.1109/VAST.2011.6102439;10.1109/TVCG.2006.147;10.1109/TVCG.2011.185;10.1109/VISUAL.1991.175815;10.1109/TVCG.2007.70556;10.1109/INFVIS.2002.1173150;10.1109/VAST.2006.261450;10.1109/INFVIS.2002.1173148;10.1109/INFVIS.2003.1249026;10.1109/TVCG.2007.70529	Information visualization, Tree comparison	
InfoVis	2013	Visualizing Fuzzy Overlapping Communities in Networks	10.1109/TVCG.2013.232	http://dx.doi.org/10.1109/TVCG.2013.232	2486	2495	J	An important feature of networks for many application domains is their community structure. This is because objects within the same community usually have at least one property in common. The investigation of community structure can therefore support the understanding of object attributes from the network topology alone. In real-world systems, objects may belong to several communities at the same time, i.e., communities can overlap. Analyzing fuzzy community memberships is essential to understand to what extent objects contribute to different communities and whether some communities are highly interconnected. We developed a visualization approach that is based on node-link diagrams and supports the investigation of fuzzy communities in weighted undirected graphs at different levels of detail. Starting with the network of communities, the user can continuously drill down to the network of individual nodes and finally analyze the membership distribution of nodes of interest. Our approach uses layout strategies and further visual mappings to graphically encode the fuzzy community memberships. The usefulness of our approach is illustrated by two case studies analyzing networks of different domains: social networking and biological interactions. The case studies showed that our layout and visualization approach helps investigate fuzzy overlapping communities. Fuzzy vertices as well as the different communities to which they belong can be easily identified based on node color and position.	Corinna Vehlow;Thomas Reinhardt;Daniel Weiskopf	VISUS, Univ. of Stuttgart, Stuttgart, Germany|c|;;	10.1109/VISUAL.1993.398872;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2011.186;10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/INFVIS.2004.43;10.1109/TVCG.2009.113	Overlapping community visualization, fuzzy clustering, graph visualization, uncertainty visualization	
InfoVis	2013	Visualizing Request-Flow Comparison to Aid Performance Diagnosis in Distributed Systems	10.1109/TVCG.2013.233	http://dx.doi.org/10.1109/TVCG.2013.233	2466	2475	J	Distributed systems are complex to develop and administer, and performance problem diagnosis is particularly challenging. When performance degrades, the problem might be in any of the system's many components or could be a result of poor interactions among them. Recent research efforts have created tools that automatically localize the problem to a small number of potential culprits, but research is needed to understand what visualization techniques work best for helping distributed systems developers understand and explore their results. This paper compares the relative merits of three well-known visualization approaches (side-by-side, diff, and animation) in the context of presenting the results of one proven automated localization technique called request-flow comparison. Via a 26-person user study, which included real distributed systems developers, we identify the unique benefits that each approach provides for different problem types and usage modes.	Raja R. Sambasivan;Ilari Shafer;Michelle L. Mazurek;Gregory R. Ganger	;;;	10.1109/VAST.2010.5652910;10.1109/TVCG.2008.125;10.1109/TVCG.2007.70539;10.1109/VAST.2011.6102442	Distributed systems, human factors, problem diagnosis, visualization	
InfoVis	2013	What Makes a Visualization Memorable?	10.1109/TVCG.2013.234	http://dx.doi.org/10.1109/TVCG.2013.234	2306	2315	J	An ongoing debate in the Visualization community concerns the role that visualization types play in data understanding. In human cognition, understanding and memorability are intertwined. As a first step towards being able to ask questions about impact and effectiveness, here we ask: 'What makes a visualization memorable?' We ran the largest scale visualization study to date using 2,070 single-panel visualizations, categorized with visualization type (e.g., bar chart, line graph, etc.), collected from news media sites, government reports, scientific journals, and infographic sources. Each visualization was annotated with additional attributes, including ratings for data-ink ratios and visual densities. Using Amazon's Mechanical Turk, we collected memorability scores for hundreds of these visualizations, and discovered that observers are consistent in which visualizations they find memorable and forgettable. We find intuitive results (e.g., attributes like color and the inclusion of a human recognizable object enhance memorability) and less intuitive results (e.g., common graphs are less memorable than unique visualization types). Altogether our findings suggest that quantifying memorability is a general metric of the utility of information, an essential step towards determining how to design effective visualizations.	Michelle Borkin;Azalea A. Vo;Zoya Bylinskii;Phillip Isola;Shashank Sunkavalli;Aude Oliva;Hanspeter Pfister	Sch. of Eng. & Appl. Sci., Harvard Univ., Cambridge, MA, USA|c|;;;;;;	10.1109/TVCG.2012.221;10.1109/INFVIS.2004.59;10.1109/TVCG.2012.197;10.1109/TVCG.2012.245;10.1109/TVCG.2011.175	Visualization taxonomy, information visualization, memorability	
SciVis	2013	A Lightweight Tangible 3D Interface for Interactive Visualization of Thin fiber Structures	10.1109/TVCG.2013.121	http://dx.doi.org/10.1109/TVCG.2013.121	2802	2809	J	We present a prop-based, tangible interface for 3D interactive visualization of thin fiber structures. These data are commonly found in current bioimaging datasets, for example second-harmonic generation microscopy of collagen fibers in tissue. Our approach uses commodity visualization technologies such as a depth sensing camera and low-cost 3D display. Unlike most current uses of these emerging technologies in the games and graphics communities, we employ the depth sensing camera to create a fish-tank sterePoscopic virtual reality system at the scientist's desk that supports tracking of small-scale gestures with objects already found in the work space. We apply the new interface to the problem of interactive exploratory visualization of three-dimensional thin fiber data. A critical task for the visual analysis of these data is understanding patterns in fiber orientation throughout a volume.The interface enables a new, fluid style of data exploration and fiber orientation analysis by using props to provide needed passive-haptic feedback, making 3D interactions with these fiber structures more controlled. We also contribute a low-level algorithm for extracting fiber centerlines from volumetric imaging. The system was designed and evaluated with two biophotonic experts who currently use it in their lab. As compared to typical practice within their field, the new visualization system provides a more effective way to examine and understand the 3D bioimaging datasets they collect.	Bret Jackson;Tung Yuen Lau;David Schroeder;Kimani C. Toussaint;Daniel F. Keefe	Univ. of Minnesota, Minneapolis, MN, USA|c|;;;;	10.1109/TVCG.2009.138;10.1109/VISUAL.2005.1532846;10.1109/VISUAL.2002.1183753;10.1109/VISUAL.1997.663912	Scientific visualization, 3D interaction, tangible interaction, microscopy visualization	
SciVis	2013	A Multi-Criteria Approach to Camera Motion Design for Volume Data Animation	10.1109/TVCG.2013.123	http://dx.doi.org/10.1109/TVCG.2013.123	2792	2801	J	We present an integrated camera motion design and path generation system for building volume data animations. Creating animations is an essential task in presenting complex scientific visualizations. Existing visualization systems use an established animation function based on keyframes selected by the user. This approach is limited in providing the optimal in-between views of the data. Alternatively, computer graphics and virtual reality camera motion planning is frequently focused on collision free movement in a virtual walkthrough. For semi-transparent, fuzzy, or blobby volume data the collision free objective becomes insufficient. Here, we provide a set of essential criteria focused on computing camera paths to establish effective animations of volume data. Our dynamic multi-criteria solver coupled with a force-directed routing algorithm enables rapid generation of camera paths. Once users review the resulting animation and evaluate the camera motion, they are able to determine how each criterion impacts path generation. In this paper, we demonstrate how incorporating this animation approach with an interactive volume visualization system reduces the effort in creating context-aware and coherent animations. This frees the user to focus on visualization tasks with the objective of gaining additional insight from the volume data.	Wei-Hsien Hsu;Yubo Zhang;Kwan-Liu Ma	Univ. of California, Davis, Davis, CA, USA|c|;;	10.1109/TVCG.2006.152;10.1109/TVCG.2006.140;10.1109/TVCG.2009.189;10.1109/INFVIS.2003.1249004;10.1109/VISUAL.2005.1532834;10.1109/TVCG.2012.292;10.1109/VISUAL.2005.1532787;10.1109/VISUAL.2005.1532833;10.1109/VISUAL.2001.964517	Camera motion planning, volume rendering, visualization, animation	
SciVis	2013	A Systematic Review on the Practice of Evaluating Visualization	10.1109/TVCG.2013.126	http://dx.doi.org/10.1109/TVCG.2013.126	2818	2827	J	We present an assessment of the state and historic development of evaluation practices as reported in papers published at the IEEE Visualization conference. Our goal is to reflect on a meta-level about evaluation in our community through a systematic understanding of the characteristics and goals of presented evaluations. For this purpose we conducted a systematic review of ten years of evaluations in the published papers using and extending a coding scheme previously established by Lam et al. [2012]. The results of our review include an overview of the most common evaluation goals in the community, how they evolved over time, and how they contrast or align to those of the IEEE Information Visualization conference. In particular, we found that evaluations specific to assessing resulting images and algorithm performance are the most prevalent (with consistently 80-90% of all papers since 1997). However, especially over the last six years there is a steady increase in evaluation methods that include participants, either by evaluating their performances and subjective feedback or by evaluating their work practices and their improved analysis and reasoning capabilities using visual tools. Up to 2010, this trend in the IEEE Visualization conference was much more pronounced than in the IEEE Information Visualization conference which only showed an increasing percentage of evaluation through user performance and experience testing. Since 2011, however, also papers in IEEE Information Visualization show such an increase of evaluations of work practices and analysis as well as reasoning using visual tools. Further, we found that generally the studies reporting requirements analyses and domain-specific work practices are too informally reported which hinders cross-comparison and lowers external validity.	Tobias Isenberg 0001;Petra Isenberg;Jian Chen;Michael Sedlmair;Torsten Möller	INRIA, France|c|;;;;	10.1109/TVCG.2009.121;10.1109/VISUAL.2005.1532781;10.1109/TVCG.2006.143;10.1109/TVCG.2011.224;10.1109/TVCG.2010.199;10.1109/TVCG.2010.223;10.1109/TVCG.2012.213;10.1109/TVCG.2010.134;10.1109/TVCG.2009.194;10.1109/TVCG.2011.174;10.1109/TVCG.2009.111;10.1109/TVCG.2011.206;10.1109/TVCG.2012.234;10.1109/TVCG.2012.292;10.1109/TVCG.2008.128;10.1109/TVCG.2009.167;10.1109/TVCG.2012.223	Evaluation, validation, systematic review, visualization, scientific visualization, information visualization	
SciVis	2013	Acuity-Driven Gigapixel Visualization	10.1109/TVCG.2013.127	http://dx.doi.org/10.1109/TVCG.2013.127	2886	2895	J	We present a framework for acuity-driven visualization of super-high resolution image data on gigapixel displays. Tiled display walls offer a large workspace that can be navigated physically by the user. Based on head tracking information, the physical characteristics of the tiled display and the formulation of visual acuity, we guide an out-of-core gigapixel rendering scheme by delivering high levels of detail only in places where it is perceivable to the user. We apply this principle to gigapixel image rendering through adaptive level of detail selection. Additionally, we have developed an acuity-driven tessellation scheme for high-quality Focus-and-Context (F+C) lenses that significantly reduces visual artifacts while accurately capturing the underlying lens function. We demonstrate this framework on the Reality Deck, an immersive gigapixel display. We present the results of a user study designed to quantify the impact of our acuity-driven rendering optimizations in the visual exploration process. We discovered no evidence suggesting a difference in search task performance between our framework and naive rendering of gigapixel resolution data, while realizing significant benefits in terms of data transfer overhead. Additionally, we show that our acuity-driven tessellation scheme offers substantially increased frame rates when compared to naive pre-tessellation, while providing indistinguishable image quality.	Charilaos Papadopoulos;Arie E. Kaufman	Stony Brook Univ., Stony Brook, NY, USA|c|;	10.1109/TVCG.2011.231;10.1109/INFVIS.2004.66	Gigapixel visualization, visual acuity, focus and context, Reality Deck, gigapixel display	
SciVis	2013	Adaptive Refinement of the Flow Map Using Sparse Samples	10.1109/TVCG.2013.128	http://dx.doi.org/10.1109/TVCG.2013.128	2753	2762	J	We present a new efficient and scalable method for the high quality reconstruction of the flow map from sparse samples. The flow map describes the transport of massless particles along the flow. As such, it is a fundamental concept in the analysis of transient flow phenomena and all so-called Lagrangian flow visualization techniques require its approximation. The flow map is generally obtained by integrating a dense 1D, 2D, or 3D set of particles across the domain of definition of the flow. Despite its embarrassingly parallel nature, this computation creates a performance bottleneck in the analysis of large-scale datasets that existing adaptive techniques alleviate only partially. Our iterative approximation method significantly improves upon the state of the art by precisely modeling the flow behavior around automatically detected geometric structures embedded in the flow, thus effectively restricting the sampling effort to interesting regions. Our data reconstruction is based on a modified version of Sibson's scattered data interpolation and allows us at each step to offer an intermediate dense approximation of the flow map and to seamlessly integrate regions that will be further refined in subsequent steps. We present a quantitative and qualitative evaluation of our method on different types of flow datasets and offer a detailed comparison with existing techniques.	Samer S. Barakat;Xavier Tricoche	Comput. Sci. Dept., Purdue Univ., West Lafayette, IN, USA|c|;	10.1109/TVCG.2009.190;10.1109/TVCG.2008.133;10.1109/TVCG.2007.70554;10.1109/TVCG.2007.70551	Lagrangian flow visualization, flow map, edge features, scattered data interpolation, sparse sampling, adaptive refinement, parallel reconstruction	
SciVis	2013	Ambient Volume Scattering	10.1109/TVCG.2013.129	http://dx.doi.org/10.1109/TVCG.2013.129	2936	2945	J	We present ambient scattering as a preintegration method for scattering on mesoscopic scales in direct volume rendering. Far-range scattering effects usually provide negligible contributions to a given location due to the exponential attenuation with increasing distance. This motivates our approach to preintegrating multiple scattering within a finite spherical region around any given sample point. To this end, we solve the full light transport with a Monte-Carlo simulation within a set of spherical regions, where each region may have different material parameters regarding anisotropy and extinction. This precomputation is independent of the data set and the transfer function, and results in a small preintegration table. During rendering, the look-up table is accessed for each ray sample point with respect to the viewing direction, phase function, and material properties in the spherical neighborhood of the sample. Our rendering technique is efficient and versatile because it readily fits in existing ray marching algorithms and can be combined with local illumination and volumetric ambient occlusion. It provides interactive volumetric scattering and soft shadows, with interactive control of the transfer function, anisotropy parameter of the phase function, lighting conditions, and viewpoint. A GPU implementation demonstrates the benefits of ambient scattering for the visualization of different types of data sets, with respect to spatial perception, high-quality illumination, translucency, and rendering speed.	Marco Ament;Filip Sadlo;Daniel Weiskopf	Univ. of Stuttgart, Stuttgart, Germany|c|;;	10.1109/TVCG.2011.211;10.1109/TVCG.2007.70555;10.1109/VISUAL.2003.1250394;10.1109/VISUAL.2000.885683;10.1109/TVCG.2010.187;10.1109/VISUAL.2004.64;10.1109/VISUAL.2003.1250406;10.1109/TVCG.2010.145;10.1109/TVCG.2012.232;10.1109/TVCG.2011.161;10.1109/TVCG.2011.198;10.1109/VISUAL.2002.1183764;10.1109/VISUAL.2005.1532803;10.1109/TVCG.2009.204	Direct volume rendering, volume illumination, ambient scattering, preintegrated light transport, gradient-free shading	
SciVis	2013	An Exploration Framework to Identify and Track Movement of Cloud Systems	10.1109/TVCG.2013.131	http://dx.doi.org/10.1109/TVCG.2013.131	2896	2905	J	We describe a framework to explore and visualize the movement of cloud systems. Using techniques from computational topology and computer vision, our framework allows the user to study this movement at various scales in space and time. Such movements could have large temporal and spatial scales such as the Madden Julian Oscillation (MJO), which has a spatial scale ranging from 1000 km to 10000 km and time of oscillation of around 40 days. Embedded within these larger scale oscillations are a hierarchy of cloud clusters which could have smaller spatial and temporal scales such as the Nakazawa cloud clusters. These smaller cloud clusters, while being part of the equatorial MJO, sometimes move at speeds different from the larger scale and in a direction opposite to that of the MJO envelope. Hitherto, one could only speculate about such movements by selectively analysing data and a priori knowledge of such systems. Our framework automatically delineates such cloud clusters and does not depend on the prior experience of the user to define cloud clusters. Analysis using our framework also shows that most tropical systems such as cyclones also contain multi-scale interactions between clouds and cloud systems. We show the effectiveness of our framework to track organized cloud system during one such rainfall event which happened at Mumbai, India in July 2005 and for cyclone Aila which occurred in Bay of Bengal during May 2009.	Harish Doraiswamy;Vijay Natarajan;Ravi S. Nanjundiah	Dept. of Comput. Sci. & Eng., Polytech. Inst. of New York Univ., New York, NY, USA|c|;;	10.1109/TVCG.2007.70519;10.1109/TVCG.2006.186;10.1109/VISUAL.2003.1250383	Cloud clusters, tracking, computational topology, split tree, weather and climate simulations	
SciVis	2013	An Information-Aware Framework for Exploring Multivariate Data Sets	10.1109/TVCG.2013.133	http://dx.doi.org/10.1109/TVCG.2013.133	2683	2692	J	Information theory provides a theoretical framework for measuring information content for an observed variable, and has attracted much attention from visualization researchers for its ability to quantify saliency and similarity among variables. In this paper, we present a new approach towards building an exploration framework based on information theory to guide the users through the multivariate data exploration process. In our framework, we compute the total entropy of the multivariate data set and identify the contribution of individual variables to the total entropy. The variables are classified into groups based on a novel graph model where a node represents a variable and the links encode the mutual information shared between the variables. The variables inside the groups are analyzed for their representativeness and an information based importance is assigned. We exploit specific information metrics to analyze the relationship between the variables and use the metrics to choose isocontours of selected variables. For a chosen group of points, parallel coordinates plots (PCP) are used to show the states of the variables and provide an interface for the user to select values of interest. Experiments with different data sets reveal the effectiveness of our proposed framework in depicting the interesting regions of the data sets taking into account the interaction among the variables.	Ayan Biswas;Soumya Dutta;Han-Wei Shen;Jonathan Woodring	Gravity Group, Ohio State Univ., Columbus, OH, USA|c|;;;	10.1109/TVCG.2010.132;10.1109/TVCG.2009.120;10.1109/VISUAL.1990.146402;10.1109/TVCG.2010.131;10.1109/TVCG.2006.152;10.1109/TVCG.2008.116;10.1109/TVCG.2010.184;10.1109/INFVIS.2004.15;10.1109/TVCG.2008.160;10.1109/TVCG.2008.140;10.1109/VAST.2007.4389000;10.1109/TVCG.2011.201;10.1109/VISUAL.1995.485139;10.1109/VISUAL.2005.1532833;10.1109/TVCG.2010.182;10.1109/VISUAL.1997.663875;10.1109/VISUAL.2002.1183785	Information theory, framework, isosurface, multivariate uncertainty	
SciVis	2013	Area-Preservation Mapping using Optimal Mass Transport	10.1109/TVCG.2013.135	http://dx.doi.org/10.1109/TVCG.2013.135	2838	2847	J	We present a novel area-preservation mapping/flattening method using the optimal mass transport technique, based on the Monge-Brenier theory. Our optimal transport map approach is rigorous and solid in theory, efficient and parallel in computation, yet general for various applications. By comparison with the conventional Monge-Kantorovich approach, our method reduces the number of variables from O(n2) to O(n), and converts the optimal mass transport problem to a convex optimization problem, which can now be efficiently carried out by Newton's method. Furthermore, our framework includes the area weighting strategy that enables users to completely control and adjust the size of areas everywhere in an accurate and quantitative way. Our method significantly reduces the complexity of the problem, and improves the efficiency, flexibility and scalability during visualization. Our framework, by combining conformal mapping and optimal mass transport mapping, serves as a powerful tool for a broad range of applications in visualization and graphics, especially for medical imaging. We provide a variety of experimental results to demonstrate the efficiency, robustness and efficacy of our novel framework.	Xin Zhao;Zhengyu Su;Xianfeng Gu;Arie E. Kaufman;Jian Sun;Jie Gao;Feng Luo 0002	;;;;;;	10.1109/TVCG.2011.171	Area-preservation mapping, surface flattening, optimal transport map, Monge-Brenier theory, visualization and graphics applications	
SciVis	2013	Characterizing and Visualizing Predictive Uncertainty in Numerical Ensembles Through Bayesian Model Averaging	10.1109/TVCG.2013.138	http://dx.doi.org/10.1109/TVCG.2013.138	2703	2712	J	Numerical ensemble forecasting is a powerful tool that drives many risk analysis efforts and decision making tasks. These ensembles are composed of individual simulations that each uniquely model a possible outcome for a common event of interest: e.g., the direction and force of a hurricane, or the path of travel and mortality rate of a pandemic. This paper presents a new visual strategy to help quantify and characterize a numerical ensemble's predictive uncertainty: i.e., the ability for ensemble constituents to accurately and consistently predict an event of interest based on ground truth observations. Our strategy employs a Bayesian framework to first construct a statistical aggregate from the ensemble. We extend the information obtained from the aggregate with a visualization strategy that characterizes predictive uncertainty at two levels: at a global level, which assesses the ensemble as a whole, as well as a local level, which examines each of the ensemble's constituents. Through this approach, modelers are able to better assess the predictive strengths and weaknesses of the ensemble as a whole, as well as individual models. We apply our method to two datasets to demonstrate its broad applicability.	Luke J. Gosink;Kevin Bensema;Trenton Pulsipher;Harald Obermaier;Michael Henry;Hank Childs;Kenneth I. Joy	;;;;;;	10.1109/VISUAL.2002.1183769;10.1109/VISUAL.2005.1532853;10.1109/VISUAL.1996.568116;10.1109/TVCG.2010.208;10.1109/TVCG.2010.181	Uncertainty visualization, numerical ensembles, statistical visualization	
SciVis	2013	Colon Flattening Using Heat Diffusion Riemannian Metric	10.1109/TVCG.2013.139	http://dx.doi.org/10.1109/TVCG.2013.139	2848	2857	J	We propose a new colon flattening algorithm that is efficient, shape-preserving, and robust to topological noise. Unlike previous approaches, which require a mandatory topological denoising to remove fake handles, our algorithm directly flattens the colon surface without any denoising. In our method, we replace the original Euclidean metric of the colon surface with a heat diffusion metric that is insensitive to topological noise. Using this heat diffusion metric, we then solve a Laplacian equation followed by an integration step to compute the final flattening. We demonstrate that our method is shape-preserving and the shape of the polyps are well preserved. The flattened colon also provides an efficient way to enhance the navigation and inspection in virtual colonoscopy. We further show how the existing colon registration pipeline is made more robust by using our colon flattening. We have tested our method on several colon wall surfaces and the experimental results demonstrate the robustness and the efficiency of our method.	Krishna Chaitanya Gurijala;Rui Shi;Wei Zeng;Xianfeng Gu;Arie E. Kaufman	Stony Brook Univ., Stony Brook, NY, USA|c|;;;;	10.1109/VISUAL.2001.964540;10.1109/TVCG.2006.112;10.1109/VISUAL.2001.964540;10.1109/TVCG.2010.200	Colon flattening, heat diffusion, virtual colonoscopy, volume rendering, topological noise, shape-preserving mapping	
SciVis	2013	Comparative Visual Analysis of Lagrangian Transport in CFD Ensembles	10.1109/TVCG.2013.141	http://dx.doi.org/10.1109/TVCG.2013.141	2743	2752	J	Sets of simulation runs based on parameter and model variation, so-called ensembles, are increasingly used to model physical behaviors whose parameter space is too large or complex to be explored automatically. Visualization plays a key role in conveying important properties in ensembles, such as the degree to which members of the ensemble agree or disagree in their behavior. For ensembles of time-varying vector fields, there are numerous challenges for providing an expressive comparative visualization, among which is the requirement to relate the effect of individual flow divergence to joint transport characteristics of the ensemble. Yet, techniques developed for scalar ensembles are of little use in this context, as the notion of transport induced by a vector field cannot be modeled using such tools. We develop a Lagrangian framework for the comparison of flow fields in an ensemble. Our techniques evaluate individual and joint transport variance and introduce a classification space that facilitates incorporation of these properties into a common ensemble visualization. Variances of Lagrangian neighborhoods are computed using pathline integration and Principal Components Analysis. This allows for an inclusion of uncertainty measurements into the visualization and analysis approach. Our results demonstrate the usefulness and expressiveness of the presented method on several practical examples.	Mathias Hummel;Harald Obermaier;Christoph Garth;Kenneth I. Joy	Univ. of Kaiserslautern, Kaiserslautern, Germany|c|;;;	10.1109/TVCG.2011.203;10.1109/VISUAL.1996.568116;10.1109/TVCG.2010.190;10.1109/TVCG.2010.181;10.1109/TVCG.2007.70551	Ensemble, flow field, time-varying, comparison, visualization, Lagrangian, variance, principal components analysis	
SciVis	2013	ConnectomeExplorer: Query-Guided Visual Analysis of Large Volumetric Neuroscience Data	10.1109/TVCG.2013.142	http://dx.doi.org/10.1109/TVCG.2013.142	2868	2877	J	This paper presents ConnectomeExplorer, an application for the interactive exploration and query-guided visual analysis of large volumetric electron microscopy (EM) data sets in connectomics research. Our system incorporates a knowledge-based query algebra that supports the interactive specification of dynamically evaluated queries, which enable neuroscientists to pose and answer domain-specific questions in an intuitive manner. Queries are built step by step in a visual query builder, building more complex queries from combinations of simpler queries. Our application is based on a scalable volume visualization framework that scales to multiple volumes of several teravoxels each, enabling the concurrent visualization and querying of the original EM volume, additional segmentation volumes, neuronal connectivity, and additional meta data comprising a variety of neuronal data attributes. We evaluate our application on a data set of roughly one terabyte of EM data and 750 GB of segmentation data, containing over 4,000 segmented structures and 1,000 synapses. We demonstrate typical use-case scenarios of our collaborators in neuroscience, where our system has enabled them to answer specific scientific questions using interactive querying and analysis on the full-size data for the first time.	Johanna Beyer;Ali Al-Awami;Narayanan Kasthuri;Jeff Lichtman;Hanspeter Pfister;Markus Hadwiger	King Abdullah Univ. of Sci. & Technol. (KAUST), Thuwal, Saudi Arabia|c|;;;;;	10.1109/INFVIS.2000.885086;10.1109/VISUAL.2005.1532792;10.1109/TVCG.2009.178;10.1109/TVCG.2012.240;10.1109/TVCG.2006.195;10.1109/VISUAL.1995.485139;10.1109/TVCG.2007.70560;10.1109/TVCG.2009.118;10.1109/TVCG.2009.121	Connectomics, neuroscience, query algebra, visual knowledge discovery, petascale volume analysis	
SciVis	2013	Contour Boxplots: A Method for Characterizing Uncertainty in Feature Sets from Simulation Ensembles	10.1109/TVCG.2013.143	http://dx.doi.org/10.1109/TVCG.2013.143	2713	2722	J	Ensembles of numerical simulations are used in a variety of applications, such as meteorology or computational solid mechanics, in order to quantify the uncertainty or possible error in a model or simulation. Deriving robust statistics and visualizing the variability of an ensemble is a challenging task and is usually accomplished through direct visualization of ensemble members or by providing aggregate representations such as an average or pointwise probabilities. In many cases, the interesting quantities in a simulation are not dense fields, but are sets of features that are often represented as thresholds on physical or derived quantities. In this paper, we introduce a generalization of boxplots, called contour boxplots, for visualization and exploration of ensembles of contours or level sets of functions. Conventional boxplots have been widely used as an exploratory or communicative tool for data analysis, and they typically show the median, mean, confidence intervals, and outliers of a population. The proposed contour boxplots are a generalization of functional boxplots, which build on the notion of data depth. Data depth approximates the extent to which a particular sample is centrally located within its density function. This produces a center-outward ordering that gives rise to the statistical quantities that are essential to boxplots. Here we present a generalization of functional data depth to contours and demonstrate methods for displaying the resulting boxplots for two-dimensional simulation data in weather forecasting and computational fluid dynamics.	Ross T. Whitaker;Mahsa Mirzargar;Robert Michael Kirby	Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;	10.1109/VISUAL.2002.1183769;10.1109/VISUAL.1996.568105;10.1109/VISUAL.2005.1532807;10.1109/TVCG.2010.181	Uncertainty visualization, boxplots, band depth, ensemble visualization, order statistics	
SciVis	2013	Coupled Ensemble Flow Line Advection and Analysis	10.1109/TVCG.2013.144	http://dx.doi.org/10.1109/TVCG.2013.144	2733	2742	J	Ensemble run simulations are becoming increasingly widespread. In this work, we couple particle advection with pathline analysis to visualize and reveal the differences among the flow fields of ensemble runs. Our method first constructs a variation field using a Lagrangian-based distance metric. The variation field characterizes the variation between vector fields of the ensemble runs, by extracting and visualizing the variation of pathlines within ensemble. Parallelism in a MapReduce style is leveraged to handle data processing and computing at scale. Using our prototype system, we demonstrate how scientists can effectively explore and investigate differences within ensemble simulations.	Hanqi Guo;Xiaoru Yuan;Jian Huang;Xiaomin Zhu	Key Lab. of Machine Perception, Peking Univ., Beijing, China|c|;;;	10.1109/VISUAL.2005.1532853;10.1109/TVCG.2011.219;10.1109/TVCG.2011.203;10.1109/TVCG.2006.116;10.1109/TVCG.2010.190;10.1109/TVCG.2010.181;10.1109/VISUAL.1996.568116;10.1109/TVCG.2007.70551	Ensemble analysis, parallel processing, field line advection	
SciVis	2013	Design by Dragging: An Interface for Creative Forward and Inverse Design with Simulation Ensembles	10.1109/TVCG.2013.147	http://dx.doi.org/10.1109/TVCG.2013.147	2783	2791	J	We present an interface for exploring large design spaces as encountered in simulation-based engineering, design of visual effects, and other tasks that require tuning parameters of computationally-intensive simulations and visually evaluating results. The goal is to enable a style of design with simulations that feels as-direct-as-possible so users can concentrate on creative design tasks. The approach integrates forward design via direct manipulation of simulation inputs (e.g., geometric properties, applied forces) in the same visual space with inverse design via 'tugging' and reshaping simulation outputs (e.g., scalar fields from finite element analysis (FEA) or computational fluid dynamics (CFD)). The interface includes algorithms for interpreting the intent of users' drag operations relative to parameterized models, morphing arbitrary scalar fields output from FEA and CFD simulations, and in-place interactive ensemble visualization. The inverse design strategy can be extended to use multi-touch input in combination with an as-rigid-as-possible shape manipulation to support rich visual queries. The potential of this new design approach is confirmed via two applications: medical device engineering of a vacuum-assisted biopsy device and visual effects design using a physically based flame simulation.	Dane M. Coffey;Chi-Lun Lin;Arthur G. Erdman;Daniel F. Keefe	Univ. of Minnesota, Minneapolis, MN, USA|c|;;;	10.1109/TVCG.2012.261;10.1109/TVCG.2010.223;10.1109/TVCG.2010.190;10.1109/TVCG.2011.248;10.1109/VISUAL.2000.885734;10.1109/TVCG.2010.171;10.1109/TVCG.2007.70581	Design, simulation, direct manipulation, multi-touch	
SciVis	2013	Detecting Symmetry in Scalar fields Using Augmented Extremum Graphs	10.1109/TVCG.2013.148	http://dx.doi.org/10.1109/TVCG.2013.148	2663	2672	J	Visualizing symmetric patterns in the data often helps the domain scientists make important observations and gain insights about the underlying experiment. Detecting symmetry in scalar fields is a nascent area of research and existing methods that detect symmetry are either not robust in the presence of noise or computationally costly. We propose a data structure called the augmented extremum graph and use it to design a novel symmetry detection method based on robust estimation of distances. The augmented extremum graph captures both topological and geometric information of the scalar field and enables robust and computationally efficient detection of symmetry. We apply the proposed method to detect symmetries in cryo-electron microscopy datasets and the experiments demonstrate that the algorithm is capable of detecting symmetry even in the presence of significant noise. We describe novel applications that use the detected symmetry to enhance visualization of scalar field data and facilitate their exploration.	Dilip Mathew Thomas;Vijay Natarajan	Dept. of Comput. Sci. & Autom., Indian Inst. of Sci., Bangalore, India|c|;	10.1109/VISUAL.2004.68;10.1109/TVCG.2009.120;10.1109/TVCG.2011.236;10.1109/TVCG.2008.143;10.1109/TVCG.2011.244;10.1109/TVCG.2007.70603;10.1109/TVCG.2012.200;10.1109/TVCG.2006.186	Scalar field visualization, extremum graph, Morse decomposition, symmetry detection, data exploration	
SciVis	2013	Efficient Local Statistical Analysis via Integral Histograms with Discrete Wavelet Transform	10.1109/TVCG.2013.152	http://dx.doi.org/10.1109/TVCG.2013.152	2693	2702	J	Histograms computed from local regions are commonly used in many visualization applications, and allowing the user to query histograms interactively in regions of arbitrary locations and sizes plays an important role in feature identification and tracking. Computing histograms in regions with arbitrary location and size, nevertheless, can be time consuming for large data sets since it involves expensive I/O and scan of data elements. To achieve both performance- and storage-efficient query of local histograms, we present a new algorithm called WaveletSAT, which utilizes integral histograms, an extension of the summed area tables (SAT), and discrete wavelet transform (DWT). Similar to SAT, an integral histogram is the histogram computed from the area between each grid point and the grid origin, which can be be pre-computed to support fast query. Nevertheless, because one histogram contains multiple bins, it will be very expensive to store one integral histogram at each grid point. To reduce the storage cost for large integral histograms, WaveletSAT treats the integral histograms of all grid points as multiple SATs, each of which can be converted into a sparse representation via DWT, allowing the reconstruction of axis-aligned region histograms of arbitrary sizes from a limited number of wavelet coefficients. Besides, we present an efficient wavelet transform algorithm for SATs that can operate on each grid point separately in logarithmic time complexity, which can be extended to parallel GPU-based implementation. With theoretical and empirical demonstration, we show that WaveletSAT can achieve fast preprocessing and smaller storage overhead than the conventional integral histogram approach with close query performance.	Teng-Yok Lee;Han-Wei Shen	Ohio State Univ., Columbus, OH, USA|c|;	10.1109/VISUAL.1999.809910;10.1109/TVCG.2010.131;10.1109/TVCG.2011.246;10.1109/VISUAL.2001.964516;10.1109/TVCG.2011.198;10.1109/TVCG.2009.197	WaveletSAT, integral histograms, discrete wavelet transform	
SciVis	2013	Evaluation of Static and Dynamic Visualization Training Approaches for Users with Different Spatial Abilities	10.1109/TVCG.2013.156	http://dx.doi.org/10.1109/TVCG.2013.156	2810	2817	J	Conflicting results are reported in the literature on whether dynamic visualizations are more effective than static visualizations for learning and mastering 3-D tasks, and only a few investigations have considered the influence of the spatial abilities of the learners. In a study with 117 participants, we compared the benefit of static vs. dynamic visualization training tools on learners with different spatial abilities performing a typical 3-D task (specifically, creating orthographic projections of a 3-D object). We measured the spatial abilities of the participants using the Mental Rotation Test (MRT) and classified participants into two groups (high and low abilities) to examine how the participants' abilities predicted change in performance after training with static versus dynamic training tools. Our results indicate that: 1) visualization training programs can help learners to improve 3-D task performance, 2) dynamic visualizations provide no advantages over static visualizations that show intermediate steps, 3) training programs are more beneficial for individuals with low spatial abilities than for individuals with high spatial abilities, and 4) training individuals with high spatial abilities using dynamic visualizations provides little benefit.	Maria-Elena Froese;Melanie Tory;Guy-Warwick Evans;Kedar Shrikhande	;;;	10.1109/VISUAL.2005.1532836;10.1109/VISUAL.2003.1250396	Spatial ability, 3D visualization, training, evaluation, orthographic projection, CAD	
SciVis	2013	Fast Blending Scheme for Molecular Surface Representation	10.1109/TVCG.2013.158	http://dx.doi.org/10.1109/TVCG.2013.158	2653	2662	J	Representation of molecular surfaces is a well established way to study the interaction of molecules. The state-of-theart molecular representation is the SES model, which provides a detailed surface visualization. Nevertheless, it is computationally expensive, so the less accurate Gaussian model is traditionally preferred. We introduce a novel surface representation that resembles the SES and approaches the rendering performance of the Gaussian model. Our technique is based on the iterative blending of implicit functions and avoids any pre-computation. Additionally, we propose a GPU-based ray-casting algorithm that efficiently visualize our molecular representation. A qualitative and quantitative comparison of our model with respect to the Gaussian and SES models is presented. As showcased in the paper, our technique is a valid and appealing alternative to the Gaussian representation. This is especially relevant in all the applications where the cost of the SES is prohibitive.	Július Parulek;Andrea Brambilla	Dept. ofInformatics, Univ. of Bergen, Bergen, Norway|c|;	10.1109/TVCG.2009.157;10.1109/VISUAL.2003.1250414;10.1109/TVCG.2006.115	Molecular visualization, geometry-based techniques, implicit surfaces	
SciVis	2013	Fast Generation of Virtual X-ray Images for Reconstruction of 3D Anatomy	10.1109/TVCG.2013.159	http://dx.doi.org/10.1109/TVCG.2013.159	2673	2682	J	We propose a novel GPU-based approach to render virtual X-ray projections of deformable tetrahedral meshes. These meshes represent the shape and the internal density distribution of a particular anatomical structure and are derived from statistical shape and intensity models (SSIMs). We apply our method to improve the geometric reconstruction of 3D anatomy (e.g. pelvic bone) from 2D X-ray images. For that purpose, shape and density of a tetrahedral mesh are varied and virtual X-ray projections are generated within an optimization process until the similarity between the computed virtual X-ray and the respective anatomy depicted in a given clinical X-ray is maximized. The OpenGL implementation presented in this work deforms and projects tetrahedral meshes of high resolution (200.000+ tetrahedra) at interactive rates. It generates virtual X-rays that accurately depict the density distribution of an anatomy of interest. Compared to existing methods that accumulate X-ray attenuation in deformable meshes, our novel approach significantly boosts the deformation/projection performance. The proposed projection algorithm scales better with respect to mesh resolution and complexity of the density distribution, and the combined deformation and projection on the GPU scales better with respect to the number of deformation parameters. The gain in performance allows for a larger number of cycles in the optimization process. Consequently, it reduces the risk of being stuck in a local optimum. We believe that our approach will improve treatments in orthopedics, where 3D anatomical information is essential.	Moritz Ehlke;Heiko Ramm;Hans Lamecker;Hans-Christian Hege;Stefan Zachow	Zuse Inst. Berlin, Berlin, Germany|c|;;;;	10.1109/VISUAL.2005.1532809;10.1109/VISUAL.2005.1532815;10.1109/TVCG.2006.110;10.1109/VISUAL.2003.1250384	Digitally reconstructed radiographs, volume rendering, mesh deformation, statistical shape and intensity models, image registration, GPU acceleration	
SciVis	2013	GRACE: A Visual Comparison Framework for Integrated Spatial and Non-Spatial Geriatric Data	10.1109/TVCG.2013.161	http://dx.doi.org/10.1109/TVCG.2013.161	2916	2925	J	We present the design of a novel framework for the visual integration, comparison, and exploration of correlations in spatial and non-spatial geriatric research data. These data are in general high-dimensional and span both the spatial, volumetric domain - through magnetic resonance imaging volumes - and the non-spatial domain, through variables such as age, gender, or walking speed. The visual analysis framework blends medical imaging, mathematical analysis and interactive visualization techniques, and includes the adaptation of Sparse Partial Least Squares and iterated Tikhonov Regularization algorithms to quantify potential neurologymobility connections. A linked-view design geared specifically at interactive visual comparison integrates spatial and abstract visual representations to enable the users to effectively generate and refine hypotheses in a large, multidimensional, and fragmented space. In addition to the domain analysis and design description, we demonstrate the usefulness of this approach on two case studies. Last, we report the lessons learned through the iterative design and evaluation of our approach, in particular those relevant to the design of comparative visualization of spatial and non-spatial data.	Adrian Maries;Nathan Mays;MeganOlson Hunt;Kim F. Wong;William J. Layton;Robert Boudreau;Caterina Rosano;G. Elisabeta Marai	Dept. of Comput. Sci., Univ. of Pittsburgh, Pittsburgh, PA, USA|c|;;;;;;;	10.1109/TVCG.2009.141;10.1109/VISUAL.2000.885739;10.1109/VAST.2006.261438;10.1109/TVCG.2009.111;10.1109/TVCG.2010.137;10.1109/TVCG.2009.114;10.1109/VISUAL.1991.175815;10.1109/TVCG.2010.162	Design studies, methodology design, task and requirements analysis, integrating spatial and non-spatial data visualization, visual comparison, high-dimensional data, applications of visualization	
SciVis	2013	Interactive Patient-Specific Vascular Modeling with Sweep Surfaces	10.1109/TVCG.2013.169	http://dx.doi.org/10.1109/TVCG.2013.169	2828	2837	J	The precise modeling of vascular structures plays a key role in medical imaging applications, such as diagnosis, therapy planning and blood flow simulations. For the simulation of blood flow in particular, high-precision models are required to produce accurate results. It is thus common practice to perform extensive manual data polishing on vascular segmentations prior to simulation. This usually involves a complex tool chain which is highly impractical for clinical on-site application. To close this gap in current blood flow simulation pipelines, we present a novel technique for interactive vascular modeling which is based on implicit sweep surfaces. Our method is able to generate and correct smooth high-quality models based on geometric centerline descriptions on the fly. It supports complex vascular free-form contours and consequently allows for an accurate and fast modeling of pathological structures such as aneurysms or stenoses. We extend the concept of implicit sweep surfaces to achieve increased robustness and applicability as required in the medical field. We finally compare our method to existing techniques and provide case studies that confirm its contribution to current simulation pipelines.	Jan Kretschmer;Christian Godenschwager;Bernhard Preim;Marc Stamminger	Dept. of Comput. Graphics, FAU Erlangen, Erlangen, Germany|c|;;;	10.1109/VISUAL.2001.964538;10.1109/VISUAL.1994.346339	Surface modeling, vascular visualization, centerline-based modeling	
SciVis	2013	Lighting Design for Globally Illuminated Volume Rendering	10.1109/TVCG.2013.172	http://dx.doi.org/10.1109/TVCG.2013.172	2946	2955	J	With the evolution of graphics hardware, high quality global illumination becomes available for real-time volume rendering. Compared to local illumination, global illumination can produce realistic shading effects which are closer to real world scenes, and has proven useful for enhancing volume data visualization to enable better depth and shape perception. However, setting up optimal lighting could be a nontrivial task for average users. There were lighting design works for volume visualization but they did not consider global light transportation. In this paper, we present a lighting design method for volume visualization employing global illumination. The resulting system takes into account view and transfer-function dependent content of the volume data to automatically generate an optimized three-point lighting environment. Our method fully exploits the back light which is not used by previous volume visualization systems. By also including global shadow and multiple scattering, our lighting system can effectively enhance the depth and shape perception of volumetric features of interest. In addition, we propose an automatic tone mapping operator which recovers visual details from overexposed areas while maintaining sufficient contrast in the dark areas. We show that our method is effective for visualizing volume datasets with complex structures. The structural information is more clearly and correctly presented under the automatically generated light sources.	Yubo Zhang;Kwan-Liu Ma	Univ. of California, Davis, Davis, CA, USA|c|;	10.1109/VISUAL.2005.1532812;10.1109/VISUAL.2004.62;10.1109/TVCG.2011.198;10.1109/TVCG.2012.267;10.1109/VISUAL.2002.1183785	Global illumination, lighting design, volume rendering, tone mapping	
SciVis	2013	ManyVis: Multiple Applications in an Integrated Visualization Environment	10.1109/TVCG.2013.174	http://dx.doi.org/10.1109/TVCG.2013.174	2878	2885	J	As the visualization field matures, an increasing number of general toolkits are developed to cover a broad range of applications. However, no general tool can incorporate the latest capabilities for all possible applications, nor can the user interfaces and workflows be easily adjusted to accommodate all user communities. As a result, users will often chose either substandard solutions presented in familiar, customized tools or assemble a patchwork of individual applications glued through ad-hoc scripts and extensive, manual intervention. Instead, we need the ability to easily and rapidly assemble the best-in-task tools into custom interfaces and workflows to optimally serve any given application community. Unfortunately, creating such meta-applications at the API or SDK level is difficult, time consuming, and often infeasible due to the sheer variety of data models, design philosophies, limits in functionality, and the use of closed commercial systems. In this paper, we present the ManyVis framework which enables custom solutions to be built both rapidly and simply by allowing coordination and communication across existing unrelated applications. ManyVis allows users to combine software tools with complementary characteristics into one virtual application driven by a single, custom-designed interface.	Atul Rungta;Brian Summa;Dogan Demir;Peer-Timo Bremer;Valerio Pascucci	SCI Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;;;	10.1109/TVCG.2007.70552	Visualization environments, integrated applications, macros, linked views	
SciVis	2013	MObjects--A Novel Method for the Visualization and Interactive Exploration of Defects in Industrial XCT Data	10.1109/TVCG.2013.177	http://dx.doi.org/10.1109/TVCG.2013.177	2906	2915	J	This paper describes an advanced visualization method for the analysis of defects in industrial 3D X-Ray Computed Tomography (XCT) data. We present a novel way to explore a high number of individual objects in a dataset, e.g., pores, inclusions, particles, fibers, and cracks demonstrated on the special application area of pore extraction in carbon fiber reinforced polymers (CFRP). After calculating the individual object properties volume, dimensions and shape factors, all objects are clustered into a mean object (MObject). The resulting MObject parameter space can be explored interactively. To do so, we introduce the visualization of mean object sets (MObject Sets) in a radial and a parallel arrangement. Each MObject may be split up into sub-classes by selecting a specific property, e.g., volume or shape factor, and the desired number of classes. Applying this interactive selection iteratively leads to the intended classifications and visualizations of MObjects along the selected analysis path. Hereby the given different scaling factors of the MObjects down the analysis path are visualized through a visual linking approach. Furthermore the representative MObjects are exported as volumetric datasets to serve as input for successive calculations and simulations. In the field of porosity determination in CFRP non-destructive testing practitioners use representative MObjects to improve ultrasonic calibration curves. Representative pores also serve as input for heat conduction simulations in active thermography. For a fast overview of the pore properties in a dataset we propose a local MObjects visualization in combination with a color-coded homogeneity visualization of cells. The advantages of our novel approach are demonstrated using real world CFRP specimens. The results were evaluated through a questionnaire in order to determine the practicality of the MObjects visualization as a supportive tool for domain specialists.	Andreas Reh;Christian Gusenbauer;Johann Kastner;Eduard Gröller;Christoph Heinzl	Univ. of Appl. Sci. Upper Austria, Wels, Austria|c|;;;;	10.1109/TVCG.2012.231;10.1109/VISUAL.1999.809871;10.1109/TVCG.2009.121;10.1109/TVCG.2012.227;10.1109/TVCG.2011.248;10.1109/VISUAL.2005.1532807;10.1109/TVCG.2010.190;10.1109/TVCG.2010.214;10.1109/VISUAL.1993.398859;10.1109/VISUAL.1997.663875	3D X-ray computed tomography, carbon fiber reinforced polymers, porosity, parameter space analysis, MObjects	
SciVis	2013	Noise-Based Volume Rendering for the Visualization of Multivariate Volumetric Data	10.1109/TVCG.2013.180	http://dx.doi.org/10.1109/TVCG.2013.180	2926	2935	J	Analysis of multivariate data is of great importance in many scientific disciplines. However, visualization of 3D spatially-fixed multivariate volumetric data is a very challenging task. In this paper we present a method that allows simultaneous real-time visualization of multivariate data. We redistribute the opacity within a voxel to improve the readability of the color defined by a regular transfer function, and to maintain the see-through capabilities of volume rendering. We use predictable procedural noise - random-phase Gabor noise - to generate a high-frequency redistribution pattern and construct an opacity mapping function, which allows to partition the available space among the displayed data attributes. This mapping function is appropriately filtered to avoid aliasing, while maintaining transparent regions. We show the usefulness of our approach on various data sets and with different example applications. Furthermore, we evaluate our method by comparing it to other visualization techniques in a controlled user study. Overall, the results of our study indicate that users are much more accurate in determining exact data values with our novel 3D volume visualization method. Significantly lower error rates for reading data values and high subjective ranking of our method imply that it has a high chance of being adopted for the purpose of visualization of multivariate 3D data.	Rostislav Khlebnikov;Bernhard Kainz;Markus Steinberger;Dieter Schmalstieg	Graz Univ. of Technol., Graz, Austria|c|;;;	10.1109/VISUAL.1990.146373;10.1109/VISUAL.2003.1250412;10.1109/TVCG.2006.113;10.1109/VISUAL.2005.1532807;10.1109/TVCG.2007.70623;10.1109/TVCG.2012.223;10.1109/VISUAL.2003.1250362	Volume rendering, multi-variate data visualization, multi-volume rendering, scientific visualization	
SciVis	2013	Semi-Automatic Vortex Extraction in 4D PC-MRI Cardiac Blood Flow Data using Line Predicates	10.1109/TVCG.2013.189	http://dx.doi.org/10.1109/TVCG.2013.189	2773	2782	J	Cardiovascular diseases (CVD) are the leading cause of death worldwide. Their initiation and evolution depends strongly on the blood flow characteristics. In recent years, advances in 4D PC-MRI acquisition enable reliable and time-resolved 3D flow measuring, which allows a qualitative and quantitative analysis of the patient-specific hemodynamics. Currently, medical researchers investigate the relation between characteristic flow patterns like vortices and different pathologies. The manual extraction and evaluation is tedious and requires expert knowledge. Standardized, (semi-)automatic and reliable techniques are necessary to make the analysis of 4D PC-MRI applicable for the clinical routine. In this work, we present an approach for the extraction of vortex flow in the aorta and pulmonary artery incorporating line predicates. We provide an extensive comparison of existent vortex extraction methods to determine the most suitable vortex criterion for cardiac blood flow and apply our approach to ten datasets with different pathologies like coarctations, Tetralogy of Fallot and aneurysms. For two cases we provide a detailed discussion how our results are capable to complement existent diagnosis information. To ensure real-time feedback for the domain experts we implement our method completely on the GPU.	Benjamin Köhler;Rocco Gasteiger;Uta Preim;Holger Theisel;Matthias Gutberlet;Bernhard Preim	;;;;;	10.1109/TVCG.2011.260;10.1109/VISUAL.1999.809869;10.1109/TVCG.2010.153;10.1109/VISUAL.1999.809896;10.1109/TVCG.2011.243;10.1109/TVCG.2007.70545;10.1109/VISUAL.2004.99;10.1109/TVCG.2010.173	4D pc-mri, cardiac blood flow, hemodynamics, line predicates, vortex extraction	
SciVis	2013	Uncertainty Quantification in Linear Interpolation for Isosurface Extraction	10.1109/TVCG.2013.208	http://dx.doi.org/10.1109/TVCG.2013.208	2723	2732	J	We present a study of linear interpolation when applied to uncertain data. Linear interpolation is a key step for isosurface extraction algorithms, and the uncertainties in the data lead to non-linear variations in the geometry of the extracted isosurface. We present an approach for deriving the probability density function of a random variable modeling the positional uncertainty in the isosurface extraction. When the uncertainty is quantified by a uniform distribution, our approach provides a closed-form characterization of the mentioned random variable. This allows us to derive, in closed form, the expected value as well as the variance of the level-crossing position. While the former quantity is used for constructing a stable isosurface for uncertain data, the latter is used for visualizing the positional uncertainties in the expected isosurface level crossings on the underlying grid.	Tushar Athawale;Alireza Entezari	Dept. of Comput. & Inf. Sci. & Eng., Univ. of Florida, Gainesville, FL, USA|c|;	10.1109/VISUAL.2005.1532853;10.1109/TVCG.2007.70602;10.1109/VISUAL.1991.175782;10.1109/TVCG.2007.70518;10.1109/TVCG.2012.249;10.1109/VISUAL.1994.346331;10.1109/VISUAL.1996.568116;10.1109/TVCG.2009.194;10.1109/TVCG.2011.203	Uncertainty quantification, linear interpolation, isosurface extraction, marching cubes	
SciVis	2013	Vessel Visualization using Curved Surface Reformation	10.1109/TVCG.2013.215	http://dx.doi.org/10.1109/TVCG.2013.215	2858	2867	J	Visualizations of vascular structures are frequently used in radiological investigations to detect and analyze vascular diseases. Obstructions of the blood flow through a vessel are one of the main interests of physicians, and several methods have been proposed to aid the visual assessment of calcifications on vessel walls. Curved Planar Reformation (CPR) is a wide-spread method that is designed for peripheral arteries which exhibit one dominant direction. To analyze the lumen of arbitrarily oriented vessels, Centerline Reformation (CR) has been proposed. Both methods project the vascular structures into 2D image space in order to reconstruct the vessel lumen. In this paper, we propose Curved Surface Reformation (CSR), a technique that computes the vessel lumen fully in 3D. This offers high-quality interactive visualizations of vessel lumina and does not suffer from problems of earlier methods such as ambiguous visibility cues or premature discretization of centerline data. Our method maintains exact visibility information until the final query of the 3D lumina data. We also present feedback from several domain experts.	Thomas Auzinger;Gabriel Mistelbauer;Ivan Baclija;Rüdiger Schernthaner;Arnold Köchl;Michael Wimmer;Eduard Gröller;Stefan Bruckner	Vienna Univ. of Technol., Vienna, Austria|c|;;;;;;;	10.1109/TVCG.2009.138;10.1109/VISUAL.2004.104;10.1109/VISUAL.2003.1250353;10.1109/VISUAL.2003.1250400;10.1109/TVCG.2006.152;10.1109/TVCG.2009.136;10.1109/VISUAL.2002.1183754;10.1109/TVCG.2011.244;10.1109/VISUAL.2003.1250351;10.1109/TVCG.2006.201;10.1109/VISUAL.2001.964555	Reformation, volume rendering, surface approximation	
SciVis	2013	Visualization of Morse Connection Graphs for Topologically Rich 2D Vector fields	10.1109/TVCG.2013.229	http://dx.doi.org/10.1109/TVCG.2013.229	2763	2772	J	Recent advances in vector field topologymake it possible to compute its multi-scale graph representations for autonomous 2D vector fields in a robust and efficient manner. One of these representations is a Morse Connection Graph (MCG), a directed graph whose nodes correspond to Morse sets, generalizing stationary points and periodic trajectories, and arcs - to trajectories connecting them. While being useful for simple vector fields, the MCG can be hard to comprehend for topologically rich vector fields, containing a large number of features. This paper describes a visual representation of the MCG, inspired by previous work on graph visualization. Our approach aims to preserve the spatial relationships between the MCG arcs and nodes and highlight the coherent behavior of connecting trajectories. Using simulations of ocean flow, we show that it can provide useful information on the flow structure. This paper focuses specifically on MCGs computed for piecewise constant (PC) vector fields. In particular, we describe extensions of the PC framework that make it more flexible and better suited for analysis of data on complex shaped domains with a boundary. We also describe a topology simplification scheme that makes our MCG visualizations less ambiguous. Despite the focus on the PC framework, our approach could also be applied to graph representations or topological skeletons computed using different methods.	Andrzej Szymczak;Levente Sipeki	Colorado Sch. of Mines, Golden, CO, USA|c|;	10.1109/TVCG.2011.233;10.1109/TVCG.2008.135;10.1109/TVCG.2012.209;10.1109/VISUAL.2000.885716	Morse connection graph, vector field topology	
VAST	2013	A Partition-Based Framework for Building and Validating Regression Models	10.1109/TVCG.2013.125	http://dx.doi.org/10.1109/TVCG.2013.125	1962	1971	J	Regression models play a key role in many application domains for analyzing or predicting a quantitative dependent variable based on one or more independent variables. Automated approaches for building regression models are typically limited with respect to incorporating domain knowledge in the process of selecting input variables (also known as feature subset selection). Other limitations include the identification of local structures, transformations, and interactions between variables. The contribution of this paper is a framework for building regression models addressing these limitations. The framework combines a qualitative analysis of relationship structures by visualization and a quantification of relevance for ranking any number of features and pairs of features which may be categorical or continuous. A central aspect is the local approximation of the conditional target distribution by partitioning 1D and 2D feature domains into disjoint regions. This enables a visual investigation of local patterns and largely avoids structural assumptions for the quantitative ranking. We describe how the framework supports different tasks in model building (e.g., validation and comparison), and we present an interactive workflow for feature subset selection. A real-world case study illustrates the step-wise identification of a five-dimensional model for natural gas consumption. We also report feedback from domain experts after two months of deployment in the energy sector, indicating a significant effort reduction for building and improving regression models.	Thomas Mühlbacher;Harald Piringer	;	10.1109/TVCG.2012.219;10.1109/TVCG.2009.128;10.1109/VISUAL.1993.398859;10.1109/VAST.2012.6400486;10.1109/VAST.2011.6102453;10.1109/VAST.2009.5333431;10.1109/TVCG.2010.213;10.1109/TVCG.2012.205;10.1109/VAST.2009.5332628;10.1109/VISUAL.1990.146402;10.1109/VAST.2011.6102450;10.1109/VAST.2008.4677368;10.1109/VAST.2010.5652460;10.1109/TVCG.2011.248;10.1109/INFVIS.2005.1532142;10.1109/VAST.2007.4388999;10.1109/INFVIS.2004.10;10.1109/TVCG.2009.110;10.1109/VAST.2011.6102448;10.1109/INFVIS.2004.3	Regression, model building, visual knowledge discovery, feature selection, data partitioning, guided visualization	
VAST	2013	An Extensible Framework for Provenance in Human Terrain Visual Analytics	10.1109/TVCG.2013.132	http://dx.doi.org/10.1109/TVCG.2013.132	2139	2148	J	We describe and demonstrate an extensible framework that supports data exploration and provenance in the context of Human Terrain Analysis (HTA). Working closely with defence analysts we extract requirements and a list of features that characterise data analysed at the end of the HTA chain. From these, we select an appropriate non-classified data source with analogous features, and model it as a set of facets. We develop ProveML, an XML-based extension of the Open Provenance Model, using these facets and augment it with the structures necessary to record the provenance of data, analytical process and interpretations. Through an iterative process, we develop and refine a prototype system for Human Terrain Visual Analytics (HTVA), and demonstrate means of storing, browsing and recalling analytical provenance and process through analytic bookmarks in ProveML. We show how these bookmarks can be combined to form narratives that link back to the live data. Throughout the process, we demonstrate that through structured workshops, rapid prototyping and structured communication with intelligence analysts we are able to establish requirements, and design schema, techniques and tools that meet the requirements of the intelligence community. We use the needs and reactions of defence analysts in defining and steering the methods to validate the framework.	Rick Walker;Aidan Slingsby;Jason Dykes;Kai Xu 0003;Jo Wood;Phong H. Nguyen;Derek Stephens;B. L. William Wong;Yongjun Zheng	Middlesex Univ., London, UK|c|;;;;;;;;	10.1109/TVCG.2012.252;10.1109/TVCG.2010.191;10.1109/VAST.2007.4388992;10.1109/TVCG.2006.142;10.1109/VAST.2006.261431;10.1109/TVCG.2010.154;10.1109/TVCG.2012.213;10.1109/INFVIS.2000.885086;10.1109/TVCG.2007.70577;10.1109/TVCG.2009.111;10.1109/VAST.2008.4677366;10.1109/VAST.2008.4677365;10.1109/VAST.2007.4388992;10.1109/TVCG.2009.128;10.1109/VAST.2009.5332611;10.1109/TVCG.2010.183;10.1109/VAST.2009.5333919;10.1109/TVCG.2011.209;10.1109/TVCG.2009.139;10.1109/TVCG.2008.175	Human terrain analysis, provenance, framework, bookmarks, narratives	
VAST	2013	Decision Exploration Lab: A Visual Analytics Solution for Decision Management	10.1109/TVCG.2013.146	http://dx.doi.org/10.1109/TVCG.2013.146	1972	1981	J	We present a visual analytics solution designed to address prevalent issues in the area of Operational Decision Management (ODM). In ODM, which has its roots in Artificial Intelligence (Expert Systems) and Management Science, it is increasingly important to align business decisions with business goals. In our work, we consider decision models (executable models of the business domain) as ontologies that describe the business domain, and production rules that describe the business logic of decisions to be made over this ontology. Executing a decision model produces an accumulation of decisions made over time for individual cases. We are interested, first, to get insight in the decision logic and the accumulated facts by themselves. Secondly and more importantly, we want to see how the accumulated facts reveal potential divergences between the reality as captured by the decision model, and the reality as captured by the executed decisions. We illustrate the motivation, added value for visual analytics, and our proposed solution and tooling through a business case from the car insurance industry.	Bertjan Broeksema;Thomas Baudel;Arthur G. Telea;Paolo Crisafulli	IBM France Center for Adv. Studies, Univ. of Groningen, Groningen, France|c|;;;	10.1109/VISUAL.1991.175815;10.1109/VAST.2011.6102463;10.1109/VAST.2010.5652398;10.1109/VAST.2008.4677361;10.1109/VAST.2008.4677363;10.1109/TVCG.2011.185;10.1109/VAST.2011.6102457	Decision support systems, model validation and analysis, multivariate Statistics, program analysis	
VAST	2013	Explainers: Expert Explorations with Crafted Projections	10.1109/TVCG.2013.157	http://dx.doi.org/10.1109/TVCG.2013.157	2042	2051	J	This paper introduces an approach to exploration and discovery in high-dimensional data that incorporates a user's knowledge and questions to craft sets of projection functions meaningful to them. Unlike most prior work that defines projections based on their statistical properties, our approach creates projection functions that align with user-specified annotations. Therefore, the resulting derived dimensions represent concepts defined by the user's examples. These especially crafted projection functions, or explainers, can help find and explain relationships between the data variables and user-designated concepts. They can organize the data according to these concepts. Sets of explainers can provide multiple perspectives on the data. Our approach considers tradeoffs in choosing these projection functions, including their simplicity, expressive power, alignment with prior knowledge, and diversity. We provide techniques for creating collections of explainers. The methods, based on machine learning optimization frameworks, allow exploring the tradeoffs. We demonstrate our approach on model problems and applications in text analysis.	Michael Gleicher	Dept. of Comput. Sci., Univ. of Wisconsin - Madison, Madison, WI, USA|c|	10.1109/VAST.2012.6400487;10.1109/VAST.2012.6400486;10.1109/TVCG.2012.277;10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2004.71;10.1109/TVCG.2012.256;10.1109/VAST.2010.5652392;10.1109/VAST.2012.6400490;10.1109/TVCG.2011.220;10.1109/INFVIS.1998.729559;10.1109/VAST.2011.6102448;10.1109/TVCG.2009.153	High-dimensional spaces, exploration, support vector machines	
VAST	2013	HierarchicalTopics: Visually Exploring Large Text Collections Using Topic Hierarchies	10.1109/TVCG.2013.162	http://dx.doi.org/10.1109/TVCG.2013.162	2002	2011	J	Analyzing large textual collections has become increasingly challenging given the size of the data available and the rate that more data is being generated. Topic-based text summarization methods coupled with interactive visualizations have presented promising approaches to address the challenge of analyzing large text corpora. As the text corpora and vocabulary grow larger, more topics need to be generated in order to capture the meaningful latent themes and nuances in the corpora. However, it is difficult for most of current topic-based visualizations to represent large number of topics without being cluttered or illegible. To facilitate the representation and navigation of a large number of topics, we propose a visual analytics system - HierarchicalTopic (HT). HT integrates a computational algorithm, Topic Rose Tree, with an interactive visual interface. The Topic Rose Tree constructs a topic hierarchy based on a list of topics. The interactive visual interface is designed to present the topic content as well as temporal evolution of topics in a hierarchical fashion. User interactions are provided for users to make changes to the topic hierarchy based on their mental model of the topic space. To qualitatively evaluate HT, we present a case study that showcases how HierarchicalTopics aid expert users in making sense of a large number of topics and discovering interesting patterns of topic groups. We have also conducted a user study to quantitatively evaluate the effect of hierarchical topic structure. The study results reveal that the HT leads to faster identification of large number of relevant topics. We have also solicited user feedback during the experiments and incorporated some suggestions into the current version of HierarchicalTopics.	Wenwen Dou;Li Yu;Xiaoyu Wang;Zhiqiang Ma;William Ribarsky	Univ. of North Carolina at Charlotte, Charlotte, NC, USA|c|;;;;	10.1109/VAST.2010.5652931;10.1109/VAST.2012.6400557;10.1109/TVCG.2011.239;10.1109/VAST.2011.6102461;10.1109/VAST.2012.6400485	Hierarchical topic representation, topic modeling, visual analytics, rose tree	
VAST	2013	Identifying Redundancy and Exposing Provenance in Crowdsourced Data Analysis	10.1109/TVCG.2013.164	http://dx.doi.org/10.1109/TVCG.2013.164	2198	2206	J	We present a system that lets analysts use paid crowd workers to explore data sets and helps analysts interactively examine and build upon workers' insights. We take advantage of the fact that, for many types of data, independent crowd workers can readily perform basic analysis tasks like examining views and generating explanations for trends and patterns. However, workers operating in parallel can often generate redundant explanations. Moreover, because workers have different competencies and domain knowledge, some responses are likely to be more plausible than others. To efficiently utilize the crowd's work, analysts must be able to quickly identify and consolidate redundant responses and determine which explanations are the most plausible. In this paper, we demonstrate several crowd-assisted techniques to help analysts make better use of crowdsourced explanations: (1) We explore crowd-assisted strategies that utilize multiple workers to detect redundant explanations. We introduce color clustering with representative selection-a strategy in which multiple workers cluster explanations and we automatically select the most-representative result-and show that it generates clusterings that are as good as those produced by experts. (2) We capture explanation provenance by introducing highlighting tasks and capturing workers' browsing behavior via an embedded web browser, and refine that provenance information via source-review tasks. We expose this information in an explanation-management interface that allows analysts to interactively filter and sort responses, select the most plausible explanations, and decide which to explore further.	Wesley Willett;Shiry Ginosar;Avital Steinitz;Björn Hartmann;Maneesh Agrawala	INRIA, Sophia-Antipolis, France|c|;;;;	10.1109/TVCG.2007.70577	Crowdsourcing, social data analysis	
VAST	2013	Interactive Exploration of Implicit and Explicit Relations in Faceted Datasets	10.1109/TVCG.2013.167	http://dx.doi.org/10.1109/TVCG.2013.167	2080	2089	J	Many datasets, such as scientific literature collections, contain multiple heterogeneous facets which derive implicit relations, as well as explicit relational references between data items. The exploration of this data is challenging not only because of large data scales but also the complexity of resource structures and semantics. In this paper, we present PivotSlice, an interactive visualization technique which provides efficient faceted browsing as well as flexible capabilities to discover data relationships. With the metaphor of direct manipulation, PivotSlice allows the user to visually and logically construct a series of dynamic queries over the data, based on a multi-focus and multi-scale tabular view that subdivides the entire dataset into several meaningful parts with customized semantics. PivotSlice further facilitates the visual exploration and sensemaking process through features including live search and integration of online data, graphical interaction histories and smoothly animated visual state transitions. We evaluated PivotSlice through a qualitative lab study with university researchers and report the findings from our observations and interviews. We also demonstrate the effectiveness of PivotSlice using a scenario of exploring a repository of information visualization literature.	Jian Zhao;Christopher Collins;Fanny Chevalier;Ravin Balakrishnan	Univ. of Toronto, Toronto, ON, Canada|c|;;;	10.1109/TVCG.2008.137;10.1109/VAST.2011.6102440;10.1109/TVCG.2011.213;10.1109/TVCG.2010.154;10.1109/VAST.2006.261426;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2010.205;10.1109/TVCG.2012.252;10.1109/TVCG.2006.166;10.1109/INFVIS.2000.885086	Faceted browsing, network exploration, dynamic query, interaction, information visualization, visual analytics	
VAST	2013	Interactive Exploration of Surveillance Video through Action Shot Summarization and Trajectory Visualization	10.1109/TVCG.2013.168	http://dx.doi.org/10.1109/TVCG.2013.168	2119	2128	J	We propose a novel video visual analytics system for interactive exploration of surveillance video data. Our approach consists of providing analysts with various views of information related to moving objects in a video. To do this we first extract each object's movement path. We visualize each movement by (a) creating a single action shot image (a still image that coalesces multiple frames), (b) plotting its trajectory in a space-time cube and (c) displaying an overall timeline view of all the movements. The action shots provide a still view of the moving object while the path view presents movement properties such as speed and location. We also provide tools for spatial and temporal filtering based on regions of interest. This allows analysts to filter out large amounts of movement activities while the action shot representation summarizes the content of each movement. We incorporated this multi-part visual representation of moving objects in sViSIT, a tool to facilitate browsing through the video content by interactive querying and retrieval of data. Based on our interaction with security personnel who routinely interact with surveillance video data, we identified some of the most common tasks performed. This resulted in designing a user study to measure time-to-completion of the various tasks. These generally required searching for specific events of interest (targets) in videos. Fourteen different tasks were designed and a total of 120 min of surveillance video were recorded (indoor and outdoor locations recording movements of people and vehicles). The time-to-completion of these tasks were compared against a manual fast forward video browsing guided with movement detection. We demonstrate how our system can facilitate lengthy video exploration and significantly reduce browsing time to find events of interest. Reports from expert users identify positive aspects of our approach which we summarize in our recommendations for future video visual analytics systems.	Amir H. Meghdadi;Pourang Irani	Dept. of Comput. Sci., Univ. of Manitoba, Winnipeg, MB, Canada|c|;	10.1109/INFVIS.2004.27;10.1109/TVCG.2012.222;10.1109/VISUAL.2003.1250401	Video visual analytics, surveillance video, video visualization, video summarization, video browsing and exploration	
VAST	2013	MotionExplorer: Exploratory Search in Human Motion Capture Data Based on Hierarchical Aggregation	10.1109/TVCG.2013.178	http://dx.doi.org/10.1109/TVCG.2013.178	2257	2266	J	We present MotionExplorer, an exploratory search and analysis system for sequences of human motion in large motion capture data collections. This special type of multivariate time series data is relevant in many research fields including medicine, sports and animation. Key tasks in working with motion data include analysis of motion states and transitions, and synthesis of motion vectors by interpolation and combination. In the practice of research and application of human motion data, challenges exist in providing visual summaries and drill-down functionality for handling large motion data collections. We find that this domain can benefit from appropriate visual retrieval and analysis support to handle these tasks in presence of large motion data. To address this need, we developed MotionExplorer together with domain experts as an exploratory search system based on interactive aggregation and visualization of motion states as a basis for data navigation, exploration, and search. Based on an overview-first type visualization, users are able to search for interesting sub-sequences of motion based on a query-by-example metaphor, and explore search results by details on demand. We developed MotionExplorer in close collaboration with the targeted users who are researchers working on human motion synthesis and analysis, including a summative field study. Additionally, we conducted a laboratory design study to substantially improve MotionExplorer towards an intuitive, usable and robust design. MotionExplorer enables the search in human motion capture data with only a few mouse clicks. The researchers unanimously confirm that the system can efficiently support their work.	Jürgen Bernard;Nils Wilhelm;Björn Krüger;Thorsten May;Tobias Schreck;Jörn Kohlhammer	Fraunhofer Inst. for Comput. Graphics Res. Darmstadt, Darmstadt, Germany|c|;;;;;	10.1109/VISUAL.1999.809865;10.1109/VAST.2008.4677350;10.1109/TVCG.2006.120;10.1109/TVCG.2011.181;10.1109/TVCG.2011.188	Visual analytics, exploratory search, multivariate time series, motion capture data, data aggregation, cluster glyph	
VAST	2013	Open-Box Spectral Clustering: Applications to Medical Image Analysis	10.1109/TVCG.2013.181	http://dx.doi.org/10.1109/TVCG.2013.181	2100	2108	J	Spectral clustering is a powerful and versatile technique, whose broad range of applications includes 3D image analysis. However, its practical use often involves a tedious and time-consuming process of tuning parameters and making application-specific choices. In the absence of training data with labeled clusters, help from a human analyst is required to decide the number of clusters, to determine whether hierarchical clustering is needed, and to define the appropriate distance measures, parameters of the underlying graph, and type of graph Laplacian. We propose to simplify this process via an open-box approach, in which an interactive system visualizes the involved mathematical quantities, suggests parameter values, and provides immediate feedback to support the required decisions. Our framework focuses on applications in 3D image analysis, and links the abstract high-dimensional feature space used in spectral clustering to the three-dimensional data space. This provides a better understanding of the technique, and helps the analyst predict how well specific parameter settings will generalize to similar tasks. In addition, our system supports filtering outliers and labeling the final clusters in such a way that user actions can be recorded and transferred to different data in which the same structures are to be found. Our system supports a wide range of inputs, including triangular meshes, regular grids, and point clouds. We use our system to develop segmentation protocols in chest CT and brain MRI that are then successfully applied to other datasets in an automated manner.	Thomas Schultz 0001;Gordon L. Kindlmann	Univ. of Bonn, Bonn, Germany|c|;	10.1109/VISUAL.2005.1532820;10.1109/VAST.2010.5652926;10.1109/VISUAL.2000.885740;10.1109/VAST.2012.6400488;10.1109/TVCG.2009.141;10.1109/TVCG.2009.112;10.1109/TVCG.2009.177;10.1109/TVCG.2010.199;10.1109/TVCG.2009.199;10.1109/TVCG.2011.248;10.1109/TVCG.2011.253	Image segmentation, spectral clustering, high-dimensional embeddings, linked views, programming with example	
VAST	2013	ScatterBlogs2: Real-Time Monitoring of Microblog Messages through User-Guided filtering	10.1109/TVCG.2013.186	http://dx.doi.org/10.1109/TVCG.2013.186	2022	2031	J	The number of microblog posts published daily has reached a level that hampers the effective retrieval of relevant messages, and the amount of information conveyed through services such as Twitter is still increasing. Analysts require new methods for monitoring their topic of interest, dealing with the data volume and its dynamic nature. It is of particular importance to provide situational awareness for decision making in time-critical tasks. Current tools for monitoring microblogs typically filter messages based on user-defined keyword queries and metadata restrictions. Used on their own, such methods can have drawbacks with respect to filter accuracy and adaptability to changes in trends and topic structure. We suggest ScatterBlogs2, a new approach to let analysts build task-tailored message filters in an interactive and visual manner based on recorded messages of well-understood previous events. These message filters include supervised classification and query creation backed by the statistical distribution of terms and their co-occurrences. The created filter methods can be orchestrated and adapted afterwards for interactive, visual real-time monitoring and analysis of microblog feeds. We demonstrate the feasibility of our approach for analyzing the Twitter stream in emergency management scenarios.	Harald Bosch;Dennis Thom;Florian Heimerl;Edwin Puttmann;Steffen Koch;Robert Krüger;Michael Wörner;Thomas Ertl	Visualization & Interactive Syst., Univ. of Stuttgart, Stuttgart, Germany|c|;;;;;;;	10.1109/VISUAL.2005.1532781;10.1109/VAST.2012.6400492;10.1109/VAST.2012.6400557;10.1109/TVCG.2012.291;10.1109/TVCG.2012.277;10.1109/VAST.2012.6400485;10.1109/VAST.2007.4389013;10.1109/VAST.2007.4389006;10.1109/VAST.2011.6102456;10.1109/TVCG.2008.175	Microblog analysis, Twitter, text analytics, social media monitoring, live monitoring, visual analytics, information visualization, filter construction, query construction, text classification	
VAST	2013	Semantics of Directly Manipulating Spatializations	10.1109/TVCG.2013.188	http://dx.doi.org/10.1109/TVCG.2013.188	2052	2059	J	When high-dimensional data is visualized in a 2D plane by using parametric projection algorithms, users may wish to manipulate the layout of the data points to better reflect their domain knowledge or to explore alternative structures. However, few users are well-versed in the algorithms behind the visualizations, making parameter tweaking more of a guessing game than a series of decisive interactions. Translating user interactions into algorithmic input is a key component of Visual to Parametric Interaction (V2PI) [13]. Instead of adjusting parameters, users directly move data points on the screen, which then updates the underlying statistical model. However, we have found that some data points that are not moved by the user are just as important in the interactions as the data points that are moved. Users frequently move some data points with respect to some other 'unmoved' data points that they consider as spatially contextual. However, in current V2PI interactions, these points are not explicitly identified when directly manipulating the moved points. We design a richer set of interactions that makes this context more explicit, and a new algorithm and sophisticated weighting scheme that incorporates the importance of these unmoved data points into V2PI.	Xinran Hu;Lauren Bradel;Dipayan Maiti;Leanna House;Chris North;Scotland Leman	;;;;;	10.1109/VAST.2011.6102449;10.1109/INFVIS.1995.528686;10.1109/TVCG.2012.260;10.1109/VAST.2012.6400486;10.1109/VAST.2008.4677358	Visual to parametric interaction, visual analytics, statistical models	
VAST	2013	SketchPadN-D: WYDIWYG Sculpting and Editing in High-Dimensional Space	10.1109/TVCG.2013.190	http://dx.doi.org/10.1109/TVCG.2013.190	2060	2069	J	High-dimensional data visualization has been attracting much attention. To fully test related software and algorithms, researchers require a diverse pool of data with known and desired features. Test data do not always provide this, or only partially. Here we propose the paradigm WYDIWYGS (What You Draw Is What You Get). Its embodiment, SketchPadND, is a tool that allows users to generate high-dimensional data in the same interface they also use for visualization. This provides for an immersive and direct data generation activity, and furthermore it also enables users to interactively edit and clean existing high-dimensional data from possible artifacts. SketchPadND offers two visualization paradigms, one based on parallel coordinates and the other based on a relatively new framework using an N-D polygon to navigate in high-dimensional space. The first interface allows users to draw arbitrary profiles of probability density functions along each dimension axis and sketch shapes for data density and connections between adjacent dimensions. The second interface embraces the idea of sculpting. Users can carve data at arbitrary orientations and refine them wherever necessary. This guarantees that the data generated is truly high-dimensional. We demonstrate our tool's usefulness in real data visualization scenarios.	Bing Wang;Puripant Ruchikachorn;Klaus Mueller	Comput. Sci. Dept., Stony Brook Univ., Stony Brook, NY, USA|c|;;	10.1109/TVCG.2011.237;10.1109/VAST.2012.6400489	Synthetic data generation, data editing, data acquisition and management, multivariate data, high-dimensional data, interaction, user interface, parallel coordinates, scatterplot, N-D navigation, multiple views	
VAST	2013	Space Transformation for Understanding Group Movement	10.1109/TVCG.2013.193	http://dx.doi.org/10.1109/TVCG.2013.193	2169	2178	J	We suggest a methodology for analyzing movement behaviors of individuals moving in a group. Group movement is analyzed at two levels of granularity: the group as a whole and the individuals it comprises. For analyzing the relative positions and movements of the individuals with respect to the rest of the group, we apply space transformation, in which the trajectories of the individuals are converted from geographical space to an abstract 'group space'. The group space reference system is defined by both the position of the group center, which is taken as the coordinate origin, and the direction of the group's movement. Based on the individuals' positions mapped onto the group space, we can compare the behaviors of different individuals, determine their roles and/or ranks within the groups, and, possibly, understand how group movement is organized. The utility of the methodology has been evaluated by applying it to a set of real data concerning movements of wild social animals and discussing the results with experts in animal ethology.	Natalia V. Andrienko;Gennady L. Andrienko;Louise Barrett;Marcus Dostie;S. Peter Henzi	;;;;	10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2004.27	Visual analytics, movement data, collective movement	
VAST	2013	Space-Time Visual Analytics of Eye-Tracking Data for Dynamic Stimuli	10.1109/TVCG.2013.194	http://dx.doi.org/10.1109/TVCG.2013.194	2129	2138	J	We introduce a visual analytics method to analyze eye movement data recorded for dynamic stimuli such as video or animated graphics. The focus lies on the analysis of data of several viewers to identify trends in the general viewing behavior, including time sequences of attentional synchrony and objects with strong attentional focus. By using a space-time cube visualization in combination with clustering, the dynamic stimuli and associated eye gazes can be analyzed in a static 3D representation. Shot-based, spatiotemporal clustering of the data generates potential areas of interest that can be filtered interactively. We also facilitate data drill-down: the gaze points are shown with density-based color mapping and individual scan paths as lines in the space-time cube. The analytical process is supported by multiple coordinated views that allow the user to focus on different aspects of spatial and temporal information in eye gaze data. Common eye-tracking visualization techniques are extended to incorporate the spatiotemporal characteristics of the data. For example, heat maps are extended to motion-compensated heat maps and trajectories of scan paths are included in the space-time visualization. Our visual analytics approach is assessed in a qualitative users study with expert users, which showed the usefulness of the approach and uncovered that the experts applied different analysis strategies supported by the system.	Kuno Kurzhals;Daniel Weiskopf	Visualization Res. Center (VISUS), Univ. of Stuttgart, Stuttgart, Germany|c|;	10.1109/TVCG.2010.149;10.1109/TVCG.2011.193;10.1109/TVCG.2012.276;10.1109/TVCG.2006.194	Eye-tracking, space-time cube, dynamic areas of interest, spatiotemporal clustering, motion-compensated heat map	
VAST	2013	Supporting Awareness through Collaborative Brushing and Linking of Tabular Data	10.1109/TVCG.2013.197	http://dx.doi.org/10.1109/TVCG.2013.197	2189	2197	J	Maintaining an awareness of collaborators' actions is critical during collaborative work, including during collaborative visualization activities. Particularly when collaborators are located at a distance, it is important to know what everyone is working on in order to avoid duplication of effort, share relevant results in a timely manner and build upon each other's results. Can a person's brushing actions provide an indication of their queries and interests in a data set? Can these actions be revealed to a collaborator without substantially disrupting their own independent work? We designed a study to answer these questions in the context of distributed collaborative visualization of tabular data. Participants in our study worked independently to answer questions about a tabular data set, while simultaneously viewing brushing actions of a fictitious collaborator, shown directly within a shared workspace. We compared three methods of presenting the collaborator's actions: brushing & linking (i.e. highlighting exactly what the collaborator would see), selection (i.e. showing only a selected item), and persistent selection (i.e. showing only selected items but having them persist for some time). Our results demonstrated that persistent selection enabled some awareness of the collaborator's activities while causing minimal interference with independent work. Other techniques were less effective at providing awareness, and brushing & linking caused substantial interference. These findings suggest promise for the idea of exploiting natural brushing actions to provide awareness in collaborative work.	Amir Hossein Hajizadeh;Melanie Tory;Rock Leung	Univ. of Victoria, Victoria, BC, Canada|c|;;	10.1109/TVCG.2011.196;10.1109/TVCG.2007.70541;10.1109/TVCG.2011.185;10.1109/VAST.2010.5652880;10.1109/INFVIS.2003.1249020;10.1109/VAST.2007.4389011;10.1109/VAST.2011.6102447	Collaboration, awareness, attentionally ambient visualization, brushing and linking, linked views, user study	
VAST	2013	Supporting the Visual Analysis of Dynamic Networks by Clustering associated Temporal Attributes	10.1109/TVCG.2013.198	http://dx.doi.org/10.1109/TVCG.2013.198	2267	2276	J	The visual analysis of dynamic networks is a challenging task. In this paper, we introduce a new approach supporting the discovery of substructures sharing a similar trend over time by combining computation, visualization and interaction. With existing techniques, their discovery would be a tedious endeavor because of the number of nodes, edges as well as time points to be compared. First, on the basis of the supergraph, we therefore group nodes and edges according to their associated attributes that are changing over time. Second, the supergraph is visualized to provide an overview of the groups of nodes and edges with similar behavior over time in terms of their associated attributes. Third, we provide specific interactions to explore and refine the temporal clustering, allowing the user to further steer the analysis of the dynamic network. We demonstrate our approach by the visual analysis of a large wireless mesh network.	Steffen Hadlak;Heidrun Schumann;Clemens H. Cap;Till Wollenberg	Univ. of Rostock, Rostock, Germany|c|;;;	10.1109/INFVIS.2005.1532151;10.1109/VAST.2010.5652530;10.1109/INFVIS.2004.18;10.1109/TVCG.2011.226;10.1109/TVCG.2011.213;10.1109/TVCG.2006.193;10.1109/VAST.2012.6400493;10.1109/INFVIS.1999.801851;10.1109/TVCG.2007.70529;10.1109/INFVIS.2002.1173160	Dynamic networks, visualization, supergraph clustering	
VAST	2013	Temporal Event Sequence Simplification	10.1109/TVCG.2013.200	http://dx.doi.org/10.1109/TVCG.2013.200	2227	2236	J	Electronic Health Records (EHRs) have emerged as a cost-effective data source for conducting medical research. The difficulty in using EHRs for research purposes, however, is that both patient selection and record analysis must be conducted across very large, and typically very noisy datasets. Our previous work introduced EventFlow, a visualization tool that transforms an entire dataset of temporal event records into an aggregated display, allowing researchers to analyze population-level patterns and trends. As datasets become larger and more varied, however, it becomes increasingly difficult to provide a succinct, summarizing display. This paper presents a series of user-driven data simplifications that allow researchers to pare event records down to their core elements. Furthermore, we present a novel metric for measuring visual complexity, and a language for codifying disjoint strategies into an overarching simplification framework. These simplifications were used by real-world researchers to gain new and valuable insights from initially overwhelming datasets.	Megan Monroe;Rongjian Lan;Hanseung Lee;Catherine Plaisant;Ben Shneiderman	Univ. of Maryland, College Park, MD, USA|c|;;;;	10.1109/TVCG.2009.117;10.1109/TVCG.2012.213;10.1109/VAST.2010.5652890	Event sequences, simplification, electronic heath records, temporal query	
VAST	2013	The Impact of Physical Navigation on Spatial Organization for Sensemaking	10.1109/TVCG.2013.205	http://dx.doi.org/10.1109/TVCG.2013.205	2207	2216	J	Spatial organization has been proposed as a compelling approach to externalizing the sensemaking process. However, there are two ways in which space can be provided to the user: by creating a physical workspace that the user can interact with directly, such as can be provided by a large, high-resolution display, or through the use of a virtual workspace that the user navigates using virtual navigation techniques such as zoom and pan. In this study we explicitly examined the use of spatial sensemaking techniques within these two environments. The results demonstrate that these two approaches to providing sensemaking space are not equivalent, and that the greater embodiment afforded by the physical workspace changes how the space is perceived and used, leading to increased externalization of the sensemaking process.	Christopher Andrews;Chris North	Middlebury Coll., USA|c|;	10.1109/VAST.2012.6400559;10.1109/VAST.2008.4677358;10.1109/VAST.2009.5333878	Sensemaking, visual analytics, physical navigation, embodiment, large and high-resolution displays	
VAST	2013	TimeBench: A Data Model and Software Library for Visual Analytics of Time-Oriented Data	10.1109/TVCG.2013.206	http://dx.doi.org/10.1109/TVCG.2013.206	2247	2256	J	Time-oriented data play an essential role in many Visual Analytics scenarios such as extracting medical insights from collections of electronic health records or identifying emerging problems and vulnerabilities in network traffic. However, many software libraries for Visual Analytics treat time as a flat numerical data type and insufficiently tackle the complexity of the time domain such as calendar granularities and intervals. Therefore, developers of advanced Visual Analytics designs need to implement temporal foundations in their application code over and over again. We present TimeBench, a software library that provides foundational data structures and algorithms for time-oriented data in Visual Analytics. Its expressiveness and developer accessibility have been evaluated through application examples demonstrating a variety of challenges with time-oriented data and long-term developer studies conducted in the scope of research and student projects.	Alexander Rind;Tim Lammarsch;Wolfgang Aigner;Bilal Alsallakh;Silvia Miksch	Inst. of Software Technol. & Interactive Syst., Vienna Univ. of Technol., Vienna, Austria|c|;;;;	10.1109/TVCG.2009.174;10.1109/INFVIS.2004.12;10.1109/VAST.2011.6102446;10.1109/VAST.2006.261428;10.1109/INFVIS.2000.885086;10.1109/TVCG.2010.144;10.1109/TVCG.2006.178;10.1109/INFVIS.2004.64;10.1109/TVCG.2013.222;10.1109/INFVIS.2002.1173155;10.1109/TVCG.2011.185;10.1109/TVCG.2010.126;10.1109/INFVIS.1997.636792	Visual Analytics, information visualization, toolkits, software infrastructure, time, temporal data	
VAST	2013	Transformation of an Uncertain Video Search Pipeline to a Sketch-Based Visual Analytics Loop	10.1109/TVCG.2013.207	http://dx.doi.org/10.1109/TVCG.2013.207	2109	2118	J	Traditional sketch-based image or video search systems rely on machine learning concepts as their core technology. However, in many applications, machine learning alone is impractical since videos may not be semantically annotated sufficiently, there may be a lack of suitable training data, and the search requirements of the user may frequently change for different tasks. In this work, we develop a visual analytics systems that overcomes the shortcomings of the traditional approach. We make use of a sketch-based interface to enable users to specify search requirement in a flexible manner without depending on semantic annotation. We employ active machine learning to train different analytical models for different types of search requirements. We use visualization to facilitate knowledge discovery at the different stages of visual analytics. This includes visualizing the parameter space of the trained model, visualizing the search space to support interactive browsing, visualizing candidature search results to support rapid interaction for active learning while minimizing watching videos, and visualizing aggregated information of the search results. We demonstrate the system for searching spatiotemporal attributes from sports video to identify key instances of the team and player performance.	Philip A. Legg;David H. S. Chung;Matthew L. Parry;Rhodri Bown;Mark W. Jones;Iwan W. Griffiths;Min Chen	Dept. of Comput. Sci., Swansea Univ., Swansea, UK|c|;;;;;;	10.1109/TVCG.2006.138;10.1109/VISUAL.2003.1250401;10.1109/VAST.2009.5332628;10.1109/TVCG.2010.184;10.1109/VAST.2007.4389001;10.1109/TVCG.2008.131;10.1109/INFVIS.1998.729559;10.1109/TVCG.2006.194;10.1109/TVCG.2011.208	Visual knowledge discovery, data clustering, machine learning, multimedia visualization	
VAST	2013	Using Interactive Visual Reasoning to Support Sense-Making: Implications for Design	10.1109/TVCG.2013.211	http://dx.doi.org/10.1109/TVCG.2013.211	2217	2226	J	This research aims to develop design guidelines for systems that support investigators and analysts in the exploration and assembly of evidence and inferences. We focus here on the problem of identifying candidate 'influencers' within a community of practice. To better understand this problem and its related cognitive and interaction needs, we conducted a user study using a system called INVISQUE (INteractive Visual Search and QUery Environment) loaded with content from the ACM Digital Library. INVISQUE supports search and manipulation of results over a freeform infinite 'canvas'. The study focuses on the representations user create and their reasoning process. It also draws on some pre-established theories and frameworks related to sense-making and cognitive work in general, which we apply as a 'theoretical lenses' to consider findings and articulate solutions. Analysing the user-study data in the light of these provides some understanding of how the high-level problem of identifying key players within a domain can translate into lower-level questions and interactions. This, in turn, has informed our understanding of representation and functionality needs at a level of description which abstracts away from the specifics of the problem at hand to the class of problems of interest. We consider the study outcomes from the perspective of implications for design.	Neesha Kodagoda;Simon Attfield;B. L. William Wong;Chris Rooney;Sharmin (Tinni) Choudhury	Middlesex Univ., London, UK|c|;;;;	10.1109/VAST.2009.5333020;10.1109/VAST.2007.4389006;10.1109/TVCG.2012.252	Visual analytics, sense-making, dataframe mode, evaluation, reasoning, analysis, interaction, interface design	
VAST	2013	UTOPIAN: User-Driven Topic Modeling Based on Interactive Nonnegative Matrix Factorization	10.1109/TVCG.2013.212	http://dx.doi.org/10.1109/TVCG.2013.212	1992	2001	J	Topic modeling has been widely used for analyzing text document collections. Recently, there have been significant advancements in various topic modeling techniques, particularly in the form of probabilistic graphical modeling. State-of-the-art techniques such as Latent Dirichlet Allocation (LDA) have been successfully applied in visual text analytics. However, most of the widely-used methods based on probabilistic modeling have drawbacks in terms of consistency from multiple runs and empirical convergence. Furthermore, due to the complicatedness in the formulation and the algorithm, LDA cannot easily incorporate various types of user feedback. To tackle this problem, we propose a reliable and flexible visual analytics system for topic modeling called UTOPIAN (User-driven Topic modeling based on Interactive Nonnegative Matrix Factorization). Centered around its semi-supervised formulation, UTOPIAN enables users to interact with the topic modeling method and steer the result in a user-driven manner. We demonstrate the capability of UTOPIAN via several usage scenarios with real-world document corpuses such as InfoVis/VAST paper data set and product review data sets.	Jaegul Choo;Changhyun Lee;Chandan K. Reddy;Haesun Park	Georgia Inst. of Technol., Atlanta, GA, USA|c|;;;	10.1109/TVCG.2012.258;10.1109/VAST.2009.5332629;10.1109/TVCG.2011.239;10.1109/VAST.2011.6102461;10.1109/VAST.2012.6400485;10.1109/VAST.2007.4388999;10.1109/VAST.2007.4389006;10.1109/TVCG.2008.138;10.1109/VAST.2010.5652443	Latent Dirichlet allocation, nonnegative matrix factorization, topic modeling, visual analytics, interactive clustering, text analytics  	
VAST	2013	VAICo: Visual Analysis for Image Comparison	10.1109/TVCG.2013.213	http://dx.doi.org/10.1109/TVCG.2013.213	2090	2099	J	Scientists, engineers, and analysts are confronted with ever larger and more complex sets of data, whose analysis poses special challenges. In many situations it is necessary to compare two or more datasets. Hence there is a need for comparative visualization tools to help analyze differences or similarities among datasets. In this paper an approach for comparative visualization for sets of images is presented. Well-established techniques for comparing images frequently place them side-by-side. A major drawback of such approaches is that they do not scale well. Other image comparison methods encode differences in images by abstract parameters like color. In this case information about the underlying image data gets lost. This paper introduces a new method for visualizing differences and similarities in large sets of images which preserves contextual information, but also allows the detailed analysis of subtle variations. Our approach identifies local changes and applies cluster analysis techniques to embed them in a hierarchy. The results of this process are then presented in an interactive web application which allows users to rapidly explore the space of differences and drill-down on particular features. We demonstrate the flexibility of our approach by applying it to multiple distinct domains.	Johanna Schmidt;Eduard Gröller;Stefan Bruckner	Vienna Univ. of Technol., Vienna, Austria|c|;;	10.1109/TVCG.2007.70584;10.1109/TVCG.2007.70623;10.1109/VAST.2012.6400555;10.1109/TVCG.2010.190;10.1109/VISUAL.1999.809871;10.1109/VISUAL.1999.809873;10.1109/TVCG.2011.248;10.1109/VISUAL.2002.1183790	Comparative visualization, focus+context visualization, image set comparison	
VAST	2013	Vis4Heritage: Visual Analytics Approach on Grotto Wall Painting Degradations	10.1109/TVCG.2013.219	http://dx.doi.org/10.1109/TVCG.2013.219	1982	1991	J	For preserving the grotto wall paintings and protecting these historic cultural icons from the damage and deterioration in nature environment, a visual analytics framework and a set of tools are proposed for the discovery of degradation patterns. In comparison with the traditional analysis methods that used restricted scales, our method provides users with multi-scale analytic support to study the problems on site, cave, wall and particular degradation area scales, through the application of multidimensional visualization techniques. Several case studies have been carried out using real-world wall painting data collected from a renowned World Heritage site, to verify the usability and effectiveness of the proposed method. User studies and expert reviews were also conducted through by domain experts ranging from scientists such as microenvironment researchers, archivists, geologists, chemists, to practitioners such as conservators, restorers and curators.	Jiawan Zhang;Kai Kang;Dajian Liu;Ye Yuan;E. Yanli	Sch. of Comput. Software & Inf. Technol., Tianjin Univ., Tianjin, China|c|;;;;	10.1109/TVCG.2011.239;10.1109/INFVIS.2004.1;10.1109/TVCG.2008.173;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2006.147;10.1109/TVCG.2012.244;10.1109/VAST.2007.4389013;10.1109/TVCG.2008.153;10.1109/INFVIS.2000.885098	Cultural heritage, wall paintings, degradation, visual analytics	
VAST	2013	Visual Analysis of Higher-Order Conjunctive Relationships in Multidimensional Data Using a Hypergraph Query System	10.1109/TVCG.2013.220	http://dx.doi.org/10.1109/TVCG.2013.220	2070	2079	J	Visual exploration and analysis of multidimensional data becomes increasingly difficult with increasing dimensionality. We want to understand the relationships between dimensions of data, but lack flexible techniques for exploration beyond low-order relationships. Current visual techniques for multidimensional data analysis focus on binary conjunctive relationships between dimensions. Recent techniques, such as cross-filtering on an attribute relationship graph, facilitate the exploration of some higher-order conjunctive relationships, but require a great deal of care and precision to do so effectively. This paper provides a detailed analysis of the expressive power of existing visual querying systems and describes a more flexible approach in which users can explore n-ary conjunctive inter- and intra- dimensional relationships by interactively constructing queries as visual hypergraphs. In a hypergraph query, nodes represent subsets of values and hyperedges represent conjunctive relationships. Analysts can dynamically build and modify the query using sequences of simple interactions. The hypergraph serves not only as a query specification, but also as a compact visual representation of the interactive state. Using examples from several domains, focusing on the digital humanities, we describe the design considerations for developing the querying system and incorporating it into visual analysis tools. We analyze query expressiveness with regard to the kinds of questions it can and cannot pose, and describe how it simultaneously expands the expressiveness of and is complemented by cross-filtering.	Rachel Shadoan;Chris Weaver	Akashic Labs. LLC, USA|c|;	10.1109/TVCG.2006.160;10.1109/INFVIS.2004.12;10.1109/VAST.2011.6102440;10.1109/VAST.2007.4389006;10.1109/TVCG.2006.166;10.1109/VAST.2010.5652520	Graph search, graph query language, multidimensional data, attribute relationship graphs, multivariate data analysis, higher-order conjunctive queries, visual query language, digital humanities	
VAST	2013	Visual Analysis of Topic Competition on Social Media	10.1109/TVCG.2013.221	http://dx.doi.org/10.1109/TVCG.2013.221	2012	2021	J	How do various topics compete for public attention when they are spreading on social media? What roles do opinion leaders play in the rise and fall of competitiveness of various topics? In this study, we propose an expanded topic competition model to characterize the competition for public attention on multiple topics promoted by various opinion leaders on social media. To allow an intuitive understanding of the estimated measures, we present a timeline visualization through a metaphoric interpretation of the results. The visual design features both topical and social aspects of the information diffusion process by compositing ThemeRiver with storyline style visualization. ThemeRiver shows the increase and decrease of competitiveness of each topic. Opinion leaders are drawn as threads that converge or diverge with regard to their roles in influencing the public agenda change over time. To validate the effectiveness of the visual analysis techniques, we report the insights gained on two collections of Tweets: the 2012 United States presidential election and the Occupy Wall Street movement.	Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Jonathan J. H. Zhu;Huamin Qu	Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;;	10.1109/TVCG.2008.166;10.1109/TVCG.2011.239;10.1109/TVCG.2012.253;10.1109/TVCG.2012.225;10.1109/VAST.2009.5333437;10.1109/TVCG.2010.194;10.1109/TVCG.2012.291;10.1109/VAST.2010.5652931;10.1109/TVCG.2013.196;10.1109/INFVIS.2001.963273;10.1109/TVCG.2012.212;10.1109/VAST.2010.5652922;10.1109/TVCG.2010.129;10.1109/INFVIS.1999.801851	Social media visuaization, topic competition, information diffusion, information propagation, agenda-setting	
VAST	2013	Visual Analytics for Model Selection in Time Series Analysis	10.1109/TVCG.2013.222	http://dx.doi.org/10.1109/TVCG.2013.222	2237	2246	J	Model selection in time series analysis is a challenging task for domain experts in many application areas such as epidemiology, economy, or environmental sciences. The methodology used for this task demands a close combination of human judgement and automated computation. However, statistical software tools do not adequately support this combination through interactive visual interfaces. We propose a Visual Analytics process to guide domain experts in this task. For this purpose, we developed the TiMoVA prototype that implements this process based on user stories and iterative expert feedback on user experience. The prototype was evaluated by usage scenarios with an example dataset from epidemiology and interviews with two external domain experts in statistics. The insights from the experts' feedback and the usage scenarios show that TiMoVA is able to support domain experts in model selection tasks through interactive visual interfaces with short feedback cycles.	Markus Bögl;Wolfgang Aigner;Peter Filzmoser;Tim Lammarsch;Silvia Miksch;Alexander Rind	Vienna Univ. of Technol., Vienna, Austria|c|;;;;;	10.1109/TVCG.2013.206;10.1109/TVCG.2012.213;10.1109/TVCG.2007.70539	Visual analytics, model selection, visual interaction, time series analysis, coordinated & multiple views	
VAST	2013	Visual Analytics for Multimodal Social Network Analysis: A Design Study with Social Scientists	10.1109/TVCG.2013.223	http://dx.doi.org/10.1109/TVCG.2013.223	2032	2041	J	Social network analysis (SNA) is becoming increasingly concerned not only with actors and their relations, but also with distinguishing between different types of such entities. For example, social scientists may want to investigate asymmetric relations in organizations with strict chains of command, or incorporate non-actors such as conferences and projects when analyzing coauthorship patterns. Multimodal social networks are those where actors and relations belong to different types, or modes, and multimodal social network analysis (mSNA) is accordingly SNA for such networks. In this paper, we present a design study that we conducted with several social scientist collaborators on how to support mSNA using visual analytics tools. Based on an openended, formative design process, we devised a visual representation called parallel node-link bands (PNLBs) that splits modes into separate bands and renders connections between adjacent ones, similar to the list view in Jigsaw. We then used the tool in a qualitative evaluation involving five social scientists whose feedback informed a second design phase that incorporated additional network metrics. Finally, we conducted a second qualitative evaluation with our social scientist collaborators that provided further insights on the utility of the PNLBs representation and the potential of visual analytics for mSNA.	Sohaib Ghani;Bum Chul Kwon;Seungyoon Lee;Ji Soo Yi;Niklas Elmqvist	Sch. of Electr. & Comput. Eng., Purdue Univ., West Lafayette, IN, USA|c|;;;;	10.1109/TVCG.2011.247;10.1109/VAST.2011.6102440;10.1109/TVCG.2012.213;10.1109/TVCG.2011.201;10.1109/VAST.2007.4389006;10.1109/TVCG.2007.70521;10.1109/INFVIS.2005.1532142;10.1109/VISUAL.1990.146402;10.1109/TVCG.2007.70535;10.1109/INFVIS.2002.1173155;10.1109/VAST.2006.261430;10.1109/TVCG.2006.166;10.1109/TVCG.2011.209	Design study, user-centered design, node-link diagrams, multimodal graphs, interaction, qualitative evaluation	
VAST	2013	Visual Analytics for Spatial Clustering: Using a Heuristic Approach for Guided Exploration	10.1109/TVCG.2013.224	http://dx.doi.org/10.1109/TVCG.2013.224	2179	2188	J	We propose a novel approach of distance-based spatial clustering and contribute a heuristic computation of input parameters for guiding users in the search of interesting cluster constellations. We thereby combine computational geometry with interactive visualization into one coherent framework. Our approach entails displaying the results of the heuristics to users, as shown in Figure 1, providing a setting from which to start the exploration and data analysis. Addition interaction capabilities are available containing visual feedback for exploring further clustering options and is able to cope with noise in the data. We evaluate, and show the benefits of our approach on a sophisticated artificial dataset and demonstrate its usefulness on real-world data.	Eli Packer;Peter Bak;Mikko Nikkilä;Valentin Polishchuk;Harold J. Ship	IBM Res. Haifa Lab., Haifa, Israel|c|;;;;	10.1109/VAST.2011.6102449;10.1109/INFVIS.2003.1249015;10.1109/VAST.2012.6400486;10.1109/TVCG.2009.122;10.1109/VAST.2010.5652443;10.1109/TVCG.2011.186	Heuristic-based spatial clustering, interactive visual clustering, k-order a-(alpha)-shapes	
VAST	2013	Visual Exploration of Big Spatio-Temporal Urban Data: A Study of New York City Taxi Trips	10.1109/TVCG.2013.226	http://dx.doi.org/10.1109/TVCG.2013.226	2149	2158	J	As increasing volumes of urban data are captured and become available, new opportunities arise for data-driven analysis that can lead to improvements in the lives of citizens through evidence-based decision making and policies. In this paper, we focus on a particularly important urban data set: taxi trips. Taxis are valuable sensors and information associated with taxi trips can provide unprecedented insight into many different aspects of city life, from economic activity and human behavior to mobility patterns. But analyzing these data presents many challenges. The data are complex, containing geographical and temporal components in addition to multiple variables associated with each trip. Consequently, it is hard to specify exploratory queries and to perform comparative analyses (e.g., compare different regions over time). This problem is compounded due to the size of the data-there are on average 500,000 taxi trips each day in NYC. We propose a new model that allows users to visually query taxi trips. Besides standard analytics queries, the model supports origin-destination queries that enable the study of mobility across the city. We show that this model is able to express a wide range of spatio-temporal queries, and it is also flexible in that not only can queries be composed but also different aggregations and visual representations can be applied, allowing users to explore and compare results. We have built a scalable system that implements this model which supports interactive response times; makes use of an adaptive level-of-detail rendering strategy to generate clutter-free visualization for large results; and shows hidden details to the users in a summary through the use of overlay heat maps. We present a series of case studies motivated by traffic engineers and economists that show how our model and system enable domain experts to perform tasks that were previously unattainable for them.	Nivan Ferreira;Jorge Poco;Huy T. Vo;Juliana Freire;Cláudio T. Silva	;;;;	10.1109/INFVIS.2004.12;10.1109/VAST.2008.4677356;10.1109/VAST.2011.6102454;10.1109/TVCG.2007.70535;10.1109/VAST.2010.5652467;10.1109/INFVIS.2005.1532150;10.1109/VAST.2008.4677370;10.1109/INFVIS.2000.885086	Spatio-temporal queries, urban data, taxi movement data, visual exploration	
VAST	2013	Visual Traffic Jam Analysis Based on Trajectory Data	10.1109/TVCG.2013.228	http://dx.doi.org/10.1109/TVCG.2013.228	2159	2168	J	In this work, we present an interactive system for visual analysis of urban traffic congestion based on GPS trajectories. For these trajectories we develop strategies to extract and derive traffic jam information. After cleaning the trajectories, they are matched to a road network. Subsequently, traffic speed on each road segment is computed and traffic jam events are automatically detected. Spatially and temporally related events are concatenated in, so-called, traffic jam propagation graphs. These graphs form a high-level description of a traffic jam and its propagation in time and space. Our system provides multiple views for visually exploring and analyzing the traffic condition of a large city as a whole, on the level of propagation graphs, and on road segment level. Case studies with 24 days of taxi GPS trajectories collected in Beijing demonstrate the effectiveness of our system.	Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;Huub van de Wetering	Key Lab. of Machine Perception, Peking Univ., Beijing, China|c|;;;;	10.1109/VISUAL.1997.663866;10.1109/VAST.2011.6102454;10.1109/TVCG.2009.145;10.1109/VAST.2012.6400556;10.1109/INFVIS.2004.27;10.1109/VAST.2008.4677356;10.1109/TVCG.2011.202;10.1109/VAST.2012.6400553;10.1109/TVCG.2012.265;10.1109/TVCG.2011.181;10.1109/VAST.2009.5332593;10.1109/TVCG.2008.125;10.1109/VAST.2011.6102455	Traffic visualization, traffic jam propagation	
InfoVis	2014	UpSet: Visualization of Intersecting Sets	10.1109/TVCG.2014.2346248	http://dx.doi.org/10.1109/TVCG.2014.2346248	1983	1992	J	Understanding relationships between sets is an important analysis task that has received widespread attention in the visualization community. The major challenge in this context is the combinatorial explosion of the number of set intersections if the number of sets exceeds a trivial threshold. In this paper we introduce UpSet, a novel visualization technique for the quantitative analysis of sets, their intersections, and aggregates of intersections. UpSet is focused on creating task-driven aggregates, communicating the size and properties of aggregates and intersections, and a duality between the visualization of the elements in a dataset and their set membership. UpSet visualizes set intersections in a matrix layout and introduces aggregates based on groupings and queries. The matrix layout enables the effective representation of associated data, such as the number of elements in the aggregates and intersections, as well as additional summary statistics derived from subset or element attributes. Sorting according to various measures enables a task-driven analysis of relevant intersections and aggregates. The elements represented in the sets and their associated attributes are visualized in a separate view. Queries based on containment in specific intersections, aggregates or driven by attribute filters are propagated between both views. We also introduce several advanced visual encodings and interaction methods to overcome the problems of varying scales and to address scalability. UpSet is web-based and open source. We demonstrate its general utility in multiple use cases from various domains.	Alexander Lex;Nils Gehlenborg;Hendrik Strobelt;Romain Vuillemot;Hanspeter Pfister	Hendrik Strobelt & Hanspeter Pfister, Harvard Univ., Cambridge, MA, USA|c|;;;;	10.1109/TVCG.2008.144;10.1109/TVCG.2013.184;10.1109/TVCG.2011.186;10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/TVCG.2011.185;10.1109/TVCG.2011.183	Sets, set visualization, sets intersections, set attributes, set relationships, multidimensional data	
InfoVis	2014	OnSet: A Visualization Technique for Large-scale Binary Set Data	10.1109/TVCG.2014.2346249	http://dx.doi.org/10.1109/TVCG.2014.2346249	1993	2002	J	Visualizing sets to reveal relationships between constituent elements is a complex representational problem. Recent research presents several automated placement and grouping techniques to highlight connections between set elements. However, these techniques do not scale well for sets with cardinality greater than one hundred elements. We present OnSet, an interactive, scalable visualization technique for representing large-scale binary set data. The visualization technique defines a single, combined domain of elements for all sets, and models each set by the elements that it both contains and does not contain. OnSet employs direct manipulation interaction and visual highlighting to support easy identification of commonalities and differences as well as membership patterns across different sets of elements. We present case studies to illustrate how the technique can be successfully applied across different domains such as bio-chemical metabolomics and task and event scheduling.	Ramik Sadana;Timothy Major;Alistair D. M. Dove;John T. Stasko	Georgia Tech, Atlanta, GA, USA|c|;;;	10.1109/TVCG.2010.210;10.1109/TVCG.2009.122;10.1109/TVCG.2011.185;10.1109/TVCG.2008.144;10.1109/TVCG.2011.186;10.1109/TVCG.2013.184	Set visualization, information visualization, direct manipulation, Euler diagrams, interaction, logical operations	
InfoVis	2014	DimpVis: Exploring Time-varying Information Visualizations by Direct Manipulation	10.1109/TVCG.2014.2346250	http://dx.doi.org/10.1109/TVCG.2014.2346250	2003	2012	J	We introduce a new direct manipulation technique, DimpVis, for interacting with visual items in information visualizations to enable exploration of the time dimension. DimpVis is guided by visual hint paths which indicate how a selected data item changes through the time dimension in a visualization. Temporal navigation is controlled by manipulating any data item along its hint path. All other items are updated to reflect the new time. We demonstrate how the DimpVis technique can be designed to directly manipulate position, colour, and size in familiar visualizations such as bar charts and scatter plots, as a means for temporal navigation. We present results from a comparative evaluation, showing that the DimpVis technique was subjectively preferred and quantitatively competitive with the traditional time slider, and significantly faster than small multiples for a variety of tasks.	Brittany Kondo;Christopher Collins	Inst. of Technol., Univ. of Ontario, Toronto, ON, Canada|c|;	10.1109/TVCG.2013.147;10.1109/TVCG.2012.204;10.1109/TVCG.2012.260;10.1109/TVCG.2008.175;10.1109/VAST.2012.6400486;10.1109/TVCG.2012.265;10.1109/TVCG.2013.149;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2011.185;10.1109/TVCG.2008.125;10.1109/TVCG.2011.195	Time navigation, direct manipulation, information visualization	
InfoVis	2014	Axis Calibration for Improving Data Attribute Estimation in Star Coordinates Plots	10.1109/TVCG.2014.2346258	http://dx.doi.org/10.1109/TVCG.2014.2346258	2013	2022	J	Star coordinates is a well-known multivariate visualization method that produces linear dimensionality reduction mappings through a set of radial axes defined by vectors in an observable space. One of its main drawbacks concerns the difficulty to recover attributes of data samples accurately, which typically lie in the [0], [1] interval, given the locations of the low-dimensional embeddings and the vectors. In this paper we show that centering the data can considerably increase attribute estimation accuracy, where data values can be read off approximately by projecting embedded points onto calibrated (i.e., labeled) axes, similarly to classical statistical biplots. In addition, this idea can be coupled with a recently developed orthonormalization process on the axis vectors that prevents unnecessary distortions. We demonstrate that the combination of both approaches not only enhances the estimates, but also provides more faithful representations of the data.	Manuel Rubio-Sánchez;Alberto Sanchez	URJC, Fuenlabrada, Spain|c|;	10.1109/TVCG.2010.209;10.1109/TVCG.2013.182;10.1109/VISUAL.1990.146402;10.1109/VISUAL.1997.663916	Star Coordinates, RadViz, Biplots, Axis calibration, Attribute value estimation, Data centering, Orthographic projection	
InfoVis	2014	Domino: Extracting, Comparing, and Manipulating Subsets Across Multiple Tabular Datasets	10.1109/TVCG.2014.2346260	http://dx.doi.org/10.1109/TVCG.2014.2346260	2023	2032	J	Answering questions about complex issues often requires analysts to take into account information contained in multiple interconnected datasets. A common strategy in analyzing and visualizing large and heterogeneous data is dividing it into meaningful subsets. Interesting subsets can then be selected and the associated data and the relationships between the subsets visualized. However, neither the extraction and manipulation nor the comparison of subsets is well supported by state-of-the-art techniques. In this paper we present Domino, a novel multiform visualization technique for effectively representing subsets and the relationships between them. By providing comprehensive tools to arrange, combine, and extract subsets, Domino allows users to create both common visualization techniques and advanced visualizations tailored to specific use cases. In addition to the novel technique, we present an implementation that enables analysts to manage the wide range of options that our approach offers. Innovative interactive features such as placeholders and live previews support rapid creation of complex analysis setups. We introduce the technique and the implementation using a simple example and demonstrate scalability and effectiveness in a use case from the field of cancer genomics.	Samuel Gratzl;Nils Gehlenborg;Alexander Lex;Hanspeter Pfister;Marc Streit	Johannes Kepler Univ. Linz, Linz, Austria|c|;;;;	10.1109/TVCG.2009.179;10.1109/TVCG.2010.138;10.1109/VISUAL.1990.146402;10.1109/TVCG.2012.207;10.1109/TVCG.2011.250;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2013.173;10.1109/TVCG.2011.183;10.1109/TVCG.2013.160;10.1109/TVCG.2011.201;10.1109/TVCG.2006.166;10.1109/INFVIS.2005.1532152;10.1109/INFVIS.2004.15;10.1109/TVCG.2007.70521	Multiple coordinated views, visual linking, relationships, heterogeneous data, categorical data	
InfoVis	2014	Attribute Signatures: Dynamic Visual Summaries for Analyzing Multivariate Geographical Data	10.1109/TVCG.2014.2346265	http://dx.doi.org/10.1109/TVCG.2014.2346265	2033	2042	J	The visual analysis of geographically referenced datasets with a large number of attributes is challenging due to the fact that the characteristics of the attributes are highly dependent upon the locations at which they are focussed, and the scale and time at which they are measured. Specialized interactive visual methods are required to help analysts in understanding the characteristics of the attributes when these multiple aspects are considered concurrently. Here, we develop attribute signatures-interactively crafted graphics that show the geographic variability of statistics of attributes through which the extent of dependency between the attributes and geography can be visually explored. We compute a number of statistical measures, which can also account for variations in time and scale, and use them as a basis for our visualizations. We then employ different graphical configurations to show and compare both continuous and discrete variation of location and scale. Our methods allow variation in multiple statistical summaries of multiple attributes to be considered concurrently and geographically, as evidenced by examples in which the census geography of London and the wider UK are explored.	Cagatay Turkay;Aidan Slingsby;Helwig Hauser;Jo Wood;Jason Dykes	Dept. of Comput. Sci., City Univ. London, London, UK|c|;;;;	10.1109/TVCG.2013.173;10.1109/TVCG.2011.178;10.1109/TVCG.2013.226;10.1109/TVCG.2011.197;10.1109/TVCG.2007.70558;10.1109/TVCG.2008.149;10.1109/INFVIS.2004.12;10.1109/TVCG.2012.256;10.1109/TVCG.2007.70574;10.1109/VAST.2008.4677350;10.1109/TVCG.2008.125;10.1109/TVCG.2013.122	Visual analytics, multi-variate data, geographic information, geovisualization, interactive data analysis	
InfoVis	2014	Origin-Destination Flow Data Smoothing and Mapping	10.1109/TVCG.2014.2346271	http://dx.doi.org/10.1109/TVCG.2014.2346271	2043	2052	J	This paper presents a new approach to flow mapping that extracts inherent patterns from massive geographic mobility data and constructs effective visual representations of the data for the understanding of complex flow trends. This approach involves a new method for origin-destination flow density estimation and a new method for flow map generalization, which together can remove spurious data variance, normalize flows with control population, and detect high-level patterns that are not discernable with existing approaches. The approach achieves three main objectives in addressing the challenges for analyzing and mapping massive flow data. First, it removes the effect of size differences among spatial units via kernel-based density estimation, which produces a measurement of flow volume between each pair of origin and destination. Second, it extracts major flow patterns in massive flow data through a new flow sampling method, which filters out duplicate information in the smoothed flows. Third, it enables effective flow mapping and allows intuitive perception of flow patterns among origins and destinations without bundling or altering flow paths. The approach can work with both point-based flow data (such as taxi trips with GPS locations) and area-based flow data (such as county-to-county migration). Moreover, the approach can be used to detect and compare flow patterns at different scales or in relatively sparse flow datasets, such as migration for each age group. We evaluate and demonstrate the new approach with case studies of U.S. migration data and experiments with synthetic data.	Diansheng Guo;Xi Zhu	Dept. of Geogr., Univ. of South Carolina, Columbia, WA, USA|c|;	10.1109/TVCG.2009.143;10.1109/TVCG.2008.135;10.1109/TVCG.2006.147;10.1109/TVCG.2006.193;10.1109/TVCG.2011.202;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2011.181;10.1109/VISUAL.2005.1532819	flow mapping, kernel smoothing, generalization, multi-resolution mapping, graph drawing, spatial data mining	
InfoVis	2014	Stenomaps: Shorthand for shapes	10.1109/TVCG.2014.2346274	http://dx.doi.org/10.1109/TVCG.2014.2346274	2053	2062	J	We address some of the challenges in representing spatial data with a novel form of geometric abstraction-the stenomap. The stenomap comprises a series of smoothly curving linear glyphs that each represent both the boundary and the area of a polygon. We present an efficient algorithm to automatically generate these open, C1-continuous splines from a set of input polygons. Feature points of the input polygons are detected using the medial axis to maintain important shape properties. We use dynamic programming to compute a planar non-intersecting spline representing each polygon's base shape. The results are stylised glyphs whose appearance may be parameterised and that offer new possibilities in the 'cartographic design space'. We compare our glyphs with existing forms of geometric schematisation and discuss their relative merits and shortcomings. We describe several use cases including the depiction of uncertain model data in the form of hurricane track forecasting; minimal ink thematic mapping; and the depiction of continuous statistical data.	Arthur van Goethem;Andreas Reimer;Bettina Speckmann;Jo Wood	Tech. Univ. Eindhoven, Eindhoven, Netherlands|c|;;;	10.1109/INFVIS.2005.1532145	Schematisation, Maps, Algorithm, Design	
InfoVis	2014	Nmap: A Novel Neighborhood Preservation Space-filling Algorithm	10.1109/TVCG.2014.2346276	http://dx.doi.org/10.1109/TVCG.2014.2346276	2063	2071	J	Space-filling techniques seek to use as much as possible the visual space to represent a dataset, splitting it into regions that represent the data elements. Amongst those techniques, Treemaps have received wide attention due to its simplicity, reduced visual complexity, and compact use of the available space. Several different Treemap algorithms have been proposed, however the core idea is the same, to divide the visual space into rectangles with areas proportional to some data attribute or weight. Although pleasant layouts can be effectively produced by the existing techniques, most of them do not take into account relationships that might exist between different data elements when partitioning the visual space. This violates the distance-similarity metaphor, that is, close rectangles do not necessarily represent similar data elements. In this paper, we propose a novel approach, called Neighborhood Treemap (Nmap), that seeks to solve this limitation by employing a slice and scale strategy where the visual space is successively bisected on the horizontal or vertical directions and the bisections are scaled until one rectangle is defined per data element. Compared to the current techniques with the same similarity preservation goal, our approach presents the best results while being two to three orders of magnitude faster. The usefulness of Nmap is shown by two applications involving the organization of document collections and the construction of cartograms illustrating its effectiveness on different scenarios.	Felipe S. L. G. Duarte;Fabio Sikansi;Francisco M. Fatore;Samuel G. Fadel;Fernando Vieira Paulovich	Inst. of Math. & Comput. Sci., Sao Carlos, Brazil|c|;;;;	10.1109/INFVIS.2000.885091;10.1109/INFVIS.2005.1532145;10.1109/TVCG.2007.70522;10.1109/TVCG.2009.128;10.1109/TVCG.2007.70529;10.1109/VISUAL.1991.175815;10.1109/TVCG.2008.165	Space-filling techniques, treemaps, distance-similarity preservation	
InfoVis	2014	Tree Colors: Color Schemes for Tree-Structured Data	10.1109/TVCG.2014.2346277	http://dx.doi.org/10.1109/TVCG.2014.2346277	2072	2081	J	We present a method to map tree structures to colors from the Hue-Chroma-Luminance color model, which is known for its well balanced perceptual properties. The Tree Colors method can be tuned with several parameters, whose effect on the resulting color schemes is discussed in detail. We provide a free and open source implementation with sensible parameter defaults. Categorical data are very common in statistical graphics, and often these categories form a classification tree. We evaluate applying Tree Colors to tree structured data with a survey on a large group of users from a national statistical institute. Our user study suggests that Tree Colors are useful, not only for improving node-link diagrams, but also for unveiling tree structure in non-hierarchical visualizations.	Martijn Tennekes;Edwin de Jonge	;	10.1109/TVCG.2011.193;10.1109/INFVIS.2000.885091;10.1109/INFVIS.2002.1173151	Color schemes, statistical graphics, hierarchical data	
InfoVis	2014	Revisiting Bertin Matrices: New Interactions for Crafting Tabular Visualizations	10.1109/TVCG.2014.2346279	http://dx.doi.org/10.1109/TVCG.2014.2346279	2082	2091	J	We present Bertifier, a web app for rapidly creating tabular visualizations from spreadsheets. Bertifier draws from Jacques Bertin's matrix analysis method, whose goal was to ÔÇ£simplify without destroyingÔÇØ by encoding cell values visually and grouping similar rows and columns. Although there were several attempts to bring this method to computers, no implementation exists today that is both exhaustive and accessible to a large audience. Bertifier remains faithful to Bertin's method while leveraging the power of today's interactive computers. Tables are formatted and manipulated through crossets, a new interaction technique for rapidly applying operations on rows and columns. We also introduce visual reordering, a semi-interactive reordering approach that lets users apply and tune automatic reordering algorithms in a WYSIWYG manner. Sessions with eight users from different backgrounds suggest that Bertifier has the potential to bring Bertin's method to a wider audience of both technical and non-technical users, and empower them with data analysis and communication tools that were so far only accessible to a handful of specialists.COMPUTER	Charles Perin;Pierre Dragicevic;Jean-Daniel Fekete	INRIA, Sophia-Antipolis, France|c|;;	10.1109/TVCG.2006.160;10.1109/TVCG.2014.2346292;10.1109/TVCG.2014.2346426	Visualization, Interaction, Tabular Data, Bertin, Crossing, Crossets	
InfoVis	2014	iVisDesigner: Expressive Interactive Design of Information Visualizations	10.1109/TVCG.2014.2346291	http://dx.doi.org/10.1109/TVCG.2014.2346291	2092	2101	J	We present the design, implementation and evaluation of iVisDesigner, a web-based system that enables users to design information visualizations for complex datasets interactively, without the need for textual programming. Our system achieves high interactive expressiveness through conceptual modularity, covering a broad information visualization design space. iVisDesigner supports the interactive design of interactive visualizations, such as provisioning for responsive graph layouts and different types of brushing and linking interactions. We present the system design and implementation, exemplify it through a variety of illustrative visualization designs and discuss its limitations. A performance analysis and an informal user study are presented to evaluate the system.	Donghao Ren;Tobias Höllerer;Xiaoru Yuan	Dept. of Comput. Sci., Univ. of California, Santa Barbara, Santa Barbara, CA, USA|c|;;	10.1109/INFVIS.2004.12;10.1109/TVCG.2010.144;10.1109/TVCG.2009.179;10.1109/TVCG.2009.174;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2011.185;10.1109/TVCG.2007.70577;10.1109/INFVIS.2004.64;10.1109/TVCG.2010.126;10.1109/TVCG.2013.191;10.1109/INFVIS.1997.636792;10.1109/TVCG.2011.201;10.1109/TVCG.2011.261;10.1109/TVCG.2012.275;10.1109/INFVIS.1997.636761	Visualization design, Interactive Design, Interaction, Expressiveness, Web-based visualization	
InfoVis	2014	Constructing Visual Representations: Investigating the Use of Tangible Tokens	10.1109/TVCG.2014.2346292	http://dx.doi.org/10.1109/TVCG.2014.2346292	2102	2111	J	The accessibility of infovis authoring tools to a wide audience has been identified as a major research challenge. A key task in the authoring process is the development of visual mappings. While the infovis community has long been deeply interested in finding effective visual mappings, comparatively little attention has been placed on how people construct visual mappings. In this paper, we present the results of a study designed to shed light on how people transform data into visual representations. We asked people to create, update and explain their own information visualizations using only tangible building blocks. We learned that all participants, most of whom had little experience in visualization authoring, were readily able to create and talk about their own visualizations. Based on our observations, we discuss participants' actions during the development of their visual representations and during their analytic activities. We conclude by suggesting implications for tool design to enable broader support for infovis authoring.	Samuel Huron;Yvonne Jansen;M. Sheelagh T. Carpendale	IRI, Inria, Orsay, France|c|;;	10.1109/TVCG.2009.176;10.1109/TVCG.2011.185;10.1109/TVCG.2013.227;10.1109/TVCG.2007.70577;10.1109/INFVIS.2004.64;10.1109/TVCG.2011.251;10.1109/VISUAL.1997.663890;10.1109/TVCG.2012.275;10.1109/TVCG.2013.134;10.1109/TVCG.2010.164;10.1109/TVCG.2007.70541;10.1109/TVCG.2012.199	Constructive visualization, Physical visualization, Dynamic visualization, Empirical study, Token, Visualization authoring, Information visualization, Visual mapping, Novices, Visualization construction, Visual analytics	
InfoVis	2014	PanoramicData: Data Analysis through Pen & Touch	10.1109/TVCG.2014.2346293	http://dx.doi.org/10.1109/TVCG.2014.2346293	2112	2121	J	Interactively exploring multidimensional datasets requires frequent switching among a range of distinct but inter-related tasks (e.g., producing different visuals based on different column sets, calculating new variables, and observing the interactions between sets of data). Existing approaches either target specific different problem domains (e.g., data-transformation or data-presentation) or expose only limited aspects of the general exploratory process; in either case, users are forced to adopt coping strategies (e.g., arranging windows or using undo as a mechanism for comparison instead of using side-by-side displays) to compensate for the lack of an integrated suite of exploratory tools. PanoramicData (PD) addresses these problems by unifying a comprehensive set of tools for visual data exploration into a hybrid pen and touch system designed to exploit the visualization advantages of large interactive displays. PD goes beyond just familiar visualizations by including direct UI support for data transformation and aggregation, filtering and brushing. Leveraging an unbounded whiteboard metaphor, users can combine these tools like building blocks to create detailed interactive visual display networks in which each visualization can act as a filter for others. Further, by operating directly on relational-databases, PD provides an approachable visual language that exposes a broad set of the expressive power of SQL including functionally complete logic filtering, computation of aggregates and natural table joins. To understand the implications of this novel approach, we conducted a formative user study with both data and visualization experts. The results indicated that the system provided a fluid and natural user experience for probing multi-dimensional data and was able to cover the full range of queries that the users wanted to pose.	Emanuel Zgraggen;Robert C. Zeleznik;Steven M. Drucker	;;	10.1109/INFVIS.2000.885086;10.1109/TVCG.2009.162;10.1109/TVCG.2010.164;10.1109/TVCG.2011.251;10.1109/TVCG.2013.191;10.1109/TVCG.2012.275;10.1109/VAST.2007.4389013;10.1109/TVCG.2013.150;10.1109/TVCG.2007.70521;10.1109/TVCG.2008.137;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2007.70594;10.1109/TVCG.2012.204	Visual analytics, pen and touch, user interfaces, interaction design, coordinated and multiple views	
InfoVis	2014	Visualizing Statistical Mix Effects and Simpson's Paradox	10.1109/TVCG.2014.2346297	http://dx.doi.org/10.1109/TVCG.2014.2346297	2132	2141	J	We discuss how ÔÇ£mix effectsÔÇØ can surprise users of visualizations and potentially lead them to incorrect conclusions. This statistical issue (also known as ÔÇ£omitted variable biasÔÇØ or, in extreme cases, as ÔÇ£Simpson's paradoxÔÇØ) is widespread and can affect any visualization in which the quantity of interest is an aggregated value such as a weighted sum or average. Our first contribution is to document how mix effects can be a serious issue for visualizations, and we analyze how mix effects can cause problems in a variety of popular visualization techniques, from bar charts to treemaps. Our second contribution is a new technique, the ÔÇ£comet chart,ÔÇØ that is meant to ameliorate some of these issues.	Zan Armstrong;Martin Wattenberg	;	10.1109/TVCG.2012.213;10.1109/TVCG.2007.70577	Mix effects, Omitted variable bias, Simpson's paradox, Statistics	
InfoVis	2014	Error Bars Considered Harmful: Exploring Alternate Encodings for Mean and Error	10.1109/TVCG.2014.2346298	http://dx.doi.org/10.1109/TVCG.2014.2346298	2142	2151	J	When making an inference or comparison with uncertain, noisy, or incomplete data, measurement error and confidence intervals can be as important for judgment as the actual mean values of different groups. These often misunderstood statistical quantities are frequently represented by bar charts with error bars. This paper investigates drawbacks with this standard encoding, and considers a set of alternatives designed to more effectively communicate the implications of mean and error data to a general audience, drawing from lessons learned from the use of visual statistics in the information visualization community. We present a series of crowd-sourced experiments that confirm that the encoding of mean and error significantly changes how viewers make decisions about uncertain data. Careful consideration of design tradeoffs in the visual presentation of data results in human reasoning that is more consistently aligned with statistical inferences. We suggest the use of gradient plots (which use transparency to encode uncertainty) and violin plots (which use width) as better alternatives for inferential tasks than bar charts with error bars.	Michael Correll;Michael Gleicher	Dept. of Comput. Sci., Univ. of Wisconsin-Madison, Madison, WI, USA|c|;	10.1109/TVCG.2012.220;10.1109/TVCG.2012.199;10.1109/TVCG.2012.262;10.1109/TVCG.2011.175;10.1109/TVCG.2012.279	Visual statistics, information visualization, crowd-sourcing, empirical evaluation	
InfoVis	2014	MovExp: A Versatile Visualization Tool for Human-Computer Interaction Studies with 3D Performance and Biomechanical Data	10.1109/TVCG.2014.2346311	http://dx.doi.org/10.1109/TVCG.2014.2346311	2359	2368	J	In Human-Computer Interaction (HCI), experts seek to evaluate and compare the performance and ergonomics of user interfaces. Recently, a novel cost-efficient method for estimating physical ergonomics and performance has been introduced to HCI. It is based on optical motion capture and biomechanical simulation. It provides a rich source for analyzing human movements summarized in a multidimensional data set. Existing visualization tools do not sufficiently support the HCI experts in analyzing this data. We identified two shortcomings. First, appropriate visual encodings are missing particularly for the biomechanical aspects of the data. Second, the physical setup of the user interface cannot be incorporated explicitly into existing tools. We present MovExp, a versatile visualization tool that supports the evaluation of user interfaces. In particular, it can be easily adapted by the HCI experts to include the physical setup that is being evaluated, and visualize the data on top of it. Furthermore, it provides a variety of visual encodings to communicate muscular loads, movement directions, and other specifics of HCI studies that employ motion capture and biomechanical simulation. In this design study, we follow a problem-driven research approach. Based on a formalization of the visualization needs and the data structure, we formulate technical requirements for the visualization tool and present novel solutions to the analysis needs of the HCI experts. We show the utility of our tool with four case studies from the daily work of our HCI experts.	Gregorio Palmas;Myroslav Bachynskyi;Antti Oulasvirta;Hans-Peter Seidel;Tino Weinkauf	Max Planck Inst. for Inf., Saarbrucken, Germany|c|;;;;	10.1109/TVCG.2009.152;10.1109/TVCG.2012.213;10.1109/TVCG.2012.204;10.1109/INFVIS.2000.885086;10.1109/VISUAL.1994.346302;10.1109/INFVIS.2004.12	Information visualization, Design study, Human-Computer Interaction	
InfoVis	2014	NeuroLines: A Subway Map Metaphor for Visualizing Nanoscale Neuronal Connectivity	10.1109/TVCG.2014.2346312	http://dx.doi.org/10.1109/TVCG.2014.2346312	2369	2378	J	We present NeuroLines, a novel visualization technique designed for scalable detailed analysis of neuronal connectivity at the nanoscale level. The topology of 3D brain tissue data is abstracted into a multi-scale, relative distance-preserving subway map visualization that allows domain scientists to conduct an interactive analysis of neurons and their connectivity. Nanoscale connectomics aims at reverse-engineering the wiring of the brain. Reconstructing and analyzing the detailed connectivity of neurons and neurites (axons, dendrites) will be crucial for understanding the brain and its development and diseases. However, the enormous scale and complexity of nanoscale neuronal connectivity pose big challenges to existing visualization techniques in terms of scalability. NeuroLines offers a scalable visualization framework that can interactively render thousands of neurites, and that supports the detailed analysis of neuronal structures and their connectivity. We describe and analyze the design of NeuroLines based on two real-world use-cases of our collaborators in developmental neuroscience, and investigate its scalability to large-scale neuronal connectivity data.	Ali Al-Awami;Johanna Beyer;Hendrik Strobelt;Narayanan Kasthuri;Jeff Lichtman;Hanspeter Pfister;Markus Hadwiger	King Abdullah Univ. of Sci. & Technol., Thuwal, Saudi Arabia|c|;;;;;;	10.1109/TVCG.2013.142;10.1109/TVCG.2012.240;10.1109/TVCG.2014.2346371;10.1109/TVCG.2009.121;10.1109/VAST.2011.6102439;10.1109/TVCG.2009.108;10.1109/TVCG.2011.192;10.1109/VISUAL.2002.1183754;10.1109/TVCG.2013.154	Connectomics, Neuroscience, Data Abstraction, Multi-Trees, Focus+Context	
InfoVis	2014	Four Experiments on the Perception of Bar Charts	10.1109/TVCG.2014.2346320	http://dx.doi.org/10.1109/TVCG.2014.2346320	2152	2160	J	Bar charts are one of the most common visualization types. In a classic graphical perception paper, Cleveland & McGill studied how different bar chart designs impact the accuracy with which viewers can complete simple perceptual tasks. They found that people perform substantially worse on stacked bar charts than on aligned bar charts, and that comparisons between adjacent bars are more accurate than between widely separated bars. However, the study did not explore why these differences occur. In this paper, we describe a series of follow-up experiments to further explore and explain their results. While our results generally confirm Cleveland & McGill's ranking of various bar chart configurations, we provide additional insight into the bar chart reading task and the sources of participants' errors. We use our results to propose new hypotheses on the perception of bar charts.	Justin Talbot;Vidya Setlur;Anushka Anand	Tableau Res., USA|c|;;	10.1109/TVCG.2012.237	Graphical perception, bar charts	
InfoVis	2014	Visual Parameter Space Analysis: A Conceptual Framework	10.1109/TVCG.2014.2346321	http://dx.doi.org/10.1109/TVCG.2014.2346321	2161	2170	J	Various case studies in different application domains have shown the great potential of visual parameter space analysis to support validating and using simulation models. In order to guide and systematize research endeavors in this area, we provide a conceptual framework for visual parameter space analysis problems. The framework is based on our own experience and a structured analysis of the visualization literature. It contains three major components: (1) a data flow model that helps to abstractly describe visual parameter space analysis problems independent of their application domain; (2) a set of four navigation strategies of how parameter space analysis can be supported by visualization tools; and (3) a characterization of six analysis tasks. Based on our framework, we analyze and classify the current body of literature, and identify three open research gaps in visual parameter space analysis. The framework and its discussion are meant to support visualization designers and researchers in characterizing parameter space analysis problems and to guide their design and evaluation processes.	Michael Sedlmair;Christoph Heinzl;Stefan Bruckner;Harald Piringer;Torsten Möller	Univ. of Vienna, Vienna, Austria|c|;;;;	10.1109/INFVIS.1995.528680;10.1109/TVCG.2010.177;10.1109/TVCG.2008.145;10.1109/TVCG.2012.219;10.1109/TVCG.2009.155;10.1109/TVCG.2010.223;10.1109/TVCG.2012.224;10.1109/TVCG.2012.213;10.1109/TVCG.2010.190;10.1109/INFVIS.2005.1532136;10.1109/VISUAL.1993.398859;10.1109/VAST.2009.5333431;10.1109/TVCG.2007.70581;10.1109/TVCG.2013.142;10.1109/VAST.2010.5652392;10.1109/INFVIS.2005.1532142;10.1109/TVCG.2013.130;10.1109/TVCG.2013.147;10.1109/TVCG.2013.124;10.1109/TVCG.2012.190;10.1109/TVCG.2009.111;10.1109/TVCG.2011.229;10.1109/TVCG.2013.157;10.1109/TVCG.2013.125;10.1109/VAST.2011.6102450;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2013.126;10.1109/TVCG.2011.248;10.1109/TVCG.2010.214;10.1109/TVCG.2009.170;10.1109/VAST.2011.6102457;10.1109/TVCG.2013.120;10.1109/TVCG.2011.253	Parameter space analysis, input-output model, simulation, task characterization, literature analysis	
InfoVis	2014	Moving beyond sequential design: Reflections on a rich multi-channel approach to data visualization	10.1109/TVCG.2014.2346323	http://dx.doi.org/10.1109/TVCG.2014.2346323	2171	2180	J	We reflect on a four-year engagement with transport authorities and others involving a large dataset describing the use of a public bicycle-sharing scheme. We describe the role visualization of these data played in fostering engagement with policy makers, transport operators, the transport research community, the museum and gallery sector and the general public. We identify each of these as `channels'-evolving relationships between producers and consumers of visualization-where traditional roles of the visualization expert and domain expert are blurred. In each case, we identify the different design decisions that were required to support each of these channels and the role played by the visualization process. Using chauffeured interaction with a flexible visual analytics system we demonstrate how insight was gained by policy makers into gendered spatio-temporal cycle behaviors, how this led to further insight into workplace commuting activity, group cycling behavior and explanations for street navigation choice. We demonstrate how this supported, and was supported by, the seemingly unrelated development of narrative-driven visualization via TEDx, of the creation and the setting of an art installation and the curating of digital and physical artefacts. We assert that existing models of visualization design, of tool/technique development and of insight generation do not adequately capture the richness of parallel engagement via these multiple channels of communication. We argue that developing multiple channels in parallel opens up opportunities for visualization design and analysis by building trust and authority and supporting creativity. This rich, non-sequential approach to visualization design is likely to foster serendipity, deepen insight and increase impact.	Jo Wood;Roger Beecham;Jason Dykes	giCentre, City Univ. London, London, UK|c|;;	10.1109/TVCG.2012.272;10.1109/TVCG.2012.262;10.1109/TVCG.2012.213;10.1109/TVCG.2011.175;10.1109/TVCG.2013.134;10.1109/TVCG.2010.179;10.1109/TVCG.2013.132;10.1109/INFVIS.2004.59;10.1109/TVCG.2011.209;10.1109/TVCG.2013.145;10.1109/TVCG.2008.127	Movement visualization, visual analytics, bikeshare, impact, visualization models, design study	
InfoVis	2014	An Algebraic Process for Visualization Design	10.1109/TVCG.2014.2346325	http://dx.doi.org/10.1109/TVCG.2014.2346325	2181	2190	J	We present a model of visualization design based on algebraic considerations of the visualization process. The model helps characterize visual encodings, guide their design, evaluate their effectiveness, and highlight their shortcomings. The model has three components: the underlying mathematical structure of the data or object being visualized, the concrete representation of the data in a computer, and (to the extent possible) a mathematical description of how humans perceive the visualization. Because we believe the value of our model lies in its practical application, we propose three general principles for good visualization design. We work through a collection of examples where our model helps explain the known properties of existing visualizations methods, both good and not-so-good, as well as suggesting some novel methods. We describe how to use the model alongside experimental user studies, since it can help frame experiment outcomes in an actionable manner. Exploring the implications and applications of our model and its design principles should provide many directions for future visualization research.	Gordon L. Kindlmann;Carlos Eduardo Scheidegger	Univ. of Chicago, Chicago, IL, USA|c|;	10.1109/TVCG.2013.173;10.1109/INFVIS.1999.801860;10.1109/TVCG.2010.132;10.1109/TVCG.2010.199;10.1109/VISUAL.1996.568118;10.1109/TVCG.2013.124;10.1109/TVCG.2009.125;10.1109/TVCG.2009.111;10.1109/TVCG.2007.70594;10.1109/TVCG.2013.119;10.1109/INFVIS.2003.1249005;10.1109/INFVIS.2004.59;10.1109/VISUAL.1996.567784;10.1109/TVCG.2013.126;10.1109/TVCG.2008.121;10.1109/TVCG.2012.230;10.1109/TVCG.2010.161	Visualization Design, Symmetries, Visualization Theory	
InfoVis	2014	Design Activity Framework for Visualization Design	10.1109/TVCG.2014.2346331	http://dx.doi.org/10.1109/TVCG.2014.2346331	2191	2200	J	An important aspect in visualization design is the connection between what a designer does and the decisions the designer makes. Existing design process models, however, do not explicitly link back to models for visualization design decisions. We bridge this gap by introducing the design activity framework, a process model that explicitly connects to the nested model, a well-known visualization design decision model. The framework includes four overlapping activities that characterize the design process, with each activity explicating outcomes related to the nested model. Additionally, we describe and characterize a list of exemplar methods and how they overlap among these activities. The design activity framework is the result of reflective discussions from a collaboration on a visualization redesign project, the details of which we describe to ground the framework in a real-world design process. Lastly, from this redesign project we provide several research outcomes in the domain of cybersecurity, including an extended data abstraction and rich opportunities for future visualization research.	Sean McKenna;Dominika Mazur;James Agutter;Miriah D. Meyer	Sch. of Comput., Univ. of Utah, Salt Lake City, UT, USA|c|;;;	10.1109/TVCG.2012.213;10.1109/TVCG.2011.209;10.1109/TVCG.2009.111;10.1109/TVCG.2013.126;10.1109/TVCG.2013.145	Design, frameworks, process, cybersecurity, nested model, decisions, models, evaluation, visualization	
InfoVis	2014	The Persuasive Power of Data Visualization	10.1109/TVCG.2014.2346419	http://dx.doi.org/10.1109/TVCG.2014.2346419	2211	2220	J	Data visualization has been used extensively to inform users. However, little research has been done to examine the effects of data visualization in influencing users or in making a message more persuasive. In this study, we present experimental research to fill this gap and present an evidence-based analysis of persuasive visualization. We built on persuasion research from psychology and user interfaces literature in order to explore the persuasive effects of visualization. In this experimental study we define the circumstances under which data visualization can make a message more persuasive, propose hypotheses, and perform quantitative and qualitative analyses on studies conducted to test these hypotheses. We compare visual treatments with data presented through barcharts and linecharts on the one hand, treatments with data presented through tables on the other, and then evaluate their persuasiveness. The findings represent a first step in exploring the effectiveness of persuasive visualization.	Anshul Vikram Pandey;Anjali Manivannan;Oded Nov;Margaret Satterthwaite;Enrico Bertini	New York Univ., New York, NY, USA|c|;;;;	10.1109/TVCG.2012.199;10.1109/TVCG.2012.221;10.1109/TVCG.2012.197;10.1109/TVCG.2011.192;10.1109/TVCG.2013.234	Persuasive visualization, elaboration likelihood model, evaluation	
InfoVis	2014	Comparative Eye Tracking Study on Node-Link Visualizations of Trajectories	10.1109/TVCG.2014.2346420	http://dx.doi.org/10.1109/TVCG.2014.2346420	2221	2230	J	We present the results of an eye tracking study that compares different visualization methods for long, dense, complex, and piecewise linear spatial trajectories. Typical sources of such data are from temporally discrete measurements of the positions of moving objects, for example, recorded GPS tracks of animals in movement ecology. In the repeated-measures within-subjects user study, four variants of node-link visualization techniques are compared, with the following representations of directed links: standard arrow, tapered, equidistant arrows, and equidistant comets. In addition, we investigate the effect of rendering order for the halo visualization of those links as well as the usefulness of node splatting. All combinations of link visualization techniques are tested for different trajectory density levels. We used three types of tasks: tracing of paths, identification of longest links, and estimation of the density of trajectory clusters. Results are presented in the form of the statistical evaluation of task completion time, task solution accuracy, and two eye tracking metrics. These objective results are complemented by a summary of subjective feedback from the participants. The main result of our study is that tapered links perform very well. However, we discuss that equidistant comets and equidistant arrows are a good option to perceive direction information independent of zoom-level of the display.	Rudolf Netzel;Michael Burch;Daniel Weiskopf	;;	10.1109/INFVIS.2004.1;10.1109/TVCG.2011.193;10.1109/TVCG.2011.226	User study, eye tracking, evaluation, trajectory visualization, node-link visualization, direction encoding, node splatting, halo rendering	
InfoVis	2014	Node, Node-Link, and Node-Link-Group Diagrams: An Evaluation	10.1109/TVCG.2014.2346422	http://dx.doi.org/10.1109/TVCG.2014.2346422	2231	2240	J	Effectively showing the relationships between objects in a dataset is one of the main tasks in information visualization. Typically there is a well-defined notion of distance between pairs of objects, and traditional approaches such as principal component analysis or multi-dimensional scaling are used to place the objects as points in 2D space, so that similar objects are close to each other. In another typical setting, the dataset is visualized as a network graph, where related nodes are connected by links. More recently, datasets are also visualized as maps, where in addition to nodes and links, there is an explicit representation of groups and clusters. We consider these three Techniques, characterized by a progressive increase of the amount of encoded information: node diagrams, node-link diagrams and node-link-group diagrams. We assess these three types of diagrams with a controlled experiment that covers nine different tasks falling broadly in three categories: node-based tasks, network-based tasks and group-based tasks. Our findings indicate that adding links, or links and group representations, does not negatively impact performance (time and accuracy) of node-based tasks. Similarly, adding group representations does not negatively impact the performance of network-based tasks. Node-link-group diagrams outperform the others on group-based tasks. These conclusions contradict results in other studies, in similar but subtly different settings. Taken together, however, such results can have significant implications for the design of standard and domain snecific visualizations tools.	Bahador Saket;Paolo Simonetto;Stephen G. Kobourov;Katy Börner	Univ. of Arizona, Tucson, AZ, USA|c|;;;	10.1109/INFVIS.2003.1249011;10.1109/TVCG.2011.186;10.1109/TVCG.2008.155;10.1109/INFVIS.1995.528686;10.1109/TVCG.2007.70596;10.1109/TVCG.2009.122;10.1109/TVCG.2013.187;10.1109/TVCG.2013.124	graphs, networks, maps, scatter plots	
InfoVis	2014	The Not-so-Staggering Effect of Staggered Animated Transitions on Visual Tracking	10.1109/TVCG.2014.2346424	http://dx.doi.org/10.1109/TVCG.2014.2346424	2241	2250	J	Interactive visual applications often rely on animation to transition from one display state to another. There are multiple animation techniques to choose from, and it is not always clear which should produce the best visual correspondences between display elements. One major factor is whether the animation relies on staggering-an incremental delay in start times across the moving elements. It has been suggested that staggering may reduce occlusion, while also reducing display complexity and producing less overwhelming animations, though no empirical evidence has demonstrated these advantages. Work in perceptual psychology does show that reducing occlusion, and reducing inter-object proximity (crowding) more generally, improves performance in multiple object tracking. We ran simulations confirming that staggering can in some cases reduce crowding in animated transitions involving dot clouds (as found in, e.g., animated 2D scatterplots). We empirically evaluated the effect of two staggering techniques on tracking tasks, focusing on cases that should most favour staggering. We found that introducing staggering has a negligible, or even negative, impact on multiple object tracking performance. The potential benefits of staggering may be outweighed by strong costs: a loss of common-motion grouping information about which objects travel in similar paths, and less predictability about when any specific object would begin to move. Staggering may be beneficial in some conditions, but they have yet to be demonstrated. The present results are a significant step toward a better understanding of animation pacing, and provide direction for further research.	Fanny Chevalier;Pierre Dragicevic;Steven Franconeri	Inria, Sophia-Antipolis, France|c|;;	10.1109/TVCG.2012.199;10.1109/INFVIS.1999.801854;10.1109/INFVIS.2002.1173148;10.1109/TVCG.2008.153;10.1109/TVCG.2007.70539	Animated transitions, staggered animation, visual tracking	
InfoVis	2014	The Influence of Contour on Similarity Perception of Star Glyphs	10.1109/TVCG.2014.2346426	http://dx.doi.org/10.1109/TVCG.2014.2346426	2251	2260	J	We conducted three experiments to investigate the effects of contours on the detection of data similarity with star glyph variations. A star glyph is a small, compact, data graphic that represents a multi-dimensional data point. Star glyphs are often used in small-multiple settings, to represent data points in tables, on maps, or as overlays on other types of data graphics. In these settings, an important task is the visual comparison of the data points encoded in the star glyph, for example to find other similar data points or outliers. We hypothesized that for data comparisons, the overall shape of a star glyph-enhanced through contour lines-would aid the viewer in making accurate similarity judgments. To test this hypothesis, we conducted three experiments. In our first experiment, we explored how the use of contours influenced how visualization experts and trained novices chose glyphs with similar data values. Our results showed that glyphs without contours make the detection of data similarity easier. Given these results, we conducted a second study to understand intuitive notions of similarity. Star glyphs without contours most intuitively supported the detection of data similarity. In a third experiment, we tested the effect of star glyph reference structures (i.e., tickmarks and gridlines) on the detection of similarity. Surprisingly, our results show that adding reference structures does improve the correctness of similarity judgments for star glyphs with contours, but not for the standard star glyph. As a result of these experiments, we conclude that the simple star glyph without contours performs best under several criteria, reinforcing its practice and popularity in the literature. Contours seem to enhance the detection of other types of similarity, e. g., shape similarity and are distracting when data similarity has to be judged. Based on these findings we provide design considerations regarding the use of contours and reference structures on star glyp- s.	Johannes Fuchs;Petra Isenberg;Anastasia Bezerianos;Fabian Fischer;Enrico Bertini	Univ. of Konstanz, Konstanz, Germany|c|;;;;	10.1109/TVCG.2012.220;10.1109/TVCG.2008.136;10.1109/TVCG.2011.242;10.1109/INFVIS.2004.15	Glyphs, star glyphs, contours, perception, quantitative evaluation, similarity detection, visual comparison	
InfoVis	2014	Order of Magnitude Markers: An Empirical Study on Large Magnitude Number Detection	10.1109/TVCG.2014.2346428	http://dx.doi.org/10.1109/TVCG.2014.2346428	2261	2270	J	In this paper we introduce Order of Magnitude Markers (OOMMs) as a new technique for number representation. The motivation for this work is that many data sets require the depiction and comparison of numbers that have varying orders of magnitude. Existing techniques for representation use bar charts, plots and colour on linear or logarithmic scales. These all suffer from related problems. There is a limit to the dynamic range available for plotting numbers, and so the required dynamic range of the plot can exceed that of the depiction method. When that occurs, resolving, comparing and relating values across the display becomes problematical or even impossible for the user. With this in mind, we present an empirical study in which we compare logarithmic, linear, scale-stack bars and our new markers for 11 different stimuli grouped into 4 different tasks across all 8 marker types.	Rita Borgo;Joel Dearden;Mark W. Jones	;;	10.1109/TVCG.2013.187;10.1109/TVCG.2012.229;10.1109/INFVIS.2004.59;10.1109/TVCG.2012.197;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2011.160;10.1109/TVCG.2010.130;10.1109/TVCG.2013.234	Orders of magnitude, bar charts, logarithmic scale	
InfoVis	2014	Overview: The Design, Adoption, and Analysis of a Visual Document Mining Tool for Investigative Journalists	10.1109/TVCG.2014.2346431	http://dx.doi.org/10.1109/TVCG.2014.2346431	2271	2280	J	For an investigative journalist, a large collection of documents obtained from a Freedom of Information Act request or a leak is both a blessing and a curse: such material may contain multiple newsworthy stories, but it can be difficult and time consuming to find relevant documents. Standard text search is useful, but even if the search target is known it may not be possible to formulate an effective query. In addition, summarization is an important non-search task. We present Overview, an application for the systematic analysis of large document collections based on document clustering, visualization, and tagging. This work contributes to the small set of design studies which evaluate a visualization system ÔÇ£in the wildÔÇØ, and we report on six case studies where Overview was voluntarily used by self-initiated journalists to produce published stories. We find that the frequently-used language of ÔÇ£exploringÔÇØ a document collection is both too vague and too narrow to capture how journalists actually used our application. Our iterative process, including multiple rounds of deployment and observations of real world usage, led to a much more specific characterization of tasks. We analyze and justify the visual encoding and interaction techniques used in Overview's design with respect to our final task abstractions, and propose generalizable lessons for visualization design methodology.	Matthew Brehmer;Stephen Ingram;Jonathan Stray;Tamara Munzner	Univ. of British Columbia, Vancouver, BC, Canada|c|;;;	10.1109/TVCG.2009.127;10.1109/INFVIS.2004.19;10.1109/TVCG.2012.224;10.1109/TVCG.2012.213;10.1109/TVCG.2012.260;10.1109/TVCG.2009.140;10.1109/TVCG.2013.162;10.1109/TVCG.2013.153;10.1109/TVCG.2009.148;10.1109/TVCG.2013.124;10.1109/TVCG.2011.239;10.1109/VAST.2010.5652940;10.1109/TVCG.2011.209	Design study, investigative journalism, task and requirements analysis, text and document data, text analysis	
InfoVis	2014	How Hierarchical Topics Evolve in Large Text Corpora	10.1109/TVCG.2014.2346433	http://dx.doi.org/10.1109/TVCG.2014.2346433	2281	2290	J	Using a sequence of topic trees to organize documents is a popular way to represent hierarchical and evolving topics in text corpora. However, following evolving topics in the context of topic trees remains difficult for users. To address this issue, we present an interactive visual text analysis approach to allow users to progressively explore and analyze the complex evolutionary patterns of hierarchical topics. The key idea behind our approach is to exploit a tree cut to approximate each tree and allow users to interactively modify the tree cuts based on their interests. In particular, we propose an incremental evolutionary tree cut algorithm with the goal of balancing 1) the fitness of each tree cut and the smoothness between adjacent tree cuts; 2) the historical and new information related to user interests. A time-based visualization is designed to illustrate the evolving topics over time. To preserve the mental map, we develop a stable layout algorithm. As a result, our approach can quickly guide users to progressively gain profound insights into evolving hierarchical topics. We evaluate the effectiveness of the proposed method on Amazon's Mechanical Turk and real-world news data. The results show that users are able to successfully analyze evolving topics in text data.	Weiwei Cui;Shixia Liu;Zhuofeng Wu;Hao Wei	Microsoft Res., Redmond, WA, USA|c|;;;	10.1109/TVCG.2013.196;10.1109/TVCG.2009.108;10.1109/VAST.2014.7042494;10.1109/TVCG.2009.111;10.1109/TVCG.2011.239;10.1109/TVCG.2014.2346920;10.1109/TVCG.2012.212;10.1109/TVCG.2013.221;10.1109/TVCG.2012.225;10.1109/TVCG.2013.162;10.1109/TVCG.2013.200	Hierarchical topic visualization, evolutionary tree clustering, data transformation	
InfoVis	2014	Exploring the Placement and Design of Word-Scale Visualizations	10.1109/TVCG.2014.2346435	http://dx.doi.org/10.1109/TVCG.2014.2346435	2291	2300	J	We present an exploration and a design space that characterize the usage and placement of word-scale visualizations within text documents. Word-scale visualizations are a more general version of sparklines-small, word-sized data graphics that allow meta-information to be visually presented in-line with document text. In accordance with Edward Tufte's definition, sparklines are traditionally placed directly before or after words in the text. We describe alternative placements that permit a wider range of word-scale graphics and more flexible integration with text layouts. These alternative placements include positioning visualizations between lines, within additional vertical and horizontal space in the document, and as interactive overlays on top of the text. Each strategy changes the dimensions of the space available to display the visualizations, as well as the degree to which the text must be adjusted or reflowed to accommodate them. We provide an illustrated design space of placement options for word-scale visualizations and identify six important variables that control the placement of the graphics and the level of disruption of the source text. We also contribute a quantitative analysis that highlights the effect of different placements on readability and text disruption. Finally, we use this analysis to propose guidelines to support the design and placement of word-scale visualizations.	Pascal Goffin;Wesley Willett;Jean-Daniel Fekete;Petra Isenberg	;;;	10.1109/TVCG.2013.192;10.1109/TVCG.2006.163;10.1109/TVCG.2012.196;10.1109/TVCG.2011.185;10.1109/TVCG.2007.70589;10.1109/TVCG.2011.183;10.1109/TVCG.2013.120;10.1109/TVCG.2010.194;10.1109/INFVIS.2005.1532144	Information visualization, text visualization, sparklines, glyphs, design space, word-scale visualizations	
InfoVis	2014	Effects of Presentation Mode and Pace Control on Performance in Image Classification	10.1109/TVCG.2014.2346437	http://dx.doi.org/10.1109/TVCG.2014.2346437	2301	2309	J	A common task in visualization is to quickly find interesting items in large sets. When appropriate metadata is missing, automatic queries are impossible and users have to inspect all elements visually. We compared two fundamentally different, but obvious display modes for this task and investigated the difference with respect to effectiveness, efficiency, and satisfaction. The static mode is based on the page metaphor and presents successive pages with a static grid of items. The moving mode is based on the conveyor belt metaphor and lets a grid of items slide though the screen in a continuous flow. In our evaluation, we applied both modes to the common task of browsing images. We performed two experiments where 18 participants had to search for certain target images in a large image collection. The number of shown images per second (pace) was predefined in the first experiment, and under user control in the second one. We conclude that at a fixed pace, the mode has no significant impact on the recall. The perceived pace is generally slower for moving mode, which causes users to systematically choose for a faster real pace than in static mode at the cost of recall, keeping the average number of target images found per second equal for both modes.	Paul van der Corput;Jarke J. van Wijk	;		RSVP, image classification, image browsing, multimedia visualization	
InfoVis	2014	Multivariate Network Exploration and Presentation: From Detail to Overview via Selections and Aggregations	10.1109/TVCG.2014.2346441	http://dx.doi.org/10.1109/TVCG.2014.2346441	2310	2319	J	Network data is ubiquitous; e-mail traffic between persons, telecommunication, transport and financial networks are some examples. Often these networks are large and multivariate, besides the topological structure of the network, multivariate data on the nodes and links is available. Currently, exploration and analysis methods are focused on a single aspect; the network topology or the multivariate data. In addition, tools and techniques are highly domain specific and require expert knowledge. We focus on the non-expert user and propose a novel solution for multivariate network exploration and analysis that tightly couples structural and multivariate analysis. In short, we go from Detail to Overview via Selections and Aggregations (DOSA): users are enabled to gain insights through the creation of selections of interest (manually or automatically), and producing high-level, infographic-style overviews simultaneously. Finally, we present example explorations on real-world datasets that demonstrate the effectiveness of our method for the exploration and understanding of multivariate networks where presentation of findings comes for free.	Stef van den Elzen;Jarke J. van Wijk	Dept. of Mathematic & Comput. Sci., Eindhoven Univ. of Technol., Eindhoven, Netherlands|c|;	10.1109/VISUAL.1995.485139;10.1109/INFVIS.2003.1249008;10.1109/TVCG.2006.122;10.1109/TVCG.2009.145;10.1109/TVCG.2013.223;10.1109/VAST.2007.4389013;10.1109/VISUAL.1994.346302;10.1109/TVCG.2007.70589;10.1109/TVCG.2008.153;10.1109/TVCG.2009.108;10.1109/TVCG.2006.166;10.1109/TVCG.2006.147	Multivariate Networks, Selections of Interest, Interaction, Direct Manipulation	
InfoVis	2014	GLO-STIX: Graph-Level Operations for Specifying Techniques and Interactive eXploration	10.1109/TVCG.2014.2346444	http://dx.doi.org/10.1109/TVCG.2014.2346444	2320	2328	J	The field of graph visualization has produced a wealth of visualization techniques for accomplishing a variety of analysis tasks. Therefore analysts often rely on a suite of different techniques, and visual graph analysis application builders strive to provide this breadth of techniques. To provide a holistic model for specifying network visualization techniques (as opposed to considering each technique in isolation) we present the Graph-Level Operations (GLO) model. We describe a method for identifying GLOs and apply it to identify five classes of GLOs, which can be flexibly combined to re-create six canonical graph visualization techniques. We discuss advantages of the GLO model, including potentially discovering new, effective network visualization techniques and easing the engineering challenges of building multi-technique graph visualization applications. Finally, we implement the GLOs that we identified into the GLO-STIX prototype system that enables an analyst to interactively explore a graph by applying GLOs.	Charles D. Stolper;Minsuk Kahng;Zhiyuan Lin 0001;Florian Foerster;Aakash Goel;John T. Stasko;Duen Horng Chau	Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;;;;;;	10.1109/TVCG.2008.137;10.1109/VAST.2011.6102441;10.1109/TVCG.2010.144;10.1109/TVCG.2008.135;10.1109/TVCG.2007.70582;10.1109/VAST.2011.6102440;10.1109/INFVIS.2002.1173155;10.1109/TVCG.2006.147;10.1109/TVCG.2010.205;10.1109/INFVIS.1997.636793;10.1109/TVCG.2011.233;10.1109/TVCG.2011.185;10.1109/TVCG.2006.166;10.1109/TVCG.2009.108;10.1109/TVCG.2013.192	Graph-level operations, graph visualization, visualization technique specification, graph analysis, information visualization	
InfoVis	2014	TenniVis: Visualization for Tennis Match Analysis	10.1109/TVCG.2014.2346445	http://dx.doi.org/10.1109/TVCG.2014.2346445	2339	2348	J	Existing research efforts into tennis visualization have primarily focused on using ball and player tracking data to enhance professional tennis broadcasts and to aid coaches in helping their students. Gathering and analyzing this data typically requires the use of an array of synchronized cameras, which are expensive for non-professional tennis matches. In this paper, we propose TenniVis, a novel tennis match visualization system that relies entirely on data that can be easily collected, such as score, point outcomes, point lengths, service information, and match videos that can be captured by one consumer-level camera. It provides two new visualizations to allow tennis coaches and players to quickly gain insights into match performance. It also provides rich interactions to support ad hoc hypothesis development and testing. We first demonstrate the usefulness of the system by analyzing the 2007 Australian Open men's singles final. We then validate its usability by two pilot user studies where two college tennis coaches analyzed the matches of their own players. The results indicate that useful insights can quickly be discovered and ad hoc hypotheses based on these insights can conveniently be tested through linked match videos.	Tom Polk;Jing Yang;Yueqi Hu;Ye Zhao	Univ. of North Carolina at Charlotte, Charlotte, NC, USA|c|;;;	10.1109/TVCG.2012.263;10.1109/TVCG.2013.192;10.1109/VISUAL.2001.964496;10.1109/INFVIS.1996.559229;10.1109/INFVIS.2002.1173148	Visual knowledge discovery, sports analytics, tennis visualization	
InfoVis	2014	The Effects of Interactive Latency on Exploratory Visual Analysis	10.1109/TVCG.2014.2346452	http://dx.doi.org/10.1109/TVCG.2014.2346452	2122	2131	J	To support effective exploration, it is often stated that interactive visualizations should provide rapid response times. However, the effects of interactive latency on the process and outcomes of exploratory visual analysis have not been systematically studied. We present an experiment measuring user behavior and knowledge discovery with interactive visualizations under varying latency conditions. We observe that an additional delay of 500ms incurs significant costs, decreasing user activity and data set coverage. Analyzing verbal data from think-aloud protocols, we find that increased latency reduces the rate at which users make observations, draw generalizations and generate hypotheses. Moreover, we note interaction effects in which initial exposure to higher latencies leads to subsequently reduced performance in a low-latency setting. Overall, increased latency causes users to shift exploration strategy, in turn affecting performance. We discuss how these results can inform the design of interactive analysis tools.	Zhicheng Liu;Jeffrey Heer	;	10.1109/TVCG.2010.177	Interaction, latency, exploratory analysis, interactive visualization, scalability, user performance, verbal analysis	
InfoVis	2014	LiveGantt: Interactively Visualizing a Large Manufacturing Schedule	10.1109/TVCG.2014.2346454	http://dx.doi.org/10.1109/TVCG.2014.2346454	2329	2338	J	In this paper, we introduce LiveGantt as a novel interactive schedule visualization tool that helps users explore highly-concurrent large schedules from various perspectives. Although a Gantt chart is the most common approach to illustrate schedules, currently available Gantt chart visualization tools suffer from limited scalability and lack of interactions. LiveGantt is built with newly designed algorithms and interactions to improve conventional charts with better scalability, explorability, and reschedulability. It employs resource reordering and task aggregation to display the schedules in a scalable way. LiveGantt provides four coordinated views and filtering techniques to help users explore and interact with the schedules in more flexible ways. In addition, LiveGantt is equipped with an efficient rescheduler to allow users to instantaneously modify their schedules based on their scheduling experience in the fields. To assess the usefulness of the application of LiveGantt, we conducted a case study on manufacturing schedule data with four industrial engineering researchers. Participants not only grasped an overview of a schedule but also explored the schedule from multiple perspectives to make enhancements.	Jaemin Jo;Jaeseok Huh;Jonghun Park;Bo Hyoung Kim;Jinwook Seo	Seoul Nat. Univ., Seoul, South Korea|c|;;;;	10.1109/TVCG.2013.200;10.1109/TVCG.2012.213;10.1109/TVCG.2009.117;10.1109/TVCG.2012.225	Schedule visualization, event sequence visualization, simplification, exploratory interactions, simulation	
InfoVis	2014	Combing the Communication Hairball: Visualizing Parallel Execution Traces using Logical Time	10.1109/TVCG.2014.2346456	http://dx.doi.org/10.1109/TVCG.2014.2346456	2349	2358	J	With the continuous rise in complexity of modern supercomputers, optimizing the performance of large-scale parallel programs is becoming increasingly challenging. Simultaneously, the growth in scale magnifies the impact of even minor inefficiencies - potentially millions of compute hours and megawatts in power consumption can be wasted on avoidable mistakes or sub-optimal algorithms. This makes performance analysis and optimization critical elements in the software development process. One of the most common forms of performance analysis is to study execution traces, which record a history of per-process events and interprocess messages in a parallel application. Trace visualizations allow users to browse this event history and search for insights into the observed performance behavior. However, current visualizations are difficult to understand even for small process counts and do not scale gracefully beyond a few hundred processes. Organizing events in time leads to a virtually unintelligible conglomerate of interleaved events and moderately high process counts overtax even the largest display. As an alternative, we present a new trace visualization approach based on transforming the event history into logical time inferred directly from happened-before relationships. This emphasizes the code's structural behavior, which is much more familiar to the application developer. The original timing data, or other information, is then encoded through color, leading to a more intuitive visualization. Furthermore, we use the discrete nature of logical timelines to cluster processes according to their local behavior leading to a scalable visualization of even long traces on large process counts. We demonstrate our system using two case studies on large-scale parallel codes.	Katherine E. Isaacs;Peer-Timo Bremer;Ilir Jusufi;Todd Gamblin;Abhinav Bhatele;Martin Schulz 0001;Bernd Hamann	Univ. of California, Davis, Davis, CA, USA|c|;;;;;;	10.1109/TVCG.2012.286;10.1109/TVCG.2009.196;10.1109/TVCG.2011.199;10.1109/TVCG.2013.200	Information visualization, software visualization, timelines, traces, performance analysis	
InfoVis	2014	Learning Perceptual Kernels for Visualization Design	10.1109/TVCG.2014.2346978	http://dx.doi.org/10.1109/TVCG.2014.2346978	1933	1942	J	Visualization design can benefit from careful consideration of perception, as different assignments of visual encoding variables such as color, shape and size affect how viewers interpret data. In this work, we introduce perceptual kernels: distance matrices derived from aggregate perceptual judgments. Perceptual kernels represent perceptual differences between and within visual variables in a reusable form that is directly applicable to visualization evaluation and automated design. We report results from crowd-sourced experiments to estimate kernels for color, shape, size and combinations thereof. We analyze kernels estimated using five different judgment types-including Likert ratings among pairs, ordinal triplet comparisons, and manual spatial arrangement-and compare them to existing perceptual models. We derive recommendations for collecting perceptual similarities, and then demonstrate how the resulting kernels can be applied to automate visualization design decisions.	Çagatay Demiralp;Michael S. Bernstein;Jeffrey Heer	Stanford Univ., Stanford, CA, USA|c|;;	10.1109/TVCG.2010.186;10.1109/TVCG.2006.163;10.1109/TVCG.2007.70594;10.1109/TVCG.2011.167;10.1109/TVCG.2007.70583;10.1109/TVCG.2008.125;10.1109/TVCG.2010.130;10.1109/TVCG.2007.70539	Visualization, design, encoding, perception, model, crowdsourcing, automated visualization, visual embedding	
InfoVis	2014	Ranking Visualizations of Correlation Using Weber's Law	10.1109/TVCG.2014.2346979	http://dx.doi.org/10.1109/TVCG.2014.2346979	1943	1952	J	Despite years of research yielding systems and guidelines to aid visualization design, practitioners still face the challenge of identifying the best visualization for a given dataset and task. One promising approach to circumvent this problem is to leverage perceptual laws to quantitatively evaluate the effectiveness of a visualization design. Following previously established methodologies, we conduct a large scale (n = 1687) crowdsourced experiment to investigate whether the perception of correlation in nine commonly used visualizations can be modeled using Weber's law. The results of this experiment contribute to our understanding of information visualization by establishing that: (1) for all tested visualizations, the precision of correlation judgment could be modeled by Weber's law, (2) correlation judgment precision showed striking variation between negatively and positively correlated data, and (3) Weber models provide a concise means to quantify, compare, and rank the perceptual precision afforded by a visualization.	Lane Harrison;Fumeng Yang;Steven Franconeri;Remco Chang	Tufts Univ., Medford, MA, USA|c|;;;	10.1109/TVCG.2013.187;10.1109/TVCG.2009.111;10.1109/TVCG.2007.70594	Perception, Visualization, Evaluation	
InfoVis	2014	The relation between visualization size, grouping, and user performance	10.1109/TVCG.2014.2346983	http://dx.doi.org/10.1109/TVCG.2014.2346983	1953	1962	J	In this paper we make the following contributions: (1) we describe how the grouping, quantity, and size of visual marks affects search time based on the results from two experiments; (2) we report how search performance relates to self-reported difficulty in finding the target for different display types; and (3) we present design guidelines based on our findings to facilitate the design of effective visualizations. Both Experiment 1 and 2 asked participants to search for a unique target in colored visualizations to test how the grouping, quantity, and size of marks affects user performance. In Experiment 1, the target square was embedded in a grid of squares and in Experiment 2 the target was a point in a scatterplot. Search performance was faster when colors were spatially grouped than when they were randomly arranged. The quantity of marks had little effect on search time for grouped displays (ÔÇ£pop-outÔÇØ), but increasing the quantity of marks slowed reaction time for random displays. Regardless of color layout (grouped vs. random), response times were slowest for the smallest mark size and decreased as mark size increased to a point, after which response times plateaued. In addition to these two experiments we also include potential application areas, as well as results from a small case study where we report preliminary findings that size may affect how users infer how visualizations should be used. We conclude with a list of design guidelines that focus on how to best create visualizations based on grouping, quantity, and size of visual marks.	Connor Gramazio;Karen B. Schloss;David H. Laidlaw	Dept. of Comput. Sci., Brown Univ., Providence, RI, USA|c|;;	10.1109/TVCG.2012.233;10.1109/TVCG.2012.196;10.1109/TVCG.2011.185;10.1109/VAST.2007.4389009;10.1109/TVCG.2013.187;10.1109/TVCG.2011.175;10.1109/TVCG.2013.183;10.1109/TVCG.2006.184;10.1109/TVCG.2010.186;10.1109/VISUAL.1996.568118;10.1109/TVCG.2012.220;10.1109/TVCG.2013.170;10.1109/TVCG.2013.234	information visualization, graphical perception, size, layout	
InfoVis	2014	A Principled Way of Assessing Visualization Literacy	10.1109/TVCG.2014.2346984	http://dx.doi.org/10.1109/TVCG.2014.2346984	1963	1972	J	We describe a method for assessing the visualization literacy (VL) of a user. Assessing how well people understand visualizations has great value for research (e. g., to avoid confounds), for design (e. g., to best determine the capabilities of an audience), for teaching (e. g., to assess the level of new students), and for recruiting (e. g., to assess the level of interviewees). This paper proposes a method for assessing VL based on Item Response Theory. It describes the design and evaluation of two VL tests for line graphs, and presents the extension of the method to bar charts and scatterplots. Finally, it discusses the reimplementation of these tests for fast, effective, and scalable web-based use.	Jeremy Boy;Ronald A. Rensink;Enrico Bertini;Jean-Daniel Fekete	EnsadLab, Telecom ParisTech, Paris, France|c|;;;	10.1109/TVCG.2011.160	Literacy, Visualization literacy, Rasch Model, Item Response Theory	
InfoVis	2014	Reinforcing Visual Grouping Cues to Communicate Complex Informational Structure	10.1109/TVCG.2014.2346998	http://dx.doi.org/10.1109/TVCG.2014.2346998	1973	1982	J	In his book Multimedia Learning [7], Richard Mayer asserts that viewers learn best from imagery that provides them with cues to help them organize new information into the correct knowledge structures. Designers have long been exploiting the Gestalt laws of visual grouping to deliver viewers those cues using visual hierarchy, often communicating structures much more complex than the simple organizations studied in psychological research. Unfortunately, designers are largely practical in their work, and have not paused to build a complex theory of structural communication. If we are to build a tool to help novices create effective and well structured visuals, we need a better understanding of how to create them. Our work takes a first step toward addressing this lack, studying how five of the many grouping cues (proximity, color similarity, common region, connectivity, and alignment) can be effectively combined to communicate structured text and imagery from real world examples. To measure the effectiveness of this structural communication, we applied a digital version of card sorting, a method widely used in anthropology and cognitive science to extract cognitive structures. We then used tree edit distance to measure the difference between perceived and communicated structures. Our most significant findings are: 1) with careful design, complex structure can be communicated clearly; 2) communicating complex structure is best done with multiple reinforcing grouping cues; 3) common region (use of containers such as boxes) is particularly effective at communicating structure; and 4) alignment is a weak structural communicator.	Juhee Bae;Benjamin Watson	North Carolina State Univ., Raleigh, NC, USA|c|;	10.1109/TVCG.2010.174;10.1109/INFVIS.2003.1249005	Visual grouping, visual hierarchy, gestalt principles, perception, visual communication	
InfoVis	2014	Activity Sculptures: Exploring the Impact of Physical Visualizations on Running Activity	10.1109/TVCG.2014.2352953	http://dx.doi.org/10.1109/TVCG.2014.2352953	2201	2210	J	Data sculptures are a promising type of visualizations in which data is given a physical form. In the past, they have mostly been used for artistic, communicative or educational purposes, and designers of data sculptures argue that in such situations, physical visualizations can be more enriching than pixel-based visualizations. We present the design of Activity Sculptures: data sculptures of running activity. In a three-week field study we investigated the impact of the sculptures on 14 participants' running activity, the personal and social behaviors generated by the sculptures, as well as participants' experiences when receiving these individual physical tokens generated from the specific data of their runs. The physical rewards generated curiosity and personal experimentation but also social dynamics such as discussion on runs or envy/competition. We argue that such passive (or calm) visualizations can complement nudging and other mechanisms of persuasion with a more playful and reflective look at ones' activity.	Simon Stusak;Aurélien Tabard;Franziska Sauka;Rohit Ashok Khot;Andreas Butz	Univ. of Munich, Munich, Germany|c|;;;;	10.1109/TVCG.2007.70541;10.1109/INFVIS.2003.1249031;10.1109/TVCG.2013.134	Physical Visualizations, Activity Sculptures, Physical Activity, Data Sculptures, Behavioral Change	
SciVis	2014	Predicate-Based Focus-and-Context Visualization for 3D Ultrasound	10.1109/TVCG.2014.2346317	http://dx.doi.org/10.1109/TVCG.2014.2346317	2379	2387	J	Direct volume visualization techniques offer powerful insight into volumetric medical images and are part of the clinical routine for many applications. Up to now, however, their use is mostly limited to tomographic imaging modalities such as CT or MRI. With very few exceptions, such as fetal ultrasound, classic volume rendering using one-dimensional intensity-based transfer functions fails to yield satisfying results in case of ultrasound volumes. This is particularly due its gradient-like nature, a high amount of noise and speckle, and the fact that individual tissue types are rather characterized by a similar texture than by similar intensity values. Therefore, clinicians still prefer to look at 2D slices extracted from the ultrasound volume. In this work, we present an entirely novel approach to the classification and compositing stage of the volume rendering pipeline, specifically designed for use with ultrasonic images. We introduce point predicates as a generic formulation for integrating the evaluation of not only low-level information like local intensity or gradient, but also of high-level information, such as non-local image features or even anatomical models. Thus, we can successfully filter clinically relevant from non-relevant information. In order to effectively reduce the potentially high dimensionality of the predicate configuration space, we propose the predicate histogram as an intuitive user interface. This is augmented by a scribble technique to provide a comfortable metaphor for selecting predicates of interest. Assigning importance factors to the predicates allows for focus-and-context visualization that ensures to always show important (focus) regions of the data while maintaining as much context information as possible. Our method naturally integrates into standard ray casting algorithms and yields superior results in comparison to traditional methods in terms of visualizing a specific target anatomy in ultrasound volumes.	Christian Schulte zu Berge;Maximilian Baust;Ankur Kapoor;Nassir Navab	Dept. of Comput.-Aided Med. Procedures, Tech. Univ. Munchen, Mu&#x0308;nchen, Germany|c|;;;	10.1109/TVCG.2006.148;10.1109/TVCG.2006.124;10.1109/TVCG.2013.189;10.1109/VISUAL.2003.1250413;10.1109/VISUAL.2001.964539	Direct Volume Rendering, Ultrasound, Classification, Predicate Function, User Interface	
SciVis	2014	ViSlang: A System for Interpreted Domain-Specific Languages for Scientific Visualization	10.1109/TVCG.2014.2346318	http://dx.doi.org/10.1109/TVCG.2014.2346318	2388	2396	J	Researchers from many domains use scientific visualization in their daily practice. Existing implementations of algorithms usually come with a graphical user interface (high-level interface), or as software library or source code (low-level interface). In this paper we present a system that integrates domain-specific languages (DSLs) and facilitates the creation of new DSLs. DSLs provide an effective interface for domain scientists avoiding the difficulties involved with low-level interfaces and at the same time offering more flexibility than high-level interfaces. We describe the design and implementation of ViSlang, an interpreted language specifically tailored for scientific visualization. A major contribution of our design is the extensibility of the ViSlang language. Novel DSLs that are tailored to the problems of the domain can be created and integrated into ViSlang. We show that our approach can be added to existing user interfaces to increase the flexibility for expert users on demand, but at the same time does not interfere with the user experience of novice users. To demonstrate the flexibility of our approach we present new DSLs for volume processing, querying and visualization. We report the implementation effort for new DSLs and compare our approach with Matlab and Python implementations in terms of run-time performance.	Peter Rautek;Stefan Bruckner;Eduard Gröller;Markus Hadwiger	KAUST, Thuwal, Saudi Arabia|c|;;;	10.1109/VISUAL.2005.1532792;10.1109/VISUAL.1992.235219;10.1109/TVCG.2009.174;10.1109/TVCG.2014.2346322;10.1109/VISUAL.2004.95;10.1109/TVCG.2011.185;10.1109/VISUAL.2005.1532788;10.1109/VISUAL.1992.235202;10.1109/TVCG.2008.184	Domain-specific languages, Volume visualization, Volume visualization framework	
SciVis	2014	Interactive Progressive Visualization with Space-Time Error Control	10.1109/TVCG.2014.2346319	http://dx.doi.org/10.1109/TVCG.2014.2346319	2397	2406	J	We present a novel scheme for progressive rendering in interactive visualization. Static settings with respect to a certain image quality or frame rate are inherently incapable of delivering both high frame rates for rapid changes and high image quality for detailed investigation. Our novel technique flexibly adapts by steering the visualization process in three major degrees of freedom: when to terminate the refinement of a frame in the background and start a new one, when to display a frame currently computed, and how much resources to consume. We base these decisions on the correlation of the errors due to insufficient sampling and response delay, which we estimate separately using fast yet expressive heuristics. To automate the configuration of the steering behavior, we employ offline video quality analysis. We provide an efficient implementation of our scheme for the application of volume raycasting, featuring integrated GPU-accelerated image reconstruction and error estimation. Our implementation performs an integral handling of the changes due to camera transforms, transfer function adaptations, as well as the progression of the data to in time. Finally, the overall technique is evaluated with an expert study.	Steffen Frey;Filip Sadlo;Kwan-Liu Ma;Thomas Ertl	Univ. of Stuttgart, Stuttgart, Germany|c|;;;	10.1109/VISUAL.1994.346321;10.1109/TVCG.2013.126;10.1109/VISUAL.2000.885702;10.1109/TVCG.2009.114	Progressive visualization, error-based frame control, interactive volume raycasting	
SciVis	2014	Vivaldi: A Domain-Specific Language for Volume Processing and Visualization on Distributed Heterogeneous Systems	10.1109/TVCG.2014.2346322	http://dx.doi.org/10.1109/TVCG.2014.2346322	2407	2416	J	As the size of image data from microscopes and telescopes increases, the need for high-throughput processing and visualization of large volumetric data has become more pressing. At the same time, many-core processors and GPU accelerators are commonplace, making high-performance distributed heterogeneous computing systems affordable. However, effectively utilizing GPU clusters is difficult for novice programmers, and even experienced programmers often fail to fully leverage the computing power of new parallel architectures due to their steep learning curve and programming complexity. In this paper, we propose Vivaldi, a new domain-specific language for volume processing and visualization on distributed heterogeneous computing systems. Vivaldi's Python-like grammar and parallel processing abstractions provide flexible programming tools for non-experts to easily write high-performance parallel computing code. Vivaldi provides commonly used functions and numerical operators for customized visualization and high-throughput image processing applications. We demonstrate the performance and usability of Vivaldi on several examples ranging from volume rendering to image segmentation.	Hyungsuk Choi;Woohyuk Choi;Tran Minh Quan;David G. C. Hildebrand;Hanspeter Pfister;Won-Ki Jeong	;;;;;	10.1109/VISUAL.2004.95	Domain-specific language, volume rendering, GPU computing, distributed heterogeneous systems	
SciVis	2014	Sparse PDF Volumes for Consistent Multi-Resolution Volume Rendering	10.1109/TVCG.2014.2346324	http://dx.doi.org/10.1109/TVCG.2014.2346324	2417	2426	J	This paper presents a new multi-resolution volume representation called sparse pdf volumes, which enables consistent multi-resolution volume rendering based on probability density functions (pdfs) of voxel neighborhoods. These pdfs are defined in the 4D domain jointly comprising the 3D volume and its 1D intensity range. Crucially, the computation of sparse pdf volumes exploits data coherence in 4D, resulting in a sparse representation with surprisingly low storage requirements. At run time, we dynamically apply transfer functions to the pdfs using simple and fast convolutions. Whereas standard low-pass filtering and down-sampling incur visible differences between resolution levels, the use of pdfs facilitates consistent results independent of the resolution level used. We describe the efficient out-of-core computation of large-scale sparse pdf volumes, using a novel iterative simplification procedure of a mixture of 4D Gaussians. Finally, our data structure is optimized to facilitate interactive multi-resolution volume rendering on GPUs.	Ronell Sicat;Jens H. Krüger;Torsten Möller;Markus Hadwiger	King Abdullah Univ. of Sci. & Technol. (KAUST), Thuwal, Saudi Arabia|c|;;;	10.1109/TVCG.2006.143;10.1109/TVCG.2012.240;10.1109/VISUAL.1999.809908	Multi-resolution representations, sparse approximation, pursuit algorithms, large-scale volume rendering	
SciVis	2014	Multiscale Symmetry Detection in Scalar Fields by Clustering Contours	10.1109/TVCG.2014.2346332	http://dx.doi.org/10.1109/TVCG.2014.2346332	2427	2436	J	The complexity in visualizing volumetric data often limits the scope of direct exploration of scalar fields. Isocontour extraction is a popular method for exploring scalar fields because of its simplicity in presenting features in the data. In this paper, we present a novel representation of contours with the aim of studying the similarity relationship between the contours. The representation maps contours to points in a high-dimensional transformation-invariant descriptor space. We leverage the power of this representation to design a clustering based algorithm for detecting symmetric regions in a scalar field. Symmetry detection is a challenging problem because it demands both segmentation of the data and identification of transformation invariant segments. While the former task can be addressed using topological analysis of scalar fields, the latter requires geometry based solutions. Our approach combines the two by utilizing the contour tree for segmenting the data and the descriptor space for determining transformation invariance. We discuss two applications, query driven exploration and asymmetry visualization, that demonstrate the effectiveness of the approach.	Dilip Mathew Thomas;Vijay Natarajan	Dept. of Comput. Sci. & Autom., Indian Inst. of Sci., Bangalore, India|c|;	10.1109/TVCG.2013.142;10.1109/VISUAL.1999.809869;10.1109/TVCG.2006.149;10.1109/TVCG.2011.236;10.1109/TVCG.2008.143;10.1109/TVCG.2011.258;10.1109/TVCG.2013.148	Scalar field visualization, symmetry detection, contour tree, data exploration	
SciVis	2014	Low-Pass Filtered Volumetric Shadows	10.1109/TVCG.2014.2346333	http://dx.doi.org/10.1109/TVCG.2014.2346333	2437	2446	J	We present a novel and efficient method to compute volumetric soft shadows for interactive direct volume visualization to improve the perception of spatial depth. By direct control of the softness of volumetric shadows, disturbing visual patterns due to hard shadows can be avoided and users can adapt the illumination to their personal and application-specific requirements. We compute the shadowing of a point in the data set by employing spatial filtering of the optical depth over a finite area patch pointing toward each light source. Conceptually, the area patch spans a volumetric region that is sampled with shadow rays; afterward, the resulting optical depth values are convolved with a low-pass filter on the patch. In the numerical computation, however, to avoid expensive shadow ray marching, we show how to align and set up summed area tables for both directional and point light sources. Once computed, the summed area tables enable efficient evaluation of soft shadows for each point in constant time without shadow ray marching and the softness of the shadows can be controlled interactively. We integrated our method in a GPU-based volume renderer with ray casting from the camera, which offers interactive control of the transfer function, light source positions, and viewpoint, for both static and time-dependent data sets. Our results demonstrate the benefit of soft shadows for visualization to achieve user-controlled illumination with many-point lighting setups for improved perception combined with high rendering speed.	Marco Ament;Filip Sadlo;Carsten Dachsbacher;Daniel Weiskopf	Karlsruhe Inst. of Technol., Karlsruhe, Germany|c|;;;	10.1109/TVCG.2013.172;10.1109/TVCG.2013.129;10.1109/TVCG.2011.211;10.1109/VISUAL.2003.1250394;10.1109/TVCG.2012.232;10.1109/TVCG.2011.161;10.1109/TVCG.2011.198;10.1109/VISUAL.2002.1183764	Direct volume rendering, volume illumination, soft shadows, filtered shadows, summed area table	
SciVis	2014	Boundary Aware Reconstruction of Scalar Fields	10.1109/TVCG.2014.2346351	http://dx.doi.org/10.1109/TVCG.2014.2346351	2447	2455	J	In visualization, the combined role of data reconstruction and its classification plays a crucial role. In this paper we propose a novel approach that improves classification of different materials and their boundaries by combining information from the classifiers at the reconstruction stage. Our approach estimates the targeted materials' local support before performing multiple material-specific reconstructions that prevent much of the misclassification traditionally associated with transitional regions and transfer function (TF) design. With respect to previously published methods our approach offers a number of improvements and advantages. For one, it does not rely on TFs acting on derivative expressions, therefore it is less sensitive to noisy data and the classification of a single material does not depend on specialized TF widgets or specifying regions in a multidimensional TF. Additionally, improved classification is attained without increasing TF dimensionality, which promotes scalability to multivariate data. These aspects are also key in maintaining low interaction complexity. The results are simple-to-achieve visualizations that better comply with the user's understanding of discrete features within the studied object.	Stefan Lindholm;Daniel Jönsson;Charles D. Hansen;Anders Ynnerman	Dept. of Sci. & Technol., Linkoping Univ., Linko&#x0308;ping, Sweden|c|;;;	10.1109/TVCG.2007.70518;10.1109/TVCG.2008.186;10.1109/VISUAL.2003.1250386;10.1109/VISUAL.2005.1532807;10.1109/VISUAL.1998.745311;10.1109/VISUAL.2003.1250387	Reconstruction, signal processing, kernel regression, volume rendering	
SciVis	2014	Attractive Flicker: Guiding Attention in Dynamic Narrative Visualizations	10.1109/TVCG.2014.2346352	http://dx.doi.org/10.1109/TVCG.2014.2346352	2456	2465	J	Focus-context techniques provide visual guidance in visualizations by giving strong visual prominence to elements of interest while the context is suppressed. However, finding a visual feature to enhance for the focus to pop out from its context in a large dynamic scene, while leading to minimal visual deformation and subjective disturbance, is challenging. This paper proposes Attractive Flicker, a novel technique for visual guidance in dynamic narrative visualizations. We first show that flicker is a strong visual attractor in the entire visual field, without distorting, suppressing, or adding any scene elements. The novel aspect of our Attractive Flicker technique is that it consists of two signal stages: The first ÔÇ£orientation stageÔÇØ is a short but intensive flicker stimulus to attract the attention to elements of interest. Subsequently, the intensive flicker is reduced to a minimally disturbing luminance oscillation (ÔÇ£engagement stageÔÇØ) as visual support to keep track of the focus elements. To find a good trade-off between attraction effectiveness and subjective annoyance caused by flicker, we conducted two perceptual studies to find suitable signal parameters. We showcase Attractive Flicker with the parameters obtained from the perceptual statistics in a study of molecular interactions. With Attractive Flicker, users were able to easily follow the narrative of the visualization on a large display, while the flickering of focus elements was not disturbing when observing the context.	Manuela Waldner;Mathieu Le Muzic;Matthias Bernhard;Werner Purgathofer;Ivan Viola	;;;;	10.1109/TVCG.2009.185;10.1109/VISUAL.1995.480802;10.1109/VISUAL.2005.1532838;10.1109/TVCG.2010.179;10.1109/TVCG.2011.183;10.1109/TVCG.2006.174	Visual attention, flicker, narrative visualization	
SciVis	2014	Design and Evaluation of Interactive Proofreading Tools for Connectomics	10.1109/TVCG.2014.2346371	http://dx.doi.org/10.1109/TVCG.2014.2346371	2466	2475	J	Proofreading refers to the manual correction of automatic segmentations of image data. In connectomics, electron microscopy data is acquired at nanometer-scale resolution and results in very large image volumes of brain tissue that require fully automatic segmentation algorithms to identify cell boundaries. However, these algorithms require hundreds of corrections per cubic micron of tissue. Even though this task is time consuming, it is fairly easy for humans to perform corrections through splitting, merging, and adjusting segments during proofreading. In this paper we present the design and implementation of Mojo, a fully-featured single-user desktop application for proofreading, and Dojo, a multi-user web-based application for collaborative proofreading. We evaluate the accuracy and speed of Mojo, Dojo, and Raveler, a proofreading tool from Janelia Farm, through a quantitative user study. We designed a between-subjects experiment and asked non-experts to proofread neurons in a publicly available connectomics dataset. Our results show a significant improvement of corrections using web-based Dojo, when given the same amount of time. In addition, all participants using Dojo reported better usability. We discuss our findings and provide an analysis of requirements for designing visual proofreading software.	Daniel Haehn;Seymour Knowles-Barley;Mike Roberts;Johanna Beyer;Narayanan Kasthuri;Jeff Lichtman;Hanspeter Pfister	Sch. of Eng. & Appl. Sci., Harvard Univ., Cambridge, MA, USA|c|;;;;;;	10.1109/TVCG.2013.142;10.1109/TVCG.2012.240	Proofreading, Segmentation, Connectomics, Quantitative Evaluation	
SciVis	2014	Characterizing Molecular Interactions in Chemical Systems	10.1109/TVCG.2014.2346403	http://dx.doi.org/10.1109/TVCG.2014.2346403	2476	2485	J	Interactions between atoms have a major influence on the chemical properties of molecular systems. While covalent interactions impose the structural integrity of molecules, noncovalent interactions govern more subtle phenomena such as protein folding, bonding or self assembly. The understanding of these types of interactions is necessary for the interpretation of many biological processes and chemical design tasks. While traditionally the electron density is analyzed to interpret the quantum chemistry of a molecular system, noncovalent interactions are characterized by low electron densities and only slight variations of them - challenging their extraction and characterization. Recently, the signed electron density and the reduced gradient, two scalar fields derived from the electron density, have drawn much attention in quantum chemistry since they enable a qualitative visualization of these interactions even in complex molecular systems and experimental measurements. In this work, we present the first combinatorial algorithm for the automated extraction and characterization of covalent and noncovalent interactions in molecular systems. The proposed algorithm is based on a joint topological analysis of the signed electron density and the reduced gradient. Combining the connectivity information of the critical points of these two scalar fields enables to visualize, enumerate, classify and investigate molecular interactions in a robust manner. Experiments on a variety of molecular systems, from simple dimers to proteins or DNA, demonstrate the ability of our technique to robustly extract these interactions and to reveal their structural relations to the atoms and bonds forming the molecules. For simple systems, our analysis corroborates the observations made by the chemists while it provides new visual and quantitative insights on chemical interactions for larger molecular systems.	David Günther;Roberto A. Boto;Juila Contreras-Garcia;Jean-Philip Piquemal;Julien Tierny	Inst. Mines-Telecom, Telecom ParisTech, Paris, France|c|;;;;	10.1109/TVCG.2009.163;10.1109/VISUAL.2004.96;10.1109/VISUAL.2003.1250376;10.1109/TVCG.2008.110;10.1109/TVCG.2009.157;10.1109/TVCG.2011.259;10.1109/TVCG.2007.70578;10.1109/TVCG.2013.158	Molecular Chemistry, Topological Data Analysis, Morse-Smale Complex, Join Tree	
SciVis	2014	Ligand Excluded Surface: A New Type of Molecular Surface	10.1109/TVCG.2014.2346404	http://dx.doi.org/10.1109/TVCG.2014.2346404	2486	2495	J	The most popular molecular surface in molecular visualization is the solvent excluded surface (SES). It provides information about the accessibility of a biomolecule for a solvent molecule that is geometrically approximated by a sphere. During a period of almost four decades, the SES has served for many purposes - including visualization, analysis of molecular interactions and the study of cavities in molecular structures. However, if one is interested in the surface that is accessible to a molecule whose shape differs significantly from a sphere, a different concept is necessary. To address this problem, we generalize the definition of the SES by replacing the probe sphere with the full geometry of the ligand defined by the arrangement of its van der Waals spheres. We call the new surface ligand excluded surface (LES) and present an efficient, grid-based algorithm for its computation. Furthermore, we show that this algorithm can also be used to compute molecular cavities that could host the ligand molecule. We provide a detailed description of its implementation on CPU and GPU. Furthermore, we present a performance and convergence analysis and compare the LES for several molecules, using as ligands either water or small organic molecules.	Norbert Lindow;Daniel Baum;Hans-Christian Hege	Zuse Inst. Berlin, Berlin, Germany|c|;;	10.1109/TVCG.2009.157;10.1109/TVCG.2011.259;10.1109/TVCG.2013.158	Molecular visualization, solvent excluded surface, ligand excluded surface, cavity analysis	
SciVis	2014	ADR - Anatomy-Driven Reformation	10.1109/TVCG.2014.2346405	http://dx.doi.org/10.1109/TVCG.2014.2346405	2496	2505	J	Dedicated visualization methods are among the most important tools of modern computer-aided medical applications. Reformation methods such as Multiplanar Reformation or Curved Planar Reformation have evolved as useful tools that facilitate diagnostic and therapeutic work. In this paper, we present a novel approach that can be seen as a generalization of Multiplanar Reformation to curved surfaces. The main concept is to generate reformatted medical volumes driven by the individual anatomical geometry of a specific patient. This process generates flat views of anatomical structures that facilitate many tasks such as diagnosis, navigation and annotation. Our reformation framework is based on a non-linear as-rigid-as-possible volumetric deformation scheme that uses generic triangular surface meshes as input. To manage inevitable distortions during reformation, we introduce importance maps which allow controlling the error distribution and improving the overall visual quality in areas of elevated interest. Our method seamlessly integrates with well-established concepts such as the slice-based inspection of medical datasets and we believe it can improve the overall efficiency of many medical workflows. To demonstrate this, we additionally present an integrated visualization system and discuss several use cases that substantiate its benefits.	Jan Kretschmer;Grzegorz Soza;Christian Tietjen;Michael Sühling;Bernhard Preim;Marc Stamminger	Dept. of Comput. Graphics, FAU Erlangen, Erlangen, Germany|c|;;;;;	10.1109/VISUAL.2003.1250353;10.1109/TVCG.2013.215;10.1109/VISUAL.2001.964540;10.1109/TVCG.2007.70550;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2003.1250351	Medical Visualization, Volume Reformation, Viewing Algorithms	
SciVis	2014	Combined Visualization of Wall Thickness and Wall Shear Stress for the Evaluation of Aneurysms	10.1109/TVCG.2014.2346406	http://dx.doi.org/10.1109/TVCG.2014.2346406	2506	2515	J	For an individual rupture risk assessment of aneurysms, the aneurysm's wall morphology and hemodynamics provide valuable information. Hemodynamic information is usually extracted via computational fluid dynamic (CFD) simulation on a previously extracted 3D aneurysm surface mesh or directly measured with 4D phase-contrast magnetic resonance imaging. In contrast, a noninvasive imaging technique that depicts the aneurysm wall in vivo is still not available. Our approach comprises an experiment, where intravascular ultrasound (IVUS) is employed to probe a dissected saccular aneurysm phantom, which we modeled from a porcine kidney artery. Then, we extracted a 3D surface mesh to gain the vessel wall thickness and hemodynamic information from a CFD simulation. Building on this, we developed a framework that depicts the inner and outer aneurysm wall with dedicated information about local thickness via distance ribbons. For both walls, a shading is adapted such that the inner wall as well as its distance to the outer wall is always perceivable. The exploration of the wall is further improved by combining it with hemodynamic information from the CFD simulation. Hence, the visual analysis comprises a brushing and linking concept for individual highlighting of pathologic areas. Also, a surface clustering is integrated to provide an automatic division of different aneurysm parts combined with a risk score depending on wall thickness and hemodynamic information. In general, our approach can be employed for vessel visualization purposes where an inner and outer wall has to be adequately represented.	Sylvia Glaßer;Kai Lawonn;Thomas Hoffmann;Martin Skalej;Bernhard Preim	Dept. for Simulation & Graphics, Univ. of Magdeburg, Magdeburg, Germany|c|;;;;	10.1109/TVCG.2012.202;10.1109/TVCG.2007.70550;10.1109/VISUAL.1995.480795;10.1109/TVCG.2011.189	Aneurysm, IVUS, Wall Thickness, Wall Shear Stress, Brushing and Linking, Focus + Context	
SciVis	2014	Visualization of Brain Microstructure Through Spherical Harmonics Illumination of High Fidelity Spatio-Angular Fields	10.1109/TVCG.2014.2346411	http://dx.doi.org/10.1109/TVCG.2014.2346411	2516	2525	J	Diffusion kurtosis imaging (DKI) is gaining rapid adoption in the medical imaging community due to its ability to measure the non-Gaussian property of water diffusion in biological tissues. Compared to traditional diffusion tensor imaging (DTI), DKI can provide additional details about the underlying microstructural characteristics of the neural tissues. It has shown promising results in studies on changes in gray matter and mild traumatic brain injury where DTI is often found to be inadequate. The DKI dataset, which has high-fidelity spatio-angular fields, is difficult to visualize. Glyph-based visualization techniques are commonly used for visualization of DTI datasets; however, due to the rapid changes in orientation, lighting, and occlusion, visually analyzing the much more higher fidelity DKI data is a challenge. In this paper, we provide a systematic way to manage, analyze, and visualize high-fidelity spatio-angular fields from DKI datasets, by using spherical harmonics lighting functions to facilitate insights into the brain microstructure.	Sujal Bista;Jiachen Zhuo;Rao P. Gullapalli;Amitabh Varshney	Univ. of Maryland, College Park, MD, USA|c|;;;	10.1109/TVCG.2013.172;10.1109/TVCG.2007.70602;10.1109/TVCG.2010.199;10.1109/TVCG.2012.231;10.1109/VISUAL.1999.809886;10.1109/VISUAL.2004.62;10.1109/TVCG.2008.162;10.1109/VISUAL.2004.64;10.1109/VISUAL.2004.5;10.1109/TVCG.2011.198;10.1109/TVCG.2008.148	Diffusion Kurtosis Imaging, Diffusion Tensor Imaging, Spatio-Angular Fields, Spherical Harmonics Fields, Tensor Fields	
SciVis	2014	A Robust Parity Test for Extracting Parallel Vectors in 3D	10.1109/TVCG.2014.2346412	http://dx.doi.org/10.1109/TVCG.2014.2346412	2526	2534	J	Parallel vectors (PV), the loci where two vector fields are parallel, are commonly used to represent curvilinear features in 3D for data visualization. Methods for extracting PV usually operate on a 3D grid and start with detecting seed points on a cell face. We propose, to the best of our knowledge, the first provably correct test that determines the parity of the number of PV points on a cell face. The test only needs to sample along the face boundary and works for any choice of the two vector fields. A discretization of the test is described, validated, and compared with existing tests that are also based on boundary sampling. The test can guide PV-extraction algorithms to ensure closed curves wherever the input fields are continuous, which we exemplify in extracting ridges and valleys of scalar functions.	Tao Ju;Minxin Cheng;Xu Wang;Ye Duan	Washington Univ. in St. Louis, St. Louis, MO, USA|c|;;;	10.1109/VISUAL.2002.1183786;10.1109/VISUAL.2005.1532851;10.1109/VISUAL.1999.809896	Parallel vectors, feature curve extraction, ridges and valleys, parity test	
SciVis	2014	Vortex Cores of Inertial Particles	10.1109/TVCG.2014.2346415	http://dx.doi.org/10.1109/TVCG.2014.2346415	2535	2544	J	The cores of massless, swirling particle motion are an indicator for vortex-like behavior in vector fields and to this end, a number of coreline extractors have been proposed in the literature. Though, many practical applications go beyond the study of the vector field. Instead, engineers seek to understand the behavior of inertial particles moving therein, for instance in sediment transport, helicopter brownout and pulverized coal combustion. In this paper, we present two strategies for the extraction of the corelines that inertial particles swirl around, which depend on particle density, particle diameter, fluid viscosity and gravity. The first is to deduce the local swirling behavior from the autonomous inertial motion ODE, which eventually reduces to a parallel vectors operation. For the second strategy, we use a particle density estimation to locate inertial attractors. With this, we are able to extract the cores of swirling inertial particle motion for both steady and unsteady 3D vector fields. We demonstrate our techniques in a number of benchmark data sets, and elaborate on the relation to traditional massless corelines.	Tobias Günther;Holger Theisel	;	10.1109/VISUAL.2005.1532851;10.1109/TVCG.2007.70545;10.1109/TVCG.2010.198;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1998.745296	Inertial particles, flow visualization, vortex cores	
SciVis	2014	FLDA: Latent Dirichlet Allocation Based Unsteady Flow Analysis	10.1109/TVCG.2014.2346416	http://dx.doi.org/10.1109/TVCG.2014.2346416	2545	2554	J	In this paper, we present a novel feature extraction approach called FLDA for unsteady flow fields based on Latent Dirichlet allocation (LDA) model. Analogous to topic modeling in text analysis, in our approach, pathlines and features in a given flow field are defined as documents and words respectively. Flow topics are then extracted based on Latent Dirichlet allocation. Different from other feature extraction methods, our approach clusters pathlines with probabilistic assignment, and aggregates features to meaningful topics at the same time. We build a prototype system to support exploration of unsteady flow field with our proposed LDA-based method. Interactive techniques are also developed to explore the extracted topics and to gain insight from the data. We conduct case studies to demonstrate the effectiveness of our proposed approach.	Fan Hong;Chufan Lai;Hanqi Guo;Enya Shen;Xiaoru Yuan;Sikun Li	Minist. of Educ., Peking Univ., Beijing, China|c|;;;;;	10.1109/TVCG.2008.131;10.1109/TVCG.2010.131;10.1109/TVCG.2011.239;10.1109/TVCG.2006.165;10.1109/TVCG.2008.116;10.1109/TVCG.2006.164;10.1109/TVCG.2010.190;10.1109/TVCG.2011.246;10.1109/TVCG.2008.167;10.1109/TVCG.2009.112;10.1109/TVCG.2010.170;10.1109/TVCG.2013.133	Flow visualization, Topic model, Latent Dirichlet allocation (LDA)	
SciVis	2014	Advection-Based Sparse Data Management for Visualizing Unsteady Flow	10.1109/TVCG.2014.2346418	http://dx.doi.org/10.1109/TVCG.2014.2346418	2555	2564	J	When computing integral curves and integral surfaces for large-scale unsteady flow fields, a major bottleneck is the widening gap between data access demands and the available bandwidth (both I/O and in-memory). In this work, we explore a novel advection-based scheme to manage flow field data for both efficiency and scalability. The key is to first partition flow field into blocklets (e.g. cells or very fine-grained blocks of cells), and then (pre)fetch and manage blocklets on-demand using a parallel key-value store. The benefits are (1) greatly increasing the scale of local-range analysis (e.g. source-destination queries, streak surface generation) that can fit within any given limit of hardware resources; (2) improving memory and I/O bandwidth-efficiencies as well as the scalability of naive task-parallel particle advection. We demonstrate our method using a prototype system that works on workstation and also in supercomputing environments. Results show significantly reduced I/O overhead compared to accessing raw flow data, and also high scalability on a supercomputer for a variety of applications.	Hanqi Guo;Jiang Zhang;Richen Liu;Lu Liu;Xiaoru Yuan;Jian Huang;Xiangfei Meng;Jingshan Pan	;;;;;;;	10.1109/TVCG.2009.154;10.1109/TVCG.2011.219;10.1109/VISUAL.1997.663898;10.1109/TVCG.2013.144;10.1109/TVCG.2013.128;10.1109/TVCG.2007.70551	Flow visualization, Data management, High performance visualization, Key-value store	
SciVis	2014	Trajectory-Based Flow Feature Tracking in Joint Particle/Volume Datasets	10.1109/TVCG.2014.2346423	http://dx.doi.org/10.1109/TVCG.2014.2346423	2565	2574	J	Studying the dynamic evolution of time-varying volumetric data is essential in countless scientific endeavors. The ability to isolate and track features of interest allows domain scientists to better manage large complex datasets both in terms of visual understanding and computational efficiency. This work presents a new trajectory-based feature tracking technique for use in joint particle/volume datasets. While traditional feature tracking approaches generally require a high temporal resolution, this method utilizes the indexed trajectories of corresponding Lagrangian particle data to efficiently track features over large jumps in time. Such a technique is especially useful for situations where the volume dataset is either temporally sparse or too large to efficiently track a feature through all intermediate timesteps. In addition, this paper presents a few other applications of this approach, such as the ability to efficiently track the internal properties of volumetric features using variables from the particle data. We demonstrate the effectiveness of this technique using real world combustion and atmospheric datasets and compare it to existing tracking methods to justify its advantages and accuracy.	Franz Sauer;Hongfeng Yu;Kwan-Liu Ma	Univ. of California, Davis, Davis, CA, USA|c|;;	10.1109/VISUAL.1997.663930;10.1109/VISUAL.1996.567807;10.1109/TVCG.2007.70599;10.1109/VISUAL.2003.1250374;10.1109/VISUAL.1990.146391;10.1109/VISUAL.1998.745288	Feature extraction and tracking, particle data, volume data, particle trajectories, flow visualization	
SciVis	2014	Visualizing 2-dimensional Manifolds with Curve Handles in 4D	10.1109/TVCG.2014.2346425	http://dx.doi.org/10.1109/TVCG.2014.2346425	2575	2584	J	In this paper, we present a mathematical visualization paradigm for exploring curves embedded in 3D and surfaces in 4D mathematical world. The basic problem is that, 3D figures of 4D mathematical entities often twist, turn, and fold back on themselves, leaving important properties behind the surface sheets. We propose an interactive system to visualize the topological features of the original 4D surface by slicing its 3D figure into a series of feature diagram. A novel 4D visualization interface is designed to allow users to control 4D topological shapes via the collection of diagram handles using the established curve manipulation mechanism. Our system can support rich mathematical interaction of 4D mathematical objects which is very difficult with any existing approach. We further demonstrate the effectiveness of the proposed visualization tool using various experimental results and cases studies.	Hui Zhang 0006;Jianguang Weng;Guangchen Ruan	Pervasive Technol. Inst., Indiana Univ., Bloomington, IN, USA|c|;;	10.1109/TVCG.2012.242;10.1109/VISUAL.2005.1532804;10.1109/VISUAL.2005.1532843;10.1109/TVCG.2010.151;10.1109/VISUAL.2005.1532833;10.1109/TVCG.2007.70593	math visualization, 4D, deformation, Reidemeister theorem	
SciVis	2014	Fast and Memory-Efficienty Topological Denoising of 2D and 3D Scalar Fields	10.1109/TVCG.2014.2346432	http://dx.doi.org/10.1109/TVCG.2014.2346432	2585	2594	J	Data acquisition, numerical inaccuracies, and sampling often introduce noise in measurements and simulations. Removing this noise is often necessary for efficient analysis and visualization of this data, yet many denoising techniques change the minima and maxima of a scalar field. For example, the extrema can appear or disappear, spatially move, and change their value. This can lead to wrong interpretations of the data, e.g., when the maximum temperature over an area is falsely reported being a few degrees cooler because the denoising method is unaware of these features. Recently, a topological denoising technique based on a global energy optimization was proposed, which allows the topology-controlled denoising of 2D scalar fields. While this method preserves the minima and maxima, it is constrained by the size of the data. We extend this work to large 2D data and medium-sized 3D data by introducing a novel domain decomposition approach. It allows processing small patches of the domain independently while still avoiding the introduction of new critical points. Furthermore, we propose an iterative refinement of the solution, which decreases the optimization energy compared to the previous approach and therefore gives smoother results that are closer to the input. We illustrate our technique on synthetic and real-world 2D and 3D data sets that highlight potential applications.	David Günther;Alec Jacobson;Jan Reininghaus;Hans-Peter Seidel;Olga Sorkine-Hornung;Tino Weinkauf	Inst. Mines-Telecom, Paris, France|c|;;;;;	10.1109/TVCG.2012.228;10.1109/VISUAL.2001.964507	Numerical optimization, topology, scalar fields	
SciVis	2014	Conforming Morse-Smale Complexes	10.1109/TVCG.2014.2346434	http://dx.doi.org/10.1109/TVCG.2014.2346434	2595	2603	J	Morse-Smale (MS) complexes have been gaining popularity as a tool for feature-driven data analysis and visualization. However, the quality of their geometric embedding and the sole dependence on the input scalar field data can limit their applicability when expressing application-dependent features. In this paper we introduce a new combinatorial technique to compute an MS complex that conforms to both an input scalar field and an additional, prior segmentation of the domain. The segmentation constrains the MS complex computation guaranteeing that boundaries in the segmentation are captured as separatrices of the MS complex. We demonstrate the utility and versatility of our approach with two applications. First, we use streamline integration to determine numerically computed basins/mountains and use the resulting segmentation as an input to our algorithm. This strategy enables the incorporation of prior flow path knowledge, effectively resulting in an MS complex that is as geometrically accurate as the employed numerical integration. Our second use case is motivated by the observation that often the data itself does not explicitly contain features known to be present by a domain expert. We introduce edit operations for MS complexes so that a user can directly modify their features while maintaining all the advantages of a robust topology-based representation.	Attila Gyulassy;David Günther;Joshua A. Levine;Julien Tierny;Valerio Pascucci	SCI Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;;;	10.1109/TVCG.2011.249;10.1109/TVCG.2008.110;10.1109/TVCG.2007.70603;10.1109/TVCG.2006.186;10.1109/TVCG.2012.228;10.1109/TVCG.2012.209;10.1109/VISUAL.2005.1532839	Computational Topology, Morse-Smale Complex, Data Analysis	
SciVis	2014	Escape Maps	10.1109/TVCG.2014.2346442	http://dx.doi.org/10.1109/TVCG.2014.2346442	2604	2613	J	We present a technique to visualize the streamline-based mapping between the boundary of a simply-connected subregion of arbitrary 3D vector fields. While the streamlines are seeded on one part of the boundary, the remaining part serves as escape border. Hence, the seeding part of the boundary represents a map of streamline behavior, indicating if streamlines reach the escape border or not. Since the resulting maps typically exhibit a very fine and complex structure and are thus not amenable to direct sampling, our approach instead aims at topologically consistent extraction of their boundary. We show that isocline surfaces of the projected vector field provide a robust basis for stream-surface-based extraction of these boundaries. The utility of our technique is demonstrated in the context of transport processes using vector field data from different domains.	Gustavo Mello Machado;Filip Sadlo;Thomas Müller 0005;Thomas Ertl	Univ. of Stuttgart, Stuttgart, Germany|c|;;;	10.1109/VISUAL.1991.175773;10.1109/VISUAL.1992.235211;10.1109/VISUAL.2003.1250376	Streamline behavior, vector field topology, isocline surfaces, coronal hole extraction	
SciVis	2014	City Forensics: Using Visual Elements to Predict Non-Visual City Attributes	10.1109/TVCG.2014.2346446	http://dx.doi.org/10.1109/TVCG.2014.2346446	2624	2633	J	We present a method for automatically identifying and validating predictive relationships between the visual appearance of a city and its non-visual attributes (e.g. crime statistics, housing prices, population density etc.). Given a set of street-level images and (location, city-attribute-value) pairs of measurements, we first identify visual elements in the images that are discriminative of the attribute. We then train a predictor by learning a set of weights over these elements using non-linear Support Vector Regression. To perform these operations efficiently, we implement a scalable distributed processing framework that speeds up the main computational bottleneck (extracting visual elements) by an order of magnitude. This speedup allows us to investigate a variety of city attributes across 6 different American cities. We find that indeed there is a predictive relationship between visual elements and a number of city attributes including violent crime rates, theft rates, housing prices, population density, tree presence, graffiti presence, and the perception of danger. We also test human performance for predicting theft based on street-level images and show that our predictor outperforms this baseline with 33% higher accuracy on average. Finally, we present three prototype applications that use our system to (1) define the visual boundary of city neighborhoods, (2) generate walking directions that avoid or seek out exposure to city attributes, and (3) validate user-specified visual elements for prediction.	Sean M. Arietta;Alexei A. Efros;Ravi Ramamoorthi;Maneesh Agrawala	EECS Dept., Univ. of California, Berkeley, Berkeley, CA, USA|c|;;;		Data mining, big data, computational geography, visual processing	
SciVis	2014	Decomposition and Simplification of Multivariate Data using Pareto Sets	10.1109/TVCG.2014.2346447	http://dx.doi.org/10.1109/TVCG.2014.2346447	2684	2693	J	Topological and structural analysis of multivariate data is aimed at improving the understanding and usage of such data through identification of intrinsic features and structural relationships among multiple variables. We present two novel methods for simplifying so-called Pareto sets that describe such structural relationships. Such simplification is a precondition for meaningful visualization of structurally rich or noisy data. As a framework for simplification operations, we introduce a decomposition of the data domain into regions of equivalent structural behavior and the reachability graph that describes global connectivity of Pareto extrema. Simplification is then performed as a sequence of edge collapses in this graph; to determine a suitable sequence of such operations, we describe and utilize a comparison measure that reflects the changes to the data that each operation represents. We demonstrate and evaluate our methods on synthetic and real-world examples.	Lars Huettenberger;Christian Heine 0002;Christoph Garth	Tech. Univ. Kaiserslautern, Kaiserslautern, Denmark|c|;;	10.1109/TVCG.2012.228;10.1109/VISUAL.2005.1532839;10.1109/TVCG.2009.120;10.1109/VISUAL.2002.1183774;10.1109/VISUAL.2000.885716;10.1109/TVCG.2008.110	Multivariate Topology, Pareto Set, Simplification, Decomposition	
SciVis	2014	Multi-Charts for Comparative 3D Ensemble Visualization	10.1109/TVCG.2014.2346448	http://dx.doi.org/10.1109/TVCG.2014.2346448	2694	2703	J	A comparative visualization of multiple volume data sets is challenging due to the inherent occlusion effects, yet it is important to effectively reveal uncertainties, correlations and reliable trends in 3D ensemble fields. In this paper we present bidirectional linking of multi-charts and volume visualization as a means to analyze visually 3D scalar ensemble fields at the data level. Multi-charts are an extension of conventional bar and line charts: They linearize the 3D data points along a space-filling curve and draw them as multiple charts in the same plot area. The bar charts encode statistical information on ensemble members, such as histograms and probability densities, and line charts are overlayed to allow comparing members against the ensemble. Alternative linearizations based on histogram similarities or ensemble variation allow clustering of spatial locations depending on data distribution. Multi-charts organize the data at multiple scales to quickly provide overviews and enable users to select regions exhibiting interesting behavior interactively. They are further put into a spatial context by allowing the user to brush or query value intervals and specific distributions, and to simultaneously visualize the corresponding spatial points via volume rendering. By providing a picking mechanism in 3D and instantly highlighting the corresponding data points in the chart, the user can go back and forth between the abstract and the 3D view to focus the analysis.	Ismail Demir;Christian Dick;Rüdiger Westermann	Comput. Graphics & Visualization Group, Tech. Univ. Munchen, Garching, Germany|c|;;	10.1109/TVCG.2013.143;10.1109/VISUAL.2000.885739;10.1109/TVCG.2006.159;10.1109/TVCG.2008.139;10.1109/TVCG.2007.70518;10.1109/TVCG.2010.181;10.1109/TVCG.2009.198;10.1109/INFVIS.2002.1173157;10.1109/VISUAL.1999.809921	Ensemble visualization, brushing and linking, statistical analysis	
SciVis	2014	Using Topological Analysis to Support Event-Guided Exploration in Urban Data	10.1109/TVCG.2014.2346449	http://dx.doi.org/10.1109/TVCG.2014.2346449	2634	2643	J	The explosion in the volume of data about urban environments has opened up opportunities to inform both policy and administration and thereby help governments improve the lives of their citizens, increase the efficiency of public services, and reduce the environmental harms of development. However, cities are complex systems and exploring the data they generate is challenging. The interaction between the various components in a city creates complex dynamics where interesting facts occur at multiple scales, requiring users to inspect a large number of data slices over time and space. Manual exploration of these slices is ineffective, time consuming, and in many cases impractical. In this paper, we propose a technique that supports event-guided exploration of large, spatio-temporal urban data. We model the data as time-varying scalar functions and use computational topology to automatically identify events in different data slices. To handle a potentially large number of events, we develop an algorithm to group and index them, thus allowing users to interactively explore and query event patterns on the fly. A visual exploration interface helps guide users towards data slices that display interesting events and trends. We demonstrate the effectiveness of our technique on two different data sets from New York City (NYC): data about taxi trips and subway service. We also report on the feedback we received from analysts at different NYC agencies.	Harish Doraiswamy;Nivan Ferreira;Theodoros Damoulas;Juliana Freire;Cláudio T. Silva	New York Univ., New York, NY, USA|c|;;;;	10.1109/TVCG.2013.130;10.1109/TVCG.2007.70574;10.1109/VAST.2008.4677356;10.1109/VISUAL.2004.96;10.1109/TVCG.2013.179;10.1109/TVCG.2006.186;10.1109/VAST.2008.4677354;10.1109/TVCG.2013.226;10.1109/TVCG.2013.228;10.1109/VAST.2012.6400557;10.1109/VAST.2011.6102454;10.1109/TVCG.2013.131	Computational topology, event detection, spatio-temporal index, urban data, visual exploration	
SciVis	2014	Trend-Centric Motion Visualization: Designing and Applying a New Strategy for Analyzing Scientific Motion Collections	10.1109/TVCG.2014.2346451	http://dx.doi.org/10.1109/TVCG.2014.2346451	2644	2653	J	In biomechanics studies, researchers collect, via experiments or simulations, datasets with hundreds or thousands of trials, each describing the same type of motion (e.g., a neck flexion-extension exercise) but under different conditions (e.g., different patients, different disease states, pre- and post-treatment). Analyzing similarities and differences across all of the trials in these collections is a major challenge. Visualizing a single trial at a time does not work, and the typical alternative of juxtaposing multiple trials in a single visual display leads to complex, difficult-to-interpret visualizations. We address this problem via a new strategy that organizes the analysis around motion trends rather than trials. This new strategy matches the cognitive approach that scientists would like to take when analyzing motion collections. We introduce several technical innovations making trend-centric motion visualization possible. First, an algorithm detects a motion collection's trends via time-dependent clustering. Second, a 2D graphical technique visualizes how trials leave and join trends. Third, a 3D graphical technique, using a median 3D motion plus a visual variance indicator, visualizes the biomechanics of the set of trials within each trend. These innovations are combined to create an interactive exploratory visualization tool, which we designed through an iterative process in collaboration with both domain scientists and a traditionally-trained graphic designer. We report on insights generated during this design process and demonstrate the tool's effectiveness via a validation study with synthetic data and feedback from expert musculoskeletal biomechanics researchers who used the tool to analyze the effects of disc degeneration on human spinal kinematics.	David Schroeder;Fedor Korsakov;Carissa Mai-Ping Knipe;Lauren Thorson;Arin M. Ellingson;David J. Nuckley;John V. Carlis;Daniel F. Keefe	Univ. of Minnesota, Minneapolis, MN, USA|c|;;;;;;;	10.1109/TVCG.2013.178;10.1109/TVCG.2009.152;10.1109/VAST.2011.6102454;10.1109/TVCG.2010.223;10.1109/VISUAL.2001.964496;10.1109/TVCG.2007.70518;10.1109/VAST.2009.5332593;10.1109/VISUAL.2005.1532857	Design studies, focus + context techniques, integrating spatial and non-spatial data visualization, visual design, biomedical and medical visualization	
SciVis	2014	Curve Boxplot: Generalization of Boxplot for Ensembles of Curves	10.1109/TVCG.2014.2346455	http://dx.doi.org/10.1109/TVCG.2014.2346455	2654	2663	J	In simulation science, computational scientists often study the behavior of their simulations by repeated solutions with variations in parameters and/or boundary values or initial conditions. Through such simulation ensembles, one can try to understand or quantify the variability or uncertainty in a solution as a function of the various inputs or model assumptions. In response to a growing interest in simulation ensembles, the visualization community has developed a suite of methods for allowing users to observe and understand the properties of these ensembles in an efficient and effective manner. An important aspect of visualizing simulations is the analysis of derived features, often represented as points, surfaces, or curves. In this paper, we present a novel, nonparametric method for summarizing ensembles of 2D and 3D curves. We propose an extension of a method from descriptive statistics, data depth, to curves. We also demonstrate a set of rendering and visualization strategies for showing rank statistics of an ensemble of curves, which is a generalization of traditional whisker plots or boxplots to multidimensional curves. Results are presented for applications in neuroimaging, hurricane forecasting and fluid dynamics.	Mahsa Mirzargar;Ross T. Whitaker;Robert Michael Kirby	Sci. Comput. & Imaging Inst., Univ. of Utah, Salt Lake City, UT, USA|c|;;	10.1109/TVCG.2013.143;10.1109/VISUAL.2002.1183769;10.1109/VISUAL.1996.568116;10.1109/VISUAL.1996.568105;10.1109/TVCG.2013.141;10.1109/TVCG.2010.212;10.1109/TVCG.2013.126;10.1109/TVCG.2010.181	Uncertainty visualization, boxplots, ensemble visualization, order statistics, data depth, nonparametric statistic, functional data, parametric curves	
SciVis	2014	Volume-Preserving Mapping and Registration for Collective Data Visualization	10.1109/TVCG.2014.2346457	http://dx.doi.org/10.1109/TVCG.2014.2346457	2664	2673	J	In order to visualize and analyze complex collective data, complicated geometric structure of each data is desired to be mapped onto a canonical domain to enable map-based visual exploration. This paper proposes a novel volume-preserving mapping and registration method which facilitates effective collective data visualization. Given two 3-manifolds with the same topology, there exists a mapping between them to preserve each local volume element. Starting from an initial mapping, a volume restoring diffeomorphic flow is constructed as a compressible flow based on the volume forms at the manifold. Such a flow yields equality of each local volume element between the original manifold and the target at its final state. Furthermore, the salient features can be used to register the manifold to a reference template by an incompressible flow guided by a divergence-free vector field within the manifold. The process can retain the equality of local volume elements while registering the manifold to a template at the same time. An efficient and practical algorithm is also presented to generate a volume-preserving mapping and a salient feature registration on discrete 3D volumes which are represented with tetrahedral meshes embedded in 3D space. This method can be applied to comparative analysis and visualization of volumetric medical imaging data across subjects. We demonstrate an example application in multimodal neuroimaging data analysis and collective data visualization.	Jiaxi Hu;Guangyu Zou;Jing Hua	Dept. of Comput. Sci., Wayne State Univ., Detroit, MI, USA|c|;;	10.1109/TVCG.2008.134;10.1109/VISUAL.2004.75;10.1109/VISUAL.2002.1183795;10.1109/TVCG.2011.171	Volume-preserving mapping, data regularization, data transformation	
SciVis	2014	Fixed-Rate Compressed Floating-Point Arrays	10.1109/TVCG.2014.2346458	http://dx.doi.org/10.1109/TVCG.2014.2346458	2674	2683	J	Current compression schemes for floating-point data commonly take fixed-precision values and compress them to a variable-length bit stream, complicating memory management and random access. We present a fixed-rate, near-lossless compression scheme that maps small blocks of 4d values in d dimensions to a fixed, user-specified number of bits per block, thereby allowing read and write random access to compressed floating-point data at block granularity. Our approach is inspired by fixed-rate texture compression methods widely adopted in graphics hardware, but has been tailored to the high dynamic range and precision demands of scientific applications. Our compressor is based on a new, lifted, orthogonal block transform and embedded coding, allowing each per-block bit stream to be truncated at any point if desired, thus facilitating bit rate selection using a single compression scheme. To avoid compression or decompression upon every data access, we employ a software write-back cache of uncompressed blocks. Our compressor has been designed with computational simplicity and speed in mind to allow for the possibility of a hardware implementation, and uses only a small number of fixed-point arithmetic operations per compressed value. We demonstrate the viability and benefits of lossy compression in several applications, including visualization, quantitative data analysis, and numerical simulation.	Peter Lindstrom	Center for Appl. Sci. Comput., Lawrence Livermore Nat. Lab., Livermore, CA, USA|c|	10.1109/TVCG.2006.143;10.1109/VISUAL.2001.964531;10.1109/TVCG.2006.186;10.1109/VISUAL.2001.964520;10.1109/VISUAL.2003.1250385;10.1109/TVCG.2012.209;10.1109/TVCG.2007.70516;10.1109/TVCG.2012.194;10.1109/VISUAL.1996.568138	Data compression, floating-point arrays, orthogonal block transform, embedded coding	
SciVis	2014	Stent Maps - Comparative Visualization for the Prediction of Adverse Events of Transcatheter Aortic Valve Implantations	10.1109/TVCG.2014.2346459	http://dx.doi.org/10.1109/TVCG.2014.2346459	2704	2713	J	Transcatheter aortic valve implantation (TAVI) is a minimally-invasive method for the treatment of aortic valve stenosis in patients with high surgical risk. Despite the success of TAVI, side effects such as paravalvular leakages can occur postoperatively. The goal of this project is to quantitatively analyze the co-occurrence of this complication and several potential risk factors such as stent shape after implantation, implantation height, amount and distribution of calcifications, and contact forces between stent and surrounding structure. In this paper, we present a two-dimensional visualization (stent maps), which allows (1) to comprehensively display all these aspects from CT data and mechanical simulation results and (2) to compare different datasets to identify patterns that are typical for adverse effects. The area of a stent map represents the surface area of the implanted stent - virtually straightened and uncoiled. Several properties of interest, like radial forces or stent compression, are displayed in this stent map in a heatmap-like fashion. Important anatomical landmarks and calcifications are plotted to show their spatial relation to the stent and possible correlations with the color-coded parameters. To provide comparability, the maps of different patient datasets are spatially adjusted according to a corresponding anatomical landmark. Also, stent maps summarizing the characteristics of different populations (e.g. with or without side effects) can be generated. Up to this point several interesting patterns have been observed with our technique, which remained hidden when examining the raw CT data or 3D visualizations of the same data. One example are obvious radial force maxima between the right and non-coronary valve leaflet occurring mainly in cases without leakages. These observations confirm the usefulness of our approach and give starting points for new hypotheses and further analyses. Because of its reduced dimensionality, the stent map data- is an appropriate input for statistical group evaluation and machine learning methods.	Silvia Born;Simon H. Sündermann;Christoph Russ;Raoul Hopf;Carlos E. Ruiz;Volkmar Falk;Michael Gessat	Univ. of Zurich, Zurich, Switzerland|c|;;;;;;	10.1109/TVCG.2009.169;10.1109/TVCG.2007.70550;10.1109/VISUAL.2001.964540;10.1109/TVCG.2011.235;10.1109/TVCG.2013.139;10.1109/VISUAL.2003.1250353	Comparative visualization, medical visualization, vessel flattening, transcatheter aortic valve implantation (TAVI)	
SciVis	2014	Visualization of Regular Maps: The Chase Continues	10.1109/TVCG.2014.2352952	http://dx.doi.org/10.1109/TVCG.2014.2352952	2614	2623	J	A regular map is a symmetric tiling of a closed surface, in the sense that all faces, vertices, and edges are topologically indistinguishable. Platonic solids are prime examples, but also for surfaces with higher genus such regular maps exist. We present a new method to visualize regular maps. Space models are produced by matching regular maps with target shapes in the hyperbolic plane. The approach is an extension of our earlier work. Here a wider variety of target shapes is considered, obtained by duplicating spherical and toroidal regular maps, merging triangles, punching holes, and gluing the edges. The method produces about 45 new examples, including the genus 7 Hurwitz surface.	Jarke J. van Wijk	Eindhoven Univ. of Technol., Eindhoven, Netherlands|c|		regular maps, tiling, tessellation, surface topology, mathematical visualization	
VAST	2014	Knowledge Generation Model for Visual Analytics	10.1109/TVCG.2014.2346481	http://dx.doi.org/10.1109/TVCG.2014.2346481	1604	1613	J	Visual analytics enables us to analyze huge information spaces in order to support complex decision making and data exploration. Humans play a central role in generating knowledge from the snippets of evidence emerging from visual data analysis. Although prior research provides frameworks that generalize this process, their scope is often narrowly focused so they do not encompass different perspectives at different levels. This paper proposes a knowledge generation model for visual analytics that ties together these diverse frameworks, yet retains previously developed models (e.g., KDD process) to describe individual segments of the overall visual analytic processes. To test its utility, a real world visual analytics system is compared against the model, demonstrating that the knowledge generation process model provides a useful guideline when developing and evaluating such systems. The model is used to effectively compare different data analysis systems. Furthermore, the model provides a common language and description of visual analytic processes, which can be used for communication between researchers. At the end, our model reflects areas of research that future researchers can embark on.	Dominik Sacha;Andreas Stoffel;Florian Stoffel;Bum Chul Kwon;Geoffrey P. Ellis;Daniel A. Keim	Data Anal. & Visualization Group, Univ. of Konstanz, Konstanz, Germany|c|;;;;;	10.1109/VISUAL.2005.1532781;10.1109/TVCG.2013.124;10.1109/VAST.2009.5333023;10.1109/TVCG.2011.229;10.1109/TVCG.2008.109;10.1109/VAST.2008.4677361;10.1109/VAST.2008.4677365;10.1109/VAST.2010.5652879;10.1109/TVCG.2012.273;10.1109/VAST.2008.4677358;10.1109/TVCG.2008.121;10.1109/VAST.2007.4389006;10.1109/VAST.2011.6102435;10.1109/TVCG.2013.120	Visual Analytics, Knowledge Generation, Reasoning, Visualization Taxonomies and Models, Interaction	
VAST	2014	INFUSE: Interactive Feature Selection for Predictive Modeling of High Dimensional Data	10.1109/TVCG.2014.2346482	http://dx.doi.org/10.1109/TVCG.2014.2346482	1614	1623	J	Predictive modeling techniques are increasingly being used by data scientists to understand the probability of predicted outcomes. However, for data that is high-dimensional, a critical step in predictive modeling is determining which features should be included in the models. Feature selection algorithms are often used to remove non-informative features from models. However, there are many different classes of feature selection algorithms. Deciding which one to use is problematic as the algorithmic output is often not amenable to user interpretation. This limits the ability for users to utilize their domain expertise during the modeling process. To improve on this limitation, we developed INFUSE, a novel visual analytics system designed to help analysts understand how predictive features are being ranked across feature selection algorithms, cross-validation folds, and classifiers. We demonstrate how our system can lead to important insights in a case study involving clinical researchers predicting patient outcomes from electronic medical records.	Josua Krause;Adam Perer;Enrico Bertini	;;	10.1109/INFVIS.2004.71;10.1109/VAST.2009.5332586;10.1109/INFVIS.2005.1532142;10.1109/TVCG.2011.229;10.1109/VAST.2011.6102448;10.1109/INFVIS.2003.1249015;10.1109/TVCG.2011.178;10.1109/VAST.2011.6102453;10.1109/TVCG.2013.125;10.1109/TVCG.2009.153;10.1109/VAST.2010.5652443	Predictive modeling, feature selection, classification, visual analytics, high-dimensional data	
VAST	2014	Transforming Scagnostics to Reveal Hidden Features	10.1109/TVCG.2014.2346572	http://dx.doi.org/10.1109/TVCG.2014.2346572	1624	1632	J	Scagnostics (Scatterplot Diagnostics) were developed by Wilkinson et al. based on an idea of Paul and John Tukey, in order to discern meaningful patterns in large collections of scatterplots. The Tukeys' original idea was intended to overcome the impediments involved in examining large scatterplot matrices (multiplicity of plots and lack of detail). Wilkinson's implementation enabled for the first time scagnostics computations on many points as well as many plots. Unfortunately, scagnostics are sensitive to scale transformations. We illustrate the extent of this sensitivity and show how it is possible to pair statistical transformations with scagnostics to enable discovery of hidden structures in data that are not discernible in untransformed visualizations.	Dang Tuan Nhon;Leland Wilkinson	Dept. of Comput. Sci., Univ. of Illinois at Chicago, Chicago, IL, USA|c|;	10.1109/TVCG.2006.163;10.1109/INFVIS.2005.1532142;10.1109/TVCG.2013.187;10.1109/TVCG.2011.167;10.1109/VAST.2006.261423;10.1109/TVCG.2010.184;10.1109/VAST.2011.6102437;10.1109/VAST.2007.4389006	Scagnostics, Scatterplot matrix, Transformation, High-Dimensional Visual Analytics	
VAST	2014	Supporting Communication and Coordination in Collaborative Sensemaking	10.1109/TVCG.2014.2346573	http://dx.doi.org/10.1109/TVCG.2014.2346573	1633	1642	J	When people work together to analyze a data set, they need to organize their findings, hypotheses, and evidence, share that information with their collaborators, and coordinate activities amongst team members. Sharing externalizations (recorded information such as notes) could increase awareness and assist with team communication and coordination. However, we currently know little about how to provide tool support for this sort of sharing. We explore how linked common work (LCW) can be employed within a `collaborative thinking space', to facilitate synchronous collaborative sensemaking activities in Visual Analytics (VA). Collaborative thinking spaces provide an environment for analysts to record, organize, share and connect externalizations. Our tool, CLIP, extends earlier thinking spaces by integrating LCW features that reveal relationships between collaborators' findings. We conducted a user study comparing CLIP to a baseline version without LCW. Results demonstrated that LCW significantly improved analytic outcomes at a collaborative intelligence task. Groups using CLIP were also able to more effectively coordinate their work, and held more discussion of their findings and hypotheses. LCW enabled them to maintain awareness of each other's activities and findings and link those findings to their own work, preventing disruptive oral awareness notifications.	Narges Mahyar;Melanie Tory	Univ. of Victoria, Victoria, BC, Canada|c|;	10.1109/VAST.2009.5333245;10.1109/VAST.2006.261439;10.1109/VAST.2008.4677358;10.1109/TVCG.2013.197;10.1109/VAST.2011.6102438;10.1109/VAST.2009.5333878;10.1109/VAST.2006.261430;10.1109/VAST.2007.4389011;10.1109/VAST.2007.4389006;10.1109/VAST.2011.6102447	Sensemaking, Collaboration, Externalization, Linked common work, Collaborative thinking space	
VAST	2014	Progressive Visual Analytics: User-Driven Visual Exploration of In-Progress Analytics	10.1109/TVCG.2014.2346574	http://dx.doi.org/10.1109/TVCG.2014.2346574	1653	1662	J	As datasets grow and analytic algorithms become more complex, the typical workflow of analysts launching an analytic, waiting for it to complete, inspecting the results, and then re-Iaunching the computation with adjusted parameters is not realistic for many real-world tasks. This paper presents an alternative workflow, progressive visual analytics, which enables an analyst to inspect partial results of an algorithm as they become available and interact with the algorithm to prioritize subspaces of interest. Progressive visual analytics depends on adapting analytical algorithms to produce meaningful partial results and enable analyst intervention without sacrificing computational speed. The paradigm also depends on adapting information visualization techniques to incorporate the constantly refining results without overwhelming analysts and provide interactions to support an analyst directing the analytic. The contributions of this paper include: a description of the progressive visual analytics paradigm; design goals for both the algorithms and visualizations in progressive visual analytics systems; an example progressive visual analytics system (Progressive Insights) for analyzing common patterns in a collection of event sequences; and an evaluation of Progressive Insights and the progressive visual analytics paradigm by clinical researchers analyzing electronic medical records.	Charles D. Stolper;Adam Perer;David Gotz	Sch. of Interactive Comput., Georgia Inst. of Technol., Atlanta, GA, USA|c|;;	10.1109/VAST.2006.261421;10.1109/TVCG.2013.227;10.1109/TVCG.2009.187;10.1109/TVCG.2011.179;10.1109/INFVIS.2005.1532133;10.1109/TVCG.2012.225;10.1109/TVCG.2013.179;10.1109/INFVIS.2000.885097;10.1109/TVCG.2013.200	Progressive visual analytics, information visualization, interactive machine learning, electronic medical records	
VAST	2014	Finding Waldo: Learning about Users from their Interactions	10.1109/TVCG.2014.2346575	http://dx.doi.org/10.1109/TVCG.2014.2346575	1663	1672	J	Visual analytics is inherently a collaboration between human and computer. However, in current visual analytics systems, the computer has limited means of knowing about its users and their analysis processes. While existing research has shown that a user's interactions with a system reflect a large amount of the user's reasoning process, there has been limited advancement in developing automated, real-time techniques that mine interactions to learn about the user. In this paper, we demonstrate that we can accurately predict a user's task performance and infer some user personality traits by using machine learning techniques to analyze interaction data. Specifically, we conduct an experiment in which participants perform a visual search task, and apply well-known machine learning algorithms to three encodings of the users' interaction data. We achieve, depending on algorithm and encoding, between 62% and 83% accuracy at predicting whether each user will be fast or slow at completing the task. Beyond predicting performance, we demonstrate that using the same techniques, we can infer aspects of the user's personality factors, including locus of control, extraversion, and neuroticism. Further analyses show that strong results can be attained with limited observation time: in one case 95% of the final accuracy is gained after a quarter of the average task completion time. Overall, our findings show that interactions can provide information to the computer about its human collaborator, and establish a foundation for realizing mixed-initiative visual analytics systems.	Eli T. Brown;Alvitta Ottley;Helen Zhao;Quan Lin;Richard Souvenir;Alex Endert;Remco Chang	Tufts Univ., Medford, MA, USA|c|;;;;;;	10.1109/TVCG.2012.204;10.1109/VAST.2010.5653587;10.1109/VAST.2009.5333020;10.1109/VAST.2012.6400486;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2012.276;10.1109/VAST.2006.261436;10.1109/VAST.2008.4677352	User Interactions, Analytic Provenance, Visualization, Applied Machine Learning	
VAST	2014	Opening the Black Box: Strategies for Increased User Involvement in Existing Algorithm Implementations	10.1109/TVCG.2014.2346578	http://dx.doi.org/10.1109/TVCG.2014.2346578	1643	1652	J	An increasing number of interactive visualization tools stress the integration with computational software like MATLAB and R to access a variety of proven algorithms. In many cases, however, the algorithms are used as black boxes that run to completion in isolation which contradicts the needs of interactive data exploration. This paper structures, formalizes, and discusses possibilities to enable user involvement in ongoing computations. Based on a structured characterization of needs regarding intermediate feedback and control, the main contribution is a formalization and comparison of strategies for achieving user involvement for algorithms with different characteristics. In the context of integration, we describe considerations for implementing these strategies either as part of the visualization tool or as part of the algorithm, and we identify requirements and guidelines for the design of algorithmic APIs. To assess the practical applicability, we provide a survey of frequently used algorithm implementations within R regarding the fulfillment of these guidelines. While echoing previous calls for analysis modules which support data exploration more directly, we conclude that a range of pragmatic options for enabling user involvement in ongoing computations exists on both the visualization and algorithm side and should be used.	Thomas Mühlbacher;Harald Piringer;Samuel Gratzl;Michael Sedlmair;Marc Streit	VRVis Res. Center, Vienna, Austria|c|;;;;	10.1109/VAST.2012.6400486;10.1109/VAST.2007.4388999;10.1109/VAST.2011.6102449;10.1109/TVCG.2007.70515;10.1109/TVCG.2009.151;10.1109/TVCG.2014.2346321;10.1109/VAST.2008.4677350;10.1109/TVCG.2006.171;10.1109/TVCG.2013.212;10.1109/TVCG.2013.125;10.1109/INFVIS.2002.1173145;10.1109/TVCG.2009.110;10.1109/INFVIS.2004.60;10.1109/VAST.2011.6102453;10.1109/TVCG.2012.195;10.1109/INFVIS.2003.1249014;10.1109/TVCG.2011.229	Visual analytics infrastructures, integration, interactive algorithms, user involvement, problem subdivision	
VAST	2014	Interactive Visual Analysis of Image-Centric Cohort Study Data	10.1109/TVCG.2014.2346591	http://dx.doi.org/10.1109/TVCG.2014.2346591	1673	1682	J	Epidemiological population studies impose information about a set of subjects (a cohort) to characterize disease-specific risk factors. Cohort studies comprise heterogenous variables describing the medical condition as well as demographic and lifestyle factors and, more recently, medical image data. We propose an Interactive Visual Analysis (IVA) approach that enables epidemiologists to rapidly investigate the entire data pool for hypothesis validation and generation. We incorporate image data, which involves shape-based object detection and the derivation of attributes describing the object shape. The concurrent investigation of image-based and non-image data is realized in a web-based multiple coordinated view system, comprising standard views from information visualization and epidemiological data representations such as pivot tables. The views are equipped with brushing facilities and augmented by 3D shape renderings of the segmented objects, e.g., each bar in a histogram is overlaid with a mean shape of the associated subgroup of the cohort. We integrate an overview visualization, clustering of variables and object shape for data-driven subgroup definition and statistical key figures for measuring the association between variables. We demonstrate the IVA approach by validating and generating hypotheses related to lower back pain as part of a qualitative evaluation.	Paul Klemm;Steffen Oeltze-Jafra;Kai Lawonn;Katrin Hegenscheid;Henry Völzke;Bernhard Preim	Otto-von-Guericke Univ. Magdeburg, Magdeburg, Germany|c|;;;;;	10.1109/TVCG.2013.160;10.1109/TVCG.2011.185;10.1109/VISUAL.2000.885739;10.1109/TVCG.2011.217;10.1109/TVCG.2007.70569	Interactive Visual Analysis, Epidemiology, Spine	
VAST	2014	Visual Abstraction and Exploration of Multi-class Scatterplots	10.1109/TVCG.2014.2346594	http://dx.doi.org/10.1109/TVCG.2014.2346594	1683	1692	J	Scatterplots are widely used to visualize scatter dataset for exploring outliers, clusters, local trends, and correlations. Depicting multi-class scattered points within a single scatterplot view, however, may suffer from heavy overdraw, making it inefficient for data analysis. This paper presents a new visual abstraction scheme that employs a hierarchical multi-class sampling technique to show a feature-preserving simplification. To enhance the density contrast, the colors of multiple classes are optimized by taking the multi-class point distributions into account. We design a visual exploration system that supports visual inspection and quantitative analysis from different perspectives. We have applied our system to several challenging datasets, and the results demonstrate the efficiency of our approach.	Haidong Chen;Wei Chen;Honghui Mei;Zhiqi Liu;Kun Zhou;Weifeng Chen;Wentao Gu;Kwan-Liu Ma	State Key Lab. of CAD&CG, Zhejiang Univ., Hangzhou, China|c|;;;;;;;	10.1109/TVCG.2013.150;10.1109/TVCG.2008.119;10.1109/VISUAL.1998.745301;10.1109/TVCG.2008.120;10.1109/TVCG.2010.197;10.1109/TVCG.2006.187;10.1109/TVCG.2007.70623;10.1109/TVCG.2013.180;10.1109/INFVIS.2004.52;10.1109/VAST.2010.5652460;10.1109/TVCG.2009.112;10.1109/TVCG.2009.122;10.1109/TVCG.2011.181;10.1109/TVCG.2012.238;10.1109/TVCG.2010.176;10.1109/TVCG.2013.212;10.1109/TVCG.2011.261;10.1109/TVCG.2008.153;10.1109/TVCG.2013.183	Scatterplot, overdraw reduction, sampling, visual abstraction	
VAST	2014	Cupid: Cluster-Based Exploration of Geometry Generators with Parallel Coordinates and Radial Trees	10.1109/TVCG.2014.2346626	http://dx.doi.org/10.1109/TVCG.2014.2346626	1693	1702	J	Geometry generators are commonly used in video games and evaluation systems for computer vision to create geometric shapes such as terrains, vegetation or airplanes. The parameters of the generator are often sampled automatically which can lead to many similar or unwanted geometric shapes. In this paper, we propose a novel visual exploration approach that combines the abstract parameter space of the geometry generator with the resulting 3D shapes in a composite visualization. Similar geometric shapes are first grouped using hierarchical clustering and then nested within an illustrative parallel coordinates visualization. This helps the user to study the sensitivity of the generator with respect to its parameter space and to identify invalid parameter settings. Starting from a compact overview representation, the user can iteratively drill-down into local shape differences by clicking on the respective clusters. Additionally, a linked radial tree gives an overview of the cluster hierarchy and enables the user to manually split or merge clusters. We evaluate our approach by exploring the parameter space of a cup generator and provide feedback from domain experts.	Michael Beham;Wolfgang Herzner;Eduard Gröller;Johannes Kehrer	Austrian Inst. of Technol., Vienna Univ. of Technol., Vienna, Austria|c|;;;	10.1109/TVCG.2013.147;10.1109/TVCG.2013.213;10.1109/TVCG.2010.138;10.1109/TVCG.2009.155;10.1109/VISUAL.2005.1532856;10.1109/TVCG.2010.190;10.1109/TVCG.2006.147;10.1109/VISUAL.1993.398859;10.1109/VISUAL.1999.809866;10.1109/TVCG.2007.70581	Composite visualization, hierarchical clustering, illustrative parallel coordinates, radial trees, 3D shape analysis	
VAST	2014	Visual Methods for Analyzing Probabilistic Classification Data	10.1109/TVCG.2014.2346660	http://dx.doi.org/10.1109/TVCG.2014.2346660	1703	1712	J	Multi-class classifiers often compute scores for the classification samples describing probabilities to belong to different classes. In order to improve the performance of such classifiers, machine learning experts need to analyze classification results for a large number of labeled samples to find possible reasons for incorrect classification. Confusion matrices are widely used for this purpose. However, they provide no information about classification scores and features computed for the samples. We propose a set of integrated visual methods for analyzing the performance of probabilistic classifiers. Our methods provide insight into different aspects of the classification results for a large number of samples. One visualization emphasizes at which probabilities these samples were classified and how these probabilities correlate with classification error in terms of false positives and false negatives. Another view emphasizes the features of these samples and ranks them by their separation power between selected true and false classifications. We demonstrate the insight gained using our technique in a benchmarking classification dataset, and show how it enables improving classification performance by interactively defining and evaluating post-classification rules.	Bilal Alsallakh;Allan Hanbury;Helwig Hauser;Silvia Miksch;Andreas Rauber	Vienna Univ. of Technol., Vienna, Austria|c|;;;;	10.1109/VISUAL.2000.885740;10.1109/VAST.2010.5652398;10.1109/VAST.2009.5332628;10.1109/TVCG.2012.277;10.1109/VAST.2012.6400486;10.1109/TVCG.2013.184;10.1109/TVCG.2012.254;10.1109/VAST.2011.6102448;10.1109/VAST.2011.6102453;10.1109/VAST.2012.6400492;10.1109/VAST.2010.5652443	Probabilistic classification, confusion analysis, feature evaluation and selection, visual inspection	
VAST	2014	A Five-Level Design Framework for Bicluster Visualizations	10.1109/TVCG.2014.2346665	http://dx.doi.org/10.1109/TVCG.2014.2346665	1713	1722	J	Analysts often need to explore and identify coordinated relationships (e.g., four people who visited the same five cities on the same set of days) within some large datasets for sensemaking. Biclusters provide a potential solution to ease this process, because each computed bicluster bundles individual relationships into coordinated sets. By understanding such computed, structural, relations within biclusters, analysts can leverage their domain knowledge and intuition to determine the importance and relevance of the extracted relationships for making hypotheses. However, due to the lack of systematic design guidelines, it is still a challenge to design effective and usable visualizations of biclusters to enhance their perceptibility and interactivity for exploring coordinated relationships. In this paper, we present a five-level design framework for bicluster visualizations, with a survey of the state-of-the-art design considerations and applications that are related or that can be applied to bicluster visualizations. We summarize pros and cons of these design options to support user tasks at each of the five-level relationships. Finally, we discuss future research challenges for bicluster visualizations and their incorporation into visual analytics tools.	Maoyuan Sun;Chris North;Naren Ramakrishnan	Dept. of Comput. Sci., Virginia Tech, Blacksburg, VA, USA|c|;;	10.1109/TVCG.2006.147;10.1109/TVCG.2009.153;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2010.138;10.1109/VISUAL.1990.146402;10.1109/TVCG.2011.250;10.1109/TVCG.2006.160;10.1109/TVCG.2009.122;10.1109/VISUAL.1999.809866;10.1109/VAST.2006.261426;10.1109/INFVIS.2004.1;10.1109/VAST.2011.6102449;10.1109/TVCG.2013.167;10.1109/TVCG.2006.170;10.1109/TVCG.2007.70582	Biclusters, interactive visual analytics, coordinated relationships, design framework	
VAST	2014	VarifocalReader -- In-Depth Visual Analysis of Large Text Documents	10.1109/TVCG.2014.2346677	http://dx.doi.org/10.1109/TVCG.2014.2346677	1723	1732	J	Interactive visualization provides valuable support for exploring, analyzing, and understanding textual documents. Certain tasks, however, require that insights derived from visual abstractions are verified by a human expert perusing the source text. So far, this problem is typically solved by offering overview-detail techniques, which present different views with different levels of abstractions. This often leads to problems with visual continuity. Focus-context techniques, on the other hand, succeed in accentuating interesting subsections of large text documents but are normally not suited for integrating visual abstractions. With VarifocalReader we present a technique that helps to solve some of these approaches' problems by combining characteristics from both. In particular, our method simplifies working with large and potentially complex text documents by simultaneously offering abstract representations of varying detail, based on the inherent structure of the document, and access to the text itself. In addition, VarifocalReader supports intra-document exploration through advanced navigation concepts and facilitates visual analysis tasks. The approach enables users to apply machine learning techniques and search mechanisms as well as to assess and adapt these techniques. This helps to extract entities, concepts and other artifacts from texts. In combination with the automatic generation of intermediate text levels through topic segmentation for thematic orientation, users can test hypotheses or develop interesting new research questions. To illustrate the advantages of our approach, we provide usage examples from literature studies.	Steffen Koch;Markus John;Michael Wörner;Andreas Müller;Thomas Ertl	Inst. of Visualization & Interactive Syst., Univ. of Stuttgart, Stuttgart, Germany|c|;;;;	10.1109/VAST.2010.5652926;10.1109/TVCG.2008.172;10.1109/VAST.2012.6400485;10.1109/TVCG.2013.188;10.1109/TVCG.2007.70577;10.1109/VAST.2012.6400486;10.1109/TVCG.2012.277;10.1109/TVCG.2009.165;10.1109/TVCG.2013.162;10.1109/INFVIS.1995.528686;10.1109/VAST.2009.5333248;10.1109/TVCG.2012.260;10.1109/VAST.2007.4389006;10.1109/VAST.2009.5333919;10.1109/VAST.2007.4389004	visual analytics, document analysis, literary analysis, natural language processing, text mining, machine learning, distant reading	
VAST	2014	DecisionFlow: Visual Analytics for High-Dimensional Temporal Event Sequence Data	10.1109/TVCG.2014.2346682	http://dx.doi.org/10.1109/TVCG.2014.2346682	1783	1792	J	Temporal event sequence data is increasingly commonplace, with applications ranging from electronic medical records to financial transactions to social media activity. Previously developed techniques have focused on low-dimensional datasets (e.g., with less than 20 distinct event types). Real-world datasets are often far more complex. This paper describes DecisionFlow, a visual analysis technique designed to support the analysis of high-dimensional temporal event sequence data (e.g., thousands of event types). DecisionFlow combines a scalable and dynamic temporal event data structure with interactive multi-view visualizations and ad hoc statistical analytics. We provide a detailed review of our methods, and present the results from a 12-person user study. The study results demonstrate that DecisionFlow enables the quick and accurate completion of a range of sequence analysis tasks for datasets containing thousands of event types and millions of individual events.	David Gotz;Harry Stavropoulos	Univ. of North Carolina at Chapel Hill, Chapel Hill, NC, USA|c|;	10.1109/TVCG.2013.206;10.1109/TVCG.2012.225;10.1109/TVCG.2011.179;10.1109/INFVIS.2000.885097;10.1109/VAST.2009.5332595;10.1109/VAST.2010.5652890;10.1109/TVCG.2009.117;10.1109/VAST.2006.261421;10.1109/TVCG.2013.200	Information Visualization, Temporal Event Sequences, Visual Analytics, Flow Diagrams, Medical Informatics	
VAST	2014	Footprints: A Visual Search Tool that Supports Discovery and Coverage Tracking	10.1109/TVCG.2014.2346743	http://dx.doi.org/10.1109/TVCG.2014.2346743	1793	1802	J	Searching a large document collection to learn about a broad subject involves the iterative process of figuring out what to ask, filtering the results, identifying useful documents, and deciding when one has covered enough material to stop searching. We are calling this activity ÔÇ£discoverage,ÔÇØ discovery of relevant material and tracking coverage of that material. We built a visual analytic tool called Footprints that uses multiple coordinated visualizations to help users navigate through the discoverage process. To support discovery, Footprints displays topics extracted from documents that provide an overview of the search space and are used to construct searches visuospatially. Footprints allows users to triage their search results by assigning a status to each document (To Read, Read, Useful), and those status markings are shown on interactive histograms depicting the user's coverage through the documents across dates, sources, and topics. Coverage histograms help users notice biases in their search and fill any gaps in their analytic process. To create Footprints, we used a highly iterative, user-centered approach in which we conducted many evaluations during both the design and implementation stages and continually modified the design in response to feedback.	Ellen Isaacs;Kelly Domico;Shane Ahern;Eugene Bart;Mudita Singhal	;;;;	10.1109/VAST.2009.5333443;10.1109/VAST.2008.4677365;10.1109/VAST.2007.4389006;10.1109/INFVIS.2001.963287;10.1109/TVCG.2007.70589;10.1109/VAST.2006.261426;10.1109/TVCG.2007.70577	discovery search visualization, visual cues, discoverage, coverage tracking, document triage, interactive histograms	
VAST	2014	Visual Analytics for Complex Engineering Systems: Hybrid Visual Steering of Simulation Ensembles	10.1109/TVCG.2014.2346744	http://dx.doi.org/10.1109/TVCG.2014.2346744	1803	1812	J	In this paper we propose a novel approach to hybrid visual steering of simulation ensembles. A simulation ensemble is a collection of simulation runs of the same simulation model using different sets of control parameters. Complex engineering systems have very large parameter spaces so a nai╠êve sampling can result in prohibitively large simulation ensembles. Interactive steering of simulation ensembles provides the means to select relevant points in a multi-dimensional parameter space (design of experiment). Interactive steering efficiently reduces the number of simulation runs needed by coupling simulation and visualization and allowing a user to request new simulations on the fly. As system complexity grows, a pure interactive solution is not always sufficient. The new approach of hybrid steering combines interactive visual steering with automatic optimization. Hybrid steering allows a domain expert to interactively (in a visualization) select data points in an iterative manner, approximate the values in a continuous region of the simulation space (by regression) and automatically find the ÔÇ£bestÔÇØ points in this continuous region based on the specified constraints and objectives (by optimization). We argue that with the full spectrum of optimization options, the steering process can be improved substantially. We describe an integrated system consisting of a simulation, a visualization, and an optimization component. We also describe typical tasks and propose an interactive analysis workflow for complex engineering systems. We demonstrate our approach on a case study from automotive industry, the optimization of a hydraulic circuit in a high pressure common rail Diesel injection system.	Kresimir Matkovic;Denis Gracanin;Rainer Splechtna;Mario Jelovic;Benedikt Stehno;Helwig Hauser;Werner Purgathofer	VRVis Res. Center, Vienna, Austria|c|;;;;;;	10.1109/TVCG.2010.223;10.1109/TVCG.2012.280;10.1109/TVCG.2008.145;10.1109/TVCG.2009.110;10.1109/TVCG.2010.171	Interactive Visual Analysis, Integrated Design Environment, Simulation, Visual Steering, Automatic Optimization	
VAST	2014	Visual Exploration of Sparse Traffic Trajectory Data	10.1109/TVCG.2014.2346746	http://dx.doi.org/10.1109/TVCG.2014.2346746	1813	1822	J	In this paper, we present a visual analysis system to explore sparse traffic trajectory data recorded by transportation cells. Such data contains the movements of nearly all moving vehicles on the major roads of a city. Therefore it is very suitable for macro-traffic analysis. However, the vehicle movements are recorded only when they pass through the cells. The exact tracks between two consecutive cells are unknown. To deal with such uncertainties, we first design a local animation, showing the vehicle movements only in the vicinity of cells. Besides, we ignore the micro-behaviors of individual vehicles, and focus on the macro-traffic patterns. We apply existing trajectory aggregation techniques to the dataset, studying cell status pattern and inter-cell flow pattern. Beyond that, we propose to study the correlation between these two patterns with dynamic graph visualization techniques. It allows us to check how traffic congestion on one cell is correlated with traffic flows on neighbouring links, and with route selection in its neighbourhood. Case studies show the effectiveness of our system.	Zuchao Wang;Tangzhi Ye;Min Lu;Xiaoru Yuan;Huamin Qu;Jacky Yuan;Qianliang Wu	Peking Univ., Beijing, China|c|;;;;;;	10.1109/VAST.2012.6400556;10.1109/INFVIS.2004.27;10.1109/VAST.2008.4677356;10.1109/INFVIS.2005.1532151;10.1109/VAST.2011.6102458;10.1109/TVCG.2011.226;10.1109/TVCG.2013.228;10.1109/TVCG.2013.193;10.1109/VAST.2009.5332584;10.1109/TVCG.2013.226;10.1109/VAST.2011.6102454;10.1109/VAST.2011.6102455;10.1109/TVCG.2009.182;10.1109/TVCG.2012.265	Sparse Traffic Trajectory, Traffic Visualization, Dynamic Graph Visualization, Traffic Congestion	
VAST	2014	DIA2: Web-based Cyberinfrastructure for Visual Analysis of Funding Portfolios	10.1109/TVCG.2014.2346747	http://dx.doi.org/10.1109/TVCG.2014.2346747	1823	1832	J	We present a design study of the Deep Insights Anywhere, Anytime (DIA2) platform, a web-based visual analytics system that allows program managers and academic staff at the U.S. National Science Foundation to search, view, and analyze their research funding portfolio. The goal of this system is to facilitate users' understanding of both past and currently active research awards in order to make more informed decisions of their future funding. This user group is characterized by high domain expertise yet not necessarily high literacy in visualization and visual analytics-they are essentially casual experts-and thus require careful visual and information design, including adhering to user experience standards, providing a self-instructive interface, and progressively refining visualizations to minimize complexity. We discuss the challenges of designing a system for casual experts and highlight how we addressed this issue by modeling the organizational structure and workflows of the NSF within our system. We discuss each stage of the design process, starting with formative interviews, prototypes, and finally live deployments and evaluation with stakeholders.	Krishna P. C. Madhavan;Niklas Elmqvist;Mihaela Vorvoreanu;Xin Chen;Yuet Ling Wong;Hanjun Xian;Zhihua Dong;Aditya Johri	Purdue Univ., West Lafayette, IN, USA|c|;;;;;;;	10.1109/TVCG.2007.70541;10.1109/TVCG.2011.174;10.1109/TVCG.2010.177;10.1109/TVCG.2012.255;10.1109/TVCG.2009.123;10.1109/TVCG.2013.223;10.1109/INFVIS.2001.963283;10.1109/TVCG.2012.213;10.1109/VAST.2008.4677361	visual analytics, portfolio mining, web-based visualization, casual visualization, design study	
VAST	2014	Visual Analytics for Comparison of Ocean Model Output with Reference Data: Detecting and Analyzing Geophysical Processes Using Clustering Ensembles	10.1109/TVCG.2014.2346751	http://dx.doi.org/10.1109/TVCG.2014.2346751	1893	1902	J	Researchers assess the quality of an ocean model by comparing its output to that of a previous model version or to observations. One objective of the comparison is to detect and to analyze differences and similarities between both data sets regarding geophysical processes, such as particular ocean currents. This task involves the analysis of thousands or hundreds of thousands of geographically referenced temporal profiles in the data. To cope with the amount of data, modelers combine aggregation of temporal profiles to single statistical values with visual comparison. Although this strategy is based on experience and a well-grounded body of expert knowledge, our discussions with domain experts have shown that it has two limitations: (1) using a single statistical measure results in a rather limited scope of the comparison and in significant loss of information, and (2) the decisions modelers have to make in the process may lead to important aspects being overlooked.	Patrick Köthur;Mike Sips;Henryk Dobslaw;Doris Dransch	GFZ German Res. Centre for Geosci., Potsdam, Germany|c|;;;	10.1109/TVCG.2012.190;10.1109/TVCG.2012.284;10.1109/TVCG.2008.139	Ocean modeling, model assessment, geospatial time series, cluster ensembles, visual comparison, visual analytics	
VAST	2014	ConTour: Data-Driven Exploration of Multi-Relational Datasets for Drug Discovery	10.1109/TVCG.2014.2346752	http://dx.doi.org/10.1109/TVCG.2014.2346752	1883	1892	J	Large scale data analysis is nowadays a crucial part of drug discovery. Biologists and chemists need to quickly explore and evaluate potentially effective yet safe compounds based on many datasets that are in relationship with each other. However, there is a lack of tools that support them in these processes. To remedy this, we developed ConTour, an interactive visual analytics technique that enables the exploration of these complex, multi-relational datasets. At its core ConTour lists all items of each dataset in a column. Relationships between the columns are revealed through interaction: selecting one or multiple items in one column highlights and re-sorts the items in other columns. Filters based on relationships enable drilling down into the large data space. To identify interesting items in the first place, ConTour employs advanced sorting strategies, including strategies based on connectivity strength and uniqueness, as well as sorting based on item attributes. ConTour also introduces interactive nesting of columns, a powerful method to show the related items of a child column for each item in the parent column. Within the columns, ConTour shows rich attribute data about the items as well as information about the connection strengths to other datasets. Finally, ConTour provides a number of detail views, which can show items from multiple datasets and their associated data at the same time. We demonstrate the utility of our system in case studies conducted with a team of chemical biologists, who investigate the effects of chemical compounds on cells and need to understand the underlying mechanisms.	Christian Partl;Alexander Lex;Marc Streit;Hendrik Strobelt;Anne Mai Wassermann;Hanspeter Pfister;Dieter Schmalstieg	Graz Univ. of Technol., Graz, Austria|c|;;;;;;	10.1109/TVCG.2013.167;10.1109/TVCG.2012.213;10.1109/TVCG.2012.252;10.1109/VAST.2007.4389006;10.1109/TVCG.2006.166;10.1109/TVCG.2013.223	Multi-relational data, visual data analysis, drug discovery	
VAST	2014	Genotet: An Interactive Web-based Visual Exploration Framework to Support Validation of Gene Regulatory Networks	10.1109/TVCG.2014.2346753	http://dx.doi.org/10.1109/TVCG.2014.2346753	1903	1912	J	Elucidation of transcriptional regulatory networks (TRNs) is a fundamental goal in biology, and one of the most important components of TRNs are transcription factors (TFs), proteins that specifically bind to gene promoter and enhancer regions to alter target gene expression patterns. Advances in genomic technologies as well as advances in computational biology have led to multiple large regulatory network models (directed networks) each with a large corpus of supporting data and gene-annotation. There are multiple possible biological motivations for exploring large regulatory network models, including: validating TF-target gene relationships, figuring out co-regulation patterns, and exploring the coordination of cell processes in response to changes in cell state or environment. Here we focus on queries aimed at validating regulatory network models, and on coordinating visualization of primary data and directed weighted gene regulatory networks. The large size of both the network models and the primary data can make such coordinated queries cumbersome with existing tools and, in particular, inhibits the sharing of results between collaborators. In this work, we develop and demonstrate a web-based framework for coordinating visualization and exploration of expression data (RNA-seq, microarray), network models and gene-binding data (ChIP-seq). Using specialized data structures and multiple coordinated views, we design an efficient querying model to support interactive analysis of the data. Finally, we show the effectiveness of our framework through case studies for the mouse immune system (a dataset focused on a subset of key cellular functions) and a model bacteria (a small genome with high data-completeness).	Bowen Yu;Harish Doraiswamy;Xi Chen;Emily R. Miraldi;Mario Luis Arrieta-Ortiz;Christoph Hafemeister;Aviv Madar;Richard Bonneau;Cláudio T. Silva	Sch. of Eng., NYU Polytech., New York, NY, USA|c|;;;;;;;;	10.1109/TVCG.2008.117;10.1109/TVCG.2009.146;10.1109/TVCG.2011.185;10.1109/TVCG.2009.167	Web-based visualization, gene regulatory network	
VAST	2014	The Spinel Explorer - Interactive Visual Analysis of Spinel Group Minerals	10.1109/TVCG.2014.2346754	http://dx.doi.org/10.1109/TVCG.2014.2346754	1913	1922	J	Geologists usually deal with rocks that are up to several thousand million years old. They try to reconstruct the tectonic settings where these rocks were formed and the history of events that affected them through the geological time. The spinel group minerals provide useful information regarding the geological environment in which the host rocks were formed. They constitute excellent indicators of geological environments (tectonic settings) and are of invaluable help in the search for mineral deposits of economic interest. The current workflow requires the scientists to work with different applications to analyze spine data. They do use specific diagrams, but these are usually not interactive. The current workflow hinders domain experts to fully exploit the potentials of tediously and expensively collected data. In this paper, we introduce the Spinel Explorer-an interactive visual analysis application for spinel group minerals. The design of the Spinel Explorer and of the newly introduced interactions is a result of a careful study of geologists' tasks. The Spinel Explorer includes most of the diagrams commonly used for analyzing spinel group minerals, including 2D binary plots, ternary plots, and 3D Spinel prism plots. Besides specific plots, conventional information visualization views are also integrated in the Spinel Explorer. All views are interactive and linked. The Spinel Explorer supports conventional statistics commonly used in spinel minerals exploration. The statistics views and different data derivation techniques are fully integrated in the system. Besides the Spinel Explorer as newly proposed interactive exploration system, we also describe the identified analysis tasks, and propose a new workflow. We evaluate the Spinel Explorer using real-life data from two locations in Argentina: the Frontal Cordillera in Central Andes and Patagonia. We describe the new findings of the geologists which would have been much more difficult to achieve using the cur- ent workflow only. Very positive feedback from geologists confirms the usefulness of the Spinel Explorer.	Maria Luján Ganuza;Gabriela Ferracutti;Maria Florencia Gargiulo;Silvia Mabel Castro;Ernesto A. Bjerg;Eduard Gröller;Kresimir Matkovic	VyGLab Res. Lab., Univ. Nac. del Sur, Bahia Blanca, Argentina|c|;;;;;;	10.1109/INFVIS.2000.885086;10.1109/TVCG.2009.155;10.1109/VISUAL.1995.485139	Interactive visual analysis, visualization in earth/space/ and environmental sciences, coordinated and multiple views, design studies	
VAST	2014	Visual Reconciliation of Alternative Similarity Spaces in Climate Modeling	10.1109/TVCG.2014.2346755	http://dx.doi.org/10.1109/TVCG.2014.2346755	1923	1932	J	Visual data analysis often requires grouping of data objects based on their similarity. In many application domains researchers use algorithms and techniques like clustering and multidimensional scaling to extract groupings from data. While extracting these groups using a single similarity criteria is relatively straightforward, comparing alternative criteria poses additional challenges. In this paper we define visual reconciliation as the problem of reconciling multiple alternative similarity spaces through visualization and interaction. We derive this problem from our work on model comparison in climate science where climate modelers are faced with the challenge of making sense of alternative ways to describe their models: one through the output they generate, another through the large set of properties that describe them. Ideally, they want to understand whether groups of models with similar spatio-temporal behaviors share similar sets of criteria or, conversely, whether similar criteria lead to similar behaviors. We propose a visual analytics solution based on linked views, that addresses this problem by allowing the user to dynamically create, modify and observe the interaction among groupings, thereby making the potential explanations apparent. We present case studies that demonstrate the usefulness of our technique in the area of climate science.	Jorge Poco;Aritra Dasgupta;Yaxing Wei;William W. Hargrove;Christopher R. Schwalm;Deborah N. Huntzinger;Robert B. Cook;Enrico Bertini;Cláudio T. Silva	New York Univ., New York, NY, USA|c|;;;;;;;;	10.1109/TVCG.2008.139;10.1109/TVCG.2012.256;10.1109/VISUAL.2005.1532821;10.1109/TVCG.2013.157;10.1109/VAST.2012.6400486;10.1109/TVCG.2013.188;10.1109/TVCG.2013.224;10.1109/VAST.2008.4677350;10.1109/TVCG.2013.120	Similarity, clustering, matrix, optimization, climate model	
VAST	2014	Visualizing Mobility of Public Transportation System	10.1109/TVCG.2014.2346893	http://dx.doi.org/10.1109/TVCG.2014.2346893	1833	1842	J	Public transportation systems (PTSs) play an important role in modern cities, providing shared/massive transportation services that are essential for the general public. However, due to their increasing complexity, designing effective methods to visualize and explore PTS is highly challenging. Most existing techniques employ network visualization methods and focus on showing the network topology across stops while ignoring various mobility-related factors such as riding time, transfer time, waiting time, and round-the-clock patterns. This work aims to visualize and explore passenger mobility in a PTS with a family of analytical tasks based on inputs from transportation researchers. After exploring different design alternatives, we come up with an integrated solution with three visualization modules: isochrone map view for geographical information, isotime flow map view for effective temporal information comparison and manipulation, and OD-pair journey view for detailed visual analysis of mobility factors along routes between specific origin-destination pairs. The isotime flow map linearizes a flow map into a parallel isoline representation, maximizing the visualization of mobility information along the horizontal time axis while presenting clear and smooth pathways from origin to destinations. Moreover, we devise several interactive visual query methods for users to easily explore the dynamics of PTS mobility over space and time. Lastly, we also construct a PTS mobility model from millions of real passenger trajectories, and evaluate our visualization techniques with assorted case studies with the transportation researchers.	Wei Zeng;Chi-Wing Fu;Stefan Müller Arisona;Alexander Erath;Huamin Qu	Nanyang Technol. Univ., Singapore, Singapore|c|;;;;	10.1109/INFVIS.2001.963273;10.1109/TVCG.2011.202;10.1109/TVCG.2011.205;10.1109/TVCG.2009.143;10.1109/TVCG.2012.265;10.1109/TVCG.2013.228;10.1109/TVCG.2013.226;10.1109/VAST.2011.6102455;10.1109/INFVIS.2005.1532150	Mobility, public transportation, visual analytics	
VAST	2014	Visual Analysis of Public Utility Service Problems in a Metropolis	10.1109/TVCG.2014.2346898	http://dx.doi.org/10.1109/TVCG.2014.2346898	1843	1852	J	Issues about city utility services reported by citizens can provide unprecedented insights into the various aspects of such services. Analysis of these issues can improve living quality through evidence-based decision making. However, these issues are complex, because of the involvement of spatial and temporal components, in addition to having multi-dimensional and multivariate natures. Consequently, exploring utility service problems and creating visual representations are difficult. To analyze these issues, we propose a visual analytics process based on the main tasks of utility service management. We also propose an aggregate method that transforms numerous issues into legible events and provide visualizations for events. In addition, we provide a set of tools and interaction techniques to explore such issues. Our approach enables administrators to make more informed decisions.	Jiawan Zhang;E. Yanli;Jing Ma;Yahui Zhao;Binghan Xu;Liting Sun;Jinyan Chen;Xiaoru Yuan	Sch. of Comput. Sci. & Technol., Tianjin Univ., Tianjin, China|c|;;;;;;;	10.1109/VAST.2012.6400557;10.1109/VAST.2012.6400556;10.1109/TVCG.2013.228;10.1109/TVCG.2009.111;10.1109/VAST.2008.4677356;10.1109/TVCG.2012.291;10.1109/TVCG.2013.132;10.1109/TVCG.2013.226;10.1109/VAST.2011.6102455;10.1109/VAST.2011.6102460;10.1109/TVCG.2009.122	utility services, evidence-based decision making, visual analytics, aggregate	
VAST	2014	VASA: Interactive Computational Steering of Large Asynchronous Simulation Pipelines for Societal Infrastructure	10.1109/TVCG.2014.2346911	http://dx.doi.org/10.1109/TVCG.2014.2346911	1853	1862	J	We present VASA, a visual analytics platform consisting of a desktop application, a component model, and a suite of distributed simulation components for modeling the impact of societal threats such as weather, food contamination, and traffic on critical infrastructure such as supply chains, road networks, and power grids. Each component encapsulates a high-fidelity simulation model that together form an asynchronous simulation pipeline: a system of systems of individual simulations with a common data and parameter exchange format. At the heart of VASA is the Workbench, a visual analytics application providing three distinct features: (1) low-fidelity approximations of the distributed simulation components using local simulation proxies to enable analysts to interactively configure a simulation run; (2) computational steering mechanisms to manage the execution of individual simulation components; and (3) spatiotemporal and interactive methods to explore the combined results of a simulation run. We showcase the utility of the platform using examples involving supply chains during a hurricane as well as food contamination in a fast food restaurant chain.	Sungahn Ko;Jieqiong Zhao;Jing Xia;Shehzad Afzal;Xiaoyu Wang;Greg Abram;Niklas Elmqvist;Len Kne;David Van Riper;Kelly P. Gaither;Shaun Kennedy;William J. Tolone;William Ribarsky;David S. Ebert	Purdue Univ. in West Lafayette, West Lafayette, IN, USA|c|;;;;;;;;;;;;;	10.1109/INFVIS.2000.885098;10.1109/TVCG.2011.225;10.1109/TVCG.2012.260;10.1109/TVCG.2007.70541;10.1109/TVCG.2010.223;10.1109/TVCG.2013.146;10.1109/TVCG.2010.171;10.1109/VAST.2011.6102460;10.1109/VAST.2011.6102457	Computational steering, visual analytics, critical infrastructure, homeland security	
VAST	2014	LoyalTracker: Visualizing Loyalty Dynamics in Search Engines	10.1109/TVCG.2014.2346912	http://dx.doi.org/10.1109/TVCG.2014.2346912	1733	1742	J	The huge amount of user log data collected by search engine providers creates new opportunities to understand user loyalty and defection behavior at an unprecedented scale. However, this also poses a great challenge to analyze the behavior and glean insights into the complex, large data. In this paper, we introduce LoyalTracker, a visual analytics system to track user loyalty and switching behavior towards multiple search engines from the vast amount of user log data. We propose a new interactive visualization technique (flow view) based on a flow metaphor, which conveys a proper visual summary of the dynamics of user loyalty of thousands of users over time. Two other visualization techniques, a density map and a word cloud, are integrated to enable analysts to gain further insights into the patterns identified by the flow view. Case studies and the interview with domain experts are conducted to demonstrate the usefulness of our technique in understanding user loyalty and switching behavior in search engines.	Conglei Shi;Yingcai Wu;Shixia Liu;Hong Zhou;Huamin Qu	Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;	10.1109/VAST.2010.5652931;10.1109/TVCG.2009.171;10.1109/VAST.2007.4389008;10.1109/TVCG.2012.253;10.1109/INFVIS.1996.559227;10.1109/TVCG.2012.212;10.1109/TVCG.2010.129;10.1109/TVCG.2012.225;10.1109/TVCG.2011.239;10.1109/VAST.2012.6400494;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2008.166	Time-series visualization, stacked graphs, log data visualization, text visualization	
VAST	2014	VAET: A Visual Analytics Approach for E-Transactions Time-Series	10.1109/TVCG.2014.2346913	http://dx.doi.org/10.1109/TVCG.2014.2346913	1743	1752	J	Previous studies on E-transaction time-series have mainly focused on finding temporal trends of transaction behavior. Interesting transactions that are time-stamped and situation-relevant may easily be obscured in a large amount of information. This paper proposes a visual analytics system, Visual Analysis of E-transaction Time-Series (VAET), that allows the analysts to interactively explore large transaction datasets for insights about time-varying transactions. With a set of analyst-determined training samples, VAET automatically estimates the saliency of each transaction in a large time-series using a probabilistic decision tree learner. It provides an effective time-of-saliency (TOS) map where the analysts can explore a large number of transactions at different time granularities. Interesting transactions are further encoded with KnotLines, a compact visual representation that captures both the temporal variations and the contextual connection of transactions. The analysts can thus explore, select, and investigate knotlines of interest. A case study and user study with a real E-transactions dataset (26 million records) demonstrate the effectiveness of VAET.	Cong Xie;Wei Chen;Xinxin Huang;Yueqi Hu;Scott Barlowe;Jing Yang	State Key Lab. of CAD&CG, Zhejiang Univ., Hangzhou, China|c|;;;;;	10.1109/TVCG.2009.123;10.1109/VAST.2007.4389009;10.1109/TVCG.2012.212;10.1109/INFVIS.1995.528685;10.1109/VAST.2012.6400494;10.1109/TVCG.2010.162;10.1109/TVCG.2009.180	Time-Series, Visual Analytics, E-transaction	
VAST	2014	EvoRiver: Visual Analysis of Topic Coopetition on Social Media	10.1109/TVCG.2014.2346919	http://dx.doi.org/10.1109/TVCG.2014.2346919	1753	1762	J	Cooperation and competition (jointly called ÔÇ£coopetitionÔÇØ) are two modes of interactions among a set of concurrent topics on social media. How do topics cooperate or compete with each other to gain public attention? Which topics tend to cooperate or compete with one another? Who plays the key role in coopetition-related interactions? We answer these intricate questions by proposing a visual analytics system that facilitates the in-depth analysis of topic coopetition on social media. We model the complex interactions among topics as a combination of carry-over, coopetition recruitment, and coopetition distraction effects. This model provides a close functional approximation of the coopetition process by depicting how different groups of influential users (i.e., ÔÇ£topic leadersÔÇØ) affect coopetition. We also design EvoRiver, a time-based visualization, that allows users to explore coopetition-related interactions and to detect dynamically evolving patterns, as well as their major causes. We test our model and demonstrate the usefulness of our system based on two Twitter data sets (social topics data and business topics data).	Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Jonathan J. H. Zhu;Ronghua Liang	;;;;;	10.1109/VAST.2010.5652931;10.1109/TVCG.2012.291;10.1109/TVCG.2008.166;10.1109/TVCG.2011.239;10.1109/TVCG.2012.253;10.1109/TVCG.2014.2346920;10.1109/TVCG.2013.221;10.1109/TVCG.2013.196;10.1109/TVCG.2013.162	Topic coopetition, information diffusion, information propagation, time-based visualization	
VAST	2014	OpinionFlow: Visual Analysis of Opinion Diffusion on Social Media	10.1109/TVCG.2014.2346920	http://dx.doi.org/10.1109/TVCG.2014.2346920	1763	1772	J	It is important for many different applications such as government and business intelligence to analyze and explore the diffusion of public opinions on social media. However, the rapid propagation and great diversity of public opinions on social media pose great challenges to effective analysis of opinion diffusion. In this paper, we introduce a visual analysis system called OpinionFlow to empower analysts to detect opinion propagation patterns and glean insights. Inspired by the information diffusion model and the theory of selective exposure, we develop an opinion diffusion model to approximate opinion propagation among Twitter users. Accordingly, we design an opinion flow visualization that combines a Sankey graph with a tailored density map in one view to visually convey diffusion of opinions among many users. A stacked tree is used to allow analysts to select topics of interest at different levels. The stacked tree is synchronized with the opinion flow visualization to help users examine and compare diffusion patterns across topics. Experiments and case studies on Twitter data demonstrate the effectiveness and usability of OpinionFlow.	Yingcai Wu;Shixia Liu;Kai Yan;Mengchen Liu;Fangzhao Wu	Microsoft Res., Redmond, WA, USA|c|;;;;	10.1109/TVCG.2011.239;10.1109/TVCG.2013.162;10.1109/TVCG.2013.221;10.1109/TVCG.2014.2346433;10.1109/INFVIS.2005.1532152;10.1109/TVCG.2012.291;10.1109/VAST.2006.261431;10.1109/TVCG.2010.129;10.1109/TVCG.2013.196;10.1109/TVCG.2014.2346919;10.1109/TVCG.2010.183;10.1109/VAST.2009.5333919	Opinion visualization, opinion diffusion, opinion flow, influence estimation, kernel density estimation, level-of-detail	
VAST	2014	#FluxFlow: Visual Analysis of Anomalous Information Spreading on Social Media	10.1109/TVCG.2014.2346922	http://dx.doi.org/10.1109/TVCG.2014.2346922	1773	1782	J	We present FluxFlow, an interactive visual analysis system for revealing and analyzing anomalous information spreading in social media. Everyday, millions of messages are created, commented, and shared by people on social media websites, such as Twitter and Facebook. This provides valuable data for researchers and practitioners in many application domains, such as marketing, to inform decision-making. Distilling valuable social signals from the huge crowd's messages, however, is challenging, due to the heterogeneous and dynamic crowd behaviors. The challenge is rooted in data analysts' capability of discerning the anomalous information behaviors, such as the spreading of rumors or misinformation, from the rest that are more conventional patterns, such as popular topics and newsworthy events, in a timely fashion. FluxFlow incorporates advanced machine learning algorithms to detect anomalies, and offers a set of novel visualization designs for presenting the detected threads for deeper analysis. We evaluated FluxFlow with real datasets containing the Twitter feeds captured during significant events such as Hurricane Sandy. Through quantitative measurements of the algorithmic performance and qualitative interviews with domain experts, the results show that the back-end anomaly detection model is effective in identifying anomalous retweeting threads, and its front-end interactive visualizations are intuitive and useful for analysts to discover insights in data and comprehend the underlying analytical model.	Jian Zhao;Nan Cao;Zhen Wen;Yale Song;Yu-Ru Lin;Christopher Collins	Univ. of Toronto, Toronto, ON, Canada|c|;;;;;	10.1109/VAST.2011.6102456;10.1109/TVCG.2012.291;10.1109/VAST.2012.6400557;10.1109/TVCG.2011.179;10.1109/TVCG.2011.239;10.1109/TVCG.2012.226;10.1109/TVCG.2013.227;10.1109/VAST.2012.6400485;10.1109/VAST.2010.5652922;10.1109/TVCG.2010.129;10.1109/TVCG.2013.221;10.1109/TVCG.2013.162	Retweeting threads, anomaly detection, social media, visual analytics, machine learning, information visualization	
VAST	2014	Proactive Spatiotemporal Resource Allocation and Predictive Visual Analytics for Community Policing and Law Enforcement	10.1109/TVCG.2014.2346926	http://dx.doi.org/10.1109/TVCG.2014.2346926	1863	1872	J	In this paper, we present a visual analytics approach that provides decision makers with a proactive and predictive environment in order to assist them in making effective resource allocation and deployment decisions. The challenges involved with such predictive analytics processes include end-users' understanding, and the application of the underlying statistical algorithms at the right spatiotemporal granularity levels so that good prediction estimates can be established. In our approach, we provide analysts with a suite of natural scale templates and methods that enable them to focus and drill down to appropriate geospatial and temporal resolution levels. Our forecasting technique is based on the Seasonal Trend decomposition based on Loess (STL) method, which we apply in a spatiotemporal visual analytics context to provide analysts with predicted levels of future activity. We also present a novel kernel density estimation technique we have developed, in which the prediction process is influenced by the spatial correlation of recent incidents at nearby locations. We demonstrate our techniques by applying our methodology to Criminal, Traffic and Civil (CTC) incident datasets.	Abish Malik;Ross Maciejewski;Sherry Towers;Sean McCullough;David S. Ebert	Purdue Univ., West Lafayette, IN, USA|c|;;;;	10.1109/TVCG.2013.125;10.1109/TVCG.2013.206;10.1109/VAST.2012.6400491;10.1109/VAST.2007.4389006;10.1109/TVCG.2013.200	Visual Analytics, Natural Scales, Seasonal Trend decomposition based on Loess (STL), Law Enforcement	
VAST	2014	Run Watchers: Automatic Simulation-Based Decision Support in Flood Management	10.1109/TVCG.2014.2346930	http://dx.doi.org/10.1109/TVCG.2014.2346930	1873	1882	J	In this paper, we introduce a simulation-based approach to design protection plans for flood events. Existing solutions require a lot of computation time for an exhaustive search, or demand for a time-consuming expert supervision and steering. We present a faster alternative based on the automated control of multiple parallel simulation runs. Run Watchers are dedicated system components authorized to monitor simulation runs, terminate them, and start new runs originating from existing ones according to domain-specific rules. This approach allows for a more efficient traversal of the search space and overall performance improvements due to a re-use of simulated states and early termination of failed runs. In the course of search, Run Watchers generate large and complex decision trees. We visualize the entire set of decisions made by Run Watchers using interactive, clustered timelines. In addition, we present visualizations to explain the resulting response plans. Run Watchers automatically generate storyboards to convey plan details and to justify the underlying decisions, including those which leave particular buildings unprotected. We evaluate our solution with domain experts.	Artem Konev;Jürgen Waser;Bernhard Sadransky;Daniel Cornel;Rui A. P. Perdigão;Zsolt Horváth;Eduard Gröller	VRVis Vienna, Vienna, Austria|c|;;;;;;	10.1109/INFVIS.2002.1173149;10.1109/VISUAL.2000.885727;10.1109/TVCG.2010.190;10.1109/TVCG.2011.248;10.1109/TVCG.2010.223;10.1109/TVCG.2008.145	Disaster management, simulation control, decision making, visual evidence, storytelling	
VAST	2014	Towards Interactive, Intelligent, and Integrated Multimedia Analytics	10.1109/VAST.2014.7042476	http://dx.doi.org/10.1109/VAST.2014.7042476	3	12	C	The size and importance of visual multimedia collections grew rapidly over the last years, creating a need for sophisticated multimedia analytics systems enabling large-scale, interactive, and insightful analysis. These systems need to integrate the human's natural expertise in analyzing multimedia with the machine's ability to process large-scale data. The paper starts off with a comprehensive overview of representation, learning, and interaction techniques from both the human's and the machine's point of view. To this end, hundreds of references from the related disciplines (visual analytics, information visualization, computer vision, multimedia information retrieval) have been surveyed. Based on the survey, a novel general multimedia analytics model is synthesized. In the model, the need for semantic navigation of the collection is emphasized and multimedia analytics tasks are placed on the exploration-search axis. The axis is composed of both exploration and search in a certain proportion which changes as the analyst progresses towards insight. Categorization is proposed as a suitable umbrella task realizing the exploration-search axis in the model. Finally, the pragmatic gap, defined as the difference between the tight machine categorization model and the flexible human categorization model is identified as a crucial multimedia analytics topic.	Jan Zahálka;Marcel Worring	University of Amsterdam|c|;	10.1109/VAST.2006.261425;10.1109/VAST.2007.4389003;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2010.136;10.1109/TVCG.2007.70515;10.1109/TVCG.2007.70541;10.1109/TVCG.2013.168	Multimedia (image/video/music) visualization, machine learning	
VAST	2014	Feature-Driven Visual Analytics of Soccer Data	10.1109/VAST.2014.7042477	http://dx.doi.org/10.1109/VAST.2014.7042477	13	22	C	Soccer is one the most popular sports today and also very interesting from an scientific point of view. We present a system for analyzing high-frequency position-based soccer data at various levels of detail, allowing to interactively explore and analyze for movement features and game events. Our Visual Analytics method covers single-player, multi-player and event-based analytical views. Depending on the task the most promising features are semi-automatically selected, processed, and visualized. Our aim is to help soccer analysts in finding the most important and interesting events in a match. We present a flexible, modular, and expandable layer-based system allowing in-depth analysis. The integration of Visual Analytics techniques into the analysis process enables the analyst to find interesting events based on classification and allows, by a set of custom views, to communicate the found results. The feedback loop in the Visual Analytics pipeline helps to further improve the classification results. We evaluate our approach by investigating real-world soccer matches and collecting additional expert feedback. Several use cases and findings illustrate the capabilities of our approach.	Halldór Janetzko;Dominik Sacha;Manuel Stein;Tobias Schreck;Daniel A. Keim;Oliver Deussen	University of Konstanz|c|;;;;;	10.1109/TVCG.2012.263;10.1109/VAST.2008.4677350;10.1109/TVCG.2007.70621;10.1109/TVCG.2013.228;10.1109/TVCG.2013.193;10.1109/TVCG.2013.207;10.1109/TVCG.2013.186	Visual Analytics, Sport Analytics, Soccer Analysis	
VAST	2014	Baseball4D: A Tool for Baseball Game Reconstruction & Visualization	10.1109/VAST.2014.7042478	http://dx.doi.org/10.1109/VAST.2014.7042478	23	32	C	While many sports use statistics and video to analyze and improve game play, baseball has led the charge throughout its history. With the advent of new technologies that allow all players and the ball to be tracked across the entire field, it is now possible to bring this understanding to another level. From discrete positions across time, we present techniques to reconstruct entire baseball games and visually explore each play. This provides opportunities to not only derive new metrics for the game, but also allow us to investigate existing measures with targeted visualizations. In addition, our techniques allow users to filter on demand so specific situations can be analyzed both in general and according to those situations. We show that gameplay can be accurately reconstructed from the raw position data and discuss how visualization and statistical methods can combine to better inform baseball analyses.	Carlos A. Dietrich;David Koop;Huy T. Vo;Cláudio T. Silva	;;;	10.1109/TVCG.2012.263;10.1109/TVCG.2013.192;10.1109/TVCG.2012.225;10.1109/VISUAL.2001.964496	sports visualization, sports analytics, baseball, game reconstruction, baseball metrics, event data	
VAST	2014	A System for Visual Analysis of Radio Signal Data	10.1109/VAST.2014.7042479	http://dx.doi.org/10.1109/VAST.2014.7042479	33	42	C	Analysis of radio transmissions is vital for military defense as it provides valuable information about enemy communication and infrastructure. One challenge to the data analysis task is that there are far too many signals for analysts to go through by hand. Even typical signal meta data (such as frequency band, duration, and geographic location) can be overwhelming. In this paper, we present a system for exploring and analyzing such radio signal meta-data. Our system incorporates several visual representations for signal data, designed for readability and ease of comparison, as well as novel algorithms for extracting and classifying consistent signal patterns. We demonstrate the effectiveness of our system using data collected from real missions with an airborne sensor platform.	Tarik Crnovrsanin;Chris Muelder;Kwan-Liu Ma	VIDi @ U. C. Davis|c|;;	10.1109/TVCG.2012.286;10.1109/VAST.2009.5332596;10.1109/INFVIS.2005.1532138;10.1109/VISUAL.1998.745302;10.1109/VAST.2009.5332593	Intelligence Analysis, Coordinated and Multiple Views, Time-varying data, Geographic/Geospatial Visualization	
VAST	2014	Feedback-Driven Interactive Exploration of Large Multidimensional Data Supported by Visual Classifier	10.1109/VAST.2014.7042480	http://dx.doi.org/10.1109/VAST.2014.7042480	43	52	C	The extraction of relevant and meaningful information from multivariate or high-dimensional data is a challenging problem. One reason for this is that the number of possible representations, which might contain relevant information, grows exponentially with the amount of data dimensions. Also, not all views from a possibly large view space, are potentially relevant to a given analysis task or user. Focus+Context or Semantic Zoom Interfaces can help to some extent to efficiently search for interesting views or data segments, yet they show scalability problems for very large data sets. Accordingly, users are confronted with the problem of identifying interesting views, yet the manual exploration of the entire view space becomes ineffective or even infeasible. While certain quality metrics have been proposed recently to identify potentially interesting views, these often are defined in a heuristic way and do not take into account the application or user context. We introduce a framework for a feedback-driven view exploration, inspired by relevance feedback approaches used in Information Retrieval. Our basic idea is that users iteratively express their notion of interestingness when presented with candidate views. From that expression, a model representing the user's preferences, is trained and used to recommend further interesting view candidates. A decision support system monitors the exploration process and assesses the relevance-driven search process for convergence and stability. We present an instantiation of our framework for exploration of Scatter Plot Spaces based on visual features. We demonstrate the effectiveness of this implementation by a case study on two real-world datasets. We also discuss our framework in light of design alternatives and point out its usefulness for development of user- and context-dependent visual exploration systems.	Michael Behrisch;Fatih Korkmaz;Lin Shao;Tobias Schreck	Universit&#x00E4;t Konstanz, Germany|c|;;;	10.1109/INFVIS.2005.1532142;10.1109/TVCG.2012.277;10.1109/TVCG.2010.184;10.1109/VAST.2012.6400486;10.1109/VAST.2007.4389001;10.1109/TVCG.2013.160;10.1109/VAST.2012.6400488	View Space Exploration Framework, Interesting View Problem, Relevance Feedback, User Preference Model	
VAST	2014	An Integrated Visual Analysis System for Fusing MR Spectroscopy and Multi-Modal Radiology Imaging	10.1109/VAST.2014.7042481	http://dx.doi.org/10.1109/VAST.2014.7042481	53	62	C	For cancers such as glioblastoma multiforme, there is an increasing interest in defining biological target volumes" (BTV), high tumour-burden regions which may be targeted with dose boosts in radiotherapy. The definition of a BTV requires insight into tumour characteristics going beyond conventionally defined radiological abnormalities and anatomical features. Molecular and biochemical imaging techniques, like positron emission tomography, the use of Magnetic Resonance (MR) Imaging contrast agents or MR Spectroscopy deliver this information and support BTV delineation. MR Spectroscopy Imaging (MRSI) is the only non-invasive technique in this list. Studies with MRSI have shown that voxels with certain metabolic signatures are more susceptible to predict the site of relapse. Nevertheless, the discovery of complex relationships between a high number of different metabolites, anatomical, molecular and functional features is an ongoing topic of research still lacking appropriate tools supporting a smooth workflow by providing data integration and fusion of MRSI data with other imaging modalities. We present a solution bridging this gap which gives fast and flexible access to all data at once. By integrating a customized visualization of the multi-modal and multi-variate image data with a highly flexible visual analytics (VA) framework, it is for the first time possible to interactively fuse, visualize and explore user defined metabolite relations derived from MRSI in combination with markers delivered by other imaging modalities. Real-world medical cases demonstrate the utility of our solution. By making MRSI data available both in a VA tool and in a multi-modal visualization renderer we can combine insights from each side to arrive at a superior BTV delineation. We also report feedback from domain experts indicating significant positive impact in how this work can improve the understanding of MRSI data and its integration into radiotherapy planning."	Miguel Nunes;Benjamin Rowland;Matthias Schlachter;Soléakhéna Ken;Kresimir Matkovic;Anne Laprie;Katja Bühler	VRVis Research Center, Vienna, Austria|c|;;;;;;	10.1109/TVCG.2007.70569;10.1109/TVCG.2013.180;10.1109/TVCG.2010.176	MR spectroscopy, cancer, brain, visualization, multi-modality data, radiotherapy planning, medical decision support systems	
VAST	2014	An Insight- and Task-based Methodology for Evaluating Spatiotemporal Visual Analytics	10.1109/VAST.2014.7042482	http://dx.doi.org/10.1109/VAST.2014.7042482	63	72	C	We present a method for evaluating visualizations using both tasks and exploration, and demonstrate this method in a study of spatiotemporal network designs for a visual analytics system. The method is well suited for studying visual analytics applications in which users perform both targeted data searches and analyses of broader patterns. In such applications, an effective visualization design is one that helps users complete tasks accurately and efficiently, and supports hypothesis generation during open-ended exploration. To evaluate both of these aims in a single study, we developed an approach called layered insight- and task-based evaluation (LITE) that interposes several prompts for observations about the data model between sequences of predefined search tasks. We demonstrate the evaluation method in a user study of four network visualizations for spatiotemporal data in a visual analytics application. Results include findings that might have been difficult to obtain in a single experiment using a different methodology. For example, with one dataset we studied, we found that on average participants were faster on search tasks using a force-directed layout than using our other designs; at the same time, participants found this design least helpful in understanding the data. Our contributions include a novel evaluation method that combines well-defined tasks with exploration and observation, an evaluation of network visualization designs for spatiotemporal visual analytics, and guidelines for using this evaluation method.	Steven R. Gomez;Hua Guo;Caroline Ziemkiewicz;David H. Laidlaw	Brown University|c|;;;	10.1109/TVCG.2012.233;10.1109/TVCG.2007.70617;10.1109/TVCG.2013.124;10.1109/TVCG.2010.154;10.1109/TVCG.2013.126;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2009.128;10.1109/TVCG.2011.185;10.1109/TVCG.2010.163;10.1109/TVCG.2013.120	Evaluation methodology, insight-based evaluation, visual analytics, network visualization, information visualization	
VAST	2014	Weaving a Carpet from Log Entries: A Network Security Visualization Built with Co-Creation	10.1109/VAST.2014.7042483	http://dx.doi.org/10.1109/VAST.2014.7042483	73	82	C	We created a pixel map for multivariate data based on an analysis of the needs of network security engineers. Parameters of a log record are shown as pixels and these pixels are stacked to represent a record. This allows a broad view of a data set on one screen while staying very close to the raw data and to expose common and rare patterns of user behavior through the visualization itself (the Carpet"). Visualizations that immediately point to areas of suspicious activity without requiring extensive filtering, help network engineers investigating unknown computer security incidents. Most of them, however, have limited knowledge of advanced visualization techniques, while many designers and data scientists are unfamiliar with computer security topics. To bridge this gap, we developed visualizations together with engineers, following a co-creative process. We will show how we explored the scope of the engineers' tasks and how we jointly developed ideas and designs. Our expert evaluation indicates that this visualization helps to scan large parts of log files quickly and to defne areas of interest for closer inspection."	Johannes Landstorfer;Ivo Herrmann;Jan-Erik Stange;Marian Dörk;Reto Wettach	Department of Design at the University of Applied Sciences Potsdam, Germany|c|;;;;	10.1109/TVCG.2006.160;10.1109/INFVIS.2005.1532134;10.1109/VISUAL.1991.175795;10.1109/VAST.2006.261436;10.1109/TVCG.2009.111;10.1109/INFVIS.1995.528685	Pixel-oriented techniques, task and requirements analysis, multidimensional data, network security and intrusion	
VAST	2014	Analyzing High-dimensional Multivariate Network Links with Integrated Anomaly Detection, Highlighting and Exploration	10.1109/VAST.2014.7042484	http://dx.doi.org/10.1109/VAST.2014.7042484	83	92	C	This paper focuses on the integration of a family of visual analytics techniques for analyzing high-dimensional, multivariate network data that features spatial and temporal information, network connections, and a variety of other categorical and numerical data types. Such data types are commonly encountered in transportation, shipping, and logistics industries. Due to the scale and complexity of the data, it is essential to integrate techniques for data analysis, visualization, and exploration. We present new visual representations, Petal and Thread, to effectively present many-to-many network data including multi-attribute vectors. In addition, we deploy an information-theoretic model for anomaly detection across varying dimensions, displaying highlighted anomalies in a visually consistent manner, as well as supporting a managed process of exploration. Lastly, we evaluate the proposed methodology through data exploration and an empirical study.	Sungahn Ko;Shehzad Afzal;Simon J. Walton;Yang Yang;Junghoon Chae;Abish Malik;Yun Jang;Min Chen 0001;David S. Ebert	Purdue University|c|;;;;;;;;	10.1109/VAST.2012.6400554;10.1109/TVCG.2010.150;10.1109/TVCG.2007.70582;10.1109/TVCG.2011.190;10.1109/VAST.2011.6102440;10.1109/TVCG.2009.143;10.1109/INFVIS.1999.801851;10.1109/TVCG.2006.166;10.1109/VAST.2007.4389013		
VAST	2014	Visual Analysis of Patterns in Multiple Amino Acid Mutation Graphs	10.1109/VAST.2014.7042485	http://dx.doi.org/10.1109/VAST.2014.7042485	93	102	C	Proteins are essential parts in all living organisms. They consist of sequences of amino acids. An interaction with reactive agent can stimulate a mutation at a specific position in the sequence. This mutation may set off a chain reaction, which effects other amino acids in the protein. Chain reactions need to be analyzed, as they may invoke unwanted side effects in drug treatment. A mutation chain is represented by a directed acyclic graph, where amino acids are connected by their mutation dependencies. As each amino acid may mutate individually, many mutation graphs exist. To determine important impacts of mutations, experts need to analyze and compare common patterns in these mutations graphs. Experts, however, lack suitable tools for this purpose. We present a new system for the search and the exploration of frequent patterns (i.e., motifs) in mutation graphs. We present a fast pattern search algorithm specifically developed for finding biologically relevant patterns in many mutation graphs (i.e., many labeled acyclic directed graphs). Our visualization system allows an interactive exploration and comparison of the found patterns. It enables locating the found patterns in the mutation graphs and in the 3D protein structures. In this way, potentially interesting patterns can be discovered. These patterns serve as starting point for a further biological analysis. In cooperation with biologists, we use our approach for analyzing a real world data set based on multiple HIV protease sequences.	Olav Lenz;Frank Keul;Sebastian Bremm;Kay Hamacher;Tatiana von Landesberger	GRIS, TU Darmstadt|c|;;;;	10.1109/TVCG.2013.225;10.1109/VAST.2011.6102439;10.1109/VAST.2009.5333893;10.1109/TVCG.2009.167;10.1109/TVCG.2007.70521;10.1109/TVCG.2009.122;10.1109/TVCG.2007.70529	Biologic Visualization, Graph Visualization, Motif Search, Motif Visualization, Biology, Mutations, Pattern Visualization	
VAST	2014	A Visual Reasoning Approach for Data-driven Transport Assessment on Urban Roads	10.1109/VAST.2014.7042486	http://dx.doi.org/10.1109/VAST.2014.7042486	103	112	C	Transport assessment plays a vital role in urban planning and traffic control, which are influenced by multi-faceted traffic factors involving road infrastructure and traffic flow. Conventional solutions can hardly meet the requirements and expectations of domain experts. In this paper we present a data-driven solution by leveraging a visual analysis system to evaluate the real traffic situations based on taxi trajectory data. A sketch-based visual interface is designed to support dynamic query and visual reasoning of traffic situations within multiple coordinated views. In particular, we propose a novel road-based query model for analysts to interactively conduct evaluation tasks. This model is supported by a bi-directional hash structure, TripHash, which enables real-time responses to the data queries over a huge amount of trajectory data. Case studies with a real taxi GPS trajectory dataset (> 30GB) show that our system performs well for on-demand transport assessment and reasoning.	Fei Wang;Wei Chen;Feiran Wu;Ye Zhao;Han Hong;Tianyu Gu;Long Wang;Ronghua Liang;Hujun Bao	State Key Lab of CAD&CG, Zhejiang University|c|;;;;;;;;	10.1109/VAST.2011.6102458;10.1109/TVCG.2013.226;10.1109/TVCG.2013.228;10.1109/TVCG.2013.179;10.1109/VAST.2011.6102455;10.1109/TVCG.2013.133	Road-based Query, Taxi Trajectory, Hash Index, Visual Analysis	
VAST	2014	Using Visualizations to Monitor Changes and Harvest Insights from a Global-Scale Logging Infrastructure at Twitter	10.1109/VAST.2014.7042487	http://dx.doi.org/10.1109/VAST.2014.7042487	113	122	C	Logging user activities is essential to data analysis for internet products and services. Twitter has built a unified logging infrastructure that captures user activities across all clients it owns, making it one of the largest datasets in the organization. This paper describes challenges and opportunities in applying information visualization to log analysis at this massive scale, and shows how various visualization techniques can be adapted to help data scientists extract insights. In particular, we focus on two scenarios: (1) monitoring and exploring a large collection of log events, and (2) performing visual funnel analysis on log data with tens of thousands of event types. Two interactive visualizations were developed for these purposes: we discuss design choices and the implementation of these systems, along with case studies of how they are being used in day-to-day operations at Twitter.	Krist Wongsuphasawat;Jimmy J. Lin	Twitter, Inc.|c|;	10.1109/INFVIS.2000.885091;10.1109/TVCG.2009.117;10.1109/INFVIS.1997.636718;10.1109/VAST.2007.4389008;10.1109/INFVIS.1996.559227;10.1109/TVCG.2012.225;10.1109/TVCG.2007.70529;10.1109/VAST.2012.6400494;10.1109/TVCG.2013.231;10.1109/INFVIS.2004.64;10.1109/VISUAL.1991.175815;10.1109/TVCG.2013.200;10.1109/VAST.2006.261421;10.1109/TVCG.2011.185	Information Visualization, Visual Analytics, Log Analysis, Log Visualization, Session Analysis, Funnel Analysis	
VAST	2014	HydroQual: Visual Analysis of River Water Quality	10.1109/VAST.2014.7042488	http://dx.doi.org/10.1109/VAST.2014.7042488	123	132	C	Economic development based on industrialization, intensive agriculture expansion and population growth places greater pressure on water resources through increased water abstraction and water quality degradation [40]. River pollution is now a visible issue, with emblematic ecological disasters following industrial accidents such as the pollution of the Rhine river in 1986 [31]. River water quality is a pivotal public health and environmental issue that has prompted governments to plan initiatives for preserving or restoring aquatic ecosystems and water resources [56]. Water managers require operational tools to help interpret the complex range of information available on river water quality functioning. Tools based on statistical approaches often fail to resolve some tasks due to the sparse nature of the data. Here we describe HydroQual, a tool to facilitate visual analysis of river water quality. This tool combines spatiotemporal data mining and visualization techniques to perform tasks defined by water experts. We illustrate the approach with a case study that illustrates how the tool helps experts analyze water quality. We also perform a qualitative evaluation with these experts.	Pierre Accorsi;Nathalie Lalande;Mickaël Fabrègue;Agnès Braud;Pascal Poncelet;Arnaud Sallaberry;Sandra Bringay;Maguelonne Teisseire;Flavie Cernesson;Florence Le Ber	LIRMM, Univ. Montpellier 2, Montpellier, France|c|;;;;;;;;;	10.1109/VISUAL.1996.568146;10.1109/INFVIS.2000.885097	Visual Analytics, Spatiotemporal Data Mining and Visualization, Water Quality	
VAST	2014	Vismate: Interactive Visual Analysis of Station-Based Observation Data on Climate Changes	10.1109/VAST.2014.7042489	http://dx.doi.org/10.1109/VAST.2014.7042489	133	142	C	We present a new approach to visualizing the climate data of multi-dimensional, time-series, and geo-related characteristics. Our approach integrates three new highly interrelated visualization techniques, and uses the same input data types as in the traditional model-based analysis methods. As the main visualization view, Global Radial Map is used to identify the overall state of climate changes and provide users with a compact and intuitive view for analyzing spatial and temporal patterns at the same time. Other two visualization techniques, providing complementary views, are specialized in analysing time trend and detecting abnormal cases, which are two important analysis tasks in any climate change study. Case studies and expert reviews have been conducted, through which the effectiveness and scalability of the proposed approach has been confirmed.	Jie Li;Kang Zhang;Zhao-Peng Meng	Sch. of Comput. Sci. & Technol., Tianjin Univ., Tianjin, China|c|;;	10.1109/VAST.2012.6400491;10.1109/TVCG.2010.194;10.1109/INFVIS.2000.885098;10.1109/TVCG.2007.70523;10.1109/TVCG.2009.199;10.1109/TVCG.2010.183;10.1109/VAST.2012.6400553;10.1109/TVCG.2010.180;10.1109/TVCG.2009.197	climate changes, spatiotemporal visualization, station-based observation data, radial layout, visual analytics	
VAST	2014	BoundarySeer: Visual Analysis of 2D Boundary Changes	10.1109/VAST.2014.7042490	http://dx.doi.org/10.1109/VAST.2014.7042490	143	152	C	Boundary changes exist ubiquitously in our daily life. From the Antarctic ozone hole to the land desertification, and from the territory of a country to the area within one-hour reach from a downtown location, boundaries change over time. With a large number of time-varying boundaries recorded, people often need to analyze the changes, detect their similarities or differences, and find out spatial and temporal patterns of the evolution for various applications. In this paper, we present a comprehensive visual analytics system, BoundarySeer, to help users gain insight into the changes of boundaries. Our system consists of four major viewers: 1) a global viewer to show boundary groups based on their similarity and the distribution of boundary attributes such as smoothness and perimeter; 2) a region viewer to display the regions encircled by the boundaries and how they are affected by boundary changes; 3) a trend viewer to reveal the temporal patterns in the boundary evolution and potential spatio-temporal correlations; 4) a directional change viewer to encode movements of boundary segments in different directions. Quantitative analyses of boundaries (e.g., similarity measurement and adaptive clustering) and intuitive visualizations (e.g., density map and ThemeRiver) are integrated into these viewers, which enable users to explore boundary changes from different aspects and at different scales. Case studies with two real-world datasets have been carried out to demonstrate the effectiveness of our system.	Wenchao Wu;Yixian Zheng;Huamin Qu;Wei Chen;Eduard Gröller;Lionel M. Ni	Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;	10.1109/TVCG.2013.230;10.1109/INFVIS.2004.27;10.1109/INFVIS.2001.963273;10.1109/TVCG.2011.239;10.1109/TVCG.2008.166;10.1109/INFVIS.2005.1532149;10.1109/TVCG.2013.213;10.1109/TVCG.2012.265;10.1109/TVCG.2007.70535;10.1109/TVCG.2008.125;10.1109/TVCG.2007.70561	Boundary change, visual analytics, scatter plot, ThemeRiver, contour map, radial visualization	
VAST	2014	YMCA - Your Mesh Comparison Application	10.1109/VAST.2014.7042491	http://dx.doi.org/10.1109/VAST.2014.7042491	153	162	C	Polygonal meshes can be created in several different ways. In this paper we focus on the reconstruction of meshes from point clouds, which are sets of points in 3D. Several algorithms that tackle this task already exist, but they have different benefits and drawbacks, which leads to a large number of possible reconstruction results (i.e., meshes). The evaluation of those techniques requires extensive comparisons between different meshes which is up to now done by either placing images of rendered meshes side-by-side, or by encoding differences by heat maps. A major drawback of both approaches is that they do not scale well with the number of meshes. This paper introduces a new comparative visual analysis technique for 3D meshes which enables the simultaneous comparison of several meshes and allows for the interactive exploration of their differences. Our approach gives an overview of the differences of the input meshes in a 2D view. By selecting certain areas of interest, the user can switch to a 3D representation and explore the spatial differences in detail. To inspect local variations, we provide a magic lens tool in 3D. The location and size of the lens provide further information on the variations of the reconstructions in the selected area. With our comparative visualization approach, differences between several mesh reconstruction algorithms can be easily localized and inspected.	Johanna Schmidt;Reinhold Preiner;Thomas Auzinger;Michael Wimmer;Eduard Gröller;Stefan Bruckner	Vienna Univ. of Technol., Vienna, Austria|c|;;;;;	10.1109/INFVIS.2002.1173157;10.1109/VISUAL.1990.146402;10.1109/TVCG.2013.213;10.1109/VISUAL.2002.1183790	Visual analysis, comparative visualization, 3D data exploration, focus+context, mesh comparison	
VAST	2014	Multi-Model Semantic Interaction for Text Analytics	10.1109/VAST.2014.7042492	http://dx.doi.org/10.1109/VAST.2014.7042492	163	172	C	Semantic interaction offers an intuitive communication mechanism between human users and complex statistical models. By shielding the users from manipulating model parameters, they focus instead on directly manipulating the spatialization, thus remaining in their cognitive zone. However, this technique is not inherently scalable past hundreds of text documents. To remedy this, we present the concept of multi-model semantic interaction, where semantic interactions can be used to steer multiple models at multiple levels of data scale, enabling users to tackle larger data problems. We also present an updated visualization pipeline model for generalized multi-model semantic interaction. To demonstrate multi-model semantic interaction, we introduce StarSPIRE, a visual text analytics prototype that transforms user interactions on documents into both small-scale display layout updates as well as large-scale relevancy-based document selection.	Lauren Bradel;Chris North;Leanna House;Scotland Leman	;;;	10.1109/VAST.2011.6102449;10.1109/TVCG.2013.188;10.1109/VAST.2012.6400559;10.1109/VAST.2012.6400486;10.1109/INFVIS.1995.528686;10.1109/VAST.2007.4389006	Visual analytics, Semantic Interaction, Sensemaking, Text Analytics	
VAST	2014	Serendip: Topic Model-Driven Visual Exploration of Text Corpora	10.1109/VAST.2014.7042493	http://dx.doi.org/10.1109/VAST.2014.7042493	173	182	C	Exploration and discovery in a large text corpus requires investigation at multiple levels of abstraction, from a zoomed-out view of the entire corpus down to close-ups of individual passages and words. At each of these levels, there is a wealth of information that can inform inquiry - from statistical models, to metadata, to the researcher's own knowledge and expertise. Joining all this information together can be a challenge, and there are issues of scale to be combatted along the way. In this paper, we describe an approach to text analysis that addresses these challenges of scale and multiple information sources, using probabilistic topic models to structure exploration through multiple levels of inquiry in a way that fosters serendipitous discovery. In implementing this approach into a tool called Serendip, we incorporate topic model data and metadata into a highly reorderable matrix to expose corpus level trends; extend encodings of tagged text to illustrate probabilistic information at a passage level; and introduce a technique for visualizing individual word rankings, along with interaction techniques and new statistical methods to create links between different levels and information types. We describe example uses from both the humanities and visualization research that illustrate the benefits of our approach.	Eric C. Alexander;Joe Kohlmann;Robin Valenza;Michael Witmore;Michael Gleicher	Dept. of Comput. Sci., Univ. of Wisconsin-Madison, Madison, WI, USA|c|;;;;	10.1109/VAST.2011.6102449;10.1109/INFVIS.2000.885098;10.1109/INFVIS.1998.729568;10.1109/TVCG.2011.239;10.1109/TVCG.2011.220;10.1109/VAST.2012.6400486;10.1109/VAST.2011.6102461;10.1109/TVCG.2013.157;10.1109/TVCG.2013.162;10.1109/VAST.2007.4389006;10.1109/VAST.2007.4389004	Text visualization, topic modeling	
VAST	2014	TopicPanorama: A Full Picture of Relevant Topics	10.1109/VAST.2014.7042494	http://dx.doi.org/10.1109/VAST.2014.7042494	183	192	C	We present a visual analytics approach to developing a full picture of relevant topics discussed in multiple sources such as news, blogs, or micro-blogs. The full picture consists of a number of common topics among multiple sources as well as distinctive topics. The key idea behind our approach is to jointly match the topics extracted from each source together in order to interactively and effectively analyze common and distinctive topics. We start by modeling each textual corpus as a topic graph. These graphs are then matched together with a consistent graph matching method. Next, we develop an LOD-based visualization for better understanding and analysis of the matched graph. The major feature of this visualization is that it combines a radially stacked tree visualization with a density-based graph visualization to facilitate the examination of the matched topic graph from multiple perspectives. To compensate for the deficiency of the graph matching algorithm and meet different users' needs, we allow users to interactively modify the graph matching result. We have applied our approach to various data including news, tweets, and blog data. Qualitative evaluation and a real-world case study with domain experts demonstrate the promise of our approach, especially in support of analyzing a topic-graph-based full picture at different levels of detail.	Shixia Liu;Xiting Wang;Jianfei Chen;Jim Zhu;Baining Guo	;;;;	10.1109/VAST.2011.6102461;10.1109/TVCG.2011.239;10.1109/TVCG.2009.111;10.1109/TVCG.2010.154;10.1109/VAST.2011.6102439;10.1109/TVCG.2006.193;10.1109/TVCG.2012.285;10.1109/TVCG.2013.221;10.1109/TVCG.2013.162;10.1109/TVCG.2012.279;10.1109/TVCG.2010.183;10.1109/TVCG.2014.2346433;10.1109/TVCG.2007.70521;10.1109/TVCG.2013.233;10.1109/TVCG.2013.212;10.1109/TVCG.2007.70582;10.1109/TVCG.2013.232;10.1109/TVCG.2010.129;10.1109/TVCG.2014.2346919	Topic graph, graph matching, graph visualization, user interactions, level-of-detail	
VAST	2014	Integrating Predictive Analytics and Social Media	10.1109/VAST.2014.7042495	http://dx.doi.org/10.1109/VAST.2014.7042495	193	202	C	A key analytical task across many domains is model building and exploration for predictive analysis. Data is collected, parsed and analyzed for relationships, and features are selected and mapped to estimate the response of a system under exploration. As social media data has grown more abundant, data can be captured that may potentially represent behavioral patterns in society. In turn, this unstructured social media data can be parsed and integrated as a key factor for predictive intelligence. In this paper, we present a framework for the development of predictive models utilizing social media data. We combine feature selection mechanisms, similarity comparisons and model cross-validation through a variety of interactive visualizations to support analysts in model building and prediction. In order to explore how predictions might be performed in such a framework, we present results from a user study focusing on social media data as a predictor for movie box-office success.	Yafeng Lu;Robert Krüger;Dennis Thom;Feng Wang;Steffen Koch;Thomas Ertl;Ross Maciejewski	Arizona State Univ., Tempe, AZ, USA|c|;;;;;;	10.1109/VAST.2012.6400557;10.1109/TVCG.2011.185;10.1109/VAST.2012.6400486;10.1109/TVCG.2013.162;10.1109/TVCG.2013.221;10.1109/VAST.2011.6102456;10.1109/TVCG.2012.291;10.1109/TVCG.2013.125;10.1109/INFVIS.2004.10;10.1109/VAST.2011.6102448;10.1109/VAST.2010.5652443;10.1109/INFVIS.2004.3	Social Media, Predictive Analytics, Feature Selection	
VAST	2014	PEARL: An Interactive Visual Analytic Tool for Understanding Personal Emotion Style Derived from Social Media	10.1109/VAST.2014.7042496	http://dx.doi.org/10.1109/VAST.2014.7042496	203	212	C	Hundreds of millions of people leave digital footprints on social media (e.g., Twitter and Facebook). Such data not only disclose a person's demographics and opinions, but also reveal one's emotional style. Emotional style captures a person's patterns of emotions over time, including his overall emotional volatility and resilience. Understanding one's emotional style can provide great benefits for both individuals and businesses alike, including the support of self-reflection and delivery of individualized customer care. We present PEARL, a timeline-based visual analytic tool that allows users to interactively discover and examine a person's emotional style derived from this person's social media text. Compared to other visual text analytic systems, our work offers three unique contributions. First, it supports multi-dimensional emotion analysis from social media text to automatically detect a person's expressed emotions at different time points and summarize those emotions to reveal the person's emotional style. Second, it effectively visualizes complex, multi-dimensional emotion analysis results to create a visual emotional profile of an individual, which helps users browse and interpret one's emotional style. Third, it supports rich visual interactions that allow users to interactively explore and validate emotion analysis results. We have evaluated our work extensively through a series of studies. The results demonstrate the effectiveness of our tool both in emotion analysis from social media and in support of interactive visualization of the emotion analysis results.	Jian Zhao;Liang Gou;Fei Wang;Michelle X. Zhou	;;;	10.1109/TVCG.2011.239;10.1109/VAST.2012.6400485;10.1109/TVCG.2010.129;10.1109/TVCG.2011.185;10.1109/TVCG.2010.183	Personal emotion analytics, affective and mood modeling, social media text, Twitter, information visualization	
InfoVis	2015	Matches, Mismatches, and Methods: Multiple-View Workflows for Energy Portfolio Analysis	10.1109/TVCG.2015.2466971	http://dx.doi.org/10.1109/TVCG.2015.2466971	449	458	J	The energy performance of large building portfolios is challenging to analyze and monitor, as current analysis tools are not scalable or they present derived and aggregated data at too coarse of a level. We conducted a visualization design study, beginning with a thorough work domain analysis and a characterization of data and task abstractions. We describe generalizable visual encoding design choices for time-oriented data framed in terms of matches and mismatches, as well as considerations for workflow design. Our designs address several research questions pertaining to scalability, view coordination, and the inappropriateness of line charts for derived and aggregated data due to a combination of data semantics and domain convention. We also present guidelines relating to familiarity and trust, as well as methodological considerations for visualization design studies. Our designs were adopted by our collaborators and incorporated into the design of an energy analysis software application that will be deployed to tens of thousands of energy workers in their client base.	Matthew Brehmer;Jocelyn Ng;Kevin Tate;Tamara Munzner	;;;	10.1109/TVCG.2011.185;10.1109/TVCG.2013.124;10.1109/TVCG.2008.166;10.1109/TVCG.2013.145;10.1109/TVCG.2013.173;10.1109/TVCG.2010.162;10.1109/TVCG.2007.70583;10.1109/TVCG.2011.209;10.1109/TVCG.2014.2346331;10.1109/TVCG.2014.2346578;10.1109/TVCG.2009.111;10.1109/TVCG.2011.196;10.1109/TVCG.2012.213;10.1109/INFVIS.1999.801851;10.1109/INFVIS.2005.1532122	Design study, design methodologies, time series data, task and requirements analysis, coordinated and multiple views	
InfoVis	2015	Evaluation of Parallel Coordinates: Overview, Categorization and Guidelines for Future Research	10.1109/TVCG.2015.2466992	http://dx.doi.org/10.1109/TVCG.2015.2466992	579	588	J	The parallel coordinates technique is widely used for the analysis of multivariate data. During recent decades significant research efforts have been devoted to exploring the applicability of the technique and to expand upon it, resulting in a variety of extensions. Of these many research activities, a surprisingly small number concerns user-centred evaluations investigating actual use and usability issues for different tasks, data and domains. The result is a clear lack of convincing evidence to support and guide uptake by users as well as future research directions. To address these issues this paper contributes a thorough literature survey of what has been done in the area of user-centred evaluation of parallel coordinates. These evaluations are divided into four categories based on characterization of use, derived from the survey. Based on the data from the survey and the categorization combined with the authors' experience of working with parallel coordinates, a set of guidelines for future research directions is proposed.	Jimmy Johansson;Camilla Forsell	Norrkoping Visualization Center C, Linkoping Univ., Linkoping, Sweden|c|;	10.1109/TVCG.2014.2346626;10.1109/TVCG.2011.201;10.1109/VISUAL.1999.809866;10.1109/TVCG.2014.2346979;10.1109/INFVIS.2002.1173157;10.1109/TVCG.2013.126;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2009.153;10.1109/INFVIS.2004.15;10.1109/INFVIS.2004.5;10.1109/TVCG.2011.197;10.1109/VISUAL.1997.663867	Survey, evaluation, guidelines, parallel coordinates	
InfoVis	2015	SchemeLens: A Content-Aware Vector-Based Fisheye Technique for Navigating Large Systems Diagrams	10.1109/TVCG.2015.2467035	http://dx.doi.org/10.1109/TVCG.2015.2467035	330	338	J	System schematics, such as those used for electrical or hydraulic systems, can be large and complex. Fisheye techniques can help navigate such large documents by maintaining the context around a focus region, but the distortion introduced by traditional fisheye techniques can impair the readability of the diagram. We present SchemeLens, a vector-based, topology-aware fisheye technique which aims to maintain the readability of the diagram. Vector-based scaling reduces distortion to components, but distorts layout. We present several strategies to reduce this distortion by using the structure of the topology, including orthogonality and alignment, and a model of user intention to foster smooth and predictable navigation. We evaluate this approach through two user studies: Results show that (1) SchemeLens is 16-27% faster than both round and rectangular flat-top fisheye lenses at finding and identifying a target along one or several paths in a network diagram; (2) augmenting SchemeLens with a model of user intentions aids in learning the network topology.	Aurélie Cohé;Bastien Liutkus;Gilles Bailly;James R. Eagan;Eric Lecolinet	;;;;	10.1109/INFVIS.2004.66;10.1109/TVCG.2012.245;10.1109/INFVIS.2003.1249008	Fisheye, vector-scaling, content-aware, network schematics, interactive zoom, navigation, information visualization	
InfoVis	2015	AggreSet: Rich and Scalable Set Exploration using Visualizations of Element Aggregations	10.1109/TVCG.2015.2467051	http://dx.doi.org/10.1109/TVCG.2015.2467051	688	697	J	Datasets commonly include multi-value (set-typed) attributes that describe set memberships over elements, such as genres per movie or courses taken per student. Set-typed attributes describe rich relations across elements, sets, and the set intersections. Increasing the number of sets results in a combinatorial growth of relations and creates scalability challenges. Exploratory tasks (e.g. selection, comparison) have commonly been designed in separation for set-typed attributes, which reduces interface consistency. To improve on scalability and to support rich, contextual exploration of set-typed data, we present AggreSet. AggreSet creates aggregations for each data dimension: sets, set-degrees, set-pair intersections, and other attributes. It visualizes the element count per aggregate using a matrix plot for set-pair intersections, and histograms for set lists, set-degrees and other attributes. Its non-overlapping visual design is scalable to numerous and large sets. AggreSet supports selection, filtering, and comparison as core exploratory tasks. It allows analysis of set relations inluding subsets, disjoint sets and set intersection strength, and also features perceptual set ordering for detecting patterns in set matrices. Its interaction is designed for rich and rapid data exploration. We demonstrate results on a wide range of datasets from different domains with varying characteristics, and report on expert reviews and a case study using student enrollment and degree data with assistant deans at a major public university.	Mehmet Adil Yalçin;Niklas Elmqvist;Benjamin B. Bederson	Univ. of Maryland, College Park, MD, USA|c|;;	10.1109/TVCG.2011.186;10.1109/TVCG.2013.184;10.1109/TVCG.2011.185;10.1109/TVCG.2009.122;10.1109/TVCG.2007.70535;10.1109/TVCG.2008.144;10.1109/INFVIS.2004.1;10.1109/TVCG.2007.70539;10.1109/TVCG.2008.141;10.1109/TVCG.2014.2346248;10.1109/TVCG.2010.210;10.1109/TVCG.2014.2346249	Multi-valued attributes, sets, visualization, set visualization, data exploration, interaction, design, scalability	
InfoVis	2015	Reactive Vega: A Streaming Dataflow Architecture for Declarative Interactive Visualization	10.1109/TVCG.2015.2467091	http://dx.doi.org/10.1109/TVCG.2015.2467091	659	668	J	We present Reactive Vega, a system architecture that provides the first robust and comprehensive treatment of declarative visual and interaction design for data visualization. Starting from a single declarative specification, Reactive Vega constructs a dataflow graph in which input data, scene graph elements, and interaction events are all treated as first-class streaming data sources. To support expressive interactive visualizations that may involve time-varying scalar, relational, or hierarchical data, Reactive Vega's dataflow graph can dynamically re-write itself at runtime by extending or pruning branches in a data-driven fashion. We discuss both compile- and run-time optimizations applied within Reactive Vega, and share the results of benchmark studies that indicate superior interactive performance to both D3 and the original, non-reactive Vega system.	Arvind Satyanarayan;Ryan Russell;Jane Hoffswell;Jeffrey Heer	;;;	10.1109/VISUAL.1995.480821;10.1109/TVCG.2009.174;10.1109/TVCG.2011.185;10.1109/TVCG.2010.144;10.1109/TVCG.2014.2346250;10.1109/TVCG.2013.179;10.1109/TVCG.2010.177;10.1109/VISUAL.1996.567752;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2004.12;10.1109/TVCG.2015.2467191;10.1109/TVCG.2007.70515	Information visualization, systems, toolkits, declarative specification, optimization, interaction, streaming data	
InfoVis	2015	Visualization, Selection, and Analysis of Traffic Flows	10.1109/TVCG.2015.2467112	http://dx.doi.org/10.1109/TVCG.2015.2467112	379	388	J	Visualization of the trajectories of moving objects leads to dense and cluttered images, which hinders exploration and understanding. It also hinders adding additional visual information, such as direction, and makes it difficult to interactively extract traffic flows, i.e., subsets of trajectories. In this paper we present our approach to visualize traffic flows and provide interaction tools to support their exploration. We show an overview of the traffic using a density map. The directions of traffic flows are visualized using a particle system on top of the density map. The user can extract traffic flows using a novel selection widget that allows for the intuitive selection of an area, and filtering on a range of directions and any additional attributes. Using simple, visual set expressions, the user can construct more complicated selections. The dynamic behaviors of selected flows may then be shown in annotation windows in which they can be interactively explored and compared. We validate our approach through use cases where we explore and analyze the temporal behavior of aircraft and vessel trajectories, e.g., landing and takeoff sequences, or the evolution of flight route density. The aircraft use cases have been developed and validated in collaboration with domain experts.	Roeland Scheepens;Christophe Hurter;Huub van de Wetering;Jarke J. van Wijk	Dept. of Math. & Comput. Sci., Eindhoven Univ. of Technol., Eindhoven, Netherlands|c|;;;	10.1109/TVCG.2011.185;10.1109/TVCG.2011.261;10.1109/VISUAL.1999.809905;10.1109/VISUAL.1998.745294	Moving Object Visualization, traffic flows, interaction	
InfoVis	2015	Optimal Sets of Projections of High-Dimensional Data	10.1109/TVCG.2015.2467132	http://dx.doi.org/10.1109/TVCG.2015.2467132	609	618	J	Finding good projections of n-dimensional datasets into a 2D visualization domain is one of the most important problems in Information Visualization. Users are interested in getting maximal insight into the data by exploring a minimal number of projections. However, if the number is too small or improper projections are used, then important data patterns might be overlooked. We propose a data-driven approach to find minimal sets of projections that uniquely show certain data patterns. For this we introduce a dissimilarity measure of data projections that discards affine transformations of projections and prevents repetitions of the same data patterns. Based on this, we provide complete data tours of at most n/2 projections. Furthermore, we propose optimal paths of projection matrices for an interactive data exploration. We illustrate our technique with a set of state-of-the-art real high-dimensional benchmark datasets.	Dirk J. Lehmann;Holger Theisel	Univ. of Magdeburg, Magdeburg, Germany|c|;	10.1109/VAST.2010.5652433;10.1109/VAST.2011.6102437;10.1109/TVCG.2011.229;10.1109/VISUAL.1997.663916;10.1109/TVCG.2011.220;10.1109/TVCG.2013.182;10.1109/TVCG.2010.207;10.1109/VAST.2006.261423;10.1109/INFVIS.2005.1532142	Multivariate Projections, Star Coordinates, Radial Visualization, High-dimensional Data	
InfoVis	2015	Voyager: Exploratory Analysis via Faceted Browsing of Visualization Recommendations	10.1109/TVCG.2015.2467191	http://dx.doi.org/10.1109/TVCG.2015.2467191	649	658	J	General visualization tools typically require manual specification of views: analysts must select data variables and then choose which transformations and visual encodings to apply. These decisions often involve both domain and visualization design expertise, and may impose a tedious specification process that impedes exploration. In this paper, we seek to complement manual chart construction with interactive navigation of a gallery of automatically-generated visualizations. We contribute Voyager, a mixed-initiative system that supports faceted browsing of recommended charts chosen according to statistical and perceptual measures. We describe Voyager's architecture, motivating design principles, and methods for generating and interacting with visualization recommendations. In a study comparing Voyager to a manual visualization specification tool, we find that Voyager facilitates exploration of previously unseen data and leads to increased data variable coverage. We then distill design implications for visualization tools, in particular the need to balance rapid exploration and targeted question-answering.	Kanit Wongsuphasawat;Dominik Moritz;Anushka Anand;Jock D. Mackinlay;Bill Howe;Jeffrey Heer	;;;;;	10.1109/TVCG.2014.2346297;10.1109/TVCG.2009.174;10.1109/TVCG.2011.185;10.1109/TVCG.2007.70594;10.1109/TVCG.2014.2346291;10.1109/INFVIS.2000.885086	User interfaces, information visualization, exploratory analysis, visualization recommendation, mixed-initiative systems	
InfoVis	2015	How do People Make Sense of Unfamiliar Visualizations?: A Grounded Model of Novice's Information Visualization Sensemaking	10.1109/TVCG.2015.2467195	http://dx.doi.org/10.1109/TVCG.2015.2467195	499	508	J	In this paper, we would like to investigate how people make sense of unfamiliar information visualizations. In order to achieve the research goal, we conducted a qualitative study by observing 13 participants when they endeavored to make sense of three unfamiliar visualizations (i.e., a parallel-coordinates plot, a chord diagram, and a treemap) that they encountered for the first time. We collected data including audio/video record of think-aloud sessions and semi-structured interview; and analyzed the data using the grounded theory method. The primary result of this study is a grounded model of NOvice's information VIsualization Sensemaking (NOVIS model), which consists of the five major cognitive activities: 1 encountering visualization, 2 constructing a frame, 3 exploring visualization, 4 questioning the frame, and 5 floundering on visualization. We introduce the NOVIS model by explaining the five activities with representative quotes from our participants. We also explore the dynamics in the model. Lastly, we compare with other existing models and share further research directions that arose from our observations.	Sukwon Lee;Sung-Hee Kim;Ya-Hsin Hung;Heidi Lam;Youn ah Kang;Ji Soo Yi	Sch. of Ind. Eng., Purdue Univ., West Lafayette, IN, USA|c|;;;;;	10.1109/TVCG.2013.234;10.1109/TVCG.2014.2346984;10.1109/TVCG.2010.164;10.1109/VAST.2011.6102435;10.1109/TVCG.2014.2346452;10.1109/TVCG.2010.177;10.1109/TVCG.2014.2346481;10.1109/TVCG.2010.179;10.1109/TVCG.2007.70515	Sensemaking model, information visualization, novice users, grounded theory, qualitative study	
InfoVis	2015	Visualizing Multiple Variables Across Scale and Geography	10.1109/TVCG.2015.2467199	http://dx.doi.org/10.1109/TVCG.2015.2467199	599	608	J	Comparing multiple variables to select those that effectively characterize complex entities is important in a wide variety of domains - geodemographics for example. Identifying variables that correlate is a common practice to remove redundancy, but correlation varies across space, with scale and over time, and the frequently used global statistics hide potentially important differentiating local variation. For more comprehensive and robust insights into multivariate relations, these local correlations need to be assessed through various means of defining locality. We explore the geography of this issue, and use novel interactive visualization to identify interdependencies in multivariate data sets to support geographically informed multivariate analysis. We offer terminology for considering scale and locality, visual techniques for establishing the effects of scale on correlation and a theoretical framework through which variation in geographic correlation with scale and locality are addressed explicitly. Prototype software demonstrates how these contributions act together. These techniques enable multiple variables and their geographic characteristics to be considered concurrently as we extend visual parameter space analysis (vPSA) to the spatial domain. We find variable correlations to be sensitive to scale and geography to varying degrees in the context of energy-based geodemographics. This sensitivity depends upon the calculation of locality as well as the geographical and statistical structure of the variable.	Sarah Goodwin;Jason Dykes;Aidan Slingsby;Cagatay Turkay	;;;	10.1109/TVCG.2007.70558;10.1109/TVCG.2013.145;10.1109/TVCG.2007.70539;10.1109/TVCG.2014.2346482;10.1109/VAST.2011.6102448;10.1109/TVCG.2013.125;10.1109/TVCG.2014.2346321;10.1109/TVCG.2009.128;10.1109/TVCG.2011.197;10.1109/TVCG.2012.256;10.1109/TVCG.2014.2346265	Scale, Geography, Multivariate, Sensitivity Analysis, Variable Selection, Local Statistics, Geodemographics, Energy	
InfoVis	2015	Suggested Interactivity: Seeking Perceived Affordances for Information Visualization	10.1109/TVCG.2015.2467201	http://dx.doi.org/10.1109/TVCG.2015.2467201	639	648	J	In this article, we investigate methods for suggesting the interactivity of online visualizations embedded with text. We first assess the need for such methods by conducting three initial experiments on Amazon's Mechanical Turk. We then present a design space for Suggested Interactivity (i. e., visual cues used as perceived affordances-SI), based on a survey of 382 HTML5 and visualization websites. Finally, we assess the effectiveness of three SI cues we designed for suggesting the interactivity of bar charts embedded with text. Our results show that only one cue (SI3) was successful in inciting participants to interact with the visualizations, and we hypothesize this is because this particular cue provided feedforward.	Jeremy Boy;Louis Eveillard;Françoise Détienne;Jean-Daniel Fekete	;;;	10.1109/TVCG.2014.2346984;10.1109/TVCG.2013.134;10.1109/TVCG.2010.179;10.1109/INFVIS.2005.1532122	Suggested interactivity, perceived affordances, information visualization for the people, online visualization	
InfoVis	2015	High-Quality Ultra-Compact Grid Layout of Grouped Networks	10.1109/TVCG.2015.2467251	http://dx.doi.org/10.1109/TVCG.2015.2467251	339	348	J	Prior research into network layout has focused on fast heuristic techniques for layout of large networks, or complex multi-stage pipelines for higher quality layout of small graphs. Improvements to these pipeline techniques, especially for orthogonal-style layout, are difficult and practical results have been slight in recent years. Yet, as discussed in this paper, there remain significant issues in the quality of the layouts produced by these techniques, even for quite small networks. This is especially true when layout with additional grouping constraints is required. The first contribution of this paper is to investigate an ultra-compact, grid-like network layout aesthetic that is motivated by the grid arrangements that are used almost universally by designers in typographical layout. Since the time when these heuristic and pipeline-based graph-layout methods were conceived, generic technologies (MIP, CP and SAT) for solving combinatorial and mixed-integer optimization problems have improved massively. The second contribution of this paper is to reassess whether these techniques can be used for high-quality layout of small graphs. While they are fast enough for graphs of up to 50 nodes we found these methods do not scale up. Our third contribution is a large-neighborhood search meta-heuristic approach that is scalable to larger networks.	Vahan Yoghourdjian;Tim Dwyer;Graeme Gange;Steve Kieffer;Karsten Klein;Kim Marriott	;;;;;	10.1109/TVCG.2008.117;10.1109/TVCG.2013.151;10.1109/TVCG.2006.156;10.1109/TVCG.2009.109;10.1109/INFVIS.2003.1249009;10.1109/TVCG.2015.2467451;10.1109/TVCG.2012.245	Network visualization, graph drawing, power graph, optimization, large-neighborhood search	
InfoVis	2015	Sketching Designs Using the Five Design-Sheet Methodology	10.1109/TVCG.2015.2467271	http://dx.doi.org/10.1109/TVCG.2015.2467271	419	428	J	Sketching designs has been shown to be a useful way of planning and considering alternative solutions. The use of lo-fidelity prototyping, especially paper-based sketching, can save time, money and converge to better solutions more quickly. However, this design process is often viewed to be too informal. Consequently users do not know how to manage their thoughts and ideas (to first think divergently, to then finally converge on a suitable solution). We present the Five Design Sheet (FdS) methodology. The methodology enables users to create information visualization interfaces through lo-fidelity methods. Users sketch and plan their ideas, helping them express different possibilities, think through these ideas to consider their potential effectiveness as solutions to the task (sheet 1); they create three principle designs (sheets 2,3 and 4); before converging on a final realization design that can then be implemented (sheet 5). In this article, we present (i) a review of the use of sketching as a planning method for visualization and the benefits of sketching, (ii) a detailed description of the Five Design Sheet (FdS) methodology, and (iii) an evaluation of the FdS using the System Usability Scale, along with a case-study of its use in industry and experience of its use in teaching.	Jonathan C. Roberts;Christopher James Headleand;Panagiotis D. Ritsos	;;	10.1109/TVCG.2010.132;10.1109/INFVIS.2000.885092;10.1109/TVCG.2006.178;10.1109/VISUAL.1994.346304;10.1109/TVCG.2014.2346331;10.1109/TVCG.2009.111;10.1109/TVCG.2012.213;10.1109/INFVIS.2004.59;10.1109/TVCG.2012.262;10.1109/TVCG.2007.70515;10.1109/TVCG.2008.171	Lo-fidelity prototyping, User-centred design, Sketching for visualization, Ideation	
InfoVis	2015	Acquired Codes of Meaning in Data Visualization and Infographics: Beyond Perceptual Primitives	10.1109/TVCG.2015.2467321	http://dx.doi.org/10.1109/TVCG.2015.2467321	509	518	J	While information visualization frameworks and heuristics have traditionally been reluctant to include acquired codes of meaning, designers are making use of them in a wide variety of ways. Acquired codes leverage a user's experience to understand the meaning of a visualization. They range from figurative visualizations which rely on the reader's recognition of shapes, to conventional arrangements of graphic elements which represent particular subjects. In this study, we used content analysis to codify acquired meaning in visualization. We applied the content analysis to a set of infographics and data visualizations which are exemplars of innovative and effective design. 88% of the infographics and 71% of data visualizations in the sample contain at least one use of figurative visualization. Conventions on the arrangement of graphics are also widespread in the sample. In particular, a comparison of representations of time and other quantitative data showed that conventions can be specific to a subject. These results suggest that there is a need for information visualization research to expand its scope beyond perceptual channels, to include social and culturally constructed meaning. Our paper demonstrates a viable method for identifying figurative techniques and graphic conventions and integrating them into heuristics for visualization design.	Lydia Byrne;Daniel Angus;Janet Wiles	;;	10.1109/TVCG.2013.234;10.1109/TVCG.2010.126;10.1109/INFVIS.2005.1532122;10.1109/TVCG.2011.255;10.1109/TVCG.2007.70594;10.1109/TVCG.2010.179;10.1109/INFVIS.2004.59;10.1109/TVCG.2012.221;10.1109/TVCG.2008.171	Visual Design, Taxonomies, Illustrative Visualization, Design Methodologies	
InfoVis	2015	Off the Radar: Comparative Evaluation of Radial Visualization Solutions for Composite Indicators	10.1109/TVCG.2015.2467322	http://dx.doi.org/10.1109/TVCG.2015.2467322	569	578	J	A composite indicator (CI) is a measuring and benchmark tool used to capture multi-dimensional concepts, such as Information and Communication Technology (ICT) usage. Individual indicators are selected and combined to reflect a phenomena being measured. Visualization of a composite indicator is recommended as a tool to enable interested stakeholders, as well as the public audience, to better understand the indicator components and evolution overtime. However, existing CI visualizations introduce a variety of solutions and there is a lack in CI's visualization guidelines. Radial visualizations are popular among these solutions because of CI's inherent multi-dimensionality. Although in dispute, Radar-charts are often used for CI presentation. However, no empirical evidence on Radar's effectiveness and efficiency for common CI tasks is available. In this paper, we aim to fill this gap by reporting on a controlled experiment that compares the Radar chart technique with two other radial visualization methods: Flowercharts as used in the well-known OECD Betterlife index, and Circle-charts which could be adopted for this purpose. Examples of these charts in the current context are shown in Figure 1. We evaluated these charts, showing the same data with each of the mentioned techniques applying small multiple views for different dimensions of the data. We compared users' performance and preference empirically under a formal task-taxonomy. Results indicate that the Radar chart was the least effective and least liked, while performance of the two other options were mixed and dependent on the task. Results also showed strong preference of participants toward the Flower chart. Summarizing our results, we provide specific design guidelines for composite indicator visualization.	Yael Albo;Joel Lanir;Peter Bak;Sheizaf Rafaeli	Univ. of Haifa, Haifa, Israel|c|;;;	10.1109/TVCG.2010.209;10.1109/TVCG.2008.125	Visualization evaluation, radial layout design, composite indicator visualization, experiment	
InfoVis	2015	Automatic Selection of Partitioning Variables for Small Multiple Displays	10.1109/TVCG.2015.2467323	http://dx.doi.org/10.1109/TVCG.2015.2467323	669	677	J	Effective small multiple displays are created by partitioning a visualization on variables that reveal interesting conditional structure in the data. We propose a method that automatically ranks partitioning variables, allowing analysts to focus on the most promising small multiple displays. Our approach is based on a randomized, non-parametric permutation test, which allows us to handle a wide range of quality measures for visual patterns defined on many different visualization types, while discounting spurious patterns. We demonstrate the effectiveness of our approach on scatterplots of real-world, multidimensional datasets.	Anushka Anand;Justin Talbot	;	10.1109/VAST.2010.5652433;10.1109/INFVIS.1998.729559;10.1109/TVCG.2011.229;10.1109/TVCG.2006.161;10.1109/TVCG.2010.184;10.1109/TVCG.2009.153;10.1109/INFVIS.2003.1249006;10.1109/TVCG.2007.70594;10.1109/VAST.2006.261423;10.1109/INFVIS.2000.885086;10.1109/VAST.2009.5332628;10.1109/TVCG.2010.161;10.1109/INFVIS.2005.1532142	Small multiple displays, Visualization selection, Multidimensional data	
InfoVis	2015	A comparative study between RadViz and Star Coordinates	10.1109/TVCG.2015.2467324	http://dx.doi.org/10.1109/TVCG.2015.2467324	619	628	J	RadViz and star coordinates are two of the most popular projection-based multivariate visualization techniques that arrange variables in radial layouts. Formally, the main difference between them consists of a nonlinear normalization step inherent in RadViz. In this paper we show that, although RadViz can be useful when analyzing sparse data, in general this design choice limits its applicability and introduces several drawbacks for exploratory data analysis. In particular, we observe that the normalization step introduces nonlinear distortions, can encumber outlier detection, prevents associating the plots with useful linear mappings, and impedes estimating original data attributes accurately. In addition, users have greater flexibility when choosing different layouts and views of the data in star coordinates. Therefore, we suggest that analysts and researchers should carefully consider whether RadViz's normalization step is beneficial regarding the data sets' characteristics and analysis tasks.	Manuel Rubio-Sánchez;Laura Raya;Francisco Diaz;Alberto Sanchez	;;;	10.1109/VAST.2010.5652433;10.1109/INFVIS.1998.729559;10.1109/VISUAL.1997.663916;10.1109/TVCG.2013.182;10.1109/TVCG.2014.2346258;10.1109/TVCG.2008.173	RadViz, Star coordinates, Exploratory data analysis, Cluster analysis, Classification, Outlier detection	
InfoVis	2015	TimeSpan: Using Visualization to Explore Temporal Multi-dimensional Data of Stroke Patients	10.1109/TVCG.2015.2467325	http://dx.doi.org/10.1109/TVCG.2015.2467325	409	418	J	We present TimeSpan, an exploratory visualization tool designed to gain a better understanding of the temporal aspects of the stroke treatment process. Working with stroke experts, we seek to provide a tool to help improve outcomes for stroke victims. Time is of critical importance in the treatment of acute ischemic stroke patients. Every minute that the artery stays blocked, an estimated 1.9 million neurons and 12 km of myelinated axons are destroyed. Consequently, there is a critical need for efficiency of stroke treatment processes. Optimizing time to treatment requires a deep understanding of interval times. Stroke health care professionals must analyze the impact of procedures, events, and patient attributes on time-ultimately, to save lives and improve quality of life after stroke. First, we interviewed eight domain experts, and closely collaborated with two of them to inform the design of TimeSpan. We classify the analytical tasks which a visualization tool should support and extract design goals from the interviews and field observations. Based on these tasks and the understanding gained from the collaboration, we designed TimeSpan, a web-based tool for exploring multi-dimensional and temporal stroke data. We describe how TimeSpan incorporates factors from stacked bar graphs, line charts, histograms, and a matrix visualization to create an interactive hybrid view of temporal data. From feedback collected from domain experts in a focus group session, we reflect on the lessons we learned from abstracting the tasks and iteratively designing TimeSpan.	Mona Hosseinkhani Loorak;Charles Perin;Noreen Kamal;Michael Hill;M. Sheelagh T. Carpendale	Dept. of Comput. Sci., Univ. of Calgary, Calgary, AB, Canada|c|;;;;	10.1109/INFVIS.2005.1532136;10.1109/VAST.2006.261421;10.1109/TVCG.2014.2346682;10.1109/TVCG.2013.200;10.1109/TVCG.2014.2346279;10.1109/INFVIS.2005.1532152;10.1109/TVCG.2009.187;10.1109/TVCG.2012.225;10.1109/TVCG.2007.70515	Multi-dimensional data, Temporal event sequences, Electronic health records	
InfoVis	2015	HOLA: Human-like Orthogonal Network Layout	10.1109/TVCG.2015.2467451	http://dx.doi.org/10.1109/TVCG.2015.2467451	349	358	J	Over the last 50 years a wide variety of automatic network layout algorithms have been developed. Some are fast heuristic techniques suitable for networks with hundreds of thousands of nodes while others are multi-stage frameworks for higher-quality layout of smaller networks. However, despite decades of research currently no algorithm produces layout of comparable quality to that of a human. We give a new ΓÇ£human-centredΓÇ¥ methodology for automatic network layout algorithm design that is intended to overcome this deficiency. User studies are first used to identify the aesthetic criteria algorithms should encode, then an algorithm is developed that is informed by these criteria and finally, a follow-up study evaluates the algorithm output. We have used this new methodology to develop an automatic orthogonal network layout method, HOLA, that achieves measurably better (by user study) layout than the best available orthogonal layout algorithm and which produces layouts of comparable quality to those produced by hand.	Steve Kieffer;Tim Dwyer;Kim Marriott;Michael Wybrow	;;;	10.1109/TVCG.2006.120;10.1109/TVCG.2012.208;10.1109/TVCG.2013.151;10.1109/TVCG.2006.156;10.1109/TVCG.2009.109;10.1109/TVCG.2008.141;10.1109/TVCG.2006.147;10.1109/TVCG.2012.245;10.1109/TVCG.2008.155	Graph layout, orthogonal layout, automatic layout algorithms, user-generated layout, graph-drawing aesthetics	
InfoVis	2015	Speculative Practices: Utilizing InfoVis to Explore Untapped Literary Collections	10.1109/TVCG.2015.2467452	http://dx.doi.org/10.1109/TVCG.2015.2467452	429	438	J	In this paper we exemplify how information visualization supports speculative thinking, hypotheses testing, and preliminary interpretation processes as part of literary research. While InfoVis has become a buzz topic in the digital humanities, skepticism remains about how effectively it integrates into and expands on traditional humanities research approaches. From an InfoVis perspective, we lack case studies that show the specific design challenges that make literary studies and humanities research at large a unique application area for information visualization. We examine these questions through our case study of the Speculative W@nderverse, a visualization tool that was designed to enable the analysis and exploration of an untapped literary collection consisting of thousands of science fiction short stories. We present the results of two empirical studies that involved general-interest readers and literary scholars who used the evolving visualization prototype as part of their research for over a year. Our findings suggest a design space for visualizing literary collections that is defined by (1) their academic and public relevance, (2) the tension between qualitative vs. quantitative methods of interpretation, (3) result-vs. process-driven approaches to InfoVis, and (4) the unique material and visual qualities of cultural collections. Through the Speculative W@nderverse we demonstrate how visualization can bridge these sometimes contradictory perspectives by cultivating curiosity and providing entry points into literary collections while, at the same time, supporting multiple aspects of humanities research processes.	Uta Hinrichs;Stefania Forlini;Bridget Moynihan	SACHI Group, Univ. of St. Andrews, St. Andrews, UK|c|;;	10.1109/TVCG.2012.272;10.1109/TVCG.2014.2346431;10.1109/TVCG.2008.175;10.1109/TVCG.2008.127;10.1109/TVCG.2007.70541;10.1109/TVCG.2012.213;10.1109/VAST.2007.4389006;10.1109/TVCG.2009.165;10.1109/TVCG.2007.70577;10.1109/TVCG.2009.171;10.1109/TVCG.2008.172;10.1109/VAST.2008.4677370	Digital Humanities, Interlinked Visualization, Literary Studies, Cultural Collections, Science Fiction	
InfoVis	2015	A Linguistic Approach to Categorical Color Assignment for Data Visualization	10.1109/TVCG.2015.2467471	http://dx.doi.org/10.1109/TVCG.2015.2467471	698	707	J	When data categories have strong color associations, it is useful to use these semantically meaningful concept-color associations in data visualizations. In this paper, we explore how linguistic information about the terms defining the data can be used to generate semantically meaningful colors. To do this effectively, we need first to establish that a term has a strong semantic color association, then discover which color or colors express it. Using co-occurrence measures of color name frequencies from Google n-grams, we define a measure for colorability that describes how strongly associated a given term is to any of a set of basic color terms. We then show how this colorability score can be used with additional semantic analysis to rank and retrieve a representative color from Google Images. Alternatively, we use symbolic relationships defined by WordNet to select identity colors for categories such as countries or brands. To create visually distinct color palettes, we use k-means clustering to create visually distinct sets, iteratively reassigning terms with multiple basic color associations as needed. This can be additionally constrained to use colors only in a predefined palette.	Vidya Setlur;Maureen C. Stone	;		linguistics, natural language processing, semantics, color names, categorical color, Google n-grams, WordNet, XKCD	
InfoVis	2015	Beyond Weber's Law: A Second Look at Ranking Visualizations of Correlation	10.1109/TVCG.2015.2467671	http://dx.doi.org/10.1109/TVCG.2015.2467671	469	478	J	Models of human perception - including perceptual ΓÇ£lawsΓÇ¥ - can be valuable tools for deriving visualization design recommendations. However, it is important to assess the explanatory power of such models when using them to inform design. We present a secondary analysis of data previously used to rank the effectiveness of bivariate visualizations for assessing correlation (measured with Pearson's r) according to the well-known Weber-Fechner Law. Beginning with the model of Harrison et al. [1], we present a sequence of refinements including incorporation of individual differences, log transformation, censored regression, and adoption of Bayesian statistics. Our model incorporates all observations dropped from the original analysis, including data near ceilings caused by the data collection process and entire visualizations dropped due to large numbers of observations worse than chance. This model deviates from Weber's Law, but provides improved predictive accuracy and generalization. Using Bayesian credibility intervals, we derive a partial ranking that groups visualizations with similar performance, and we give precise estimates of the difference in performance between these groups. We find that compared to other visualizations, scatterplots are unique in combining low variance between individuals and high precision on both positively- and negatively correlated data. We conclude with a discussion of the value of data sharing and replication, and share implications for modeling similar experimental data.	Matthew Kay;Jeffrey Heer	;	10.1109/TVCG.2014.2346979	Weber's law, perception of correlation, log transformation, censored regression, Bayesian methods	
InfoVis	2015	AmbiguityVis: Visualization of Ambiguity in Graph Layouts	10.1109/TVCG.2015.2467691	http://dx.doi.org/10.1109/TVCG.2015.2467691	359	368	J	Node-link diagrams provide an intuitive way to explore networks and have inspired a large number of automated graph layout strategies that optimize aesthetic criteria. However, any particular drawing approach cannot fully satisfy all these criteria simultaneously, producing drawings with visual ambiguities that can impede the understanding of network structure. To bring attention to these potentially problematic areas present in the drawing, this paper presents a technique that highlights common types of visual ambiguities: ambiguous spatial relationships between nodes and edges, visual overlap between community structures, and ambiguity in edge bundling and metanodes. Metrics, including newly proposed metrics for abnormal edge lengths, visual overlap in community structures and node/edge aggregation, are proposed to quantify areas of ambiguity in the drawing. These metrics and others are then displayed using a heatmap-based visualization that provides visual feedback to developers of graph drawing and visualization approaches, allowing them to quickly identify misleading areas. The novel metrics and the heatmap-based visualization allow a user to explore ambiguities in graph layouts from multiple perspectives in order to make reasonable graph layout choices. The effectiveness of the technique is demonstrated through case studies and expert reviews.	Yong Wang;Qiaomu Shen;Daniel Archambault;Zhiguang Zhou;Min Zhu;Sixiao Yang;Huamin Qu	;;;;;;	10.1109/TVCG.2006.120;10.1109/TVCG.2006.147;10.1109/TVCG.2012.245;10.1109/VAST.2009.5332628;10.1109/TVCG.2008.155;10.1109/TVCG.2012.189	Visual Ambiguity, Visualization, Node-link diagram, Graph layout, Graph visualization	
InfoVis	2015	Probing Projections: Interaction Techniques for Interpreting Arrangements and Errors of Dimensionality Reductions	10.1109/TVCG.2015.2467717	http://dx.doi.org/10.1109/TVCG.2015.2467717	629	638	J	We introduce a set of integrated interaction techniques to interpret and interrogate dimensionality-reduced data. Projection techniques generally aim to make a high-dimensional information space visible in form of a planar layout. However, the meaning of the resulting data projections can be hard to grasp. It is seldom clear why elements are placed far apart or close together and the inevitable approximation errors of any projection technique are not exposed to the viewer. Previous research on dimensionality reduction focuses on the efficient generation of data projections, interactive customisation of the model, and comparison of different projection techniques. There has been only little research on how the visualization resulting from data projection is interacted with. We contribute the concept of probing as an integrated approach to interpreting the meaning and quality of visualizations and propose a set of interactive methods to examine dimensionality-reduced data as well as the projection itself. The methods let viewers see approximation errors, question the positioning of elements, compare them to each other, and visualize the influence of data dimensions on the projection space. We created a web-based system implementing these methods, and report on findings from an evaluation with data analysts using the prototype to examine multidimensional datasets.	Julian Stahnke;Marian Dörk;Boris Müller;Andreas Thom	;;;	10.1109/TVCG.2013.157;10.1109/TVCG.2011.255;10.1109/VAST.2010.5652392;10.1109/VISUAL.1990.146402;10.1109/TVCG.2009.153;10.1109/TVCG.2012.279;10.1109/TVCG.2014.2346419;10.1109/TVCG.2013.153;10.1109/TVCG.2009.127;10.1109/VISUAL.1994.346302;10.1109/TVCG.2007.70589;10.1109/INFVIS.2004.60;10.1109/INFVIS.1995.528686	Information visualization, interactivity, dimensionality reduction, multidimensional scaling	
InfoVis	2015	Beyond Memorability: Visualization Recognition and Recall	10.1109/TVCG.2015.2467732	http://dx.doi.org/10.1109/TVCG.2015.2467732	519	528	J	In this paper we move beyond memorability and investigate how visualizations are recognized and recalled. For this study we labeled a dataset of 393 visualizations and analyzed the eye movements of 33 participants as well as thousands of participant-generated text descriptions of the visualizations. This allowed us to determine what components of a visualization attract people's attention, and what information is encoded into memory. Our findings quantitatively support many conventional qualitative design guidelines, including that (1) titles and supporting text should convey the message of a visualization, (2) if used appropriately, pictograms do not interfere with understanding and can improve recognition, and (3) redundancy helps effectively communicate the message. Importantly, we show that visualizations memorable ΓÇ£at-a-glanceΓÇ¥ are also capable of effectively conveying the message of the visualization. Thus, a memorable visualization is often also an effective one.	Michelle Borkin;Zoya Bylinskii;Nam Wook Kim;Constance May Bainbridge;Chelsea S. Yeh;Daniel Borkin;Hanspeter Pfister;Aude Oliva	;;;;;;;	10.1109/TVCG.2012.197;10.1109/TVCG.2013.234;10.1109/TVCG.2011.193;10.1109/TVCG.2012.233;10.1109/TVCG.2011.175;10.1109/TVCG.2013.234;10.1109/TVCG.2012.215;10.1109/VAST.2010.5653598;10.1109/TVCG.2012.245;10.1109/TVCG.2012.221	Information visualization, memorability, recognition, recall, eye-tracking study	
InfoVis	2015	TimeNotes: A Study on Effective Chart Visualization and Interaction Techniques for Time-Series Data	10.1109/TVCG.2015.2467751	http://dx.doi.org/10.1109/TVCG.2015.2467751	549	558	J	Collecting sensor data results in large temporal data sets which need to be visualized, analyzed, and presented. One-dimensional time-series charts are used, but these present problems when screen resolution is small in comparison to the data. This can result in severe over-plotting, giving rise for the requirement to provide effective rendering and methods to allow interaction with the detailed data. Common solutions can be categorized as multi-scale representations, frequency based, and lens based interaction techniques. In this paper, we comparatively evaluate existing methods, such as Stack Zoom [15] and ChronoLenses [38], giving a graphical overview of each and classifying their ability to explore and interact with data. We propose new visualizations and other extensions to the existing approaches. We undertake and report an empirical study and a field study using these techniques.	James S. Walker;Rita Borgo;Mark W. Jones	;;	10.1109/TVCG.2009.181;10.1109/TVCG.2014.2346428;10.1109/INFVIS.2005.1532148;10.1109/TVCG.2011.160;10.1109/TVCG.2010.162;10.1109/TVCG.2010.193;10.1109/INFVIS.1999.801860;10.1109/TVCG.2011.195	Time-series Exploration, Focus+Context, Lens, Interaction Techniques	
InfoVis	2015	Visual Encodings of Temporal Uncertainty: A Comparative User Study	10.1109/TVCG.2015.2467752	http://dx.doi.org/10.1109/TVCG.2015.2467752	539	548	J	A number of studies have investigated different ways of visualizing uncertainty. However, in the temporal dimension, it is still an open question how to best represent uncertainty, since the special characteristics of time require special visual encodings and may provoke different interpretations. Thus, we have conducted a comprehensive study comparing alternative visual encodings of intervals with uncertain start and end times: gradient plots, violin plots, accumulated probability plots, error bars, centered error bars, and ambiguation. Our results reveal significant differences in error rates and completion time for these different visualization types and different tasks. We recommend using ambiguation - using a lighter color value to represent uncertain regions - or error bars for judging durations and temporal bounds, and gradient plots - using fading color or transparency - for judging probability values.	Theresia Gschwandtner;Markus Bögl;Paolo Federico 0001;Silvia Miksch	;;;	10.1109/TVCG.2014.2346298;10.1109/TVCG.2012.279;10.1109/INFVIS.2002.1173145;10.1109/TVCG.2009.114	Uncertainty, temporal intervals, visualization	
InfoVis	2015	Visually Comparing Weather Features in Forecasts	10.1109/TVCG.2015.2467754	http://dx.doi.org/10.1109/TVCG.2015.2467754	389	398	J	Meteorologists process and analyze weather forecasts using visualization in order to examine the behaviors of and relationships among weather features. In this design study conducted with meteorologists in decision support roles, we identified and attempted to address two significant common challenges in weather visualization: the employment of inconsistent and often ineffective visual encoding practices across a wide range of visualizations, and a lack of support for directly visualizing how different weather features relate across an ensemble of possible forecast outcomes. In this work, we present a characterization of the problems and data associated with meteorological forecasting, we propose a set of informed default encoding choices that integrate existing meteorological conventions with effective visualization practice, and we extend a set of techniques as an initial step toward directly visualizing the interactions of multiple features over an ensemble forecast. We discuss the integration of these contributions into a functional prototype tool, and also reflect on the many practical challenges that arise when working with weather data.	P. Samuel Quinan;Miriah D. Meyer	;	10.1109/VISUAL.1990.146361;10.1109/VISUAL.2002.1183788;10.1109/TVCG.2011.209;10.1109/TVCG.2010.181;10.1109/TVCG.2012.213;10.1109/TVCG.2013.143	Design study, weather, geographic/geospatial visualization, ensemble data	
InfoVis	2015	Improving Bayesian Reasoning: The Effects of Phrasing, Visualization, and Spatial Ability	10.1109/TVCG.2015.2467758	http://dx.doi.org/10.1109/TVCG.2015.2467758	529	538	J	Decades of research have repeatedly shown that people perform poorly at estimating and understanding conditional probabilities that are inherent in Bayesian reasoning problems. Yet in the medical domain, both physicians and patients make daily, life-critical judgments based on conditional probability. Although there have been a number of attempts to develop more effective ways to facilitate Bayesian reasoning, reports of these findings tend to be inconsistent and sometimes even contradictory. For instance, the reported accuracies for individuals being able to correctly estimate conditional probability range from 6% to 62%. In this work, we show that problem representation can significantly affect accuracies. By controlling the amount of information presented to the user, we demonstrate how text and visualization designs can increase overall accuracies to as high as 77%. Additionally, we found that for users with high spatial ability, our designs can further improve their accuracies to as high as 100%. By and large, our findings provide explanations for the inconsistent reports on accuracy in Bayesian reasoning tasks and show a significant improvement over existing methods. We believe that these findings can have immediate impact on risk communication in health-related fields.	Alvitta Ottley;Evan M. Peck;Lane Harrison;Daniel Afergan;Caroline Ziemkiewicz;Holly A. Taylor;Paul K. J. Han;Remco Chang	;;;;;;;	10.1109/TVCG.2014.2346575;10.1109/VAST.2010.5653587;10.1109/TVCG.2011.255;10.1109/TVCG.2013.119;10.1109/TVCG.2012.199;10.1109/TVCG.2010.179;10.1109/VISUAL.2005.1532836	Bayesian Reasoning, Visualization, Spatial Ability, Individual Differences	
InfoVis	2015	Guidelines for Effective Usage of Text Highlighting Techniques	10.1109/TVCG.2015.2467759	http://dx.doi.org/10.1109/TVCG.2015.2467759	489	498	J	Semi-automatic text analysis involves manual inspection of text. Often, different text annotations (like part-of-speech or named entities) are indicated by using distinctive text highlighting techniques. In typesetting there exist well-known formatting conventions, such as bold typeface, italics, or background coloring, that are useful for highlighting certain parts of a given text. Also, many advanced techniques for visualization and highlighting of text exist; yet, standard typesetting is common, and the effects of standard typesetting on the perception of text are not fully understood. As such, we surveyed and tested the effectiveness of common text highlighting techniques, both individually and in combination, to discover how to maximize pop-out effects while minimizing visual interference between techniques. To validate our findings, we conducted a series of crowd-sourced experiments to determine: i) a ranking of nine commonly-used text highlighting techniques; ii) the degree of visual interference between pairs of text highlighting techniques; iii) the effectiveness of techniques for visual conjunctive search. Our results show that increasing font size works best as a single highlighting technique, and that there are significant visual interferences between some pairs of highlighting techniques. We discuss the pros and cons of different combinations as a design guideline to choose text highlighting techniques for text viewers.	Hendrik Strobelt;Daniela Oelke;Bum Chul Kwon;Tobias Schreck;Hanspeter Pfister	;;;;	10.1109/TVCG.2012.277;10.1109/VAST.2007.4389004;10.1109/TVCG.2014.2346677;10.1109/TVCG.2007.70594;10.1109/TVCG.2011.183;10.1109/TVCG.2009.139;10.1109/VAST.2011.6102453;10.1109/INFVIS.1995.528686	Text highlighting techniques, visual document analytics, text annotation, crowdsourced study	
InfoVis	2015	Poemage: Visualizing the Sonic Topology of a Poem	10.1109/TVCG.2015.2467811	http://dx.doi.org/10.1109/TVCG.2015.2467811	439	448	J	The digital humanities have experienced tremendous growth within the last decade, mostly in the context of developing computational tools that support what is called distant reading - collecting and analyzing huge amounts of textual data for synoptic evaluation. On the other end of the spectrum is a practice at the heart of the traditional humanities, close reading - the careful, in-depth analysis of a single text in order to extract, engage, and even generate as much productive meaning as possible. The true value of computation to close reading is still very much an open question. During a two-year design study, we explored this question with several poetry scholars, focusing on an investigation of sound and linguistic devices in poetry. The contributions of our design study include a problem characterization and data abstraction of the use of sound in poetry as well as Poemage, a visualization tool for interactively exploring the sonic topology of a poem. The design of Poemage is grounded in the evaluation of a series of technology probes we deployed to our poetry collaborators, and we validate the final design with several case studies that illustrate the disruptive impact technology can have on poetry scholarship. Finally, we also contribute a reflection on the challenges we faced conducting visualization research in literary studies.	Nina McCurdy;Julie Lein;Katherine Coles;Miriah D. Meyer	;;;	10.1109/TVCG.2011.186;10.1109/TVCG.2009.122;10.1109/VAST.2009.5333443;10.1109/TVCG.2008.135;10.1109/TVCG.2011.233;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2012.213;10.1109/VAST.2007.4389006;10.1109/TVCG.2009.165;10.1109/TVCG.2009.171;10.1109/INFVIS.2002.1173155;10.1109/TVCG.2008.172;10.1109/INFVIS.1995.528686	Visualization in the humanities, design studies, text and document data, graph/network data	
InfoVis	2015	Visual Mementos: Reflecting Memories with Personal Data	10.1109/TVCG.2015.2467831	http://dx.doi.org/10.1109/TVCG.2015.2467831	369	378	J	In this paper we discuss the creation of visual mementos as a new application area for visualization. We define visual mementos as visualizations of personally relevant data for the purpose of reminiscing, and sharing of life experiences. Today more people collect digital information about their life than ever before. The shift from physical to digital archives poses new challenges and opportunities for self-reflection and self-representation. Drawing on research on autobiographical memory and on the role of artifacts in reminiscing, we identified design challenges for visual mementos: mapping data to evoke familiarity, expressing subjectivity, and obscuring sensitive details for sharing. Visual mementos can make use of the known strengths of visualization in revealing patterns to show the familiar instead of the unexpected, and extend representational mappings beyond the objective to include the more subjective. To understand whether people's subjective views on their past can be reflected in a visual representation, we developed, deployed and studied a technology probe that exemplifies our concept of visual mementos. Our results show how reminiscing has been supported and reveal promising new directions for self-reflection and sharing through visual mementos of personal experiences.	Alice Thudt;Dominikus Baur;Samuel Huron;M. Sheelagh T. Carpendale	;;;	10.1109/TVCG.2010.206;10.1109/TVCG.2007.70541;10.1109/TVCG.2014.2352953;10.1109/INFVIS.2004.8	Visual Memento, Memories, Personal Visualization, Movement Data, World Wide Web	
InfoVis	2015	Time Curves: Folding Time to Visualize Patterns of Temporal Evolution in Data	10.1109/TVCG.2015.2467851	http://dx.doi.org/10.1109/TVCG.2015.2467851	559	568	J	We introduce time curves as a general approach for visualizing patterns of evolution in temporal data. Examples of such patterns include slow and regular progressions, large sudden changes, and reversals to previous states. These patterns can be of interest in a range of domains, such as collaborative document editing, dynamic network analysis, and video analysis. Time curves employ the metaphor of folding a timeline visualization into itself so as to bring similar time points close to each other. This metaphor can be applied to any dataset where a similarity metric between temporal snapshots can be defined, thus it is largely datatype-agnostic. We illustrate how time curves can visually reveal informative patterns in a range of different datasets.	Benjamin Bach;Conglei Shi;Nicolas Heulot;Tara M. Madhyastha;Thomas J. Grabowski;Pierre Dragicevic	Microsoft Res.-Inria Joint Centre, USA|c|;;;;;	10.1109/TVCG.2011.186;10.1109/TVCG.2007.70535;10.1109/INFVIS.2004.1;10.1109/TVCG.2014.2346325;10.1109/TVCG.2013.192;10.1109/INFVIS.2002.1173155	Temporal data visualization, information visualization, multidimensional scaling	
InfoVis	2015	Orientation-Enhanced Parallel Coordinate Plots	10.1109/TVCG.2015.2467872	http://dx.doi.org/10.1109/TVCG.2015.2467872	589	598	J	Parallel Coordinate Plots (PCPs) is one of the most powerful techniques for the visualization of multivariate data. However, for large datasets, the representation suffers from clutter due to overplotting. In this case, discerning the underlying data information and selecting specific interesting patterns can become difficult. We propose a new and simple technique to improve the display of PCPs by emphasizing the underlying data structure. Our Orientation-enhanced Parallel Coordinate Plots (OPCPs) improve pattern and outlier discernibility by visually enhancing parts of each PCP polyline with respect to its slope. This enhancement also allows us to introduce a novel and efficient selection method, the Orientation-enhanced Brushing (O-Brushing). Our solution is particularly useful when multiple patterns are present or when the view on certain patterns is obstructed by noise. We present the results of our approach with several synthetic and real-world datasets. Finally, we conducted a user evaluation, which verifies the advantages of the OPCPs in terms of discernibility of information in complex data. It also confirms that O-Brushing eases the selection of data patterns in PCPs and reduces the amount of necessary user interactions compared to state-of-the-art brushing techniques.	Renata Georgia Raidou;Martin Eisemann;Marcel Breeuwer;Elmar Eisemann;Anna Vilanova	;;;;	10.1109/INFVIS.1998.729559;10.1109/INFVIS.2004.68;10.1109/TVCG.2006.138;10.1109/TVCG.2007.70535;10.1109/INFVIS.2005.1532141;10.1109/VISUAL.1999.809866;10.1109/TVCG.2011.166;10.1109/TVCG.2014.2346979;10.1109/INFVIS.2002.1173157;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2009.153;10.1109/VISUAL.1995.485139;10.1109/TVCG.2006.170;10.1109/INFVIS.2004.15;10.1109/VISUAL.1994.346302;10.1109/INFVIS.2003.1249008;10.1109/VISUAL.1996.567800;10.1109/INFVIS.2003.1249015;10.1109/TVCG.2009.179	Parallel Coordinates, Orientation-enhanced Parallel Coordinates, Brushing, Orientation-enhanced Brushing, Data Readability, Data Selection	
InfoVis	2015	Vials: Visualizing Alternative Splicing of Genes	10.1109/TVCG.2015.2467911	http://dx.doi.org/10.1109/TVCG.2015.2467911	399	408	J	Alternative splicing is a process by which the same DNA sequence is used to assemble different proteins, called protein isoforms. Alternative splicing works by selectively omitting some of the coding regions (exons) typically associated with a gene. Detection of alternative splicing is difficult and uses a combination of advanced data acquisition methods and statistical inference. Knowledge about the abundance of isoforms is important for understanding both normal processes and diseases and to eventually improve treatment through targeted therapies. The data, however, is complex and current visualizations for isoforms are neither perceptually efficient nor scalable. To remedy this, we developed Vials, a novel visual analysis tool that enables analysts to explore the various datasets that scientists use to make judgments about isoforms: the abundance of reads associated with the coding regions of the gene, evidence for junctions, i.e., edges connecting the coding regions, and predictions of isoform frequencies. Vials is scalable as it allows for the simultaneous analysis of many samples in multiple groups. Our tool thus enables experts to (a) identify patterns of isoform abundance in groups of samples and (b) evaluate the quality of the data. We demonstrate the value of our tool in case studies using publicly available datasets.	Hendrik Strobelt;Bilal Alsallakh;Joseph Botros;Brant Peterson;Mark Borowsky;Hanspeter Pfister;Alexander Lex	;;;;;;	10.1109/TVCG.2013.214;10.1109/TVCG.2013.223;10.1109/TVCG.2014.2346248	Biology visualization, protein isoforms, mRNA-seq, directed acyclic graphs, multivariate networks	
InfoVis	2015	A Psychophysical Investigation of Size as a Physical Variable	10.1109/TVCG.2015.2467951	http://dx.doi.org/10.1109/TVCG.2015.2467951	479	488	J	Physical visualizations, or data physicalizations, encode data in attributes of physical shapes. Despite a considerable body of work on visual variables, ΓÇ£physical variablesΓÇ¥ remain poorly understood. One of them is physical size. A difficulty for solid elements is that ΓÇ£sizeΓÇ¥ is ambiguous - it can refer to either length/diameter, surface, or volume. Thus, it is unclear for designers of physicalizations how to effectively encode quantities in physical size. To investigate, we ran an experiment where participants estimated ratios between quantities represented by solid bars and spheres. Our results suggest that solid bars are compared based on their length, consistent with previous findings for 2D and 3D bars on flat media. But for spheres, participants' estimates are rather proportional to their surface. Depending on the estimation method used, judgments are rather consistent across participants, thus the use of perceptually-optimized size scales seems possible. We conclude by discussing implications for the design of data physicalizations and the need for more empirical studies on physical variables.	Yvonne Jansen;Kasper Hornbæk	Univ. of Copenhagen, Copenhagen, Denmark|c|;	10.1109/TVCG.2012.251;10.1109/TVCG.2013.234;10.1109/TVCG.2012.220;10.1109/TVCG.2013.134;10.1109/TVCG.2007.70541;10.1109/TVCG.2014.2352953;10.1109/TVCG.2014.2346320	Data physicalization, physical visualization, psychophysics, experiment, physical variable	
InfoVis	2015	A Simple Approach for Boundary Improvement of Euler Diagrams	10.1109/TVCG.2015.2467992	http://dx.doi.org/10.1109/TVCG.2015.2467992	678	687	J	General methods for drawing Euler diagrams tend to generate irregular polygons. Yet, empirical evidence indicates that smoother contours make these diagrams easier to read. In this paper, we present a simple method to smooth the boundaries of any Euler diagram drawing. When refining the diagram, the method must ensure that set elements remain inside their appropriate boundaries and that no region is removed or created in the diagram. Our approach uses a force system that improves the diagram while at the same time ensuring its topological structure does not change. We demonstrate the effectiveness of the approach through case studies and quantitative evaluations.	Paolo Simonetto;Daniel Archambault;Carlos Eduardo Scheidegger	;;	10.1109/TVCG.2011.186;10.1109/TVCG.2013.184;10.1109/TVCG.2009.122;10.1109/TVCG.2014.2346248;10.1109/TVCG.2010.210	Euler diagrams, Boundary Improvement, Force-Directed Approaches	
InfoVis	2015	Spatial Reasoning and Data Displays	10.1109/TVCG.2015.2469125	http://dx.doi.org/10.1109/TVCG.2015.2469125	459	468	J	Graphics convey numerical information very efficiently, but rely on a different set of mental processes than tabular displays. Here, we present a study relating demographic characteristics and visual skills to perception of graphical lineups. We conclude that lineups are essentially a classification test in a visual domain, and that performance on the lineup protocol is associated with general aptitude, rather than specific tasks such as card rotation and spatial manipulation. We also examine the possibility that specific graphical tasks may be associated with certain visual skills and conclude that more research is necessary to understand which visual skills are required in order to understand certain plot types.	Susan VanderPlas;Heike Hofmann	;	10.1109/TVCG.2012.230;10.1109/TVCG.2014.2346320;10.1109/TVCG.2010.161	Data visualization, Perception, Statistical graphics, Statistical computing	
SciVis	2015	A Classification of User Tasks in Visual Analysis of Volume Data	10.1109/SciVis.2015.7429485	http://dx.doi.org/10.1109/SciVis.2015.7429485	1	8	C	Empirical findings from studies in one scientific domain have very limited applicability to other domains, unless we formally establish deeper insights on the generalizability of task types. We present a domain-independent classification of visual analysis tasks with volume visualizations. This taxonomy will help researchers design experiments, ensure coverage, and generate hypotheses in empirical studies with volume datasets. To develop our taxonomy, we first interviewed scientists working with spatial data in disparate domains. We then ran a survey to evaluate the design participants in which were scientists and professionals from around the world, working with volume data in various scientific domains. Respondents agreed substantially with our taxonomy design, but also suggested important refinements. We report the results in the form of a goal-based generic categorization of visual analysis tasks with volume visualizations. Our taxonomy covers tasks performed with a wide variety of volume datasets.	Bireswar Laha;Doug A. Bowman;David H. Laidlaw;John J. Socha	Stanford University|c|;;;	10.1109/INFVIS.2004.10;10.1109/TVCG.2013.124;10.1109/TVCG.2012.216;10.1109/TVCG.2009.126;10.1109/TVCG.2013.130;10.1109/TVCG.2013.120;10.1109/TVCG.2014.2346321;10.1109/INFVIS.2004.59	Task Taxonomy, Empirical Evaluation, Volume Visualization, Scientific Visualization, Virtual Reality, 3D Interaction	
SciVis	2015	Using Maximum Topology Matching to Explore Differences in Species Distribution Models	10.1109/SciVis.2015.7429486	http://dx.doi.org/10.1109/SciVis.2015.7429486	9	16	C	Species distribution models (SDM) are used to help understand what drives the distribution of various plant and animal species. These models are typically high dimensional scalar functions, where the dimensions of the domain correspond to predictor variables of the model algorithm. Understanding and exploring the differences between models help ecologists understand areas where their data or understanding of the system is incomplete and will help guide further investigation in these regions. These differences can also indicate an important source of model to model uncertainty. However, it is cumbersome and often impractical to perform this analysis using existing tools, which allows for manual exploration of the models usually as 1-dimensional curves. In this paper, we propose a topology-based framework to help ecologists explore the differences in various SDMs directly in the high dimensional domain. In order to accomplish this, we introduce the concept of maximum topology matching that computes a locality-aware correspondence between similar extrema of two scalar functions. The matching is then used to compute the similarity between two functions. We also design a visualization interface that allows ecologists to explore SDMs using their topological features and to study the differences between pairs of models found using maximum topological matching. We demonstrate the utility of the proposed framework through several use cases using different data sets and report the feedback obtained from ecologists.	Jorge Poco;Harish Doraiswamy;Marian Talbert;Jeffrey T. Morisette;Cláudio T. Silva	New York University|c|;;;;	10.1109/TVCG.2011.244;10.1109/TVCG.2010.213;10.1109/TVCG.2008.145;10.1109/TVCG.2009.155;10.1109/TVCG.2013.125;10.1109/TVCG.2008.143;10.1109/TVCG.2011.236;10.1109/TVCG.2013.148;10.1109/TVCG.2014.2346332;10.1109/TVCG.2011.248;10.1109/TVCG.2007.70601	Function similarity, computational topology, species distribution models, persistence, high dimensional visualization	
SciVis	2015	Visual Verification of Space Weather Ensemble Simulations	10.1109/SciVis.2015.7429487	http://dx.doi.org/10.1109/SciVis.2015.7429487	17	24	C	We propose a system to analyze and contextualize simulations of coronal mass ejections. As current simulation techniques require manual input, uncertainty is introduced into the simulation pipeline leading to inaccurate predictions that can be mitigated through ensemble simulations. We provide the space weather analyst with a multi-view system providing visualizations to: 1. compare ensemble members against ground truth measurements, 2. inspect time-dependent information derived from optical flow analysis of satellite images, and 3. combine satellite images with a volumetric rendering of the simulations. This three-tier workflow provides experts with tools to discover correlations between errors in predictions and simulation parameters, thus increasing knowledge about the evolution and propagation of coronal mass ejections that pose a danger to Earth and interplanetary travel.	Alexander Bock;Asher Pembroke;M. Leila Mays;Lutz Rastaetter;Timo Ropinski;Anders Ynnerman	Linkoping University|c|;;;;;	10.1109/TVCG.2010.190;10.1109/TVCG.2010.181;10.1109/TVCG.2013.143	Visual Verification, Space Weather, Coronal Mass Ejections, Ensemble	
SciVis	2015	A Visual Voting Framework for Weather Forecast Calibration	10.1109/SciVis.2015.7429488	http://dx.doi.org/10.1109/SciVis.2015.7429488	25	32	C	Numerical weather predictions have been widely used for weather forecasting. Many large meteorological centers are producing highly accurate ensemble forecasts routinely to provide effective weather forecast services. However, biases frequently exist in forecast products because of various reasons, such as the imperfection of the weather forecast models. Failure to identify and neutralize the biases would result in unreliable forecast products that might mislead analysts; consequently, unreliable weather predictions are produced. The analog method has been commonly used to overcome the biases. Nevertheless, this method has some serious limitations including the difficulties in finding effective similar past forecasts, the large search space for proper parameters and the lack of support for interactive, real-time analysis. In this study, we develop a visual analytics system based on a novel voting framework to circumvent the problems. The framework adopts the idea of majority voting to combine judiciously the different variants of analog methods towards effective retrieval of the proper analogs for calibration. The system seamlessly integrates the analog methods into an interactive visualization pipeline with a set of coordinated views that characterizes the different methods. Instant visual hints are provided in the views to guide users in finding and refining analogs. We have worked closely with the domain experts in the meteorological research to develop the system. The effectiveness of the system is demonstrated using two case studies. An informal evaluation with the experts proves the usability and usefulness of the system.	Hongsen Liao;Yingcai Wu;Li Chen;Thomas M. Hamill;Yunhai Wang;Kan Dai;Hui Zhang;Wei Chen	School of Software, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University|c|;;;;;;;	10.1109/TVCG.2013.131;10.1109/TVCG.2013.138;10.1109/TVCG.2013.144;10.1109/TVCG.2009.197;10.1109/TVCG.2008.139;10.1109/TVCG.2014.2346755;10.1109/TVCG.2010.181;10.1109/VISUAL.1994.346298;10.1109/TVCG.2013.143	Weather forecast, analog method, calibration, majority voting, visual analytics	
SciVis	2015	Real-time Uncertainty Visualization for B-Mode Ultrasound	10.1109/SciVis.2015.7429489	http://dx.doi.org/10.1109/SciVis.2015.7429489	33	40	C	B-mode ultrasound is a very well established imaging modality and is widely used in many of today's clinical routines. However, acquiring good images and interpreting them correctly is a challenging task due to the complex ultrasound image formation process depending on a large number of parameters. To facilitate ultrasound acquisitions, we introduce a novel framework for real-time uncertainty visualization in B-mode images. We compute real-time per-pixel ultrasound Confidence Maps, which we fuse with the original ultrasound image in order to provide the user with an interactive feedback on the quality and credibility of the image. In addition to a standard color overlay mode, primarily intended for educational purposes, we propose two perceptional visualization schemes to be used in clinical practice. Our mapping of uncertainty to chroma uses the perceptionally uniform L*a*b* color space to ensure that the perceived brightness of B-mode ultrasound remains the same. The alternative mapping of uncertainty to fuzziness keeps the B-mode image in its original grayscale domain and locally blurs or sharpens the image based on the uncertainty distribution. An elaborate evaluation of our system and user studies on both medical students and expert sonographers demonstrate the usefulness of our proposed technique. In particular for ultrasound novices, such as medical students, our technique yields powerful visual cues to evaluate the image quality and thereby learn the ultrasound image formation process. Furthermore, seeing the distribution of uncertainty adjust to the transducer positioning in real-time, provides also expert clinicians with a strong visual feedback on their actions. This helps them to optimize the acoustic window and can improve the general clinical value of ultrasound.	Christian Schulte zu Berge;Denis Declara;Christoph Hennersperger;Maximilian Baust;Nassir Navab	;;;;	10.1109/VISUAL.2001.964550;10.1109/TVCG.2006.134;10.1109/TVCG.2007.70518;10.1109/TVCG.2012.279;10.1109/TVCG.2009.114	Ultrasound, Uncertainty Visualization, Confidence Maps, Real-time	
SciVis	2015	Explicit Frequency Control for High-Quality Texture-Based Flow Visualization	10.1109/SciVis.2015.7429490	http://dx.doi.org/10.1109/SciVis.2015.7429490	41	48	C	In this work we propose an effective method for frequency-controlled dense flow visualization derived from a generalization of the Line Integral Convolution (LIC) technique. Our approach consists in considering the spectral properties of the dense flow visualization process as an integral operator defined in a local curvilinear coordinate system aligned with the flow. Exploring LIC from this point of view, we suggest a systematic way to design a flow visualization process with particular local spatial frequency properties of the resulting image. Our method is efficient, intuitive, and based on a long-standing model developed as a result of numerous perception studies. The method can be described as an iterative application of line integral convolution, followed by a one-dimensional Gabor filtering orthogonal to the flow. To demonstrate the utility of the technique, we generated novel adaptive multi-frequency flow visualizations, that according to our evaluation, feature a higher level of frequency control and higher quality scores than traditional approaches in texture-based flow visualization.	Victor Matvienko;Jens H. Krüger	Saarland University|c|;	10.1109/VISUAL.2005.1532853;10.1109/TVCG.2007.70595;10.1109/TVCG.2006.161;10.1109/VISUAL.1994.346313;10.1109/VISUAL.1996.567784;10.1109/VISUAL.2001.964505;10.1109/TVCG.2009.126;10.1109/VISUAL.1999.809892;10.1109/VISUAL.2003.1250362;10.1109/VISUAL.2005.1532781	flow visualization, texture-based visualization, LIC, Gabor filter, spatial frequency, image contrast	
SciVis	2015	Feature-Based Tensor Field Visualization for Fiber Reinforced Polymers	10.1109/SciVis.2015.7429491	http://dx.doi.org/10.1109/SciVis.2015.7429491	49	56	C	Virtual testing is an integral part of modern product development in mechanical engineering. Numerical structure simulations allow the computation of local stresses which are given as tensor fields. For homogeneous materials, the tensor information is usually reduced to a scalar field like the von Mises stress. A material-dependent threshold defines the material failure answering the key question of engineers. This leads to a rather simple feature-based visualisation. For composite materials like short fiber reinforced polymers, the situation is much more complex. The material property is determined by the fiber distribution at every position, often described as fiber orientation tensor field. Essentially, the material's ability to cope with stress becomes anisotropic and inhomogeneous. We show how to combine the stress field and the fiber orientation field in such cases, leading to a feature-based visualization of tensor fields for composite materials. The resulting features inform the engineer about potential improvements in the product development.	Valentin Zobel;Markus Stommel;Gerik Scheuermann	Leipzig University|c|;;	10.1109/VISUAL.1994.346326;10.1109/TVCG.2009.184;10.1109/VISUAL.1995.485141;10.1109/TVCG.2010.199;10.1109/VISUAL.2004.105	tensor visualization, feature-based visualisation, composite materials, structural mechanics	
SciVis	2015	CPU Ray Tracing Large Particle Data with Balanced P-k-d Trees	10.1109/SciVis.2015.7429492	http://dx.doi.org/10.1109/SciVis.2015.7429492	57	64	C	We present a novel approach to rendering large particle data sets from molecular dynamics, astrophysics and other sources. We employ a new data structure adapted from the original balanced k-d tree, which allows for representation of data with trivial or no overhead. In the OSPRay visualization framework, we have developed an efficient CPU algorithm for traversing, classifying and ray tracing these data. Our approach is able to render up to billions of particles on a typical workstation, purely on the CPU, without any approximations or level-of-detail techniques, and optionally with attribute-based color mapping, dynamic range query, and advanced lighting models such as ambient occlusion and path tracing.	Ingo Wald;Aaron Knoll;Gregory P. Johnson;Will Usher;Valerio Pascucci;Michael E. Papka	Intel Corporation|c|;;;;;	10.1109/TVCG.2010.148;10.1109/TVCG.2009.142;10.1109/TVCG.2012.282	Ray tracing, Visualization, Particle Data, k-d Trees	
SciVis	2015	Auto-Calibration of Multi-Projector Displays with a Single Handheld Camera	10.1109/SciVis.2015.7429493	http://dx.doi.org/10.1109/SciVis.2015.7429493	65	72	C	We present a novel approach that utilizes a simple handheld camera to automatically calibrate multi-projector displays. Most existing studies adopt active structured light patterns to verify the relationship between the camera and the projectors. The utilized camera is typically expensive and requires an elaborate installation process depending on the scalability of its applications. Moreover, the observation of the entire area by the camera is almost impossible for a small space surrounded by walls as there is not enough distance for the camera to capture the entire scene. We tackle these issues by requiring only a portion of the walls to be visible to a handheld camera that is widely used these days. This becomes possible by the introduction of our new structured light pattern scheme based on a perfect submap and a geometric calibration that successfully utilizes the geometric information of multi-planar environments. We demonstrate that immersive display in a small space such as an ordinary room can be effectively created using images captured by a handheld camera.	Sanghun Park;Hyunggoog Seo;Seunghoon Cha;Jun-yong Noh	KAIST|c|;;;	10.1109/VISUAL.2002.1183793;10.1109/VISUAL.2000.885685;10.1109/VISUAL.1999.809883		
SciVis	2015	Correlation analysis in multidimensional multivariate time-varying datasets	10.1109/SciVis.2015.7429502	http://dx.doi.org/10.1109/SciVis.2015.7429502	139	140	M	One of the most vital challenges for weather forecasters is the correlation between two geographical phenomena that are distributed continuously in multidimensional multivariate time-varying datasets. In this research, we have visualized the correlation between Pressure and Temperature in the climate datasets. Pearson correlation is used in this study to measure the major linear relationship between two variables in the dataset. Using glyphs in the spatial location, we highlighted the significant association between variables. Based on the positive or negative slope of correlation lines, we can conclude how much they are correlated. The principal of this research is visualizing the local trend of variables versus each other in multidimensional multivariate time-varying datasets, which needs to be visualized with their spatial locations in meteorological datasets. Using glyphs, not only can we visualize the correlation between two variables in the coordinate system, but we can also discern whether any of these variables is separately increasing or decreasing. Moreover, we can visualize the background color as another variable and see the correlation lines around of a particular zone such as storm area.	Najmeh Abedzadeh	Mississippi State University|c|			
SciVis	2015	OpenSpace: Public dissemination of space mission profiles	10.1109/SciVis.2015.7429503	http://dx.doi.org/10.1109/SciVis.2015.7429503	141	142	M	This work presents a visualization system and its application to space missions. The system allows the public to disseminate the scientific findings of space craft and gain a greater understanding thereof. Instruments' field-of-views and their measurements are embedded in an accurate 3 dimensional rendering of the solar system to provide context to past measurements or the planning of future events. We tested our system with NASA's New Horizons at the Pluto Pallooza event in New York and will expose it to the greater public on the upcoming July 14th Pluto flyby.	Alexander Bock;Michal Marcinkowski;Joakim Kilby;Carter Emmart;Anders Ynnerman	Link&#65533;&#65533;ping University|c|;;;;			
SciVis	2015	3D superquadric glyphs for visualizing myocardial motion	10.1109/SciVis.2015.7429504	http://dx.doi.org/10.1109/SciVis.2015.7429504	143	144	M	Various cardiac diseases can be diagnosed by the analysis of myocardial motion. Relevant biomarkers are radial, longitudinal, and rotational velocities of the cardiac muscle computed locally from MR images. We designed a visual encoding that maps these three attributes to glyph shapes according to a barycentric space formed by 3D superquadric glyphs. The glyphs show aggregated myocardial motion information following the AHA model and are displayed in a respective 3D layout.	Teodora Chitiboi;Mathias Neugebauer;Susanne Schnell;Michael Markl;Lars Linsen	FraunhoferMEVIS, Jacobs University Bremen|c|;;;;			
SciVis	2015	Real-time interactive time correction on the GPU	10.1109/SciVis.2015.7429505	http://dx.doi.org/10.1109/SciVis.2015.7429505	145	146	M	The study of physical phenomena and their dynamic evolution is supported by the analysis and visualization of time-enabled data. In many applications, available data are sparsely distributed in the space-time domain, which leads to incomprehensible visualizations. We present an interactive approach for the dynamic tracking and visualization of measured data particles through advection in a simulated flow. We introduce a fully GPU-based technique for efficient spatio-temporal interpolation, using a kd-tree forest for acceleration. As the user interacts with the system using a time slider, particle positions are reconstructed for the time selected by the user. Our results show that the proposed technique achieves highly accurate parallel tracking for thousands of particles. The rendering performance is mainly affected by the size of the query set.	Mai El-Shehaly;Denis Gracanin;Mohamed Gad;JunPeng Wang;Hicham G. Elmongui	Virginia Tech|c|;;;;			
SciVis	2015	Visualizing crossing probabilistic tracts	10.1109/SciVis.2015.7429506	http://dx.doi.org/10.1109/SciVis.2015.7429506	147	148	M	Diffusion weighted magnetic resonance imaging (dMRI) together with tractography algorithms allow to probe for principal white matter tracts in the living human brain. Specifically, probabilistic tractography quantifies the existence of physical connections to a given seed region as a 3D scalar map of confidence scores. Fiber-Stippling is a visualization for probabilistic tracts that effectively communicates the diffusion pattern, connectivity score, and anatomical context. Unfortunately, it cannot handle multiple diffusion orientations per voxel, which exist in high angular resolution diffusion imaging (HARDI) data. Such data is needed to resolve tracts in complex configurations, such as crossings. In this work, we suggest a visualization based on Fiber-Stippling but sensible to multiple diffusion orientations from HARDI-based diffusion models. With such a technique, it is now possible to visualize probabilistic tracts from HARDI-based tractography algorithms. This implies that tract crossings may now be visualized as crossing stipples, which is an essential step towards an accurate visualization of the neuroanatomy, as crossing tracts are widespread phenomena in the brain.	Mathias Goldau;André Reichenbach;Mario Hlawitschka	Leipzig University|c|;;			
SciVis	2015	An evaluation of three methods for visualizing uncertainty in architecture and archaeology	10.1109/SciVis.2015.7429507	http://dx.doi.org/10.1109/SciVis.2015.7429507	149	150	M	This project explores the representation of uncertainty in visualizations for archaeological research and provides insights obtained from user feedback. Our 3D models brought together information from standing architecture and excavated remains, surveyed plans, ground penetrating radar (GPR) data from the Carthusian monastery of Bourgfontaine in northern France. We also included information from comparative Carthusian sites and a bird's eye representation of the site in an early modern painting. Each source was assigned a certainty value which was then mapped to a color or texture for the model. Certainty values between one and zero were assigned by one subject matter expert and should be considered qualitative. Students and faculty from the fields of architectural history and archaeology at two institutions interacted with the models and answered a short survey with four questions about each. We discovered equal preference for color and transparency and a strong dislike for the texture model. Discoveries during model building also led to changes of the excavation plans for summer 2015.	Scott Houde;Sheila Bonde;David H. Laidlaw	Brown University|c|;;			
SciVis	2015	Multiresolution visualization of digital earth data via hexagonal box-spline wavelets	10.1109/SciVis.2015.7429508	http://dx.doi.org/10.1109/SciVis.2015.7429508	151	152	M	Multiresolution analysis is an important tool for exploring large-scale data sets. Such analysis provides facilities to visualize data at different levels of detail while providing the advantages of efficient data compression and transmission. In this work, an approach is presented to apply multiresolution analysis to digital Earth data where each resolution describes data at a specific level of detail. Geospatial data at a fine level is taken as the input and a hierarchy of approximation and detail coefficients is built by applying a hexagonal discrete wavelet transform. Multiresolution filters are designed for hexagonal cells based on the three directional linear box spline which is natively supported by modern GPUs.	Mohammad Imrul Jubair;Usman R. Alim;Niklas Röber;John Clyne;Ali Mahdavi-Amiri;Faramarz F. Samavati	University of Calgary|c|;;;;;			
SciVis	2015	Automated visualization workflow for simulation experiments	10.1109/SciVis.2015.7429509	http://dx.doi.org/10.1109/SciVis.2015.7429509	153	154	M	Modeling and simulation is often used to predict future events and plan accordingly. Experiments in this domain often produce thousands of results from individual simulations, based on slightly varying input parameters. Geo-spatial visualizations can be a powerful tool to help health researchers and decision-makers to take measures during catastrophic and epidemic events such as Ebola outbreaks. The work produced a web-based geo-visualization tool to visualize and compare the spread of Ebola in the West African countries Ivory Coast and Senegal based on multiple simulation results. The visualization is not Ebola specific and may visualize any time-varying frequencies for given geo-locations.	Jonathan Leidig;Santhosh Dharmapuri	School of Computing and Information Systems, Grand Valley State University|c|;			
SciVis	2015	A bottom-up scheme for user-defined feature exploration in vector field ensembles	10.1109/SciVis.2015.7429510	http://dx.doi.org/10.1109/SciVis.2015.7429510	155	156	M	Most of the existing approaches to visualize vector field ensembles are achieved by visualizing the uncertainty of individual variables from different simulation runs. However, the comparison of the derived feature or user-defined feature, such as the vortex in ensemble flow is also of vital significance since they often make more sense according to the domain knowledge. In this work, we present a framework to extract user-defined feature from different simulation runs. Specially, we use a bottom-up searching scheme to help to extract vortex with a user-defined shape, and further compute the geometry information including the size, and the geo-spatial location of the extracted vortex. Finally we design some linked views to compare the feature between different runs.	Richen Liu;Hanqi Guo;Xiaoru Yuan	Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University|c|;;			
SciVis	2015	A proposed multivariate visualization taxonomy from user data	10.1109/SciVis.2015.7429511	http://dx.doi.org/10.1109/SciVis.2015.7429511	157	158	M	We revisited past user study data on multivariate visualizations, looking at whether image processing measures offer any insight into user performance. While we find statistically significant correlations, some of the greatest insights into user performance came from variables that have strong ties to two key properties of multivariate representations. We discuss our analysis and propose a taxonomy of multivariate visualizations that arises.	Mark A. Livingston;Jonathan W. Decker;Zhuming Ai	;;			
SciVis	2015	PathlinesExplorer ??? Image-based exploration of large-scale pathline fields	10.1109/SciVis.2015.7429512	http://dx.doi.org/10.1109/SciVis.2015.7429512	159	160	M	PathlinesExplorer is a novel image-based tool, which has been designed to visualize large scale pathline fields on a single computer [7]. PathlinesExplorer integrates explorable images (EI) technique [4] with order-independent transparency (OIT) method [2]. What makes this method different is that it allows users to handle large data on a single workstation. Although it is a view-dependent method, PathlinesExplorer combines both exploration and modification of visual aspects without re-accessing the original huge data. Our approach is based on constructing a per-pixel linked list data structure in which each pixel contains a list of pathline segments. With this view-dependent method, it is possible to filter, color-code, and explore large-scale flow data in real-time. In addition, optimization techniques such as early-ray termination and deferred shading are applied, which further improves the performance and scalability of our approach.	Omniah H. Nagoor;Markus Hadwiger;Madhusudhanan Srinivasan	KAUST|c|;;			
SciVis	2015	Visualizing 3D flow through cutting planes	10.1109/SciVis.2015.7429513	http://dx.doi.org/10.1109/SciVis.2015.7429513	161	162	M	Studies have found conflicting results regarding the effectiveness of tube-like structures for representing 3D flow data. This paper presents the findings of a small-scale pilot study contrasting static monoscopic depth cues to ascertain their importance in perceiving the orientation of a three-dimensional glyph with respect to a cutting plane. A simple striped texture and shading were found to reduce judgement errors when used with a 3D tube glyph as compared to plain or shaded line glyphs. A discussion of considerations for a full-scale study and possible future work follows.	Colin Ware;Andrew H. Stevens	University of New Hampshire|c|;			
SciVis	2015	Inviwo ??? An extensible, multi-purpose visualization framework	10.1109/SciVis.2015.7429514	http://dx.doi.org/10.1109/SciVis.2015.7429514	163	164	M	To enable visualization research impacting other scientific domains, the availability of easy-to-use visualization frameworks is essential. Nevertheless, an easy-to-use system also has to be adapted to the capabilities of modern hardware architectures, as only this allows for realizing interactive visualizations. With this trade-off in mind, we have designed and realized the cross-platform Inviwo (Interactive Visualization Workshop) visualization framework, that supports both interactive visualization research as well as efficient visualization application development and deployment. In this poster we give an overview of the architecture behind Inviwo, and show how its design enables us and other researchers to realize their visualization ideas efficiently. Inviwo consists of a modern and lightweight, graphics independent core, which is extended by optional modules that encapsulate visualization algorithms, well-known utility libraries and commonly used parallel-processing APIs (such as OpenGL and OpenCL). The core enables a simplistic structure for creating bridges between the different modules regarding data transfer across architecture and devices with an easy-to-use screen graph and minimalistic programming. Making the base structures in a modern way while providing intuitive methods of extending the functionality and creating modules based on other modules, we hope that Inviwo can help the visualization community to perform research through a rapid-prototyping design and GUI, while at the same time allowing users to take advantage of the results implemented in the system in any way they desire later on. Inviwo is publicly available at www.inviwo.org, and can be used freely by anyone under a permissive free software license (Simplified BSD).	Erik Sundén;Peter Steneteg;Sathish Kottravel;Daniel Jönsson;Rickard Englund;Martin Falk;Timo Ropinski	Linkoping University|c|;;;;;;			
SciVis	2015	High performance flow field visualization with high-order access dependencies	10.1109/SciVis.2015.7429515	http://dx.doi.org/10.1109/SciVis.2015.7429515	165	166	M	We present a novel model based on high-order access dependencies for high performance pathline computation in flow field. The high-order access dependencies are defined as transition probabilities from one data block to other blocks based on a few historical data accesses. Compared with existing methods which employed first-order access dependencies, our approach takes the advantages of high order access dependencies with higher accuracy and reliability in data access prediction. In our work, high-order access dependencies are calculated by tracing densely-seeded pathlines. The efficiency of our proposed approach is demonstrated through a parallel particle tracing framework with high-order data prefetching. Results show that our method can achieve higher data locality than the first-order access dependencies based method, thereby reducing the I/O requests and improving the efficiency of pathline computation in various applications.	Jiang Zhang;Hanqi Guo;Xiaoru Yuan	Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University|c|;;			
SciVis	2015	Extracting, Tracking, and Visualizing Magnetic Flux Vortices in 3D Complex-Valued Superconductor Simulation Data	10.1109/TVCG.2015.2466838	http://dx.doi.org/10.1109/TVCG.2015.2466838	827	836	J	We propose a method for the vortex extraction and tracking of superconducting magnetic flux vortices for both structured and unstructured mesh data. In the Ginzburg-Landau theory, magnetic flux vortices are well-defined features in a complex-valued order parameter field, and their dynamics determine electromagnetic properties in type-II superconductors. Our method represents each vortex line (a 1D curve embedded in 3D space) as a connected graph extracted from the discretized field in both space and time. For a time-varying discrete dataset, our vortex extraction and tracking method is as accurate as the data discretization. We then apply 3D visualization and 2D event diagrams to the extraction and tracking results to help scientists understand vortex dynamics and macroscale superconductor behavior in greater detail than previously possible.	Hanqi Guo;Carolyn L. Phillips;Tom Peterka;Dmitry A. Karpeyev;Andreas Glatz	Math. & Comput. Sci. Div., Argonne Nat. Lab., Argonne, IL, USA|c|;;;;	10.1109/VISUAL.1994.346327;10.1109/VISUAL.2005.1532795;10.1109/TVCG.2011.249;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1996.568137;10.1109/VISUAL.1998.745288;10.1109/VISUAL.2004.3;10.1109/TVCG.2012.212;10.1109/VISUAL.2005.1532851;10.1109/TVCG.2007.70545	Superconductor, Vortex extraction, Feature tracking, Unstructured grid	
SciVis	2015	Visualizing Tensor Normal Distributions at Multiple Levels of Detail	10.1109/TVCG.2015.2467031	http://dx.doi.org/10.1109/TVCG.2015.2467031	975	984	J	Despite the widely recognized importance of symmetric second order tensor fields in medicine and engineering, the visualization of data uncertainty in tensor fields is still in its infancy. A recently proposed tensorial normal distribution, involving a fourth order covariance tensor, provides a mathematical description of how different aspects of the tensor field, such as trace, anisotropy, or orientation, vary and covary at each point. However, this wealth of information is far too rich for a human analyst to take in at a single glance, and no suitable visualization tools are available. We propose a novel approach that facilitates visual analysis of tensor covariance at multiple levels of detail. We start with a visual abstraction that uses slice views and direct volume rendering to indicate large-scale changes in the covariance structure, and locations with high overall variance. We then provide tools for interactive exploration, making it possible to drill down into different types of variability, such as in shape or orientation. Finally, we allow the analyst to focus on specific locations of the field, and provide tensor glyph animations and overlays that intuitively depict confidence intervals at those points. Our system is demonstrated by investigating the effects of measurement noise on diffusion tensor MRI, and by analyzing two ensembles of stress tensor fields from solid mechanics.	Amin Abbasloo;Vitalis Wiens;Max Hermann;Thomas Schultz 0001	Univ. of Bonn, Bonn, Germany|c|;;;	10.1109/TVCG.2009.170;10.1109/TVCG.2009.184;10.1109/VISUAL.2005.1532773;10.1109/TVCG.2006.181;10.1109/TVCG.2006.134;10.1109/TVCG.2010.199;10.1109/TVCG.2008.128;10.1109/TVCG.2007.70602;10.1109/TVCG.2015.2467435	Uncertainty visualization, tensor visualization, direct volume rendering, interaction, glyph based visualization	
SciVis	2015	Visualization-by-Sketching: An Artist's Interface for Creating Multivariate Time-Varying Data Visualizations	10.1109/TVCG.2015.2467153	http://dx.doi.org/10.1109/TVCG.2015.2467153	877	885	J	We present Visualization-by-Sketching, a direct-manipulation user interface for designing new data visualizations. The goals are twofold: First, make the process of creating real, animated, data-driven visualizations of complex information more accessible to artists, graphic designers, and other visual experts with traditional, non-technical training. Second, support and enhance the role of human creativity in visualization design, enabling visual experimentation and workflows similar to what is possible with traditional artistic media. The approach is to conceive of visualization design as a combination of processes that are already closely linked with visual creativity: sketching, digital painting, image editing, and reacting to exemplars. Rather than studying and tweaking low-level algorithms and their parameters, designers create new visualizations by painting directly on top of a digital data canvas, sketching data glyphs, and arranging and blending together multiple layers of animated 2D graphics. This requires new algorithms and techniques to interpret painterly user input relative to data ΓÇ£underΓÇ¥ the canvas, balance artistic freedom with the need to produce accurate data visualizations, and interactively explore large (e.g., terabyte-sized) multivariate datasets. Results demonstrate a variety of multivariate data visualization techniques can be rapidly recreated using the interface. More importantly, results and feedback from artists support the potential for interfaces in this style to attract new, creative users to the challenging task of designing more effective data visualizations and to help these users stay ΓÇ£in the creative zoneΓÇ¥ as they work.	David Schroeder;Daniel F. Keefe	;	10.1109/VAST.2008.4677356;10.1109/TVCG.2009.181;10.1109/TVCG.2013.124;10.1109/TVCG.2011.202;10.1109/TVCG.2008.153;10.1109/TVCG.2013.226;10.1109/TVCG.2014.2346271;10.1109/INFVIS.2002.1173157;10.1109/TVCG.2009.145;10.1109/TVCG.2010.162;10.1109/INFVIS.2001.963286;10.1109/TVCG.2011.181;10.1109/TVCG.2012.265;10.1109/TVCG.2014.2346441	Visualization design, multivariate, art, sketch, color map, glyph	
SciVis	2015	TelCoVis: Visual Exploration of Co-occurrence in Urban Human Mobility Based on Telco Data	10.1109/TVCG.2015.2467194	http://dx.doi.org/10.1109/TVCG.2015.2467194	935	944	J	Understanding co-occurrence in urban human mobility (i.e. people from two regions visit an urban place during the same time span) is of great value in a variety of applications, such as urban planning, business intelligence, social behavior analysis, as well as containing contagious diseases. In recent years, the widespread use of mobile phones brings an unprecedented opportunity to capture large-scale and fine-grained data to study co-occurrence in human mobility. However, due to the lack of systematic and efficient methods, it is challenging for analysts to carry out in-depth analyses and extract valuable information. In this paper, we present TelCoVis, an interactive visual analytics system, which helps analysts leverage their domain knowledge to gain insight into the co-occurrence in urban human mobility based on telco data. Our system integrates visualization techniques with new designs and combines them in a novel way to enhance analysts' perception for a comprehensive exploration. In addition, we propose to study the correlations in co-occurrence (i.e. people from multiple regions visit different places during the same time span) by means of biclustering techniques that allow analysts to better explore coordinated relationships among different regions and identify interesting patterns. The case studies based on a real-world dataset and interviews with domain experts have demonstrated the effectiveness of our system in gaining insights into co-occurrence and facilitating various analytical tasks.	Wenchao Wu;Jiayi Xu;Haipeng Zeng;Yixian Zheng;Huamin Qu;Bing Ni;Mingxuan Yuan;Lionel M. Ni	;;;;;;;	10.1109/VAST.2010.5652478;10.1109/TVCG.2013.193;10.1109/TVCG.2014.2346276;10.1109/TVCG.2013.226;10.1109/TVCG.2011.166;10.1109/TVCG.2013.173;10.1109/TVCG.2014.2346271;10.1109/VAST.2011.6102455;10.1109/INFVIS.2000.885091;10.1109/TVCG.2014.2346665;10.1109/TVCG.2012.265;10.1109/TVCG.2013.228;10.1109/VAST.2014.7042490;10.1109/TVCG.2014.2346922	Co-occurrence, human mobility, telco data, bicluster, visual analytics	
SciVis	2015	Accurate Interactive Visualization of Large Deformations and Variability in Biomedical Image Ensembles	10.1109/TVCG.2015.2467198	http://dx.doi.org/10.1109/TVCG.2015.2467198	708	717	J	Large image deformations pose a challenging problem for the visualization and statistical analysis of 3D image ensembles which have a multitude of applications in biology and medicine. Simple linear interpolation in the tangent space of the ensemble introduces artifactual anatomical structures that hamper the application of targeted visual shape analysis techniques. In this work we make use of the theory of stationary velocity fields to facilitate interactive non-linear image interpolation and plausible extrapolation for high quality rendering of large deformations and devise an efficient image warping method on the GPU. This does not only improve quality of existing visualization techniques, but opens up a field of novel interactive methods for shape ensemble analysis. Taking advantage of the efficient non-linear 3D image warping, we showcase four visualizations: 1) browsing on-the-fly computed group mean shapes to learn about shape differences between specific classes, 2) interactive reformation to investigate complex morphologies in a single view, 3) likelihood volumes to gain a concise overview of variability and 4) streamline visualization to show variation in detail, specifically uncovering its component tangential to a reference surface. Evaluation on a real world dataset shows that the presented method outperforms the state-of-the-art in terms of visual quality while retaining interactive frame rates. A case study with a domain expert was performed in which the novel analysis and visualization methods are applied on standard model structures, namely skull and mandible of different rodents, to investigate and compare influence of phylogeny, diet and geography on shape. The visualizations enable for instance to distinguish (population-)normal and pathological morphology, assist in uncovering correlation to extrinsic factors and potentially support assessment of model quality.	Max Hermann;Anja C. Schunke;Thomas Schultz 0001;Reinhard Klein	Inst. fur Inf. II, Univ. Bonn, Bonn, Germany|c|;;;	10.1109/TVCG.2006.140;10.1109/VISUAL.2002.1183754;10.1109/TVCG.2014.2346591;10.1109/TVCG.2014.2346405;10.1109/TVCG.2006.123	Statistical deformation model, stationary velocity fields, image warping, interactive visual analysis	
SciVis	2015	Rotation Invariant Vortices for Flow Visualization	10.1109/TVCG.2015.2467200	http://dx.doi.org/10.1109/TVCG.2015.2467200	817	826	J	We propose a new class of vortex definitions for flows that are induced by rotating mechanical parts, such as stirring devices, helicopters, hydrocyclones, centrifugal pumps, or ventilators. Instead of a Galilean invariance, we enforce a rotation invariance, i.e., the invariance of a vortex under a uniform-speed rotation of the underlying coordinate system around a fixed axis. We provide a general approach to transform a Galilean invariant vortex concept to a rotation invariant one by simply adding a closed form matrix to the Jacobian. In particular, we present rotation invariant versions of the well-known Sujudi-Haimes, Lambda-2, and Q vortex criteria. We apply them to a number of artificial and real rotating flows, showing that for these cases rotation invariant vortices give better results than their Galilean invariant counterparts.	Tobias Günther;Maik Schulze;Holger Theisel	;;	10.1109/TVCG.2014.2346415;10.1109/VISUAL.2002.1183789;10.1109/TVCG.2014.2346412;10.1109/TVCG.2011.249;10.1109/TVCG.2013.189;10.1109/VISUAL.1999.809917;10.1109/VISUAL.1999.809896;10.1109/VISUAL.1998.745296;10.1109/VISUAL.2005.1532851;10.1109/TVCG.2007.70545;10.1109/TVCG.2010.198	Vortex cores, rotation invariance, Galilean invariance, scientific visualization, flow visualization, line fields	
SciVis	2015	CAST: Effective and Efficient User Interaction for Context-Aware Selection in 3D Particle Clouds	10.1109/TVCG.2015.2467202	http://dx.doi.org/10.1109/TVCG.2015.2467202	886	895	J	We present a family of three interactive Context-Aware Selection Techniques (CAST) for the analysis of large 3D particle datasets. For these datasets, spatial selection is an essential prerequisite to many other analysis tasks. Traditionally, such interactive target selection has been particularly challenging when the data subsets of interest were implicitly defined in the form of complicated structures of thousands of particles. Our new techniques SpaceCast, TraceCast, and PointCast improve usability and speed of spatial selection in point clouds through novel context-aware algorithms. They are able to infer a user's subtle selection intention from gestural input, can deal with complex situations such as partially occluded point clusters or multiple cluster layers, and can all be fine-tuned after the selection interaction has been completed. Together, they provide an effective and efficient tool set for the fast exploratory analysis of large datasets. In addition to presenting Cast, we report on a formal user study that compares our new techniques not only to each other but also to existing state-of-the-art selection methods. Our results show that Cast family members are virtually always faster than existing methods without tradeoffs in accuracy. In addition, qualitative feedback shows that PointCast and TraceCast were strongly favored by our participants for intuitiveness and efficiency.	Lingyun Yu;Konstantinos Efstathiou 0001;Petra Isenberg;Tobias Isenberg 0001	Hangzhou Dianzi Univ., Hangzhou, China|c|;;;	10.1109/TVCG.2008.153;10.1109/VISUAL.1999.809932;10.1109/TVCG.2013.126;10.1109/TVCG.2012.292;10.1109/INFVIS.1996.559216;10.1109/TVCG.2012.217;10.1109/TVCG.2010.157	Selection, spatial selection, structure-aware selection, context-aware selection, exploratory data visualization and analysis, 3D interaction, user interaction	
SciVis	2015	Cluster Analysis of Vortical Flow in Simulations of Cerebral Aneurysm Hemodynamics	10.1109/TVCG.2015.2467203	http://dx.doi.org/10.1109/TVCG.2015.2467203	757	766	J	Computational fluid dynamic (CFD) simulations of blood flow provide new insights into the hemodynamics of vascular pathologies such as cerebral aneurysms. Understanding the relations between hemodynamics and aneurysm initiation, progression, and risk of rupture is crucial in diagnosis and treatment. Recent studies link the existence of vortices in the blood flow pattern to aneurysm rupture and report observations of embedded vortices - a larger vortex encloses a smaller one flowing in the opposite direction - whose implications are unclear. We present a clustering-based approach for the visual analysis of vortical flow in simulated cerebral aneurysm hemodynamics. We show how embedded vortices develop at saddle-node bifurcations on vortex core lines and convey the participating flow at full manifestation of the vortex by a fast and smart grouping of streamlines and the visualization of group representatives. The grouping result may be refined based on spectral clustering generating a more detailed visualization of the flow pattern, especially further off the core lines. We aim at supporting CFD engineers researching the biological implications of embedded vortices.	Steffen Oeltze-Jafra;Juan R. Cebral;Gábor Janiga;Bernhard Preim	Dept. of Simulation & Graphics, Univ. of Magdeburg, Magdeburg, Germany|c|;;;	10.1109/TVCG.2009.138;10.1109/TVCG.2012.202;10.1109/TVCG.2014.2346406;10.1109/TVCG.2006.201;10.1109/VISUAL.2002.1183789;10.1109/TVCG.2013.189;10.1109/VISUAL.2004.59;10.1109/TVCG.2006.199;10.1109/VISUAL.2005.1532830;10.1109/VISUAL.2005.1532859	Blood Flow, Aneurysm, Clustering, Vortex Dynamics, Embedded Vortices	
SciVis	2015	Streamline Variability Plots for Characterizing the Uncertainty in Vector Field Ensembles	10.1109/TVCG.2015.2467204	http://dx.doi.org/10.1109/TVCG.2015.2467204	767	776	J	We present a new method to visualize from an ensemble of flow fields the statistical properties of streamlines passing through a selected location. We use principal component analysis to transform the set of streamlines into a low-dimensional Euclidean space. In this space the streamlines are clustered into major trends, and each cluster is in turn approximated by a multivariate Gaussian distribution. This yields a probabilistic mixture model for the streamline distribution, from which confidence regions can be derived in which the streamlines are most likely to reside. This is achieved by transforming the Gaussian random distributions from the low-dimensional Euclidean space into a streamline distribution that follows the statistical model, and by visualizing confidence regions in this distribution via iso-contours. We further make use of the principal component representation to introduce a new concept of streamline-median, based on existing median concepts in multidimensional Euclidean spaces. We demonstrate the potential of our method in a number of real-world examples, and we compare our results to alternative clustering approaches for particle trajectories as well as curve boxplots.	Florian Ferstl;Kai Bürger;Rüdiger Westermann	Comput. Graphics & Visualization Group, Tech. Univ. Munchen, Munich, Germany|c|;;	10.1109/TVCG.2007.70595;10.1109/VISUAL.2000.885715;10.1109/VISUAL.1999.809863;10.1109/TVCG.2013.141;10.1109/TVCG.2007.70518;10.1109/TVCG.2014.2346455;10.1109/VISUAL.2005.1532779;10.1109/TVCG.2010.181;10.1109/VISUAL.1999.809865;10.1109/TVCG.2013.143	Ensemble visualization, uncertainty visualization, flow visualization, streamlines, statistical modeling	
SciVis	2015	Reconstruction and Visualization of Coordinated 3D Cell Migration Based on Optical Flow	10.1109/TVCG.2015.2467291	http://dx.doi.org/10.1109/TVCG.2015.2467291	995	1004	J	Animal development is marked by the repeated reorganization of cells and cell populations, which ultimately determine form and shape of the growing organism. One of the central questions in developmental biology is to understand precisely how cells reorganize, as well as how and to what extent this reorganization is coordinated. While modern microscopes can record video data for every cell during animal development in 3D+t, analyzing these videos remains a major challenge: reconstruction of comprehensive cell tracks turned out to be very demanding especially with decreasing data quality and increasing cell densities. In this paper, we present an analysis pipeline for coordinated cellular motions in developing embryos based on the optical flow of a series of 3D images. We use numerical integration to reconstruct cellular long-term motions in the optical flow of the video, we take care of data validation, and we derive a LIC-based, dense flow visualization for the resulting pathlines. This approach allows us to handle low video quality such as noisy data or poorly separated cells, and it allows the biologists to get a comprehensive understanding of their data by capturing dynamic growth processes in stills. We validate our methods using three videos of growing fruit fly embryos.	Christopher P. Kappe;Lucas Schutz;Stefan Gunther;Lars Hufnagel;Steffen Lemke;Heike Leitte	IWR, Heidelberg Univ., Heidelberg, Germany|c|;;;;;	10.1109/TVCG.2010.169;10.1109/VISUAL.1996.567784;10.1109/TVCG.2009.190;10.1109/VISUAL.2003.1250364;10.1109/VISUAL.1997.663898;10.1109/VISUAL.2003.1250363	Cell migration, vector field, 3D, timedependent,LIC, tracking, validation	
SciVis	2015	Multi-field Pattern Matching based on Sparse Feature Sampling	10.1109/TVCG.2015.2467292	http://dx.doi.org/10.1109/TVCG.2015.2467292	807	816	J	We present an approach to pattern matching in 3D multi-field scalar data. Existing pattern matching algorithms work on single scalar or vector fields only, yet many numerical simulations output multi-field data where only a joint analysis of multiple fields describes the underlying phenomenon fully. Our method takes this into account by bundling information from multiple fields into the description of a pattern. First, we extract a sparse set of features for each 3D scalar field using the 3D SIFT algorithm (Scale-Invariant Feature Transform). This allows for a memory-saving description of prominent features in the data with invariance to translation, rotation, and scaling. Second, the user defines a pattern as a set of SIFT features in multiple fields by e.g. brushing a region of interest. Third, we locate and rank matching patterns in the entire data set. Experiments show that our algorithm is efficient in terms of required memory and computational efforts.	Zhongjie Wang;Hans-Peter Seidel;Tino Weinkauf	MPI for Inf., Saarbrucken, Germany|c|;;	10.1109/VISUAL.2003.1250372;10.1109/TVCG.2009.141;10.1109/TVCG.2006.165;10.1109/TVCG.2007.70579;10.1109/TVCG.2014.2346332;10.1109/TVCG.2011.236	Pattern matching, multi-field visualization	
SciVis	2015	Real-Time Molecular Visualization Supporting Diffuse Interreflections and Ambient Occlusion	10.1109/TVCG.2015.2467293	http://dx.doi.org/10.1109/TVCG.2015.2467293	718	727	J	Today molecular simulations produce complex data sets capturing the interactions of molecules in detail. Due to the complexity of this time-varying data, advanced visualization techniques are required to support its visual analysis. Current molecular visualization techniques utilize ambient occlusion as a global illumination approximation to improve spatial comprehension. Besides these shadow-like effects, interreflections are also known to improve the spatial comprehension of complex geometric structures. Unfortunately, the inherent computational complexity of interreflections would forbid interactive exploration, which is mandatory in many scenarios dealing with static and time-varying data. In this paper, we introduce a novel analytic approach for capturing interreflections of molecular structures in real-time. By exploiting the knowledge of the underlying space filling representations, we are able to reduce the required parameters and can thus apply symbolic regression to obtain an analytic expression for interreflections. We show how to obtain the data required for the symbolic regression analysis, and how to exploit our analytic solution to enhance interactive molecular visualizations.	Robin Skanberg;Pere-Pau Vázquez;Victor Guallar;Timo Ropinski	;;;	10.1109/TVCG.2007.70578;10.1109/TVCG.2009.168;10.1109/TVCG.2007.70517;10.1109/TVCG.2012.282;10.1109/TVCG.2009.157;10.1109/TVCG.2014.2346404;10.1109/TVCG.2006.115	Molecular visualization, diffuse interreflections, ambient occlusion	
SciVis	2015	Intuitive Exploration of Volumetric Data Using Dynamic Galleries	10.1109/TVCG.2015.2467294	http://dx.doi.org/10.1109/TVCG.2015.2467294	896	905	J	In this work we present a volume exploration method designed to be used by novice users and visitors to science centers and museums. The volumetric digitalization of artifacts in museums is of rapidly increasing interest as enhanced user experience through interactive data visualization can be achieved. This is, however, a challenging task since the vast majority of visitors are not familiar with the concepts commonly used in data exploration, such as mapping of visual properties from values in the data domain using transfer functions. Interacting in the data domain is an effective way to filter away undesired information but it is difficult to predict where the values lie in the spatial domain. In this work we make extensive use of dynamic previews instantly generated as the user explores the data domain. The previews allow the user to predict what effect changes in the data domain will have on the rendered image without being aware that visual parameters are set in the data domain. Each preview represents a subrange of the data domain where overview and details are given on demand through zooming and panning. The method has been designed with touch interfaces as the target platform for interaction. We provide a qualitative evaluation performed with visitors to a science center to show the utility of the approach.	Daniel Jönsson;Martin Falk;Anders Ynnerman	Linkoping Univ., Linkoping, Sweden|c|;;	10.1109/TVCG.2008.162;10.1109/TVCG.2011.261;10.1109/VISUAL.1996.568113;10.1109/TVCG.2012.231;10.1109/TVCG.2010.195;10.1109/TVCG.2011.224;10.1109/TVCG.2006.148;10.1109/TVCG.2011.218	Transfer function, scalar fields, volume rendering, touch interaction, visualization, user interfaces	
SciVis	2015	JiTTree: A Just-in-Time Compiled Sparse GPU Volume Data Structure	10.1109/TVCG.2015.2467331	http://dx.doi.org/10.1109/TVCG.2015.2467331	1025	1034	J	Sparse volume data structures enable the efficient representation of large but sparse volumes in GPU memory for computation and visualization. However, the choice of a specific data structure for a given data set depends on several factors, such as the memory budget, the sparsity of the data, and data access patterns. In general, there is no single optimal sparse data structure, but a set of several candidates with individual strengths and drawbacks. One solution to this problem are hybrid data structures which locally adapt themselves to the sparsity. However, they typically suffer from increased traversal overhead which limits their utility in many applications. This paper presents JiTTree, a novel sparse hybrid volume data structure that uses just-in-time compilation to overcome these problems. By combining multiple sparse data structures and reducing traversal overhead we leverage their individual advantages. We demonstrate that hybrid data structures adapt well to a large range of data sets. They are especially superior to other sparse data structures for data sets that locally vary in sparsity. Possible optimization criteria are memory, performance and a combination thereof. Through just-in-time (JIT) compilation, JiTTree reduces the traversal overhead of the resulting optimal data structure. As a result, our hybrid volume data structure enables efficient computations on the GPU, while being superior in terms of memory usage when compared to non-hybrid data structures.	Matthias Labschutz;Stefan Bruckner;Eduard Gröller;Markus Hadwiger;Peter Rautek	;;;;	10.1109/TVCG.2012.240	Data Transformation and Representation, GPUs and Multi-core Architectures, Volume Rendering	
SciVis	2015	In Situ Eddy Analysis in a High-Resolution Ocean Climate Model	10.1109/TVCG.2015.2467411	http://dx.doi.org/10.1109/TVCG.2015.2467411	857	866	J	An eddy is a feature associated with a rotating body of fluid, surrounded by a ring of shearing fluid. In the ocean, eddies are 10 to 150 km in diameter, are spawned by boundary currents and baroclinic instabilities, may live for hundreds of days, and travel for hundreds of kilometers. Eddies are important in climate studies because they transport heat, salt, and nutrients through the world's oceans and are vessels of biological productivity. The study of eddies in global ocean-climate models requires large-scale, high-resolution simulations. This poses a problem for feasible (timely) eddy analysis, as ocean simulations generate massive amounts of data, causing a bottleneck for traditional analysis workflows. To enable eddy studies, we have developed an in situ workflow for the quantitative and qualitative analysis of MPAS-Ocean, a high-resolution ocean climate model, in collaboration with the ocean model research and development process. Planned eddy analysis at high spatial and temporal resolutions will not be possible with a postprocessing workflow due to various constraints, such as storage size and I/O time, but the in situ workflow enables it and scales well to ten-thousand processing elements.	Jonathan Woodring;Mark Petersen;Andre Schmeißer;John Patchett;James P. Ahrens;Hans Hagen	Los Alamos Nat. Lab., Los Alamos, NM, USA|c|;;;;;	10.1109/TVCG.2008.143;10.1109/VISUAL.2005.1532830;10.1109/TVCG.2010.215;10.1109/TVCG.2011.162	In situ analysis, online analysis, mesoscale eddies, ocean modeling, climate modeling, simulation, feature extraction,feature analysis, high performance computing, supercomputing, software engineering, collaborative development, revision control	
SciVis	2015	Adaptive Multilinear Tensor Product Wavelets	10.1109/TVCG.2015.2467412	http://dx.doi.org/10.1109/TVCG.2015.2467412	985	994	J	Many foundational visualization techniques including isosurfacing, direct volume rendering and texture mapping rely on piecewise multilinear interpolation over the cells of a mesh. However, there has not been much focus within the visualization community on techniques that efficiently generate and encode globally continuous functions defined by the union of multilinear cells. Wavelets provide a rich context for analyzing and processing complicated datasets. In this paper, we exploit adaptive regular refinement as a means of representing and evaluating functions described by a subset of their nonzero wavelet coefficients. We analyze the dependencies involved in the wavelet transform and describe how to generate and represent the coarsest adaptive mesh with nodal function values such that the inverse wavelet transform is exactly reproduced via simple interpolation (subdivision) over the mesh elements. This allows for an adaptive, sparse representation of the function with on-demand evaluation at any point in the domain. We focus on the popular wavelets formed by tensor products of linear B-splines, resulting in an adaptive, nonconforming but crack-free quadtree (2D) or octree (3D) mesh that allows reproducing globally continuous functions via multilinear interpolation over its cells.	Kenneth Weiss;Peter Lindstrom	Lawrence Livermore Nat. Lab., Livermore, CA, USA|c|;	10.1109/TVCG.2010.145;10.1109/VISUAL.1997.663860;10.1109/VISUAL.2002.1183810;10.1109/TVCG.2011.252;10.1109/VISUAL.1996.568127;10.1109/TVCG.2009.186	Multilinear interpolation, adaptive wavelets, multiresolution models, octrees, continuous reconstruction	
SciVis	2015	Planar Visualization of Treelike Structures	10.1109/TVCG.2015.2467413	http://dx.doi.org/10.1109/TVCG.2015.2467413	906	915	J	We present a novel method to create planar visualizations of treelike structures (e.g., blood vessels and airway trees) where the shape of the object is well preserved, allowing for easy recognition by users familiar with the structures. Based on the extracted skeleton within the treelike object, a radial planar embedding is first obtained such that there are no self-intersections of the skeleton which would have resulted in occlusions in the final view. An optimization procedure which adjusts the angular positions of the skeleton nodes is then used to reconstruct the shape as closely as possible to the original, according to a specified view plane, which thus preserves the global geometric context of the object. Using this shape recovered embedded skeleton, the object surface is then flattened to the plane without occlusions using harmonic mapping. The boundary of the mesh is adjusted during the flattening step to account for regions where the mesh is stretched over concavities. This parameterized surface can then be used either as a map for guidance during endoluminal navigation or directly for interrogation and decision making. Depth cues are provided with a grayscale border to aid in shape understanding. Examples are presented using bronchial trees, cranial and lower limb blood vessels, and upper aorta datasets, and the results are evaluated quantitatively and with a user study.	Joseph Marino;Arie E. Kaufman	;	10.1109/TVCG.2011.235;10.1109/VISUAL.2001.964540;10.1109/TVCG.2011.192;10.1109/TVCG.2014.2346406;10.1109/VISUAL.2001.964538;10.1109/VISUAL.2004.75;10.1109/VISUAL.2002.1183754;10.1109/VISUAL.2003.1250353;10.1109/TVCG.2011.182;10.1109/TVCG.2006.172	Geometry-based techniques, view-dependent visualization, medical visualization, planar embedding	
SciVis	2015	Association Analysis for Visual Exploration of Multivariate Scientific Data Sets	10.1109/TVCG.2015.2467431	http://dx.doi.org/10.1109/TVCG.2015.2467431	955	964	J	The heterogeneity and complexity of multivariate characteristics poses a unique challenge to visual exploration of multivariate scientific data sets, as it requires investigating the usually hidden associations between different variables and specific scalar values to understand the data's multi-faceted properties. In this paper, we present a novel association analysis method that guides visual exploration of scalar-level associations in the multivariate context. We model the directional interactions between scalars of different variables as information flows based on association rules. We introduce the concepts of informativeness and uniqueness to describe how information flows between scalars of different variables and how they are associated with each other in the multivariate domain. Based on scalar-level associations represented by a probabilistic association graph, we propose the Multi-Scalar Informativeness-Uniqueness (MSIU) algorithm to evaluate the informativeness and uniqueness of scalars. We present an exploration framework with multiple interactive views to explore the scalars of interest with confident associations in the multivariate spatial domain, and provide guidelines for visual exploration using our framework. We demonstrate the effectiveness and usefulness of our approach through case studies using three representative multivariate scientific data sets.	Xiaotong Liu;Han-Wei Shen	;	10.1109/TVCG.2013.133;10.1109/TVCG.2007.70519;10.1109/TVCG.2008.116;10.1109/TVCG.2007.70615;10.1109/VISUAL.1995.485139;10.1109/TVCG.2006.165;10.1109/VAST.2012.6400488;10.1109/TVCG.2011.178;10.1109/VAST.2007.4389000	Multivariate data, association analysis, visual exploration, multiple views	
SciVis	2015	Interstitial and Interlayer Ion Diffusion Geometry Extraction in Graphitic Nanosphere Battery Materials	10.1109/TVCG.2015.2467432	http://dx.doi.org/10.1109/TVCG.2015.2467432	916	925	J	Large-scale molecular dynamics (MD) simulations are commonly used for simulating the synthesis and ion diffusion of battery materials. A good battery anode material is determined by its capacity to store ion or other diffusers. However, modeling of ion diffusion dynamics and transport properties at large length and long time scales would be impossible with current MD codes. To analyze the fundamental properties of these materials, therefore, we turn to geometric and topological analysis of their structure. In this paper, we apply a novel technique inspired by discrete Morse theory to the Delaunay triangulation of the simulated geometry of a thermally annealed carbon nanosphere. We utilize our computed structures to drive further geometric analysis to extract the interstitial diffusion structure as a single mesh. Our results provide a new approach to analyze the geometry of the simulated carbon nanosphere, and new insights into the role of carbon defect size and distribution in determining the charge capacity and charge dynamics of these carbon based battery materials.	Attila Gyulassy;Aaron Knoll;Kah Chun Lau;Bei Wang;Peer-Timo Bremer;Michael E. Papka;Larry A. Curtiss;Valerio Pascucci	;;;	10.1109/VISUAL.2005.1532795;10.1109/TVCG.2011.244;10.1109/TVCG.2014.2346403;10.1109/VISUAL.2005.1532839;10.1109/TVCG.2011.259	materials science, morse-smale, topology, Delaunay, computational geometry	
SciVis	2015	Interactive Visualization for Singular Fibers of Functions f : R3 -> R2	10.1109/TVCG.2015.2467433	http://dx.doi.org/10.1109/TVCG.2015.2467433	945	954	J	Scalar topology in the form of Morse theory has provided computational tools that analyze and visualize data from scientific and engineering tasks. Contracting isocontours to single points encapsulates variations in isocontour connectivity in the Reeb graph. For multivariate data, isocontours generalize to fibers-inverse images of points in the range, and this area is therefore known as fiber topology. However, fiber topology is less fully developed than Morse theory, and current efforts rely on manual visualizations. This paper presents how to accelerate and semi-automate this task through an interface for visualizing fiber singularities of multivariate functions R3->R2. This interface exploits existing conventions of fiber topology, but also introduces a 3D view based on the extension of Reeb graphs to Reeb spaces. Using the Joint Contour Net, a quantized approximation of the Reeb space, this accelerates topological visualization and permits online perturbation to reduce or remove degeneracies in functions under study. Validation of the interface is performed by assessing whether the interface supports the mathematical workflow both of experts and of less experienced mathematicians.	Daisuke Sakurai;Osamu Saeki;Hamish Carr;Hsiang-Yun Wu;Takahiro Yamamoto;David J. Duke;Shigeo Takahashi	Univ. of Tokyo & Japan Atomic Energy Agency, Kashiwa, Japan|c|;;;;;;	10.1109/TVCG.2008.119;10.1109/VISUAL.1997.663875;10.1109/TVCG.2012.287;10.1109/TVCG.2010.213;10.1109/TVCG.2014.2346447;10.1109/TVCG.2010.146;10.1109/VISUAL.2002.1183774;10.1109/TVCG.2008.143;10.1109/TVCG.2009.119;10.1109/TVCG.2007.70601	Singular fibers, fiber topology, mathematical visualization, design study	
SciVis	2015	AnimoAminoMiner: Exploration of Protein Tunnels and their Properties in Molecular Dynamics	10.1109/TVCG.2015.2467434	http://dx.doi.org/10.1109/TVCG.2015.2467434	747	756	J	In this paper we propose a novel method for the interactive exploration of protein tunnels. The basic principle of our approach is that we entirely abstract from the 3D/4D space the simulated phenomenon is embedded in. A complex 3D structure and its curvature information is represented only by a straightened tunnel centerline and its width profile. This representation focuses on a key aspect of the studied geometry and frees up graphical estate to key chemical and physical properties represented by surrounding amino acids. The method shows the detailed tunnel profile and its temporal aggregation. The profile is interactively linked with a visual overview of all amino acids which are lining the tunnel over time. In this overview, each amino acid is represented by a set of colored lines depicting the spatial and temporal impact of the amino acid on the corresponding tunnel. This representation clearly shows the importance of amino acids with respect to selected criteria. It helps the biochemists to select the candidate amino acids for mutation which changes the protein function in a desired way. The AnimoAminoMiner was designed in close cooperation with domain experts. Its usefulness is documented by their feedback and a case study, which are included.	Jan Byska;Mathieu Le Muzic;Eduard Gröller;Ivan Viola;Barbora Kozlíková	Masaryk Univ., Brno, Czech Republic|c|;;;;	10.1109/VISUAL.2002.1183754;10.1109/TVCG.2009.136;10.1109/TVCG.2011.259;10.1109/VISUAL.2001.964540	Protein, tunnel, molecular dynamics, aggregation, interaction	
SciVis	2015	Glyph-Based Comparative Visualization for Diffusion Tensor Fields	10.1109/TVCG.2015.2467435	http://dx.doi.org/10.1109/TVCG.2015.2467435	797	806	J	Diffusion Tensor Imaging (DTI) is a magnetic resonance imaging modality that enables the in-vivo reconstruction and visualization of fibrous structures. To inspect the local and individual diffusion tensors, glyph-based visualizations are commonly used since they are able to effectively convey full aspects of the diffusion tensor. For several applications it is necessary to compare tensor fields, e.g., to study the effects of acquisition parameters, or to investigate the influence of pathologies on white matter structures. This comparison is commonly done by extracting scalar information out of the tensor fields and then comparing these scalar fields, which leads to a loss of information. If the glyph representation is kept, simple juxtaposition or superposition can be used. However, neither facilitates the identification and interpretation of the differences between the tensor fields. Inspired by the checkerboard style visualization and the superquadric tensor glyph, we design a new glyph to locally visualize differences between two diffusion tensors by combining juxtaposition and explicit encoding. Because tensor scale, anisotropy type, and orientation are related to anatomical information relevant for DTI applications, we focus on visualizing tensor differences in these three aspects. As demonstrated in a user study, our new glyph design allows users to efficiently and effectively identify the tensor differences. We also apply our new glyphs to investigate the differences between DTI datasets of the human brain in two different contexts using different b-values, and to compare datasets from a healthy and HIV-infected subject.	Changgong Zhang;Thomas Schultz 0001;Kai Lawonn;Elmar Eisemann;Anna Vilanova	;;;;	10.1109/TVCG.2015.2467031;10.1109/TVCG.2006.134;10.1109/TVCG.2010.134;10.1109/VISUAL.1998.745294;10.1109/VAST.2014.7042491;10.1109/TVCG.2010.199	Glyph Design, Comparative Visualization, Diffusion Tensor Field	
SciVis	2015	Distribution Driven Extraction and Tracking of Features for Time-varying Data Analysis	10.1109/TVCG.2015.2467436	http://dx.doi.org/10.1109/TVCG.2015.2467436	837	846	J	Effective analysis of features in time-varying data is essential in numerous scientific applications. Feature extraction and tracking are two important tasks scientists rely upon to get insights about the dynamic nature of the large scale time-varying data. However, often the complexity of the scientific phenomena only allows scientists to vaguely define their feature of interest. Furthermore, such features can have varying motion patterns and dynamic evolution over time. As a result, automatic extraction and tracking of features becomes a non-trivial task. In this work, we investigate these issues and propose a distribution driven approach which allows us to construct novel algorithms for reliable feature extraction and tracking with high confidence in the absence of accurate feature definition. We exploit two key properties of an object, motion and similarity to the target feature, and fuse the information gained from them to generate a robust feature-aware classification field at every time step. Tracking of features is done using such classified fields which enhances the accuracy and robustness of the proposed algorithm. The efficacy of our method is demonstrated by successfully applying it on several scientific data sets containing a wide range of dynamic time-varying features.	Soumya Dutta;Han-Wei Shen	;	10.1109/TVCG.2007.70599;10.1109/VISUAL.1993.398877;10.1109/VISUAL.2004.107;10.1109/TVCG.2011.246;10.1109/TVCG.2007.70615;10.1109/VISUAL.2003.1250374;10.1109/TVCG.2013.152;10.1109/TVCG.2014.2346423;10.1109/TVCG.2007.70579;10.1109/VISUAL.1996.567807;10.1109/VISUAL.1998.745288;10.1109/TVCG.2008.163;10.1109/TVCG.2008.140	Gaussian mixture model (GMM), Incremental learning, Feature extraction and tracking, Time-varying data analysis	
SciVis	2015	NeuroBlocks - Visual Tracking of Segmentation and Proofreading for Large Connectomics Projects	10.1109/TVCG.2015.2467441	http://dx.doi.org/10.1109/TVCG.2015.2467441	738	746	J	In the field of connectomics, neuroscientists acquire electron microscopy volumes at nanometer resolution in order to reconstruct a detailed wiring diagram of the neurons in the brain. The resulting image volumes, which often are hundreds of terabytes in size, need to be segmented to identify cell boundaries, synapses, and important cell organelles. However, the segmentation process of a single volume is very complex, time-intensive, and usually performed using a diverse set of tools and many users. To tackle the associated challenges, this paper presents NeuroBlocks, which is a novel visualization system for tracking the state, progress, and evolution of very large volumetric segmentation data in neuroscience. NeuroBlocks is a multi-user web-based application that seamlessly integrates the diverse set of tools that neuroscientists currently use for manual and semi-automatic segmentation, proofreading, visualization, and analysis. NeuroBlocks is the first system that integrates this heterogeneous tool set, providing crucial support for the management, provenance, accountability, and auditing of large-scale segmentations. We describe the design of NeuroBlocks, starting with an analysis of the domain-specific tasks, their inherent challenges, and our subsequent task abstraction and visual representation. We demonstrate the utility of our design based on two case studies that focus on different user roles and their respective requirements for performing and tracking the progress of segmentation and proofreading in a large real-world connectomics project.	Ali K. Ai-Awami;Johanna Beyer;Daniel Haehn;Narayanan Kasthuri;Jeff Lichtman;Hanspeter Pfister;Markus Hadwiger	;;;;;;	10.1109/TVCG.2014.2346312;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2013.142;10.1109/TVCG.2009.121;10.1109/TVCG.2012.240;10.1109/TVCG.2014.2346371;10.1109/TVCG.2013.174;10.1109/TVCG.2014.2346249;10.1109/TVCG.2007.70584	Neuroscience, Segmentation, Proofreading, Data and Provenance Tracking	
SciVis	2015	Diderot: a Domain-Specific Language for Portable Parallel Scientific Visualization and Image Analysis	10.1109/TVCG.2015.2467449	http://dx.doi.org/10.1109/TVCG.2015.2467449	867	876	J	Many algorithms for scientific visualization and image analysis are rooted in the world of continuous scalar, vector, and tensor fields, but are programmed in low-level languages and libraries that obscure their mathematical foundations. Diderot is a parallel domain-specific language that is designed to bridge this semantic gap by providing the programmer with a high-level, mathematical programming notation that allows direct expression of mathematical concepts in code. Furthermore, Diderot provides parallel performance that takes advantage of modern multicore processors and GPUs. The high-level notation allows a concise and natural expression of the algorithms and the parallelism allows efficient execution on real-world datasets.	Gordon L. Kindlmann;Charisee Chiw;Nicholas Seltzer;Lamont Samuels;John H. Reppy	;;;;	10.1109/TVCG.2009.174;10.1109/TVCG.2011.185;10.1109/VISUAL.2005.1532856;10.1109/TVCG.2014.2346322;10.1109/TVCG.2012.240;10.1109/VISUAL.2003.1250414;10.1109/VISUAL.1999.809896;10.1109/TVCG.2007.70534;10.1109/TVCG.2014.2346318;10.1109/VISUAL.1998.745290;10.1109/TVCG.2008.148;10.1109/TVCG.2008.163	Domain specific language, portable parallel programming, scientific visualization, tensor fields	
SciVis	2015	Visualization and Analysis of Rotating Stall for Transonic Jet Engine Simulation	10.1109/TVCG.2015.2467952	http://dx.doi.org/10.1109/TVCG.2015.2467952	847	856	J	Identification of early signs of rotating stall is essential for the study of turbine engine stability. With recent advancements of high performance computing, high-resolution unsteady flow fields allow in depth exploration of rotating stall and its possible causes. Performing stall analysis, however, involves significant effort to process large amounts of simulation data, especially when investigating abnormalities across many time steps. In order to assist scientists during the exploration process, we present a visual analytics framework to identify suspected spatiotemporal regions through a comparative visualization so that scientists are able to focus on relevant data in more detail. To achieve this, we propose efficient stall analysis algorithms derived from domain knowledge and convey the analysis results through juxtaposed interactive plots. Using our integrated visualization system, scientists can visually investigate the detected regions for potential stall initiation and further explore these regions to enhance the understanding of this phenomenon. Positive feedback from scientists demonstrate the efficacy of our system in analyzing rotating stall.	Chun-Ming Chen;Soumya Dutta;Xiaotong Liu;Gregory Heinlein;Han-Wei Shen;Jen-Ping Chen	Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH, USA|c|;;;;;	10.1109/VISUAL.1991.175794;10.1109/TVCG.2007.70599;10.1109/VISUAL.2000.885739;10.1109/TVCG.2013.122;10.1109/TVCG.2013.189;10.1109/VISUAL.2004.128;10.1109/VISUAL.2005.1532830;10.1109/TVCG.2014.2346265	Turbine flow visualization, vortex extraction, anomaly detection, juxtaposition, brushing and linking, time series	
SciVis	2015	Isosurface Visualization of Data with Nonparametric Models for Uncertainty	10.1109/TVCG.2015.2467958	http://dx.doi.org/10.1109/TVCG.2015.2467958	777	786	J	The problem of isosurface extraction in uncertain data is an important research problem and may be approached in two ways. One can extract statistics (e.g., mean) from uncertain data points and visualize the extracted field. Alternatively, data uncertainty, characterized by probability distributions, can be propagated through the isosurface extraction process. We analyze the impact of data uncertainty on topology and geometry extraction algorithms. A novel, edge-crossing probability based approach is proposed to predict underlying isosurface topology for uncertain data. We derive a probabilistic version of the midpoint decider that resolves ambiguities that arise in identifying topological configurations. Moreover, the probability density function characterizing positional uncertainty in isosurfaces is derived analytically for a broad class of nonparametric distributions. This analytic characterization can be used for efficient closed-form computation of the expected value and variation in geometry. Our experiments show the computational advantages of our analytic approach over Monte-Carlo sampling for characterizing positional uncertainty. We also show the advantage of modeling underlying error densities in a nonparametric statistical framework as opposed to a parametric statistical framework through our experiments on ensemble datasets and uncertain scalar fields.	Tushar Athawale;Elham Sakhaee;Alireza Entezari	Dept. of Comput. & Inf. Sci. & Eng., Univ. of Florida, Gainesville, FL, USA|c|;;	10.1109/TVCG.2013.208;10.1109/VISUAL.2002.1183769;10.1109/TVCG.2013.152;10.1109/TVCG.2007.70518;10.1109/TVCG.2012.249;10.1109/TVCG.2013.143	Uncertainty quantification, linear interpolation, isosurface extraction, marching cubes, nonparametric statistics	
SciVis	2015	Occlusion-free Blood Flow Animation with Wall Thickness Visualization	10.1109/TVCG.2015.2467961	http://dx.doi.org/10.1109/TVCG.2015.2467961	728	737	J	We present the first visualization tool that combines pathlines from blood flow and wall thickness information. Our method uses illustrative techniques to provide occlusion-free visualization of the flow. We thus offer medical researchers an effective visual analysis tool for aneurysm treatment risk assessment. Such aneurysms bear a high risk of rupture and significant treatment-related risks. Therefore, to get a fully informed decision it is essential to both investigate the vessel morphology and the hemodynamic data. Ongoing research emphasizes the importance of analyzing the wall thickness in risk assessment. Our combination of blood flow visualization and wall thickness representation is a significant improvement for the exploration and analysis of aneurysms. As all presented information is spatially intertwined, occlusion problems occur. We solve these occlusion problems by dynamic cutaway surfaces. We combine this approach with a glyph-based blood flow representation and a visual mapping of wall thickness onto the vessel surface. We developed a GPU-based implementation of our visualizations which facilitates wall thickness analysis through real-time rendering and flexible interactive data exploration mechanisms. We designed our techniques in collaboration with domain experts, and we provide details about the evaluation of the technique and tool.	Kai Lawonn;Sylvia Glaßer;Anna Vilanova;Bernhard Preim;Tobias Isenberg 0001	Univ. of Magdeburg, Magdeburg, Germany|c|;;;;	10.1109/TVCG.2009.138;10.1109/TVCG.2011.243;10.1109/TVCG.2014.2346406;10.1109/TVCG.2010.153;10.1109/TVCG.2011.215;10.1109/VISUAL.2004.48	Medical visualization, aneurysms, blood flow, wall thickness, illustrative visualization	
SciVis	2015	Effectiveness of Structured Textures on Dynamically Changing Terrain-like Surfaces	10.1109/TVCG.2015.2467962	http://dx.doi.org/10.1109/TVCG.2015.2467962	926	934	J	Previous perceptual research and human factors studies have identified several effective methods for texturing 3D surfaces to ensure that their curvature is accurately perceived by viewers. However, most of these studies examined the application of these techniques to static surfaces. This paper explores the effectiveness of applying these techniques to dynamically changing surfaces. When these surfaces change shape, common texturing methods, such as grids and contours, induce a range of different motion cues, which can draw attention and provide information about the size, shape, and rate of change. A human factors study was conducted to evaluate the relative effectiveness of these methods when applied to dynamically changing pseudo-terrain surfaces. The results indicate that, while no technique is most effective for all cases, contour lines generally perform best, and that the pseudo-contour lines induced by banded color scales convey the same benefits.	Thomas Butkiewicz;Andrew H. Stevens	Center for Coastal & Ocean Mapping, Univ. of New Hampshire, Durham, NH, USA|c|;		Structured textures, terrain, deformation, dynamic surfaces	
SciVis	2015	Anisotropic Ambient Volume Shading	10.1109/TVCG.2015.2467963	http://dx.doi.org/10.1109/TVCG.2015.2467963	1015	1024	J	We present a novel method to compute anisotropic shading for direct volume rendering to improve the perception of the orientation and shape of surface-like structures. We determine the scale-aware anisotropy of a shading point by analyzing its ambient region. We sample adjacent points with similar scalar values to perform a principal component analysis by computing the eigenvectors and eigenvalues of the covariance matrix. In particular, we estimate the tangent directions, which serve as the tangent frame for anisotropic bidirectional reflectance distribution functions. Moreover, we exploit the ratio of the eigenvalues to measure the magnitude of the anisotropy at each shading point. Altogether, this allows us to model a data-driven, smooth transition from isotropic to strongly anisotropic volume shading. In this way, the shape of volumetric features can be enhanced significantly by aligning specular highlights along the principal direction of anisotropy. Our algorithm is independent of the transfer function, which allows us to compute all shading parameters once and store them with the data set. We integrated our method in a GPU-based volume renderer, which offers interactive control of the transfer function, light source positions, and viewpoint. Our results demonstrate the benefit of anisotropic shading for visualization to achieve data-driven local illumination for improved perception compared to isotropic shading.	Marco Ament;Carsten Dachsbacher	Karlsruhe Inst. of Technol., Karlsruhe, Germany|c|;	10.1109/TVCG.2014.2346333;10.1109/TVCG.2013.129;10.1109/TVCG.2014.2346411;10.1109/TVCG.2012.232;10.1109/VISUAL.1999.809886;10.1109/VISUAL.2003.1250414;10.1109/TVCG.2011.161;10.1109/VISUAL.2005.1532772;10.1109/VISUAL.1994.346331;10.1109/VISUAL.2002.1183771;10.1109/TVCG.2011.198;10.1109/VISUAL.2004.5;10.1109/TVCG.2012.267;10.1109/VISUAL.1996.567777	Direct volume rendering, volume illumination, anisotropic shading	
SciVis	2015	Mining Graphs for Understanding Time-Varying Volumetric Data	10.1109/TVCG.2015.2468031	http://dx.doi.org/10.1109/TVCG.2015.2468031	965	974	J	A notable recent trend in time-varying volumetric data analysis and visualization is to extract data relationships and represent them in a low-dimensional abstract graph view for visual understanding and making connections to the underlying data. Nevertheless, the ever-growing size and complexity of data demands novel techniques that go beyond standard brushing and linking to allow significant reduction of cognition overhead and interaction cost. In this paper, we present a mining approach that automatically extracts meaningful features from a graph-based representation for exploring time-varying volumetric data. This is achieved through the utilization of a series of graph analysis techniques including graph simplification, community detection, and visual recommendation. We investigate the most important transition relationships for time-varying data and evaluate our solution with several time-varying data sets of different sizes and characteristics. For gaining insights from the data, we show that our solution is more efficient and effective than simply asking users to extract relationships via standard interaction techniques, especially when the data set is large and the relationships are complex. We also collect expert feedback to confirm the usefulness of our approach.	Yi Gu;Chaoli Wang;Tom Peterka;Robert Jacob;Seung Hyun Kim	Dept. Comput. Sci. & Eng., Univ. of Notre Dame, Notre Dame, IN, USA|c|;;;;	10.1109/TVCG.2009.122;10.1109/TVCG.2013.151;10.1109/TVCG.2011.246;10.1109/TVCG.2008.116;10.1109/VISUAL.1999.809871;10.1109/TVCG.2006.165;10.1109/TVCG.2009.165;10.1109/TVCG.2006.159	Time-varying data visualization, graph simplification, community detection, visual recommendation	
SciVis	2015	Gaze Stripes: Image-Based Visualization of Eye Tracking Data	10.1109/TVCG.2015.2468091	http://dx.doi.org/10.1109/TVCG.2015.2468091	1005	1014	J	We present a new visualization approach for displaying eye tracking data from multiple participants. We aim to show the spatio-temporal data of the gaze points in the context of the underlying image or video stimulus without occlusion. Our technique, denoted as gaze stripes, does not require the explicit definition of areas of interest but directly uses the image data around the gaze points, similar to thumbnails for images. A gaze stripe consists of a sequence of such gaze point images, oriented along a horizontal timeline. By displaying multiple aligned gaze stripes, it is possible to analyze and compare the viewing behavior of the participants over time. Since the analysis is carried out directly on the image data, expensive post-processing or manual annotation are not required. Therefore, not only patterns and outliers in the participants' scanpaths can be detected, but the context of the stimulus is available as well. Furthermore, our approach is especially well suited for dynamic stimuli due to the non-aggregated temporal mapping. Complementary views, i.e., markers, notes, screenshots, histograms, and results from automatic clustering, can be added to the visualization to display analysis results. We illustrate the usefulness of our technique on static and dynamic stimuli. Furthermore, we discuss the limitations and scalability of our approach in comparison to established visualization techniques.	Kuno Kurzhals;Marcel Hlawatsch;Florian Heimerl;Michael Burch;Thomas Ertl;Daniel Weiskopf	;;;;;	10.1109/TVCG.2011.232;10.1109/TVCG.2012.276;10.1109/INFVIS.2002.1173156;10.1109/TVCG.2013.194;10.1109/TVCG.2008.125	Eye tracking, time-dependent data, spatio-temporal visualization	
SciVis	2015	Effective Visualization of Temporal Ensembles	10.1109/TVCG.2015.2468093	http://dx.doi.org/10.1109/TVCG.2015.2468093	787	796	J	An ensemble is a collection of related datasets, called members, built from a series of runs of a simulation or an experiment. Ensembles are large, temporal, multidimensional, and multivariate, making them difficult to analyze. Another important challenge is visualizing ensembles that vary both in space and time. Initial visualization techniques displayed ensembles with a small number of members, or presented an overview of an entire ensemble, but without potentially important details. Recently, researchers have suggested combining these two directions, allowing users to choose subsets of members to visualization. This manual selection process places the burden on the user to identify which members to explore. We first introduce a static ensemble visualization system that automatically helps users locate interesting subsets of members to visualize. We next extend the system to support analysis and visualization of temporal ensembles. We employ 3D shape comparison, cluster tree visualization, and glyph based visualization to represent different levels of detail within an ensemble. This strategy is used to provide two approaches for temporal ensemble analysis: (1) segment based ensemble analysis, to capture important shape transition time-steps, clusters groups of similar members, and identify common shape changes over time across multiple members; and (2) time-step based ensemble analysis, which assumes ensemble members are aligned in time by combining similar shapes at common time-steps. Both approaches enable users to interactively visualize and analyze a temporal ensemble from different perspectives at different levels of detail. We demonstrate our techniques on an ensemble studying matter transition from hadronic gas to quark-gluon plasma during gold-on-gold particle collisions.	Lihua Hao;Christopher G. Healey;Steffen A. Bass	;;	10.1109/TVCG.2014.2346448;10.1109/VISUAL.2005.1532839;10.1109/VISUAL.2005.1532838;10.1109/TVCG.2014.2346751;10.1109/TVCG.2009.155;10.1109/TVCG.2014.2346455;10.1109/TVCG.2010.181;10.1109/TVCG.2013.143	Ensemble visualization	
VAST	2015	TargetVue: Visual Analysis of Anomalous User Behaviors in Online Communication Systems	10.1109/TVCG.2015.2467196	http://dx.doi.org/10.1109/TVCG.2015.2467196	280	289	J	Users with anomalous behaviors in online communication systems (e.g. email and social medial platforms) are potential threats to society. Automated anomaly detection based on advanced machine learning techniques has been developed to combat this issue; challenges remain, though, due to the difficulty of obtaining proper ground truth for model training and evaluation. Therefore, substantial human judgment on the automated analysis results is often required to better adjust the performance of anomaly detection. Unfortunately, techniques that allow users to understand the analysis results more efficiently, to make a confident judgment about anomalies, and to explore data in their context, are still lacking. In this paper, we propose a novel visual analysis system, TargetVue, which detects anomalous users via an unsupervised learning model and visualizes the behaviors of suspicious users in behavior-rich context through novel visualization designs and multiple coordinated contextual views. Particularly, TargetVue incorporates three new ego-centric glyphs to visually summarize a user's behaviors which effectively present the user's communication activities, features, and social interactions. An efficient layout method is proposed to place these glyphs on a triangle grid, which captures similarities among users and facilitates comparisons of behaviors of different users. We demonstrate the power of TargetVue through its application in a social bot detection challenge using Twitter data, a case study based on email records, and an interview with expert users. Our evaluation shows that TargetVue is beneficial to the detection of users with anomalous communication behaviors.	Nan Cao;Conglei Shi;Wan-Yi Sabrina Lin;Jie Lu;Yu-Ru Lin;Ching-Yung Lin	;;;;;	10.1109/TVCG.2012.291;10.1109/TVCG.2006.170;10.1109/VISUAL.2002.1183816;10.1109/TVCG.2014.2346922	Anomaly Detection, Social Media, Visual Analysis	
VAST	2015	TimeLineCurator: Interactive Authoring of Visual Timelines from Unstructured Text	10.1109/TVCG.2015.2467531	http://dx.doi.org/10.1109/TVCG.2015.2467531	300	309	J	We present TimeLineCurator, a browser-based authoring tool that automatically extracts event data from temporal references in unstructured text documents using natural language processing and encodes them along a visual timeline. Our goal is to facilitate the timeline creation process for journalists and others who tell temporal stories online. Current solutions involve manually extracting and formatting event data from source documents, a process that tends to be tedious and error prone. With TimeLineCurator, a prospective timeline author can quickly identify the extent of time encompassed by a document, as well as the distribution of events occurring along this timeline. Authors can speculatively browse possible documents to quickly determine whether they are appropriate sources of timeline material. TimeLineCurator provides controls for curating and editing events on a timeline, the ability to combine timelines from multiple source documents, and export curated timelines for online deployment. We evaluate TimeLineCurator through a benchmark comparison of entity extraction error against a manual timeline curation process, a preliminary evaluation of the user experience of timeline authoring, a brief qualitative analysis of its visual output, and a discussion of prospective use cases suggested by members of the target author communities following its deployment.	Johanna Fulda;Matthew Brehmer;Tamara Munzner	;;	10.1109/VAST.2014.7042493;10.1109/TVCG.2011.185;10.1109/TVCG.2014.2346431;10.1109/TVCG.2013.124;10.1109/VAST.2012.6400557;10.1109/VAST.2011.6102461;10.1109/VAST.2012.6400485;10.1109/TVCG.2013.162;10.1109/TVCG.2013.214;10.1109/TVCG.2012.224;10.1109/TVCG.2014.2346291;10.1109/TVCG.2012.213;10.1109/VAST.2007.4389006;10.1109/TVCG.2012.212;10.1109/VAST.2012.6400530;10.1109/TVCG.2007.70577	System, timelines, authoring environment, time-oriented data, journalism	
VAST	2015	Characterizing Provenance in Visualization and Data Analysis: An Organizational Framework of Provenance Types and Purposes	10.1109/TVCG.2015.2467551	http://dx.doi.org/10.1109/TVCG.2015.2467551	31	40	J	While the primary goal of visual analytics research is to improve the quality of insights and findings, a substantial amount of research in provenance has focused on the history of changes and advances throughout the analysis process. The term, provenance, has been used in a variety of ways to describe different types of records and histories related to visualization. The existing body of provenance research has grown to a point where the consolidation of design knowledge requires cross-referencing a variety of projects and studies spanning multiple domain areas. We present an organizational framework of the different types of provenance information and purposes for why they are desired in the field of visual analytics. Our organization is intended to serve as a framework to help researchers specify types of provenance and coordinate design knowledge across projects. We also discuss the relationships between these factors and the methods used to capture provenance information. In addition, our organization can be used to guide the selection of evaluation methodology and the comparison of study outcomes in provenance research.	Eric D. Ragan;Alex Endert;Jibonananda Sanyal;Jian Chen	;;;	10.1109/INFVIS.2005.1532136;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2013.155;10.1109/VISUAL.1993.398857;10.1109/VAST.2012.6400486;10.1109/TVCG.2014.2346575;10.1109/VAST.2010.5652932;10.1109/VAST.2008.4677365;10.1109/TVCG.2008.137;10.1109/TVCG.2013.126;10.1109/VAST.2009.5333020;10.1109/VAST.2010.5653598;10.1109/TVCG.2012.271;10.1109/TVCG.2014.2346573;10.1109/VAST.2008.4677366;10.1109/TVCG.2013.130;10.1109/TVCG.2010.181;10.1109/TVCG.2010.179;10.1109/VISUAL.1990.146375	Provenance, Analytic provenance, Visual analytics, Framework, Visualization, Conceptual model	
VAST	2015	The Data Context Map: Fusing Data and Attributes into a Unified Display	10.1109/TVCG.2015.2467552	http://dx.doi.org/10.1109/TVCG.2015.2467552	121	130	J	Numerous methods have been described that allow the visualization of the data matrix. But all suffer from a common problem - observing the data points in the context of the attributes is either impossible or inaccurate. We describe a method that allows these types of comprehensive layouts. We achieve it by combining two similarity matrices typically used in isolation - the matrix encoding the similarity of the attributes and the matrix encoding the similarity of the data points. This combined matrix yields two of the four submatrices needed for a full multi-dimensional scaling type layout. The remaining two submatrices are obtained by creating a fused similarity matrix - one that measures the similarity of the data points with respect to the attributes, and vice versa. The resulting layout places the data objects in direct context of the attributes and hence we call it the data context map. It allows users to simultaneously appreciate (1) the similarity of data objects, (2) the similarity of attributes in the specific scope of the collection of data objects, and (3) the relationships of data objects with attributes and vice versa. The contextual layout also allows data regions to be segmented and labeled based on the locations of the attributes. This enables, for example, the map's application in selection tasks where users seek to identify one or more data objects that best fit a certain configuration of factors, using the map to visually balance the tradeoffs.	Shenghui Cheng;Klaus Mueller	;	10.1109/TVCG.2013.146;10.1109/VAST.2009.5332629;10.1109/VISUAL.1997.663916;10.1109/VISUAL.1990.146402;10.1109/TVCG.2011.220;10.1109/INFVIS.1997.636793;10.1109/TVCG.2010.207	High Dimensional Data, Low-Dimensional Embedding, Visual Analytics, Decision Make, Tradeoffs	
VAST	2015	Temporal MDS Plots for Analysis of Multivariate Data	10.1109/TVCG.2015.2467553	http://dx.doi.org/10.1109/TVCG.2015.2467553	141	150	J	Multivariate time series data can be found in many application domains. Examples include data from computer networks, healthcare, social networks, or financial markets. Often, patterns in such data evolve over time among multiple dimensions and are hard to detect. Dimensionality reduction methods such as PCA and MDS allow analysis and visualization of multivariate data, but per se do not provide means to explore multivariate patterns over time. We propose Temporal Multidimensional Scaling (TMDS), a novel visualization technique that computes temporal one-dimensional MDS plots for multivariate data which evolve over time. Using a sliding window approach, MDS is computed for each data window separately, and the results are plotted sequentially along the time axis, taking care of plot alignment. Our TMDS plots enable visual identification of patterns based on multidimensional similarity of the data evolving over time. We demonstrate the usefulness of our approach in the field of network security and show in two case studies how users can iteratively explore the data to identify previously unknown, temporally evolving patterns.	Dominik Jäckle;Fabian Fischer;Tobias Schreck;Daniel A. Keim	Univ. of Konstanz, Konstanz, Germany|c|;;;	10.1109/VAST.2009.5332593;10.1109/VISUAL.1990.146402;10.1109/VISUAL.1995.485140;10.1109/VISUAL.1990.146386;10.1109/TVCG.2007.70592;10.1109/VAST.2009.5332628	Multivariate Data, Time Series, Data Reduction, Multidimensional Scaling	
VAST	2015	An Uncertainty-Aware Approach for Exploratory Microblog Retrieval	10.1109/TVCG.2015.2467554	http://dx.doi.org/10.1109/TVCG.2015.2467554	250	259	J	Although there has been a great deal of interest in analyzing customer opinions and breaking news in microblogs, progress has been hampered by the lack of an effective mechanism to discover and retrieve data of interest from microblogs. To address this problem, we have developed an uncertainty-aware visual analytics approach to retrieve salient posts, users, and hashtags. We extend an existing ranking technique to compute a multifaceted retrieval result: the mutual reinforcement rank of a graph node, the uncertainty of each rank, and the propagation of uncertainty among different graph nodes. To illustrate the three facets, we have also designed a composite visualization with three visual components: a graph visualization, an uncertainty glyph, and a flow map. The graph visualization with glyphs, the flow map, and the uncertainty analysis together enable analysts to effectively find the most uncertain results and interactively refine them. We have applied our approach to several Twitter datasets. Qualitative evaluation and two real-world case studies demonstrate the promise of our approach for retrieving high-quality microblog data.	Mengchen Liu;Shixia Liu;Xizhou Zhu;Qinying Liao;Furu Wei;Shimei Pan	;;;;;	10.1109/TVCG.2013.186;10.1109/TVCG.2012.291;10.1109/VAST.2009.5332611;10.1109/TVCG.2013.223;10.1109/TVCG.2011.233;10.1109/VAST.2014.7042494;10.1109/VISUAL.1996.568116;10.1109/INFVIS.2005.1532150;10.1109/VAST.2010.5652931;10.1109/TVCG.2011.197;10.1109/TVCG.2014.2346919;10.1109/TVCG.2013.232;10.1109/TVCG.2011.202;10.1109/TVCG.2014.2346920;10.1109/TVCG.2010.183;10.1109/TVCG.2012.285;10.1109/TVCG.2013.221;10.1109/TVCG.2014.2346922	microblog data, mutual reinforcement model, uncertainty modeling, uncertainty visualization, uncertainty propagation	
VAST	2015	VisOHC: Designing Visual Analytics for Online Health Communities	10.1109/TVCG.2015.2467555	http://dx.doi.org/10.1109/TVCG.2015.2467555	71	80	J	Through online health communities (OHCs), patients and caregivers exchange their illness experiences and strategies for overcoming the illness, and provide emotional support. To facilitate healthy and lively conversations in these communities, their members should be continuously monitored and nurtured by OHC administrators. The main challenge of OHC administrators' tasks lies in understanding the diverse dimensions of conversation threads that lead to productive discussions in their communities. In this paper, we present a design study in which three domain expert groups participated, an OHC researcher and two OHC administrators of online health communities, which was conducted to find with a visual analytic solution. Through our design study, we characterized the domain goals of OHC administrators and derived tasks to achieve these goals. As a result of this study, we propose a system called VisOHC, which visualizes individual OHC conversation threads as collapsed boxes-a visual metaphor of conversation threads. In addition, we augmented the posters' reply authorship network with marks and/or beams to show conversation dynamics within threads. We also developed unique measures tailored to the characteristics of OHCs, which can be encoded for thread visualizations at the users' requests. Our observation of the two administrators while using VisOHC showed that it supports their tasks and reveals interesting insights into online health communities. Finally, we share our methodological lessons on probing visual designs together with domain experts by allowing them to freely encode measurements into visual variables.	Bum Chul Kwon;Sung-Hee Kim;Sukwon Lee;Jaegul Choo;Jina Huh;Ji Soo Yi	;;;;;	10.1109/TVCG.2014.2346433;10.1109/VAST.2011.6102441;10.1109/TVCG.2014.2346292;10.1109/INFVIS.2003.1249028;10.1109/TVCG.2010.175;10.1109/VAST.2014.7042494;10.1109/TVCG.2014.2346331;10.1109/VAST.2009.5333919;10.1109/TVCG.2012.213;10.1109/TVCG.2009.171;10.1109/TVCG.2009.187;10.1109/TVCG.2013.221;10.1109/VAST.2012.6400554;10.1109/VAST.2014.7042496;10.1109/TVCG.2008.171	Online health communities, visual analytics, conversation analysis, thread visualization, healthcare, design study	
VAST	2015	The Role of Uncertainty, Awareness, and Trust in Visual Analytics	10.1109/TVCG.2015.2467591	http://dx.doi.org/10.1109/TVCG.2015.2467591	240	249	J	Visual analytics supports humans in generating knowledge from large and often complex datasets. Evidence is collected, collated and cross-linked with our existing knowledge. In the process, a myriad of analytical and visualisation techniques are employed to generate a visual representation of the data. These often introduce their own uncertainties, in addition to the ones inherent in the data, and these propagated and compounded uncertainties can result in impaired decision making. The user's confidence or trust in the results depends on the extent of user's awareness of the underlying uncertainties generated on the system side. This paper unpacks the uncertainties that propagate through visual analytics systems, illustrates how human's perceptual and cognitive biases influence the user's awareness of such uncertainties, and how this affects the user's trust building. The knowledge generation model for visual analytics is used to provide a terminology and framework to discuss the consequences of these aspects in knowledge construction and though examples, machine uncertainty is compared to human trust measures with provenance. Furthermore, guidelines for the design of uncertainty-aware systems are presented that can aid the user in better decision making.	Dominik Sacha;Hansi Senaratne;Bum Chul Kwon;Geoffrey P. Ellis;Daniel A. Keim	;;;;	10.1109/TVCG.2014.2346575;10.1109/VISUAL.2000.885679;10.1109/VAST.2008.4677385;10.1109/VAST.2009.5332611;10.1109/TVCG.2012.260;10.1109/VAST.2011.6102473;10.1109/VAST.2009.5333020;10.1109/VAST.2011.6102435;10.1109/TVCG.2012.279;10.1109/TVCG.2014.2346481;10.1109/VAST.2006.261416	Visual Analytics, Knowledge Generation, Uncertainty Measures and Propagation, Trust Building, Human Factors	
VAST	2015	Visually Exploring Transportation Schedules	10.1109/TVCG.2015.2467592	http://dx.doi.org/10.1109/TVCG.2015.2467592	170	179	J	Public transportation schedules are designed by agencies to optimize service quality under multiple constraints. However, real service usually deviates from the plan. Therefore, transportation analysts need to identify, compare and explain both eventual and systemic performance issues that must be addressed so that better timetables can be created. The purely statistical tools commonly used by analysts pose many difficulties due to the large number of attributes at tripand station-level for planned and real service. Also challenging is the need for models at multiple scales to search for patterns at different times and stations, since analysts do not know exactly where or when relevant patterns might emerge and need to compute statistical summaries for multiple attributes at different granularities. To aid in this analysis, we worked in close collaboration with a transportation expert to design TR-EX, a visual exploration tool developed to identify, inspect and compare spatio-temporal patterns for planned and real transportation service. TR-EX combines two new visual encodings inspired by Marey's Train Schedule: Trips Explorer for trip-level analysis of frequency, deviation and speed; and Stops Explorer for station-level study of delay, wait time, reliability and performance deficiencies such as bunching. To tackle overplotting and to provide a robust representation for a large numbers of trips and stops at multiple scales, the system supports variable kernel bandwidths to achieve the level of detail required by users for different tasks. We justify our design decisions based on specific analysis needs of transportation analysts. We provide anecdotal evidence of the efficacy of TR-EX through a series of case studies that explore NYC subway service, which illustrate how TR-EX can be used to confirm hypotheses and derive new insights through visual exploration.	Cesar Palomo;Zhan Guo;Cláudio T. Silva;Juliana Freire	;;;	10.1109/INFVIS.2004.68;10.1109/TVCG.2014.2346449;10.1109/TVCG.2007.70535;10.1109/TVCG.2011.176;10.1109/TVCG.2013.226;10.1109/VISUAL.1999.809866;10.1109/TVCG.2008.137;10.1109/TVCG.2009.131;10.1109/INFVIS.2005.1532138;10.1109/TVCG.2011.179;10.1109/TVCG.2006.170;10.1109/INFVIS.2003.1249005	Transportation, schedules, kernel density estimation, visual exploration	
VAST	2015	SensePath: Understanding the Sensemaking Process Through Analytic Provenance	10.1109/TVCG.2015.2467611	http://dx.doi.org/10.1109/TVCG.2015.2467611	41	50	J	Sensemaking is described as the process of comprehension, finding meaning and gaining insight from information, producing new knowledge and informing further action. Understanding the sensemaking process allows building effective visual analytics tools to make sense of large and complex datasets. Currently, it is often a manual and time-consuming undertaking to comprehend this: researchers collect observation data, transcribe screen capture videos and think-aloud recordings, identify recurring patterns, and eventually abstract the sensemaking process into a general model. In this paper, we propose a general approach to facilitate such a qualitative analysis process, and introduce a prototype, SensePath, to demonstrate the application of this approach with a focus on browser-based online sensemaking. The approach is based on a study of a number of qualitative research sessions including observations of users performing sensemaking tasks and post hoc analyses to uncover their sensemaking processes. Based on the study results and a follow-up participatory design session with HCI researchers, we decided to focus on the transcription and coding stages of thematic analysis. SensePath automatically captures user's sensemaking actions, i.e., analytic provenance, and provides multi-linked views to support their further analysis. A number of other requirements elicited from the design session are also implemented in SensePath, such as easy integration with existing qualitative analysis workflow and non-intrusive for participants. The tool was used by an experienced HCI researcher to analyze two sensemaking sessions. The researcher found the tool intuitive and considerably reduced analysis time, allowing better understanding of the sensemaking process.	Phong H. Nguyen;Kai Xu 0003;Ashley Wheat;B. L. William Wong;Simon Attfield;Bob Fields	;;;;;	10.1109/VISUAL.2005.1532788;10.1109/TVCG.2011.185;10.1109/TVCG.2014.2346575;10.1109/VAST.2008.4677365;10.1109/TVCG.2008.137;10.1109/VAST.2009.5333020;10.1109/TVCG.2013.132	Sensemaking, analytic provenance, transcription, coding, qualitative research, timeline visualization	
VAST	2015	Visual Analytics for Development and Evaluation of Order Selection Criteria for Autoregressive Processes	10.1109/TVCG.2015.2467612	http://dx.doi.org/10.1109/TVCG.2015.2467612	151	159	J	Order selection of autoregressive processes is an active research topic in time series analysis, and the development and evaluation of automatic order selection criteria remains a challenging task for domain experts. We propose a visual analytics approach, to guide the analysis and development of such criteria. A flexible synthetic model generator-combined with specialized responsive visualizations-allows comprehensive interactive evaluation. Our fast framework allows feedback-driven development and fine-tuning of new order selection criteria in real-time. We demonstrate the applicability of our approach in three use-cases for two general as well as a real-world example.	Thomas Löwe;Emmy-Charlotte Förster;Georgia Albuquerque;Jens-Peter Kreiss;Marcus A. Magnor	Comput. Graphics Lab., Tech. Univ. Braunschweig, Braunschweig, Germany|c|;;;;	10.1109/TVCG.2013.222	Visual analytics, time series analysis, order selection	
VAST	2015	A Case Study Using Visualization Interaction Logs and Insight Metrics to Understand How Analysts Arrive at Insights	10.1109/TVCG.2015.2467613	http://dx.doi.org/10.1109/TVCG.2015.2467613	51	60	J	We present results from an experiment aimed at using logs of interactions with a visual analytics application to better understand how interactions lead to insight generation. We performed an insight-based user study of a visual analytics application and ran post hoc quantitative analyses of participants' measured insight metrics and interaction logs. The quantitative analyses identified features of interaction that were correlated with insight characteristics, and we confirmed these findings using a qualitative analysis of video captured during the user study. Results of the experiment include design guidelines for the visual analytics application aimed at supporting insight generation. Furthermore, we demonstrated an analysis method using interaction logs that identified which interaction patterns led to insights, going beyond insight-based evaluations that only quantify insight characteristics. We also discuss choices and pitfalls encountered when applying this analysis method, such as the benefits and costs of applying an abstraction framework to application-specific actions before further analysis. Our method can be applied to evaluations of other visualization tools to inform the design of insight-promoting interactions and to better understand analyst behaviors.	Hua Guo;Steven R. Gomez;Caroline Ziemkiewicz;David H. Laidlaw	;;;	10.1109/INFVIS.2005.1532136;10.1109/TVCG.2014.2346575;10.1109/VAST.2014.7042482;10.1109/VAST.2008.4677365;10.1109/TVCG.2008.137;10.1109/VAST.2009.5333878;10.1109/TVCG.2014.2346452;10.1109/TVCG.2012.221;10.1109/TVCG.2007.70515	Evaluation, visual analytics, interaction, intelligence analysis, insight-based evaluation	
VAST	2015	InterAxis: Steering Scatterplot Axes via Observation-Level Interaction	10.1109/TVCG.2015.2467615	http://dx.doi.org/10.1109/TVCG.2015.2467615	131	140	J	Scatterplots are effective visualization techniques for multidimensional data that use two (or three) axes to visualize data items as a point at its corresponding x and y Cartesian coordinates. Typically, each axis is bound to a single data attribute. Interactive exploration occurs by changing the data attributes bound to each of these axes. In the case of using scatterplots to visualize the outputs of dimension reduction techniques, the x and y axes are combinations of the true, high-dimensional data. For these spatializations, the axes present usability challenges in terms of interpretability and interactivity. That is, understanding the axes and interacting with them to make adjustments can be challenging. In this paper, we present InterAxis, a visual analytics technique to properly interpret, define, and change an axis in a user-driven manner. Users are given the ability to define and modify axes by dragging data items to either side of the x or y axes, from which the system computes a linear combination of data attributes and binds it to the axis. Further, users can directly tune the positive and negative contribution to these complex axes by using the visualization of data attributes that correspond to each axis. We describe the details of our technique and demonstrate the intended usage through two scenarios.	Hannah Kim;Jaegul Choo;Haesun Park;Alex Endert	;;;	10.1109/TVCG.2011.185;10.1109/VAST.2012.6400486;10.1109/TVCG.2013.212;10.1109/VAST.2010.5652443;10.1109/TVCG.2011.201;10.1109/TVCG.2008.153;10.1109/VAST.2011.6102449;10.1109/TVCG.2013.157;10.1109/TVCG.2014.2346250;10.1109/VISUAL.1990.146386;10.1109/TVCG.2011.178;10.1109/TVCG.2013.167	Scatterplots, user interaction, model steering	
VAST	2015	Task-Driven Comparison of Topic Models	10.1109/TVCG.2015.2467618	http://dx.doi.org/10.1109/TVCG.2015.2467618	320	329	J	Topic modeling, a method of statistically extracting thematic content from a large collection of texts, is used for a wide variety of tasks within text analysis. Though there are a growing number of tools and techniques for exploring single models, comparisons between models are generally reduced to a small set of numerical metrics. These metrics may or may not reflect a model's performance on the analyst's intended task, and can therefore be insufficient to diagnose what causes differences between models. In this paper, we explore task-centric topic model comparison, considering how we can both provide detail for a more nuanced understanding of differences and address the wealth of tasks for which topic models are used. We derive comparison tasks from single-model uses of topic models, which predominantly fall into the categories of understanding topics, understanding similarity, and understanding change. Finally, we provide several visualization techniques that facilitate these tasks, including buddy plots, which combine color and position encodings to allow analysts to readily view changes in document similarity.	Eric C. Alexander;Michael Gleicher	Univ. of Wisconsin-Madison, Madison, WI, USA|c|;	10.1109/TVCG.2011.232;10.1109/VAST.2014.7042493;10.1109/TVCG.2013.212;10.1109/TVCG.2011.239;10.1109/TVCG.2012.260;10.1109/INFVIS.2000.885098;10.1109/TVCG.2014.2346578;10.1109/TVCG.2013.221	Text visualization, topic modeling	
VAST	2015	Interactive Visual Discovering of Movement Patterns from Sparsely Sampled Geo-tagged Social Media Data	10.1109/TVCG.2015.2467619	http://dx.doi.org/10.1109/TVCG.2015.2467619	270	279	J	Social media data with geotags can be used to track people's movements in their daily lives. By providing both rich text and movement information, visual analysis on social media data can be both interesting and challenging. In contrast to traditional movement data, the sparseness and irregularity of social media data increase the difficulty of extracting movement patterns. To facilitate the understanding of people's movements, we present an interactive visual analytics system to support the exploration of sparsely sampled trajectory data from social media. We propose a heuristic model to reduce the uncertainty caused by the nature of social media data. In the proposed system, users can filter and select reliable data from each derived movement category, based on the guidance of uncertainty model and interactive selection tools. By iteratively analyzing filtered movements, users can explore the semantics of movements, including the transportation methods, frequent visiting sequences and keyword descriptions. We provide two cases to demonstrate how our system can help users to explore the movement patterns.	Siming Chen;Xiaoru Yuan;Zhenhuang Wang;Cong Guo;Jie Liang;Zuchao Wang;Xiaolong Luke Zhang;Jiawan Zhang	;;;;;;;	10.1109/VAST.2009.5332584;10.1109/VAST.2008.4677356;10.1109/TVCG.2009.182;10.1109/TVCG.2011.185;10.1109/TVCG.2012.291;10.1109/TVCG.2009.143;10.1109/INFVIS.2004.27;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2012.265;10.1109/TVCG.2014.2346746;10.1109/TVCG.2014.2346922	Spatial temporal visual analytics, Geo-tagged social media, Sparsely sampling, Uncertainty, Movement	
VAST	2015	Interactive Visual Profiling of Musicians	10.1109/TVCG.2015.2467620	http://dx.doi.org/10.1109/TVCG.2015.2467620	200	209	J	Determining similar objects based upon the features of an object of interest is a common task for visual analytics systems. This process is called profiling, if the object of interest is a person with individual attributes. The profiling of musicians similar to a musician of interest with the aid of visual means became an interesting research question for musicologists working with the Bavarian Musicians Encyclopedia Online. This paper illustrates the development of a visual analytics profiling system that is used to address such research questions. Taking musicological knowledge into account, we outline various steps of our collaborative digital humanities project, priority (1) the definition of various measures to determine the similarity of musicians' attributes, and (2) the design of an interactive profiling system that supports musicologists in iteratively determining similar musicians. The utility of the profiling system is emphasized by various usage scenarios illustrating current research questions in musicology.	Stefan Jänicke;Josef Focht;Gerik Scheuermann	Image & Signal Process. Group, Leipzig Univ., Leipzig, Germany|c|;;	10.1109/VAST.2011.6102454;10.1109/TVCG.2010.159;10.1109/TVCG.2014.2346431;10.1109/TVCG.2007.70617;10.1109/VAST.2009.5333443;10.1109/TVCG.2014.2346433;10.1109/TVCG.2008.175;10.1109/TVCG.2012.252;10.1109/VAST.2012.6400485;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2012.277;10.1109/VAST.2012.6400491;10.1109/VAST.2007.4389004;10.1109/TVCG.2014.2346677;10.1109/TVCG.2009.111;10.1109/TVCG.2006.122;10.1109/VAST.2010.5652931;10.1109/VAST.2009.5333023;10.1109/VAST.2007.4389006;10.1109/VAST.2009.5333248;10.1109/VAST.2008.4677370;10.1109/VAST.2010.5652520	visual analytics, profiling system, musicians database visualization, digital humanities, musicology	
VAST	2015	CiteRivers: Visual Analytics of Citation Patterns	10.1109/TVCG.2015.2467621	http://dx.doi.org/10.1109/TVCG.2015.2467621	190	199	J	The exploration and analysis of scientific literature collections is an important task for effective knowledge management. Past interest in such document sets has spurred the development of numerous visualization approaches for their interactive analysis. They either focus on the textual content of publications, or on document metadata including authors and citations. Previously presented approaches for citation analysis aim primarily at the visualization of the structure of citation networks and their exploration. We extend the state-of-the-art by presenting an approach for the interactive visual analysis of the contents of scientific documents, and combine it with a new and flexible technique to analyze their citations. This technique facilitates user-steered aggregation of citations which are linked to the content of the citing publications using a highly interactive visualization approach. Through enriching the approach with additional interactive views of other important aspects of the data, we support the exploration of the dataset over time and enable users to analyze citation patterns, spot trends, and track long-term developments. We demonstrate the strengths of our approach through a use case and discuss it based on expert user feedback.	Florian Heimerl;Qi Han;Steffen Koch;Thomas Ertl	;;	10.1109/INFVIS.2004.77;10.1109/TVCG.2015.2467757;10.1109/TVCG.2008.166;10.1109/TVCG.2013.212;10.1109/VAST.2009.5333443;10.1109/TVCG.2011.239;10.1109/TVCG.2012.252;10.1109/TVCG.2013.162;10.1109/TVCG.2012.277;10.1109/INFVIS.2004.45;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2009.162;10.1109/TVCG.2009.171;10.1109/INFVIS.2005.1532122;10.1109/INFVIS.1995.528686;10.1109/TVCG.2014.2346920;10.1109/TVCG.2009.202	scientific literature, visual document analysis, visual citation analysis, streamgraph, clustering	
VAST	2015	Supporting Iterative Cohort Construction with Visual Temporal Queries	10.1109/TVCG.2015.2467622	http://dx.doi.org/10.1109/TVCG.2015.2467622	91	100	J	Many researchers across diverse disciplines aim to analyze the behavior of cohorts whose behaviors are recorded in large event databases. However, extracting cohorts from databases is a difficult yet important step, often overlooked in many analytical solutions. This is especially true when researchers wish to restrict their cohorts to exhibit a particular temporal pattern of interest. In order to fill this gap, we designed COQUITO, a visual interface that assists users defining cohorts with temporal constraints. COQUITO was designed to be comprehensible to domain experts with no preknowledge of database queries and also to encourage exploration. We then demonstrate the utility of COQUITO via two case studies, involving medical and social media researchers.	Josua Krause;Adam Perer;Harry Stavropoulos	;;	10.1109/TVCG.2011.185;10.1109/VAST.2007.4389013;10.1109/VAST.2006.261421;10.1109/TVCG.2014.2346682;10.1109/VAST.2010.5652890;10.1109/TVCG.2014.2346482;10.1109/TVCG.2013.200;10.1109/TVCG.2013.206;10.1109/TVCG.2009.117;10.1109/INFVIS.2001.963273;10.1109/TVCG.2012.225;10.1109/TVCG.2013.167	Visual temporal queries, cohort definition, electronic medical records, information visualization	
VAST	2015	PhenoBlocks: Phenotype Comparison Visualizations	10.1109/TVCG.2015.2467733	http://dx.doi.org/10.1109/TVCG.2015.2467733	101	110	J	The differential diagnosis of hereditary disorders is a challenging task for clinicians due to the heterogeneity of phenotypes that can be observed in patients. Existing clinical tools are often text-based and do not emphasize consistency, completeness, or granularity of phenotype reporting. This can impede clinical diagnosis and limit their utility to genetics researchers. Herein, we present PhenoBlocks, a novel visual analytics tool that supports the comparison of phenotypes between patients, or between a patient and the hallmark features of a disorder. An informal evaluation of PhenoBlocks with expert clinicians suggested that the visualization effectively guides the process of differential diagnosis and could reinforce the importance of complete, granular phenotypic reporting.	Michael Glueck;Peter Hamilton;Fanny Chevalier;Simon Breslav;Azam Khan;Daniel J. Wigdor;Michael Brudno	;;;;;;	10.1109/VAST.2011.6102439;10.1109/TVCG.2013.214;10.1109/TVCG.2013.231;10.1109/VAST.2011.6102438;10.1109/TVCG.2008.121;10.1109/TVCG.2009.167;10.1109/TVCG.2009.116;10.1109/INFVIS.2000.885091;10.1109/TVCG.2007.70529;10.1109/INFVIS.2003.1249030;10.1109/TVCG.2012.226	Clinical diagnosis, differential hierarchy comparison, ontology, genomics, phenomics, phenotype	
VAST	2015	Visual Analysis and Dissemination of Scientific Literature Collections with SurVis	10.1109/TVCG.2015.2467757	http://dx.doi.org/10.1109/TVCG.2015.2467757	180	189	J	Bibliographic data such as collections of scientific articles and citation networks have been studied extensively in information visualization and visual analytics research. Powerful systems have been built to support various types of bibliographic analysis, but they require some training and cannot be used to disseminate the insights gained. In contrast, we focused on developing a more accessible visual analytics system, called SurVis, that is ready to disseminate a carefully surveyed literature collection. The authors of a survey may use our Web-based system to structure and analyze their literature database. Later, readers of the survey can obtain an overview, quickly retrieve specific publications, and reproduce or extend the original bibliographic analysis. Our system employs a set of selectors that enable users to filter and browse the literature collection as well as to control interactive visualizations. The versatile selector concept includes selectors for textual search, filtering by keywords and meta-information, selection and clustering of similar publications, and following citation links. Agreement to the selector is represented by word-sized sparkline visualizations seamlessly integrated into the user interface. Based on an analysis of the analytical reasoning process, we derived requirements for the system. We developed the system in a formative way involving other researchers writing literature surveys. A questionnaire study with 14 visual analytics experts confirms that SurVis meets the initially formulated requirements.	Fabian Beck;Sebastian Koch;Daniel Weiskopf	VISUS, Univ. of Stuttgart, Stuttgart, Germany|c|;;	10.1109/TVCG.2011.169;10.1109/TVCG.2012.252;10.1109/TVCG.2015.2467621;10.1109/VAST.2009.5333564;10.1109/TVCG.2010.194;10.1109/VAST.2007.4389006;10.1109/TVCG.2013.167	Visual analytics of documents, bibliographic data, dissemination, literature browser	
VAST	2015	TrajGraph: A Graph-Based Visual Analytics Approach to Studying Urban Network Centralities Using Taxi Trajectory Data	10.1109/TVCG.2015.2467771	http://dx.doi.org/10.1109/TVCG.2015.2467771	160	169	J	We propose TrajGraph, a new visual analytics method, for studying urban mobility patterns by integrating graph modeling and visual analysis with taxi trajectory data. A special graph is created to store and manifest real traffic information recorded by taxi trajectories over city streets. It conveys urban transportation dynamics which can be discovered by applying graph analysis algorithms. To support interactive, multiscale visual analytics, a graph partitioning algorithm is applied to create region-level graphs which have smaller size than the original street-level graph. Graph centralities, including Pagerank and betweenness, are computed to characterize the time-varying importance of different urban regions. The centralities are visualized by three coordinated views including a node-link graph view, a map view and a temporal information view. Users can interactively examine the importance of streets to discover and assess city traffic patterns. We have implemented a fully working prototype of this approach and evaluated it using massive taxi trajectories of Shenzhen, China. TrajGraph's capability in revealing the importance of city streets was evaluated by comparing the calculated centralities with the subjective evaluations from a group of drivers in Shenzhen. Feedback from a domain expert was collected. The effectiveness of the visual interface was evaluated through a formal user study. We also present several examples and a case study to demonstrate the usefulness of TrajGraph in urban transportation analysis.	Xiaoke Huang;Ye Zhao;Chao Ma;Jing Yang;Xinyue Ye;Chong Zhang	;;;;;	10.1109/VAST.2009.5332593;10.1109/TVCG.2013.226;10.1109/TVCG.2009.145;10.1109/VAST.2011.6102455;10.1109/TVCG.2006.122;10.1109/TVCG.2012.265;10.1109/TVCG.2013.228;10.1109/TVCG.2014.2346746	Graph based visual analytics, Centrality, Taxi trajectories, Urban network, Transportation assessment	
VAST	2015	BiSet: Semantic Edge Bundling with Biclusters for Sensemaking	10.1109/TVCG.2015.2467813	http://dx.doi.org/10.1109/TVCG.2015.2467813	310	319	J	Identifying coordinated relationships is an important task in data analytics. For example, an intelligence analyst might want to discover three suspicious people who all visited the same four cities. Existing techniques that display individual relationships, such as between lists of entities, require repetitious manual selection and significant mental aggregation in cluttered visualizations to find coordinated relationships. In this paper, we present BiSet, a visual analytics technique to support interactive exploration of coordinated relationships. In BiSet, we model coordinated relationships as biclusters and algorithmically mine them from a dataset. Then, we visualize the biclusters in context as bundled edges between sets of related entities. Thus, bundles enable analysts to infer task-oriented semantic insights about potentially coordinated activities. We make bundles as first class objects and add a new layer, ΓÇ£in-betweenΓÇ¥, to contain these bundle objects. Based on this, bundles serve to organize entities represented in lists and visually reveal their membership. Users can interact with edge bundles to organize related entities, and vice versa, for sensemaking purposes. With a usage scenario, we demonstrate how BiSet supports the exploration of coordinated relationships in text analytics.	Maoyuan Sun;Peng Mi;Chris North;Naren Ramakrishnan	;;;	10.1109/TVCG.2007.70521;10.1109/TVCG.2009.122;10.1109/TVCG.2008.135;10.1109/TVCG.2012.252;10.1109/TVCG.2012.260;10.1109/INFVIS.2004.1;10.1109/TVCG.2014.2346260;10.1109/TVCG.2007.70582;10.1109/TVCG.2006.147;10.1109/TVCG.2011.233;10.1109/VAST.2009.5333878;10.1109/TVCG.2011.250;10.1109/TVCG.2010.138;10.1109/TVCG.2014.2346752;10.1109/TVCG.2010.210;10.1109/TVCG.2011.183;10.1109/TVCG.2014.2346665	Bicluster, coordinated relationship, semantic edge bundling	
VAST	2015	VA2: A Visual Analytics Approach for Evaluating Visual Analytics Applications	10.1109/TVCG.2015.2467871	http://dx.doi.org/10.1109/TVCG.2015.2467871	61	70	J	Evaluation has become a fundamental part of visualization research and researchers have employed many approaches from the field of human-computer interaction like measures of task performance, thinking aloud protocols, and analysis of interaction logs. Recently, eye tracking has also become popular to analyze visual strategies of users in this context. This has added another modality and more data, which requires special visualization techniques to analyze this data. However, only few approaches exist that aim at an integrated analysis of multiple concurrent evaluation procedures. The variety, complexity, and sheer amount of such coupled multi-source data streams require a visual analytics approach. Our approach provides a highly interactive visualization environment to display and analyze thinking aloud, interaction, and eye movement data in close relation. Automatic pattern finding algorithms allow an efficient exploratory search and support the reasoning process to derive common eye-interaction-thinking patterns between participants. In addition, our tool equips researchers with mechanisms for searching and verifying expected usage patterns. We apply our approach to a user study involving a visual analytics application and we discuss insights gained from this joint analysis. We anticipate our approach to be applicable to other combinations of evaluation techniques and a broad class of visualization applications.	Tanja Blascheck;Markus John;Kuno Kurzhals;Steffen Koch;Thomas Ertl	Inst. for Visualization & Interactive Syst., Univ. of Stuttgart, Stuttgart, Germany|c|;;;;	10.1109/TVCG.2012.276;10.1109/TVCG.2013.124;10.1109/VAST.2008.4677361;10.1109/VAST.2009.5333878;10.1109/TVCG.2014.2346677;10.1109/VAST.2010.5653598;10.1109/TVCG.2012.273;10.1109/VISUAL.2005.1532837	visual analytics, qualitative evaluation, thinking aloud, interaction logs, eye tracking, time series data	
VAST	2015	The Visual Causality Analyst: An Interactive Interface for Causal Reasoning	10.1109/TVCG.2015.2467931	http://dx.doi.org/10.1109/TVCG.2015.2467931	230	239	J	Uncovering the causal relations that exist among variables in multivariate datasets is one of the ultimate goals in data analytics. Causation is related to correlation but correlation does not imply causation. While a number of casual discovery algorithms have been devised that eliminate spurious correlations from a network, there are no guarantees that all of the inferred causations are indeed true. Hence, bringing a domain expert into the casual reasoning loop can be of great benefit in identifying erroneous casual relationships suggested by the discovery algorithm. To address this need we present the Visual Causal Analyst - a novel visual causal reasoning framework that allows users to apply their expertise, verify and edit causal links, and collaborate with the causal discovery algorithm to identify a valid causal network. Its interface consists of both an interactive 2D graph view and a numerical presentation of salient statistical parameters, such as regression coefficients, p-values, and others. Both help users in gaining a good understanding of the landscape of causal structures particularly when the number of variables is large. Our framework is also novel in that it can handle both numerical and categorical variables within one unified model and return plausible results. We demonstrate its use via a set of case studies using multiple practical datasets.	Jun Wang;Klaus Mueller	Comput. Sci. Dept., Stony Brook Univ., Stony Brook, NY, USA|c|;	10.1109/INFVIS.2003.1249025;10.1109/TVCG.2007.70528;10.1109/TVCG.2012.225;10.1109/VAST.2007.4388999	Visual knowledge discovery, Causality, Hypothesis testing, Visual evidence, High-dimensional data	
VAST	2015	VEEVVIE: Visual Explorer for Empirical Visualization, VR and Interaction Experiments	10.1109/TVCG.2015.2467954	http://dx.doi.org/10.1109/TVCG.2015.2467954	111	120	J	Empirical, hypothesis-driven, experimentation is at the heart of the scientific discovery process and has become commonplace in human-factors related fields. To enable the integration of visual analytics in such experiments, we introduce VEEVVIE, the Visual Explorer for Empirical Visualization, VR and Interaction Experiments. VEEVVIE is comprised of a back-end ontology which can model several experimental designs encountered in these fields. This formalization allows VEEVVIE to capture experimental data in a query-able form and makes it accessible through a front-end interface. This front-end offers several multi-dimensional visualization widgets with built-in filtering and highlighting functionality. VEEVVIE is also expandable to support custom experimental measurements and data types through a plug-in visualization widget architecture. We demonstrate VEEVVIE through several case studies of visual analysis, performed on the design and data collected during an experiment on the scalability of high-resolution, immersive, tiled-display walls.	Charilaos Papadopoulos;Ievgeniia Gutenko;Arie E. Kaufman	Dept. of Comput. Sci., Stony Brook Univ., Stony Brook, NY, USA|c|;;	10.1109/TVCG.2012.276;10.1109/TVCG.2012.251;10.1109/TVCG.2014.2346591;10.1109/TVCG.2010.157;10.1109/TVCG.2014.2346311;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2004.12	Visual Analytics, Evaluation, User Studies, Ontology, Experiments, Interaction, Virtual Reality, Visualization	
VAST	2015	VAiRoma: A Visual Analytics System for Making Sense of Places, Times, and Events in Roman History	10.1109/TVCG.2015.2467971	http://dx.doi.org/10.1109/TVCG.2015.2467971	210	219	J	Learning and gaining knowledge of Roman history is an area of interest for students and citizens at large. This is an example of a subject with great sweep (with many interrelated sub-topics over, in this case, a 3,000 year history) that is hard to grasp by any individual and, in its full detail, is not available as a coherent story. In this paper, we propose a visual analytics approach to construct a data driven view of Roman history based on a large collection of Wikipedia articles. Extracting and enabling the discovery of useful knowledge on events, places, times, and their connections from large amounts of textual data has always been a challenging task. To this aim, we introduce VAiRoma, a visual analytics system that couples state-of-the-art text analysis methods with an intuitive visual interface to help users make sense of events, places, times, and more importantly, the relationships between them. VAiRoma goes beyond textual content exploration, as it permits users to compare, make connections, and externalize the findings all within the visual interface. As a result, VAiRoma allows users to learn and create new knowledge regarding Roman history in an informed way. We evaluated VAiRoma with 16 participants through a user study, with the task being to learn about roman piazzas through finding relevant articles and new relationships. Our study results showed that the VAiRoma system enables the participants to find more relevant articles and connections compared to Web searches and literature search conducted in a roman library. Subjective feedback on VAiRoma was also very positive. In addition, we ran two case studies that demonstrate how VAiRoma can be used for deeper analysis, permitting the rapid discovery and analysis of a small number of key documents even when the original collection contains hundreds of thousands of documents.	Isaac Cho;Wenwen Dou;Xiaoyu Wang;Eric Sauda;William Ribarsky	;;;;	10.1109/VAST.2014.7042493;10.1109/VAST.2007.4389012;10.1109/TVCG.2014.2346431;10.1109/TVCG.2007.70617;10.1109/TVCG.2008.178;10.1109/VAST.2010.5652885;10.1109/TVCG.2011.239;10.1109/VAST.2012.6400485;10.1109/TVCG.2013.162;10.1109/INFVIS.2000.885098;10.1109/TVCG.2011.179;10.1109/TVCG.2014.2346481;10.1109/INFVIS.2000.885091	Visual Analytics, Text Analytics, Wikipedia	
VAST	2015	Exploring Evolving Media Discourse Through Event Cueing	10.1109/TVCG.2015.2467991	http://dx.doi.org/10.1109/TVCG.2015.2467991	220	229	J	Online news, microblogs and other media documents all contain valuable insight regarding events and responses to events. Underlying these documents is the concept of framing, a process in which communicators act (consciously or unconsciously) to construct a point of view that encourages facts to be interpreted by others in a particular manner. As media discourse evolves, how topics and documents are framed can undergo change, shifting the discussion to different viewpoints or rhetoric. What causes these shifts can be difficult to determine directly; however, by linking secondary datasets and enabling visual exploration, we can enhance the hypothesis generation process. In this paper, we present a visual analytics framework for event cueing using media data. As discourse develops over time, our framework applies a time series intervention model which tests to see if the level of framing is different before or after a given date. If the model indicates that the times before and after are statistically significantly different, this cues an analyst to explore related datasets to help enhance their understanding of what (if any) events may have triggered these changes in discourse. Our framework consists of entity extraction and sentiment analysis as lenses for data exploration and uses two different models for intervention analysis. To demonstrate the usage of our framework, we present a case study on exploring potential relationships between climate change framing and conflicts in Africa.	Yafeng Lu;Michael Steptoe;Sarah Burke;Hong Wang;Jiun-Yi Tsai;Hasan Davulcu;Douglas Montgomery;Steven R. Corman;Ross Maciejewski	;;;;;;;;	10.1109/TVCG.2013.222;10.1109/VAST.2011.6102488;10.1109/VAST.2012.6400557;10.1109/VAST.2012.6400485;10.1109/TVCG.2013.162;10.1109/VAST.2008.4677364;10.1109/TVCG.2014.2346682;10.1109/VAST.2014.7042484;10.1109/TVCG.2011.179;10.1109/VAST.2014.7042494;10.1109/VAST.2012.6400491;10.1109/VAST.2009.5333919;10.1109/INFVIS.1999.801851;10.1109/TVCG.2012.225;10.1109/TVCG.2014.2346913	Media Analysis, Time Series Analysis, Event Detection	
VAST	2015	LiteVis: Integrated Visualization for Simulation-Based Decision Support in Lighting Design	10.1109/TVCG.2015.2468011	http://dx.doi.org/10.1109/TVCG.2015.2468011	290	299	J	State-of-the-art lighting design is based on physically accurate lighting simulations of scenes such as offices. The simulation results support lighting designers in the creation of lighting configurations, which must meet contradicting customer objectives regarding quality and price while conforming to industry standards. However, current tools for lighting design impede rapid feedback cycles. On the one side, they decouple analysis and simulation specification. On the other side, they lack capabilities for a detailed comparison of multiple configurations. The primary contribution of this paper is a design study of LiteVis, a system for efficient decision support in lighting design. LiteVis tightly integrates global illumination-based lighting simulation, a spatial representation of the scene, and non-spatial visualizations of parameters and result indicators. This enables an efficient iterative cycle of simulation parametrization and analysis. Specifically, a novel visualization supports decision making by ranking simulated lighting configurations with regard to a weight-based prioritization of objectives that considers both spatial and non-spatial characteristics. In the spatial domain, novel concepts support a detailed comparison of illumination scenarios. We demonstrate LiteVis using a real-world use case and report qualitative feedback of lighting designers. This feedback indicates that LiteVis successfully supports lighting designers to achieve key tasks more efficiently and with greater certainty.	Johannes Sorger;Thomas Ortner;Christian Luksch;Michael Schwärzler;Eduard Gröller;Harald Piringer	;;;;;	10.1109/TVCG.2014.2346626;10.1109/TVCG.2011.185;10.1109/TVCG.2010.190;10.1109/TVCG.2013.147;10.1109/INFVIS.2003.1249032;10.1109/TVCG.2013.173;10.1109/TVCG.2009.110;10.1109/TVCG.2014.2346321	Integrating Spatial and Non-Spatial Data Visualization, Visualization in Physical Sciences and Engineering, Coordinated and Multiple Views, Visual Knowledge Discovery	
VAST	2015	Reducing Snapshots to Points: A Visual Analytics Approach to Dynamic Network Exploration	10.1109/TVCG.2015.2468078	http://dx.doi.org/10.1109/TVCG.2015.2468078	1	10	J	We propose a visual analytics approach for the exploration and analysis of dynamic networks. We consider snapshots of the network as points in high-dimensional space and project these to two dimensions for visualization and interaction using two juxtaposed views: one for showing a snapshot and one for showing the evolution of the network. With this approach users are enabled to detect stable states, recurring states, outlier topologies, and gain knowledge about the transitions between states and the network evolution in general. The components of our approach are discretization, vectorization and normalization, dimensionality reduction, and visualization and interaction, which are discussed in detail. The effectiveness of the approach is shown by applying it to artificial and real-world dynamic networks.	Stef van den Elzen;Danny Holten;Jorik Blaas;Jarke J. van Wijk	;;;	10.1109/TVCG.2011.226;10.1109/INFVIS.2004.18;10.1109/TVCG.2013.198;10.1109/TVCG.2006.147;10.1109/TVCG.2006.193;10.1109/TVCG.2008.125;10.1109/TVCG.2011.178;10.1109/INFVIS.1999.801851	Dynamic Networks, Exploration, Dimensionality Reduction	
VAST	2015	MobilityGraphs: Visual Analysis of Mass Mobility Dynamics via Spatio-Temporal Graphs and Clustering	10.1109/TVCG.2015.2468111	http://dx.doi.org/10.1109/TVCG.2015.2468111	11	20	J	Learning more about people mobility is an important task for official decision makers and urban planners. Mobility data sets characterize the variation of the presence of people in different places over time as well as movements (or flows) of people between the places. The analysis of mobility data is challenging due to the need to analyze and compare spatial situations (i.e., presence and flows of people at certain time moments) and to gain an understanding of the spatio-temporal changes (variations of situations over time). Traditional flow visualizations usually fail due to massive clutter. Modern approaches offer limited support for investigating the complex variation of the movements over longer time periods. We propose a visual analytics methodology that solves these issues by combined spatial and temporal simplifications. We have developed a graph-based method, called MobilityGraphs, which reveals movement patterns that were occluded in flow maps. Our method enables the visual representation of the spatio-temporal variation of movements for long time series of spatial situations originally containing a large number of intersecting flows. The interactive system supports data exploration from various perspectives and at various levels of detail by interactive setting of clustering parameters. The feasibility our approach was tested on aggregated mobility data derived from a set of geolocated Twitter posts within the Greater London city area and mobile phone call data records in Abidjan, Ivory Coast. We could show that MobilityGraphs support the identification of regular daily and weekly movement patterns of resident population.	Tatiana von Landesberger;Felix Brodkorb;Philipp Roskosch;Natalia V. Andrienko;Gennady L. Andrienko;Andreas Kerren	Tech. Univ. of Darmstadt, Darmstadt, Germany|c|;;;;;	10.1109/TVCG.2011.202;10.1109/TVCG.2011.226;10.1109/TVCG.2011.233;10.1109/INFVIS.2004.18;10.1109/TVCG.2009.143;10.1109/TVCG.2014.2346271;10.1109/TVCG.2008.125;10.1109/TVCG.2014.2346441;10.1109/INFVIS.1999.801851;10.1109/VAST.2012.6400553;10.1109/VAST.2009.5333893;10.1109/INFVIS.2005.1532150	Visual analytics, movement data, networks, graphs, temporal aggregation, spatial aggregation, flows, clustering	
VAST	2015	egoSlider: Visual Analysis of Egocentric Network Evolution	10.1109/TVCG.2015.2468151	http://dx.doi.org/10.1109/TVCG.2015.2468151	260	269	J	Ego-network, which represents relationships between a specific individual, i.e., the ego, and people connected to it, i.e., alters, is a critical target to study in social network analysis. Evolutionary patterns of ego-networks along time provide huge insights to many domains such as sociology, anthropology, and psychology. However, the analysis of dynamic ego-networks remains challenging due to its complicated time-varying graph structures, for example: alters come and leave, ties grow stronger and fade away, and alter communities merge and split. Most of the existing dynamic graph visualization techniques mainly focus on topological changes of the entire network, which is not adequate for egocentric analytical tasks. In this paper, we present egoSlider, a visual analysis system for exploring and comparing dynamic ego-networks. egoSlider provides a holistic picture of the data through multiple interactively coordinated views, revealing ego-network evolutionary patterns at three different layers: a macroscopic level for summarizing the entire ego-network data, a mesoscopic level for overviewing specific individuals' ego-network evolutions, and a microscopic level for displaying detailed temporal information of egos and their alters. We demonstrate the effectiveness of egoSlider with a usage scenario with the DBLP publication records. Also, a controlled user study indicates that in general egoSlider outperforms a baseline visualization of dynamic networks for completing egocentric analytical tasks.	Yanhong Wu;Naveen Pitipornvivat;Jian Zhao;Sixiao Yang;Guowei Huang;Huamin Qu	Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;;;;	10.1109/TVCG.2011.169;10.1109/TVCG.2011.226;10.1109/TVCG.2006.147;10.1109/TVCG.2013.149	Egocentric network, dynamic graph, network visualization, glyph-based design, visual analytics	
VAST	2015	3D Regression Heat Map Analysis of Population Study Data	10.1109/TVCG.2015.2468291	http://dx.doi.org/10.1109/TVCG.2015.2468291	81	90	J	Epidemiological studies comprise heterogeneous data about a subject group to define disease-specific risk factors. These data contain information (features) about a subject's lifestyle, medical status as well as medical image data. Statistical regression analysis is used to evaluate these features and to identify feature combinations indicating a disease (the target feature). We propose an analysis approach of epidemiological data sets by incorporating all features in an exhaustive regression-based analysis. This approach combines all independent features w.r.t. a target feature. It provides a visualization that reveals insights into the data by highlighting relationships. The 3D Regression Heat Map, a novel 3D visual encoding, acts as an overview of the whole data set. It shows all combinations of two to three independent features with a specific target disease. Slicing through the 3D Regression Heat Map allows for the detailed analysis of the underlying relationships. Expert knowledge about disease-specific hypotheses can be included into the analysis by adjusting the regression model formulas. Furthermore, the influences of features can be assessed using a difference view comparing different calculation results. We applied our 3D Regression Heat Map method to a hepatic steatosis data set to reproduce results from a data mining-driven analysis. A qualitative analysis was conducted on a breast density data set. We were able to derive new hypotheses about relations between breast density and breast lesions with breast cancer. With the 3D Regression Heat Map, we present a visual overview of epidemiological data that allows for the first time an interactive regression-based analysis of large feature sets with respect to a disease.	Paul Klemm;Kai Lawonn;Sylvia Glaßer;Uli Niemann;Katrin Hegenscheid;Henry Völzke;Bernhard Preim	Otto-von-Guericke Univ. Magdeburg, Magdeburg, Germany	10.1109/TVCG.2011.229;10.1109/TVCG.2011.185;10.1109/VAST.2009.5333431;10.1109/TVCG.2013.160;10.1109/TVCG.2014.2346591;10.1109/TVCG.2013.161;10.1109/TVCG.2013.125;10.1109/TVCG.2014.2346321	Interactive Visual Analysis, Regression Analysis, Heat Map, Epidemiology, Breast Cancer, Hepatic Steatosis	
VAST	2015	MotionFlow: Visual Abstraction and Aggregation of Sequential Patterns in Human Motion Tracking Data	10.1109/TVCG.2015.2468292	http://dx.doi.org/10.1109/TVCG.2015.2468292	21	30	J	Pattern analysis of human motions, which is useful in many research areas, requires understanding and comparison of different styles of motion patterns. However, working with human motion tracking data to support such analysis poses great challenges. In this paper, we propose MotionFlow, a visual analytics system that provides an effective overview of various motion patterns based on an interactive flow visualization. This visualization formulates a motion sequence as transitions between static poses, and aggregates these sequences into a tree diagram to construct a set of motion patterns. The system also allows the users to directly reflect the context of data and their perception of pose similarities in generating representative pose states. We provide local and global controls over the partition-based clustering process. To support the users in organizing unstructured motion data into pattern groups, we designed a set of interactions that enables searching for similar motion sequences from the data, detailed exploration of data subsets, and creating and modifying the group of motion patterns. To evaluate the usability of MotionFlow, we conducted a user study with six researchers with expertise in gesture-based interaction design. They used MotionFlow to explore and organize unstructured motion tracking data. Results show that the researchers were able to easily learn how to use MotionFlow, and the system effectively supported their pattern analysis activities, including leveraging their perception and domain knowledge.	Sujin Jang;Niklas Elmqvist;Karthik Ramani	Purdue Univ. in West LafayetteWest Lafayette, West Lafayette, IN, USA|c|;;	10.1109/TVCG.2013.178;10.1109/TVCG.2009.181;10.1109/TVCG.2011.239;10.1109/TVCG.2014.2346682;10.1109/TVCG.2012.258;10.1109/TVCG.2013.196;10.1109/TVCG.2013.200;10.1109/TVCG.2006.192;10.1109/INFVIS.2005.1532152;10.1109/TVCG.2013.181;10.1109/TVCG.2010.149;10.1109/VISUAL.2002.1183778;10.1109/TVCG.2008.172;10.1109/TVCG.2012.225;10.1109/TVCG.2014.2346920	Human motion visualization, interactive clustering, motion tracking data, expert reviews, user study	
VAST	2015	Wavelet-based visualization of time-varying data on graphs	10.1109/VAST.2015.7347624	http://dx.doi.org/10.1109/VAST.2015.7347624	1	8	C	Visualizing time-varying data defined on the nodes of a graph is a challenging problem that has been faced with different approaches. Although techniques based on aggregation, topology, and topic modeling have proven their usefulness, the visual analysis of smooth and/or abrupt data variations as well as the evolution of such variations over time are aspects not properly tackled by existing methods. In this work we propose a novel visualization methodology that relies on graph wavelet theory and stacked graph metaphor to enable the visual analysis of time-varying data defined on the nodes of a graph. The proposed method is able to identify regions where data presents abrupt and mild spacial and/or temporal variation while still been able to show how such changes evolve over time, making the identification of events an easier task. The usefulness of our approach is shown through a set of results using synthetic as well as a real data set involving taxi trips in downtown Manhattan. The methodology was able to reveal interesting phenomena and events such as the identification of specific locations with abrupt variation in the number of taxi pickups.	Paola Valdivia;Fabio Dias;Fabiano Petronetto;Cláudio T. Silva;Luis Gustavo Nonato	;;;;	10.1109/VAST.2008.4677356;10.1109/TVCG.2014.2346449;10.1109/TVCG.2013.226;10.1109/INFVIS.2000.885098;10.1109/TVCG.2013.228	Time-varying data, graph wavelets, stacked graph visualization	
VAST	2015	Mixed-initiative visual analytics using task-driven recommendations	10.1109/VAST.2015.7347625	http://dx.doi.org/10.1109/VAST.2015.7347625	9	16	C	Visual data analysis is composed of a collection of cognitive actions and tasks to decompose, internalize, and recombine data to produce knowledge and insight. Visual analytic tools provide interactive visual interfaces to data to support discovery and sensemaking tasks, including forming hypotheses, asking questions, and evaluating and organizing evidence. Myriad analytic models can be incorporated into visual analytic systems at the cost of increasing complexity in the analytic discourse between user and system. Techniques exist to increase the usability of interacting with analytic models, such as inferring data models from user interactions to steer the underlying models of the system via semantic interaction, shielding users from having to do so explicitly. Such approaches are often also referred to as mixed-initiative systems. Sensemaking researchers have called for development of tools that facilitate analytic sensemaking through a combination of human and automated activities. However, design guidelines do not exist for mixed-initiative visual analytic systems to support iterative sensemaking. In this paper, we present candidate design guidelines and introduce the Active Data Environment (ADE) prototype, a spatial workspace supporting the analytic process via task recommendations invoked by inferences about user interactions within the workspace. ADE recommends data and relationships based on a task model, enabling users to co-reason with the system about their data in a single, spatial workspace. This paper provides an illustrative use case, a technical description of ADE, and a discussion of the strengths and limitations of the approach.	Kristin A. Cook;Nick Cramer;David Israel;Michael Wolverton;Joe Bruce;Russ Burtner;Alex Endert	Pacific Northwest Nat. Lab., Richland, WA, USA|c|;;;;;;	10.1109/VAST.2012.6400486;10.1109/VAST.2011.6102438;10.1109/VAST.2012.6400559;10.1109/TVCG.2014.2346573;10.1109/VAST.2014.7042492;10.1109/TVCG.2008.174;10.1109/TVCG.2013.225	mixed-initiative visual analytics, task modeling, recommender systems, sensemaking	
VAST	2015	Integrating predictive analytics into a spatiotemporal epidemic simulation	10.1109/VAST.2015.7347626	http://dx.doi.org/10.1109/VAST.2015.7347626	17	24	C	The Epidemic Simulation System (EpiSimS) is a scalable, complex modeling tool for analyzing disease within the United States. Due to its high input dimensionality, time requirements, and resource constraints, simulating over the entire parameter space is unfeasible. One solution is to take a granular sampling of the input space and use simpler predictive models (emulators) in between. The quality of the implemented emulator depends on many factors: robustness, sophistication, configuration, and suitability to the input data. Visual analytics can be leveraged to provide guidance and understanding of these things to the user. In this paper, we have implemented a novel interface and workflow for emulator building and use. We introduce a workflow to build emulators, make predictions, and then analyze the results. Our prediction process first predicts temporal time series, and uses these to derive predicted spatial densities. Integrated into the EpiSimS framework, we target users who are non-experts at statistical modeling. This approach allows for a high level of analysis into the state of the built emulators and their resultant predictions. We present our workflow, models, the associated system, and evaluate the overall utility with feedback from EpiSimS scientists.	Chris Bryan;Xue Wu;Susan M. Mniszewski;Kwan-Liu Ma	VIDi @ U.C. Davis, Davis, CA, USA|c|;;;	10.1109/VAST.2011.6102457;10.1109/INFVIS.1998.729563;10.1109/TVCG.2014.2346926;10.1109/TVCG.2013.125;10.1109/TVCG.2010.181;10.1109/TVCG.2014.2346321;10.1109/TVCG.2011.248;10.1109/TVCG.2012.190	Predictive Modeling, Visual Analytics, Epidemic Visualization, Spatial-Temporal Systems	
VAST	2015	Collaborative visual analysis with RCloud	10.1109/VAST.2015.7347627	http://dx.doi.org/10.1109/VAST.2015.7347627	25	32	C	Consider the emerging role of data science teams embedded in larger organizations. Individual analysts work on loosely related problems, and must share their findings with each other and the organization at large, moving results from exploratory data analyses (EDA) into automated visualizations, diagnostics and reports deployed for wider consumption. There are two problems with the current practice. First, there are gaps in this workflow: EDA is performed with one set of tools, and automated reports and deployments with another. Second, these environments often assume a single-developer perspective, while data scientist teams could get much benefit from easier sharing of scripts and data feeds, experiments, annotations, and automated recommendations, which are well beyond what traditional version control systems provide. We contribute and justify the following three requirements for systems built to support current data science teams and users: discoverability, technology transfer, and coexistence. In addition, we contribute the design and implementation of RCloud, a system that supports the requirements of collaborative data analysis, visualization and web deployment. About 100 people used RCloud for two years. We report on interviews with some of these users, and discuss design decisions, tradeoffs and limitations in comparison to other approaches.	Stephen C. North;Carlos Eduardo Scheidegger;Simon Urbanek;Gordon Woodhull	Infovisible, USA|c|;;;	10.1109/TVCG.2011.185;10.1109/VAST.2007.4389011;10.1109/TVCG.2012.219;10.1109/TVCG.2009.195;10.1109/TVCG.2007.70577	visual analytics process, provenance, collaboration, visualization, computer-supported cooperative work	
VAST	2015	Four considerations for supporting visual analysis in display ecologies	10.1109/VAST.2015.7347628	http://dx.doi.org/10.1109/VAST.2015.7347628	33	40	C	The current proliferation of large displays and mobile devices presents a number of exciting opportunities for visual analytics and information visualization. The display ecology enables multiple displays to function in concert within a broader technological environment to accomplish visual analysis tasks. Based on a comprehensive survey of multi-display systems from a variety of fields, we propose four key considerations for visual analysis in display ecologies: 1) Display Composition, 2) Information Coordination/Transfer, 3) Information Connection, and 4) Display Membership. Different aspects of display ecologies stemming from these design considerations will enable users to transform and empower multiple displays as a display ecology for visual analysis.	Haeyong Chung;Chris North;Sarang Joshi;Jian Chen	Univ. of Alabama Huntsville, Huntsville, AL, USA|c|;;;	10.1109/VAST.2008.4677358		
VAST	2015	Supporting activity recognition by visual analytics	10.1109/VAST.2015.7347629	http://dx.doi.org/10.1109/VAST.2015.7347629	41	48	C	Recognizing activities has become increasingly relevant in many application domains, such as security or ambient assisted living. To handle different scenarios, the underlying automated algorithms are configured using multiple input parameters. However, the influence and interplay of these parameters is often not clear, making exhaustive evaluations necessary. On this account, we propose a visual analytics approach to supporting users in understanding the complex relationships among parameters, recognized activities, and associated accuracies. First, representative parameter settings are determined. Then, the respective output is computed and statistically analyzed to assess parameters' influence in general. Finally, visualizing the parameter settings along with the activities provides overview and allows to investigate the computed results in detail. Coordinated interaction helps to explore dependencies, compare different settings, and examine individual activities. By integrating automated, visual, and interactive means users can select parameter values that meet desired quality criteria. We demonstrate the application of our solution in a use case with realistic complexity, involving a study of human protagonists in daily living with respect to hundreds of parameter settings.	Martin Röhlig;Martin Luboschik;Frank Krüger 0001;Thomas Kirste;Heidrun Schumann;Markus Bögl;Bilal Alsallakh;Silvia Miksch	Univ. of Rostock, Rostock, Germany|c|;;;;;;;	10.1109/TVCG.2014.2346454;10.1109/TVCG.2011.253;10.1109/TVCG.2014.2346321;10.1109/TVCG.2011.248;10.1109/TVCG.2009.187;10.1109/VAST.2009.5332595		
VAST	2015	iVizTRANS: Interactive visual learning for home and work place detection from massive public transportation data	10.1109/VAST.2015.7347630	http://dx.doi.org/10.1109/VAST.2015.7347630	49	56	C	Using transport smart card transaction data to understand the homework dynamics of a city for urban planning is emerging as an alternative to traditional surveys which may be conducted every few years are no longer effective and efficient for the rapidly transforming modern cities. As commuters travel patterns are highly diverse, existing rule-based methods are not fully adequate. In this paper, we present iVizTRANS - a tool which combines an interactive visual analytics (VA) component to aid urban planners to analyse complex travel patterns and decipher activity locations for single public transport commuters. It is coupled with a machine learning component that iteratively learns from the planners classifications to train a classifier. The classifier is then applied to the city-wide smart card data to derive the dynamics for all public transport commuters. Our evaluation shows it outperforms the rule-based methods in previous work.	Liang Yu;Wei Wu;Xiaohui Li;Guangxia Li;Wee Siong Ng;See-Kiong Ng;Zhongwen Huang;Anushiya Arunan;Hui Min Watt	Inst. for Infocomm Res., Singapore, Singapore|c|;;;;;;;;	10.1109/INFVIS.2004.27;10.1109/INFVIS.2002.1173155	Smart card data, origin-destination (OD), spatiotemporal visualization, clustering, machine learning	
VAST	2015	DemographicVis: Analyzing demographic information based on user generated content	10.1109/VAST.2015.7347631	http://dx.doi.org/10.1109/VAST.2015.7347631	57	64	C	The wide-spread of social media provides unprecedented sources of written language that can be used to model and infer online demographics. In this paper, we introduce a novel visual text analytics system, DemographicVis, to aid interactive analysis of such demographic information based on user-generated content. Our approach connects categorical data (demographic information) with textual data, allowing users to understand the characteristics of different demographic groups in a transparent and exploratory manner. The modeling and visualization are based on ground truth demographic information collected via a survey conducted on Reddit.com. Detailed user information is taken into our modeling process that connects the demographic groups with features that best describe the distinguishing characteristics of each group. Features including topical and linguistic are generated from the user-generated contents. Such features are then analyzed and ranked based on their ability to predict the users' demographic information. To enable interactive demographic analysis, we introduce a web-based visual interface that presents the relationship of the demographic groups, their topic interests, as well as the predictive power of various features. We present multiple case studies to showcase the utility of our visual analytics approach in exploring and understanding the interests of different demographic groups. We also report results from a comparative evaluation, showing that the DemographicVis is quantitatively superior or competitive and subjectively preferred when compared to a commercial text analysis tool.	Wenwen Dou;Isaac Cho;Omar ElTayeby;Jaegul Choo;Xiaoyu Wang;William Ribarsky	UNC, Charlotte, NC, USA|c|;;;;;	10.1109/VAST.2014.7042493;10.1109/TVCG.2013.212;10.1109/TVCG.2014.2346433;10.1109/VAST.2011.6102461;10.1109/TVCG.2014.2346920	Visual Text Analysis, User Interface, Social Media, Demographic Analysis	
VAST	2015	EgoNetCloud: Event-based egocentric dynamic network visualization	10.1109/VAST.2015.7347632	http://dx.doi.org/10.1109/VAST.2015.7347632	65	72	C	Event-based egocentric dynamic networks are an important class of networks widely seen in many domains. In this paper, we present a visual analytics approach for these networks by combining data-driven network simplifications with a novel visualization design - EgoNetCloud. In particular, an integrated data processing pipeline is proposed to prune, compress and filter the networks into smaller but salient abstractions. To accommodate the simplified network into the visual design, we introduce a constrained graph layout algorithm on the dynamic network. Through a real-life case study as well as conversations with the domain expert, we demonstrate the effectiveness of the EgoNetCloud design and system in completing analysis tasks on event-based dynamic networks. The user study comparing EgoNetCloud with a working system on academic search confirms the effectiveness and convenience of our visual analytics based approach.	Qingsong Liu;Yifan Hu;Lei Shi;Xinzhu Mu;Yutao Zhang;Jie Tang	SKLCS, Inst. of Software, Beijing, China|c|;;;;;	10.1109/TVCG.2010.159;10.1109/TVCG.2011.226;10.1109/TVCG.2011.213		
VAST	2015	FPSSeer: Visual analysis of game frame rate data	10.1109/VAST.2015.7347633	http://dx.doi.org/10.1109/VAST.2015.7347633	73	80	C	The rate at which frames are rendered in a computer game directly influences both game playability and enjoyability. Players frequently have to deal with the trade-off between high frame rates and good resolution. Analyzing patterns in frame rate data and their correlation with the overall game performance is important in designing games (e.g., graphic card/display setting suggestion and game performance measurement). However, this task is challenging because game frame rates vary both temporally and spatially. In addition, players may adjust their display settings based on their gaming experience and hardware conditions, which further contributes to the unpredictability of frame rates. In this paper, we present a comprehensive visual analytics system FPSSeer, to help game designers gain insight into frame rate data. Our system consists of four major views: 1) a frame rate view to show the overall distribution in a geographic scale, 2) a grid view to show the frame rate distribution and grid element clusters based on their similarity, 3) a FootRiver view to reveal the temporal patterns in game condition changes and potential spatiotemporal correlations, and 4) a comparison view to evaluate game performance discrepancy under different game tests. The real-world case studies demonstrate the effectiveness of our system. The system has been applied to an online commercial game to monitor its performance and to provide feedbacks to designers and developers.	Quan Li;Peng Xu;Huamin Qu	NetEase Games, NetEase, Inc., Hong Kong Univ. of Sci. & Technol., Hong Kong, China|c|;;	10.1109/TVCG.2008.166;10.1109/INFVIS.2000.885098;10.1109/TVCG.2011.202;10.1109/TVCG.2014.2346445;10.1109/INFVIS.2001.963273	frame rate data, game performance evaluation, visual analytics	
VAST	2015	Comparative visual analysis of vector field ensembles	10.1109/VAST.2015.7347634	http://dx.doi.org/10.1109/VAST.2015.7347634	81	88	C	We present a new visual analysis approach to support the comparative exploration of 2D vector-valued ensemble fields. Our approach enables the user to quickly identify the most similar groups of ensemble members, as well as the locations where the variation among the members is high. We further provide means to visualize the main features of the potentially multimodal directional distributions at user-selected locations. For this purpose, directional data is modelled using mixtures of probability density functions (pdfs), which allows us to characterize and classify complex distributions with relatively few parameters. The resulting mixture models are used to determine the degree of similarity between ensemble members, and to construct glyphs showing the direction, spread, and strength of the principal modes of the directional distributions. We also propose several similarity measures, based on which we compute pairwise member similarities in the spatial domain and form clusters of similar members. The hierarchical clustering is shown using dendrograms and similarity matrices, which can be used to select particular members and visualize their variations. A user interface providing multiple linked views enables the simultaneous visualization of aggregated global and detailed local variations, as well as the selection of members for a detailed comparison.	Mihaela Jarema;Ismail Demir;Johannes Kehrer;Rüdiger Westermann	Tech. Univ. Munchen, Mu&#x0308;nchen, Germany|c|;;;	10.1109/TVCG.2014.2346626;10.1109/TVCG.2010.190;10.1109/VAST.2009.5332611;10.1109/TVCG.2006.160;10.1109/TVCG.2013.141;10.1109/TVCG.2013.177;10.1109/TVCG.2010.199;10.1109/TVCG.2014.2346321	Uncertainty Visualization, Vector Field Data, Coordinated and Multiple Views, Glyph-based Techniques	
VAST	2015	Interactive visual steering of hierarchical simulation ensembles	10.1109/VAST.2015.7347635	http://dx.doi.org/10.1109/VAST.2015.7347635	89	96	C	Multi-level simulation models, i.e., models where different components are simulated using sub-models of varying levels of complexity, belong to the current state-of-the-art in simulation. The existing analysis practice for multi-level simulation results is to manually compare results from different levels of complexity, amounting to a very tedious and error-prone, trial-and-error exploration process. In this paper, we introduce hierarchical visual steering, a new approach to the exploration and design of complex systems. Hierarchical visual steering makes it possible to explore and analyze hierarchical simulation ensembles at different levels of complexity. At each level, we deal with a dynamic simulation ensemble - the ensemble grows during the exploration process. There is at least one such ensemble per simulation level, resulting in a collection of dynamic ensembles, analyzed simultaneously. The key challenge is to map the multi-dimensional parameter space of one ensemble to the multi-dimensional parameter space of another ensemble (from another level). In order to support the interactive visual analysis of such complex data we propose a novel approach to interactive and semi-automatic parameter space segmentation and comparison. The approach combines a novel interaction technique and automatic, computational methods - clustering, concave hull computation, and concave polygon overlapping - to support the analysts in the cross-ensemble parameter space mapping. In addition to the novel parameter space segmentation we also deploy coordinated multiple views with standard plots. We describe the abstract analysis tasks, identified during a case study, i.e., the design of a variable valve actuation system of a car engine. The study is conducted in cooperation with experts from the automotive industry. Very positive feedback indicates the usefulness and efficiency of the newly proposed approach.	Rainer Splechtna;Kresimir Matkovic;Denis Gracanin;Mario Jelovic;Helwig Hauser	VRVis Res. Center in Vienna, Vienna, Austria|c|;;;;	10.1109/TVCG.2008.145;10.1109/TVCG.2014.2346744;10.1109/TVCG.2014.2346321;10.1109/VAST.2009.5333081;10.1109/TVCG.2010.223	Interactive Visual Analysis, Simulation-Ensemble Steering, Multi-resolution simulation	
VAST	2015	Urbane: A 3D framework to support data driven decision making in urban development	10.1109/VAST.2015.7347636	http://dx.doi.org/10.1109/VAST.2015.7347636	97	104	C	Architects working with developers and city planners typically rely on experience, precedent and data analyzed in isolation when making decisions that impact the character of a city. These decisions are critical in enabling vibrant, sustainable environments but must also negotiate a range of complex political and social forces. This requires those shaping the built environment to balance maximizing the value of a new development with its impact on the character of a neighborhood. As a result architects are focused on two issues throughout the decision making process: a) what defines the character of a neighborhood? and b) how will a new development change its neighborhood? In the first, character can be influenced by a variety of factors and understanding the interplay between diverse data sets is crucial; including safety, transportation access, school quality and access to entertainment. In the second, the impact of a new development is measured, for example, by how it impacts the view from the buildings that surround it. In this paper, we work in collaboration with architects to design Urbane, a 3-dimensional multi-resolution framework that enables a data-driven approach for decision making in the design of new urban development. This is accomplished by integrating multiple data layers and impact analysis techniques facilitating architects to explore and assess the effect of these attributes on the character and value of a neighborhood. Several of these data layers, as well as impact analysis, involve working in 3-dimensions and operating in real time. Efficient computation and visualization is accomplished through the use of techniques from computer graphics. We demonstrate the effectiveness of Urbane through a case study of development in Manhattan depicting how a data-driven understanding of the value and impact of speculative buildings can benefit the design-development process between architects, planners and developers.	Nivan Ferreira;Marcos Lage;Harish Doraiswamy;Huy T. Vo;Luc Wilson;Heidi Werner;Muchan Park;Cláudio T. Silva	New York Univ., New York, NY, USA|c|;;;;;;;	10.1109/VAST.2008.4677356;10.1109/TVCG.2014.2346446;10.1109/TVCG.2007.70574;10.1109/TVCG.2013.226;10.1109/TVCG.2007.70523;10.1109/TVCG.2013.228;10.1109/TVCG.2014.2346893;10.1109/TVCG.2014.2346898		
VAST	2015	FeatureInsight: Visual support for error-driven feature ideation in text classification	10.1109/VAST.2015.7347637	http://dx.doi.org/10.1109/VAST.2015.7347637	105	112	C	Machine learning requires an effective combination of data, features, and algorithms. While many tools exist for working with machine learning data and algorithms, support for thinking of new features, or feature ideation, remains poor. In this paper, we investigate two general approaches to support feature ideation: visual summaries and sets of errors. We present FeatureInsight, an interactive visual analytics tool for building new dictionary features (semantically related groups of words) for text classification problems. FeatureInsight supports an error-driven feature ideation process and provides interactive visual summaries of sets of misclassified documents. We conducted a controlled experiment evaluating both visual summaries and sets of errors in FeatureInsight. Our results show that visual summaries significantly improve feature ideation, especially in combination with sets of errors. Users preferred visual summaries over viewing raw data, and only preferred examining sets when visual summaries were provided. We discuss extensions of both approaches to data types other than text, and point to areas for future research.	Michael Brooks;Saleema Amershi;Bongshin Lee;Steven M. Drucker;Ashish Kapoor;Patrice Y. Simard	Univ. of Washington, Seattle, WA, USA|c|;;;;;	10.1109/VAST.2010.5652443		
VAST	2015	Visual scalability of spatial ensemble uncertainty	10.1109/VAST.2015.7347671	http://dx.doi.org/10.1109/VAST.2015.7347671	187	188	M	Weather Research and Forecasting (WRF) models simulate weather conditions by generating 2D numerical weather prediction ensemble members either through perturbing initial conditions or by changing different parameterization schemes, e.g., cumulus and microphysics schemes. These simulations are often used by weather analysts to analyze the nature of uncertainty attributed by these simulations to forecast weather conditions with good accuracy. The number of simulations used for forecasting is growing with the advent of increase in computing power. Hence, there is a need for providing better visual insights of uncertainty with growing number of ensemble members. We propose a geo visual analytical framework that uses visual analytics approach to resolve visual scalability of these ensemble members. Our approach naturally fits with the workflow of an analyst analyzing ensemble spatial uncertainty. Meteorologists evaluated our framework qualitatively and found it to be effective in acquiring insights of spatial uncertainty associated with multiple ensemble runs that are simulated using multiple parameterization schemes.	Sujan Anreddy;Song Zhang 0004;Andrew Mercer 0001;Jamie Dyer;J. Edward Swan II	Mississippi State Univ., Starkville, MS, USA|c|;;;;			
VAST	2015	Visually and statistically guided imputation of missing values in univariate seasonal time series	10.1109/VAST.2015.7347672	http://dx.doi.org/10.1109/VAST.2015.7347672	189	190	M	Missing values are a problem in many real world applications, for example failing sensor measurements. For further analysis these missing values need to be imputed. Thus, imputation of such missing values is important in a wide range of applications. We propose a visually and statistically guided imputation approach, that allows applying different imputation techniques to estimate the missing values as well as evaluating and fine tuning the imputation by visual guidance. In our approach we include additional visual information about uncertainty and employ the cyclic structure of time inherent in the data. Including this cyclic structure enables visually judging the adequateness of the estimated values with respect to the uncertainty/error boundaries and according to the patterns of the neighbouring time points in linear and cyclic (e.g., the months of the year) time.	Markus Bögl;Peter Filzmoser;Theresia Gschwandtner;Silvia Miksch;Wolfgang Aigner;Alexander Rind;Tim Lammarsch	Vienna Univ. of Technol., Vienna, Austria|c|;;;;;;			
VAST	2015	StreamVisND: Visualizing relationships in streaming multivariate data	10.1109/VAST.2015.7347673	http://dx.doi.org/10.1109/VAST.2015.7347673	191	192	M		Shenghui Cheng;Yue Wang;Dan Zhang;Zhifang Jiang;Klaus Mueller	;;;;			
VAST	2015	A software developer's guide to informal evaluation of Visual Analytics environments using VAST Challenge information	10.1109/VAST.2015.7347674	http://dx.doi.org/10.1109/VAST.2015.7347674	193	194	M	The VAST Challenge has been a popular venue for academic and industry participants for over ten years. Many participants comment that the majority of their time in preparing VAST Challenge entries is discovering elements in their software environments that need to be redesigned in order to solve the given task. Fortunately, there is no need to wait until the VAST Challenge is announced to test out software systems. The Visual Analytics Benchmark Repository contains all past VAST Challenge tasks, data, solutions and submissions. In this poster we describe how developers can perform informal evaluations of various aspects of their visual analytics environments using VAST Challenge information.	Kristin A. Cook;Jean Scholtz;Mark A. Whiting	;;			
VAST	2015	HTMVS: Visualizing hierarchical topics and their evolution	10.1109/VAST.2015.7347675	http://dx.doi.org/10.1109/VAST.2015.7347675	195	196	M	Topic model has been an active research area for many years, it can be used for discovering latent semantics and finding hidden knowledge in unstructured data corpus. In this paper, we investigated the problems in visualizing hierarchical topic and their evolution. The contribution of this paper is threefold, first we explore the static visualization of hierarchical topics using the `nested circle' layout, and then in order to present the topic evolution over time, we extended a hierarchical topic model and employ topic transformation visualizations to track the arising, splitting and disappearing of certain topics under the dynamic topical hierarchy. Finally, a Hierarchical Topic Model Visualization System (HTMVS) is designed to take advantage of both static and dynamic hierarchical topic visualization.	Haoling Dong;Siliang Tang;Si Li;Fei Wu;Yueting Zhuang	Coll. of Comput. Sci., Zhejiang Univ., Hangzhou, China|c|;;;;			
VAST	2015	Interactive semi-automatic categorization for spinel group minerals	10.1109/VAST.2015.7347676	http://dx.doi.org/10.1109/VAST.2015.7347676	197	198	M	Spinel group minerals are excellent indicators of geological environments (tectonic settings). In 2001, Barnes and Roeder defined a set of contours corresponding to compositional fields for spinel group minerals. Geologists typically use this contours to estimate the tectonic environment where a particular spinel composition could have been formed. This task is prone to errors and requires tedious manual comparison of overlapping diagrams. We introduce a semi-automatic, interactive detection of tectonic settings for an arbitrary dataset based on the Barnes and Roeder contours. The new approach integrates the mentioned contours and includes a novel interaction called contour brush. The new methodology is integrated in the Spinel Explorer system and it improves the scientist's workflow significantly.	Maria Luján Ganuza;Maria Florencia Gargiulo;Gabriela Ferracutti;Silvia Mabel Castro;Ernesto A. Bjerg;Eduard Gröller;Kresimir Matkovic	VyGLab, UNS, Bahia Blanca, Argentina|c|;;;;;;			
VAST	2015	A System for visual exploration of caution spots from vehicle recorder data	10.1109/VAST.2015.7347677	http://dx.doi.org/10.1109/VAST.2015.7347677	199	200	M	It is vital for the transportation industry, which performs most of its work by automobiles, to reduce its accident rate. This paper proposes a 3D visual interaction method for exploring caution areas from large-scale vehicle recorder data. Our method provides (i) a flexible filtering interface for driving operations such as braking or handling operations by various combinations of their attribute values such as velocity and acceleration, and (ii) a 3D visual environment for spatio-temporal exploration of caution areas. The proposed method was able to extract caution areas where some accidents have actually occurred or that are on very narrow roads with bad visibility by using real data given by one of the biggest transportation companies in Japan.	Masahiko Itoh;Daisaku Yokoyama;Masashi Toyoda;Masaru Kitsuregawa	;;;			
VAST	2015	Visual Analytics for fraud detection and monitoring	10.1109/VAST.2015.7347678	http://dx.doi.org/10.1109/VAST.2015.7347678	201	202	M	One of the primary concerns of financial institutions is to guarantee security and legitimacy in their services. Being able to detect and avoid fraudulent schemes also enhances the credibility of these institutions. Currently, fraud detection approaches still lack Visual Analytics techniques. We propose a Visual Analytics process that tackles the main challenges in the area of fraud detection.	Roger A. Leite;Theresia Gschwandtner;Silvia Miksch;Erich Gstrein;Johannes Kuntner	Vienna Univ. of Technol., Vienna, Austria|c|;;;;			
VAST	2015	Visual analysis of route choice behaviour based on GPS trajectories	10.1109/VAST.2015.7347679	http://dx.doi.org/10.1109/VAST.2015.7347679	203	204	M	There are often multiple routes between regions. Many factors potentially affect driver's route choice, such as expected time cost, length etc. In this work, we present a visual analysis system to explore driver's route choice behaviour based on taxi GPS trajectory data. With interactive trajectory filtering, the system constructs feasible routes between regions of interest. Using a rank-based visualization, the attributes of multiple routes are explored and compared. Based on a statistical model, the system supports to verify trajectory-related factors' impact on route choice behaviour. The effectiveness of the system is demonstrated by applying to real trajectory dataset.	Min Lu;Chufan Lai;Tangzhi Ye;Jie Liang;Xiaoru Yuan	Key Lab. of Machine Perception, Peking Univ., Beijing, China|c|;;;;			
VAST	2015	Using visualization and analysis with efficient dimension Reduction to determine underlying factors in hospital inpatient procedure costs	10.1109/VAST.2015.7347680	http://dx.doi.org/10.1109/VAST.2015.7347680	205	206	M	The Centers for Medicare and Medicaid Services (CMS) has made public a data set showing what hospitals charged and what Medicare paid for the one hundred most common inpatient stays. Here we present the application of Reduced Basis Decomposition (RBD), an efficient novel dimension reduction algorithm for data processing, to the CMS data. This was paired with a comparative visual exploration of the results when put into context with characteristics of the hospitals and marketplaces in which they operate. We used Weave Analyst, a new web-based analysis and visualization environment, to visualize the relationship between the hospital groups, their charge levels, and distinguishing indicator variables. Particular insights to the relatively small number of underlying factors that exert greatest influence on hospital pricing surfaced thanks to the combined synergetic integration of the modeling, reduction, and visualization techniques.	Miriam Perkins;Yanlai Chen	Univ. of Massachusetts Lowell, Lowell, MA, USA|c|;			
VAST	2015	Topicks: Visualizing complex topic models for user comprehension	10.1109/VAST.2015.7347681	http://dx.doi.org/10.1109/VAST.2015.7347681	207	208	M	The interactive visualization of topic models is a promising approach to summarizing large sets of textual data. Topicks is the working title for a means to visualize topic modelling outputs. Incorporating a radial layout, users can view the relationships between topics, terms and the corpus as a whole. Interacting with topic and term nodes, as well as a related bar chart, provides the user with various ways to manipulate the visualization and explore the data. We describe the visualization and potential user interactions before discussing future work.	Jessica Peter;Steve James Szigeti;Ana Jofre;Sara Diamond	OCAD Univ., Canada|c|;;;			
VAST	2015	TimeStitch: Interactive multi-focus cohort discovery and comparison	10.1109/VAST.2015.7347682	http://dx.doi.org/10.1109/VAST.2015.7347682	209	210	M	Whereas event-based timelines for healthcare enable users to visualize the chronology of events surrounding events of interest, they are often not designed to aid the discovery, construction, or comparison of associated cohorts. We present TimeStitch, a system that helps health researchers discover and understand events that may cause abstinent smokers to lapse. TimeStitch extracts common sequences of events performed by abstinent smokers from large amounts of mobile health sensor data, and offers a suite of interactive and visualization techniques to enable cohort discovery, construction, and comparison, using extracted sequences as interactive elements. We are extending TimeStitch to support more complex health conditions with high mortality risk, such as reducing hospital readmission in congestive heart failure.	Peter J. Polack Jr.;Shang-Tse Chen;Minsuk Kahng;Moushumi Sharmin;Duen Horng Chau	;;;;			
VAST	2015	Tell me what do you see: Detecting perceptually-separable visual patterns via clustering of image-space features in visualizations	10.1109/VAST.2015.7347683	http://dx.doi.org/10.1109/VAST.2015.7347683	211	212	M	Visualization helps users infer structures and relationships in the data by encoding information as visual features that can be processed by the human visual-perceptual system. However, users would typically need to expend significant effort to scan and analyze a large number of views before they can begin to recognize relationships in a visualization. We propose a technique to partially automate the process of analyzing visualizations. By deriving and analyzing image-space features from visualizations, we can detect perceptually-separable patterns in the information space. We summarize these patterns with a tree-based meta-visualization and present it to the user to aid exploration. We illustrate this technique with an example scenario involving the analysis of census data.	Khairi Reda;Alberto Gonzalez;Jason Leigh;Michael E. Papka	Argonne Nat. Lab., Argonne, IL, USA|c|;;;			
VAST	2015	Sequencing of categorical time series	10.1109/VAST.2015.7347684	http://dx.doi.org/10.1109/VAST.2015.7347684	213	214	M	Exploring and comparing categorical time series and finding temporal patterns are complex tasks in the field of time series data mining. Although different analysis approaches exist, these tasks remain challenging, especially when numerous time series are considered at once. We propose a visual analysis approach that supports exploring such data by ordering time series in meaningful ways. We provide interaction techniques to steer the automated arrangement and to allow users to investigate patterns in detail.	Christian Richter;Martin Luboschik;Martin Röhlig;Heidrun Schumann	Univ. of Rostock, Rostock, Germany|c|;;;			
VAST	2015	Visual Pruner: Visually guided cohort selection for observational studies	10.1109/VAST.2015.7347685	http://dx.doi.org/10.1109/VAST.2015.7347685	215	216	M	Observational studies are a widely used and challenging class of studies. A key challenge is selecting a study cohort from the available data, or ΓÇ£pruningΓÇ¥ the data, in a way that produces both sufficient balance in pre-treatment covariates and an easily described cohort from which results can be generalized. Even with advanced pruning methods, it is often difficult for researchers to see how the cohort is being selected; consequently, these methods are underutilized in research. Visual Pruner is a free, easy-to-use web application that can improve both the credibility and generalizability of observational studies by letting analysts use updatable visual displays of estimated propensity scores and key baseline covariates to refine inclusion criteria. By helping researchers see how covariate distributions in their data relate to the estimated probabilities of treatment assignment, the app lets researchers make pruning decisions based on pre-treatment covariate patterns that are otherwise hard to discover. The app yields a set of inclusion criteria that can be used in conjunction with further statistical analysis in any statistical software.	Lauren R. Samuels;Robert A. Greevy	Sch. of Med., Dept. of Biostat., Vanderbilt Univ., Nashville, TN, USA|c|;			
VAST	2015	uRank: Visual analytics approach for search result exploration	10.1109/VAST.2015.7347686	http://dx.doi.org/10.1109/VAST.2015.7347686	217	218	M	uRank is a Web-based tool combining lightweight text analytics and visual methods for topic-wise exploration of document sets. It includes a view summarizing the content of the document set in meaningful terms, a dynamic document ranking view and a detailed view for further inspection of individual documents. Its major strength lies in how it supports users in reorganizing documents on-the-fly as their information interests change. We present a preliminary evaluation showing that uRank helps to reduce cognitive load compared to a traditional list-based representation.	Cecilia di Sciascio;Vedran Sabol;Eduardo E. Veas	Know-Center GmbH, Graz, Austria|c|;;			
VAST	2015	Evolution inspector: Interactive visual analysis for evolutionary molecular design	10.1109/VAST.2015.7347687	http://dx.doi.org/10.1109/VAST.2015.7347687	219	220	M	De novo design is a computational-chemistry method, where a computer program utilizes an optimization method, in our case an evolutionary algorithm, to design compounds with desired chemical properties. The optimization is performed with respect to a quantity called fitness, defined by the chemists. We present a tool that connects interactive visual analysis and evolutionary algorithm-based molecular design. We employ linked views to communicate different aspects of the data: the statistical distribution of molecule fitness, connections between individual molecules during the evolution and 3D molecular structure. The application is already used by chemists to explore and analyze the results of their evolution experiments and has proved to be highly useful.	Veronika Soltészová;Marco Foscato;Sondre H. Eliasson;Vidar R. Jensen	Christian Michelsen Res., Bergen, Norway|c|;;;			
VAST	2015	Trending pool: Visual analytics for trending event compositions for time-series categorical log data	10.1109/VAST.2015.7347688	http://dx.doi.org/10.1109/VAST.2015.7347688	221	222	M	Although many visualization tools provide us plenty of ways to view the data, users can not easily find the trending events and their explanation from the data. In this work, we address the issue by leveraging the real music streaming log data as an example to better understand a million-scale dataset. Trending event explanation turns out to be challenging when it comes to categorical log data. Therefore, we propose to use a learning-based method with an interface design to uncover the trending event compositions for time-series categorical log data, which can be extend to other datasets, e.g., the hashtags in social media. First, we perform ΓÇ£trending poolΓÇ¥ operation to save the memory and time cost. Second, we apply sparse coding to learn important trending candidate combination sets instead of traditional brute-force way or manual investigation for generating combinations. Besides the contributions above, we also observe some interesting user behaviors by exploring detected trending candidate combinations visually through our interface.	Yi-Chih Tsai;Liang-Chi Hsieh;Wen-Feng Cheng;Yin-Hsi Kuo;Winston H. Hsu;Wen-Chin Chen	Nat. Taiwan Univ., Taipei, Taiwan|c|;;;;;			
VAST	2015	Visual data quality analysis for taxi GPS data	10.1109/VAST.2015.7347689	http://dx.doi.org/10.1109/VAST.2015.7347689	223	224	M	We present a novel visual analysis method to systematically discover data quality problems in raw taxi GPS data. It combines semi-supervised active learning and interactive visual exploration. It helps analysts interactively discover unknown data quality problems, and automatically extract known problems. We report analysis results on Beijing taxi GPS data.	Zuchao Wang;Xiaoru Yuan;Tangzhi Ye;Youfeng Hao;Siming Chen;Jie Liang;Qiusheng Li;Haiyang Wang;Yadong Wu	Key Lab. of Machine Perception, Peking Univ., Beijing, China|c|;;;;;;;;			
InfoVis	2016	PowerSet: A Comprehensive Visualization of Set Intersections	10.1109/TVCG.2016.2598496	http://dx.doi.org/10.1109/TVCG.2016.2598496	361	370	J	When analyzing a large amount of data, analysts often define groups over data elements that share certain properties. Using these groups as the unit of analysis not only reduces the data volume, but also allows detecting various patterns in the data. This involves analyzing intersection relations between these groups, and how the element attributes vary between these intersections. This kind of set-based analysis has various applications in a variety of domains, due to the generic and powerful notion of sets. However, visualizing intersections relations is challenging because their number grows exponentially with the number of sets. We present a novel technique based on Treemaps to provide a comprehensive overview of non-empty intersections in a set system in a scalable way. It enables gaining insight about how elements are distributed across these intersections as well as performing fine-grained analysis to explore and compare their attributes both in overview and in detail. Interaction allows querying and filtering these elements based on their set memberships. We demonstrate how our technique supports various use cases in data exploration and analysis by providing insights into set-based data, beyond the limits of state-of-the-art techniques.	Bilal Alsallakh;Liu Ren	BOSCH Research;BOSCH Research	10.1109/TVCG.2014.2346248;10.1109/TVCG.2015.2467051;10.1109/TVCG.2006.142;10.1109/INFVIS.2001.963283;10.1109/TVCG.2010.186;10.1109/VISUAL.1991.175815;10.1109/TVCG.2012.233;10.1109/VISUAL.1993.398863;10.1109/TVCG.2011.227;10.1109/TVCG.2009.122;10.1109/TVCG.2014.2346249;10.1109/TVCG.2012.205;10.1109/TVCG.2008.144;10.1109/TVCG.2011.185;10.1109/TVCG.2013.184;10.1109/TVCG.2011.186	scalability;Set visualization;treemaps;interaction	BOSCH Research##BOSCH Research
InfoVis	2016	Investigating the Use of a Dynamic Physical Bar Chart for Data Exploration and Presentation	10.1109/TVCG.2016.2598498	http://dx.doi.org/10.1109/TVCG.2016.2598498	451	460	J	Physical data representations, or data physicalizations, are a promising new medium to represent and communicate data. Previous work mostly studied passive physicalizations which require humans to perform all interactions manually. Dynamic shape-changing displays address this limitation and facilitate data exploration tasks such as sorting, navigating in data sets which exceed the fixed size of a given physical display, or preparing &#x201C;views&#x201D; to communicate insights about data. However, it is currently unclear how people approach and interact with such data representations. We ran an exploratory study to investigate how non-experts made use of a dynamic physical bar chart for an open-ended data exploration and presentation task. We asked 16 participants to explore a data set on European values and to prepare a short presentation of their insights using a physical display. We analyze: (1) users' body movements to understand how they approach and react to the physicalization, (2) their hand-gestures to understand how they interact with physical data, (3) system interactions to understand which subsets of the data they explored and which features they used in the process, and (4) strategies used to explore the data and present observations. We discuss the implications of our findings for the use of dynamic data physicalizations and avenues for future work.	Faisal Taher;Yvonne Jansen;Jonathan Woodruff;John Hardy;Kasper Hornbæk;Jason Alexander	Lancaster University;University of Copenhagen;Lancaster University;Lancaster University;University of Copenhagen;Lancaster University	10.1109/TVCG.2014.2346292;10.1109/TVCG.2014.2352953;10.1109/TVCG.2013.124	Shape-changing displays;physicalization;physical visualization;bar charts;user behaviour;data presentation	Lancaster University##University of Copenhagen##Lancaster University##Lancaster University##University of Copenhagen##Lancaster University
InfoVis	2016	booc.io: An Education System with Hierarchical Concept Maps and Dynamic Non-linear Learning Plans	10.1109/TVCG.2016.2598518	http://dx.doi.org/10.1109/TVCG.2016.2598518	571	580	J	Information hierarchies are difficult to express when real-world space or time constraints force traversing the hierarchy in linear presentations, such as in educational books and classroom courses. We present booc.io, which allows linear and non-linear presentation and navigation of educational concepts and material. To support a breadth of material for each concept, booc.io is Web based, which allows adding material such as lecture slides, book chapters, videos, and LTIs. A visual interface assists the creation of the needed hierarchical structures. The goals of our system were formed in expert interviews, and we explain how our design meets these goals. We adapt a real-world course into booc.io, and perform introductory qualitative evaluation with students.	Michail Schwab;Hendrik Strobelt;James Tompkin;Colin Fredericks;Connor Huff;Dana Higgins;Anton Strezhnev;Mayya Komisarchik;Gary King;Hanspeter Pfister	Harvard Paulson SEAS;Harvard Paulson SEAS;Harvard Paulson SEAS;HarvardX;Harvard Institute for Quantitative Social Sciences;Harvard Institute for Quantitative Social Sciences;Harvard Institute for Quantitative Social Sciences;Harvard Institute for Quantitative Social Sciences;Harvard Institute for Quantitative Social Sciences;Harvard Paulson SEAS	;10.1109/TVCG.2006.147	education;Hierarchies;information visualization	Harvard Paulson SEAS##Harvard Paulson SEAS##Harvard Paulson SEAS##HarvardX##Harvard Institute for Quantitative Social Sciences##Harvard Institute for Quantitative Social Sciences##Harvard Institute for Quantitative Social Sciences##Harvard Institute for Quantitative Social Sciences##Harvard Institute for Quantitative Social Sciences##Harvard Paulson SEAS
InfoVis	2016	Quantifying the Visual Impact of Classification Boundaries in Choropleth Maps	10.1109/TVCG.2016.2598541	http://dx.doi.org/10.1109/TVCG.2016.2598541	371	380	J	One critical visual task when using choropleth maps is to identify spatial clusters in the data. If spatial units have the same color and are in the same neighborhood, this region can be visually identified as a spatial cluster. However, the choice of classification method used to create the choropleth map determines the visual output. The critical map elements in the classification scheme are those that lie near the classification boundary as those elements could potentially belong to different classes with a slight adjustment of the classification boundary. Thus, these elements have the most potential to impact the visual features (i.e., spatial clusters) that occur in the choropleth map. We present a methodology to enable analysts and designers to identify spatial regions where the visual appearance may be the result of spurious data artifacts. The proposed methodology automatically detects the critical boundary cases that can impact the overall visual presentation of the choropleth map using a classification metric of cluster stability. The map elements that belong to a critical boundary case are then automatically assessed to quantify the visual impact of classification edge effects. Our results demonstrate the impact of boundary elements on the resulting visualization and suggest that special attention should be given to these elements during map design.	Yifan Zhang;Ross Maciejewski	Arizona State University;Arizona State University	10.1109/VAST.2009.5332584;10.1109/TVCG.2012.233;10.1109/TVCG.2011.197	Choropleth;Classification;Visualization;Geodemographics;Geovisualization	Arizona State University##Arizona State University
InfoVis	2016	Small Multiples with Gaps	10.1109/TVCG.2016.2598542	http://dx.doi.org/10.1109/TVCG.2016.2598542	381	390	J	Small multiples enable comparison by providing different views of a single data set in a dense and aligned manner. A common frame defines each view, which varies based upon values of a conditioning variable. An increasingly popular use of this technique is to project two-dimensional locations into a gridded space (e.g. grid maps), using the underlying distribution both as the conditioning variable and to determine the grid layout. Using whitespace in this layout has the potential to carry information, especially in a geographic context. Yet, the effects of doing so on the spatial properties of the original units are not understood. We explore the design space offered by such small multiples with gaps. We do so by constructing a comprehensive suite of metrics that capture properties of the layout used to arrange the small multiples for comparison (e.g. compactness and alignment) and the preservation of the original data (e.g. distance, topology and shape). We study these metrics in geographic data sets with varying properties and numbers of gaps. We use simulated annealing to optimize for each metric and measure the effects on the others. To explore these effects systematically, we take a new approach, developing a system to visualize this design space using a set of interactive matrices. We find that adding small amounts of whitespace to small multiple arrays improves some of the characteristics of 2D layouts, such as shape, distance and direction. This comes at the cost of other metrics, such as the retention of topology. Effects vary according to the input maps, with degree of variation in size of input regions found to be a factor. Optima exist for particular metrics in many cases, but at different amounts of whitespace for different maps. We suggest multiple metrics be used in optimized layouts, finding topology to be a primary factor in existing manually-crafted solutions, followed by a trade-off between shape and displacement. But the rich range of possible optimized layouts leads us to challenge single-solution thinking; we suggest to consider alternative optimized layouts for small multiples with gaps. Key to our work is the systematic, quantified and visual approach to exploring design spaces when facing a trade-off between many competing criteria-an approach likely to be of value to the analysis of other design spaces.	Wouter Meulemans;Jason Dykes;Aidan Slingsby;Cagatay Turkay;Jo Wood	giCentre, City University, London;giCentre, City University, London;giCentre, City University, London;giCentre, City University, London;giCentre, City University, London	10.1109/TVCG.2014.2346276;10.1109/TVCG.2011.174;10.1109/TVCG.2016.2598862;10.1109/TVCG.2008.165	Geographic visualization;small multiples;whitespace;design space;metrics;optimization	giCentre, City University, London##giCentre, City University, London##giCentre, City University, London##giCentre, City University, London##giCentre, City University, London
InfoVis	2016	Exploring the Possibilities of Embedding Heterogeneous Data Attributes in Familiar Visualizations	10.1109/TVCG.2016.2598586	http://dx.doi.org/10.1109/TVCG.2016.2598586	581	590	J	Heterogeneous multi-dimensional data are now sufficiently common that they can be referred to as ubiquitous. The most frequent approach to visualizing these data has been to propose new visualizations for representing these data. These new solutions are often inventive but tend to be unfamiliar. We take a different approach. We explore the possibility of extending well-known and familiar visualizations through including Heterogeneous Embedded Data Attributes (HEDA) in order to make familiar visualizations more powerful. We demonstrate how HEDA is a generic, interactive visualization component that can extend common visualization techniques while respecting the structure of the familiar layout. HEDA is a tabular visualization building block that enables individuals to visually observe, explore, and query their familiar visualizations through manipulation of embedded multivariate data. We describe the design space of HEDA by exploring its application to familiar visualizations in the D3 gallery. We characterize these familiar visualizations by the extent to which HEDA can facilitate data queries based on attribute reordering.	Mona Hosseinkhani Loorak;Charles Perin;Christopher Collins;M. Sheelagh T. Carpendale	Department of Computer Science, University of Calgary;Department of Computer Science, University of Calgary;University of Ontario;Department of Computer Science, University of Calgary	10.1109/TVCG.2014.2346248;10.1109/TVCG.2014.2346260;10.1109/INFVIS.2005.1532151;10.1109/INFVIS.2005.1532129;10.1109/TVCG.2007.70582;10.1109/TVCG.2009.179;10.1109/INFVIS.2003.1249016;10.1109/TVCG.2010.205;10.1109/TVCG.2013.227;10.1109/TVCG.2013.210;10.1109/TVCG.2011.201;10.1109/TVCG.2015.2467325;10.1109/TVCG.2009.122;10.1109/TVCG.2014.2346279;10.1109/TVCG.2013.192;10.1109/TVCG.2013.167;10.1109/VISUAL.1990.146386;10.1109/TVCG.2011.185;10.1109/TVCG.2011.186	Multi-dimensional data;Hybrid visualization	Department of Computer Science, University of Calgary##Department of Computer Science, University of Calgary##University of Ontario##Department of Computer Science, University of Calgary
InfoVis	2016	Screenit: Visual Analysis of Cellular Screens	10.1109/TVCG.2016.2598587	http://dx.doi.org/10.1109/TVCG.2016.2598587	591	600	J	High-throughput and high-content screening enables large scale, cost-effective experiments in which cell cultures are exposed to a wide spectrum of drugs. The resulting multivariate data sets have a large but shallow hierarchical structure. The deepest level of this structure describes cells in terms of numeric features that are derived from image data. The subsequent level describes enveloping cell cultures in terms of imposed experiment conditions (exposure to drugs). We present Screenit, a visual analysis approach designed in close collaboration with screening experts. Screenit enables the navigation and analysis of multivariate data at multiple hierarchy levels and at multiple levels of detail. Screenit integrates the interactive modeling of cell physical states (phenotypes) and the effects of drugs on cell cultures (hits). In addition, quality control is enabled via the detection of anomalies that indicate low-quality data, while providing an interface that is designed to match workflows of screening experts. We demonstrate analyses for a real-world data set, CellMorph, with 6 million cells across 20,000 cell cultures.	Kasper Dinkla;Hendrik Strobelt;Bryan Genest;Stephan Reiling;Mark Borowsky;Hanspeter Pfister	Harvard University;Harvard University;Novartis Institute of BioMedical Research;Novartis Institute of BioMedical Research;Novartis Institute of BioMedical Research;Harvard University	10.1109/VAST.2012.6400492;10.1109/TVCG.2014.2346752;10.1109/TVCG.2015.2466971;10.1109/TVCG.2011.253;10.1109/VAST.2010.5652443;10.1109/TVCG.2012.213;10.1109/TVCG.2014.2346578;10.1109/TVCG.2013.173;10.1109/VAST.2011.6102453;10.1109/TVCG.2014.2346482	High-content screening;visual analysis;feature selection;image classification;biology;multivariate;hierarchy	Harvard University##Harvard University##Novartis Institute of BioMedical Research##Novartis Institute of BioMedical Research##Novartis Institute of BioMedical Research##Harvard University
InfoVis	2016	PROACT: Iterative Design of a Patient-Centered Visualization for Effective Prostate Cancer Health Risk Communication	10.1109/TVCG.2016.2598588	http://dx.doi.org/10.1109/TVCG.2016.2598588	601	610	J	Prostate cancer is the most common cancer among men in the US, and yet most cases represent localized cancer for which the optimal treatment is unclear. Accumulating evidence suggests that the available treatment options, including surgery and conservative treatment, result in a similar prognosis for most men with localized prostate cancer. However, approximately 90% of patients choose surgery over conservative treatment, despite the risk of severe side effects like erectile dysfunction and incontinence. Recent medical research suggests that a key reason is the lack of patient-centered tools that can effectively communicate personalized risk information and enable them to make better health decisions. In this paper, we report the iterative design process and results of developing the PROgnosis Assessment for Conservative Treatment (PROACT) tool, a personalized health risk communication tool for localized prostate cancer patients. PROACT utilizes two published clinical prediction models to communicate the patients' personalized risk estimates and compare treatment options. In collaboration with the Maine Medical Center, we conducted two rounds of evaluations with prostate cancer survivors and urologists to identify the design elements and narrative structure that effectively facilitate patient comprehension under emotional distress. Our results indicate that visualization can be an effective means to communicate complex risk information to patients with low numeracy and visual literacy. However, the visualizations need to be carefully chosen to balance readability with ease of comprehension. In addition, due to patients' charged emotional state, an intuitive narrative structure that considers the patients' information need is critical to aid the patients' comprehension of their risk information.	Anzu Hakone;Lane Harrison;Alvitta Ottley;Nathan Winters;Caitlin Gutheil;Paul K. J. Han;Remco Chang	Tufts University;Worcester Polytechnic Institute;Tufts University;Tufts University;Maine Medical Center;Maine Medical Center;Tufts University	10.1109/TVCG.2012.225;10.1109/TVCG.2013.200;10.1109/TVCG.2014.2346984;10.1109/TVCG.2015.2467758;10.1109/TVCG.2012.219;10.1109/TVCG.2014.2346682	Design studies;task and requirement analysis;presentation;production;and dissemination;medical visualization	Tufts University##Worcester Polytechnic Institute##Tufts University##Tufts University##Maine Medical Center##Maine Medical Center##Tufts University
InfoVis	2016	WeightLifter: Visual Weight Space Exploration for Multi-Criteria Decision Making	10.1109/TVCG.2016.2598589	http://dx.doi.org/10.1109/TVCG.2016.2598589	611	620	J	A common strategy in Multi-Criteria Decision Making (MCDM) is to rank alternative solutions by weighted summary scores. Weights, however, are often abstract to the decision maker and can only be set by vague intuition. While previous work supports a point-wise exploration of weight spaces, we argue that MCDM can benefit from a regional and global visual analysis of weight spaces. Our main contribution is WeightLifter, a novel interactive visualization technique for weight-based MCDM that facilitates the exploration of weight spaces with up to ten criteria. Our technique enables users to better understand the sensitivity of a decision to changes of weights, to efficiently localize weight regions where a given solution ranks high, and to filter out solutions which do not rank high enough for any plausible combination of weights. We provide a comprehensive requirement analysis for weight-based MCDM and describe an interactive workflow that meets these requirements. For evaluation, we describe a usage scenario of WeightLifter in automotive engineering and report qualitative feedback from users of a deployed version as well as preliminary feedback from decision makers in multiple domains. This feedback confirms that WeightLifter increases both the efficiency of weight-based MCDM and the awareness of uncertainty in the ultimate decisions.	Stephan Pajer;Marc Streit;Thomas Torsney-Weir;Florian Spechtenhauser;Torsten Möller;Harald Piringer	VRVis Research Center;University Linz;University of Vienna;VRVis Research Center;University of Vienna;VRVis Research Center	10.1109/TVCG.2015.2468011;10.1109/TVCG.2013.147;10.1109/VAST.2015.7347686;10.1109/VISUAL.1993.398859;10.1109/TVCG.2008.145;10.1109/VAST.2011.6102457;10.1109/TVCG.2011.253;10.1109/TVCG.2014.2346321;10.1109/TVCG.2010.190;10.1109/TVCG.2009.110;10.1109/VAST.2010.5652460;10.1109/TVCG.2013.173;10.1109/TVCG.2011.248;10.1109/TVCG.2009.111	Visual analysis;decision making;multi-objective optimization;interactive ranking;rank sensitivity	VRVis Research Center##University Linz##University of Vienna##VRVis Research Center##University of Vienna##VRVis Research Center
InfoVis	2016	Visualizing Social Media Content with SentenTree	10.1109/TVCG.2016.2598590	http://dx.doi.org/10.1109/TVCG.2016.2598590	621	630	J	We introduce SentenTree, a novel technique for visualizing the content of unstructured social media text. SentenTree displays frequent sentence patterns abstracted from a corpus of social media posts. The technique employs design ideas from word clouds and the Word Tree, but overcomes a number of limitations of both those visualizations. SentenTree displays a node-link diagram where nodes are words and links indicate word co-occurrence within the same sentence. The spatial arrangement of nodes gives cues to the syntactic ordering of words while the size of nodes gives cues to their frequency of occurrence. SentenTree can help people gain a rapid understanding of key concepts and opinions in a large social media text collection. It is implemented as a lightweight application that runs in the browser.	Mengdie Hu;Krist Wongsuphasawat;John T. Stasko	Georgia Institute of Technology;Twitter Inc.;Georgia Institute of Technology	10.1109/TVCG.2009.171;10.1109/TVCG.2008.172;10.1109/VAST.2009.5333443;10.1109/INFVIS.1995.528686;10.1109/TVCG.2010.154;10.1109/VAST.2012.6400485;10.1109/TVCG.2011.179;10.1109/TVCG.2010.194;10.1109/TVCG.2013.221;10.1109/TVCG.2006.156;10.1109/TVCG.2009.165;10.1109/VAST.2011.6102488;10.1109/TVCG.2014.2346920;10.1109/TVCG.2015.2467991;10.1109/TVCG.2011.239	text visualization;social media;natural language processing;word cloud;Twitter	Georgia Institute of Technology##Twitter Inc.##Georgia Institute of Technology
InfoVis	2016	Optimizing Hierarchical Visualizations with the Minimum Description Length Principle	10.1109/TVCG.2016.2598591	http://dx.doi.org/10.1109/TVCG.2016.2598591	631	640	J	In this paper we examine how the Minimum Description Length (MDL) principle can be used to efficiently select aggregated views of hierarchical datasets that feature a good balance between clutter and information. We present MDL formulae for generating uneven tree cuts tailored to treemap and sunburst diagrams, taking into account the available display space and information content of the data. We present the results of a proof-of-concept implementation. In addition, we demonstrate how such tree cuts can be used to enhance drill-down interaction in hierarchical visualizations by implementing our approach in an existing visualization tool. Validation is done with the feature congestion measure of clutter in views of a subset of the current DMOZ web directory, which contains nearly half million categories. The results show that MDL views achieve near constant clutter level across display resolutions. We also present the results of a crowdsourced user study where participants were asked to find targets in views of DMOZ generated by our approach and a set of baseline aggregation methods. The results suggest that, in some conditions, participants are able to locate targets (in particular, outliers) faster using the proposed approach.	Rafael Veras;Christopher Collins	University of OntarioInstitute of Technology;University of OntarioInstitute of Technology	10.1109/TVCG.2006.120;10.1109/TVCG.2007.70535;10.1109/INFVIS.1998.729557;10.1109/TVCG.2006.184;10.1109/TVCG.2012.233;10.1109/TVCG.2006.161	antichain;Hierarchy data;data aggregation;multiscale visualization;tree cut	University of OntarioInstitute of Technology##University of OntarioInstitute of Technology
InfoVis	2016	Visplause: Visual Data Quality Assessment of Many Time Series Using Plausibility Checks	10.1109/TVCG.2016.2598592	http://dx.doi.org/10.1109/TVCG.2016.2598592	641	650	J	Trends like decentralized energy production lead to an exploding number of time series from sensors and other sources that need to be assessed regarding their data quality (DQ). While the identification of DQ problems for such routinely collected data is typically based on existing automated plausibility checks, an efficient inspection and validation of check results for hundreds or thousands of time series is challenging. The main contribution of this paper is the validated design of Visplause, a system to support an efficient inspection of DQ problems for many time series. The key idea of Visplause is to utilize meta-information concerning the semantics of both the time series and the plausibility checks for structuring and summarizing results of DQ checks in a flexible way. Linked views enable users to inspect anomalies in detail and to generate hypotheses about possible causes. The design of Visplause was guided by goals derived from a comprehensive task analysis with domain experts in the energy sector. We reflect on the design process by discussing design decisions at four stages and we identify lessons learned. We also report feedback from domain experts after using Visplause for a period of one month. This feedback suggests significant efficiency gains for DQ assessment, increased confidence in the DQ, and the applicability of Visplause to summarize indicators also outside the context of DQ.	Clemens Arbesser;Florian Spechtenhauser;Thomas Mühlbacher;Harald Piringer	VrVis Research Center, Vienna, Austria;VrVis Research Center, Vienna, Austria;VrVis Research Center, Vienna, Austria;VrVis Research Center, Vienna, Austria	10.1109/TVCG.2014.2346248;10.1109/TVCG.2012.213;10.1109/TVCG.2012.256;10.1109/TVCG.2014.2346260;10.1109/VAST.2011.6102458;10.1109/TVCG.2009.110;10.1109/TVCG.2015.2466971	Data Quality Assessment;High-Dimensional Data;Hierarchical Aggregation;Linked Views	VrVis Research Center, Vienna, Austria##VrVis Research Center, Vienna, Austria##VrVis Research Center, Vienna, Austria##VrVis Research Center, Vienna, Austria
InfoVis	2016	The Attraction Effect in Information Visualization	10.1109/TVCG.2016.2598594	http://dx.doi.org/10.1109/TVCG.2016.2598594	471	480	J	The attraction effect is a well-studied cognitive bias in decision making research, where one's choice between two alternatives is influenced by the presence of an irrelevant (dominated) third alternative. We examine whether this cognitive bias, so far only tested with three alternatives and simple presentation formats such as numerical tables, text and pictures, also appears in visualizations. Since visualizations can be used to support decision making - e.g., when choosing a house to buy or an employee to hire - a systematic bias could have important implications. In a first crowdsource experiment, we indeed partially replicated the attraction effect with three alternatives presented as a numerical table, and observed similar effects when they were presented as a scatterplot. In a second experiment, we investigated if the effect extends to larger sets of alternatives, where the number of alternatives is too large for numerical tables to be practical. Our findings indicate that the bias persists for larger sets of alternatives presented as scatterplots. We discuss implications for future research on how to further study and possibly alleviate the attraction effect.	Evanthia Dimara;Anastasia Bezerianos;Pierre Dragicevic	Inria and UniversitÃ© Paris-Saclay;Inria, Univ Paris-Sud & CNRS (LRI)UniversitÃ© Paris-Saclay;Inria and UniversitÃ© Paris-Saclay	10.1109/TVCG.2008.153;10.1109/TVCG.2014.2346984;10.1109/VAST.2008.4677363;10.1109/TVCG.2014.2346298;10.1109/TVCG.2012.199;10.1109/TVCG.2010.174;10.1109/VAST.2009.5333920	cognitive bias;Information visualization;decision-making;decoy effect;attraction effect;asymmetric dominance effect	Inria and UniversitÃ© Paris-Saclay##Inria, Univ Paris-Sud & CNRS (LRI)UniversitÃ© Paris-Saclay##Inria and UniversitÃ© Paris-Saclay
InfoVis	2016	Embedded Data Representations	10.1109/TVCG.2016.2598608	http://dx.doi.org/10.1109/TVCG.2016.2598608	461	470	J	We introduce embedded data representations, the use of visual and physical representations of data that are deeply integrated with the physical spaces, objects, and entities to which the data refers. Technologies like lightweight wireless displays, mixed reality hardware, and autonomous vehicles are making it increasingly easier to display data in-context. While researchers and artists have already begun to create embedded data representations, the benefits, trade-offs, and even the language necessary to describe and compare these approaches remain unexplored. In this paper, we formalize the notion of physical data referents - the real-world entities and spaces to which data corresponds - and examine the relationship between referents and the visual and physical representations of their data. We differentiate situated representations, which display data in proximity to data referents, and embedded representations, which display data so that it spatially coincides with data referents. Drawing on examples from visualization, ubiquitous computing, and art, we explore the role of spatial indirection, scale, and interaction for embedded representations. We also examine the tradeoffs between non-situated, situated, and embedded data displays, including both visualizations and physicalizations. Based on our observations, we identify a variety of design challenges for embedded data representation, and suggest opportunities for future research and applications.	Wesley Willett;Yvonne Jansen;Pierre Dragicevic	University of Calgary;University of Copenhagen;Inria	10.1109/TVCG.2013.134;10.1109/INFVIS.1998.729560	augmented reality;Information visualization;data physicalization;ambient displays;ubiquitous computing	University of Calgary##University of Copenhagen##Inria
InfoVis	2016	Iterating between Tools to Create and Edit Visualizations	10.1109/TVCG.2016.2598609	http://dx.doi.org/10.1109/TVCG.2016.2598609	481	490	J	A common workflow for visualization designers begins with a generative tool, like D3 or Processing, to create the initial visualization; and proceeds to a drawing tool, like Adobe Illustrator or Inkscape, for editing and cleaning. Unfortunately, this is typically a one-way process: once a visualization is exported from the generative tool into a drawing tool, it is difficult to make further, data-driven changes. In this paper, we propose a bridge model to allow designers to bring their work back from the drawing tool to re-edit in the generative tool. Our key insight is to recast this iteration challenge as a merge problem - similar to when two people are editing a document and changes between them need to reconciled. We also present a specific instantiation of this model, a tool called Hanpuku, which bridges between D3 scripts and Illustrator. We show several examples of visualizations that are iteratively created using Hanpuku in order to illustrate the flexibility of the approach. We further describe several hypothetical tools that bridge between other visualization tools to emphasize the generality of the model.	Alex Bigelow;Steven M. Drucker;Danyel Fisher;Miriah D. Meyer	University of Utah;Microsoft Research;Microsoft Research;University of Utah	10.1109/TVCG.2014.2346292;10.1109/TVCG.2015.2467191;10.1109/TVCG.2014.2346291;10.1109/TVCG.2015.2467091;10.1109/INFVIS.2004.12;10.1109/TVCG.2011.209;10.1109/TVCG.2007.70584;10.1109/TVCG.2011.185	illustration;Visualization;iteration	University of Utah##Microsoft Research##Microsoft Research##University of Utah
InfoVis	2016	Surprise! Bayesian Weighting for De-Biasing Thematic Maps	10.1109/TVCG.2016.2598618	http://dx.doi.org/10.1109/TVCG.2016.2598618	651	660	J	Thematic maps are commonly used for visualizing the density of events in spatial data. However, these maps can mislead by giving visual prominence to known base rates (such as population densities) or to artifacts of sample size and normalization (such as outliers arising from smaller, and thus more variable, samples). In this work, we adapt Bayesian surprise to generate maps that counter these biases. Bayesian surprise, which has shown promise for modeling human visual attention, weights information with respect to how it updates beliefs over a space of models. We introduce Surprise Maps, a visualization technique that weights event data relative to a set of spatia-temporal models. Unexpected events (those that induce large changes in belief over the model space) are visualized more prominently than those that follow expected patterns. Using both synthetic and real-world datasets, we demonstrate how Surprise Maps overcome some limitations of traditional event maps.	Michael Correll;Jeffrey Heer	University of Washington;University of Washington	10.1109/TVCG.2014.2346248;10.1109/TVCG.2007.70561;10.1109/TVCG.2014.2346594;10.1109/TVCG.2014.2346325;10.1109/TVCG.2011.179;10.1109/TVCG.2014.2346298;10.1109/TVCG.2012.199;10.1109/INFVIS.2001.963274;10.1109/TVCG.2015.2467758;10.1109/TVCG.2013.184	Thematic Maps;Bayesian Surprise;Event Visualization;Spatia-temporal data	University of Washington##University of Washington
InfoVis	2016	Multi-Granular Trend Detection for Time-Series Analysis	10.1109/TVCG.2016.2598619	http://dx.doi.org/10.1109/TVCG.2016.2598619	661	670	J	Time series (such as stock prices) and ensembles (such as model runs for weather forecasts) are two important types of one-dimensional time-varying data. Such data is readily available in large quantities but visual analysis of the raw data quickly becomes infeasible, even for moderately sized data sets. Trend detection is an effective way to simplify time-varying data and to summarize salient information for visual display and interactive analysis. We propose a geometric model for trend-detection in one-dimensional time-varying data, inspired by topological grouping structures for moving objects in two- or higher-dimensional space. Our model gives provable guarantees on the trends detected and uses three natural parameters: granularity, support-size, and duration. These parameters can be changed on-demand. Our system also supports a variety of selection brushes and a time-sweep to facilitate refined searches and interactive visualization of (sub-)trends. We explore different visual styles and interactions through which trends, their persistence, and evolution can be explored.	Goethem Arthur Van;Frank Staals;Maarten Löffler;Jason Dykes;Bettina Speckmann	TU, Eindhoven;MADALGO, Aarhus University;Utrecht University;City University, London;TU, Eindhoven	10.1109/TVCG.2015.2467204;10.1109/TVCG.2010.181;10.1109/TVCG.2006.147;10.1109/TVCG.2014.2346448;10.1109/TVCG.2007.70558;10.1109/TVCG.2008.166;10.1109/TVCG.2008.125;10.1109/TVCG.2014.2346455	Interactive Exploration;Trend Detection;Time Series	TU, Eindhoven##MADALGO, Aarhus University##Utrecht University##City University, London##TU, Eindhoven
InfoVis	2016	Data-Driven Guides: Supporting Expressive Design for Information Graphics	10.1109/TVCG.2016.2598620	http://dx.doi.org/10.1109/TVCG.2016.2598620	491	500	J	In recent years, there is a growing need for communicating complex data in an accessible graphical form. Existing visualization creation tools support automatic visual encoding, but lack flexibility for creating custom design; on the other hand, freeform illustration tools require manual visual encoding, making the design process time-consuming and error-prone. In this paper, we present Data-Driven Guides (DDG), a technique for designing expressive information graphics in a graphic design environment. Instead of being confined by predefined templates or marks, designers can generate guides from data and use the guides to draw, place and measure custom shapes. We provide guides to encode data using three fundamental visual encoding channels: length, area, and position. Users can combine more than one guide to construct complex visual structures and map these structures to data. When underlying data is changed, we use a deformation technique to transform custom shapes using the guides as the backbone of the shapes. Our evaluation shows that data-driven guides allow users to create expressive and more accurate custom data-driven graphics.	Nam Wook Kim;Eston Schweickart;Zhicheng Liu;Mira Dontcheva;Wilmot Li;Jovan Popovic;Hanspeter Pfister	John A. Paulson School of Engineering and Applied SciencesHarvard University;Computer Science department, Cornell University;Adobe Research;Adobe Research;Adobe Research;Adobe Research;John A. Paulson School of Engineering and Applied SciencesHarvard University	10.1109/TVCG.2014.2346292;10.1109/INFVIS.1996.559212;10.1109/TVCG.2011.175;10.1109/TVCG.2016.2598609;10.1109/TVCG.2013.234;10.1109/INFVIS.2004.64;10.1109/TVCG.2012.197;10.1109/INFVIS.2000.885086;10.1109/INFVIS.2000.885093;10.1109/TVCG.2014.2346979;10.1109/TVCG.2014.2346320;10.1109/TVCG.2014.2346291;10.1109/TVCG.2015.2467732;10.1109/INFVIS.2004.12;10.1109/TVCG.2013.191;10.1109/TVCG.2011.251;10.1109/TVCG.2010.144;10.1109/TVCG.2011.185;10.1109/TVCG.2007.70577	Information graphics;visualization;design tools;2D graphics	John A. Paulson School of Engineering and Applied SciencesHarvard University##Computer Science department, Cornell University##Adobe Research##Adobe Research##Adobe Research##Adobe Research##John A. Paulson School of Engineering and Applied SciencesHarvard University
InfoVis	2016	Hashedcubes: Simple, Low Memory, Real-Time Visual Exploration of Big Data	10.1109/TVCG.2016.2598624	http://dx.doi.org/10.1109/TVCG.2016.2598624	671	680	J	We propose Hashedcubes, a data structure that enables real-time visual exploration of large datasets that improves the state of the art by virtue of its low memory requirements, low query latencies, and implementation simplicity. In some instances, Hashedcubes notably requires two orders of magnitude less space than recent data cube visualization proposals. In this paper, we describe the algorithms to build and query Hashedcubes, and how it can drive well-known interactive visualizations such as binned scatterplots, linked histograms and heatmaps. We report memory usage, build time and query latencies for a variety of synthetic and real-world datasets, and find that although sometimes Hashedcubes offers slightly slower querying times to the state of the art, the typical query is answered fast enough to easily sustain a interaction. In datasets with hundreds of millions of elements, only about 2% of the queries take longer than 40ms. Finally, we discuss the limitations of data structure, potential spacetime tradeoffs, and future research directions.	Cicero Augusto de Lara Pahins;Sean A. Stephens;Carlos Eduardo Scheidegger;João Luiz Dihl Comba	Instituto de InformÃ¡ticaUFRGS;University of Arizona;University of Arizona;Instituto de InformÃ¡ticaUFRGS	10.1109/TVCG.2013.179;10.1109/TVCG.2014.2346452;10.1109/TVCG.2014.2346574;10.1109/TVCG.2015.2467771	Scalability;data cube;multidimensional data;interactive exploration	Instituto de InformÃ¡ticaUFRGS##University of Arizona##University of Arizona##Instituto de InformÃ¡ticaUFRGS
InfoVis	2016	Authoring Data-Driven Videos with DataClips	10.1109/TVCG.2016.2598647	http://dx.doi.org/10.1109/TVCG.2016.2598647	501	510	J	Data videos, or short data-driven motion graphics, are an increasingly popular medium for storytelling. However, creating data videos is difficult as it involves pulling together a unique combination of skills. We introduce DataClips, an authoring tool aimed at lowering the barriers to crafting data videos. DataClips allows non-experts to assemble data-driven &#x201C;clips&#x201D; together to form longer sequences. We constructed the library of data clips by analyzing the composition of over 70 data videos produced by reputable sources such as The New York Times and The Guardian. We demonstrate that DataClips can reproduce over 90% of our data videos corpus. We also report on a qualitative study comparing the authoring process and outcome achieved by (1) non-experts using DataClips, and (2) experts using Adobe Illustrator and After Effects to create data-driven clips. Results indicated that non-experts are able to learn and use DataClips with a short training period. In the span of one hour, they were able to produce more videos than experts using a professional editing tool, and their clips were rated similarly by an independent audience.	Fereshteh Amini;Nathalie Henry Riche;Bongshin Lee;Andres Monroy-Hernández;Pourang Irani	University of Manitoba, Canada;Microsoft;Microsoft;Microsoft;University of Manitoba, Canada	10.1109/TVCG.2007.70539;10.1109/TVCG.2008.137;10.1109/VAST.2007.4388992;10.1109/TVCG.2013.234;10.1109/TVCG.2013.119;10.1109/TVCG.2011.255;10.1109/TVCG.2010.179;10.1109/VAST.2012.6400487	data video;narrative visualization;data storytelling;authoring tools;visualization systems	University of Manitoba, Canada##Microsoft##Microsoft##Microsoft##University of Manitoba, Canada
InfoVis	2016	cite2vec: Citation-Driven Document Exploration via Word Embeddings	10.1109/TVCG.2016.2598667	http://dx.doi.org/10.1109/TVCG.2016.2598667	691	700	J	Effectively exploring and browsing document collections is a fundamental problem in visualization. Traditionally, document visualization is based on a data model that represents each document as the set of its comprised words, effectively characterizing what the document is. In this paper we take an alternative perspective: motivated by the manner in which users search documents in the research process, we aim to visualize documents via their usage, or how documents tend to be used. We present a new visualization scheme - cite2vec - that allows the user to dynamically explore and browse documents via how other documents use them, information that we capture through citation contexts in a document collection. Starting from a usage-oriented word-document 2D projection, the user can dynamically steer document projections by prescribing semantic concepts, both in the form of phrase/document compositions and document:phrase analogies, enabling the exploration and comparison of documents by their use. The user interactions are enabled by a joint representation of words and documents in a common high-dimensional embedding space where user-specified concepts correspond to linear operations of word and document vectors. Our case studies, centered around a large document corpus of computer vision research papers, highlight the potential for usage-based document visualization.	Matthew Berger;Katherine McDonough;Lee M. Seversky	Air Force Research Laboratory;Northeastern University;Air Force Research Laboratory	10.1109/TVCG.2014.2346431;10.1109/VAST.2011.6102461;10.1109/TVCG.2011.220;10.1109/TVCG.2015.2467451;10.1109/TVCG.2010.207;10.1109/TVCG.2014.2346978;10.1109/TVCG.2015.2467757;10.1109/VAST.2009.5333428;10.1109/TVCG.2013.212;10.1109/TVCG.2015.2467621;10.1109/VAST.2014.7042493;10.1109/TVCG.2013.162;10.1109/TVCG.2009.202;10.1109/TVCG.2008.138	word embeddings;document visualization	Air Force Research Laboratory##Northeastern University##Air Force Research Laboratory
InfoVis	2016	Gaussian Cubes: Real-Time Modeling for Visual Exploration of Large Multidimensional Datasets	10.1109/TVCG.2016.2598694	http://dx.doi.org/10.1109/TVCG.2016.2598694	681	690	J	Recently proposed techniques have finally made it possible for analysts to interactively explore very large datasets in real time. However powerful, the class of analyses these systems enable is somewhat limited: specifically, one can only quickly obtain plots such as histograms and heatmaps. In this paper, we contribute Gaussian Cubes, which significantly improves on state-of-the-art systems by providing interactive modeling capabilities, which include but are not limited to linear least squares and principal components analysis (PCA). The fundamental insight in Gaussian Cubes is that instead of precomputing counts of many data subsets (as state-of-the-art systems do), Gaussian Cubes precomputes the best multivariate Gaussian for the respective data subsets. As an example, Gaussian Cubes can fit hundreds of models over millions of data points in well under a second, enabling novel types of visual exploration of such large datasets. We present three case studies that highlight the visualization and analysis capabilities in Gaussian Cubes, using earthquake safety simulations, astronomical catalogs, and transportation statistics. The dataset sizes range around one hundred million elements and 5 to 10 dimensions. We present extensive performance results, a discussion of the limitations in Gaussian Cubes, and future research directions.	Zhe Wang;Nivan Ferreira;Youhao Wei;Aarthy Sankari Bhaskar;Carlos Eduardo Scheidegger	University of Arizona;Universidade Federal de Pernambuco;University of Arizona;University of Arizona;University of Arizona	10.1109/VAST.2008.4677357;10.1109/INFVIS.2000.885086;10.1109/TVCG.2013.179;10.1109/TVCG.2014.2346452;10.1109/TVCG.2009.129;10.1109/TVCG.2013.141;10.1109/TVCG.2014.2346325;10.1109/VAST.2012.6400490	data cubes;Data modeling;dimensionality reduction;interactive visualization	University of Arizona##Universidade Federal de Pernambuco##University of Arizona##University of Arizona##University of Arizona
InfoVis	2016	Visualization by Demonstration: An Interaction Paradigm for Visual Data Exploration	10.1109/TVCG.2016.2598839	http://dx.doi.org/10.1109/TVCG.2016.2598839	331	340	J	Although data visualization tools continue to improve, during the data exploration process many of them require users to manually specify visualization techniques, mappings, and parameters. In response, we present the Visualization by Demonstration paradigm, a novel interaction method for visual data exploration. A system which adopts this paradigm allows users to provide visual demonstrations of incremental changes to the visual representation. The system then recommends potential transformations (Visual Representation, Data Mapping, Axes, and View Specification transformations) from the given demonstrations. The user and the system continue to collaborate, incrementally producing more demonstrations and refining the transformations, until the most effective possible visualization is created. As a proof of concept, we present VisExemplar, a mixed-initiative prototype that allows users to explore their data by recommending appropriate transformations in response to the given demonstrations.	Bahador Saket;Hannah Kim;Eli T. Brown;Alex Endert	Georgia Institute of Technology;Georgia Institute of Technology;DePaul University;Georgia Institute of Technology	10.1109/TVCG.2014.2346292;10.1109/TVCG.2015.2467191;10.1109/TVCG.2007.70594;10.1109/VAST.2011.6102449;10.1109/TVCG.2007.70515;10.1109/TVCG.2014.2346250;10.1109/TVCG.2012.275;10.1109/TVCG.2015.2467153;10.1109/TVCG.2013.191;10.1109/TVCG.2011.251;10.1109/TVCG.2011.185;10.1109/TVCG.2014.2346291;10.1109/VAST.2012.6400486	Visual Data Exploration;Visualization by Demonstration;Visualization Tools	Georgia Institute of Technology##Georgia Institute of Technology##DePaul University##Georgia Institute of Technology
InfoVis	2016	Map LineUps: Effects of spatial structure on graphical inference	10.1109/TVCG.2016.2598862	http://dx.doi.org/10.1109/TVCG.2016.2598862	391	400	J	Fundamental to the effective use of visualization as an analytic and descriptive tool is the assurance that presenting data visually provides the capability of making inferences from what we see. This paper explores two related approaches to quantifying the confidence we may have in making visual inferences from mapped geospatial data. We adapt Wickham et al.'s `Visual Line-up' method as a direct analogy with Null Hypothesis Significance Testing (NHST) and propose a new approach for generating more credible spatial null hypotheses. Rather than using as a spatial null hypothesis the unrealistic assumption of complete spatial randomness, we propose spatially autocorrelated simulations as alternative nulls. We conduct a set of crowdsourced experiments (n=361) to determine the just noticeable difference (JND) between pairs of choropleth maps of geographic units controlling for spatial autocorrelation (Moran's I statistic) and geometric configuration (variance in spatial unit area). Results indicate that people's abilities to perceive differences in spatial autocorrelation vary with baseline autocorrelation structure and the geometric configuration of geographic units. These results allow us, for the first time, to construct a visual equivalent of statistical power for geospatial data. Our JND results add to those provided in recent years by Klippel et al. (2011), Harrison et al. (2014) and Kay &amp; Heer (2015) for correlation visualization. Importantly, they provide an empirical basis for an improved construction of visual line-ups for maps and the development of theory to inform geospatial tests of graphical inference.	Roger Beecham;Jason Dykes;Wouter Meulemans;Aidan Slingsby;Cagatay Turkay;Jo Wood	giCentre, City University London;giCentre, City University London;giCentre, City University London;giCentre, City University London;giCentre, City University London;giCentre, City University London	10.1109/TVCG.2015.2467671;10.1109/TVCG.2015.2469125;10.1109/TVCG.2014.2346979;10.1109/TVCG.2010.161	Graphical inference;spatial autocorrelation;just noticeable difference;geovisualization;statistical significance	giCentre, City University London##giCentre, City University London##giCentre, City University London##giCentre, City University London##giCentre, City University London##giCentre, City University London
InfoVis	2016	Evaluation of Graph Sampling: A Visualization Perspective	10.1109/TVCG.2016.2598867	http://dx.doi.org/10.1109/TVCG.2016.2598867	401	410	J	Graph sampling is frequently used to address scalability issues when analyzing large graphs. Many algorithms have been proposed to sample graphs, and the performance of these algorithms has been quantified through metrics based on graph structural properties preserved by the sampling: degree distribution, clustering coefficient, and others. However, a perspective that is missing is the impact of these sampling strategies on the resultant visualizations. In this paper, we present the results of three user studies that investigate how sampling strategies influence node-link visualizations of graphs. In particular, five sampling strategies widely used in the graph mining literature are tested to determine how well they preserve visual features in node-link diagrams. Our results show that depending on the sampling strategy used different visual features are preserved. These results provide a complimentary view to metric evaluations conducted in the graph mining literature and provide an impetus to conduct future visualization studies.	Yanhong Wu;Nan Cao;Daniel Archambault;Qiaomu Shen;Huamin Qu;Weiwei Cui	Hong Kong University of Science and Technology;New York University, Shanghai;Swansea University;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Microsoft Research Asia	10.1109/TVCG.2015.2468151;10.1109/VISUAL.2005.1532819;10.1109/TVCG.2008.151;10.1109/TVCG.2006.147;10.1109/TVCG.2006.120;10.1109/INFVIS.2004.1;10.1109/TVCG.2007.70535;10.1109/TVCG.2008.135;10.1109/TVCG.2012.238;10.1109/TVCG.2013.232	Graph visualization;graph sampling;empirical evaluation	Hong Kong University of Science and Technology##New York University, Shanghai##Swansea University##Hong Kong University of Science and Technology##Hong Kong University of Science and Technology##Microsoft Research Asia
InfoVis	2016	Temporal Summary Images: An Approach to Narrative Visualization via Interactive Annotation Generation and Placement	10.1109/TVCG.2016.2598876	http://dx.doi.org/10.1109/TVCG.2016.2598876	511	520	J	Visualization is a powerful technique for analysis and communication of complex, multidimensional, and time-varying data. However, it can be difficult to manually synthesize a coherent narrative in a chart or graph due to the quantity of visualized attributes, a variety of salient features, and the awareness required to interpret points of interest (POls). We present Temporal Summary Images (TSIs) as an approach for both exploring this data and creating stories from it. As a visualization, a TSI is composed of three common components: (1) a temporal layout, (2) comic strip-style data snapshots, and (3) textual annotations. To augment user analysis and exploration, we have developed a number of interactive techniques that recommend relevant data features and design choices, including an automatic annotations workflow. As the analysis and visual design processes converge, the resultant image becomes appropriate for data storytelling. For validation, we use a prototype implementation for TSIs to conduct two case studies with large-scale, scientific simulation datasets.	Chris Bryan;Kwan-Liu Ma;Jonathan Woodring	University of California, Davis;University of California, Davis;Los Alamos National Laboratory	10.1109/TVCG.2008.166;10.1109/TVCG.2007.70594;10.1109/TVCG.2011.255;10.1109/TVCG.2010.179;10.1109/VAST.2010.5652890;10.1109/TVCG.2012.229;10.1109/TVCG.2012.212;10.1109/TVCG.2011.195;10.1109/VAST.2012.6400487	Narrative visualization;storytelling;annotations;comic strip visualization;time-varying data	University of California, Davis##University of California, Davis##Los Alamos National Laboratory
InfoVis	2016	Many-to-Many Geographically-Embedded Flow Visualisation: An Evaluation	10.1109/TVCG.2016.2598885	http://dx.doi.org/10.1109/TVCG.2016.2598885	411	420	J	Showing flows of people and resources between multiple geographic locations is a challenging visualisation problem. We conducted two quantitative user studies to evaluate different visual representations for such dense many-to-many flows. In our first study we compared a bundled node-link flow map representation and OD Maps [37] with a new visualisation we call MapTrix. Like OD Maps, MapTrix overcomes the clutter associated with a traditional flow map while providing geographic embedding that is missing in standard OD matrix representations. We found that OD Maps and MapTrix had similar performance while bundled node-link flow map representations did not scale at all well. Our second study compared participant performance with OD Maps and MapTrix on larger data sets. Again performance was remarkably similar.	Yalong Yang;Tim Dwyer;Sarah Goodwin;Kim Marriott	Monash University, Data61, CSIRO, Victoria;Monash University;Monash University;Monash University, Data61, CSIRO, Victoria	10.1109/INFVIS.2004.1;10.1109/TVCG.2011.202;10.1109/TVCG.2014.2346441;10.1109/TVCG.2008.165;10.1109/INFVIS.2005.1532150	Flow Maps;Matrix Visualisation;Cartographic Information Visualisation	Monash University, Data61, CSIRO, Victoria##Monash University##Monash University##Monash University, Data61, CSIRO, Victoria
InfoVis	2016	An Evaluation of Visual Search Support in Maps	10.1109/TVCG.2016.2598898	http://dx.doi.org/10.1109/TVCG.2016.2598898	421	430	J	Visual search can be time-consuming, especially if the scene contains a large number of possibly relevant objects. An instance of this problem is present when using geographic or schematic maps with many different elements representing cities, streets, sights, and the like. Unless the map is well-known to the reader, the full map or at least large parts of it must be scanned to find the elements of interest. In this paper, we present a controlled eye-tracking study (30 participants) to compare four variants of map annotation with labels: within-image annotations, grid reference annotation, directional annotation, and miniature annotation. Within-image annotation places labels directly within the map without any further search support. Grid reference annotation corresponds to the traditional approach known from atlases. Directional annotation utilizes a label in combination with an arrow pointing in the direction of the label within the map. Miniature annotation shows a miniature grid to guide the reader to the area of the map in which the label is located. The study results show that within-image annotation is outperformed by all other annotation approaches. Best task completion times are achieved with miniature annotation. The analysis of eye-movement data reveals that participants applied significantly different visual task solution strategies for the different visual annotations.	Rudolf Netzel;Marcel Hlawatsch;Michael Burch;Sanjeev Balakrishnan;Hansjörg Schmauder;Daniel Weiskopf	VISUS, University of Stuttgart;VISUS, University of Stuttgart;VISUS, University of Stuttgart;VISUS, University of Stuttgart;VISUS, University of Stuttgart;VISUS, University of Stuttgart	10.1109/TVCG.2014.2346420;10.1109/TVCG.2010.191	Visual search;laboratory study;eye tracking;map visualization	VISUS, University of Stuttgart##VISUS, University of Stuttgart##VISUS, University of Stuttgart##VISUS, University of Stuttgart##VISUS, University of Stuttgart##VISUS, University of Stuttgart
InfoVis	2016	Colorgorical: Creating discriminable and preferable color palettes for information visualization	10.1109/TVCG.2016.2598918	http://dx.doi.org/10.1109/TVCG.2016.2598918	521	530	J	We present an evaluation of Colorgorical, a web-based tool for creating discriminable and aesthetically preferable categorical color palettes. Colorgorical uses iterative semi-random sampling to pick colors from CIELAB space based on user-defined discriminability and preference importances. Colors are selected by assigning each a weighted sum score that applies the user-defined importances to Perceptual Distance, Name Difference, Name Uniqueness, and Pair Preference scoring functions, which compare a potential sample to already-picked palette colors. After, a color is added to the palette by randomly sampling from the highest scoring palettes. Users can also specify hue ranges or build off their own starting palettes. This procedure differs from previous approaches that do not allow customization (e.g., pre-made ColorBrewer palettes) or do not consider visualization design constraints (e.g., Adobe Color and ACE). In a Palette Score Evaluation, we verified that each scoring function measured different color information. Experiment 1 demonstrated that slider manipulation generates palettes that are consistent with the expected balance of discriminability and aesthetic preference for 3-, 5-, and 8-color palettes, and also shows that the number of colors may change the effectiveness of pair-based discriminability and preference scores. For instance, if the Pair Preference slider were upweighted, users would judge the palettes as more preferable on average. Experiment 2 compared Colorgorical palettes to benchmark palettes (ColorBrewer, Microsoft, Tableau, Random). Colorgorical palettes are as discriminable and are at least as preferable or more preferable than the alternative palette sets. In sum, Colorgorical allows users to make customized color palettes that are, on average, as effective as current industry standards by balancing the importance of discriminability and aesthetic preference.	Connor Gramazio;David H. Laidlaw;Karen B. Schloss	Dept. of Computer Science at Brown University;Dept. of Computer Science at Brown University;Dept. of Cognitive, Linguistic, and Psychological Sciences at Brown University	10.1109/VISUAL.1996.568118;10.1109/TVCG.2014.2346978;10.1109/TVCG.2015.2467471;10.1109/TVCG.2014.2346983;10.1109/TVCG.2012.233	Aesthetics in Visualization;Color Perception;Metrics & Benchmarks;Visual Design;Visualization	Dept. of Computer Science at Brown University##Dept. of Computer Science at Brown University##Dept. of Cognitive, Linguistic, and Psychological Sciences at Brown University
InfoVis	2016	Probabilistic Graph Layout for Uncertain Network Visualization	10.1109/TVCG.2016.2598919	http://dx.doi.org/10.1109/TVCG.2016.2598919	531	540	J	We present a novel uncertain network visualization technique based on node-link diagrams. Nodes expand spatially in our probabilistic graph layout, depending on the underlying probability distributions of edges. The visualization is created by computing a two-dimensional graph embedding that combines samples from the probabilistic graph. A Monte Carlo process is used to decompose a probabilistic graph into its possible instances and to continue with our graph layout technique. Splatting and edge bundling are used to visualize point clouds and network topology. The results provide insights into probability distributions for the entire network-not only for individual nodes and edges. We validate our approach using three data sets that represent a wide range of network types: synthetic data, protein-protein interactions from the STRING database, and travel times extracted from Google Maps. Our approach reveals general limitations of the force-directed layout and allows the user to recognize that some nodes of the graph are at a specific position just by chance.	Christoph Schulz;Arlind Nocaj;Jochen Görtler;Oliver Deussen;Ulrik Brandes;Daniel Weiskopf	VISUSUniversity of Stuttgart;University of Konstanz;University of Konstanz;University of Konstanz;University of Konstanz;VISUSUniversity of Stuttgart	10.1109/TVCG.2006.147;10.1109/TVCG.2010.176;10.1109/TVCG.2009.150;10.1109/TVCG.2009.127;10.1109/TVCG.2015.2467691;10.1109/TVCG.2015.2467591;10.1109/VAST.2009.5332611;10.1109/TVCG.2009.122;10.1109/TVCG.2013.232	Uncertainty visualization;graph layout;graph visualization;edge bundling;Monte Carlo method	VISUSUniversity of Stuttgart##University of Konstanz##University of Konstanz##University of Konstanz##University of Konstanz##VISUSUniversity of Stuttgart
InfoVis	2016	VLAT: Development of a Visualization Literacy Assessment Test	10.1109/TVCG.2016.2598920	http://dx.doi.org/10.1109/TVCG.2016.2598920	551	560	J	The Information Visualization community has begun to pay attention to visualization literacy; however, researchers still lack instruments for measuring the visualization literacy of users. In order to address this gap, we systematically developed a visualization literacy assessment test (VLAT), especially for non-expert users in data visualization, by following the established procedure of test development in Psychological and Educational Measurement: (1) Test Blueprint Construction, (2) Test Item Generation, (3) Content Validity Evaluation, (4) Test Tryout and Item Analysis, (5) Test Item Selection, and (6) Reliability Evaluation. The VLAT consists of 12 data visualizations and 53 multiple-choice test items that cover eight data visualization tasks. The test items in the VLAT were evaluated with respect to their essentialness by five domain experts in Information Visualization and Visual Analytics (average content validity ratio = 0.66). The VLAT was also tried out on a sample of 191 test takers and showed high reliability (reliability coefficient omega = 0.76). In addition, we demonstrated the relationship between users' visualization literacy and aptitude for learning an unfamiliar visualization and showed that they had a fairly high positive relationship (correlation coefficient = 0.64). Finally, we discuss evidence for the validity of the VLAT and potential research areas that are related to the instrument.	Sukwon Lee;Sung-Hee Kim;Bum Chul Kwon	School of Industrial Engineering, Purdue University, West Lafayette, IN, USA;Samsung Electronics Co., Ltd., Seoul, South Korea;IBM T.J. Watson Research Center, Yorktown Heights, NY, USA	10.1109/TVCG.2014.2346419;10.1109/TVCG.2014.2346481;10.1109/TVCG.2014.2346984;10.1109/VISUAL.1991.175815;10.1109/TVCG.2007.70515;10.1109/TVCG.2015.2467195;10.1109/VAST.2011.6102435;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2013.124;10.1109/TVCG.2015.2467201	Visualization Literacy;Assessment Test;Instrument;Measurement;Aptitude;Education	School of Industrial Engineering, Purdue University, West Lafayette, IN, USA##Samsung Electronics Co., Ltd., Seoul, South Korea##IBM T.J. Watson Research Center, Yorktown Heights, NY, USA
InfoVis	2016	Towards Unambiguous Edge Bundling: Investigating Confluent Drawings for Network Visualization	10.1109/TVCG.2016.2598958	http://dx.doi.org/10.1109/TVCG.2016.2598958	541	550	J	In this paper, we investigate Confluent Drawings (CD), a technique for bundling edges in node-link diagrams based on network connectivity. Edge-bundling techniques are designed to reduce edge clutter in node-link diagrams by coalescing lines into common paths or bundles. Unfortunately, traditional bundling techniques introduce ambiguity since edges are only bundled by spatial proximity, rather than network connectivity; following an edge from its source to its target can lead to the perception of incorrect connectivity if edges are not clearly separated within the bundles. Contrary, CDs bundle edges based on common sources or targets. Thus, a smooth path along a confluent bundle indicates precise connectivity. While CDs have been described in theory, practical investigation and application to real-world networks (i.e., networks beyond those with certain planarity restrictions) is currently lacking. Here, we provide the first algorithm for constructing CDs from arbitrary directed and undirected networks and present a simple layout method, embedded in a sand box environment providing techniques for interactive exploration. We then investigate patterns and artifacts in CDs, which we compare to other common edge-bundling techniques. Finally, we present the first user study that compares edge-compression techniques, including CD, power graphs, metro-style, and common edge bundling. We found that users without particular expertise in visualization or network analysis are able to read small CDs without difficulty. Compared to existing bundling techniques, CDs are more likely to allow people to correctly perceive connectivity.	Benjamin Bach;Nathalie Henry Riche;Christophe Hurter;Kim Marriott;Tim Dwyer	Microsoft Research-Inria Joint Centre, France;Microsoft Research, WA, USA;ENAC, Toulouse, France;Monash University, Melbourne, Australia;Monash University, Melbourne, Australia	10.1109/TVCG.2006.120;10.1109/TVCG.2006.147;10.1109/TVCG.2011.233;10.1109/TVCG.2011.190;10.1109/INFVIS.2003.1249008;10.1109/TVCG.2012.208;10.1109/TVCG.2006.160;10.1109/TVCG.2013.151;10.1109/INFVIS.2005.1532150	bundling;Network visualization;edge compression;confluent;power graph	Microsoft Research-Inria Joint Centre, France##Microsoft Research, WA, USA##ENAC, Toulouse, France##Monash University, Melbourne, Australia##Monash University, Melbourne, Australia
InfoVis	2016	Vega-Lite: A Grammar of Interactive Graphics	10.1109/TVCG.2016.2599030	http://dx.doi.org/10.1109/TVCG.2016.2599030	341	350	J	We present Vega-Lite, a high-level grammar that enables rapid specification of interactive data visualizations. Vega-Lite combines a traditional grammar of graphics, providing visual encoding rules and a composition algebra for layered and multi-view displays, with a novel grammar of interaction. Users specify interactive semantics by composing selections. In Vega-Lite, a selection is an abstraction that defines input event processing, points of interest, and a predicate function for inclusion testing. Selections parameterize visual encodings by serving as input data, defining scale extents, or by driving conditional logic. The Vega-Lite compiler automatically synthesizes requisite data flow and event handling logic, which users can override for further customization. In contrast to existing reactive specifications, Vega-Lite selections decompose an interaction design into concise, enumerable semantic units. We evaluate Vega-Lite through a range of examples, demonstrating succinct specification of both customized interaction methods and common techniques such as panning, zooming, and linked selection.	Arvind Satyanarayan;Dominik Moritz;Kanit Wongsuphasawat;Jeffrey Heer	Stanford University;University of Washington;University of Washington;University of Washington	10.1109/TVCG.2015.2467091;10.1109/TVCG.2009.174;10.1109/TVCG.2015.2467191;10.1109/TVCG.2014.2346260;10.1109/INFVIS.2000.885086;10.1109/TVCG.2007.70515;10.1109/TVCG.2011.185	Information visualization;interaction;systems;toolkits;declarative specification	Stanford University##University of Washington##University of Washington##University of Washington
InfoVis	2016	HindSight: Encouraging Exploration through Direct Encoding of Personal Interaction History	10.1109/TVCG.2016.2599058	http://dx.doi.org/10.1109/TVCG.2016.2599058	351	360	J	Physical and digital objects often leave markers of our use. Website links turn purple after we visit them, for example, showing us information we have yet to explore. These &#x201C;footprints&#x201D; of interaction offer substantial benefits in information saturated environments - they enable us to easily revisit old information, systematically explore new information, and quickly resume tasks after interruption. While applying these design principles have been successful in HCI contexts, direct encodings of personal interaction history have received scarce attention in data visualization. One reason is that there is little guidance for integrating history into visualizations where many visual channels are already occupied by data. More importantly, there is not firm evidence that making users aware of their interaction history results in benefits with regards to exploration or insights. Following these observations, we propose HindSight - an umbrella term for the design space of representing interaction history directly in existing data visualizations. In this paper, we examine the value of HindSight principles by augmenting existing visualizations with visual indicators of user interaction history (e.g. How the Recession Shaped the Economy in 255 Charts, NYTimes). In controlled experiments of over 400 participants, we found that HindSight designs generally encouraged people to visit more data and recall different insights after interaction. The results of our experiments suggest that simple additions to visualizations can make users aware of their interaction history, and that these additions significantly impact users' exploration and insights.	Mi Feng;Cheng Deng;Evan M. Peck;Lane Harrison	Worcester Polytechnic Institute;Worcester Polytechnic Institute;Bucknell University;Worcester Polytechnic Institute	10.1109/VISUAL.2002.1183791;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2014.2346452;10.1109/TVCG.2008.137;10.1109/TVCG.2014.2346424;10.1109/TVCG.2007.70589;10.1109/TVCG.2008.109	History;Visualization;Interaction	Worcester Polytechnic Institute##Worcester Polytechnic Institute##Bucknell University##Worcester Polytechnic Institute
InfoVis	2016	Evaluating the Impact of Binning 2D Scalar Fields	10.1109/TVCG.2016.2599106	http://dx.doi.org/10.1109/TVCG.2016.2599106	431	440	J	The expressiveness principle for visualization design asserts that a visualization should encode all of the available data, and only the available data, implying that continuous data types should be visualized with a continuous encoding channel. And yet, in many domains binning continuous data is not only pervasive, but it is accepted as standard practice. Prior work provides no clear guidance for when encoding continuous data continuously is preferable to employing binning techniques or how this choice affects data interpretation and decision making. In this paper, we present a study aimed at better understanding the conditions in which the expressiveness principle can or should be violated for visualizing continuous data. We provided participants with visualizations employing either continuous or binned greyscale encodings of geospatial elevation data and compared participants' ability to complete a wide variety of tasks. For various tasks, the results indicate significant differences in decision making, confidence in responses, and task completion time between continuous and binned encodings of the data. In general, participants with continuous encodings were faster to complete many of the tasks, but never outperformed those with binned encodings, while performance accuracy with binned encodings was superior to continuous encodings in some tasks. These findings suggest that strict adherence to the expressiveness principle is not always advisable. We discuss both the implications and limitations of our results and outline various avenues for potential work needed to further improve guidelines for using continuous versus binned encodings for continuous data types.	Lace M. K. Padilla;P. Samuel Quinan;Miriah D. Meyer;Sarah H. Creem-Regehr	Department of Psychology, University of Utah;University of UtahSchool of Computing;University of UtahSchool of Computing;Department of Psychology, University of Utah	10.1109/TVCG.2011.175;10.1109/TVCG.2015.2467754;10.1109/VISUAL.1999.809932;10.1109/VISUAL.1996.568118;10.1109/VISUAL.1995.480803;10.1109/TVCG.2013.124	Geographic/Geospatial Visualization;Qualitative Evaluation;Color Perception;Perceptual Cognition	Department of Psychology, University of Utah##University of UtahSchool of Computing##University of UtahSchool of Computing##Department of Psychology, University of Utah
InfoVis	2016	Immersive Collaborative Analysis of Network Connectivity: CAVE-style or Head-Mounted Display?	10.1109/TVCG.2016.2599107	http://dx.doi.org/10.1109/TVCG.2016.2599107	441	450	J	High-quality immersive display technologies are becoming mainstream with the release of head-mounted displays (HMDs) such as the Oculus Rift. These devices potentially represent an affordable alternative to the more traditional, centralised CAVE-style immersive environments. One driver for the development of CAVE-style immersive environments has been collaborative sense-making. Despite this, there has been little research on the effectiveness of collaborative visualisation in CAVE-style facilities, especially with respect to abstract data visualisation tasks. Indeed, very few studies have focused on the use of these displays to explore and analyse abstract data such as networks and there have been no formal user studies investigating collaborative visualisation of abstract data in immersive environments. In this paper we present the results of the first such study. It explores the relative merits of HMD and CAVE-style immersive environments for collaborative analysis of network connectivity, a common and important task involving abstract data. We find significant differences between the two conditions in task completion time and the physical movements of the participants within the space: participants using the HMD were faster while the CAVE2 condition introduced an asymmetry in movement between collaborators. Otherwise, affordances for collaborative data analysis offered by the low-cost HMD condition were not found to be different for accuracy and communication with the CAVE2. These results are notable, given that the latest HMDs will soon be accessible (in terms of cost and potentially ubiquity) to a massive audience.	Maxime Cordeil;Tim Dwyer;Karsten Klein;Bireswar Laha;Kim Marriott;Bruce H. Thomas	Monash University;Monash University;Monash University;Stanford University, USA;Monash University;University of South Australia	10.1109/VISUAL.2001.964545;10.1109/TVCG.2014.2346573;10.1109/VAST.2007.4389011;10.1109/TVCG.2006.156;10.1109/TVCG.2011.234	3D Network;Oculus Rift;CAVE;Immersive Analytics;Collaboration	Monash University##Monash University##Monash University##Stanford University, USA##Monash University##University of South Australia
InfoVis	2016	VizItCards: A Card-Based Toolkit for Infovis Design Education	10.1109/TVCG.2016.2599338	http://dx.doi.org/10.1109/TVCG.2016.2599338	561	570	J	Shifts in information visualization practice are forcing a reconsideration of how infovis is taught. Traditional curricula that focused on conveying research-derived knowledge are slowly integrating design thinking as a key learning objective. In part, this is motivated by the realization that infovis is a wicked design problem, requiring a different kind of design work. In this paper we describe, VizItCards, a card-driven workshop developed for our graduate infovis class. The workshop is intended to provide practice with good design techniques and to simultaneously reinforce key concepts. VizItCards relies on principles of collaborative-learning and research on parallel design to generate positive collaborations and high-quality designs. From our experience of simulating a realistic design scenario in a classroom setting, we find that our students were able to meet key learning objectives and their design performance improved during the class. We describe variants of the workshop, discussing which techniques we think match to which learning goals.	Shiqing He;Eytan Adar	School of Information at the University of Michigan;School of Information at the University of Michigan	10.1109/TVCG.2015.2467271;10.1109/TVCG.2012.213;10.1109/VAST.2009.5333245;10.1109/TVCG.2014.2346331;10.1109/INFVIS.1996.559229;10.1109/TVCG.2007.70515;10.1109/TVCG.2013.184;10.1109/TVCG.2009.111	information visualization education;peer learning;toolkit;card;design workshop	School of Information at the University of Michigan##School of Information at the University of Michigan
SciVis	2016	Correlated Photon Mapping for Interactive Global Illumination of Time-Varying Volumetric Data	10.1109/TVCG.2016.2598430	http://dx.doi.org/10.1109/TVCG.2016.2598430	901	910	J	We present a method for interactive global illumination of both static and time-varying volumetric data based on reduction of the overhead associated with re-computation of photon maps. Our method uses the identification of photon traces invariant to changes of visual parameters such as the transfer function (TF), or data changes between time-steps in a 4D volume. This lets us operate on a variant subset of the entire photon distribution. The amount of computation required in the two stages of the photon mapping process, namely tracing and gathering, can thus be reduced to the subset that are affected by a data or visual parameter change. We rely on two different types of information from the original data to identify the regions that have changed. A low resolution uniform grid containing the minimum and maximum data values of the original data is derived for each time step. Similarly, for two consecutive time-steps, a low resolution grid containing the difference between the overlapping data is used. We show that this compact metadata can be combined with the transfer function to identify the regions that have changed. Each photon traverses the low-resolution grid to identify if it can be directly transferred to the next photon distribution state or if it needs to be recomputed. An efficient representation of the photon distribution is presented leading to an order of magnitude improved performance of the raycasting step. The utility of the method is demonstrated in several examples that show visual fidelity, as well as performance. The examples show that visual quality can be retained when the fraction of retraced photons is as low as 40%-50%.	Daniel Jönsson;Anders Ynnerman	Linköping University, Nörrköping, Sweden;Linköping University, Nörrköping, Sweden	10.1109/TVCG.2011.161;10.1109/TVCG.2014.2346333;10.1109/TVCG.2012.232;10.1109/TVCG.2007.70518;10.1109/TVCG.2011.198;10.1109/TVCG.2011.211	Volume rendering;photon mapping;global illumination;participating media	Linköping University, Nörrköping, Sweden##Linköping University, Nörrköping, Sweden
SciVis	2016	Hairy Slices: Evaluating the Perceptual Effectiveness of Cutting Plane Glyphs for 3D Vector Fields	10.1109/TVCG.2016.2598448	http://dx.doi.org/10.1109/TVCG.2016.2598448	990	999	J	Three-dimensional vector fields are common datasets throughout the sciences. Visualizing these fields is inherently difficult due to issues such as visual clutter and self-occlusion. Cutting planes are often used to overcome these issues by presenting more manageable slices of data. The existing literature provides many techniques for visualizing the flow through these cutting planes; however, there is a lack of empirical studies focused on the underlying perceptual cues that make popular techniques successful. This paper presents a quantitative human factors study that evaluates static monoscopic depth and orientation cues in the context of cutting plane glyph designs for exploring and analyzing 3D flow fields. The goal of the study was to ascertain the relative effectiveness of various techniques for portraying the direction of flow through a cutting plane at a given point, and to identify the visual cues and combinations of cues involved, and how they contribute to accurate performance. It was found that increasing the dimensionality of line-based glyphs into tubular structures enhances their ability to convey orientation through shading, and that increasing their diameter intensifies this effect. These tube-based glyphs were also less sensitive to visual clutter issues at higher densities. Adding shadows to lines was also found to increase perception of flow direction. Implications of the experimental results are discussed and extrapolated into a number of guidelines for designing more perceptually effective glyphs for 3D vector field visualizations.	Andrew H. Stevens;Thomas Butkiewicz;Colin Ware	The Center for Coastal and Ocean MappingThe University of New Hampshire;The Center for Coastal and Ocean MappingThe University of New Hampshire;The Center for Coastal and Ocean MappingThe University of New Hampshire	10.1109/VISUAL.1996.568139;10.1109/TVCG.2009.126;10.1109/VISUAL.2005.1532859;10.1109/VISUAL.2004.59;10.1109/VISUAL.1991.175792;10.1109/TVCG.2012.216;10.1109/VISUAL.1999.809918;10.1109/VISUAL.1998.745317;10.1109/VISUAL.2005.1532772;10.1109/TVCG.2009.138;10.1109/VISUAL.1990.146360;10.1109/VISUAL.1996.567777	Flow visualization;3D vector fields;Cutting planes;Glyphs;Perception;Evaluation;Human factors	The Center for Coastal and Ocean MappingThe University of New Hampshire##The Center for Coastal and Ocean MappingThe University of New Hampshire##The Center for Coastal and Ocean MappingThe University of New Hampshire
SciVis	2016	Urban Pulse: Capturing the Rhythm of Cities	10.1109/TVCG.2016.2598585	http://dx.doi.org/10.1109/TVCG.2016.2598585	791	800	J	Cities are inherently dynamic. Interesting patterns of behavior typically manifest at several key areas of a city over multiple temporal resolutions. Studying these patterns can greatly help a variety of experts ranging from city planners and architects to human behavioral experts. Recent technological innovations have enabled the collection of enormous amounts of data that can help in these studies. However, techniques using these data sets typically focus on understanding the data in the context of the city, thus failing to capture the dynamic aspects of the city. The goal of this work is to instead understand the city in the context of multiple urban data sets. To do so, we define the concept of an &#x201C;urban pulse&#x201D; which captures the spatio-temporal activity in a city across multiple temporal resolutions. The prominent pulses in a city are obtained using the topology of the data sets, and are characterized as a set of beats. The beats are then used to analyze and compare different pulses. We also design a visual exploration framework that allows users to explore the pulses within and across multiple cities under different conditions. Finally, we present three case studies carried out by experts from two different domains that demonstrate the utility of our framework.	Fábio Miranda;Harish Doraiswamy;Marcos Lage;Kai Zhao;Bruno Gonçalves;Luc Wilson;Mondrian Hsieh;Cláudio T. Silva	New York University;New York University;Universidade Federal Fluminense;New York University;New York University;Kohn Pedersen Fox Associates PC;Kohn Pedersen Fox Associates PC;New York University	10.1109/TVCG.2015.2467592;10.1109/VAST.2015.7347636;10.1109/TVCG.2014.2346898;10.1109/TVCG.2013.226;10.1109/TVCG.2013.228;10.1109/TVCG.2015.2467619;10.1109/TVCG.2015.2467194;10.1109/VAST.2015.7347630;10.1109/TVCG.2011.181;10.1109/TVCG.2013.131;10.1109/TVCG.2015.2468111;10.1109/TVCG.2014.2346449	Topology-based techniques;urban data;visual exploration	New York University##New York University##Universidade Federal Fluminense##New York University##New York University##Kohn Pedersen Fox Associates PC##Kohn Pedersen Fox Associates PC##New York University
SciVis	2016	Comparing Cross-Sections and 3D Renderings for Surface Matching Tasks Using Physical Ground Truths	10.1109/TVCG.2016.2598602	http://dx.doi.org/10.1109/TVCG.2016.2598602	781	790	J	Within the visualization community there are some well-known techniques for visualizing 3D spatial data and some general assumptions about how perception affects the performance of these techniques in practice. However, there is a lack of empirical research backing up the possible performance differences among the basic techniques for general tasks. One such assumption is that 3D renderings are better for obtaining an overview, whereas cross sectional visualizations such as the commonly used Multi-Planar Reformation (MPR) are better for supporting detailed analysis tasks. In the present study we investigated this common assumption by examining the difference in performance between MPR and 3D rendering for correctly identifying a known surface. We also examined whether prior experience working with image data affects the participant's performance, and whether there was any difference between interactive or static versions of the visualizations. Answering this question is important because it can be used as part of a scientific and empirical basis for determining when to use which of the two techniques. An advantage of the present study compared to other studies is that several factors were taken into account to compare the two techniques. The problem was examined through an experiment with 45 participants, where physical objects were used as the known surface (ground truth). Our findings showed that: 1. The 3D renderings largely outperformed the cross sections; 2. Interactive visualizations were partially more effective than static visualizations; and 3. The high experience group did not generally outperform the low experience group.	Andreas J. Lind;Stefan Bruckner	University of Bergen, Norway;University of Bergen, Norway	10.1109/TVCG.2007.70569;10.1109/TVCG.2011.161;10.1109/TVCG.2013.121;10.1109/TVCG.2008.108;10.1109/VISUAL.2005.1532856;10.1109/SciVis.2015.7429485;10.1109/TVCG.2007.70542	Human-Computer Interaction;Quantitative Evaluation and Volume Visualization	University of Bergen, Norway##University of Bergen, Norway
SciVis	2016	Visualization and Extraction of Carvings for Heritage Conservation	10.1109/TVCG.2016.2598603	http://dx.doi.org/10.1109/TVCG.2016.2598603	801	810	J	We present novel techniques for visualizing, illustrating, analyzing, and generating carvings in surfaces. In particular, we consider the carvings in the plaster of the cloister of the Magdeburg cathedral, which dates to the 13th century. Due to aging and weathering, the carvings have flattened. Historians and restorers are highly interested in using digitalization techniques to analyze carvings in historic artifacts and monuments and to get impressions and illustrations of their original shape and appearance. Moreover, museums and churches are interested in such illustrations for presenting them to visitors. The techniques that we propose allow for detecting, selecting, and visualizing carving structures. In addition, we introduce an example-based method for generating carvings. The resulting tool, which integrates all techniques, was evaluated by three experienced restorers to assess the usefulness and applicability. Furthermore, we compared our approach with exaggerated shading and other state-of-the-art methods.	Kai Lawonn;Erik Trostmann;Bernhard Preim;Klaus Hildebrandt	University of Koblenz-Landau, Germany;Fraunhofer Institute for Factory Operation and Automation IFF, Germany;University of Magdeburg, Germany;Delft University of Technology, The Netherlands	10.1109/TVCG.2007.70538;10.1109/TVCG.2012.248	feature filtering;Feature extraction;heritage preservation;Frangi filter;surface analysis	University of Koblenz-Landau, Germany##Fraunhofer Institute for Factory Operation and Automation IFF, Germany##University of Magdeburg, Germany##Delft University of Technology, The Netherlands
SciVis	2016	In Situ Distribution Guided Analysis and Visualization of Transonic Jet Engine Simulations	10.1109/TVCG.2016.2598604	http://dx.doi.org/10.1109/TVCG.2016.2598604	811	820	J	Study of flow instability in turbine engine compressors is crucial to understand the inception and evolution of engine stall. Aerodynamics experts have been working on detecting the early signs of stall in order to devise novel stall suppression technologies. A state-of-the-art Navier-Stokes based, time-accurate computational fluid dynamics simulator, TURBO, has been developed in NASA to enhance the understanding of flow phenomena undergoing rotating stall. Despite the proven high modeling accuracy of TURBO, the excessive simulation data prohibits post-hoc analysis in both storage and I/O time. To address these issues and allow the expert to perform scalable stall analysis, we have designed an in situ distribution guided stall analysis technique. Our method summarizes statistics of important properties of the simulation data in situ using a probabilistic data modeling scheme. This data summarization enables statistical anomaly detection for flow instability in post analysis, which reveals the spatiotemporal trends of rotating stall for the expert to conceive new hypotheses. Furthermore, the verification of the hypotheses and exploratory visualization using the summarized data are realized using probabilistic visualization techniques such as uncertain isocontouring. Positive feedback from the domain scientist has indicated the efficacy of our system in exploratory stall analysis.	Soumya Dutta;Chun-Ming Chen;Gregory Heinlein;Han-Wei Shen;Jen-Ping Chen	The Department of Computer Science and Engineering, GRAVITY research group, The Ohio State University;The Department of Computer Science and Engineering, GRAVITY research group, The Ohio State University;The Department of Mechanical and Aerospace Engineering, The Ohio State University;The Department of Computer Science and Engineering, GRAVITY research group, The Ohio State University;The Department of Mechanical and Aerospace Engineering, The Ohio State University	10.1109/TVCG.2008.140;10.1109/TVCG.2013.152;10.1109/TVCG.2015.2467436;10.1109/TVCG.2007.70615;10.1109/TVCG.2015.2467952;10.1109/TVCG.2015.2467958;10.1109/TVCG.2015.2467411	In situ analysis;rotating stall analysis;Gaussian mixture model;incremental distribution modeling;feature analysis;high performance computing;collaborative development	The Department of Computer Science and Engineering, GRAVITY research group, The Ohio State University##The Department of Computer Science and Engineering, GRAVITY research group, The Ohio State University##The Department of Mechanical and Aerospace Engineering, The Ohio State University##The Department of Computer Science and Engineering, GRAVITY research group, The Ohio State University##The Department of Mechanical and Aerospace Engineering, The Ohio State University
SciVis	2016	Synteny Explorer: An Interactive Visualization Application for Teaching Genome Evolution	10.1109/TVCG.2016.2598789	http://dx.doi.org/10.1109/TVCG.2016.2598789	711	720	J	Rapid advances in biology demand new tools for more active research dissemination and engaged teaching. This paper presents Synteny Explorer, an interactive visualization application designed to let college students explore genome evolution of mammalian species. The tool visualizes synteny blocks: segments of homologous DNA shared between various extant species that can be traced back or reconstructed in extinct, ancestral species. We take a karyogram-based approach to create an interactive synteny visualization, leading to a more appealing and engaging design for undergraduate-level genome evolution education. For validation, we conduct three user studies: two focused studies on color and animation design choices and a larger study that performs overall system usability testing while comparing our karyogram-based designs with two more common genome mapping representations in an educational context. While existing views communicate the same information, study participants found the interactive, karyogram-based views much easier and likable to use. We additionally discuss feedback from biology and genomics faculty, who judge Synteny Explorer's fitness for use in classrooms.	Chris Bryan;Gregory Guterman;Kwan-Liu Ma;Harris Lewin;Denis Larkin;Jaebum Kim;Jian Ma;Marta Farre	University of California, Davis;University of California, Davis;University of California, Davis;University of California, Davis;Royal Veterinary College, University of London;Konkuk University, Seoul;Carnegie Mellon University;Royal Veterinary College, University of London	;10.1109/TVCG.2007.70539;10.1109/TVCG.2012.272;10.1109/TVCG.2010.163;10.1109/TVCG.2009.167;10.1109/TVCG.2011.232;10.1109/TVCG.2010.137;10.1109/TVCG.2013.214	Bioinformatic visualization;education;learning;genome evolution;chromosome;user study	University of California, Davis##University of California, Davis##University of California, Davis##University of California, Davis##Royal Veterinary College, University of London##Konkuk University, Seoul##Carnegie Mellon University##Royal Veterinary College, University of London
SciVis	2016	Visualizing Shape Deformations with Variation of Geometric Spectrum	10.1109/TVCG.2016.2598790	http://dx.doi.org/10.1109/TVCG.2016.2598790	721	730	J	This paper presents a novel approach based on spectral geometry to quantify and visualize non-isometric deformations of 3D surfaces by mapping two manifolds. The proposed method can determine multi-scale, non-isometric deformations through the variation of Laplace-Beltrami spectrum of two shapes. Given two triangle meshes, the spectra can be varied from one to another with a scale function defined on each vertex. The variation is expressed as a linear interpolation of eigenvalues of the two shapes. In each iteration step, a quadratic programming problem is constructed, based on our derived spectrum variation theorem and smoothness energy constraint, to compute the spectrum variation. The derivation of the scale function is the solution of such a problem. Therefore, the final scale function can be solved by integral of the derivation from each step, which, in turn, quantitatively describes non-isometric deformations between two shapes. To evaluate the method, we conduct extensive experiments on synthetic and real data. We employ real epilepsy patient imaging data to quantify the shape variation between the left and right hippocampi in epileptic brains. In addition, we use longitudinal Alzheimer data to compare the shape deformation of diseased and healthy hippocampus. In order to show the accuracy and effectiveness of the proposed method, we also compare it with spatial registration-based methods, e.g., non-rigid Iterative Closest Point (ICP) and voxel-based method. These experiments demonstrate the advantages of our method.	Jiaxi Hu;Hajar Hamidian;Zichun Zhong;Jing Hua	Wayne State University;Wayne State University;Wayne State University;Wayne State University	10.1109/TVCG.2009.159;10.1109/TVCG.2015.2467198;10.1109/TVCG.2011.171	Geometry-based Technique;Spectral Analysis;Biomedical Visualization	Wayne State University##Wayne State University##Wayne State University##Wayne State University
SciVis	2016	Corresponding Supine and Prone Colon Visualization Using Eigenfunction Analysis and Fold Modeling	10.1109/TVCG.2016.2598791	http://dx.doi.org/10.1109/TVCG.2016.2598791	751	760	J	We present a method for registration and visualization of corresponding supine and prone virtual colonoscopy scans based on eigenfunction analysis and fold modeling. In virtual colonoscopy, CT scans are acquired with the patient in two positions, and their registration is desirable so that physicians can corroborate findings between scans. Our algorithm performs this registration efficiently through the use of Fiedler vector representation (the second eigenfunction of the Laplace-Beltrami operator). This representation is employed to first perform global registration of the two colon positions. The registration is then locally refined using the haustral folds, which are automatically segmented using the 3D level sets of the Fiedler vector. The use of Fiedler vectors and the segmented folds presents a precise way of visualizing corresponding regions across datasets and visual modalities. We present multiple methods of visualizing the results, including 2D flattened rendering and the corresponding 3D endoluminal views. The precise fold modeling is used to automatically find a suitable cut for the 2D flattening, which provides a less distorted visualization. Our approach is robust, and we demonstrate its efficiency and efficacy by showing matched views on both the 2D flattened colons and in the 3D endoluminal view. We analytically evaluate the results by measuring the distance between features on the registered colons, and we also assess our fold segmentation against 20 manually labeled datasets. We have compared our results analytically to previous methods, and have found our method to achieve superior results. We also prove the hot spots conjecture for modeling cylindrical topology using Fiedler vector representation, which allows our approach to be used for general cylindrical geometry modeling and feature extraction.	Saad Nadeem;Joseph Marino;Xianfeng Gu;Arie E. Kaufman	Computer Science Department, Stony Brook University, Stony Brook, NY;Computer Science Department, Stony Brook University, Stony Brook, NY;Computer Science Department, Stony Brook University, Stony Brook, NY;Computer Science Department, Stony Brook University, Stony Brook, NY	10.1109/TVCG.2006.112;10.1109/TVCG.2010.200;10.1109/VISUAL.2001.964540;10.1109/TVCG.2006.158;10.1109/TVCG.2013.139;10.1109/TVCG.2015.2467413;10.1109/TVCG.2011.182;10.1109/VISUAL.2005.1532806	Medical visualization;colon registration;geometry-based techniques;mathematical foundations for visualization	Computer Science Department, Stony Brook University, Stony Brook, NY##Computer Science Department, Stony Brook University, Stony Brook, NY##Computer Science Department, Stony Brook University, Stony Brook, NY##Computer Science Department, Stony Brook University, Stony Brook, NY
SciVis	2016	Combined Visualization of Vessel Deformation and Hemodynamics in Cerebral Aneurysms	10.1109/TVCG.2016.2598795	http://dx.doi.org/10.1109/TVCG.2016.2598795	761	770	J	We present the first visualization tool that combines patient-specific hemodynamics with information about the vessel wall deformation and wall thickness in cerebral aneurysms. Such aneurysms bear the risk of rupture, whereas their treatment also carries considerable risks for the patient. For the patient-specific rupture risk evaluation and treatment analysis, both morphological and hemodynamic data have to be investigated. Medical researchers emphasize the importance of analyzing correlations between wall properties such as the wall deformation and thickness, and hemodynamic attributes like the Wall Shear Stress and near-wall flow. Our method uses a linked 2.5D and 3D depiction of the aneurysm together with blood flow information that enables the simultaneous exploration of wall characteristics and hemodynamic attributes during the cardiac cycle. We thus offer medical researchers an effective visual exploration tool for aneurysm treatment risk assessment. The 2.5D view serves as an overview that comprises a projection of the vessel surface to a 2D map, providing an occlusion-free surface visualization combined with a glyph-based depiction of the local wall thickness. The 3D view represents the focus upon which the data exploration takes place. To support the time-dependent parameter exploration and expert collaboration, a camera path is calculated automatically, where the user can place landmarks for further exploration of the properties. We developed a GPU-based implementation of our visualizations with a flexible interactive data exploration mechanism. We designed our techniques in collaboration with domain experts, and provide details about the evaluation.	Monique Meuschke;Samuel Voß;Oliver Beuing;Bernhard Preim;Kai Lawonn	University of Magdeburg, Germany;University of Magdeburg, Germany;University of Magdeburg, Germany;University of Magdeburg, Germany;University of Koblenz-Landau, Germany	10.1109/TVCG.2011.215;10.1109/TVCG.2011.243;10.1109/TVCG.2014.2346406;10.1109/TVCG.2010.153;10.1109/TVCG.2015.2467961;10.1109/TVCG.2013.189;10.1109/TVCG.2012.202	Medical visualizations;aneurysms;blood flow;wall thickness;wall deformation;projections	University of Magdeburg, Germany##University of Magdeburg, Germany##University of Magdeburg, Germany##University of Magdeburg, Germany##University of Koblenz-Landau, Germany
SciVis	2016	Molecular Surface Maps	10.1109/TVCG.2016.2598824	http://dx.doi.org/10.1109/TVCG.2016.2598824	701	710	J	We present Molecular Surface Maps, a novel, view-independent, and concise representation for molecular surfaces. It transfers the well-known world map metaphor to molecular visualization. Our application maps the complex molecular surface to a simple 2D representation through a spherical intermediate, the Molecular Surface Globe. The Molecular Surface Map concisely shows arbitrary attributes of the original molecular surface, such as biochemical properties or geometrical features. This results in an intuitive overview, which allows researchers to assess all molecular surface attributes at a glance. Our representation can be used as a visual summarization of a molecule's interface with its environment. In particular, Molecular Surface Maps simplify the analysis and comparison of different data sets or points in time. Furthermore, the map representation can be used in a Space-time Cube to analyze time-dependent data from molecular simulations without the need for animation. We show the feasibility of Molecular Surface Maps for different typical analysis tasks of biomolecular data.	Michael Krone;Florian Friess;Katrin Scharnowski;Guido Reina;Silvia Fademrecht;Tobias Kulschewski;Jürgen Pleiss;Thomas Ertl	Visualization Research Center (VISUS), University of Stuttgart, Germany;Visualization Research Center (VISUS), University of Stuttgart, Germany;Visualization Research Center (VISUS), University of Stuttgart, Germany;Visualization Research Center (VISUS), University of Stuttgart, Germany;Institute of Technical Biochemistry (ITB), University of Stuttgart, Germany;Institute of Technical Biochemistry (ITB), University of Stuttgart, Germany;Institute of Technical Biochemistry (ITB), University of Stuttgart, Germany;Visualization Research Center (VISUS), University of Stuttgart, Germany	10.1109/TVCG.2013.194;10.1109/VISUAL.2003.1250384;10.1109/TVCG.2015.2467413	Molecular Visualization;Maps;Cartography;Data Aggregation;Dimensionality Reduction;Space-time Cube	Visualization Research Center (VISUS), University of Stuttgart, Germany##Visualization Research Center (VISUS), University of Stuttgart, Germany##Visualization Research Center (VISUS), University of Stuttgart, Germany##Visualization Research Center (VISUS), University of Stuttgart, Germany##Institute of Technical Biochemistry (ITB), University of Stuttgart, Germany##Institute of Technical Biochemistry (ITB), University of Stuttgart, Germany##Institute of Technical Biochemistry (ITB), University of Stuttgart, Germany##Visualization Research Center (VISUS), University of Stuttgart, Germany
SciVis	2016	Physics-Based Visual Characterization of Molecular Interaction Forces	10.1109/TVCG.2016.2598825	http://dx.doi.org/10.1109/TVCG.2016.2598825	731	740	J	Molecular simulations are used in many areas of biotechnology, such as drug design and enzyme engineering. Despite the development of automatic computational protocols, analysis of molecular interactions is still a major aspect where human comprehension and intuition are key to accelerate, analyze, and propose modifications to the molecule of interest. Most visualization algorithms help the users by providing an accurate depiction of the spatial arrangement: the atoms involved in inter-molecular contacts. There are few tools that provide visual information on the forces governing molecular docking. However, these tools, commonly restricted to close interaction between atoms, do not consider whole simulation paths, long-range distances and, importantly, do not provide visual cues for a quick and intuitive comprehension of the energy functions (modeling intermolecular interactions) involved. In this paper, we propose visualizations designed to enable the characterization of interaction forces by taking into account several relevant variables such as molecule-ligand distance and the energy function, which is essential to understand binding affinities. We put emphasis on mapping molecular docking paths obtained from Molecular Dynamics or Monte Carlo simulations, and provide time-dependent visualizations for different energy components and particle resolutions: atoms, groups or residues. The presented visualizations have the potential to support domain experts in a more efficient drug or enzyme design process.	Pedro Hermosilla;Jorge Estrada;Victor Guallar;Timo Ropinski;Alvar Vinacua;Pere-Pau Vázquez	ViRVIG Group, Barcelona Supercomputing Center;Barcelona Supercomputing Center;Barcelona Supercomputing Center;Visual Computing Group, Ulm University;ViRVIG Group, UPC, Barcelona;ViRVIG Group, UPC, Barcelona	10.1109/TVCG.2009.168;10.1109/TVCG.2012.282;10.1109/TVCG.2015.2467293;10.1109/TVCG.2007.70578;10.1109/TVCG.2006.115;10.1109/TVCG.2007.70517;10.1109/TVCG.2014.2346403;10.1109/TVCG.2009.157	Molecular visualization;binding analysis	ViRVIG Group, Barcelona Supercomputing Center##Barcelona Supercomputing Center##Barcelona Supercomputing Center##Visual Computing Group, Ulm University##ViRVIG Group, UPC, Barcelona##ViRVIG Group, UPC, Barcelona
SciVis	2016	PelVis: Atlas-based Surgical Planning for Oncological Pelvic Surgery	10.1109/TVCG.2016.2598826	http://dx.doi.org/10.1109/TVCG.2016.2598826	741	750	J	Due to the intricate relationship between the pelvic organs and vital structures, such as vessels and nerves, pelvic anatomy is often considered to be complex to comprehend. In oncological pelvic surgery, a trade-off has to be made between complete tumor resection and preserving function by preventing damage to the nerves. Damage to the autonomic nerves causes undesirable post-operative side-effects such as fecal and urinal incontinence, as well as sexual dysfunction in up to 80 percent of the cases. Since these autonomic nerves are not visible in pre-operative MRI scans or during surgery, avoiding nerve damage during such a surgical procedure becomes challenging. In this work, we present visualization methods to represent context, target, and risk structures for surgical planning. We employ distance-based and occlusion management techniques in an atlas-based surgical planning tool for oncological pelvic surgery. Patient-specific pre-operative MRI scans are registered to an atlas model that includes nerve information. Through several interactive linked views, the spatial relationships and distances between the organs, tumor and risk zones are visualized to improve understanding, while avoiding occlusion. In this way, the surgeon can examine surgically relevant structures and plan the procedure before going into the operating theater, thus raising awareness of the autonomic nerve zone regions and potentially reducing post-operative complications. Furthermore, we present the results of a domain expert evaluation with surgical oncologists that demonstrates the advantages of our approach.	Noeska N. Smit;Kai Lawonn;Annelot Kraima;Marco DeRuiter;Hessam Sokooti;Stefan Bruckner;Elmar Eisemann;Anna Vilanova	Delft University of TechnologyUniversity of Bergen;University of Koblenz, Landau;Leiden University Medical Center;Leiden University Medical Center;Leiden University Medical Center;University of Bergen;Delft University of Technology;Delft University of Technology	10.1109/TVCG.2008.180;10.1109/VISUAL.2002.1183769;10.1109/TVCG.2011.207;10.1109/TVCG.2015.2467961;10.1109/TVCG.2011.189;10.1109/TVCG.2013.143;10.1109/VISUAL.2003.1250400	Atlas;surgical planning;medical visualization	Delft University of TechnologyUniversity of Bergen##University of Koblenz, Landau##Leiden University Medical Center##Leiden University Medical Center##Leiden University Medical Center##University of Bergen##Delft University of Technology##Delft University of Technology
SciVis	2016	Visualization as Seen through its Research Paper Keywords	10.1109/TVCG.2016.2598827	http://dx.doi.org/10.1109/TVCG.2016.2598827	771	780	J	We present the results of a comprehensive multi-pass analysis of visualization paper keywords supplied by authors for their papers published in the IEEE Visualization conference series (now called IEEE VIS) between 1990-2015. From this analysis we derived a set of visualization topics that we discuss in the context of the current taxonomy that is used to categorize papers and assign reviewers in the IEEE VIS reviewing process. We point out missing and overemphasized topics in the current taxonomy and start a discussion on the importance of establishing common visualization terminology. Our analysis of research topics in visualization can, thus, serve as a starting point to (a) help create a common vocabulary to improve communication among different visualization sub-groups, (b) facilitate the process of understanding differences and commonalities of the various research sub-fields in visualization, (c) provide an understanding of emerging new research trends, (d) facilitate the crucial step of finding the right reviewers for research submissions, and (e) it can eventually lead to a comprehensive taxonomy of visualization research. One additional tangible outcome of our work is an online query tool (http://keyvis.org/) that allows visualization researchers to easily browse the 3952 keywords used for IEEE VIS papers since 1990 to find related work or make informed keyword choices.	Petra Isenberg;Tobias Isenberg 0001;Michael Sedlmair;Jian Chen;Torsten Möller	Inria, France;Inria, France;University of Vienna, Austria;University of Maryland, Baltimore County, USA;University of Vienna, Austria	10.1109/TVCG.2012.195;10.1109/TVCG.2012.213;10.1109/INFVIS.2000.885092;10.1109/TVCG.2011.229;10.1109/TVCG.2008.109;10.1109/TVCG.2007.70515;10.1109/TVCG.2013.126	data analysis;research themes;research topics;taxonomy;visualization history;theory	Inria, France##Inria, France##University of Vienna, Austria##University of Maryland, Baltimore County, USA##University of Vienna, Austria
SciVis	2016	Decal-Maps: Real-Time Layering of Decals on Surfaces for Multivariate Visualization	10.1109/TVCG.2016.2598866	http://dx.doi.org/10.1109/TVCG.2016.2598866	821	830	J	We introduce the use of decals for multivariate visualization design. Decals are visual representations that are used for communication; for example, a pattern, a text, a glyph, or a symbol, transferred from a 2D-image to a surface upon contact. By creating what we define as decal-maps, we can design a set of images or patterns that represent one or more data attributes. We place decals on the surface considering the data pertaining to the locations we choose. We propose a (texture mapping) local parametrization that allows placing decals on arbitrary surfaces interactively, even when dealing with a high number of decals. Moreover, we extend the concept of layering to allow the co-visualization of an increased number of attributes on arbitrary surfaces. By combining decal-maps, color-maps and a layered visualization, we aim to facilitate and encourage the creative process of designing multivariate visualizations. Finally, we demonstrate the general applicability of our technique by providing examples of its use in a variety of contexts.	Allan Rocha;Usman R. Alim;Julio Daniel Silva;Mario Costa Sousa	University of Calgary;University of Calgary;University of Calgary;University of Calgary	10.1109/VISUAL.1991.175811;10.1109/TVCG.2010.181;10.1109/TVCG.2011.243;10.1109/VISUAL.1998.745294;10.1109/TVCG.2015.2467153;10.1109/VISUAL.2003.1250362;10.1109/VISUAL.1999.809905;10.1109/TVCG.2011.170	Multivariate;Visualization;Real-time;Decal;Surface;Layering;Design	University of Calgary##University of Calgary##University of Calgary##University of Calgary
SciVis	2016	Time-Hierarchical Clustering and Visualization of Weather Forecast Ensembles	10.1109/TVCG.2016.2598868	http://dx.doi.org/10.1109/TVCG.2016.2598868	831	840	J	We propose a new approach for analyzing the temporal growth of the uncertainty in ensembles of weather forecasts which are started from perturbed but similar initial conditions. As an alternative to traditional approaches in meteorology, which use juxtaposition and animation of spaghetti plots of iso-contours, we make use of contour clustering and provide means to encode forecast dynamics and spread in one single visualization. Based on a given ensemble clustering in a specified time window, we merge clusters in time-reversed order to indicate when and where forecast trajectories start to diverge. We present and compare different visualizations of the resulting time-hierarchical grouping, including space-time surfaces built by connecting cluster representatives over time, and stacked contour variability plots. We demonstrate the effectiveness of our visual encodings with forecast examples of the European Centre for Medium-Range Weather Forecasts, which convey the evolution of specific features in the data as well as the temporally increasing spatial variability.	Florian Ferstl;Mathias Kanzler;Marc Rautenhaus;Rüdiger Westermann	Technical University of Munich;Technical University of Munich;Technical University of Munich;Technical University of Munich	10.1109/TVCG.2015.2467204;10.1109/TVCG.2010.181;10.1109/INFVIS.1999.801851;10.1109/TVCG.2015.2467754;10.1109/TVCG.2013.143;10.1109/TVCG.2013.141;10.1109/TVCG.2011.203;10.1109/TVCG.2014.2346332;10.1109/TVCG.2006.168	Ensemble visualization;uncertainty visualization;meteorological visualization;iso-contours;time-varying data;clustering	Technical University of Munich##Technical University of Munich##Technical University of Munich##Technical University of Munich
SciVis	2016	Visualization of Time-Varying Weather Ensembles across Multiple Resolutions	10.1109/TVCG.2016.2598869	http://dx.doi.org/10.1109/TVCG.2016.2598869	841	850	J	Uncertainty quantification in climate ensembles is an important topic for the domain scientists, especially for decision making in the real-world scenarios. With powerful computers, simulations now produce time-varying and multi-resolution ensemble data sets. It is of extreme importance to understand the model sensitivity given the input parameters such that more computation power can be allocated to the parameters with higher influence on the output. Also, when ensemble data is produced at different resolutions, understanding the accuracy of different resolutions helps the total time required to produce a desired quality solution with improved storage and computation cost. In this work, we propose to tackle these non-trivial problems on the Weather Research and Forecasting (WRF) model output. We employ a moment independent sensitivity measure to quantify and analyze parameter sensitivity across spatial regions and time domain. A comparison of clustering structures across three resolutions enables the users to investigate the sensitivity variation over the spatial regions of the five input parameters. The temporal trend in the sensitivity values is explored via an MDS view linked with a line chart for interactive brushing. The spatial and temporal views are connected to provide a full exploration system for complete spatio-temporal sensitivity analysis. To analyze the accuracy across varying resolutions, we formulate a Bayesian approach to identify which regions are better predicted at which resolutions compared to the observed precipitation. This information is aggregated over the time domain and finally encoded in an output image through a custom color map that guides the domain experts towards an adaptive grid implementation given a cost model. Users can select and further analyze the spatial and temporal error patterns for multi-resolution accuracy analysis via brushing and linking on the produced image. In this work, we collaborate with a domain expert whose feedback shows the effectiveness of our proposed exploration work-flow.	Ayan Biswas;Guang Lin;Xiaotong Liu;Han-Wei Shen	GRAVITY group, The Ohio State University;Purdue University;GRAVITY group, The Ohio State University;GRAVITY group, The Ohio State University	10.1109/TVCG.2015.2467204;10.1109/TVCG.2010.181;10.1109/SciVis.2015.7429487;10.1109/TVCG.2013.138;10.1109/TVCG.2015.2468093;10.1109/TVCG.2013.143;10.1109/TVCG.2014.2346448;10.1109/VAST.2015.7347634;10.1109/TVCG.2012.249;10.1109/TVCG.2014.2346455;10.1109/TVCG.2013.144	Ensemble;time-varying;multi-resolution;sensitivity analysis	GRAVITY group, The Ohio State University##Purdue University##GRAVITY group, The Ohio State University##GRAVITY group, The Ohio State University
SciVis	2016	A Fractional Cartesian Composition Model for Semi-Spatial Comparative Visualization Design	10.1109/TVCG.2016.2598870	http://dx.doi.org/10.1109/TVCG.2016.2598870	851	860	J	The study of spatial data ensembles leads to substantial visualization challenges in a variety of applications. In this paper, we present a model for comparative visualization that supports the design of according ensemble visualization solutions by partial automation. We focus on applications, where the user is interested in preserving selected spatial data characteristics of the data as much as possible-even when many ensemble members should be jointly studied using comparative visualization. In our model, we separate the design challenge into a minimal set of user-specified parameters and an optimization component for the automatic configuration of the remaining design variables. We provide an illustrated formal description of our model and exemplify our approach in the context of several application examples from different domains in order to demonstrate its generality within the class of comparative visualization problems for spatial data ensembles.	Ivan Kolesar;Stefan Bruckner;Ivan Viola;Helwig Hauser	Department of Informatics, University of Bergen, Norway;Department of Informatics, University of Bergen, Norway;TU Wien, Austria;Department of Informatics, University of Bergen, Norway	10.1109/TVCG.2014.2346591;10.1109/TVCG.2008.180;10.1109/TVCG.2009.153;10.1109/TVCG.2007.70550;10.1109/VISUAL.2003.1250401;10.1109/TVCG.2006.164;10.1109/TVCG.2013.120;10.1109/TVCG.2009.136;10.1109/TVCG.2014.2346325;10.1109/TVCG.2014.2346321;10.1109/TVCG.2011.227;10.1109/VISUAL.2005.1532781;10.1109/TVCG.2011.235;10.1109/VISUAL.2003.1250353;10.1109/TVCG.2009.111	Visualization Models;Integrating Spatial and Non-Spatial Data Visualization;Design Methodologies	Department of Informatics, University of Bergen, Norway##Department of Informatics, University of Bergen, Norway##TU Wien, Austria##Department of Informatics, University of Bergen, Norway
SciVis	2016	Glyphs for General Second-Order 2D and 3D Tensors	10.1109/TVCG.2016.2598998	http://dx.doi.org/10.1109/TVCG.2016.2598998	980	989	J	Glyphs are a powerful tool for visualizing second-order tensors in a variety of scientic data as they allow to encode physical behavior in geometric properties. Most existing techniques focus on symmetric tensors and exclude non-symmetric tensors where the eigenvectors can be non-orthogonal or complex. We present a new construction of 2d and 3d tensor glyphs based on piecewise rational curves and surfaces with the following properties: invariance to (a) isometries and (b) scaling, (c) direct encoding of all real eigenvalues and eigenvectors, (d) one-to-one relation between the tensors and glyphs, (e) glyph continuity under changing the tensor. We apply the glyphs to visualize the Jacobian matrix fields of a number of 2d and 3d vector fields.	Tim Gerrits;Christian Rössl;Holger Theisel	Visual Computing group at the University of Magdeburg, Germany;Visual Computing group at the University of Magdeburg, Germany;Visual Computing group at the University of Magdeburg, Germany	10.1109/TVCG.2014.2346325;10.1109/TVCG.2010.199;10.1109/VISUAL.1991.175773;10.1109/VISUAL.2004.115;10.1109/VISUAL.2003.1250376;10.1109/VISUAL.1993.398849;10.1109/TVCG.2009.184	Glyph-based Techniques;Tensor Field Data;Flow Visualization	Visual Computing group at the University of Magdeburg, Germany##Visual Computing group at the University of Magdeburg, Germany##Visual Computing group at the University of Magdeburg, Germany
SciVis	2016	Backward Finite-Time Lyapunov Exponents in Inertial Flows	10.1109/TVCG.2016.2599016	http://dx.doi.org/10.1109/TVCG.2016.2599016	970	979	J	Inertial particles are finite-sized objects that are carried by fluid flows and in contrast to massless tracer particles they are subject to inertia effects. In unsteady flows, the dynamics of tracer particles have been extensively studied by the extraction of Lagrangian coherent structures (LCS), such as hyperbolic LCS as ridges of the Finite-Time Lyapunov Exponent (FTLE). The extension of the rich LCS framework to inertial particles is currently a hot topic in the CFD literature and is actively under research. Recently, backward FTLE on tracer particles has been shown to correlate with the preferential particle settling of small inertial particles. For larger particles, inertial trajectories may deviate strongly from (massless) tracer trajectories, and thus for a better agreement, backward FTLE should be computed on inertial trajectories directly. Inertial backward integration, however, has not been possible until the recent introduction of the influence curve concept, which - given an observation and an initial velocity - allows to recover all sources of inertial particles as tangent curves of a derived vector field. In this paper, we show that FTLE on the influence curve vector field is in agreement with preferential particle settling and more importantly it is not only valid for small (near-tracer) particles. We further generalize the influence curve concept to general equations of motion in unsteady spatio-velocity phase spaces, which enables backward integration with more general equations of motion. Applying the influence curve concept to tracer particles in the spatio-velocity domain emits streaklines in massless flows as tangent curves of the influence curve vector field. We demonstrate the correlation between inertial backward FTLE and the preferential particle settling in a number of unsteady vector fields	Tobias Günther;Holger Theisel	Visual Computing Group, University of Magdeburg;Visual Computing Group, University of Magdeburg	10.1109/TVCG.2007.70551;10.1109/TVCG.2007.70554;10.1109/TVCG.2010.198;10.1109/TVCG.2014.2346415;10.1109/TVCG.2013.128	Inertial particles;finite-time Lyapunov exponents;backward integration;preferential particle settling	Visual Computing Group, University of Magdeburg##Visual Computing Group, University of Magdeburg
SciVis	2016	Jacobi Fiber Surfaces for Bivariate Reeb Space Computation	10.1109/TVCG.2016.2599017	http://dx.doi.org/10.1109/TVCG.2016.2599017	960	969	J	This paper presents an efficient algorithm for the computation of the Reeb space of an input bivariate piecewise linear scalar function f defined on a tetrahedral mesh. By extending and generalizing algorithmic concepts from the univariate case to the bivariate one, we report the first practical, output-sensitive algorithm for the exact computation of such a Reeb space. The algorithm starts by identifying the Jacobi set of f, the bivariate analogs of critical points in the univariate case. Next, the Reeb space is computed by segmenting the input mesh along the new notion of Jacobi Fiber Surfaces, the bivariate analog of critical contours in the univariate case. We additionally present a simplification heuristic that enables the progressive coarsening of the Reeb space. Our algorithm is simple to implement and most of its computations can be trivially parallelized. We report performance numbers demonstrating orders of magnitude speedups over previous approaches, enabling for the first time the tractable computation of bivariate Reeb spaces in practice. Moreover, unlike range-based quantization approaches (such as the Joint Contour Net), our algorithm is parameter-free. We demonstrate the utility of our approach by using the Reeb space as a semi-automatic segmentation tool for bivariate data. In particular, we introduce continuous scatterplot peeling, a technique which enables the reduction of the cluttering in the continuous scatterplot, by interactively selecting the features of the Reeb space to project. We provide a VTK-based C++ implementation of our algorithm that can be used for reproduction purposes or for the development of new Reeb space based visualization techniques.	Julien Tierny;Hamish Carr	Sorbonne Universites, UPMC UnivParis06, CNRS, LIP6 UMR 7606, France;University of Leeds	10.1109/TVCG.2009.163;10.1109/TVCG.2007.70603;10.1109/TVCG.2006.186;10.1109/TVCG.2010.146;10.1109/TVCG.2006.165;10.1109/VISUAL.2004.96;10.1109/TVCG.2015.2467432;10.1109/TVCG.2008.116;10.1109/TVCG.2008.119;10.1109/TVCG.2014.2346332;10.1109/TVCG.2008.110	Topological data analysis;multivariate data;data segmentation	Sorbonne Universites, UPMC UnivParis06, CNRS, LIP6 UMR 7606, France##University of Leeds
SciVis	2016	Topological Analysis of Inertial Dynamics	10.1109/TVCG.2016.2599018	http://dx.doi.org/10.1109/TVCG.2016.2599018	950	959	J	Traditional vector field visualization has a close focus on velocity, and is typically constrained to the dynamics of massless particles. In this paper, we present a novel approach to the analysis of the force-induced dynamics of inertial particles. These forces can arise from acceleration fields such as gravitation, but also be dependent on the particle dynamics itself, as in the case of magnetism. Compared to massless particles, the velocity of an inertial particle is not determined solely by its position and time in a vector field. In contrast, its initial velocity can be arbitrary and impacts the dynamics over its entire lifetime. This leads to a four-dimensional problem for 2D setups, and a six-dimensional problem for the 3D case. Our approach avoids this increase in dimensionality and tackles the visualization by an integrated topological analysis approach. We demonstrate the utility of our approach using a synthetic time-dependent acceleration field, a system of magnetic dipoles, and N-body systems both in 2D and 3D.	Antoni Sagrista;Stefan Jordan;Andreas Just;Fabio Dias;Luis Gustavo Nonato;Filip Sadlo	Heidelberg University, Germany;Heidelberg University, Germany;ZAH, Heidelberg University, Germany;Universidade de SÃ¥o Paulo, SÃ¥o Carlos, Brazil;Universidade de SÃ¥o Paulo, SÃ¥o Carlos, Brazil;Heidelberg University, Germany	10.1109/VISUAL.1993.398859;10.1109/TVCG.2014.2346415;10.1109/VISUAL.1990.146386	Visualization of inertial dynamics;N-body systems;magnetism;acceleration	Heidelberg University, Germany##Heidelberg University, Germany##ZAH, Heidelberg University, Germany##Universidade de SÃ¥o Paulo, SÃ¥o Carlos, Brazil##Universidade de SÃ¥o Paulo, SÃ¥o Carlos, Brazil##Heidelberg University, Germany
SciVis	2016	Direct Multifield Volume Ray Casting of Fiber Surfaces	10.1109/TVCG.2016.2599040	http://dx.doi.org/10.1109/TVCG.2016.2599040	941	949	J	Multifield data are common in visualization. However, reducing these data to comprehensible geometry is a challenging problem. Fiber surfaces, an analogy of isosurfaces to bivariate volume data, are a promising new mechanism for understanding multifield volumes. In this work, we explore direct ray casting of fiber surfaces from volume data without any explicit geometry extraction. We sample directly along rays in domain space, and perform geometric tests in range space where fibers are defined, using a signed distance field derived from the control polygons. Our method requires little preprocess, and enables real-time exploration of data, dynamic modification and pixel-exact rendering of fiber surfaces, and support for higher-order interpolation in domain space. We demonstrate this approach on several bivariate datasets, including analysis of multi-field combustion data.	Kui Wu;Aaron Knoll;Benjamin J. Isaac;Hamish Carr;Valerio Pascucci	University of Utah;SCI InstituteUniversity of UtahArgonne National Laboratory;ICSE, University of Utah;School of ComputingUniversity of Leeds;SCI InstituteUniversity of Utah	10.1109/VISUAL.2003.1250414;10.1109/VISUAL.2004.89;10.1109/TVCG.2009.185;10.1109/TVCG.2009.204;10.1109/VISUAL.2003.1250384;10.1109/VISUAL.1998.745713;10.1109/TVCG.2006.157;10.1109/TVCG.2010.145;10.1109/TVCG.2015.2467433;10.1109/VISUAL.2003.1250412;10.1109/VISUAL.1998.745300;10.1109/TVCG.2008.119;10.1109/VISUAL.2004.52	Volume Rendering;Isosurface;Multidimensional Data	University of Utah##SCI InstituteUniversity of UtahArgonne National Laboratory##ICSE, University of Utah##School of ComputingUniversity of Leeds##SCI InstituteUniversity of Utah
SciVis	2016	OSPRay - A CPU Ray Tracing Framework for Scientific Visualization	10.1109/TVCG.2016.2599041	http://dx.doi.org/10.1109/TVCG.2016.2599041	931	940	J	Scientific data is continually increasing in complexity, variety and size, making efficient visualization and specifically rendering an ongoing challenge. Traditional rasterization-based visualization approaches encounter performance and quality limitations, particularly in HPC environments without dedicated rendering hardware. In this paper, we present OSPRay, a turn-key CPU ray tracing framework oriented towards production-use scientific visualization which can utilize varying SIMD widths and multiple device backends found across diverse HPC resources. This framework provides a high-quality, efficient CPU-based solution for typical visualization workloads, which has already been integrated into several prevalent visualization packages. We show that this system delivers the performance, high-level API simplicity, and modular device support needed to provide a compelling new rendering framework for implementing efficient scientific visualization workflows.	Ingo Wald;Gregory P. Johnson;J. Amstutz;Carson Brownlee;Aaron Knoll;J. Jeffers;J. Gunther;Paul A. Navrátil	Intel Corp;Intel Corp;Intel Corp;Intel Corp;SCI InsituteUniversity of Utah;Intel Corp;Intel Corp;Texas Advanced Computing Center	10.1109/SciVis.2015.7429492;10.1109/TVCG.2010.173;10.1109/TVCG.2015.2467963		Intel Corp##Intel Corp##Intel Corp##Intel Corp##SCI InsituteUniversity of Utah##Intel Corp##Intel Corp##Texas Advanced Computing Center
SciVis	2016	Progressive Direct Volume-to-Volume Transformation	10.1109/TVCG.2016.2599042	http://dx.doi.org/10.1109/TVCG.2016.2599042	921	930	J	We present a novel technique to generate transformations between arbitrary volumes, providing both expressive distances and smooth interpolates. In contrast to conventional morphing or warping approaches, our technique requires no user guidance, intermediate representations (like extracted features), or blending, and imposes no restrictions regarding shape or structure. Our technique operates directly on the volumetric data representation, and while linear programming approaches could solve the underlying problem optimally, their polynomial complexity makes them infeasible for high-resolution volumes. We therefore propose a progressive refinement approach designed for parallel execution that is able to quickly deliver approximate results that are iteratively improved toward the optimum. On this basis, we further present a new approach for the streaming selection of time steps in temporal data that allows for the reconstruction of the full sequence with a user-specified error bound. We finally demonstrate the utility of our technique for different applications, compare our approach against alternatives, and evaluate its characteristics with a variety of different data sets.	Steffen Frey;Thomas Ertl	University of Stuttgart;University of Stuttgart	10.1109/TVCG.2008.140;10.1109/TVCG.2012.284;10.1109/VISUAL.1994.346333;10.1109/TVCG.2008.143;10.1109/TVCG.2009.200;10.1109/VISUAL.2002.1183809	Volume transformation;Volume visualization;progressive;automatic;parallel;time-varying data;streaming data	University of Stuttgart##University of Stuttgart
SciVis	2016	A Versatile and Efficient GPU Data Structure for Spatial Indexing	10.1109/TVCG.2016.2599043	http://dx.doi.org/10.1109/TVCG.2016.2599043	911	920	J	In this paper we present a novel GPU-based data structure for spatial indexing. Based on Fenwick trees-a special type of binary indexed trees-our data structure allows construction in linear time. Updates and prefixes can be computed in logarithmic time, whereas point queries require only constant time on average. Unlike competing data structures such as summed-area tables and spatial hashing, our data structure requires a constant amount of bits for each data element, and it offers unconstrained point queries. This property makes our data structure ideally suited for applications requiring unconstrained indexing of large data, such as block-storage of large and block-sparse volumes. Finally, we provide asymptotic bounds on both run-time and memory requirements, and we show applications for which our new data structure is useful.	Jens Schneider;Peter Rautek	Visual Computing Center(VCC)King Abdullah University of Science and Technology (KAUST);Visual Computing Center(VCC)King Abdullah University of Science and Technology (KAUST)	10.1109/TVCG.2015.2467331	GPU-based Data Structures;Binary Index Trees;Sparse Data	Visual Computing Center(VCC)King Abdullah University of Science and Technology (KAUST)##Visual Computing Center(VCC)King Abdullah University of Science and Technology (KAUST)
SciVis	2016	GlyphLens: View-Dependent Occlusion Management in the Interactive Glyph Visualization	10.1109/TVCG.2016.2599049	http://dx.doi.org/10.1109/TVCG.2016.2599049	891	900	J	Glyph as a powerful multivariate visualization technique is used to visualize data through its visual channels. To visualize 3D volumetric dataset, glyphs are usually placed on 2D surface, such as the slicing plane or the feature surface, to avoid occluding each other. However, the 3D spatial structure of some features may be missing. On the other hand, placing large number of glyphs over the entire 3D space results in occlusion and visual clutter that make the visualization ineffective. To avoid the occlusion, we propose a view-dependent interactive 3D lens that removes the occluding glyphs by pulling the glyphs aside through the animation. We provide two space deformation models and two lens shape models to displace the glyphs based on their spatial distributions. After the displacement, the glyphs around the user-interested region are still visible as the context information, and their spatial structures are preserved. Besides, we attenuate the brightness of the glyphs inside the lens based on their depths to provide more depth cue. Furthermore, we developed an interactive glyph visualization system to explore different glyph-based visualization applications. In the system, we provide a few lens utilities that allows users to pick a glyph or a feature and look at it from different view directions. We compare different display/interaction techniques to visualize/manipulate our lens and glyphs.	Xin Tong;Cheng Li;Han-Wei Shen	The Ohio State University;The Ohio State University;The Ohio State University	10.1109/TVCG.2013.121;10.1109/INFVIS.1996.559215;10.1109/TVCG.2010.199;10.1109/TVCG.2010.127;10.1109/VISUAL.2003.1250400;10.1109/VISUAL.1993.398849;10.1109/TVCG.2015.2467202;10.1109/TVCG.2006.167;10.1109/TVCG.2010.157	View-dependent visualization;focus + context techniques;manipulation and deformation;glyph-based techniques;human-computer interaction	The Ohio State University##The Ohio State University##The Ohio State University
SciVis	2016	velle: Printable Interactive Volume Visualization	10.1109/TVCG.2016.2599211	http://dx.doi.org/10.1109/TVCG.2016.2599211	861	870	J	Interaction is an indispensable aspect of data visualization. The presentation of volumetric data, in particular, often significantly benefits from interactive manipulation of parameters such as transfer functions, rendering styles, or clipping planes. However, when we want to create hardcopies of such visualizations, this essential aspect is lost. In this paper, we present a novel approach for creating hardcopies of volume visualizations which preserves a certain degree of interactivity. We present a method for automatically generating Volvelles, printable tangible wheel charts that can be manipulated to explore different parameter settings. Our interactive system allows the flexible mapping of arbitrary visualization parameters and supports advanced features such as linked views. The resulting designs can be easily reproduced using a standard printer and assembled within a few minutes.	Sergej Stoppel;Stefan Bruckner	University of Bergen;University of Bergen	10.1109/TVCG.2014.2346292;10.1109/TVCG.2013.121;10.1109/TVCG.2013.134;10.1109/TVCG.2006.140;10.1109/TVCG.2006.148;10.1109/VISUAL.1999.809871;10.1109/TVCG.2015.2467294;10.1109/VISUAL.2005.1532856;10.1109/TVCG.2014.2352953;10.1109/TVCG.2007.70584	Illustrative Visualization;Physical Visualization;Interaction;Volume Visualization	University of Bergen##University of Bergen
SciVis	2016	Categorical Colormap Optimization with Visualization Case Studies	10.1109/TVCG.2016.2599214	http://dx.doi.org/10.1109/TVCG.2016.2599214	871	880	J	Mapping a set of categorical values to different colors is an elementary technique in data visualization. Users of visualization software routinely rely on the default colormaps provided by a system, or colormaps suggested by software such as ColorBrewer. In practice, users often have to select a set of colors in a semantically meaningful way (e.g., based on conventions, color metaphors, and logological associations), and consequently would like to ensure their perceptual differentiation is optimized. In this paper, we present an algorithmic approach for maximizing the perceptual distances among a set of given colors. We address two technical problems in optimization, i.e., (i) the phenomena of local maxima that halt the optimization too soon, and (ii) the arbitrary reassignment of colors that leads to the loss of the original semantic association. We paid particular attention to different types of constraints that users may wish to impose during the optimization process. To demonstrate the effectiveness of this work, we tested this technique in two case studies. To reach out to a wider range of users, we also developed a web application called Colourmap Hospital.	H. Fang;Simon J. Walton;E. Delahaye;J. Harris;D. A. Storchak;Min Chen 0001	University of Oxford and International Seismological Centre;University of Oxford, UK;International Seismological Centre, UK;International Seismological Centre, UK;International Seismological Centre, UK;University of Oxford, UK	10.1109/VISUAL.1996.568118;10.1109/TVCG.2014.2346978;10.1109/TVCG.2008.112;10.1109/VISUAL.1995.480803;10.1109/TVCG.2010.150;10.1109/VISUAL.2002.1183788;10.1109/TVCG.2008.118	London tube map;Color;categorical colormap;optimization;seismological data visualization	University of Oxford and International Seismological Centre##University of Oxford, UK##International Seismological Centre, UK##International Seismological Centre, UK##International Seismological Centre, UK##University of Oxford, UK
SciVis	2016	Hybrid Tactile/Tangible Interaction for 3D Data Exploration	10.1109/TVCG.2016.2599217	http://dx.doi.org/10.1109/TVCG.2016.2599217	881	890	J	We present the design and evaluation of an interface that combines tactile and tangible paradigms for 3D visualization. While studies have demonstrated that both tactile and tangible input can be efficient for a subset of 3D manipulation tasks, we reflect here on the possibility to combine the two complementary input types. Based on a field study and follow-up interviews, we present a conceptual framework of the use of these different interaction modalities for visualization both separately and combined-focusing on free exploration as well as precise control. We present a prototypical application of a subset of these combined mappings for fluid dynamics data visualization using a portable, position-aware device which offers both tactile input and tangible sensing. We evaluate our approach with domain experts and report on their qualitative feedback.	Lonni Besançon;Paul Issartel;Mehdi Ammi;Tobias Isenberg 0001	Inria Saclay, Univ. Paris Saclay, France;Univ. Paris Saclay, France;Limsi/CNRS, France;Inria, France	10.1109/TVCG.2013.121;10.1109/TVCG.2010.164;10.1109/VISUAL.2004.47;10.1109/TVCG.2007.70515;10.1109/TVCG.2010.157;10.1109/VISUAL.2005.1532846;10.1109/TVCG.2011.224;10.1109/TVCG.2013.124;10.1109/TVCG.2015.2467202;10.1109/TVCG.2012.292;10.1109/TVCG.2013.126;10.1109/TVCG.2012.217	3D data visualization;Interaction;tactile input;tangible input	Inria Saclay, Univ. Paris Saclay, France##Univ. Paris Saclay, France##Limsi/CNRS, France##Inria, France
VAST	2016	A Visual Analytics Approach for Understanding Reasons behind Snowballing and Comeback in MOBA Games	10.1109/TVCG.2016.2598415	http://dx.doi.org/10.1109/TVCG.2016.2598415	211	220	J	To design a successful Multiplayer Online Battle Arena (MOBA) game, the ratio of snowballing and comeback occurrences to all matches played must be maintained at a certain level to ensure its fairness and engagement. Although it is easy to identify these two types of occurrences, game developers often find it difficult to determine their causes and triggers with so many game design choices and game parameters involved. In addition, the huge amounts of MOBA game data are often heterogeneous, multi-dimensional and highly dynamic in terms of space and time, which poses special challenges for analysts. In this paper, we present a visual analytics system to help game designers find key events and game parameters resulting in snowballing or comeback occurrences in MOBA game data. We follow a user-centered design process developing the system with game analysts and testing with real data of a trial version MOBA game from NetEase Inc. We apply novel visualization techniques in conjunction with well-established ones to depict the evolution of players' positions, status and the occurrences of events. Our system can reveal players' strategies and performance throughout a single match and suggest patterns, e.g., specific player' actions and game events, that have led to the final occurrences. We further demonstrate a workflow of leveraging human analyzed patterns to improve the scalability and generality of match data analysis. Finally, we validate the usability of our system by proving the identified patterns are representative in snowballing or comeback matches in a one-month-long MOBA tournament dataset.	Quan Li;Peng Xu;Yeukyin Chan;Yun Wang;Zhipeng Wang;Huamin Qu;Xiaojuan Ma	Hong Kong University of Science and Technology;NetEase, Inc.;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;China Academy of Art;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology	10.1109/TVCG.2014.2346445;10.1109/VISUAL.2004.120;10.1109/VAST.2015.7347633;10.1109/VAST.2014.7042477;10.1109/VAST.2014.7042478;10.1109/TVCG.2013.192;10.1109/TVCG.2012.263	Game play data visualization;visual knowledge discovery;visual knowledge representation;and game reconstruction	Hong Kong University of Science and Technology##NetEase, Inc.##Hong Kong University of Science and Technology##Hong Kong University of Science and Technology##China Academy of Art##Hong Kong University of Science and Technology##Hong Kong University of Science and Technology
VAST	2016	SemanticTraj: A New Approach to Interacting with Massive Taxi Trajectories	10.1109/TVCG.2016.2598416	http://dx.doi.org/10.1109/TVCG.2016.2598416	11	20	J	Massive taxi trajectory data is exploited for knowledge discovery in transportation and urban planning. Existing tools typically require users to select and brush geospatial regions on a map when retrieving and exploring taxi trajectories and passenger trips. To answer seemingly simple questions such as &#x201C;What were the taxi trips starting from Main Street and ending at Wall Street in the morning?&#x201D; or &#x201C;Where are the taxis arriving at the Art Museum at noon typically coming from?&#x201D;, tedious and time consuming interactions are usually needed since the numeric GPS points of trajectories are not directly linked to the keywords such as &#x201C;Main Street&#x201D;, &#x201C;Wall Street&#x201D;, and &#x201C;Art Museum&#x201D;. In this paper, we present SemanticTraj, a new method for managing and visualizing taxi trajectory data in an intuitive, semantic rich, and efficient means. With SemanticTraj, domain and public users can find answers to the aforementioned questions easily through direct queries based on the terms. They can also interactively explore the retrieved data in visualizations enhanced by semantic information of the trajectories and trips. In particular, taxi trajectories are converted into taxi documents through a textualization transformation process. This process maps GPS points into a series of street/POI names and pick-up/drop-off locations. It also converts vehicle speeds into user-defined descriptive terms. Then, a corpus of taxi documents is formed and indexed to enable flexible semantic queries over a text search engine. Semantic labels and meta-summaries of the results are integrated with a set of visualizations in a SemanticTraj prototype, which helps users study taxi trajectories quickly and easily. A set of usage scenarios are presented to show the usability of the system. We also collected feedback from domain experts and conducted a preliminary user study to evaluate the visual system.	Shamal Al-Dohuki;Yingyu Wu;Farah Kamw;Jing Yang;Xin Li;Ye Zhao;Xinyue Ye;Wei Chen;Chao Ma;Fei Wang	Kent State University;Kent State University;Kent State University;UNC Charlotte;China Petroleum University;Kent State University;Kent State University;Zhejiang University;Kent State University;Zhejiang University	10.1109/TVCG.2015.2467732;10.1109/TVCG.2013.226;10.1109/VAST.2014.7042486;10.1109/VAST.2011.6102455;10.1109/TVCG.2014.2346746;10.1109/TVCG.2013.228;10.1109/VAST.2010.5652885	Taxi Trajectories;Taxi Document;Textualization;Name Query;Semantic Interaction;Text Search Engine	Kent State University##Kent State University##Kent State University##UNC Charlotte##China Petroleum University##Kent State University##Kent State University##Zhejiang University##Kent State University##Zhejiang University
VAST	2016	SmartAdP: Visual Analytics of Large-scale Taxi Trajectories for Selecting Billboard Locations	10.1109/TVCG.2016.2598432	http://dx.doi.org/10.1109/TVCG.2016.2598432	1	10	J	The problem of formulating solutions immediately and comparing them rapidly for billboard placements has plagued advertising planners for a long time, owing to the lack of efficient tools for in-depth analyses to make informed decisions. In this study, we attempt to employ visual analytics that combines the state-of-the-art mining and visualization techniques to tackle this problem using large-scale GPS trajectory data. In particular, we present SmartAdP, an interactive visual analytics system that deals with the two major challenges including finding good solutions in a huge solution space and comparing the solutions in a visual and intuitive manner. An interactive framework that integrates a novel visualization-driven data mining model enables advertising planners to effectively and efficiently formulate good candidate solutions. In addition, we propose a set of coupled visualizations: a solution view with metaphor-based glyphs to visualize the correlation between different solutions; a location view to display billboard locations in a compact manner; and a ranking view to present multi-typed rankings of the solutions. This system has been demonstrated using case studies with a real-world dataset and domain-expert interviews. Our approach can be adapted for other location selection problems such as selecting locations of retail stores or restaurants using trajectory data.	Dongyu Liu;Di Weng;Yuhong Li;Jie Bao 0003;Yu Zheng;Huamin Qu;Yingcai Wu	Zhejiang UniversityHong Kong University of Science and Technology;State Key Lab of CAD & CGZhejiang University;University of Macau;Microsoft Research, Beijing, China;Microsoft Research, Beijing, China;Hong Kong University of Science and Technology;State Key Lab of CAD & CGZhejiang University	10.1109/TVCG.2013.122;10.1109/TVCG.2015.2467051;10.1109/TVCG.2013.226;10.1109/VAST.2011.6102455;10.1109/TVCG.2013.228;10.1109/TVCG.2015.2467112;10.1109/TVCG.2012.265;10.1109/TVCG.2010.183;10.1109/TVCG.2014.2346912;10.1109/TVCG.2007.70521;10.1109/TVCG.2015.2467771;10.1109/TVCG.2013.173;10.1109/TVCG.2011.181;10.1109/TVCG.2009.111	optimal billboard locations;taxi trajectory;visual analytics;comparative analysis	Zhejiang UniversityHong Kong University of Science and Technology##State Key Lab of CAD & CGZhejiang University##University of Macau##Microsoft Research, Beijing, China##Microsoft Research, Beijing, China##Hong Kong University of Science and Technology##State Key Lab of CAD & CGZhejiang University
VAST	2016	Visual Analysis of MOOC Forums with iForum	10.1109/TVCG.2016.2598444	http://dx.doi.org/10.1109/TVCG.2016.2598444	201	210	J	Discussion forums of Massive Open Online Courses (MOOC) provide great opportunities for students to interact with instructional staff as well as other students. Exploration of MOOC forum data can offer valuable insights for these staff to enhance the course and prepare the next release. However, it is challenging due to the large, complicated, and heterogeneous nature of relevant datasets, which contain multiple dynamically interacting objects such as users, posts, and threads, each one including multiple attributes. In this paper, we present a design study for developing an interactive visual analytics system, called iForum, that allows for effectively discovering and understanding temporal patterns in MOOC forums. The design study was conducted with three domain experts in an iterative manner over one year, including a MOOC instructor and two official teaching assistants. iForum offers a set of novel visualization designs for presenting the three interleaving aspects of MOOC forums (i.e., posts, users, and threads) at three different scales. To demonstrate the effectiveness and usefulness of iForum, we describe a case study involving field experts, in which they use iForum to investigate real MOOC forum data for a course on JAVA programming.	Siwei Fu;Jian Zhao;Weiwei Cui;Huamin Qu	Hong Kong University of Science and Technology;Autodesk Research;Microsoft Research;Hong Kong University of Science and Technology	10.1109/TVCG.2006.147;10.1109/TVCG.2007.70535;10.1109/INFVIS.2003.1249028;10.1109/TVCG.2015.2467555	Discussion forum;MOOC;temporal visualization;visual analytics	Hong Kong University of Science and Technology##Autodesk Research##Microsoft Research##Hong Kong University of Science and Technology
VAST	2016	TopicLens: Efficient Multi-Level Visual Topic Exploration of Large-Scale Document Collections	10.1109/TVCG.2016.2598445	http://dx.doi.org/10.1109/TVCG.2016.2598445	151	160	J	Topic modeling, which reveals underlying topics of a document corpus, has been actively adopted in visual analytics for large-scale document collections. However, due to its significant processing time and non-interactive nature, topic modeling has so far not been tightly integrated into a visual analytics workflow. Instead, most such systems are limited to utilizing a fixed, initial set of topics. Motivated by this gap in the literature, we propose a novel interaction technique called TopicLens that allows a user to dynamically explore data through a lens interface where topic modeling and the corresponding 2D embedding are efficiently computed on the fly. To support this interaction in real time while maintaining view consistency, we propose a novel efficient topic modeling method and a semi-supervised 2D embedding algorithm. Our work is based on improving state-of-the-art methods such as nonnegative matrix factorization and t-distributed stochastic neighbor embedding. Furthermore, we have built a web-based visual analytics system integrated with TopicLens. We use this system to measure the performance and the visualization quality of our proposed methods. We provide several scenarios showcasing the capability of TopicLens using real-world datasets.	Minjeong Kim;Kyeongpil Kang;Deok Gun Park;Jaegul Choo;Niklas Elmqvist	Korea University;Korea University;University of Maryland, College Park, MD, USA;Korea University;University of Maryland, College Park, MD, USA	10.1109/INFVIS.2003.1249014;10.1109/TVCG.2013.212;10.1109/INFVIS.2003.1249008;10.1109/INFVIS.2004.43;10.1109/TVCG.2014.2346574;10.1109/TVCG.2011.239;10.1109/TVCG.2010.154;10.1109/VAST.2014.7042494	topic modeling;nonnegative matrix factorization;t-distributed stochastic neighbor embedding;magic lens;text analytics	Korea University##Korea University##University of Maryland, College Park, MD, USA##Korea University##University of Maryland, College Park, MD, USA
VAST	2016	AxiSketcher: Interactive Nonlinear Axis Mapping of Visualizations through User Drawings	10.1109/TVCG.2016.2598446	http://dx.doi.org/10.1109/TVCG.2016.2598446	221	230	J	Visual analytics techniques help users explore high-dimensional data. However, it is often challenging for users to express their domain knowledge in order to steer the underlying data model, especially when they have little attribute-level knowledge. Furthermore, users' complex, high-level domain knowledge, compared to low-level attributes, posits even greater challenges. To overcome these challenges, we introduce a technique to interpret a user's drawings with an interactive, nonlinear axis mapping approach called AxiSketcher. This technique enables users to impose their domain knowledge on a visualization by allowing interaction with data entries rather than with data attributes. The proposed interaction is performed through directly sketching lines over the visualization. Using this technique, users can draw lines over selected data points, and the system forms the axes that represent a nonlinear, weighted combination of multidimensional attributes. In this paper, we describe our techniques in three areas: 1) the design space of sketching methods for eliciting users' nonlinear domain knowledge; 2) the underlying model that translates users' input, extracts patterns behind the selected data points, and results in nonlinear axes reflecting users' complex intent; and 3) the interactive visualization for viewing, assessing, and reconstructing the newly formed, nonlinear axes.	Bum Chul Kwon;Hannah Kim;Emily Wall;Jaegul Choo;Haesun Park;Alex Endert	IBM T.J. Watson Research Center, Yorktown Heights, NY, USA;Georgia Institute of Technology, Atlanta, GA, USA;Georgia Institute of Technology, Atlanta, GA, USA;Korea University, Seoul, South Korea;Georgia Institute of Technology, Atlanta, GA, USA;Georgia Institute of Technology, Atlanta, GA, USA	10.1109/INFVIS.2004.60;10.1109/TVCG.2013.190;10.1109/TVCG.2015.2467615;10.1109/TVCG.2013.188;10.1109/TVCG.2014.2346481;10.1109/VAST.2011.6102449;10.1109/TVCG.2012.262;10.1109/TVCG.2015.2467591;10.1109/VAST.2010.5652443;10.1109/TVCG.2011.261;10.1109/TVCG.2013.191;10.1109/TVCG.2013.212;10.1109/TVCG.2013.167;10.1109/VAST.2012.6400486	axis mapping;interactive model steering;sketch;axis visualization;human-centered visual analytics	IBM T.J. Watson Research Center, Yorktown Heights, NY, USA##Georgia Institute of Technology, Atlanta, GA, USA##Georgia Institute of Technology, Atlanta, GA, USA##Korea University, Seoul, South Korea##Georgia Institute of Technology, Atlanta, GA, USA##Georgia Institute of Technology, Atlanta, GA, USA
VAST	2016	TextTile: An Interactive Visualization Tool for Seamless Exploratory Analysis of Structured Data and Unstructured Text	10.1109/TVCG.2016.2598447	http://dx.doi.org/10.1109/TVCG.2016.2598447	161	170	J	We describe TextTile, a data visualization tool for investigation of datasets and questions that require seamless and flexible analysis of structured data and unstructured text. TextTile is based on real-world data analysis problems gathered through our interaction with a number of domain experts and provides a general purpose solution to such problems. The system integrates a set of operations that can interchangeably be applied to the structured as well as to unstructured text part of the data to generate useful data summaries. Such summaries are then organized in visual tiles in a grid layout to allow their analysis and comparison. We validate TextTile with task analysis, use cases and a user study showing the system can be easily learned and proficiently used to carry out nontrivial tasks.	Cristian Felix;Anshul Vikram Pandey;Enrico Bertini	New York University;New York University;New York University	10.1109/TVCG.2011.176;10.1109/INFVIS.2000.885098;10.1109/VAST.2012.6400485;10.1109/VAST.2009.5333443;10.1109/TVCG.2015.2467191;10.1109/TVCG.2009.128;10.1109/INFVIS.2000.885086;10.1109/TVCG.2010.183;10.1109/TVCG.2014.2346919	Exploratory Text Analysis;Knowledge Discovery;Text Visualization	New York University##New York University##New York University
VAST	2016	Toward Theoretical Techniques for Measuring the Use of Human Effort in Visual Analytic Systems	10.1109/TVCG.2016.2598460	http://dx.doi.org/10.1109/TVCG.2016.2598460	121	130	J	Visual analytic systems have long relied on user studies and standard datasets to demonstrate advances to the state of the art, as well as to illustrate the efficiency of solutions to domain-specific challenges. This approach has enabled some important comparisons between systems, but unfortunately the narrow scope required to facilitate these comparisons has prevented many of these lessons from being generalized to new areas. At the same time, advanced visual analytic systems have made increasing use of human-machine collaboration to solve problems not tractable by machine computation alone. To continue to make progress in modeling user tasks in these hybrid visual analytic systems, we must strive to gain insight into what makes certain tasks more complex than others. This will require the development of mechanisms for describing the balance to be struck between machine and human strengths with respect to analytical tasks and workload. In this paper, we argue for the necessity of theoretical tools for reasoning about such balance in visual analytic systems and demonstrate the utility of the Human Oracle Model for this purpose in the context of sensemaking in visual analytics. Additionally, we make use of the Human Oracle Model to guide the development of a new system through a case study in the domain of cybersecurity.	R. Jordan Crouser;Lyndsey Franklin;Alex Endert;Kristin A. Cook	Smith College;Smith College;Smith College;Smith College	10.1109/VAST.2011.6102467;10.1109/VAST.2010.5652910;10.1109/VAST.2011.6102438;10.1109/TVCG.2012.195;10.1109/VAST.2015.7347625;10.1109/VAST.2007.4389009;10.1109/VAST.2011.6102449;10.1109/VAST.2012.6400486	Theoretical models;human oracle;visual analytics;mixed initiative systems;semantic interaction;sensemaking	Smith College##Smith College##Smith College##Smith College
VAST	2016	AnaFe: Visual Analytics of Image-derived Temporal Features Focusing on the Spleen	10.1109/TVCG.2016.2598463	http://dx.doi.org/10.1109/TVCG.2016.2598463	171	180	J	We present a novel visualization framework, AnaFe, targeted at observing changes in the spleen over time through multiple image-derived features. Accurate monitoring of progressive changes is crucial for diseases that result in enlargement of the organ. Our system is comprised of multiple linked views combining visualization of temporal 3D organ data, related measurements, and features. Thus it enables the observation of progression and allows for simultaneous comparison within and between the subjects. AnaFe offers insights into the overall distribution of robustly extracted and reproducible quantitative imaging features and their changes within the population, and also enables detailed analysis of individual cases. It performs similarity comparison of temporal series of one subject to all other series in both sick and healthy groups. We demonstrate our system through two use case scenarios on a population of 189 spleen datasets from 68 subjects with various conditions observed over time.	Ievgeniia Gutenko;Konstantin Dmitriev;Arie E. Kaufman;Matthew Barish	Computer Science Department, Stony Brook University, NY;Computer Science Department, Stony Brook University, NY;Computer Science Department, Stony Brook University, NY;Computer Science Department, Stony Brook University, NY	10.1109/TVCG.2014.2346591;10.1109/TVCG.2009.152;10.1109/TVCG.2015.2467622;10.1109/TVCG.2014.2346682;10.1109/TVCG.2012.225;10.1109/VISUAL.2000.885739;10.1109/TVCG.2013.200;10.1109/VAST.2006.261421	Visual Knowledge Discovery;Temporal Feature Analysis;Radiomics;Spleen;Abdominal Imaging	Computer Science Department, Stony Brook University, NY##Computer Science Department, Stony Brook University, NY##Computer Science Department, Stony Brook University, NY##Computer Science Department, Stony Brook University, NY
VAST	2016	NameClarifier: A Visual Analytics System for Author Name Disambiguation	10.1109/TVCG.2016.2598465	http://dx.doi.org/10.1109/TVCG.2016.2598465	141	150	J	In this paper, we present a novel visual analytics system called NameClarifier to interactively disambiguate author names in publications by keeping humans in the loop. Specifically, NameClarifier quantifies and visualizes the similarities between ambiguous names and those that have been confirmed in digital libraries. The similarities are calculated using three key factors, namely, co-authorships, publication venues, and temporal information. Our system estimates all possible allocations, and then provides visual cues to users to help them validate every ambiguous case. By looping users in the disambiguation process, our system can achieve more reliable results than general data mining models for highly ambiguous cases. In addition, once an ambiguous case is resolved, the result is instantly added back to our system and serves as additional cues for all the remaining unidentified names. In this way, we open up the black box in traditional disambiguation processes, and help intuitively and comprehensively explain why the corresponding classifications should hold. We conducted two use cases and an expert review to demonstrate the effectiveness of NameClarifier.	Qiaomu Shen;Tongshuang Wu;Haiyan Yang;Yanhong Wu;Huamin Qu;Weiwei Cui	Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Microsoft Research	10.1109/TVCG.2012.252;10.1109/TVCG.2011.188;10.1109/VAST.2006.261429	Name disambiguation;analytical reasoning	Hong Kong University of Science and Technology##Hong Kong University of Science and Technology##Hong Kong University of Science and Technology##Hong Kong University of Science and Technology##Hong Kong University of Science and Technology##Microsoft Research
VAST	2016	Visualizing Dimension Coverage to Support Exploratory Analysis	10.1109/TVCG.2016.2598466	http://dx.doi.org/10.1109/TVCG.2016.2598466	21	30	J	Data analysis involves constantly formulating and testing new hypotheses and questions about data. When dealing with a new dataset, especially one with many dimensions, it can be cumbersome for the analyst to clearly remember which aspects of the data have been investigated (i.e., visually examined for patterns, trends, outliers etc.) and which combinations have not. Yet this information is critical to help the analyst formulate new questions that they have not already answered. We observe that for tabular data, questions are typically comprised of varying combinations of data dimensions (e.g., what are the trends of Sales and Profit for different Regions?). We propose representing analysis history from the angle of dimension coverage (i.e., which data dimensions have been investigated and in which combinations). We use scented widgets to incorporate dimension coverage of the analysts' past work into interaction widgets of a visualization tool. We demonstrate how this approach can assist analysts with the question formation process. Our approach extends the concept of scented widgets to reveal aspects of one's own analysis history, and offers a different perspective on one's past work than typical visualization history tools. Results of our empirical study showed that participants with access to embedded dimension coverage information relied on this information when formulating questions, asked more questions about the data, generated more top-level findings, and showed greater breadth of their analysis without sacrificing depth.	Ali Sarvghad;Melanie Tory;Narges Mahyar	University of Victoria;Tableau Research;University of British Columbia	10.1109/TVCG.2015.2467191;10.1109/TVCG.2006.120;10.1109/INFVIS.1999.801862;10.1109/INFVIS.2000.885086;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2014.2346452;10.1109/VAST.2009.5333020;10.1109/INFVIS.2001.963289;10.1109/TVCG.2008.137;10.1109/TVCG.2015.2467611;10.1109/VISUAL.1993.398857;10.1109/TVCG.2007.70589;10.1109/TVCG.2013.167;10.1109/TVCG.2008.109	Dimension coverage;Tabular data;History;Empirical laboratory study;Exploratory data analysis;Scented widgets	University of Victoria##Tableau Research##University of British Columbia
VAST	2016	Magnostics: Image-Based Search of Interesting Matrix Views for Guided Network Exploration	10.1109/TVCG.2016.2598467	http://dx.doi.org/10.1109/TVCG.2016.2598467	31	40	J	In this work we address the problem of retrieving potentially interesting matrix views to support the exploration of networks. We introduce Matrix Diagnostics (or Magnostics), following in spirit related approaches for rating and ranking other visualization techniques, such as Scagnostics for scatter plots. Our approach ranks matrix views according to the appearance of specific visual patterns, such as blocks and lines, indicating the existence of topological motifs in the data, such as clusters, bi-graphs, or central nodes. Magnostics can be used to analyze, query, or search for visually similar matrices in large collections, or to assess the quality of matrix reordering algorithms. While many feature descriptors for image analyzes exist, there is no evidence how they perform for detecting patterns in matrices. In order to make an informed choice of feature descriptors for matrix diagnostics, we evaluate 30 feature descriptors-27 existing ones and three new descriptors that we designed specifically for MAGNOSTICS-with respect to four criteria: pattern response, pattern variability, pattern sensibility, and pattern discrimination. We conclude with an informed set of six descriptors as most appropriate for Magnostics and demonstrate their application in two scenarios; exploring a large collection of matrices and analyzing temporal networks.	Michael Behrisch;Benjamin Bach;Michael Hund;Michael Delz;Laura von Rüden;Jean-Daniel Fekete;Tobias Schreck	University of Konstanz, Germany;Microsoft Research-Inria Joint Centre, Saclay, France;University of Konstanz, Germany;University of Konstanz, Germany;Capgemini, RWTH Aachen University;Inria, Saclay, France;Graz University of Technology, Austria	10.1109/VAST.2012.6400488;10.1109/INFVIS.2004.15;10.1109/VAST.2014.7042480;10.1109/VAST.2010.5652433;10.1109/TVCG.2010.184;10.1109/VAST.2006.261423;10.1109/TVCG.2007.70582;10.1109/TVCG.2007.70535;10.1109/TVCG.2011.229;10.1109/VAST.2010.5652392;10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2004.3	Matrix Visualization;Visual Quality Measures;Quality Metrics;Feature Detection/Selection;Relational Data	University of Konstanz, Germany##Microsoft Research-Inria Joint Centre, Saclay, France##University of Konstanz, Germany##University of Konstanz, Germany##Capgemini, RWTH Aachen University##Inria, Saclay, France##Graz University of Technology, Austria
VAST	2016	Characterizing Guidance in Visual Analytics	10.1109/TVCG.2016.2598468	http://dx.doi.org/10.1109/TVCG.2016.2598468	111	120	J	Visual analytics (VA) is typically applied in scenarios where complex data has to be analyzed. Unfortunately, there is a natural correlation between the complexity of the data and the complexity of the tools to study them. An adverse effect of complicated tools is that analytical goals are more difficult to reach. Therefore, it makes sense to consider methods that guide or assist users in the visual analysis process. Several such methods already exist in the literature, yet we are lacking a general model that facilitates in-depth reasoning about guidance. We establish such a model by extending van Wijk's model of visualization with the fundamental components of guidance. Guidance is defined as a process that gradually narrows the gap that hinders effective continuation of the data analysis. We describe diverse inputs based on which guidance can be generated and discuss different degrees of guidance and means to incorporate guidance into VA tools. We use existing guidance approaches from the literature to illustrate the various aspects of our model. As a conclusion, we identify research challenges and suggest directions for future studies. With our work we take a necessary step to pave the way to a systematic development of guidance techniques that effectively support users in the context of VA.	Davide Ceneda;Theresia Gschwandtner;Thorsten May;Silvia Miksch;Hans-Jörg Schulz;Marc Streit;Christian Tominski	Vienna University of Technology, Austria;Vienna University of Technology, Austria;Fraunhofer IGD, Darmstadt, Germany;Vienna University of Technology, Austria;University of Rostock, Germany;Johannes Kepler University, Linz, Austria;University of Rostock, Germany	10.1109/VISUAL.2000.885678;10.1109/TVCG.2015.2467191;10.1109/VISUAL.1990.146375;10.1109/TVCG.2014.2346260;10.1109/TVCG.2014.2346481;10.1109/INFVIS.2004.2;10.1109/TVCG.2013.120;10.1109/VISUAL.1997.663889;10.1109/TVCG.2015.2467691;10.1109/VISUAL.2002.1183803;10.1109/TVCG.2007.70589;10.1109/TVCG.2008.174;10.1109/TVCG.2014.2346482	Visual analytics;guidance model;assistance;user support	Vienna University of Technology, Austria##Vienna University of Technology, Austria##Fraunhofer IGD, Darmstadt, Germany##Vienna University of Technology, Austria##University of Rostock, Germany##Johannes Kepler University, Linz, Austria##University of Rostock, Germany
VAST	2016	PhenoStacks: Cross-Sectional Cohort Phenotype Comparison Visualizations	10.1109/TVCG.2016.2598469	http://dx.doi.org/10.1109/TVCG.2016.2598469	191	200	J	Cross-sectional phenotype studies are used by genetics researchers to better understand how phenotypes vary across patients with genetic diseases, both within and between cohorts. Analyses within cohorts identify patterns between phenotypes and patients (e.g., co-occurrence) and isolate special cases (e.g., potential outliers). Comparing the variation of phenotypes between two cohorts can help distinguish how different factors affect disease manifestation (e.g., causal genes, age of onset, etc.). PhenoStacks is a novel visual analytics tool that supports the exploration of phenotype variation within and between cross-sectional patient cohorts. By leveraging the semantic hierarchy of the Human Phenotype Ontology, phenotypes are presented in context, can be grouped and clustered, and are summarized via overviews to support the exploration of phenotype distributions. The design of PhenoStacks was motivated by formative interviews with genetics researchers: we distil high-level tasks, present an algorithm for simplifying ontology topologies for visualization, and report the results of a deployment evaluation with four expert genetics researchers. The results suggest that PhenoStacks can help identify phenotype patterns, investigate data quality issues, and inform data collection design.	Michael Glueck;Alina Gvozdik;Fanny Chevalier;Azam Khan;Michael Brudno;Daniel J. Wigdor	Autodesk ResearchUniversity of Toronto;University of Toronto;Inria;Autodesk Research;Hospital for Sick Children, University of Toronto, Toronto;University of Toronto	10.1109/TVCG.2014.2346248;10.1109/TVCG.2011.185;10.1109/TVCG.2014.2346279;10.1109/TVCG.2009.167;10.1109/TVCG.2013.124;10.1109/TVCG.2015.2467622;10.1109/TVCG.2015.2467733;10.1109/TVCG.2009.116	Cross-sectional cohort analysis;Phenotypes;Human Phenotype Ontology (HPO)	Autodesk ResearchUniversity of Toronto##University of Toronto##Inria##Autodesk Research##Hospital for Sick Children, University of Toronto, Toronto##University of Toronto
VAST	2016	Designing Progressive and Interactive Analytics Processes for High-Dimensional Data Analysis	10.1109/TVCG.2016.2598470	http://dx.doi.org/10.1109/TVCG.2016.2598470	131	140	J	In interactive data analysis processes, the dialogue between the human and the computer is the enabling mechanism that can lead to actionable observations about the phenomena being investigated. It is of paramount importance that this dialogue is not interrupted by slow computational mechanisms that do not consider any known temporal human-computer interaction characteristics that prioritize the perceptual and cognitive capabilities of the users. In cases where the analysis involves an integrated computational method, for instance to reduce the dimensionality of the data or to perform clustering, such non-optimal processes are often likely. To remedy this, progressive computations, where results are iteratively improved, are getting increasing interest in visual analytics. In this paper, we present techniques and design considerations to incorporate progressive methods within interactive analysis processes that involve high-dimensional data. We define methodologies to facilitate processes that adhere to the perceptual characteristics of users and describe how online algorithms can be incorporated within these. A set of design recommendations and according methods to support analysts in accomplishing high-dimensional data analysis tasks are then presented. Our arguments and decisions here are informed by observations gathered over a series of analysis sessions with analysts from finance. We document observations and recommendations from this study and present evidence on how our approach contribute to the efficiency and productivity of interactive visual analysis sessions involving high-dimensional data.	Cagatay Turkay;Erdem Kaya;Selim Balcisoy;Helwig Hauser	City University, London, UK;Sabanci University, Turkey;Sabanci University, Turkey;University of Bergen, Norway	10.1109/TVCG.2007.70539;10.1109/VAST.2008.4677361;10.1109/TVCG.2008.153;10.1109/TVCG.2014.2346481;10.1109/TVCG.2014.2346574;10.1109/TVCG.2007.70515;10.1109/TVCG.2012.213;10.1109/TVCG.2013.125;10.1109/TVCG.2012.256;10.1109/VAST.2008.4677357;10.1109/TVCG.2015.2467613;10.1109/TVCG.2014.2346265;10.1109/TVCG.2011.178;10.1109/INFVIS.2005.1532136;10.1109/INFVIS.1996.559223;10.1109/TVCG.2011.229;10.1109/TVCG.2008.125	Progressive analytics;high dimensional data;iterative refinement;visual analytics	City University, London, UK##Sabanci University, Turkey##Sabanci University, Turkey##University of Bergen, Norway
VAST	2016	A Grammar-based Approach for Modeling User Interactions and Generating Suggestions During the Data Exploration Process	10.1109/TVCG.2016.2598471	http://dx.doi.org/10.1109/TVCG.2016.2598471	41	50	J	Despite the recent popularity of visual analytics focusing on big data, little is known about how to support users that use visualization techniques to explore multi-dimensional datasets and accomplish specific tasks. Our lack of models that can assist end-users during the data exploration process has made it challenging to learn from the user's interactive and analytical process. The ability to model how a user interacts with a specific visualization technique and what difficulties they face are paramount in supporting individuals with discovering new patterns within their complex datasets. This paper introduces the notion of visualization systems understanding and modeling user interactions with the intent of guiding a user through a task thereby enhancing visual data exploration. The challenges faced and the necessary future steps to take are discussed; and to provide a working example, a grammar-based model is presented that can learn from user interactions, determine the common patterns among a number of subjects using a K-Reversible algorithm, build a set of rules, and apply those rules in the form of suggestions to new users with the goal of guiding them along their visual analytic process. A formal evaluation study with 300 subjects was performed showing that our grammar-based model is effective at capturing the interactive process followed by users and that further research in this area has the potential to positively impact how users interact with a visualization system.	Filip Dabek;Jesus J. Caban	National Intrepid Center of Excellence, Walter Reed National Military Medical Center, Bethesda, MD;National Intrepid Center of Excellence, Walter Reed National Military Medical Center, Bethesda, MD	10.1109/TVCG.2014.2346575;10.1109/TVCG.2015.2467613;10.1109/VAST.2010.5650854;10.1109/TVCG.2015.2467871;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2012.219;10.1109/VAST.2009.5333020;10.1109/VAST.2006.261436;10.1109/TVCG.2015.2467611;10.1109/TVCG.2015.2467551;10.1109/VAST.2008.4677365;10.1109/TVCG.2007.70589	Machine Learning;Visual Analytics;User Interactions;Analytic Provenance	National Intrepid Center of Excellence, Walter Reed National Military Medical Center, Bethesda, MD##National Intrepid Center of Excellence, Walter Reed National Military Medical Center, Bethesda, MD
VAST	2016	Blockwise Human Brain Network Visual Comparison Using NodeTrix Representation	10.1109/TVCG.2016.2598472	http://dx.doi.org/10.1109/TVCG.2016.2598472	181	190	J	Visually comparing human brain networks from multiple population groups serves as an important task in the field of brain connectomics. The commonly used brain network representation, consisting of nodes and edges, may not be able to reveal the most compelling network differences when the reconstructed networks are dense and homogeneous. In this paper, we leveraged the block information on the Region Of Interest (ROI) based brain networks and studied the problem of blockwise brain network visual comparison. An integrated visual analytics framework was proposed. In the first stage, a two-level ROI block hierarchy was detected by optimizing the anatomical structure and the predictive comparison performance simultaneously. In the second stage, the NodeTrix representation was adopted and customized to visualize the brain network with block information. We conducted controlled user experiments and case studies to evaluate our proposed solution. Results indicated that our visual analytics method outperformed the commonly used node-link graph and adjacency matrix design in the blockwise network comparison tasks. We have shown compelling findings from two real-world brain network data sets, which are consistent with the prior connectomics studies.	Xinsong Yang;Lei Shi;Madelaine Daianu;Hanghang Tong;Qingsong Liu;Paul M. Thompson	Chinese Academy of Sciences, SKLCSInstitute of Software;Chinese Academy of Sciences, SKLCSInstitute of Software;Imaging Genetics CenterMark & Mary Stevens Institute for Neuroimaging & InformaticsUniversity of Southern California;School of Computing, Informatics and Decision Systems EngineeringArizona State University;Chinese Academy of Sciences, SKLCSInstitute of Software;Imaging Genetics CenterMark & Mary Stevens Institute for Neuroimaging & InformaticsUniversity of Southern California	10.1109/TVCG.2014.2346312;10.1109/VISUAL.2005.1532773;10.1109/TVCG.2007.70582	Brain Network;Visual Comparison;Hybrid Representation	Chinese Academy of Sciences, SKLCSInstitute of Software##Chinese Academy of Sciences, SKLCSInstitute of Software##Imaging Genetics CenterMark & Mary Stevens Institute for Neuroimaging & InformaticsUniversity of Southern California##School of Computing, Informatics and Decision Systems EngineeringArizona State University##Chinese Academy of Sciences, SKLCSInstitute of Software##Imaging Genetics CenterMark & Mary Stevens Institute for Neuroimaging & InformaticsUniversity of Southern California
VAST	2016	A Visual Analytics Approach for Categorical Joint Distribution Reconstruction from Marginal Projections	10.1109/TVCG.2016.2598479	http://dx.doi.org/10.1109/TVCG.2016.2598479	51	60	J	Oftentimes multivariate data are not available as sets of equally multivariate tuples, but only as sets of projections into subspaces spanned by subsets of these attributes. For example, one may find data with five attributes stored in six tables of two attributes each, instead of a single table of five attributes. This prohibits the visualization of these data with standard high-dimensional methods, such as parallel coordinates or MDS, and there is hence the need to reconstruct the full multivariate (joint) distribution from these marginal ones. Most of the existing methods designed for this purpose use an iterative procedure to estimate the joint distribution. With insufficient marginal distributions and domain knowledge, they lead to results whose joint errors can be large. Moreover, enforcing smoothness for regularizations in the joint space is not applicable if the attributes are not numerical but categorical. We propose a visual analytics approach that integrates both anecdotal data and human experts to iteratively narrow down a large set of plausible solutions. The solution space is populated using a Monte Carlo procedure which uniformly samples the solution space. A level-of-detail high dimensional visualization system helps the user understand the patterns and the uncertainties. Constraints that narrow the solution space can then be added by the user interactively during the iterative exploration, and eventually a subset of solutions with narrow uncertainty intervals emerges.	Cong Xie;Wen Zhong;Klaus Mueller	Computer Science Department, Stony Brook University;Computer Science Department, Stony Brook University;Computer Science Department, Stony Brook University	10.1109/TVCG.2010.181;10.1109/TVCG.2013.190;10.1109/VAST.2009.5332586;10.1109/TVCG.2015.2467552;10.1109/VAST.2009.5332611;10.1109/TVCG.2010.183;10.1109/TVCG.2011.248	Parallel Coordinates;Joint Distribution Reconstruction;Solution Space;High-dimensional Data;Multivariate Data	Computer Science Department, Stony Brook University##Computer Science Department, Stony Brook University##Computer Science Department, Stony Brook University
VAST	2016	Visual Interaction with Dimensionality Reduction: A Structured Literature Analysis	10.1109/TVCG.2016.2598495	http://dx.doi.org/10.1109/TVCG.2016.2598495	241	250	J	Dimensionality Reduction (DR) is a core building block in visualizing multidimensional data. For DR techniques to be useful in exploratory data analysis, they need to be adapted to human needs and domain-specific problems, ideally, interactively, and on-the-fly. Many visual analytics systems have already demonstrated the benefits of tightly integrating DR with interactive visualizations. Nevertheless, a general, structured understanding of this integration is missing. To address this, we systematically studied the visual analytics and visualization literature to investigate how analysts interact with automatic DR techniques. The results reveal seven common interaction scenarios that are amenable to interactive control such as specifying algorithmic constraints, selecting relevant features, or choosing among several DR algorithms. We investigate specific implementations of visual analysis systems integrating DR, and analyze ways that other machine learning methods have been combined with DR. Summarizing the results in a &#x201C;human in the loop&#x201D; process model provides a general lens for the evaluation of visual interactive DR systems. We apply the proposed model to study and classify several systems previously described in the literature, and to derive future research opportunities.	Dominik Sacha;Leishi Zhang;Michael Sedlmair;John Aldo Lee;Jaakko Peltonen;Daniel Weiskopf;Stephen C. North;Daniel A. Keim	University of Konstanz, Germany;Middlesex University, UK;University of Vienna, Austria;SSS, IREC, MIRO, UniversitÃ© catholique de LouvainUCLBelgian F.R.S.-FNRS.;Helsinki Institute for Information Technology HIIT, Aalto University, University of Tampere, Finland;University of Konstanz, Germany;Infovisible LLC, Oldwick, U.S.A.;VISUS, University of Stuttgart, Germany	10.1109/TVCG.2012.195;10.1109/TVCG.2009.153;10.1109/VAST.2012.6400486;10.1109/TVCG.2014.2346481;10.1109/VAST.2011.6102449;10.1109/TVCG.2007.70515;10.1109/VAST.2008.4677350;10.1109/VAST.2009.5332629;10.1109/VAST.2010.5652443;10.1109/VAST.2014.7042492;10.1109/TVCG.2015.2467132;10.1109/TVCG.2015.2467553;10.1109/TVCG.2014.2346321;10.1109/TVCG.2013.153;10.1109/VAST.2010.5652484;10.1109/TVCG.2006.156;10.1109/TVCG.2015.2467717;10.1109/TVCG.2011.229;10.1109/TVCG.2013.124;10.1109/VAST.2010.5652392;10.1109/TVCG.2013.126	Interactive visualization;machine learning;visual analytics;dimensionality reduction	University of Konstanz, Germany##Middlesex University, UK##University of Vienna, Austria##SSS, IREC, MIRO, UniversitÃ© catholique de LouvainUCLBelgian F.R.S.-FNRS.##Helsinki Institute for Information Technology HIIT, Aalto University, University of Tampere, Finland##University of Konstanz, Germany##Infovisible LLC, Oldwick, U.S.A.##VISUS, University of Stuttgart, Germany
VAST	2016	VisFlow - Web-based Visualization Framework for Tabular Data with a Subset Flow Model	10.1109/TVCG.2016.2598497	http://dx.doi.org/10.1109/TVCG.2016.2598497	251	260	J	Data flow systems allow the user to design a flow diagram that specifies the relations between system components which process, filter or visually present the data. Visualization systems may benefit from user-defined data flows as an analysis typically consists of rendering multiple plots on demand and performing different types of interactive queries across coordinated views. In this paper, we propose VisFlow, a web-based visualization framework for tabular data that employs a specific type of data flow model called the subset flow model. VisFlow focuses on interactive queries within the data flow, overcoming the limitation of interactivity from past computational data flow systems. In particular, VisFlow applies embedded visualizations and supports interactive selections, brushing and linking within a visualization-oriented data flow. The model requires all data transmitted by the flow to be a data item subset (i.e. groups of table rows) of some original input table, so that rendering properties can be assigned to the subset unambiguously for tracking and comparison. VisFlow features the analysis flexibility of a flow diagram, and at the same time reduces the diagram complexity and improves usability. We demonstrate the capability of VisFlow on two case studies with domain experts on real-world datasets showing that VisFlow is capable of accomplishing a considerable set of visualization and analysis tasks. The VisFlow system is available as open source on GitHub.	Bowen Yu;Cláudio T. Silva	New York University;New York University	10.1109/TVCG.2009.195;10.1109/INFVIS.2004.12;10.1109/VAST.2011.6102440;10.1109/INFVIS.1998.729560;10.1109/TVCG.2014.2346260;10.1109/INFVIS.2005.1532136;10.1109/TVCG.2011.225;10.1109/INFVIS.2003.1249013;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2014.2346753;10.1109/TVCG.2011.185;10.1109/TVCG.2014.2346291	Visualization framework;data flow;subset flow model;tabular data	New York University##New York University
VAST	2016	Annotation Graphs: A Graph-Based Visualization for Meta-Analysis of Data Based on User-Authored Annotations	10.1109/TVCG.2016.2598543	http://dx.doi.org/10.1109/TVCG.2016.2598543	261	270	J	User-authored annotations of data can support analysts in the activity of hypothesis generation and sensemaking, where it is not only critical to document key observations, but also to communicate insights between analysts. We present annotation graphs, a dynamic graph visualization that enables meta-analysis of data based on user-authored annotations. The annotation graph topology encodes annotation semantics, which describe the content of and relations between data selections, comments, and tags. We present a mixed-initiative approach to graph layout that integrates an analyst's manual manipulations with an automatic method based on similarity inferred from the annotation semantics. Various visual graph layout styles reveal different perspectives on the annotation semantics. Annotation graphs are implemented within C8, a system that supports authoring annotations during exploratory analysis of a dataset. We apply principles of Exploratory Sequential Data Analysis (ESDA) in designing C8, and further link these to an existing task typology in the visualization literature. We develop and evaluate the system through an iterative user-centered design process with three experts, situated in the domain of analyzing HCI experiment data. The results suggest that annotation graphs are effective as a method of visually extending user-authored annotations to data meta-analysis for discovery and organization of ideas.	Jian Zhao;Michael Glueck;Simon Breslav;Fanny Chevalier;Azam Khan	Autodesk Research;Autodesk Research;Autodesk Research;INRIA;Autodesk Research	10.1109/VAST.2009.5333878;10.1109/TVCG.2015.2467871;10.1109/VAST.2009.5333023;10.1109/VAST.2011.6102447;10.1109/TVCG.2008.137;10.1109/TVCG.2014.2346573;10.1109/VAST.2008.4677365;10.1109/TVCG.2013.124;10.1109/TVCG.2007.70577;10.1109/VAST.2010.5652879	Externalization user-authored annotation;exploratory sequential data analysis;graph-based visualization	Autodesk Research##Autodesk Research##Autodesk Research##INRIA##Autodesk Research
VAST	2016	Familiarity Vs Trust: A Comparative Study of Domain Scientists' Trust in Visual Analytics and Conventional Analysis Methods	10.1109/TVCG.2016.2598544	http://dx.doi.org/10.1109/TVCG.2016.2598544	271	280	J	Combining interactive visualization with automated analytical methods like statistics and data mining facilitates data-driven discovery. These visual analytic methods are beginning to be instantiated within mixed-initiative systems, where humans and machines collaboratively influence evidence-gathering and decision-making. But an open research question is that, when domain experts analyze their data, can they completely trust the outputs and operations on the machine-side? Visualization potentially leads to a transparent analysis process, but do domain experts always trust what they see? To address these questions, we present results from the design and evaluation of a mixed-initiative, visual analytics system for biologists, focusing on analyzing the relationships between familiarity of an analysis medium and domain experts' trust. We propose a trust-augmented design of the visual analytics system, that explicitly takes into account domain-specific tasks, conventions, and preferences. For evaluating the system, we present the results of a controlled user study with 34 biologists where we compare the variation of the level of trust across conventional and visual analytic mediums and explore the influence of familiarity and task complexity on trust. We find that despite being unfamiliar with a visual analytic medium, scientists seem to have an average level of trust that is comparable with the same in conventional analysis medium. In fact, for complex sense-making tasks, we find that the visual analytic system is able to inspire greater trust than other mediums. We summarize the implications of our findings with directions for future research on trustworthiness of visual analytic systems.	Aritra Dasgupta;Joon-Yong Lee;Ryan Wilson;Robert A. Lafrance;Nick Cramer;Kristin A. Cook;Samuel Payne	Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory;Pacific Northwest National Laboratory	10.1109/TVCG.2015.2467591;10.1109/VAST.2015.7347625;10.1109/TVCG.2012.224;10.1109/INFVIS.2005.1532136;10.1109/VAST.2006.261416;10.1109/TVCG.2013.124;10.1109/TVCG.2013.120	trust;transparency;familiarity;uncertainty;biological data analysis	Pacific Northwest National Laboratory##Pacific Northwest National Laboratory##Pacific Northwest National Laboratory##Pacific Northwest National Laboratory##Pacific Northwest National Laboratory##Pacific Northwest National Laboratory##Pacific Northwest National Laboratory
VAST	2016	What do Constraint Programming Users Want to See? Exploring the Role of Visualisation in Profiling of Models and Search	10.1109/TVCG.2016.2598545	http://dx.doi.org/10.1109/TVCG.2016.2598545	281	290	J	Constraint programming allows difficult combinatorial problems to be modelled declaratively and solved automatically. Advances in solver technologies over recent years have allowed the successful use of constraint programming in many application areas. However, when a particular solver's search for a solution takes too long, the complexity of the constraint program execution hinders the programmer's ability to profile that search and understand how it relates to their model. Therefore, effective tools to support such profiling and allow users of constraint programming technologies to refine their model or experiment with different search parameters are essential. This paper details the first user-centred design process for visual profiling tools in this domain. We report on: our insights and opportunities identified through an on-line questionnaire and a creativity workshop with domain experts carried out to elicit requirements for analytical and visual profiling techniques; our designs and functional prototypes realising such techniques; and case studies demonstrating how these techniques shed light on the behaviour of the solvers in practice.	Sarah Goodwin;Christopher Mears;Tim Dwyer;Maria Garcia de la Banda;Guido Tack;Mark Wallace	Adaptive Visualisation LabMonash University;Faculty of Information Technology, Monash University;Adaptive Visualisation LabMonash University;Faculty of Information Technology, Monash University;Faculty of Information Technology, Monash University;Faculty of Information Technology, Monash University	10.1109/TVCG.2013.145;10.1109/TVCG.2014.2346321;10.1109/TVCG.2015.2467751;10.1109/INFVIS.2004.70;10.1109/TVCG.2014.2346578;10.1109/TVCG.2013.151;10.1109/TVCG.2015.2467851;10.1109/INFVIS.2000.885103	visual analytics;user-centred design;profiling;constraint programming;tree visualisations	Adaptive Visualisation LabMonash University##Faculty of Information Technology, Monash University##Adaptive Visualisation LabMonash University##Faculty of Information Technology, Monash University##Faculty of Information Technology, Monash University##Faculty of Information Technology, Monash University
VAST	2016	ViDX: Visual Diagnostics of Assembly Line Performance in Smart Factories	10.1109/TVCG.2016.2598664	http://dx.doi.org/10.1109/TVCG.2016.2598664	291	300	J	Visual analytics plays a key role in the era of connected industry (or industry 4.0, industrial internet) as modern machines and assembly lines generate large amounts of data and effective visual exploration techniques are needed for troubleshooting, process optimization, and decision making. However, developing effective visual analytics solutions for this application domain is a challenging task due to the sheer volume and the complexity of the data collected in the manufacturing processes. We report the design and implementation of a comprehensive visual analytics system, ViDX. It supports both real-time tracking of assembly line performance and historical data exploration to identify inefficiencies, locate anomalies, and form hypotheses about their causes and effects. The system is designed based on a set of requirements gathered through discussions with the managers and operators from manufacturing sites. It features interlinked views displaying data at different levels of detail. In particular, we apply and extend the Marey's graph by introducing a time-aware outlier-preserving visual aggregation technique to support effective troubleshooting in manufacturing processes. We also introduce two novel interaction techniques, namely the quantiles brush and samples brush, for the users to interactively steer the outlier detection algorithms. We evaluate the system with example use cases and an in-depth user interview, both conducted together with the managers and operators from manufacturing plants. The result demonstrates its effectiveness and reports a successful pilot application of visual analytics for manufacturing in smart factories.	Panpan Xu;Honghui Mei;Liu Ren;Wei Chen	Bosch Research North America;Zhejiang University;Bosch Research North America;Zhejiang University	10.1109/TVCG.2014.2346454;10.1109/TVCG.2015.2467592;10.1109/TVCG.2006.170;10.1109/TVCG.2015.2467622;10.1109/TVCG.2014.2346682;10.1109/TVCG.2012.225;10.1109/TVCG.2013.200;10.1109/INFVIS.2002.1173149;10.1109/TVCG.2011.185	Temporal Data;Marey's Graph;Visual Analytics;Manufacturing;Smart Factory;Connected Industry;Industry 4.0	Bosch Research North America##Zhejiang University##Bosch Research North America##Zhejiang University
VAST	2016	Visual Analytics for Mobile Eye Tracking	10.1109/TVCG.2016.2598695	http://dx.doi.org/10.1109/TVCG.2016.2598695	301	310	J	The analysis of eye tracking data often requires the annotation of areas of interest (AOIs) to derive semantic interpretations of human viewing behavior during experiments. This annotation is typically the most time-consuming step of the analysis process. Especially for data from wearable eye tracking glasses, every independently recorded video has to be annotated individually and corresponding AOIs between videos have to be identified. We provide a novel visual analytics approach to ease this annotation process by image-based, automatic clustering of eye tracking data integrated in an interactive labeling and analysis system. The annotation and analysis are tightly coupled by multiple linked views that allow for a direct interpretation of the labeled data in the context of the recorded video stimuli. The components of our analytics environment were developed with a user-centered design approach in close cooperation with an eye tracking expert. We demonstrate our approach with eye tracking data from a real experiment and compare it to an analysis of the data by manual annotation of dynamic AOIs. Furthermore, we conducted an expert user study with 6 external eye tracking researchers to collect feedback and identify analysis strategies they used while working with our application.	Kuno Kurzhals;Marcel Hlawatsch;Christof Seeger;Daniel Weiskopf	University of Stuttgart;University of Stuttgart;Stuttgart Media University;University of Stuttgart	10.1109/TVCG.2010.149;10.1109/TVCG.2015.2468091;10.1109/VAST.2006.261433;10.1109/TVCG.2009.111	Eye tracking;visual analytics;video visualization	University of Stuttgart##University of Stuttgart##Stuttgart Media University##University of Stuttgart
VAST	2016	GazeDx: Interactive Visual Analytics Framework for Comparative Gaze Analysis with Volumetric Medical Images	10.1109/TVCG.2016.2598796	http://dx.doi.org/10.1109/TVCG.2016.2598796	311	320	J	We present an interactive visual analytics framework, GazeDx (abbr. of GazeDiagnosis), for the comparative analysis of gaze data from multiple readers examining volumetric images while integrating important contextual information with the gaze data. Gaze pattern comparison is essential to understanding how radiologists examine medical images, and to identifying factors influencing the examination. Most prior work depended upon comparisons with manually juxtaposed static images of gaze tracking results. Comparative gaze analysis with volumetric images is more challenging due to the additional cognitive load on 3D perception. A recent study proposed a visualization design based on direct volume rendering (DVR) for visualizing gaze patterns in volumetric images; however, effective and comprehensive gaze pattern comparison is still challenging due to a lack of interactive visualization tools for comparative gaze analysis. We take the challenge with GazeDx while integrating crucial contextual information such as pupil size and windowing into the analysis process for more in-depth and ecologically valid findings. Among the interactive visualization components in GazeDx, a context-embedded interactive scatterplot is especially designed to help users examine abstract gaze data in diverse contexts by embedding medical imaging representations well known to radiologists in it. We present the results from two case studies with two experienced radiologists, where they compared the gaze patterns of 14 radiologists reading two patients' volumetric CT images.	Hyunjoo Song;Jeongjin Lee;Tae Jung Kim;Kyoung Ho Lee;Bo Hyoung Kim;Jinwook Seo	Seoul National University;Soongsil University;Samsung Medical Center;Bundang Hospital, Seoul National University;Hankuk University of Foreign Studies;Seoul National University	10.1109/VAST.2011.6102435;10.1109/TVCG.2010.149	Eye tracking;gaze visualization;gaze pattern comparison;volumetric medical images;context-embedded interactive scatterplot;interactive temporal chart	Seoul National University##Soongsil University##Samsung Medical Center##Bundang Hospital, Seoul National University##Hankuk University of Foreign Studies##Seoul National University
VAST	2016	Patterns and Sequences: Interactive Exploration of Clickstreams to Understand Common Visitor Paths	10.1109/TVCG.2016.2598797	http://dx.doi.org/10.1109/TVCG.2016.2598797	321	330	J	Modern web clickstream data consists of long, high-dimensional sequences of multivariate events, making it difficult to analyze. Following the overarching principle that the visual interface should provide information about the dataset at multiple levels of granularity and allow users to easily navigate across these levels, we identify four levels of granularity in clickstream analysis: patterns, segments, sequences and events. We present an analytic pipeline consisting of three stages: pattern mining, pattern pruning and coordinated exploration between patterns and sequences. Based on this approach, we discuss properties of maximal sequential patterns, propose methods to reduce the number of patterns and describe design considerations for visualizing the extracted sequential patterns and the corresponding raw sequences. We demonstrate the viability of our approach through an analysis scenario and discuss the strengths and limitations of the methods based on user feedback.	Zhicheng Liu;Yang Wang;Mira Dontcheva;Matthew Hoffman;Seth Walker;Alan Wilson	Adobe Research;University of California, Davis;Adobe Research;Adobe Research;Adobe Research;Adobe Systems Inc.	10.1109/VAST.2010.5652910;10.1109/VAST.2010.5652926;10.1109/TVCG.2013.225;10.1109/TVCG.2013.200;10.1109/INFVIS.2005.1532152;10.1109/INFVIS.2000.885091;10.1109/TVCG.2014.2346574;10.1109/VAST.2007.4389008;10.1109/TVCG.2011.185;10.1109/VAST.2014.7042487;10.1109/TVCG.2015.2467622;10.1109/VAST.2012.6400494	event sequences;Clickstream Data;sequence mining;visual analytics	Adobe Research##University of California, Davis##Adobe Research##Adobe Research##Adobe Research##Adobe Systems Inc.
VAST	2016	Squares: Supporting Interactive Performance Analysis for Multiclass Classifiers	10.1109/TVCG.2016.2598828	http://dx.doi.org/10.1109/TVCG.2016.2598828	61	70	J	Performance analysis is critical in applied machine learning because it influences the models practitioners produce. Current performance analysis tools suffer from issues including obscuring important characteristics of model behavior and dissociating performance from data. In this work, we present Squares, a performance visualization for multiclass classification problems. Squares supports estimating common performance metrics while displaying instance-level distribution information necessary for helping practitioners prioritize efforts and access data. Our controlled study shows that practitioners can assess performance significantly faster and more accurately with Squares than a confusion matrix, a common performance analysis tool in machine learning.	Donghao Ren;Saleema Amershi;Bongshin Lee;Jina Suh;Jason D. Williams	University of California, Santa Barbara;Microsoft Research;Microsoft Research;Microsoft Research;Microsoft Research	10.1109/VISUAL.2000.885740;10.1109/VAST.2010.5652443;10.1109/TVCG.2012.277;10.1109/TVCG.2014.2346660;10.1109/VAST.2011.6102453;10.1109/TVCG.2011.185	Performance analysis;classification;usable machine learning	University of California, Santa Barbara##Microsoft Research##Microsoft Research##Microsoft Research##Microsoft Research
VAST	2016	An Analysis of Machine- and Human-Analytics in Classification	10.1109/TVCG.2016.2598829	http://dx.doi.org/10.1109/TVCG.2016.2598829	71	80	J	In this work, we present a study that traces the technical and cognitive processes in two visual analytics applications to a common theoretic model of soft knowledge that may be added into a visual analytics process for constructing a decision-tree model. Both case studies involved the development of classification models based on the &#x201C;bag of features&#x201D; approach. Both compared a visual analytics approach using parallel coordinates with a machine-learning approach using information theory. Both found that the visual analytics approach had some advantages over the machine learning approach, especially when sparse datasets were used as the ground truth. We examine various possible factors that may have contributed to such advantages, and collect empirical evidence for supporting the observation and reasoning of these factors. We propose an information-theoretic model as a common theoretic basis to explain the phenomena exhibited in these two case studies. Together we provide interconnected empirical and theoretical evidence to support the usefulness of visual analytics.	Gary K. L. Tam;Vivek Kothari;Min Chen	Swansea University;University of Oxford;University of Oxford	10.1109/VAST.2010.5652467;10.1109/TVCG.2015.2467615;10.1109/VAST.2012.6400492;10.1109/TVCG.2013.207;10.1109/TVCG.2015.2467552;10.1109/TVCG.2015.2467612;10.1109/VAST.2010.5652398;10.1109/TVCG.2010.132;10.1109/TVCG.2014.2346660;10.1109/VAST.2015.7347629;10.1109/VAST.2011.6102453;10.1109/VAST.2011.6102448	information theory;Visual analytics;classification;decision tree;model;facial expression;visualization image	Swansea University##University of Oxford##University of Oxford
VAST	2016	Multi-Resolution Climate Ensemble Parameter Analysis with Nested Parallel Coordinates Plots	10.1109/TVCG.2016.2598830	http://dx.doi.org/10.1109/TVCG.2016.2598830	81	90	J	Due to the uncertain nature of weather prediction, climate simulations are usually performed multiple times with different spatial resolutions. The outputs of simulations are multi-resolution spatial temporal ensembles. Each simulation run uses a unique set of values for multiple convective parameters. Distinct parameter settings from different simulation runs in different resolutions constitute a multi-resolution high-dimensional parameter space. Understanding the correlation between the different convective parameters, and establishing a connection between the parameter settings and the ensemble outputs are crucial to domain scientists. The multi-resolution high-dimensional parameter space, however, presents a unique challenge to the existing correlation visualization techniques. We present Nested Parallel Coordinates Plot (NPCP), a new type of parallel coordinates plots that enables visualization of intra-resolution and inter-resolution parameter correlations. With flexible user control, NPCP integrates superimposition, juxtaposition and explicit encodings in a single view for comparative data visualization and analysis. We develop an integrated visual analytics system to help domain scientists understand the connection between multi-resolution convective parameters and the large spatial temporal ensembles. Our system presents intricate climate ensembles with a comprehensive overview and on-demand geographic details. We demonstrate NPCP, along with the climate ensemble visualization system, based on real-world use-cases from our collaborators in computational and predictive science.	Junpeng Wang;Xiaotong Liu;Han-Wei Shen;Guang Lin	The Ohio State University;The Ohio State University;The Ohio State University;Purdue University	10.1109/TVCG.2010.181;10.1109/TVCG.2008.153;10.1109/INFVIS.1998.729559;10.1109/TVCG.2012.237;10.1109/INFVIS.2004.68;10.1109/TVCG.2014.2346755;10.1109/SciVis.2015.7429487;10.1109/VISUAL.1999.809866;10.1109/TVCG.2013.122;10.1109/INFVIS.2004.15;10.1109/TVCG.2015.2467431;10.1109/TVCG.2015.2468093;10.1109/TVCG.2010.184;10.1109/TVCG.2014.2346321	Parallel coordinates plots;parameter analysis;multi-resolution climate ensembles	The Ohio State University##The Ohio State University##The Ohio State University##Purdue University
VAST	2016	Towards Better Analysis of Deep Convolutional Neural Networks	10.1109/TVCG.2016.2598831	http://dx.doi.org/10.1109/TVCG.2016.2598831	91	100	J	Deep convolutional neural networks (CNNs) have achieved breakthrough performance in many pattern recognition tasks such as image classification. However, the development of high-quality deep models typically relies on a substantial amount of trial-and-error, as there is still no clear understanding of when and why a deep model works. In this paper, we present a visual analytics approach for better understanding, diagnosing, and refining deep CNNs. We formulate a deep CNN as a directed acyclic graph. Based on this formulation, a hybrid visualization is developed to disclose the multiple facets of each neuron and the interactions between them. In particular, we introduce a hierarchical rectangle packing algorithm and a matrix reordering algorithm to show the derived features of a neuron cluster. We also propose a biclustering-based edge bundling method to reduce visual clutter caused by a large number of connections between neurons. We evaluated our method on a set of CNNs and the results are generally favorable.	Mengchen Liu;Jiaxin Shi;Zhen Li;Chongxuan Li;Jun Zhu;Shixia Liu	School of Software and TNListTsinghua University;Dept. of Comp. Sci. & Tech., State Key Lab of Intell. Tech. & Sys.TNList LabCBICR Center;School of Software and TNListTsinghua University;Dept. of Comp. Sci. & Tech., State Key Lab of Intell. Tech. & Sys.TNList LabCBICR Center;School of Software and TNListTsinghua University;School of Software and TNListTsinghua University	10.1109/TVCG.2015.2468151;10.1109/TVCG.2015.2467554;10.1109/TVCG.2015.2467813;10.1109/TVCG.2010.132;10.1109/TVCG.2008.135;10.1109/TVCG.2014.2346919;10.1109/TVCG.2011.239;10.1109/VISUAL.1991.175815;10.1109/VISUAL.2005.1532820;10.1109/TVCG.2007.70582;10.1109/TVCG.2014.2346433	Deep convolutional neural networks;rectangle packing;matrix reordering;edge bundling;biclustering	School of Software and TNListTsinghua University##Dept. of Comp. Sci. & Tech., State Key Lab of Intell. Tech. & Sys.TNList LabCBICR Center##School of Software and TNListTsinghua University##Dept. of Comp. Sci. & Tech., State Key Lab of Intell. Tech. & Sys.TNList LabCBICR Center##School of Software and TNListTsinghua University##School of Software and TNListTsinghua University
VAST	2016	Visualizing the Hidden Activity of Artificial Neural Networks	10.1109/TVCG.2016.2598838	http://dx.doi.org/10.1109/TVCG.2016.2598838	101	110	J	In machine learning, pattern classification assigns high-dimensional vectors (observations) to classes based on generalization from examples. Artificial neural networks currently achieve state-of-the-art results in this task. Although such networks are typically used as black-boxes, they are also widely believed to learn (high-dimensional) higher-level representations of the original observations. In this paper, we propose using dimensionality reduction for two tasks: visualizing the relationships between learned representations of observations, and visualizing the relationships between artificial neurons. Through experiments conducted in three traditional image classification benchmark datasets, we show how visualization can provide highly valuable feedback for network designers. For instance, our discoveries in one of these datasets (SVHN) include the presence of interpretable clusters of learned representations, and the partitioning of artificial neurons into groups with apparently related discriminative roles.	Paulo E. Rauber;Samuel G. Fadel;Alexandre X. Falcão;Alexandru Telea	University of GroningenUniversity of Campinas;University of SÃ£o Paulo;University of Campinas;University of Groningen	10.1109/TVCG.2011.178;10.1109/TVCG.2011.220;10.1109/TVCG.2013.150;10.1109/TVCG.2014.2346578;10.1109/TVCG.2008.125;10.1109/TVCG.2015.2467553	Artificial neural networks;dimensionality reduction;algorithm understanding	University of GroningenUniversity of Campinas##University of SÃ£o Paulo##University of Campinas##University of Groningen
VAST	2016	VisMatchmaker: Cooperation of the User and the Computer in Centralized Matching Adjustment	10.1109/TVCG.2016.2599378	http://dx.doi.org/10.1109/TVCG.2016.2599378	231	240	J	Centralized matching is a ubiquitous resource allocation problem. In a centralized matching problem, each agent has a preference list ranking the other agents and a central planner is responsible for matching the agents manually or with an algorithm. While algorithms can find a matching which optimizes some performance metrics, they are used as a black box and preclude the central planner from applying his domain knowledge to find a matching which aligns better with the user tasks. Furthermore, the existing matching visualization techniques (i.e. bipartite graph and adjacency matrix) fail in helping the central planner understand the differences between matchings. In this paper, we present VisMatchmaker, a visualization system which allows the central planner to explore alternatives to an algorithm-generated matching. We identified three common tasks in the process of matching adjustment: problem detection, matching recommendation and matching evaluation. We classified matching comparison into three levels and designed visualization techniques for them, including the number line view and the stacked graph view. Two types of algorithmic support, namely direct assignment and range search, and their interactive operations are also provided to enable the user to apply his domain knowledge in matching adjustment.	Po-Ming Law;Wenchao Wu;Yixian Zheng;Huamin Qu	Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology	10.1109/INFVIS.2004.1;10.1109/TVCG.2006.122;10.1109/TVCG.2014.2346249;10.1109/TVCG.2014.2346441;10.1109/VAST.2011.6102453	Centralized matching;matching visualization;interaction techniques;visual analytics	Hong Kong University of Science and Technology##Hong Kong University of Science and Technology##Hong Kong University of Science and Technology##Hong Kong University of Science and Technology
VAST	2016	Supporting visual exploration for multiple users in large display environments	10.1109/VAST.2016.7883506	http://dx.doi.org/10.1109/VAST.2016.7883506	1	10	C	We present a design space exploration of interaction techniques for supporting multiple collaborators exploring data on a shared large display. Our proposed solution is based on users controlling individual lenses using both explicit gestures as well as proxemics: the spatial relations between people and physical artifacts such as their distance, orientation, and movement. We discuss different design considerations for implicit and explicit interactions through the lens, and evaluate the user experience to find a balance between the implicit and explicit interaction styles. Our findings indicate that users favor implicit interaction through proxemics for navigation and collaboration, but prefer using explicit mid-air gestures to perform actions that are perceived to be direct, such as terminating a lens composition. Based on these results, we propose a hybrid technique utilizing both proxemics and mid-air gestures, along with examples applying this technique to other datasets. Finally, we performed a usability evaluation of the hybrid technique and observed user performance improvements in the presence of both implicit and explicit interaction styles.	Sriram Karthik Badam;Fereshteh Amini;Niklas Elmqvist;Pourang Irani	University of Maryland, College Park, USA;University of Manitoba, Winnipeg, Canada;University of Maryland, College Park, USA;University of Manitoba, Winnipeg, Canada	10.1109/TVCG.2013.166;10.1109/TVCG.2009.162;10.1109/TVCG.2013.163;10.1109/TVCG.2011.185		University of Maryland, College Park, USA##University of Manitoba, Winnipeg, Canada##University of Maryland, College Park, USA##University of Manitoba, Winnipeg, Canada
VAST	2016	DocuCompass: Effective exploration of document landscapes	10.1109/VAST.2016.7883507	http://dx.doi.org/10.1109/VAST.2016.7883507	11	20	C	The creation of interactive visualization to analyze text documents has gained an impressive momentum in recent years. This is not surprising in the light of massive and still increasing amounts of available digitized texts. Websites, social media, news wire, and digital libraries are just few examples of the diverse text sources whose visual analysis and exploration offers new opportunities to effectively mine and manage the information and knowledge hidden within them. A popular visualization method for large text collections is to represent each document by a glyph in 2D space. These landscapes can be the result of optimizing pairwise distances in 2D to represent document similarities, or they are provided directly as meta data, such as geo-locations. For well-defined information needs, suitable interaction methods are available for these spatializations. However, free exploration and navigation on a level of abstraction between a labeled document spatialization and reading single documents is largely unsupported. As a result, vital foraging steps for task-tailored actions, such as selecting subgroups of documents for detailed inspection, or subsequent sense-making steps are hampered. To fill in this gap, we propose DocuCompass, a focus+context approach based on the lens metaphor. It comprises multiple methods to characterize local groups of documents, and to efficiently guide exploration based on users' requirements. DocuCompass thus allows for effective interactive exploration of document landscapes without disrupting the mental map of users by changing the layout itself. We discuss the suitability of multiple navigation and characterization methods for different spatializations and texts. Finally, we provide insights generated through user feedback and discuss the effectiveness of our approach.	Florian Heimerl;Markus John;Qi Han;Steffen Koch;Thomas Ertl	;;;;	10.1109/INFVIS.1995.528686;10.1109/VAST.2009.5333443;10.1109/TVCG.2012.277;10.1109/VAST.2007.4389006;10.1109/VAST.2011.6102449;10.1109/TVCG.2013.186;10.1109/VAST.2012.6400487;10.1109/TVCG.2014.2346433;10.1109/TVCG.2008.152;10.1109/TVCG.2013.212;10.1109/TVCG.2013.162;10.1109/TVCG.2015.2467717;10.1109/VAST.2011.6102488;10.1109/VAST.2011.6102456		########
VAST	2016	C2A: Crowd consensus analytics for virtual colonoscopy	10.1109/VAST.2016.7883508	http://dx.doi.org/10.1109/VAST.2016.7883508	21	30	C	We present a medical crowdsourcing visual analytics platform called C<sup>2</sup>A to visualize, classify and filter crowdsourced clinical data. More specifically, C<sup>2</sup>A is used to build consensus on a clinical diagnosis by visualizing crowd responses and filtering out anomalous activity. Crowdsourcing medical applications have recently shown promise where the non-expert users (the crowd) were able to achieve accuracy similar to the medical experts. This has the potential to reduce interpretation/reading time and possibly improve accuracy by building a consensus on the findings beforehand and letting the medical experts make the final diagnosis. In this paper, we focus on a virtual colonoscopy (VC) application with the clinical technicians as our target users, and the radiologists acting as consultants and classifying segments as benign or malignant. In particular, C<sup>2</sup>A is used to analyze and explore crowd responses on video segments, created from fly-throughs in the virtual colon. C<sup>2</sup>A provides several interactive visualization components to build crowd consensus on video segments, to detect anomalies in the crowd data and in the VC video segments, and finally, to improve the non-expert user's work quality and performance by A/B testing for the optimal crowdsourcing platform and application-specific parameters. Case studies and domain experts feedback demonstrate the effectiveness of our framework in improving workers' output quality, the potential to reduce the radiologists' interpretation time, and hence, the potential to improve the traditional clinical workflow by marking the majority of the video segments as benign based on the crowd consensus.	Ji Hwan Park;Saad Nadeem;Seyedkoosha Mirhosseini;Arie E. Kaufman	Stony Brook University, United States of America;Stony Brook University, United States of America;Stony Brook University, United States of America;Stony Brook University, United States of America	10.1109/TVCG.2015.2467196;10.1109/TVCG.2006.112;10.1109/TVCG.2009.171;10.1109/TVCG.2006.158;10.1109/VAST.2015.7347631;10.1109/TVCG.2013.164;10.1109/TVCG.2015.2467555		Stony Brook University, United States of America##Stony Brook University, United States of America##Stony Brook University, United States of America##Stony Brook University, United States of America
VAST	2016	The DataSpace for HIV vaccine studies	10.1109/VAST.2016.7883509	http://dx.doi.org/10.1109/VAST.2016.7883509	31	40	C	The DataSpace for HIV vaccine studies is a discovery tool available on the web to hundreds of investigators. We designed it to help them better understand activity in the field and explore new ideas latent in completed research. The DataSpace harmonizes immunoassay results and study metadata so that a broader research community can pursue more flexible discovery than the typical centrally planned analyses. Insights from human-centered design and beta evaluation suggest strong potential for visual analytics that may also apply to other efforts in open science. The contribution of this paper is to elucidate key domain challenges and demonstrate an application that addresses them. We made several changes to familiar visualizations to support key tasks such as identifying and filtering to a cohort of interest, making meaningful comparisons of time series data from multiple studies that have different plans, and preserving analytic context when making data transformations and comparisons that would normally exclude some data.	David McColgin;Paul Hoover;Mark Igra	LabKey Software, United States of America;LabKey Software, United States of America;LabKey Software, United States of America			LabKey Software, United States of America##LabKey Software, United States of America##LabKey Software, United States of America
VAST	2016	D-Map: Visual Analysis of Ego-centric Information Diffusion Patterns in Social Media	10.1109/VAST.2016.7883510	http://dx.doi.org/10.1109/VAST.2016.7883510	41	50	C	Popular social media platforms could rapidly propagate vital information over social networks among a significant number of people. In this work we present D-Map (Diffusion Map), a novel visualization method to support exploration and analysis of social behaviors during such information diffusion and propagation on typical social media through a map metaphor. In D-Map, users who participated in reposting (i.e., resending a message initially posted by others) one central user's posts (i.e., a series of original tweets) are collected and mapped to a hexagonal grid based on their behavior similarities and in chronological order of the repostings. With additional interaction and linking, D-Map is capable of providing visual portraits of the influential users and describing their social behaviors. A comprehensive visual analysis system is developed to support interactive exploration with D-Map. We evaluate our work with real world social media data and find interesting patterns among users. Key players, important information diffusion paths, and interactions among social communities can be identified.	Siming Chen;Shuai Chen;Zhenhuang Wang;Jie Liang;Xiaoru Yuan;Nan Cao;Yadong Wu	Key Laboratory of Machine Perception (Ministry of Education), Peking University, China;Key Laboratory of Machine Perception (Ministry of Education), Peking University, China;Key Laboratory of Machine Perception (Ministry of Education), Peking University, China;Faculty of Engineer and Information Technology, The University of Technology, Sydney, Australia;Key Laboratory of Machine Perception (Ministry of Education), Peking University, China;New York University, Shanghai, China;Southwest University of Science and Technology, China	10.1109/TVCG.2015.2467196;10.1109/TVCG.2014.2346922;10.1109/TVCG.2012.291;10.1109/TVCG.2010.154;10.1109/TVCG.2007.70582;10.1109/TVCG.2014.2346433;10.1109/INFVIS.2005.1532126;10.1109/TVCG.2013.221;10.1109/TVCG.2014.2346919;10.1109/TVCG.2014.2346920;10.1109/TVCG.2011.185;10.1109/TVCG.2014.2346277		Key Laboratory of Machine Perception (Ministry of Education), Peking University, China##Key Laboratory of Machine Perception (Ministry of Education), Peking University, China##Key Laboratory of Machine Perception (Ministry of Education), Peking University, China##Faculty of Engineer and Information Technology, The University of Technology, Sydney, Australia##Key Laboratory of Machine Perception (Ministry of Education), Peking University, China##New York University, Shanghai, China##Southwest University of Science and Technology, China
VAST	2016	How ideas flow across multiple social groups	10.1109/VAST.2016.7883511	http://dx.doi.org/10.1109/VAST.2016.7883511	51	60	C	Tracking how correlated ideas flow within and across multiple social groups facilitates the understanding of the transfer of information, opinions, and thoughts on social media. In this paper, we present IdeaFlow, a visual analytics system for analyzing the lead-lag changes within and across pre-defined social groups regarding a specific set of correlated ideas, each of which is described by a set of words. To model idea flows accurately, we develop a random-walk-based correlation model and integrate it with Bayesian conditional cointegration and a tensor-based technique. To convey complex lead-lag relationships over time, IdeaFlow combines the strengths of a bubble tree, a flow map, and a timeline. In particular, we develop a Voronoi-treemap-based bubble tree to help users get an overview of a set of ideas quickly. A correlated-clustering-based layout algorithm is used to simultaneously generate multiple flow maps with less ambiguity. We also introduce a focus+context timeline to explore huge amounts of temporal data at different levels of time granularity. Quantitative evaluation and case studies demonstrate the accuracy and effectiveness of IdeaFlow.	Xiting Wang;Shixia Liu;Yang Chen;Tai-Quan Peng;Jing Su;Jing Yang;Baining Guo	School of Software, Tsinghua University, China;School of Software, Tsinghua University, China;School of Software, Tsinghua University, China;Michigan State University, United States of America;Tsinghua University, China;UNCC, United States of America;Microsoft Research, United States of America	10.1109/VAST.2011.6102461;10.1109/VAST.2010.5652931;10.1109/TVCG.2015.2467554;10.1109/TVCG.2014.2346433;10.1109/TVCG.2015.2467992;10.1109/TVCG.2015.2467691;10.1109/TVCG.2011.202;10.1109/VAST.2012.6400485;10.1109/TVCG.2013.196;10.1109/TVCG.2015.2467757;10.1109/TVCG.2012.212;10.1109/TVCG.2010.129;10.1109/TVCG.2013.162;10.1109/TVCG.2013.221;10.1109/TVCG.2014.2346919;10.1109/INFVIS.2005.1532152;10.1109/TVCG.2014.2346920;10.1109/TVCG.2015.2467991;10.1109/TVCG.2011.239;10.1109/INFVIS.2005.1532150;10.1109/TVCG.2009.111;10.1109/INFVIS.2005.1532128		School of Software, Tsinghua University, China##School of Software, Tsinghua University, China##School of Software, Tsinghua University, China##Michigan State University, United States of America##Tsinghua University, China##UNCC, United States of America##Microsoft Research, United States of America
VAST	2016	EventAction: Visual analytics for temporal event sequence recommendation	10.1109/VAST.2016.7883512	http://dx.doi.org/10.1109/VAST.2016.7883512	61	70	C	Recommender systems are being widely used to assist people in making decisions, for example, recommending films to watch or books to buy. Despite its ubiquity, the problem of presenting the recommendations of temporal event sequences has not been studied. We propose EventAction, which to our knowledge, is the first attempt at a prescriptive analytics interface designed to present and explain recommendations of temporal event sequences. EventAction provides a visual analytics approach to (1) identify similar records, (2) explore potential outcomes, (3) review recommended temporal event sequences that might help achieve the users' goals, and (4) interactively assist users as they define a personalized action plan associated with a probability of success. Following the design study framework, we designed and deployed EventAction in the context of student advising and reported on the evaluation with a student review manager and three graduate students.	Fan Du;Catherine Plaisant;Neil Spring;Ben Shneiderman	University of Maryland, United States of America;University of Maryland, United States of America;University of Maryland, United States of America;University of Maryland, United States of America	10.1109/TVCG.2009.187;10.1109/TVCG.2012.225;10.1109/TVCG.2012.213;10.1109/TVCG.2015.2467622;10.1109/TVCG.2014.2346682		University of Maryland, United States of America##University of Maryland, United States of America##University of Maryland, United States of America##University of Maryland, United States of America
VAST	2016	SocialBrands: Visual analysis of public perceptions of brands on social media	10.1109/VAST.2016.7883513	http://dx.doi.org/10.1109/VAST.2016.7883513	71	80	C	Public perceptions of a brand is critical to its performance. While social media has demonstrated a huge potential to shape public perceptions of brands, existing tools are not intuitive and explanatory for domain users to use as they fail to provide a comprehensive analysis framework for perceptions of brands. In this paper, we present SocialBrands, a novel visual analysis tool for brand managers to understand public perceptions of brands on social media. Social-Brands leverages brand personality framework in marketing literature and social computing approaches to compute the personality of brands from three driving factors (user imagery, employee imagery, and official announcement) on social media, and construct an evidence network explaining the association between brand personality and driving factors. These computational results are then integrated with new interactive visualizations to help brand managers understand personality traits and their driving factors. We demonstrate the usefulness and effectiveness of SocialBrands through a series of user studies with brand managers in an enterprise context. Design lessons are also derived from our studies.	Xiaotong Liu;Anbang Xu;Liang Gou;Haibin Liu;Rama Akkiraju;Han-Wei Shen	Ohio State University, United States of America;IBM Research, United States of America;Visa Research, United States of America;IBM Research, United States of America;IBM Research, United States of America;Ohio State University, United States of America	10.1109/TVCG.2014.2346922;10.1109/VAST.2014.7042496;10.1109/TVCG.2013.227;10.1109/TVCG.2012.291;10.1109/TVCG.2010.129;10.1109/TVCG.2013.221;10.1109/INFVIS.2000.885091;10.1109/TVCG.2011.183		Ohio State University, United States of America##IBM Research, United States of America##Visa Research, United States of America##IBM Research, United States of America##IBM Research, United States of America##Ohio State University, United States of America
VAST	2016	DimScanner: A Relation-based Visual Exploration Approach Towards Data Dimension Inspection	10.1109/VAST.2016.7883514	http://dx.doi.org/10.1109/VAST.2016.7883514	81	90	C	Exploring multi-dimensional datasets can be cumbersome if data analysts have little knowledge about the data. Various dimension relation inspection tools and dimension exploration tools have been proposed for efficient data examining and understanding. However, the needed workload varies largely with respect to data complexity and user expertise, which can only be reduced with rich background knowledge over the data. In this paper we address the workload challenge with a data structuring and exploration scheme that affords dimension relation detection and that serves as the background knowledge for further investigation. We contribute a novel data structuring scheme that leverages an information-theoretic view structuring algorithm to uncover information-aware relations among different data views, and thereby discloses redundancy and other relation patterns among dimensions. The integrated system, DimScanner, empowers analysts with rich user controls and assistance widgets to interactively detect the relations of multi-dimensional data.	Jing Xia;Wei Chen;Yumeng Hou;Wanqi Hu;Xinxin Huang;David S. Ebert	State Key Lab of CAD&CG, Zhejiang University, China;State Key Lab of CAD&CG, Zhejiang University, China;State Key Lab of CAD&CG, Zhejiang University, China;State Key Lab of CAD&CG, Zhejiang University, China;State Key Lab of CAD&CG, Zhejiang University, China;Purdue University, United States of America	10.1109/TVCG.2015.2467191;10.1109/TVCG.2009.153;10.1109/INFVIS.1998.729559;10.1109/VAST.2009.5332628;10.1109/TVCG.2010.184;10.1109/VAST.2010.5652450;10.1109/VAST.2006.261423;10.1109/TVCG.2013.160;10.1109/TVCG.2013.150;10.1109/TVCG.2011.229;10.1109/INFVIS.2005.1532142;10.1109/INFVIS.2004.3		State Key Lab of CAD&CG, Zhejiang University, China##State Key Lab of CAD&CG, Zhejiang University, China##State Key Lab of CAD&CG, Zhejiang University, China##State Key Lab of CAD&CG, Zhejiang University, China##State Key Lab of CAD&CG, Zhejiang University, China##Purdue University, United States of America
VAST	2016	SenseMap: Supporting browser-based online sensemaking through analytic provenance	10.1109/VAST.2016.7883515	http://dx.doi.org/10.1109/VAST.2016.7883515	91	100	C	Sensemaking is described as the process in which people collect, organize and create representations of information, all centered around some problem they need to understand. People often get lost when solving complicated tasks using big datasets over long periods of exploration and analysis. They may forget what they have done, are unaware of where they are in the context of the overall task, and are unsure where to continue. In this paper, we introduce a tool, SenseMap, to address these issues in the context of browser-based online sensemaking. We conducted a semi-structured interview with nine participants to explore their behaviors in online sensemaking with existing browser functionality. A simplified sensemaking model based on Pirolli and Card's model is derived to better represent the behaviors we found: users iteratively collect information sources relevant to the task, curate them in a way that makes sense, and finally communicate their findings to others. SenseMap automatically captures provenance of user sensemaking actions and provides multi-linked views to visualize the collected information and enable users to curate and communicate their findings. To explore how SenseMap is used, we conducted a user study in a naturalistic work setting with five participants completing the same sensemaking task related to their daily work activities. All participants found the visual representation and interaction of the tool intuitive to use. Three of them engaged with the tool and produced successful outcomes. It helped them to organize information sources, to quickly find and navigate to the sources they wanted, and to effectively communicate their findings.	Phong H. Nguyen;Kai Xu 0003;Andy Bardill;Betul Salman;Kate Herd;B. L. William Wong	Middlesex University, London, UK;Middlesex University, London, UK;Middlesex University, London, UK;Middlesex University, London, UK;Middlesex University, London, UK;Middlesex University, London, UK	10.1109/TVCG.2008.137;10.1109/TVCG.2015.2467611;10.1109/VAST.2008.4677365;10.1109/TVCG.2013.132;10.1109/VISUAL.2005.1532788;10.1109/TVCG.2013.124;10.1109/TVCG.2011.185		Middlesex University, London, UK##Middlesex University, London, UK##Middlesex University, London, UK##Middlesex University, London, UK##Middlesex University, London, UK##Middlesex University, London, UK
VAST	2016	PorosityAnalyzer: Visual Analysis and Evaluation of Segmentation Pipelines to Determine the Porosity in Fiber-Reinforced Polymers	10.1109/VAST.2016.7883516	http://dx.doi.org/10.1109/VAST.2016.7883516	101	110	C	In this paper we present PorosityAnalyzer, a novel tool for detailed evaluation and visual analysis of pore segmentation pipelines to determine the porosity in fiber-reinforced polymers (FRPs). The presented tool consists of two modules: the computation module and the analysis module. The computation module enables a convenient setup and execution of distributed off-line-computations on industrial 3D X-ray computed tomography datasets. It allows the user to assemble individual segmentation pipelines in the form of single pipeline steps, and to specify the parameter ranges as well as the sampling of the parameter-space of each pipeline segment. The result of a single segmentation run consists of the input parameters, the calculated 3D binary-segmentation mask, the resulting porosity value, and other derived results (e.g., segmentation pipeline run-time). The analysis module presents the data at different levels of detail by drill-down filtering in order to determine accurate and robust segmentation pipelines. Overview visualizations allow to initially compare and evaluate the segmentation pipelines. With a scatter plot matrix (SPLOM), the segmentation pipelines are examined in more detail based on their input and output parameters. Individual segmentation-pipeline runs are selected in the SPLOM and visually examined and compared in 2D slice views and 3D renderings by using aggregated segmentation masks and statistical contour renderings. PorosityAnalyzer has been thoroughly evaluated with the help of twelve domain experts. Two case studies demonstrate the applicability of our proposed concepts and visualization techniques, and show that our tool helps domain experts to gain new insights and improve their workflow efficiency.	Johannes Weissenbock;Artem Amirkhanov;Eduard Gröller;Johann Kastner;Christoph Heinzl	University of Applied Sciences, Upper Austria, Wels, Austria;University of Applied Sciences, Upper Austria, Wels, Austria;TU Wien, Vienna, Austria;University of Applied Sciences, Upper Austria, Wels, Austria;University of Applied Sciences, Upper Austria, Wels, Austria	10.1109/TVCG.2013.147;10.1109/TVCG.2008.153;10.1109/VISUAL.1993.398859;10.1109/TVCG.2012.200;10.1109/TVCG.2011.253;10.1109/TVCG.2014.2346321;10.1109/TVCG.2013.177;10.1109/TVCG.2011.248		University of Applied Sciences, Upper Austria, Wels, Austria##University of Applied Sciences, Upper Austria, Wels, Austria##TU Wien, Vienna, Austria##University of Applied Sciences, Upper Austria, Wels, Austria##University of Applied Sciences, Upper Austria, Wels, Austria
VAST	2016	DropoutSeer: Visualizing learning patterns in Massive Open Online Courses for dropout reasoning and prediction	10.1109/VAST.2016.7883517	http://dx.doi.org/10.1109/VAST.2016.7883517	111	120	C	Aiming at massive participation and open access education, Massive Open Online Courses (MOOCs) have attracted millions of learners over the past few years. However, the high dropout rate of learners is considered to be one of the most crucial factors that may hinder the development of MOOCs. To tackle this problem, statistical models have been developed to predict dropout behavior based on learner activity logs. Although predictive models can foresee the dropout behavior, it is still difficult for users to understand the reasons behind the predicted results and further design interventions to prevent dropout. In addition, with a better understanding of dropout, researchers in the area of predictive modeling in turn can improve the models. In this paper, we introduce DropoutSeer, a visual analytics system which not only helps instructors and education experts understand the reasons for dropout, but also allows researchers to identify crucial features which can further improve the performance of the models. Both the heterogeneous data extracted from three different kinds of learner activity logs (i.e., clickstream, forum posts and assignment records) and the predicted results are visualized in the proposed system. Case studies and expert interviews have been conducted to demonstrate the usefulness and effectiveness of DropoutSeer.	Yuanzhe Chen;Qing Chen;Mingqian Zhao;Sebastien Boyer;Kalyan Veeramachaneni;Huamin Qu	Hong Kong University of Science and Technology, China;Hong Kong University of Science and Technology, China;Hong Kong University of Science and Technology, China;Massachusetts Institute of Technology, United States of America;Massachusetts Institute of Technology, United States of America;Hong Kong University of Science and Technology, China	10.1109/INFVIS.1999.801851;10.1109/TVCG.2015.2468151;10.1109/INFVIS.2000.885098;10.1109/VAST.2010.5652931;10.1109/TVCG.2010.129;10.1109/VAST.2012.6400557;10.1109/INFVIS.2001.963273;10.1109/TVCG.2013.221;10.1109/TVCG.2007.70515;10.1109/TVCG.2011.239		Hong Kong University of Science and Technology, China##Hong Kong University of Science and Technology, China##Hong Kong University of Science and Technology, China##Massachusetts Institute of Technology, United States of America##Massachusetts Institute of Technology, United States of America##Hong Kong University of Science and Technology, China
VAST	2016	Shape Grammar Extraction for Efficient Query-by-Sketch Pattern Matching in Long Time Series	10.1109/VAST.2016.7883518	http://dx.doi.org/10.1109/VAST.2016.7883518	121	130	C	Long time-series, involving thousands or even millions of time steps, are common in many application domains but remain very difficult to explore interactively. Often the analytical task in such data is to identify specific patterns, but this is a very complex and computationally difficult problem and so focusing the search in order to only identify interesting patterns is a common solution. We propose an efficient method for exploring user-sketched patterns, incorporating the domain expert's knowledge, in time series data through a shape grammar based approach. The shape grammar is extracted from the time series by considering the data as a combination of basic elementary shapes positioned across different amplitudes. We represent these basic shapes using a ratio value, perform binning on ratio values and apply a symbolic approximation. Our proposed method for pattern matching is amplitude-, scale- and translation-invariant and, since the pattern search and pattern constraint relaxation happen at the symbolic level, is very efficient permitting its use in a real-time/online system. We demonstrate the effectiveness of our method in a case study on stock market data although it is applicable to any numeric time series data.	Prithiviraj K. Muthumanickam;Katerina Vrotsou;Matthew D. Cooper;Jimmy Johansson	Linköping University, Sweden;Linköping University, Sweden;Linköping University, Sweden;Linköping University, Sweden	10.1109/TVCG.2008.184;10.1109/VAST.2010.5652530;10.1109/TVCG.2009.200;10.1109/TVCG.2010.137		Linköping University, Sweden##Linköping University, Sweden##Linköping University, Sweden##Linköping University, Sweden
VAST	2016	The semantics of sketch: Flexibility in visual query systems for time series data	10.1109/VAST.2016.7883519	http://dx.doi.org/10.1109/VAST.2016.7883519	131	140	C	Sketching allows analysts to specify complex and free-form patterns of interest. Visual query systems can make use of sketches to locate these patterns of interest in large datasets. However, sketching is ambiguous: the same drawing could represent a multitude of potential queries. In this work, we investigate these ambiguities as they apply to visual query systems for time series data. We define a class of &#x201C;invariants&#x201D; - the properties of a time series that the analyst wishes to ignore when performing a sketch-based query. We present the results of a crowd-sourced study, showing that these invariants are key components of how people rate the strength of match between sketch and target. We adapt a number of algorithms for time series matching to support invariants in sketches. Lastly, we present a web-deployed prototype sketch-based visual query system that relies on these invariants. We apply the prototype to data from finance, the digital humanities, and political science.	Michael Correll;Michael Gleicher	University of Washington, United States of America;University of Wisconsin-Madison, United States of America	10.1109/TVCG.2014.2346455;10.1109/INFVIS.2005.1532144;10.1109/TVCG.2013.191;10.1109/TVCG.2012.204;10.1109/TVCG.2014.2346452;10.1109/TVCG.2010.162		University of Washington, United States of America##University of Wisconsin-Madison, United States of America
VAST	2016	Visual analysis and coding of data-rich user behavior	10.1109/VAST.2016.7883520	http://dx.doi.org/10.1109/VAST.2016.7883520	141	150	C	Investigating user behavior involves abstracting low-level events to higher-level concepts. This requires an analyst to study individual user activities, assign codes which categorize behavior, and develop a consistent classification scheme. To better support this reasoning process of an analyst, we suggest a novel visual analytics approach which integrates rich user data including transcripts, videos, eye movement data, and interaction logs. Word-sized visualizations embedded into a tabular representation provide a space-efficient and detailed overview of user activities. An analyst assigns codes, grouped into code categories, as part of an interactive process. Filtering and searching helps to select specific activities and focus an analysis. A comparison visualization summarizes results of coding and reveals relationships between codes. Editing features support efficient assignment, refinement, and aggregation of codes. We demonstrate the practical applicability and usefulness of our approach in a case study and describe expert feedback.	Tanja Blascheck;Fabian Beck;Sebastian Baltes;Thomas Ertl;Daniel Weiskopf	University of Stuttgart, Germany;University of Stuttgart, Germany;University of Trier, Germany;University of Stuttgart, Germany;University of Stuttgart, Germany	10.1109/VAST.2009.5333443;10.1109/VISUAL.1990.146402;10.1109/TVCG.2011.226;10.1109/TVCG.2014.2346452;10.1109/TVCG.2008.137;10.1109/TVCG.2015.2467611;10.1109/TVCG.2015.2467757;10.1109/TVCG.2010.194;10.1109/TVCG.2014.2346677;10.1109/VAST.2008.4677365;10.1109/TVCG.2013.124		University of Stuttgart, Germany##University of Stuttgart, Germany##University of Trier, Germany##University of Stuttgart, Germany##University of Stuttgart, Germany